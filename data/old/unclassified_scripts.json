[{"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "d3100c33bc35c8d2de9c2abfcdcb21279695073d", "filename": "handlers/reload_consul_conf.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# Use SIGHUP to reload most configurations as per https://www.consul.io/docs/agent/options.html\n# Cannot use `consul reload` because it requires the HTTP API to be bound to a non-loopback interface\n\n- name: reload consul configuration on Linux\n  command: \"pkill --pidfile '{{ consul_run_path }}/consul.pid' --signal SIGHUP\"\n  when: ansible_os_family != \"Windows\"\n  listen: 'reload consul configuration'\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "4066bf28fc6bf58d40e4afeec462a0b66e4598ee", "filename": "roles/registrator/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for registrator\nregistrator_image: \"gliderlabs/registrator:master\"\nregistrator_uri: \"consul://{{ ansible_default_ipv4.address }}:8500\"\nregistrator_rebuild_container: False\nregistrator_docker_socket: \"/var/run/weave/weave.sock\"\n"}, {"commit_sha": "b02504a0a0a8b0e4169d0327a865dfe08866e9ec", "sha": "1f2798faffc673642721a0ebb4e8cb4398d3a499", "filename": "tasks/server.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/server.yml: Deploy Sensu Server/API\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure the Sensu config directory is present\n    file:\n      dest: \"{{ sensu_config_path }}/conf.d\"\n      state: directory\n      recurse: true\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n\n  - name: Deploy Sensu server API configuration\n    template:\n      dest: \"{{ sensu_config_path }}/conf.d/api.json\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      src: sensu-api.json.j2\n    notify: restart sensu-api service\n\n  - name: Deploy Sensu redis configuration\n    template:\n      dest: \"{{ sensu_config_path }}/conf.d/redis.json\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      src: sensu-redis.json.j2\n    notify: restart sensu-api service\n\n  - include: SmartOS/server.yml\n    when: ansible_distribution == \"SmartOS\"\n\n  - name: Ensure Sensu server service is running\n    service: name=sensu-server state=started enabled=yes\n\n  - name: Ensure Sensu API service is running\n    service: name=sensu-api state=started enabled=yes\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "e69de29bb2d1d6434b8b29ae775ad8c2e48c5391", "filename": "roles/prometheus/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": ""}, {"commit_sha": "15d2da095f9bd54a50954dee18597710e1951943", "sha": "82410332113af97e65d0c6da3fae655d144b2bae", "filename": "meta/main.yml", "repository": "ansiblebit/oracle-java", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# file: oracle-java/meta/main.yml\n#\n# meta file\n#\n\ngalaxy_info:\n  author: Pedro Salgado\n  description: Role to install Oracle Java.\n  company: ansiblebit.org\n  license: BSD\n  min_ansible_version: 2.0\n  platforms:\n    - name: CentOS\n      versions:\n        - all\n        - any\n        - 7\n        - 6\n    - name: Debian\n      versions:\n        - jessie\n        - wheezy\n    - name: RedHat\n      versions:\n        - all\n        - any\n        - 7\n        - 6\n    - name: Ubuntu\n      versions:\n        - xenial\n        - vivid\n        - trusty\n        - precise\n  galaxy_tags:\n    - development\n    - java\n    - system\n"}, {"commit_sha": "35ca6852d9333ef6c3ed223239f45b840c487d60", "sha": "dc1a95a34120575072494e88b77326d9fe4b594e", "filename": "roles/marathon/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for marathon\n- name: Set Marathon hostname\n  sudo: yes\n  copy:\n    content: \"{{marathon_local_address}}\"\n    dest: /etc/marathon/conf/hostname\n    mode: 0644\n  notify:\n    - Restart marathon\n  tags:\n    - marathon\n\n- name: Set Marathon consul service definition\n  sudo: yes\n  template:\n    src: marathon-consul.j2\n    dest: \"{{ consul_dir }}/marathon.json\"\n  notify:\n    - Restart consul\n  tags:\n    - marathon\n\n- name: remove marathon override\n  sudo: yes\n  file:\n    path: /etc/init/marathon.override\n    state: absent\n  tags:\n    - marathon\n\n- name: ensure marathon is running (and enable it at boot)\n  sudo: yes\n  service:\n    name: marathon\n    state: started\n    enabled: yes\n  tags:\n    - marathon\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "6fa2d9166df503bb30536ffb9a82880f9e61cc05", "filename": "roles/docker/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for docker\n- name: remove docker override\n  file:\n    path: /etc/init/docker.override\n    state: absent\n  notify:\n    - restart docker\n  tags:\n    - docker\n\n- name: configure docker graph directory\n  sudo: yes\n  lineinfile:\n    dest: /etc/default/docker\n    state: present\n    regexp: ^DOCKER_OPTS=.*--graph.*\n    line: 'DOCKER_OPTS=\\\"$DOCKER_OPTS --graph={{ docker_graph_dir }} --dns 172.17.0.1 --dns 8.8.8.8 --dns-search service.{{ consul_domain }} \\\"'\n  notify:\n    - restart docker\n\n- name: configure docker temporary directory\n  sudo: yes\n  lineinfile:\n    dest: /etc/default/docker\n    state: present\n    line: 'DOCKER_TMPDIR=\\\"{{ docker_tmp_dir }}\\\"'\n  notify:\n    - restart docker\n\n- name: configure docker proxy\n  sudo: yes\n  lineinfile:\n    dest: /etc/default/docker\n    state: present\n    line: 'export http_proxy=\\\"{{ http_proxy }}\\\"'\n  when: http_proxy is defined and http_proxy != ''\n\n- name: ensure docker is running (and enable it at boot)\n  service:\n    name: docker\n    state: started\n    enabled: yes\n  tags:\n    - docker\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "2c72c5088f7b06fd840664c149601bf9b5a7f9e5", "filename": "handlers/restart_rsyslog.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n- name: restart rsyslog\n  service:\n    name: rsyslog\n    state: restarted\n  when: ansible_os_family != \"Windows\"\n  listen: 'restart rsyslog'\n"}, {"commit_sha": "92d2f38d01d7b33610c667cfdc03e28ab2912edc", "sha": "7d152ef249e47a5927c2c22f4b1de74c238a3f72", "filename": "tasks/section_08_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n#  - name: 8.2 Configure rsyslog\n#  The rsyslog software is recommended as a replacement for the default syslogd daemon and\n#  provides improvements over syslogd, such as connection-oriented (i.e. TCP) transmission\n#  of logs, the option to log to database formats, and the encryption of log data en route to a\n#  central logging server.\n#  tags:\n#    - section8\n#    - section8.2\n\n\n  - name: 8.2.1 Install the rsyslog package (Scored)\n    apt: name=rsyslog state=present\n    tags:\n      - section8\n      - section8.2\n      - section8.2.1\n\n  - name: 8.2.2 Ensure the rsyslog Service is activated (Scored)\n    command: grep 'start on filesystem' /etc/rsyslog.conf\n    register: startonfilesystem\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.5.2 Configure rsyslog to Send Logs to a Remote Log Host (start rsyslog) (Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line='start on filesystem'\n       insertafter=EOF\n       state=present\n    when: startonfilesystem.rc == 1\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.3 Configure /etc/rsyslog.conf (Not Scored)\n    lineinfile:\n        dest: /etc/rsyslog.conf\n        line: \"{{ item }}\"\n        insertafter: EOF\n    with_items:\n      - '*.emerg :omusrmsg:*'\n      - 'mail.* -/var/log/mail'\n      - 'mail.info -/var/log/mail.info'\n      - 'mail.warning -/var/log/mail.warn'\n      - 'mail.err /var/log/mail.err'\n      - 'news.crit -/var/log/news/news.crit'\n      - 'news.err -/var/log/news/news.err'\n      - 'news.notice -/var/log/news/news.notice'\n      - '*.=warning;*.=err -/var/log/warn'\n      - '*.crit /var/log/warn'\n      - '*.*;mail.none;news.none -/var/log/messages'\n      - 'local0,local1.* -/var/log/localmessages'\n      - 'local2,local3.* -/var/log/localmessages'\n      - 'local4,local5.* -/var/log/localmessages'\n      - 'local6,local7.* -/var/log/localmessages'\n    changed_when: False\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.3\n\n  - name: 8.2.4.1 Create and Set Permissions on rsyslog Log Files (Scored)\n    shell: awk '{ print $NF }' /etc/rsyslog.d/* /etc/rsyslog.conf | grep -oiP \"/var/log/[\\w\\.-]+\"\n    register: result\n    changed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.4.2 Create and Set Permissions on rsyslog Log Files (Scored)\n    shell: 'mkdir -p -- \"$(dirname -- {{ item }})\"; touch -- {{ item }}' \n    with_items: \"{{result.stdout_lines}}\"\n    changed_when: False\n    register: rsyslog_files_created\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.4.3 Create and Set Permissions on rsyslog Log Files (Scored)\n    file:\n        path: \"{{ item }}\"\n        owner: root \n        group: \"{{ rsyslog_log_files_group }}\"\n        mode: \"{{ rsyslog_log_files_permissions }}\"\n    when: \"(rsyslog_files_created.results|length > 0) and ('skipped' not in rsyslog_files_created.results[0])\"\n    with_items: \"{{result.stdout_lines}}\"\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.5.1 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    command: grep \"^*.*[^I][^I]*@\" /etc/rsyslog.conf\n    register: remoteloghost \n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.5.2 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    lineinfile:\n        dest: /etc/rsyslog.conf\n        line: \"*.* @@{{remote_logs_host_address}}\"\n        insertafter: EOF\n        state: present\n    when: set_rsyslog_remote == True and remoteloghost.rc == 1\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.6.1 Accept Remote rsyslog Messages Only on Designated Log Hosts (Not Scored)\n    command: grep '^$ModLoad imtcp' /etc/rsyslog.conf\n    register: moadloadpresent\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.6\n\n  - name: 8.2.6.2 Accept Remote rsyslog Messages Only on Designated Log Hosts (Not Scored)\n    lineinfile:\n        dest: /etc/rsyslog.conf\n        regexp: \"^#({{ item }})\"\n        line: \"{{ item }}\"\n        state: present\n    with_items:\n        - '$ModLoad imtcp'\n        - '$InputTCPServerRun 514'\n    when: set_rsyslog_remote == True and moadloadpresent.rc == 1\n    changed_when: False\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.6\n"}, {"commit_sha": "df06f3c3304c3f73f740d444222642fbad41bebb", "sha": "0a83abaf83b1f92ffc8b54b1ff64227900b38d45", "filename": "tasks/openbsd_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Setup OpenBSD specific variables (set_fact)\n  set_fact:\n    tor_DataDir: /var/tor\n    tor_PidDir: /var/tor/pids\n  tags:\n   - reconfigure\n   - createdir\n\n- name: Ensure Tor is installed (OpenBSD)\n  become: yes\n  openbsd_pkg: name=tor state=present\n\n- name: Gather current system-wide file descriptor limits (OpenBSD)\n  shell: \"sysctl kern.maxfiles|cut -d= -f2\"\n  register: currentlimits\n\n- name: Ensure system-wide runtime file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  command: \"sysctl kern.maxfiles=20000\"\n  when: currentlimits.stdout|int < 20000\n\n- name: Ensure system-wide persistent file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  lineinfile: dest=/etc/sysctl.conf regexp=^kern.maxfiles line=\"kern.maxfiles=20000\" create=yes\n  when: currentlimits.stdout|int < 20000\n\n# We rise openfiles limits for every tor instance separately.\n# An instance is identified by its rc.d file name.\n- name: Ensure Tor process file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  lineinfile: \"dest=/etc/login.conf line='tor{{ item[0]| replace('.','_') }}_{{ item.1.orport }}::openfiles-max=13500::tc=daemon:'\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n  #TODO\n  #notify: restart tor\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "b1e95bfafea2e011017ac3d65d19c61efd4157a4", "filename": "roles/rabbitmq/handlers/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "- name: restart rabbitmq\n  sudo: true\n  service:\n    name: rabbitmq-server\n    state: restarted\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "7d8d28f9f1a854793194986ef9797453f5fb405b", "filename": "tasks/section_10_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 10.1.1.1 Set Password Expiration Days (check) (Scored)\n    command: grep -oP '(?<=^PASS_MAX_DAYS\\s)[0-9]+' /etc/login.defs\n    register: pass_max_days\n    changed_when: False\n    always_run: True\n    tags:\n      - section10\n      - section10.1\n      - section10.1.1\n\n  - name: 10.1.1.2 Set Password Expiration Days (Scored)\n    lineinfile: >\n        dest='/etc/login.defs'\n        line='PASS_MAX_DAYS 90'\n        regexp='^PASS_MAX_DAYS'\n    when: pass_max_days.stdout_lines > 90\n    tags:\n      - section10\n      - section10.1\n      - section10.1.1\n\n  - name: 10.1.2.1 Set Password Change Minimum Number of Days (check) (Scored)\n    command: grep -oP '(?<=^PASS_MIN_DAYS\\s)[0-9]+' /etc/login.defs\n    register: pass_min_days\n    changed_when: False\n    always_run: True\n    tags:\n      - section10\n      - section10.1\n      - section10.1.2\n\n  - name: 10.1.2.2 Set Password Change Minimum Number of Days (Scored)\n    lineinfile: >\n        dest='/etc/login.defs'\n        line='PASS_MIN_DAYS 7'\n        regexp='^PASS_MIN_DAYS'\n    when: pass_min_days.stdout_lines < 7\n    tags:\n      - section10\n      - section10.1\n      - section10.1.2\n\n  - name: 10.1.3.1 Set Password Expiring Warning Days (check) (Scored)\n    command: grep -oP '(?<=^PASS_WARN_AGE\\s)[0-9]+' /etc/login.defs\n    register: pass_warn_age\n    changed_when: False\n    always_run: True\n    tags:\n      - section10\n      - section10.1\n      - section10.1.3\n\n  - name: 10.1.3.2 Set Password Expiring Warning Days (Scored)\n    lineinfile: >\n        dest='/etc/login.defs'\n        line='PASS_WARN_AGE 7'\n        regexp='^PASS_WARN_AGE'\n    when: pass_warn_age.stdout_lines < 7\n    tags:\n      - section10\n      - section10.1\n      - section10.1.3\n\n  - name: 10.2.1.1 Disable System Accounts (check) (Scored)\n    shell: awk -F':' '($1!=\"root\" && $1!=\"sync\" && $1!=\"shutdown\" &&$1!=\"halt\" && $3<500 && $7!=\"/usr/sbin/nologin\" && $7!=\"/bin/false\") {print $1}' /etc/passwd\n    register: awk_etc_passwd\n    changed_when: False\n    always_run: True\n    tags:\n      - section10\n      - section10.2\n\n  - name: 10.2.2.2 Disable System Accounts (Scored)\n    command: /usr/sbin/usermod -s /usr/sbin/nologin {{ item }}\n    with_items: \"{{awk_etc_passwd.stdout_lines}}\"\n    tags:\n      - section10\n      - section10.2\n\n  - name: 10.3 Set Default Group for root Account (Scored)\n    user: >\n        name=root\n        group=root\n    tags:\n      - section10\n      - section10.3\n\n  - name: 10.4 Set Default umask for Users (Scored)\n    lineinfile: >\n        dest=/etc/login.defs\n        line='UMASK\\t077'\n        regexp='^UMASK'\n        state=present\n    tags:\n      - section10\n      - section10.4\n\n  - name: 10.5.1 Lock Inactive User Accounts (check) (Scored)\n    command: grep INACTIVE /etc/login.defs\n    changed_when: False\n    failed_when: False\n    always_run: True\n    register: lock_inactive_rc\n    tags:\n      - section10\n      - section10.5\n        \n  - name: 10.5.2 Lock Inactive User Accounts (Scored)\n    lineinfile: >\n        dest=/etc/login.defs\n        line='INACTIVE=35'\n        state=present\n    when: lock_inactive_rc.rc == 1\n    tags:\n      - section10\n      - section10.5\n\n"}, {"commit_sha": "c7cf019326c96b15ccee3b7bf4e14ff0bb894cf0", "sha": "ce10ca7f122ce605e82a2119384dd011b6728c2f", "filename": "meta/main.yml", "repository": "willshersystems/ansible-sshd", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Matt Willsher\n  description: OpenSSH SSH deamon configuration\n  company: Willsher Systems\n  license: LGPLv3\n  min_ansible_version: 1.8\n  platforms:\n  - name: Debian\n    versions:\n    - wheezy\n    - jessie\n  - name: Ubuntu\n    versions:\n    - precise\n    - trusty\n  - name: FreeBSD\n    version:\n    - 10.1\n  - name: EL\n    versions:\n    - 6\n    - 7\n  - name: Fedora\n    versions:\n    - 20\n    - 22\n  categories:\n  - networking\n  - system\ndependencies: []\n"}, {"commit_sha": "067d6cbb20adb31a1e2bd9f689b5b6e259c30288", "sha": "6b463b1541fde0430d31f1ee5361b43d6126773b", "filename": "tasks/section_08_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n#  - name: 8.2 Configure rsyslog\n#  The rsyslog software is recommended as a replacement for the default syslogd daemon and\n#  provides improvements over syslogd, such as connection-oriented (i.e. TCP) transmission\n#  of logs, the option to log to database formats, and the encryption of log data en route to a\n#  central logging server.\n#  tags:\n#    - section8\n#    - section8.2\n\n\n  - name: 8.2.1 Install the rsyslog package (Scored)\n    apt: name=rsyslog state=present\n    tags:\n      - section8\n      - section8.2\n      - section8.2.1\n\n  - name: 8.2.2 Ensure the rsyslog Service is activated (Scored)\n    command: grep 'start on filesystem' /etc/rsyslog.conf\n    register: startonfilesystem\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.5.2 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line='start on filesystem'\n       insertafter=EOF\n       state=present\n    when: startonfilesystem.rc == 1\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.3 Configure /etc/rsyslog.conf (Not Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line=\"{{ item }}\"\n       insertafter=EOF\n    with_items:\n      - '*.emerg :omusrmsg:*'\n      - 'mail.* -/var/log/mail'\n      - 'mail.info -/var/log/mail.info'\n      - 'mail.warning -/var/log/mail.warn'\n      - 'mail.err /var/log/mail.err'\n      - 'news.crit -/var/log/news/news.crit'\n      - 'news.err -/var/log/news/news.err'\n      - 'news.notice -/var/log/news/news.notice'\n      - '*.=warning;*.=err -/var/log/warn'\n      - '*.crit /var/log/warn'\n      - '*.*;mail.none;news.none -/var/log/messages'\n      - 'local0,local1.* -/var/log/localmessages'\n      - 'local2,local3.* -/var/log/localmessages'\n      - 'local4,local5.* -/var/log/localmessages'\n      - 'local6,local7.* -/var/log/localmessages'\n    changed_when: False\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.3\n\n  - name: 8.2.4.1 Create and Set Permissions on rsyslog Log Files (Scored)\n    shell: awk '{ print $NF }' /etc/rsyslog.d/* /etc/rsyslog.conf | grep /var/log | sed 's/^-//' | sed 's/)$//' \n    register: result\n    changed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.4.2 Create and Set Permissions on rsyslog Log Files (Scored)\n    shell: 'mkdir -p -- \"$(dirname -- {{ item }})\"; touch -- {{ item }}' \n    with_items: result.stdout_lines          \n    changed_when: False\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.4.3 Create and Set Permissions on rsyslog Log Files (Scored)\n    file: >\n        path='{{item}}' \n        owner=root \n        group=root \n        mode=\"og-rwx\" \n    with_items: result.stdout_lines\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.5.1 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    command: grep \"^*.*[^I][^I]*@\" /etc/rsyslog.conf\n    register: remoteloghost \n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.5.2 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line=\"*.* @@{{remote_logs_host_address}}\"\n       insertafter=EOF\n       state=present\n    when: set_rsyslog_remote == True and remoteloghost.rc == 1\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.6.1 Accept Remote rsyslog Messages Only on Designated Log Hosts (Not Scored)\n    command: grep '^$ModLoad imtcp' /etc/rsyslog.conf\n    register: moadloadpresent\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.6\n\n  - name: 8.2.6.2 Accept Remote rsyslog Messages Only on Designated Log Hosts (Not Scored)\n    lineinfile: >\n        dest=/etc/rsyslog.conf\n        regexp='^#({{ item }})'\n        line='{{ item }}'\n        state=present\n    with_items:\n        - '$ModLoad imtcp'\n        - '$InputTCPServerRun 514'\n    when: set_rsyslog_remote == True and moadloadpresent.rc == 1\n    changed_when: False\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.6\n"}, {"commit_sha": "5eb44163b7f6328c1f30168fa86326458d5dbaff", "sha": "93232d84320723e14cda3deb1fe351fdae1d1e66", "filename": "tasks/check_environment.yml", "repository": "ansiblebit/oracle-java", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# file: oracle-java/tasks/check_environment.yml\n#\n# task to set host facts:\n#   - Java is installed?\n#   - which Java version is installed?\n#\n\n# determine if Java is already installed\n\n- name: register oracle_java_installed\n  shell: \"which java\"\n  register: oracle_java_task_installed\n  ignore_errors: yes\n  changed_when: False\n# oracle_java_installed.rc == 0 : installed\n# oracle_java_installed.rc == 1 : not installed\n\n- name: echo oracle_java_task_installed\n  debug:\n    msg=\"oracle_java_task_installed={{ oracle_java_task_installed }}\"\n  when: oracle_java_task_installed is defined\n  tags:\n    - debug\n\n- name: set fact oracle_java_installed\n  set_fact:\n    oracle_java_installed={{ oracle_java_task_installed.rc == 0 }}\n  changed_when: False\n\n- name: echo oracle_java_installed\n  debug:\n    msg=\"oracle_java_installed={{ oracle_java_installed }}\"\n  when: oracle_java_installed is defined\n  tags:\n    - debug\n\n\n# determine which Java version is installed\n\n- name: if Java is installed, check version\n  shell: java -version 2>&1 | head -n 1 | awk '{ print $3 }' | awk -F '\"' '{ print $2 }'\n  when: oracle_java_installed\n  register: oracle_java_task_version\n  changed_when: False\n\n- name: echo oracle_java_task_version\n  debug:\n    msg=\"oracle_java_task_version={{ oracle_java_task_version }}\"\n  when: oracle_java_task_version is defined\n  tags:\n    - debug\n\n- name: set fact oracle_java_installed_version\n  set_fact:\n    oracle_java_version_installed={{ oracle_java_task_version.stdout }}\n  when: oracle_java_installed\n  changed_when: False\n\n- name: echo oracle_java_version_installed\n  debug:\n    msg=\"oracle_java_version_installed={{ oracle_java_version_installed }}\"\n  when: oracle_java_version_installed is defined\n  tags:\n    - debug\n\n- name: echo oracle_java_version_string\n  debug:\n    msg=\"oracle_java_version_string={{ oracle_java_version_string }}\"\n  when: oracle_java_version_string is defined\n  tags:\n    - debug\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "f607079e7a2f67b67bbbcbc26e0b0fc801de6665", "filename": "tasks/syslog.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# File: syslog.yml - syslog config for Consul logging\n\n- name: Detect syslog program\n  stat:\n    path: /usr/sbin/syslog-ng\n  register: stat_syslogng\n  when:\n    - ansible_os_family != 'Windows'\n    - consul_configure_syslogd | bool\n\n- name: Install syslog-ng config\n  template:\n    src: syslogng_consul.conf.j2\n    dest: /etc/syslog-ng/conf.d/consul.conf\n    owner: root\n    group: root\n    mode: 0444\n  when:\n    - ansible_os_family != 'Windows'\n    - consul_syslog_enable | bool\n    - consul_configure_syslogd | bool\n    - stat_syslogng.stat.exists\n  notify:\n    - restart syslog-ng\n    - restart consul\n\n- name: Install rsyslogd config\n  template:\n    src: rsyslogd_00-consul.conf.j2\n    dest: /etc/rsyslog.d/00-consul.conf\n    owner: root\n    group: root\n    mode: 0444\n  when:\n    - ansible_os_family != 'Windows'\n    - consul_syslog_enable | bool\n    - consul_configure_syslogd | bool\n    - not stat_syslogng.stat.exists\n  notify:\n    - restart rsyslog\n    - restart consul\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "677d1f9caa2f6a3ea4f0694224993b7674c23fc8", "filename": "tasks/section_11.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - include: section_11_level1.yml\n    tags:\n      - section11\n      - level1\n\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "30cb3a698bf679e0fe4f429efa90e4ea8ebc0272", "filename": "roles/marathon/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for marathon\n- name: wait for marathon to listen\n  command: /usr/local/bin/marathon-wait-for-listen.sh"}, {"commit_sha": "af3dfdf7cf37437f5609f1a12e4ac7cbaebd4867", "sha": "9c391940ff4c06eb33fba574502f64a88ffef27c", "filename": "roles/registrator/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n# Install (docker-py) python package as is a docker module dependency.\n- pip:\n    name: docker-py\n    version: 1.1.0\n  environment: proxy_env\n  tags:\n    - registrator\n\n# tasks file for docker registrator\n- name: run registrator container\n  docker:\n    name: registrator\n    image: \"{{ registrator_image }}\"\n    state: started\n    restart_policy: always\n    net: host\n    command: \"-internal {{ registrator_uri }}\"\n    volumes:\n    - \"/var/run/docker.sock:/tmp/docker.sock\"\n  environment: proxy_env\n  tags:\n    - registrator\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "70adf5b652bb2021cc4bc2f70564510e08f8a5d4", "filename": "roles/mesos_maintenance/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n- include: schedule.yml\n  when: mesos_maintenance_schedule\n\n- include: start.yml\n  when: mesos_maintenance_start\n\n- include: complete.yml\n  when: mesos_maintenance_complete\n"}, {"commit_sha": "21712b74b7f5d936e70186bbed6bb37e3a7ad5e6", "sha": "e6713f88cbdb0dc81efc32cfec442b8b365a0327", "filename": "roles/frameworks/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for frameworks\nframeworks_dcos_cli_image: capgemini/dcos-cli\nframeworks_zk_master_peers: \"zk://{{ zookeeper_peers_nodes }}/mesos\"\nframeworks_mesos_master_url: \"http://{{ ansible_ssh_host }}:5050\"\nframeworks_marathon_url: \"http://{{ ansible_ssh_host }}:8080\"\nframeworks_sources: '[\"https://github.com/Capgemini/universe/archive/version-1.x.zip\",]'\nframeworks_list:\n  - cassandra\n  - chronos\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "9f897fcac8cd6be5ce5044ccfa9fb7a82e11237e", "filename": "roles/mesos/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for mesos\n- name: start mesos master\n  become: yes\n  service:\n    name: mesos-master\n    state: started\n\n- name: start mesos slave\n  become: yes\n  service:\n    name: mesos-slave\n    state: started\n\n- name: restart mesos master\n  become: yes\n  service:\n    name: mesos-master\n    state: restarted\n\n- name: restart mesos slave\n  become: yes\n  service:\n    name: mesos-slave\n    state: restarted\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "637c9be9c788d199b34d176bd639059eb9ec1b79", "filename": "roles/st2repos/vars/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# vars file for st2repos\n"}, {"commit_sha": "584d564218d6e2e63d3ecca157daf817fe4d533c", "sha": "f40da9be66a47c62e89654001417e792e2b74fca", "filename": "tasks/camera.yml", "repository": "mikolak-net/ansible-raspi-config", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n- name: camera - ensure memory\n  pi_boot_config: config_vals=gpu_mem=128\n  when: raspi_config_enable_camera and raspi_config_memory_split_gpu < raspi_config_min_camera_mem\n- name: camera - set state\n  pi_boot_config: config_vals=start_x={{raspi_config_enable_camera|int}}\n  notify:\n    - apply raspi-config\n    - reboot"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "d4da6778abf0e637bac299093d26411502de9d52", "filename": "roles/dcos_cli/vars/chronos.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "dcos_cli_framework_chronos_enabled: \"{{ chronos_enabled }}\"\ndcos_cli_framework_chronos_mem: 512\ndcos_cli_framework_chronos_cpus: 0.5\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "6a9d803e92a3c73243dc7bd4dc2c5b85ec52db22", "filename": "roles/dcos_cli/vars/prometheus.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "dcos_cli_app_prometheus_enabled: \"{{ prometheus_enabled }}\"\ndcos_cli_app_prometheus_mem: 128\ndcos_cli_app_prometheus_cpus: 0.5\ndcos_cli_app_prometheus_instances: 1\ndcos_cli_app_prometheus_image: prom/prometheus\ndcos_cli_app_prometheus_image_tag: 0.16.1\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "98044d60d48e0dde43aaa3995dbf21a6125b02bb", "filename": "tasks/CentOS/main.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/CentOS/main.yml: CentOS specific set-up\n# This takes care of base prerequisites for CentOS\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure the Sensu Core Yum repo is present\n    copy:\n      dest: /etc/yum.repos.d/sensu.repo\n      content: |\n        [sensu]\n        name=sensu\n        baseurl=https://sensu.global.ssl.fastly.net/yum/$releasever/$basearch/\n        gpgcheck=0\n        enabled=1\n      owner: root\n      group: root\n      mode: 0644\n\n  - name: Ensure that credential is supplied if installing Sensu Enterprise\n    assert:\n      that:\n        - \"se_user != ''\"\n        - \"se_pass != ''\"\n      msg: Sensu enterprise credential must not be empty. Did you forget to set se_user and se_pass?\n    when: se_enterprise\n\n  - name: Ensure the Sensu Enterprise repo is present\n    copy:\n      dest: /etc/yum.repos.d/sensu-enterprise.repo\n      content: |\n        [sensu-enterprise]\n        name=sensu-enterprise\n        baseurl=http://{{ se_user }}:{{ se_pass }}@enterprise.sensuapp.com/yum/noarch/\n        gpgcheck=0\n        enabled=1\n      owner: root\n      group: root\n      mode: 0644\n    when: se_enterprise\n\n  - name: Ensure the Sensu Enterprise Dashboard repo is present\n    copy:\n      dest: /etc/yum.repos.d/sensu-enterprise-dashboard.repo\n      content: |\n        [sensu-enterprise-dashboard]\n        name=sensu-enterprise-dashboard\n        baseurl=http://{{ se_user }}:{{ se_pass }}@enterprise.sensuapp.com/yum/\\$basearch/\n        gpgcheck=0\n        enabled=1\n      owner: root\n      group: root\n      mode: 0644\n    when: se_enterprise\n\n  - name: Ensure Sensu is installed\n    yum: name={{ sensu_package }} state={{ sensu_pkg_state }}\n\n  - name: Ensure Sensu Enterprise is installed\n    yum: name={{ sensu_enterprise_package }} state={{ sensu_pkg_state }}\n    when: se_enterprise\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "261fd40a1c28396631c44c7da755ce451a89dacf", "filename": "tasks/section_03_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n#sections 3.3 and 3.4 have to happen before as the latter overwrite 3.1 and 3.2\n\n  - name: 3.0 Check for /boot/grub/grub.cfg file (Not Scored)\n    stat: path=/boot/grub/grub.cfg\n    register: grub_cfg_file\n    tags:\n      - section3\n\n  - name: 3.3.1.1 Set Boot Loader Superuser (check) (Scored)\n    command: grep \"^set superusers\" /boot/grub/grub.cfg\n    register: boot_superusers\n    when: grub_cfg_file.stat.exists == True\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section3\n      - section3.3\n      - section3.3.1\n      - section3.3.1.1\n\n  - name: 3.3.1.2 Set Boot Loader Superuser (Scored)\n    lineinfile: >\n        dest='/etc/grub.d/40_custom'\n        regexp='^set superusers'\n        line='set superusers=\"root\"'\n        state=present\n        create=yes\n    when: grub_cfg_file.stat.exists == True and boot_superusers.rc == 1\n    tags:\n      - section3\n      - section3.3\n      - section3.3.1\n      - section3.3.1.2\n\n  - name: 3.3.2.1 Set Boot Loader Password (check) (Scored)\n    command: grep \"^password\" /boot/grub/grub.cfg\n    register: boot_password\n    when: grub_cfg_file.stat.exists == True\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section3\n      - section3.3\n      - section3.3.2\n      - section3.3.2.1\n\n  - name: 3.3.2.2 Set Boot Loader Password (Scored)\n    lineinfile: >\n        dest='/etc/grub.d/40_custom'\n        regexp='^password'\n        line=\"password_pbkdf2 root {{root_password_grub}}\"\n        state=present\n    when: grub_cfg_file.stat.exists == True and boot_password.rc == 1\n    tags:\n      - section3\n      - section3.3\n      - section3.3.2\n      - section3.3.2.2\n\n  - name: 3.3.3 Disable password protection booting (Scored)\n    lineinfile: >\n        dest='/etc/grub.d/10_linux'\n        create=yes\n        regexp='^CLASS='\n        line='CLASS=\"--class gnu-linux --class gnu --class os --unrestricted\"'\n        state=present\n    tags:\n      - section3\n      - section3.3\n      - section3.3.3\n\n\n  - name: 3.3.4 Update Grub configuration (Scored)\n    command: update-grub\n    when: grub_cfg_file.stat.exists == True and (boot_superusers.rc == 1 or boot_password.rc == 1)\n    tags:\n      - section3\n      - section3.3\n      - section3.3.4\n\n\n  - name: 3.4.1 Require Authentication for Single-User Mode (check) (Scored)\n    shell: 'grep \"^root:[*\\!]:\" /etc/shadow'\n    register: root_password_set\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section3\n      - section3.4\n      - section3.4.1\n\n  - name: 3.4.2 Require Authentication for Single-User Mode (Scored)\n    user: name=root state=present password='{{ root_password }}'\n    when: root_password_set.rc == 1\n    tags:\n      - section3\n      - section3.4\n      - section3.4.2\n\n  - name: 3.1 Set User/Group Owner on bootloader config (Scored)\n    file: path=/boot/grub/grub.cfg owner=root group=root\n    when: grub_cfg_file.stat.exists == True\n    tags:\n      - section3\n      - section3.1\n\n  - name: 3.2 Set Permissions on bootloader config (Scored)\n    file: path=/boot/grub/grub.cfg mode=\"o-rwx,g-rwx\"\n    when: grub_cfg_file.stat.exists == True\n    become: yes\n    tags:\n      - section3\n      - section3.2\n"}, {"commit_sha": "61b008311c40b377e57e166b778232a20224f7c6", "sha": "290a74d428e3a3369a95a53f90054a69ec1c4672", "filename": "handlers/main.yml", "repository": "UnderGreen/ansible-role-mongodb", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: mongodb reload\n  service: name={{ mongodb_daemon_name }} state=reloaded\n  when: mongodb_manage_service\n\n- name: mongodb restart\n  service: name={{ mongodb_daemon_name }} state=restarted\n  when: mongodb_manage_service\n\n- name: mongodb-mms-automation-agent restart\n  service: name=mongodb-mms-automation-agent state=restarted\n  when: mongodb_manage_service\n\n- name: reload systemd\n  shell: systemctl daemon-reload\n  when: systemd.stat.exists == true and mongodb_manage_service\n\n- name: restart sysfsutils\n  service: name=sysfsutils state=restarted\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "bf25230c6c8279c150360b50ed487f06a3391abc", "filename": "tasks/section_02_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 2.18 Disable Mounting of cramfs Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install cramfs /bin/true'\n        state=present\n        create=yes\n    tags:\n      - section2\n      - section2.18\n\n  - name: 2.19 Disable Mounting of freevxfs Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install freevxfs /bin/true'\n        state=present\n        create=yes\n    tags:\n      - section2\n      - section2.19\n\n  - name: 2.20 Disable Mounting of jffs2 Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install jffs2 /bin/true'\n        state=present\n        create=yes\n    tags:\n      - section2\n      - section2.20\n\n  - name: 2.21 Disable Mounting of hfs Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install hfs /bin/true'\n        state=present\n        create=yes\n    tags:\n      - section2\n      - section2.21\n\n  - name: 2.22 Disable Mounting of hfsplus Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install hfsplus /bin/true'\n        state=present\n        create=yes\n    tags:\n      - section2\n      - section2.22\n\n  - name: 2.23 Disable Mounting of squashfs Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install squashfs /bin/true'\n        state=present\n        create=yes\n    tags:\n      - section2\n      - section2.23\n\n  - name: 2.24 Disable Mounting of udf Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install udf /bin/true'\n        state=present\n        create=yes\n    tags:\n      - section2\n      - section2.24\n"}, {"commit_sha": "b02504a0a0a8b0e4169d0327a865dfe08866e9ec", "sha": "b418e92d53b848fe7036b272cc457915aa33d76c", "filename": "tasks/SmartOS/rabbit.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/SmartOS/rabbit.yml: Deploy RabbitMQ\n# Specific to Joyent SmartOS\n\n  - name: Ensure RabbitMQ is installed\n    pkgin: name=rabbitmq state=present\n  \n  - name: Ensure EPMD is running\n    service:\n      name: epmd\n      state: started\n      enabled: true\n"}, {"commit_sha": "a2393d46f0b98700161c4cefd9260d7694bd0bf3", "sha": "17df5f59b5d000afc9346a267aa8d8e8450deb22", "filename": "tasks/section_12_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 12.1 Verify Permissions on /etc/passwd (Scored)\n    file: path=/etc/passwd mode=0644\n    tags:\n      - section12\n      - section12.1\n\n  - name: 12.2 Verify Permissions on /etc/shadow (Scored)\n    file: path=/etc/shadow mode='o-rwx,g-rw'\n    tags:\n      - section12\n      - section12.2\n\n  - name: 12.3 Verify Permissions on /etc/group (Scored)\n    file: path=/etc/group mode=0644\n    tags:\n      - section12\n      - section12.3\n\n  - name: 12.4 Verify User/Group Ownership on /etc/passwd (Scored)\n    file: path=/etc/passwd owner=root group=root\n    tags:\n      - section12\n      - section12.4\n\n  - name: 12.5 Verify User/Group Ownership on /etc/shadow (Scored)\n    file: path=/etc/shadow owner=root group=shadow\n    tags:\n      - section12\n      - section12.5\n\n  - name: 12.6 Verify User/Group Ownership on /etc/group (Scored)\n    file: path=/etc/group owner=root group=root\n    tags:\n      - section12\n      - section12.6\n\n  - name: 12.7 Find World Writable Files (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -0002 -print\n    changed_when: False\n    failed_when: False\n    register: world_files\n    tags:\n      - section12\n      - section12.7\n\n  - name: 12.7 Find World Writable Files (Not Scored)\n    debug: msg={{ item }}\n    with_items:\n        world_files.stdout_lines\n    tags:\n      - section12\n      - section12.7\n\n  - name: 12.8 Find Un-owned Files and Directories (check) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -nogroup -ls\n    changed_when: False\n    failed_when: False\n    register: unowned_files\n    tags:\n      - section12\n      - section12.8\n\n  - name: 12.8 Find Un-owned Files and Directories (Scored)\n    debug: msg={{ item }}\n    with_items:\n        unowned_files.stdout_lines\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.9 Find Un-grouped Files and Directories (check) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -nogroup -ls\n    changed_when: False\n    failed_when: False\n    register: ungrouped_files\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.9 Find Un-grouped Files and Directories (Scored)\n    debug: msg={{ item }}\n    with_items:\n        ungrouped_files.stdout_lines\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.10 Find SUID System Executables (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -4000 -print\n    changed_when: False\n    failed_when: False\n    register: suid_files\n    tags:\n      - section12\n      - section12.10\n\n  - name: 12.10 Find SUID System Executables (Not Scored)\n    debug: msg={{ item }}\n    with_items:\n        suid_files.stdout_lines\n    tags:\n      - section12\n      - section12.10\n\n  - name: 12.11 Find SGID System Executables (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -2000 -print\n    changed_when: False\n    failed_when: False\n    register: gsuid_files\n    tags:\n      - section12\n      - section12.11\n\n  - name: 12.11 Find SGID System Executables (Not Scored)\n    debug: msg={{ item }}\n    with_items:\n        gsuid_files.stdout_lines\n    tags:\n      - section12\n      - section12.10\n"}, {"commit_sha": "694a4890fcf0daa375d6a173511f6ff7dd0f2335", "sha": "7b166d0eb1dfb898c58f8c9950665c1399a0e710", "filename": "meta/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: nusenu\n  description: An Ansible role for Tor Relay Operators\n  license: GPLv3\n  platforms:\n  - name: Debian\n    versions:\n    - jessie\n  - name: FreeBSD\n    versions:\n    - 10.1\n    - 10.2\n  - name: OpenBSD\n    versions:\n    - 5.9\n  - name: EL\n    versions:\n    - 7\n  - name: Ubuntu\n    versions:\n    - 15.10\n  - name: Fedora\n    versions:\n    - 23\n  galaxy_tags:\n    - tor\n    - relay\n    - anonymity\n    - networking\n  min_ansible_version: 1.9.4\ndependencies: []\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "c62dee936ecbf9a8c6bab613f5862646d37b9cd0", "filename": "roles/weave/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n# defaults file for weave\nweave_server_group: weave_servers\nweave_launch_peers: \"\n  {%- set weave_peers = [] -%}\n  {%- for host in groups[weave_server_group] -%}\n    {%- if host != inventory_hostname and host not in weave_peers -%}\n      {% do weave_peers.append(hostvars[host]['ansible_eth0']['ipv4']['address']) %}\n    {%- endif -%}\n  {%- endfor -%}\n  {{ weave_peers|join(' ') }}\n\"\n\nweave_version: 1.4.1\nweave_url: \"https://github.com/weaveworks/weave/releases/download/v{{ weave_version }}/weave\"\nweave_bin: /mnt/weave\n"}, {"commit_sha": "61b008311c40b377e57e166b778232a20224f7c6", "sha": "b2ea55b78289952433059ca16266d6701e6450df", "filename": "meta/main.yml", "repository": "UnderGreen/ansible-role-mongodb", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\ndependencies: []\n\ngalaxy_info:\n  author: Sergei Antipov\n  company: 2GIS\n  description: Manage MongoDB with authentication and replica sets\n  license: GPLv2\n  min_ansible_version: 1.8\n  platforms:\n  - name: Ubuntu\n    versions:\n    - trusty\n  - name: Debian\n    versions:\n    - wheezy\n    - jessie\n  categories:\n  - database\n  - database:nosql\n"}, {"commit_sha": "6d51642c8f7babe4c8185b60872420333a5d3caa", "sha": "09121f1976fb916931ff9a541bd6376edc1b67f2", "filename": "tasks/ssl.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/ssl.yml: Deploy the client SSL cert/key to client systems\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - include: ssl_generate.yml\n    when: sensu_ssl_gen_certs\n\n  - name: Deploy the Sensu client SSL cert/key\n    copy:\n      src: \"{{ item }}\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      dest: \"{{ sensu_config_path }}/ssl\"\n    with_items:\n      - \"{{ sensu_ssl_client_cert }}\"\n      - \"{{ sensu_ssl_client_key }}\"\n    notify: restart sensu-client service\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "165606ee1c36e67fe797dcf02913a199365a9ae0", "filename": "roles/zookeeper/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\nconsul_dir: /etc/consul.d\nzookeeper_config_dir: /etc/zookeeper/conf\nzookeeper_image: \"mesosphere/mesos:0.27.1-2.0.226.ubuntu1404\"\nzookeeper_client_port: 2181\nzookeeper_leader_connect_port: 2888\nzookeeper_leader_election_port: 3888\nzookeeper_server_group: zookeeper_servers\nzookeeper_id: \"\n\t{%- if zookeeper_host_list is defined -%}\n\t\t{%- for host in zookeeper_host_list.split() -%}\n\t\t\t{%- if host == ansible_eth0.ipv4.address -%}\n\t        \t{{ loop.index }}\n\t\t\t{%- endif -%}\n\t\t{%- endfor -%}\n\t{%- else -%}\n    \t{%- for host in groups[zookeeper_server_group] -%}\n      \t\t{%- if host == 'default' or host == inventory_hostname or host == ansible_fqdn or host in ansible_all_ipv4_addresses -%}\n        \t\t{{ loop.index }}\n  \t\t\t{%- endif -%}\n    \t{%- endfor -%}\n    {%- endif -%}\n\"\n"}, {"commit_sha": "9966c6de1ed4ef5071a9bea83b4bb69a11dd32ba", "sha": "d867caf763ca939aa06e45824e693de4e9c39d08", "filename": "roles/serverspec/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for serverspec\nserverspec_run_tests: false\nserverspec_tests_path: /vagrant/tests\nserverspec_install_bundler: true\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "eeddca97d5c70fe44719d383d17367b9242d0c85", "filename": "tasks/main.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/main.yml: \"Master\" playbook for the cmacrae.sensu role\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - include: \"{{ ansible_distribution }}/main.yml\"\n    tags: setup\n\n  - include: redis.yml\n    tags: redis\n    when: redis_server\n          and sensu_deploy_redis\n    static: false\n\n  - include: ssl.yml\n    tags: ssl\n\n  - include: rabbit.yml\n    tags: rabbitmq\n    when: rabbitmq_server\n          and sensu_deploy_rabbitmq\n    static: false\n\n  - include: common.yml\n    tags: common\n\n  - include: server.yml\n    tags: server\n    when: sensu_master\n    static: false\n\n  - include: dashboard.yml\n    tags: dashboard\n    when: sensu_include_dashboard\n    static: false\n\n  - include: client.yml\n    tags: client\n\n  - include: plugins.yml\n    tags: plugins\n    when: sensu_include_plugins\n    static: false\n"}, {"commit_sha": "f5364b57f100ae9fa898af59b7812ec0c447ac42", "sha": "ad567fdf2538c521ac0bdb3be64333d4a0841ec2", "filename": "tasks/configure.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Ensure local DataDir folders exist (LOCAL)\n  file:\n    path: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    state: directory\n    mode: 0700\n  delegate_to: 127.0.0.1\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - createdir\n\n- name: Ensure all relay keys exist (LOCAL)\n  local_action: command tor --PublishServerDescriptor 0 --orport auto --list-fingerprint --datadirectory \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}\" --Log \"err stdout\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Generate new Ed25519 signing keys (LOCAL)\n  local_action: command tor --keygen --SigningKeyLifetime {{ tor_signingkeylifetime_days}}\\ days --datadirectory \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}\" --Log \"err stdout\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - renewkey\n\n- name: Detect duplicate relay keys across relays (LOCAL)\n  shell: openssl sha256 -r {{ tor_offline_masterkey_dir }}/*/keys/secret_id_key {{ tor_offline_masterkey_dir }}/*/keys/ed25519_master_id_secret_key|cut -d' ' -f1|sort|uniq -d|wc -l\n  delegate_to: 127.0.0.1\n  run_once: true\n  register: dupcount\n\n- name: Abort on duplicate relay keys\n  fail: msg=\"Duplicate relay key detected! Aborting.\"\n  run_once: true\n  when: dupcount.stdout|int(1) != 0\n\n- name: Detect if Ed25519 master keys are on the relay\n  stat:\n    path: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/ed25519_master_id_secret_key\"\n  become: yes\n  register: masterkeycheck\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Abort if Ed25519 master keys are on the relay\n  fail: msg=\"\n\n            Ed25519 MASTER KEY detected on the relay - it is NOT supposed to be there! Aborting.\"\n  when: item.stat.exists == True\n  with_items: \"{{ masterkeycheck.results }}\"\n\n- name: Collect fingerprints for MyFamily (LOCAL)\n  shell: cut  -d\" \" -f2 {{ tor_offline_masterkey_dir }}/*/fingerprint|sort|xargs|sed -e 's/ /,/g'\n  delegate_to: 127.0.0.1\n  run_once: true\n  register: family\n  tags:\n   - reconfigure\n\n- name: Ensure per-instance tor users exist\n  become: yes\n  user:\n    name: _tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\n    system: yes\n    shell: /bin/false\n    createhome: no\n    home: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure per-instance config folders exist (Debian only)\n  become: yes\n  file:\n    path: \"{{ tor_ConfDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    state: directory\n    mode: 0755\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  when: ansible_pkg_mgr == 'apt'\n\n- name: Ensure DataDir exists\n  become: yes\n  file:\n    path: \"{{ tor_DataDir }}\"\n    state: directory\n    owner: root\n    mode: 0755\n\n- name: Ensure \"keys\" subfolder exists\n  become: yes\n  file:\n    path: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys\"\n    state: directory\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    group: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0700\n    recurse: yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure RSA key is in place (without overriding existing keys)\n  become: yes\n  copy:\n    src: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    dest: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0700\n    force: no\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'secret_id_key' ]\n\n- name: Fetch RSA key for comparision\n  become: yes\n  fetch:\n    src: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    dest: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}.untrustedremotekey\"\n    flat: yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'secret_id_key' ]\n\n- name: Compare local vs. remote RSA key (secret_id_key)\n  local_action: shell openssl sha256 -r {{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-\"{{ item.0.ipv4 }}_{{ item.1.orport }}\"/keys/secret_id_key*|cut -d' ' -f1|uniq -d|wc -l\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  register: rsakey\n\n- name: Abort if local and remote RSA keys do not match\n  assert:\n    that:\n      - \"item.stdout|int == 1\"\n    msg: \"Key mismatch detected! Solution: http://bit.ly/2j6wc70 Affected instance: {{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.item.0.ipv4 }}_{{ item.item.1.orport }}/keys\"\n  with_items: \"{{ rsakey.results }}\"\n\n# this task is separated from the task named \"Ensure RSA key is in place\" because it is not run with 'force=no'\n- name: Transmit new Ed25519 signing keys\n  become: yes\n  copy:\n    src: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    dest: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0700\n    setype: tor_var_lib_t\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'ed25519_signing_cert', 'ed25519_signing_secret_key' ]\n  tags:\n   - renewkey\n\n# This needs to be at the end to fix SELinux contexts recursively\n- name: Ensure per-instance DataDir have proper permissions\n  become: yes\n  file:\n    path: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    state: directory\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    group: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0700\n    recurse: yes\n    setype: tor_var_lib_t\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure Tor config directory exists\n  become: yes\n  file:\n    path: \"{{ tor_ConfDir }}\"\n    state: directory\n    owner: root\n    group: \"{{ tor_user }}\"\n    mode: 0755\n\n- name: Ensure tor-exit-notice.html is present (if we are an exit)\n  become: yes\n  template:\n    src: tor-exit-notice.html\n    dest: \"{{ tor_ConfDir }}/tor-exit-notice.html\"\n    mode: 0444\n  when: tor_ExitRelay == True and tor_ExitNoticePage == True\n\n- name: Generating torrc file(s)\n  become: yes\n  template:\n    src: torrc\n    dest: \"{{ (ansible_pkg_mgr != 'apt')| ternary(tor_ConfDir ~ '/' ~ item.0.ipv4 ~ '_' ~ item.1.orport ~ '.torrc', tor_ConfDir ~ '/' ~ item.0.ipv4 ~ '_' ~ item.1.orport ~ '/torrc') }}\"\n    owner: root\n    mode: 0644\n    backup: yes\n    validate: \"tor --verify-config -f %s\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  register: instances\n  notify:\n    - Ensure Tor instances are reloaded if its torrc changed (FreeBSD)\n    - Ensure Tor instances are reloaded if its torrc changed (Linux)\n  tags:\n   - reconfigure\n"}, {"commit_sha": "9eb1a8fa8e281ef06687c1851f51fa0beec3e232", "sha": "cdeaccc3047905b4e092f283bbb224f1f8fe29de", "filename": "tasks/section_06_level1_05.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 6.5.2 Configure Network Time Protocol (restrict4) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='restrict -4 default kod nomodify notrap nopeer noquery'\n        regexp='^restrict -4 default'\n        state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.2\n\n  - name: 6.5.3 Configure Network Time Protocol (restrict6) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='restrict -6 default kod nomodify notrap nopeer noquery'\n        regexp='^restrict -6 default'\n        state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.3\n\n  - name: 6.5.4 Configure Network Time Protocol (server check) (NTP) (Scored)\n    command: 'grep \"^server\" /etc/ntp.conf'\n    register: ntp_server_rc\n    changed_when: False\n    always_run: True\n    ignore_errors: True\n    tags:\n      - section6\n      - section6.5\n      - section6.5.4\n\n  - name: 6.5.4 Configure Network Time Protocol (server add) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='server 0.fr.pool.ntp.org'\n        state=present\n    when: ntp_server_rc.rc == 1\n    tags:\n      - section6\n      - section6.5\n      - section6.5.4\n"}, {"commit_sha": "df06f3c3304c3f73f740d444222642fbad41bebb", "sha": "320b85c8826a053d758790859d0d5b61b9c579ae", "filename": "tasks/freebsd_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Setup FreeBSD specific variables (set_fact)\n  set_fact:\n    tor_DataDir: /var/db/tor\n    tor_ConfDir: /usr/local/etc/tor/enabled\n  tags:\n   - reconfigure\n   - createdir\n\n- name: Ensure Tor is installed (FreeBSD)\n  become: yes\n  pkgng: name=tor state=present\n\n# temporary solution until rc.d supports multiple instances\n- name: Ensure Tor starts at boot (FreeBSD)\n  become: yes\n  lineinfile: dest=/etc/rc.local line=\"/usr/local/bin/tor -f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\" create=yes\n  with_nested:\n   - tor_ips\n   - tor_ports\n\n- name: If LogDir is a file, rename it (FreeBSD)\n  become: yes\n  shell: \"test -f {{ tor_LogDir }} && mv {{ tor_LogDir }} {{ tor_LogDir }}.bk-`date '+%Y-%m-%d_%H%M%S'`\"\n  ignore_errors: yes\n\n- name: Gather current kern.ipc.somaxconn setting (FreeBSD)\n  shell: \"sysctl kern.ipc.somaxconn|cut -d' '  -f2\"\n  register: currentsomaxconn\n  tags:\n   - freebsdkern\n\n- name: Ensure somaxconn setting is reasonable (FreeBSD)\n  become: yes\n  command: \"sysctl kern.ipc.somaxconn={{ freebsd_somaxconn }}\"\n  when: currentsomaxconn.stdout|int < {{ freebsd_somaxconn }}\n  tags:\n   - freebsdkern\n\n- name: Ensure somaxconn setting in sysctl.conf is reasonable (FreeBSD)\n  become: yes\n  lineinfile: dest=/etc/sysctl.conf regexp=^kern.ipc.somaxconn line=\"kern.ipc.somaxconn={{ freebsd_somaxconn }}\" create=yes\n  when: currentsomaxconn.stdout|int < {{ freebsd_somaxconn }}\n  tags:\n   - freebsdkern\n\n- name: Gather current kern.ipc.nmbclusters setting (FreeBSD)\n  shell: \"sysctl kern.ipc.nmbclusters|cut -d' '  -f2\"\n  register: currentnmbc\n  tags:\n   - freebsdkern\n\n- name: Ensure nmbclusters setting is reasonable (FreeBSD)\n  become: yes\n  command: \"sysctl kern.ipc.nmbclusters={{ freebsd_nmbclusters }}\"\n  when: currentnmbc.stdout|int < {{ freebsd_nmbclusters }}\n  tags:\n   - freebsdkern\n\n- name: Ensure nmbclusters setting in sysctl.conf is reasonable (FreeBSD)\n  become: yes\n  lineinfile: dest=/etc/sysctl.conf regexp=^kern.ipc.nmbclusters line=\"kern.ipc.nmbclusters={{ freebsd_nmbclusters }}\" create=yes\n  when: currentnmbc.stdout|int < {{ freebsd_nmbclusters }}\n  tags:\n   - freebsdkern\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "d6c90b46869302b812f1b4880dd1bca1ce251b25", "filename": "tasks/FreeBSD/dashboard.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/FreeBSD/dashboard.yml: Deployment of the Uchiwa dashboard\n# Specific to FreeBSD\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure Uchiwa (dashboard) dependencies are installed\n    pkgng:\n      name: \"{{ item }}\"\n      state: present\n    with_items:\n      - go\n      - git\n      - npm\n\n  - name: Ensure Uchiwa directory exists\n    file:\n      dest: \"{{ uchiwa_path }}\"\n      state: directory\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      recurse: true\n\n  - name: Ensure Uchiwa Go/config directory exists\n    file:\n      dest: \"{{ uchiwa_path }}/{{ item }}\"\n      state: directory\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      recurse: true\n    with_items:\n      - etc\n      - go\n\n  - name: Ensure Uchiwa GOPATH exists\n    file:\n      dest: \"{{ uchiwa_path }}/go/{{ item }}\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      state: directory\n      recurse: true\n    with_items:\n      - bin\n      - pkg\n      - src\n\n  - name: Fetch Uchiwa from GitHub\n    command: go get github.com/sensu/uchiwa\n    environment:\n      GOPATH: \"{{ uchiwa_path }}/go\"\n    args:\n      creates: \"{{ uchiwa_path }}/go/src/github.com/sensu/uchiwa\"\n    notify: Build and deploy Uchiwa\n    become: true\n    become_user: \"{{ sensu_user_name }}\"\n\n  - meta: flush_handlers\n\n  - name: Deploy Uchiwa config\n    template:\n      src: uchiwa_config.json.j2\n      dest: \"{{ uchiwa_path }}/etc/config.json\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    notify: restart uchiwa service\n\n  - name: Deploy Uchiwa service file\n    template:\n      src: uchiwa_freebsd.j2\n      dest: \"/usr/local/etc/rc.d/uchiwa\"\n      mode: \"0755\"\n\n  - name: Ensure Uchiwa server service is running\n    service: name=uchiwa state=started enabled=yes\n"}, {"commit_sha": "067d6cbb20adb31a1e2bd9f689b5b6e259c30288", "sha": "cd5607a47d0af0fa3491fcced679e5a67c2ada31", "filename": "tasks/section_01_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 1.1.1 Install Updates, Patches and Additional Security Software (NotScored)\n    apt: update_cache=yes\n    tags:\n      - section1\n      - section1.1\n      - section1.1.1\n\n  - name: 1.1.2 Install Updates, Patches and Additional Security Software (NotScored)\n    apt: upgrade=yes\n    when: apt_upgrade == True\n    tags:\n      - section1\n      - section1.1\n      - section1.1.2\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "67f33a060a1b2b73ac89ae13fe70c7e156ba3780", "filename": "tasks/asserts.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# File: asserts.yml - Asserts for this playbook\n\n- name: Check distribution compatibility\n  fail:\n    msg: \"{{ ansible_distribution }} is not currently supported by this role.\"\n  when:\n    - ansible_distribution not in ['RedHat', 'CentOS', 'OracleLinux', 'Fedora', 'Debian', 'FreeBSD', 'SmartOS', 'Ubuntu', 'Archlinux', 'Alpine', 'Amazon']\n    - ansible_os_family != 'Windows'\n\n- name: Check CentOS, Red Hat or Oracle Linux version\n  fail:\n    msg: \"{{ ansible_distribution_version }} is not a supported version.\"\n  when:\n    - ansible_distribution in ['RedHat', 'CentOS', 'OracleLinux']\n    - ansible_distribution_version is version_compare(6, '<')\n\n- name: Check Debian version\n  fail:\n    msg: \"{{ ansible_distribution_version }} is not a supported version.\"\n  when:\n    - ansible_distribution == \"Debian\"\n    - (ansible_distribution_version != 'buster/sid') and (ansible_distribution_version is version_compare(8, '<'))\n\n- name: Check FreeBSD version\n  fail:\n    msg: \"{{ ansible_distribution_version }} is not a supported version.\"\n  when:\n    - ansible_distribution == \"FreeBSD\"\n    - ansible_distribution_version is version_compare(10, '<')\n\n- name: Check Ubuntu version\n  fail:\n    msg: \"{{ ansible_distribution_version }} is not a supported version.\"\n  when:\n    - ansible_distribution == \"Ubuntu\"\n    - ansible_distribution_version is version_compare(13.04, '<')\n\n- name: Check specified ethernet interface\n  fail:\n    msg: \"The ethernet interface specified by consul_iface was not found.\"\n  when:\n    - ansible_os_family != 'Windows'\n    - consul_iface not in ansible_interfaces\n\n- name: Check iptables on Red Hat, CentOS or Oracle Linux\n  fail:\n    msg: \"Use DNSmasq instead of iptables on {{ ansible_distribution }}.\"\n  when:\n    - consul_iptables_enable | bool\n    - ansible_distribution in ['RedHat', 'CentOS', 'OracleLinux']\n    - ansible_distribution_version is version_compare(6, '>=')\n\n- name: Check for both Dnsmasq and iptables enabled\n  fail:\n    msg: \"EONEORTHEOTHER: DNSmasq and iptables together is not supported.\"\n  when:\n    - consul_dnsmasq_enable | bool\n    - consul_iptables_enable | bool\n\n- name: Check for iptables enabled but no recursors\n  fail:\n    msg: \"Recursors are required if iptables is enabled.\"\n  when:\n    - consul_iptables_enable | bool\n    - consul_recursors | length == 0\n\n- name: Check consul_group_name is included in groups\n  fail:\n    msg: \"consul_group_name must be included in groups.\"\n  when: consul_group_name not in groups\n\n- name: Fail if more than one bootstrap server is defined\n  fail:\n    msg: \"You can not define more than one bootstrap server.\"\n  when:\n    - _consul_bootstrap_servers | length > 1\n\n- name: Fail if a bootstrap server is defined and bootstrap_expect is true\n  fail:\n    msg: \"Can't use a bootstrap server and bootstrap_expect at the same time.\"\n  when:\n    - _consul_bootstrap_servers | length > 0\n    - consul_bootstrap_expect | bool\n\n# Check for unzip binary\n\n- name: Check if unzip is installed on control host\n  shell: \"command -v unzip -h >/dev/null 2>&1\"\n  become: false\n  changed_when: false\n  check_mode: false\n  run_once: true\n  register: is_unzip_installed\n  ignore_errors: true\n  delegate_to: 127.0.0.1\n\n- name: Install remotely if unzip is not installed on control host\n  set_fact:\n    consul_install_remotely: true\n  when:\n    - is_unzip_installed.rc == 1\n"}, {"commit_sha": "32211ebd2a9f45112f8dceda80bc95d0db029fb4", "sha": "4ff792114aa3da6d25458cb4454e3751d42f3844", "filename": "tasks/freebsd_service.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Ensure Tor starts at boot (FreeBSD)\n  become: yes\n  lineinfile: dest=/etc/rc.local line=\"/usr/local/bin/tor -f {{ tor_ConfDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}.torrc\" create=yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure PidDir exists (FreeBSD)\n  become: yes\n  file: path={{ tor_PidDir }}\n    state=directory\n    owner=root\n    mode=0755\n\n- name: Ensure PidDir is owned by per-instance tor_user (FreeBSD)\n  become: yes\n  file: path={{ tor_PidDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\n    state=directory\n    owner=_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\n    mode=0700\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure Tor instances are reloaded if its torrc changed (FreeBSD)\n  become: yes\n  shell: \"kill -HUP `cat {{ tor_PidDir }}/{{ item.item.0.ipv4 }}_{{ item.item.1.orport }}/pid`\"\n  ignore_errors: yes\n  with_items: \"{{ instances.results }}\"\n  when: item.changed == True\n  tags:\n   - reconfigure\n\n- name: Ensure Tor instances are running (FreeBSD)\n  become: yes\n  shell: \"kill -0 `cat {{ tor_PidDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/pid` || tor -f {{ tor_ConfDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}.torrc\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - reconfigure\n"}, {"commit_sha": "1bb50a6149f6ff7f2e6399411418d088e2c52d01", "sha": "9130a32a57b6c9fb6e66a9776f0f7564b70cd368", "filename": "tasks/section_09_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 9.1.1.1 Check that cron conf file exists (check) (Scored)\n    stat: path=/etc/init/cron.conf\n    register: cron_conf_stat\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.1\n\n  - name: 9.1.1.2 Enable cron Daemon (Scored)\n    service: >\n        name=cron\n        state=started\n        enabled=yes\n    when: not cron_conf_stat.stat.exists\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.2\n\n  - name: 9.1.2 Set User/Group Owner and Permission on /etc/crontab (Scored)\n    file: path='/etc/crontab' owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.2\n\n  - name: 9.1.3 Set User/Group Owner and Permission on /etc/cron.hourly (Scored)\n    file: path=/etc/cron.hourly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.3\n\n  - name: 9.1.4 Set User/Group Owner and Permission on /etc/cron.daily (Scored)\n    file: path=/etc/cron.daily owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.4\n\n  - name: 9.1.5 Set User/Group Owner and Permission on /etc/cron.weekly(Scored)\n    file: path=/etc/cron.weekly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.5\n\n  - name: 9.1.6 Set User/Group Owner and Permission on /etc/cron.monthly(Scored)\n    file: path=/etc/cron.monthly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.6\n\n  - name: 9.1.7 Set User/Group Owner and Permission on /etc/cron.d (Scored)\n    file: path=/etc/cron.d owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.7\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (remove deny) (Scored)\n    file: path={{ item }} state=absent\n    with_items:\n        - /etc/cron.deny\n        - /etc/at.deny\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (stat cron allow) (Scored)\n    stat: path=/etc/cron.allow\n    register: cron_allow_path\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation create cron) (Scored)\n    shell: touch /etc/cron.allow\n    when: cron_allow_path.stat.exists == False\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (create cron allow) (Scored)\n    file: path=/etc/cron.allow owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (stat at allow) (Scored)\n    stat: path=/etc/at.allow\n    register: at_allow_path\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation create at) (Scored)\n    shell: touch /etc/at.allow\n    when: at_allow_path.stat.exists == False\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (create at allow) (Scored)\n    file: path=/etc/at.allow owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.2.1 Set Password Creation Requirement Parameters Using pam_cracklib (install) (Scored)\n    apt: name=libpam-cracklib state=present\n    when: use_pam_cracklib == True\n    tags:\n      - section9\n      - section9.2\n      - section9.2.1\n\n  - name: 9.2.1 Set Password Creation Requirement Parameters Using pam_cracklib (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password'\n        regexp=\"pam_cracklib.so\"\n        line=\"password required pam_cracklib.so retry=3 minlen=14 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1\"\n        state=present\n    when: use_pam_cracklib == True\n    tags:\n      - section9\n      - section9.2\n      - section9.2.1\n\n#Note for section 9.2.2:\n#If a user has been locked out because they have reached the maximum consecutive failure count\n#defined by denied= in the pam_tally2.so module, the user can be unlocked by issuing the command\n#/sbin/pam_tally2 -u username --reset\n#This command sets the failed count to 0, effectively unlocking the user\n  - name: 9.2.2 Set Lockout for Failed Password Attempts (Not Scored)\n    lineinfile: >\n        dest='/etc/pam.d/login'\n        regexp='pam_tally2'\n        line=\"auth required pam_tally2.so onerr=fail audit silent deny=5 unlock_time=900\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.2\n\n  - name: 9.2.3 Limit Password Reuse (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password'\n        regexp='remember=5'\n        line=\"password sufficient pam_unix.so remember=5\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.3\n\n  - name: 9.3 Check if ssh is installed (check) (Not Scored)\n    stat: path='/etc/ssh/sshd_config'\n    register: ssh_config_file\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n  - include: section_09_level1_03.yml\n    when: ssh_config_file.stat.exists == True\n\n  - name: 9.4 Restrict root Login to System Console (stat securetty) (Not Scored)\n    stat: path=/etc/securetty\n    register: securetty_file\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.4 Restrict root Login to System Console (Not Scored)\n    debug: msg='*** Check /etc/securetty for console allowed for root access ***'\n    when: securetty_file.stat.exists == True\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.5.1 Restrict Access to the su Command (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/su'\n        line='auth            required        pam_wheel.so use_uid'\n        state=present\n    tags:\n      - section9\n      - section9.5\n      - section9.5.1\n"}, {"commit_sha": "af3dfdf7cf37437f5609f1a12e4ac7cbaebd4867", "sha": "4b7b3bf9e10ce32988818cd2f5fb435158cbc97a", "filename": "roles/docker/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for docker\n- name: remove docker override\n  file:\n    path: /etc/init/docker.override\n    state: absent\n  notify:\n    - restart docker\n  tags:\n    - docker\n\n- name: configure docker graph directory\n  sudo: yes\n  lineinfile:\n    dest: /etc/default/docker\n    state: present\n    regexp: ^DOCKER_OPTS=.*--graph.*\n    line: 'DOCKER_OPTS=\\\"$DOCKER_OPTS --graph={{ docker_graph_dir }}\\\"'\n  notify:\n    - restart docker\n\n- name: configure docker temporary directory\n  sudo: yes\n  lineinfile:\n    dest: /etc/default/docker\n    state: present\n    line: 'DOCKER_TMPDIR=\\\"{{ docker_tmp_dir }}\\\"'\n  notify:\n    - restart docker\n\n- name: configure docker proxy\n  sudo: yes\n  lineinfile:\n    dest: /etc/default/docker\n    state: present\n    line: 'export http_proxy=\\\"{{ http_proxy }}\\\"'\n  when: http_proxy is defined and http_proxy != ''\n\n- name: ensure docker is running (and enable it at boot)\n  service:\n    name: docker\n    state: started\n    enabled: yes\n  tags:\n    - docker\n"}, {"commit_sha": "df06f3c3304c3f73f740d444222642fbad41bebb", "sha": "89469a7522ac4618769a5cf24b69cf4f111553a5", "filename": "handlers/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n#- name: restart tor\n#  service: name=tor state=restarted\n\n- name: stop tor\n  sudo: yes\n  service: name=tor state=stopped\n\n# workaround for #20\n# the proper way would be service: enabled=no\n- name: disable-sysv-debian tor\n  sudo: yes\n  command: update-rc.d tor disable\n\n- name: restart apparmor\n  sudo: yes\n  service: name=apparmor state=restarted\n\n- name: systemctl daemon-reload\n  sudo: yes\n  command: systemctl daemon-reload\n"}, {"commit_sha": "92d2f38d01d7b33610c667cfdc03e28ab2912edc", "sha": "bf242bf344e181e416d770d83fe7d1a730a74c70", "filename": "tasks/section_06_level1_05.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 6.5.2 Configure Network Time Protocol (restrict4) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='restrict -4 default kod nomodify notrap nopeer noquery'\n        regexp='^restrict -4 default'\n        state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.2\n\n  - name: 6.5.3 Configure Network Time Protocol (restrict6) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='restrict -6 default kod nomodify notrap nopeer noquery'\n        regexp='^restrict -6 default'\n        state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.3\n\n  - name: 6.5.4 Configure Network Time Protocol (server check) (NTP) (Scored)\n    command: 'grep \"^server\" /etc/ntp.conf'\n    register: ntp_server_rc\n    changed_when: False\n    always_run: True\n    ignore_errors: True\n    tags:\n      - section6\n      - section6.5\n      - section6.5.4\n\n  - name: 6.5.4 Configure Network Time Protocol (server add) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='server {{ ntp_server }}'\n        state=present\n    when: ntp_server_rc.rc == 1\n    tags:\n      - section6\n      - section6.5\n      - section6.5.4\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "784755e471f37e62cdec644058d15eba17d4268d", "filename": "meta/main.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\nallow_duplicates: no\n\n\ngalaxy_info:\n  author: Aur\u00e9lien Wailly\n  description: Ansible role to meet CIS (Center for Internet Security) requirements on ubuntu\n  license: GPLv2\n  min_ansible_version: 1.9.0.1\n  platforms:\n    - name: Ubuntu\n      versions:\n        14.04\n  categories:\n    #- cloud\n    #- cloud:ec2\n    #- cloud:gce\n    #- cloud:rax\n    #- clustering\n    #- database\n    #- database:nosql\n    #- database:sql\n    #- development\n    - monitoring\n    #- networking\n    #- packaging\n    - system\n    #- web\n\n\n\ndependencies: []\n"}, {"commit_sha": "92d2f38d01d7b33610c667cfdc03e28ab2912edc", "sha": "6210d4def003cc38dad0557bf2986903c422f8af", "filename": "tasks/section_13_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 13.1 Ensure Password Fields are Not Empty (Scored)\n    command: awk -F':' '($2 == \"\" ) { print $1 }' /etc/shadow\n    register: awk_empty_shadow\n    changed_when: False\n    failed_when: awk_empty_shadow.stdout != '' and lock_shadow_accounts == False\n    tags:\n      - section13\n      - section13.1\n\n  - name: 13.1 Ensure Password Fields are Not Empty (locking accounts) (Scored)\n    command: passwd -l '{{ item }}'\n    with_items: \"{{awk_empty_shadow.stdout_lines}}\"\n    when: lock_shadow_accounts == True\n    tags:\n      - section13\n      - section13.1\n\n  - name: 13.2 Verify No Legacy \"+\" Entries Exist in /etc/passwd File (Scored)\n    command: grep '^+:' /etc/passwd\n    register: plus_pass\n    failed_when: plus_pass.rc == 0\n    changed_when: plus_pass.rc == 0\n    tags:\n      - section13\n      - section13.2\n\n  - name: 13.3 Verify No Legacy \"+\" Entries Exist in /etc/shadow File (Scored)\n    command: grep '^+:' /etc/shadow\n    register: plus_shadow\n    failed_when: plus_shadow.rc == 0\n    changed_when: plus_shadow.rc == 0\n    tags:\n      - section13\n      - section13.3\n\n  - name: 13.4 Verify No Legacy \"+\" Entries Exist in /etc/group File (Scored)\n    command: grep '^+:' /etc/group\n    register: plus_group\n    failed_when: plus_group.rc == 0\n    changed_when: plus_group.rc == 0\n    tags:\n      - section13\n      - section13.4\n\n  - name: 13.5 Verify No UID 0 Accounts Exist Other Than root (Scored)\n    command: awk -F':' '($3 == 0) { print $1 }' /etc/passwd\n    register: uid_zero_root\n    changed_when: False\n    failed_when: uid_zero_root.stdout != 'root'\n    tags:\n      - section13\n      - section13.5\n\n  - name: 13.6.1 Ensure root PATH Integrity (empty value) (Scored)\n    shell: 'echo $PATH | grep ::'\n    register: path_colon\n    changed_when: False\n    failed_when: path_colon.rc == 0\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.2 Ensure root PATH Integrity (colon end) (Scored)\n    shell: 'echo $PATH | grep :$'\n    register: path_colon_end\n    changed_when: False\n    failed_when: path_colon_end.rc == 0\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.3 Ensure root PATH Integrity (dot in path) (Scored)\n    shell: \"/bin/bash --login -c 'env | grep ^PATH=' | sed -e 's/PATH=//' -e 's/::/:/' -e 's/:$//' -e 's/:/\\\\n/g'\"\n    become: yes\n    register: dot_in_path\n    changed_when: False\n    failed_when: '\".\" in dot_in_path.stdout_lines'\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.4 Ensure root PATH Integrity (Scored)\n    file: >\n        path='{{ item }}'\n        follow=yes\n        state=directory\n        owner=root\n        mode='o-w,g-w'\n    with_items: \"{{dot_in_path.stdout_lines}}\"\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.7.1 Check Permissions on User Home Directories (gather users) (Scored)\n    shell: /bin/egrep -v '(root|halt|sync|shutdown|false)' /etc/passwd | /usr/bin/awk -F':' '($7 != \"/usr/sbin/nologin\") { print $6 }'\n    register: home_users\n    changed_when: False\n    failed_when: False\n    tags:\n      - section13\n      - section13.7\n\n  - name: 13.7.2 Check Permissions on User Home Directories (Scored)\n    file: >\n        path='{{ item }}'\n        mode='g-w,o-rwx'\n        state=directory\n    with_items: \"{{home_users.stdout_lines}}\"\n    when: modify_user_homes == True\n    tags:\n      - section13\n      - section13.7\n\n  - name: 13.8.1 Check User Dot File Permissions (gather dotfiles) (Scored)\n    shell: for pth in `/bin/egrep -v '(root|halt|sync|shutdown)' /etc/passwd | /usr/bin/awk -F':' '($7 != \"/usr/sbin/nologin\") { print $6 }'`; do ls -d -A -1 $pth/.* | egrep -v '[..]$'; done\n    changed_when: False\n    failed_when: False\n    always_run: True\n    register: home_dot_files\n    tags:\n      - section13\n      - section13.8\n\n  - name: 13.8.2 Check User Dot File Permissions (Scored)\n    file: >\n        path='{{ item }}'\n        follow=yes\n        mode='o-w,g-w'\n    with_items: \"{{home_dot_files.stdout_lines}}\"\n    tags:\n      - section13\n      - section13.8\n\n  - name: 13.9 Check Permissions on User .netrc Files (Scored)\n    file: >\n        path='{{ item }}/.netrc'\n        mode='g-rwx,o-rwx'\n        recurse=yes\n        state=directory\n    with_items: \"{{home_users.stdout_lines}}\"\n    tags:\n      - section13\n      - section13.9\n\n  - name: 13.10 Check for Presence of User .rhosts Files (Scored)\n    file: >\n        state=absent\n        path='{{ item }}/.rhosts'\n    with_items: \"{{home_users.stdout_lines}}\"\n    tags:\n      - section13\n      - section13.10\n\n  - name: 13.11 Check Groups in /etc/passwd (preparation) (Scored)\n    command: cut -s -d':' -f4 /etc/passwd\n    register: groups_id_cut\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.11\n\n  - name: 13.11 Check Groups in /etc/passwd (Scored)\n    command: grep -q -P \"^.*?:[^:]*:{{ item }}:\" /etc/group\n    with_items: \"{{groups_id_cut.stdout_lines}}\"\n    register: groups_present\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.11\n\n  - name: 13.12 Check That Users Are Assigned Valid Home Directories (Scored)\n    stat: path='{{ item }}'\n    with_items: \"{{home_users.stdout_lines}}\"\n    register: rstat\n    failed_when: rstat is defined and rstat.stat.isdir == False\n    always_run: True\n    tags:\n      - section13\n      - section13.12\n\n  - name: 13.13 Check User Home Directory Ownership (Scored)\n    debug: msg=\"*** Hardcore ***\"\n    tags:\n      - section13\n      - section13.13\n\n  - name: 13.14 Check for Duplicate UIDs (Scored)\n    shell: cut -f3 -d':' /etc/passwd | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.14\n\n  - name: 13.15 Check for Duplicate GIDs (Scored)\n    shell: cut -f3 -d':' /etc/group | sort | uniq -d\n    register: gids_list\n    failed_when: gids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.15\n\n  - name: 13.16 Check for Duplicate User Names (Scored)\n    shell: cut -f1 -d':' /etc/passwd | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.16\n\n  - name: 13.17 Check for Duplicate Group Names (Scored)\n    shell: cut -f1 -d':' /etc/group | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.17\n\n  - name: 13.18 Check for Presence of User .netrc Files (stat) (Scored)\n    stat: path='{{ item }}/.netrc'\n    with_items: '{{ home_users.stdout_lines }}'\n    register: netrc_files\n    tags:\n      - section13\n      - section13.18\n\n  - name: 13.18 Check for Presence of User .netrc Files (Scored)\n    debug: msg='Check if {{ item.stat.path}} is needed, and remove otherwise'\n    when: item is defined and item.stat.exists == True\n    with_items: '{{ netrc_files.results }}'\n    tags:\n      - section13\n      - section13.18\n\n  - name: 13.19 Check for Presence of User .forward Files (Scored)\n    file: >\n        path='{{ item }}/.forward'\n        state=absent\n    with_items: \"{{home_users.stdout_lines}}\"\n    tags:\n      - section13\n      - section13.19\n\n  - name: 13.20.1 Ensure shadow group is empty (Scored)\n    shell: grep '^shadow' /etc/group | cut -f4 -d':'\n    register: shadow_group_empty\n    failed_when: shadow_group_empty.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.1\n\n  - name: 13.20.2 Ensure shadow group is empty (preparation) (Scored)\n    shell: grep '^shadow' /etc/group | cut -f1 -d':'\n    register: shadow_group_id\n    failed_when: False\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.1\n\n  - name: 13.20.2 Ensure shadow group is empty (Scored)\n    shell: awk -F':' '($4 == \"{{ item }}\") { print }' /etc/passwd\n    register: awk_passwd_shadow\n    with_items: \"{{shadow_group_id.stdout_lines}}\"\n    changed_when: False\n    failed_when: awk_passwd_shadow.stdout != ''\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.2\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "846735c7d00abcaf3ec9ff18ebea7f343b61a658", "filename": "roles/zookeeper/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- name: create zookeeper config directory\n  file:\n    path: \"{{ zookeeper_config_dir }}\"\n    state: directory\n    follow: yes\n    mode: 0755\n  sudo: yes\n  tags:\n    - zookeeper\n\n- name: Create zookeeper config files\n  template:\n    src: \"{{ item.src }}\"\n    dest: \"{{ item.dest }}\"\n  sudo: yes\n  with_items:\n    - src: zoo.cfg.j2\n      dest: \"{{ zookeeper_config_dir }}/zoo.cfg\"\n    - src: environment.j2\n      dest: \"{{ zookeeper_config_dir }}/environment\"\n    - src: configuration.xsl.j2\n      dest: \"{{ zookeeper_config_dir }}/configuration.xsl\"\n    - src: log4j.properties.j2\n      dest: \"{{ zookeeper_config_dir }}/log4j.properties\"\n  notify:\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: Create zookeeper myid file\n  copy:\n    content: \"{{ zookeeper_id }}\"\n    dest: \"{{ zookeeper_config_dir }}/myid\"\n    mode: 0644\n  sudo: yes\n  notify:\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: deploy zookeeper service\n  sudo: yes\n  sudo_user: root\n  template:\n    src: zookeeper.service.j2\n    dest: /etc/systemd/system/zookeeper.service\n  notify:\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: enable zookeeper\n  sudo: yes\n  service:\n    name: zookeeper\n    enabled: yes\n    state: started\n  tags:\n    - zookeeper\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "7183da4d13d6a6f91d31628bbecdf7fbdfeede7c", "filename": "tasks/FreeBSD/redis.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/FreeBSD/redis.yml: Deploy redis\n# Specific to FreeBSD\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure redis is installed\n    pkgng:\n      name: \"{{ redis_pkg_name }}\"\n      state: \"{{ redis_pkg_state }}\"\n\n  - name: Ensure redis binds to accessible IP\n    lineinfile:\n      dest: /usr/local/etc/redis.conf\n      regexp: '^bind'\n      line: 'bind 0.0.0.0'\n    notify: restart redis service\n\n  - meta: flush_handlers\n"}, {"commit_sha": "92d2f38d01d7b33610c667cfdc03e28ab2912edc", "sha": "3e144d314d083a762d664048e08c19baf8676d14", "filename": "tasks/section_04_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 4.1.1 Restrict Core Dumps (Scored)\n    lineinfile: dest='/etc/security/limits.conf' line=\"* hard core 0\" state=present\n    tags:\n      - section4\n      - section4.1\n      - section4.1.1\n\n  - name: 4.1.2 Restrict Core Dumps (Scored)\n    sysctl: >\n        name=fs.suid_dumpable\n        value=0\n        state=present\n    when: restrict_core_dumps == True\n    tags:\n      - section4\n      - section4.1\n      - section4.1.2\n\n  - name: 4.1.4 Restrict Core Dumps (stat file) (Scored)\n    stat: path='/etc/init/apport.conf'\n    register: apport_present\n    tags:\n      - section4\n      - section4.1\n      - section4.1.4\n\n  - name: 4.1.5 Restrict Core Dumps (Scored)\n    lineinfile: >\n        dest='/etc/init/apport.conf'\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n    when: apport_present.stat.exists == True\n    tags:\n      - section4\n      - section4.1\n      - section4.1.3\n\n  - name: 4.1.6 Restrict Core Dumps (stat file) (Scored)\n    stat: path='/etc/init/whoopsie.conf'\n    register: whoopsie_present\n    tags:\n      - section4\n      - section4.1\n      - section4.1.4\n\n  - name: 4.1.7 Restrict Core Dumps (Scored)\n    lineinfile: >\n        dest='/etc/init/whoopsie.conf'\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n    when: whoopsie_present.stat.exists == True\n    tags:\n      - section4\n      - section4.1\n      - section4.1.4\n\n  - name: 4.2 Enable XD/NX Support on 32-bit x86 Systems (read dmesg) (Not Scored)\n    shell: 'dmesg | grep NX'\n    register: nx_result\n    failed_when: nx_result.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section4\n      - section4.2\n\n  - name: 4.3 Enable Randomized Virtual Memory Region Placement (Scored)\n    sysctl: >\n       name=kernel.randomize_va_space\n       value=2\n       state=present\n    when: enable_aslr\n    tags:\n      - section4\n      - section4.3\n\n  - name: 4.4 Disable Prelink (check) (Scored)\n    stat: path=/usr/sbin/prelink\n    register: prelink_rc\n    tags:\n      - section4\n      - section4.4\n\n  - name: 4.4 Disable Prelink (restore) (Scored)\n    command: '/usr/sbin/prelink -ua'\n    when: prelink_rc.stat.exists == True\n    tags:\n      - section4\n      - section4.4\n\n  - name: 4.4 Disable Prelink (remove) (Scored)\n    apt: purge=yes name='prelink' state=absent\n    when: prelink_rc.stat.exists == True\n    tags:\n      - section4\n      - section4.4\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "d5bff083b618a275c63d7d639988d23c24ef1823", "filename": "roles/mistral/tasks/sync.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "- name: Sync database\n  shell: /opt/openstack/mistral/.venv/bin/python ./tools/sync_db.py --config-file /etc/mistral/mistral.conf && touch /etc/mistral/database_setup.lock\n  args:\n    chdir: /opt/openstack/mistral\n    creates: /etc/mistral/database_setup.lock\n  sudo: yes\n"}, {"commit_sha": "9966c6de1ed4ef5071a9bea83b4bb69a11dd32ba", "sha": "f0327f6115ebbd2a79606384cad436334ab82914", "filename": "roles/docker/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for docker\n"}, {"commit_sha": "cb153a13ab607e1c015fec227d8f74cfbb3d9b8e", "sha": "cfa928101c1fae7850279007a9ddc4c04cc0e450", "filename": "handlers/main.yml", "repository": "willshersystems/ansible-sshd", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n- name: reload_sshd\n  service:\n    name: \"{{ sshd_service }}\"\n    state: reloaded\n  when: sshd_allow_reload"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "873ee96859d6271467e110c7831db54f86f96746", "filename": "tasks/redis.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/redis.yml: Deploy redis\n\n  - include: \"{{ ansible_distribution }}/redis.yml\"\n\n  - name: Ensure redis is running\n    service: name={{ redis_service_name }} state=started enabled=true\n"}, {"commit_sha": "6d51642c8f7babe4c8185b60872420333a5d3caa", "sha": "cb26e98067c86561096a9464f28ab55442b97eb5", "filename": "tasks/Debian/main.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/Debian/main.yml: Debian specific set-up\n# This takes care of base prerequisites for Debian\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure the Sensu APT repo GPG key is present\n    apt_key:\n      url: http://repositories.sensuapp.org/apt/pubkey.gpg\n      state: present\n\n  - name: Ensure the Sensu Core APT repo is present\n    apt_repository:\n      repo: 'deb     http://repositories.sensuapp.org/apt sensu main'\n      state: present\n      update_cache: true\n\n  - name: Ensure Sensu is installed\n    apt: name=sensu state={{ sensu_pkg_state }}\n"}, {"commit_sha": "59bde5ac149cca3058d0b8a8bd4b2d0e21e8c861", "sha": "22c0add3c498db7b4ae54b4d408c48a1b95f73aa", "filename": "tasks/section_05_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 5.1.1 Ensure NIS is not installed (Scored)\n    apt: name=nis state=absent purge=yes\n    tags:\n    - section5\n    - section5.1\n    - section5.1.1\n\n  - name: 5.1.2 Ensure rsh, rlogin, rexec, talk, telnet, chargen, daytime, echo, discard, time is not enabled (stat inetd) (Scored)\n    stat: path=/etc/inetd.conf\n    register: inetd_path\n    tags:\n    - section5\n    - section5.1\n    - section5.1.2\n\n  - name: 5.1.2 Ensure rsh, rlogin, rexec, talk, telnet, chargen, daytime, echo, discard, time is not enabled (Scored)\n    lineinfile: >\n        dest=/etc/inetd.conf\n        regexp='^({{ item }}.*)'\n        line='#\\1'\n        state=present\n        backrefs=yes\n        backup=yes\n    with_items:\n        - shell\n        - login\n        - exec\n        - talk\n        - ntalk\n        - telnet\n        - chargen\n        - daytime\n        - echo\n        - discard\n        - time\n    when: inetd_path.stat.exists == True\n    tags:\n    - section5\n    - section5.1\n    - section5.1.2\n\n  - name: 5.1.3.1 Ensure rsh client is not installed (Scored)\n    apt: name=rsh-client state=absent purge=yes\n    tags:\n    - section5\n    - section5.1\n    - section5.1.3\n    - section5.1.3.1\n\n  - name: 5.1.3.2 Ensure rsh client is not installed (Scored)\n    apt: name=rsh-redone-client state=absent purge=yes\n    tags:\n    - section5\n    - section5.1\n    - section5.1.3\n    - section5.1.3.2\n\n  - name: 5.1.5 Ensure talk client is not installed (Scored)\n    apt: name=talk state=absent purge=yes\n    tags:\n    - section5\n    - section5.1\n    - section5.1.5\n\n  - name: 5.1.8 Ensure xinetd is not enabled (stat xinetd) (Scored)\n    stat: path=/etc/init/xinetd.conf\n    register: xinetd_path\n    tags:\n    - section5\n    - section5.1\n    - section5.1.8\n\n  - name: 5.1.8 Ensure xinetd is not enabled (Scored)\n    lineinfile: >\n        dest=/etc/init/xinetd.conf\n        regexp='start on runlevel'\n        state=present\n        line='#start on runlevel [2345]'\n    when: xinetd_path.stat.exists == True\n    tags:\n    - section5\n    - section5.1\n    - section5.1.8\n"}, {"commit_sha": "ec4de12ae75f7191a5f71aa775e0344679ea1477", "sha": "66a7653efc2716d16f7ffadf146f4307e96707ea", "filename": "tasks/main.yml", "repository": "UnderGreen/ansible-role-mongodb", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- include: install.deb.yml\n  when: ansible_os_family == 'Debian'\n\n- include: configure.yml\n\n- include: replication.yml\n  when: mongodb_conf_replSet != \"\"\n\n- include: mms-agent.yml\n  when: mongodb_mms_api_key != \"\"\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "80e889264005dc9efdaa0b81597c7fc09f757a14", "filename": "tasks/ssl_generate.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/ssl_generate.yml: Generate SSL data and stash to dynamic\n# data store for deployment to clients\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure SSL generation directory exists\n    file:\n      dest: \"{{ sensu_config_path }}/ssl_generation\"\n      state: directory\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    when: sensu_master\n\n  - block:\n\n    - name: Untar the ssl_certs tarball from sensuapp.org\n      unarchive:\n      args:\n        src: http://sensuapp.org/docs/{{ sensu_ssl_tool_version }}/files/sensu_ssl_tool.tar\n        dest: \"{{ sensu_config_path }}/ssl_generation/\"\n        creates: \"{{ sensu_config_path }}/ssl_generation/sensu_ssl_tool\"\n        copy: no\n\n    - name: Generate SSL certs\n      command: \"_ {{ sensu_config_path }}/ssl_generation/sensu_ssl_tool/ssl_certs.sh generate\"\n      args:\n        chdir: \"{{ sensu_config_path }}/ssl_generation/sensu_ssl_tool\"\n        creates: \"{{ sensu_config_path }}/ssl_generation/sensu_ssl_tool/server\"\n        executable: \"{{ __bash_path }}\"\n\n    when: sensu_master|bool\n    become: true\n    become_user: \"{{ sensu_user_name }}\"\n\n  - name: Stash the Sensu SSL certs/keys\n    fetch:\n      src: \"{{ sensu_config_path }}/ssl_generation/sensu_ssl_tool/{{ item }}\"\n      dest: \"{{ dynamic_data_store }}\"\n    when: sensu_master\n    with_items:\n      - sensu_ca/cacert.pem\n      - server/cert.pem\n      - server/key.pem\n      - client/cert.pem\n      - client/key.pem\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "206b4da8c114b64a8859725538fc75bb9092dde9", "filename": "roles/dcos_cli/vars/cassandra.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "dcos_cli_framework_cassandra_enabled: false\ndcos_cli_framework_cassandra_node_count: 1\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "4e8da9469d0ce198ffba540bbb44767cdc812560", "filename": "tasks/encrypt_gossip.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# File: encrypt_gossip.yml - Gossip encryption tasks for Consul\n\n- block:\n    - name: Read gossip encryption key from previously boostrapped server\n      shell: 'cat {{ consul_config_path }}/bootstrap/config.json | grep \"encrypt\" | sed -E ''s/\"encrypt\": \"(.+)\",?/\\1/'' | sed ''s/^ *//;s/ *$//'''\n      register: consul_key_read\n      run_once: true\n\n    - name: Save gossip encryption key from existing configuration\n      set_fact: consul_raw_key={{ consul_key_read.stdout }}\n      ignore_errors: true\n\n  when:\n    - consul_raw_key is not defined\n    - bootstrap_state.stat.exists | bool\n\n- name: Write gossip encryption key locally for use with new servers\n  copy:\n    content: \"{{ consul_raw_key }}\"\n    dest: /tmp/consul_raw.key\n  become: false\n  vars:\n    ansible_become: false\n  when:\n    - consul_raw_key is defined\n    - bootstrap_state.stat.exists | bool\n  delegate_to: 127.0.0.1\n\n- name: Read gossip encryption key for servers that require it\n  set_fact: consul_raw_key=\"{{ lookup('file', '/tmp/consul_raw.key') }}\"\n  when:\n    - consul_raw_key is not defined\n    - bootstrap_state.stat.exists | bool\n\n- name: Delete gossip encryption key file\n  file:\n    path: /tmp/consul_raw.key\n    state: absent\n  become: false\n  vars:\n    ansible_become: false\n  when:\n    - consul_raw_key is defined\n    - bootstrap_state.stat.exists | bool\n  delegate_to: 127.0.0.1\n\n- block:\n    - name: Generate gossip encryption key\n      shell: \"PATH={{ consul_bin_path }}:$PATH consul keygen\"\n      register: consul_keygen\n      run_once: true\n\n    - name: Write gossip encryption key to fact\n      set_fact: consul_raw_key={{ consul_keygen.stdout }}\n  when:\n    - consul_raw_key is not defined\n    - not bootstrap_state.stat.exists | bool\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "e2897f99ed03a13f70c51189381833d7b31d621c", "filename": "roles/st2web/defaults/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# defaults file for st2web\nst2web_revision: 1\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "c1ffb328921bc00d2df4aa68e941e6d9bd12fb66", "filename": "roles/dcos_cli/vars/exhibitor.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "dcos_cli_framework_exhibitor_enabled: false\ndcos_cli_framework_exhibitor_mem: 3072.0\ndcos_cli_framework_exhibitor_cpus: 1\ndcos_cli_framework_exhibitor_image: mesosphere/exhibitor-dcos\n"}, {"commit_sha": "80530fde7df1a94ad361434e02816b0816a2c47a", "sha": "a8566f14f8bc3d7dc24c5ef16a8efc83b4f8bc68", "filename": "roles/consul/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks file for consul\n- name: remove consul override\n  command: /bin/rm -f /etc/init/consul.override\n\n- name: start consul\n  service: name=consul state=started\n\n- name: configure consul\n  sudo: yes\n  template: src=consul.json.j2 dest=/etc/consul.d/consul.json owner=root group=root mode=0644\n  notify:\n    - Restart consul\n  tags:\n    - consul\n\n- name: configure atlas for consul\n  sudo: yes\n  template: src=atlas.json.j2 dest=/etc/consul.d/atlas.json owner=root group=root mode=0644\n  when: consul_atlas_join\n  notify:\n    - Restart consul\n  tags:\n    - consul\n\n- name: remove consul-join override\n  command: /bin/rm -f /etc/init/consul-join.override\n  when: consul_join is defined\n\n- name: configure consul-join\n  sudo: yes\n  template: src=consul-join.j2 dest=/etc/service/consul-join owner=root group=root mode=0644\n  notify:\n    - Restart consul\n  when: consul_join is defined\n  tags:\n    - consul\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "cc1d7d75d600c70f1934bd044aad7cbfe4e3bf1a", "filename": "roles/consul/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n- include: config.yml\n\n- name: enable consul\n  become: yes\n  service:\n    name: consul\n    enabled: yes\n    state: started\n  notify:\n    - restart consul\n  tags:\n    - consul\n\n- name: wait for consul to listen\n  wait_for:\n    host: \"{{ consul_bind_addr }}\"\n    port: 8500\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "a44138218617f50a7941ffb7d09e8827532218a0", "filename": "roles/traefik/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n- name: create traefik config directory\n  sudo: yes\n  file:\n    path: \"{{ traefik_config_dir }}\"\n    state: directory\n    mode: 0755\n  tags:\n    - traefik\n\n- name: configure traefik\n  sudo: yes\n  template:\n    src: traefik.toml.j2\n    dest: \"{{ traefik_config_dir }}/traefik.toml\"\n    mode: 0644\n    backup: yes\n  tags:\n    - traefik\n\n- name: deploy traefik service\n  sudo: yes\n  template:\n    src: traefik.service.j2\n    dest: /etc/systemd/system/traefik.service\n  notify:\n    - restart traefik\n  tags:\n    - traefik\n\n- name: enable traefik\n  sudo: yes\n  service:\n    name: traefik\n    state: started\n    enabled: yes\n  tags:\n    - traefik\n\n- name: Set traefik consul service definition\n  sudo: yes\n  template:\n    src: traefik-consul.json.j2\n    dest: \"{{ traefik_consul_dir }}/traefik.json\"\n  notify:\n    - restart consul\n  tags:\n    - traefik\n"}, {"commit_sha": "9966c6de1ed4ef5071a9bea83b4bb69a11dd32ba", "sha": "156b39c473edadf172419d6da18876a89382d770", "filename": "roles/mesos/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "# used for leader election amongst masters\n- name: Set ZooKeeper URL\n  template: src=zk.j2 dest=/etc/mesos/zk mode=0644\n  sudo: yes\n\n# Tasks for Master nodes\n- name: remove mesos-master override\n  file: path=/etc/init/mesos-master.override state=absent\n  when: mesos_install_mode == \"master\"\n\n- name: start mesos-master (and enable it at boot)\n  service: name=mesos-master state=started enabled=yes\n  when: mesos_install_mode == \"master\"\n\n- name: Set Mesos Master ip\n  copy:\n    content: \"{{mesos_local_address}}\"\n    dest: /etc/mesos-master/ip\n    mode: 0644\n  sudo: yes\n  notify:\n    - Restart mesos master\n  when: mesos_install_mode == \"master\"\n\n- name: Set Mesos Master hostname\n  copy:\n    content: \"{{mesos_local_address}}\"\n    dest: /etc/mesos-master/hostname\n    mode: 0644\n  sudo: yes\n  notify:\n    - Restart mesos master\n  when: mesos_install_mode == \"master\"\n\n  # The Mesos quorum value is based on the number of Mesos Masters. Take the\n  # number of masters, divide by 2, and round-up to nearest integer. For example,\n  # if there are 1 or 2 masters the quorum count is 1. If there are 3 or 4\n  # masters then the quorum count is 2. For 5 or 6 masters it's 3 and so on.\n- name: Set Mesos Master quorum count\n  template: src=quorum.j2 dest=/etc/mesos-master/quorum mode=0644\n  sudo: yes\n  notify:\n    - Restart mesos master\n  when: mesos_install_mode == \"master\"\n\n- name: Set Mesos Master Cluster name\n  copy:\n    content: \"{{mesos_cluster_name}}\"\n    dest: /etc/mesos-master/cluster\n    mode: 0644\n  sudo: yes\n  notify:\n    - Restart mesos master\n  when: mesos_install_mode == \"master\"\n\n- name: Set Mesos Master consul service definition\n  sudo: yes\n  template:\n    src: mesos-master-consul.j2\n    dest: \"{{ consul_dir }}/mesos-master.json\"\n  notify:\n    - Restart consul\n  when: mesos_install_mode == \"master\"\n\n# Tasks for Slave nodes\n- name: remove mesos-slave override\n  file: path=/etc/init/mesos-slave.override state=absent\n  when: mesos_install_mode == \"slave\"\n\n- name: Set Mesos Slave hostname\n  copy:\n    content: \"{{mesos_local_address}}\"\n    dest: /etc/mesos-slave/hostname\n    mode: 0644\n  sudo: yes\n  notify:\n    - Restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: set executor registration timeout\n  sudo: yes\n  copy:\n    dest: /etc/mesos-slave/executor_registration_timeout\n    content: \"{{ mesos_executor_registration_timeout }}\"\n  notify:\n    - Restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: set containerizers\n  sudo: yes\n  copy:\n    dest: /etc/mesos-slave/containerizers\n    content: \"{{ mesos_containerizers }}\"\n  notify:\n    - Restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: set slave resources\n  sudo: yes\n  copy:\n    dest: /etc/mesos-slave/resources\n    content: \"{{ mesos_resources }}\"\n  notify:\n    - Restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: Set Mesos Slave ip\n  copy:\n    content: \"{{mesos_local_address}}\"\n    dest: /etc/mesos-slave/ip\n    mode: 0644\n  sudo: yes\n  notify:\n    - Restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: Create Mesos Slave work area\n  file:\n    dest: \"{{mesos_slave_work_dir}}\"\n    mode: 0755\n    state: directory\n  sudo: yes\n  notify:\n    - Restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: Set Mesos Slave work area\n  copy:\n    content: \"{{mesos_slave_work_dir}}\"\n    dest: /etc/mesos-slave/work_dir\n    mode: 0644\n  sudo: yes\n  notify:\n    - Restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: start mesos-slave (and enable it at boot)\n  service: name=mesos-slave state=started enabled=yes\n"}, {"commit_sha": "a2393d46f0b98700161c4cefd9260d7694bd0bf3", "sha": "8252deeeecfb6adaa52cf98b45f21e1d1928cd03", "filename": "tasks/section_08_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: Check if the file auditd.conf exists\n    stat: >\n        path=/etc/audit/auditd.conf\n    register: auditd_file\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n\n  - name: Create the audit directory if it does not exists\n    file: >\n        path=/etc/audit/\n        state=directory\n    when: not auditd_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n\n  - name: 8.1.1-3 Configure Data Retention\n    lineinfile: >\n        dest=/etc/audit/auditd.conf\n        regexp=\"{{ item.rxp }}\"\n        line=\"{{ item.line }}\"\n        state=present\n        create=yes\n    with_items:\n      - { rxp: '^max_log_file ', line: 'max_log_file = {{ Max_Log_File }}' }\n      - { rxp: '^space_left_action', line: 'space_left_action = email' }\n      - { rxp: '^action_mail_acct', line: 'action_mail_acct = root' }\n      - { rxp: '^admin_space_left_action', line: 'admin_space_left_action = halt' }\n      - { rxp: '^max_log_file_action', line: 'max_log_file_action = keep_logs' }\n    notify: restart auditd\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n      - section8.1.1.2\n      - section8.1.1.3\n\n  - name: 8.1.2 Install and Enable auditd Service (Scored)\n    apt: name=auditd state=present\n    tags:\n      - section8\n      - section8.1\n      - section8.1.2\n      - section8.1.2\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    stat: path=/etc/default/grub\n    register: grubcfg_file\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    file: >\n        path=/etc/default/grub\n        state=touch\n    when: not grubcfg_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    lineinfile: >\n        dest=/etc/default/grub\n        line='GRUB_CMDLINE_LINUX=\"audit=1\"'\n    when: not grubcfg_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.4 Record Events That Modify Date and Time Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a always,exit -F arch=b64 -S adjtimex -S settimeofday -k time-change'\n      - '-a always,exit -F arch=b32 -S adjtimex -S settimeofday -S stime -k time-change'\n      - '-a always,exit -F arch=b64 -S clock_settime -k time-change'\n      - '-a always,exit -F arch=b32 -S clock_settime -k time-change'\n      - '-w /etc/localtime -p wa -k time-change'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"64\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.4\n\n  - name: 8.1.4 Record Events That Modify Date and Time Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line={{ item }}\n      state=present\n      create=yes\n    with_items:\n      - '-a always,exit -F arch=b32 -S adjtimex -S settimeofday -S stime -k time-change'\n      - '-a always,exit -F arch=b32 -S clock_settime -k time-change'\n      - '-w /etc/localtime -p wa -k time-change'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"32\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.4\n\n  - name: 8.1.5,7,8,9,15,16,17 Record Events That Modify User/Group Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-w /etc/group -p wa -k identity'\n      - '-w /etc/passwd -p wa -k identity'\n      - '-w /etc/gshadow -p wa -k identity'\n      - '-w /etc/shadow -p wa -k identity'\n      - '-w /etc/security/opasswd -p wa -k identity'\n      - '-w /var/log/faillog -p wa -k logins'\n      - '-w /var/log/lastlog -p wa -k logins'\n      - '-w /var/log/tallylog -p wa -k logins'\n      - '-w /var/run/utmp -p wa -k session'\n      - '-w /var/log/wtmp -p wa -k session'\n      - '-w /var/log/btmp -p wa -k session'\n      - '-w /etc/selinux/ -p wa -k MAC-policy'\n      - '-w /etc/sudoers -p wa -k scope'\n      - '-w /var/log/sudo.log -p wa -k actions'\n      - '-w /sbin/insmod -p x -k modules'\n      - '-w /sbin/rmmod -px -k modules'\n      - '-w /sbin/modprobe -p x -k modules'\n    notify: restart auditd\n    tags:\n      - section8\n      - section8.1\n      - section8.1.5\n      - section8.1.7\n      - section8.1.8\n      - section8.1.9\n      - section8.1.15\n      - section8.1.16\n      - section8.1.17\n\n  - name: 8.1.6,10,11,13,14,17 Record Events That Modify the System's Network Environment (64b) (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a exit,always -F arch=b64 -S sethostname -S setdomainname -k system-locale'\n      - '-a exit,always -F arch=b32 -S sethostname -S setdomainname -k system-locale'\n      - '-w /etc/issue -p wa -k system-locale'\n      - '-w /etc/issue.net -p wa -k system-locale'\n      - '-w /etc/hosts -p wa -k system-locale'\n      - '-w /etc/network -p wa -k system-locale'\n      - '-a always,exit -F arch=b64 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b64 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b64 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b32 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b64 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b32 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b64 -S init_module -S delete_module -k modules'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"64\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.6\n      - section8.1.10\n      - section8.1.11\n      - section8.1.13\n      - section8.1.14\n      - section8.1.17\n\n  - name: 8.1.6,10,11,13,14,17 Record Events That Modify the System's Network Environment (32b) (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a exit,always -F arch=b32 -S sethostname -S setdomainname -k system-locale'\n      - '-w /etc/issue -p wa -k system-locale'\n      - '-w /etc/issue.net -p wa -k system-locale'\n      - '-w /etc/hosts -p wa -k system-locale'\n      - '-w /etc/network -p wa -k system-locale'\n      - '-a always,exit -F arch=b32 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b32 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b32 -S init_module -S delete_module -k modules'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"32\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.6\n      - section8.1.10\n      - section8.1.11\n      - section8.1.13\n      - section8.1.14\n      - section8.1.17\n\n  - name: 8.1.12 Collect Use of Privileged Commands (Scored)\n    shell: find / -xdev \\( -perm -4000 -o -perm -2000 \\) -type f | awk '{print \"-a always,exit -F path=\" $1 \" -F perm=x -F auid>=500 -F auid!=4294967295 -k privileged\" }'\n    register: audit_lines_for_find\n    changed_when: False\n    tags:\n      - section8\n      - section8.1\n      - section8.1.12\n\n  - name: 8.1.12 Collect Use of Privileged Commands (infos) (Scored)\n    lineinfile: >\n        dest=/etc/audit/audit.rules\n        line={{ item }}\n        state=present\n        create=yes\n    with_items: audit_lines_for_find.stdout_lines\n    tags:\n      - section8\n      - section8.1\n      - section8.1.12\n\n  - name: 8.1.18 Make the Audit Configuration Immutable (Scored)\n    lineinfile: >\n        dest='/etc/audit/audit.rules'\n        line='-e 2'\n        insertafter=EOF\n        state=present\n        create=yes\n    tags:\n      - section8\n      - section8.1\n      - section8.1.18\n\n  - name: 8.3.1 Install AIDE (Scored)\n    apt: name=aide state=present\n    register: aide_installed\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (init) (Scored)\n    command: aideinit\n    when: aide_installed.changed == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (Scored)\n    stat: path=/var/lib/aide/aide.db.new\n    register: aide_db_path\n    when:\n      - aide_installed.changed == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (copy db) (Scored)\n    command: mv /var/lib/aide/aide.db.new /var/lib/aide/aide.db\n    when:\n      - aide_installed.changed == True\n      - aide_db_path.stat.exists == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.2 Implement Periodic Execution of File Integrity (Scored)\n    cron: name=\"Check files integrity\" minute=\"0\" hour=\"5\" job=\"/usr/sbin/aide --check\"\n    tags:\n      - section8\n      - section8.3\n      - section8.3.2\n"}, {"commit_sha": "af3dfdf7cf37437f5609f1a12e4ac7cbaebd4867", "sha": "f0fdf7bf9ce7825e166df898dc9f710c67cf9ae2", "filename": "roles/weave/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for weave\n- name: include all interfaces.d\n  sudo: yes\n  lineinfile:\n    dest: /etc/network/interfaces\n    state: present\n    line: 'source /etc/network/interfaces.d/*.cfg'\n  tags:\n    - weave\n\n# Start docker as it is a requirement for weave create-bridge.\n- name: Start up docker\n  service:\n    name: docker\n    state: started\n  tags:\n    - weave\n\n- name: configure weave interface\n  sudo: yes\n  template:\n    src: interfaces.j2\n    dest: /etc/network/interfaces.d/weave.cfg\n    owner: root\n    group: root\n    mode: 0644\n  tags:\n    - weave\n\n# Create weave bridge.\n- name: bring up weave bridge\n  command: ifup weave\n  sudo: yes\n\n- name: upload weave template service\n  template:\n    src: weave.conf.j2\n    dest: \"/etc/init/weave.conf\"\n    mode: 0755\n  sudo: yes\n  tags:\n    - weave\n\n# Restart docker with weave bridge available and triggers weave service.\n- name: configure weave bridge for docker\n  sudo: yes\n  lineinfile:\n    dest: /etc/default/docker\n    state: present\n    regexp: ^DOCKER_OPTS=.*--bridge=weave.*\n    line: 'DOCKER_OPTS=\\\"$DOCKER_OPTS {{ weave_docker_opts }}\\\"'\n  notify:\n    - restart docker\n  tags:\n    - weave\n\n- name: download weave scope\n  get_url:\n    url: \"{{ weave_scope_url }}\"\n    dest: \"{{ weave_scope_dest }}\"\n    mode: 0755\n    validate_certs: no\n  environment: proxy_env\n  tags:\n    - weave\n\n- name: upload weave scope template service\n  template:\n    src: scope.conf.j2\n    dest: \"/etc/init/weavescope.conf\"\n    mode: 0755\n  sudo: yes\n  tags:\n    - weave\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "aab8957023c0932fc24b2edc52d4415a3b563b29", "filename": "tasks/SmartOS/rabbit.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/SmartOS/rabbit.yml: Deploy RabbitMQ\n# Specific to Joyent SmartOS\n\n  - name: Ensure RabbitMQ is installed\n    pkgin: name=rabbitmq state=present\n\n  - name: Ensure EPMD is running\n    service:\n      name: epmd\n      state: started\n      enabled: true\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "dbf4b7f19bf4ef925df59d97ebc57b1cf8a53280", "filename": "tasks/services.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n## File: services.yml - services configuration\n\n- name: \"Configure consul services\"\n  template:\n    dest: \"{{ consul_configd_path }}/service_{{ item.name }}.json\"\n    src: service.json.j2\n    owner: \"{{ consul_user }}\"\n    group: \"{{ consul_group }}\"\n    mode: 0644\n  with_items: \"{{ consul_services }}\"\n  notify:\n    - restart consul\n\n- name: Get the list of service config file\n  find:\n    paths: \"{{ consul_configd_path }}\"\n    file_type: file\n  register: services_enabled_unix\n  when: ansible_os_family != 'Windows'\n\n- name: Get the list of service config file [Windows]\n  win_find:\n    paths: \"{{ consul_configd_path }}\"\n    file_type: file\n  register: services_enabled_windows\n  when: ansible_os_family == 'Windows'\n\n- name: set var for enabled services\n  set_fact:\n    services_enabled_files: \"{{ services_enabled_unix['files'] }}\"\n  when: ansible_os_family != 'Windows'\n\n- name: set var for enabled services [Windows]\n  set_fact:\n    services_enabled_files: \"{{ services_enabled_windows['files'] }}\"\n  when: ansible_os_family == 'Windows'\n\n- name: Set fact with list of existing configuration files\n  set_fact:\n    list_current_service_config: \"{{ list_current_service_config |default([]) + [ item.path ] }}\"\n  with_items: \"{{ services_enabled_files }}\"\n\n- name: Set fact with list of service we manage\n  set_fact:\n    managed_files: \"{{ managed_files |default([]) }} + \\\n    [ '{{ consul_configd_path }}/service_{{ item.name }}.json' ]\"\n  with_items: \"{{ consul_services }}\"\n\n- name: Delete non declared services\n  file:\n    path: \"{{ item }}\"\n    state: absent\n  when: ansible_os_family != 'Windows' and item not in managed_files\n  with_items: \"{{ list_current_service_config }}\"\n  notify:\n    - restart consul\n\n- name: Delete non declared services [Windows]\n  win_file:\n    path: \"{{ item }}\"\n    state: absent\n  when: ansible_os_family == 'Windows' and item not in managed_files\n  with_items: \"{{ list_current_service_config }}\"\n  notify:\n    - restart consul\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "88469c129a31b19688648ea87f2d73bbfbcb995e", "filename": "roles/mesos/tasks/slave.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# Tasks for Slave nodes\n- name: create mesos-slave work directory\n  file:\n    path: \"{{ mesos_slave_work_dir }}\"\n    state: directory\n    mode: 0755\n  sudo: yes\n  tags:\n    - mesos-slave\n\n- name: deploy mesos-slave service\n  sudo: yes\n  sudo_user: root\n  template:\n    src: mesos-slave.service.j2\n    dest: /etc/systemd/system/mesos-slave.service\n  notify:\n    - restart mesos slave\n  tags:\n    - mesos-slave\n\n- name: ensure mesos-slave is running (and enable it at boot)\n  sudo: yes\n  service:\n    name: mesos-slave\n    state: started\n    enabled: yes\n  tags:\n    - mesos-slave\n\n#- name: run prometheus mesos slave exporter container\n#  when: mesos_install_mode == \"slave\" and prometheus_enabled|bool\n#  docker:\n#    name: mesos-exporter\n#    image: \"{{ prometheus_mesos_exporter_image }}\"\n#    command: \"-exporter.scrape-mode=slave -exporter.url=http://{{ mesos_hostname }}:{{ mesos_slave_port }}\"\n#    state: started\n#    restart_policy: always\n#    ports:\n#    - \"{{ prometheus_mesos_exporter_port }}:{{ prometheus_mesos_exporter_port }}\"\n#  environment: proxy_env\n#  tags:\n#    - prometheus\n#    - mesos_slave\n\n#- name: Set mesos-exporter consul service definition\n#  when: mesos_install_mode == \"slave\" and prometheus_enabled|bool\n#  sudo: yes\n#  template:\n#    src: mesos-exporter-consul.j2\n#    dest: \"{{ consul_dir }}/mesos-exporter.json\"\n#  notify:\n#    - restart consul\n#  tags:\n#    - prometheus\n#    - mesos_slave\n"}, {"commit_sha": "21712b74b7f5d936e70186bbed6bb37e3a7ad5e6", "sha": "bd74553c890b5a80af3587618434921fd6314b5a", "filename": "roles/cadvisor/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for cadvisor\ncadvisor_enabled: true\ncadvisor_version: 'latest'\ncadvisor_host_port: 8081\ncadvisor_restart_policy: 'always'\ncadvisor_net: 'bridge'\ncadvisor_hostname: \"{{ ansible_ssh_host }}\"\ncadvisor_image: \"google/cadvisor:{{ cadvisor_version }}\"\ncadvisor_consul_dir: /etc/consul.d\n"}, {"commit_sha": "addbee435e20e706e7cf5d2f0a3723e17f79b527", "sha": "4b1b35d31ea6658d760101cecf50d1be6a575279", "filename": "tasks/section_08_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: Check if the file auditd.conf exists\n    stat: >\n        path=/etc/audit/auditd.conf\n    register: auditd_file\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n\n  - name: Create the audit directory if it does not exists\n    file: >\n        path=/etc/audit/\n        state=directory\n    when: not auditd_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n\n  - name: 8.1.1-3 Configure Data Retention\n    lineinfile: >\n        dest=/etc/audit/auditd.conf\n        regexp=\"{{ item.rxp }}\"\n        line=\"{{ item.line }}\"\n        state=present\n        create=yes\n    with_items:\n      - { rxp: '^max_log_file ', line: 'max_log_file = {{ Max_Log_File }}' }\n      - { rxp: '^space_left_action', line: 'space_left_action = email' }\n      - { rxp: '^action_mail_acct', line: 'action_mail_acct = root' }\n      - { rxp: '^admin_space_left_action', line: 'admin_space_left_action = halt' }\n      - { rxp: '^max_log_file_action', line: 'max_log_file_action = keep_logs' }\n    notify: restart auditd\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n      - section8.1.1.2\n      - section8.1.1.3\n\n  - name: 8.1.2 Install and Enable auditd Service (Scored)\n    apt: name=auditd state=present\n    tags:\n      - section8\n      - section8.1\n      - section8.1.2\n      - section8.1.2\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    stat: path=/etc/default/grub\n    register: grubcfg_file\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    file: >\n        path=/etc/default/grub\n        state=touch\n    when: not grubcfg_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    lineinfile: >\n        dest=/etc/default/grub\n        line='GRUB_CMDLINE_LINUX=\"audit=1\"'\n    when: not grubcfg_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.4 Record Events That Modify Date and Time Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a always,exit -F arch=b64 -S adjtimex -S settimeofday -k time-change'\n      - '-a always,exit -F arch=b32 -S adjtimex -S settimeofday -S stime -k time-change'\n      - '-a always,exit -F arch=b64 -S clock_settime -k time-change'\n      - '-a always,exit -F arch=b32 -S clock_settime -k time-change'\n      - '-w /etc/localtime -p wa -k time-change'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"64\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.4\n\n  - name: 8.1.4 Record Events That Modify Date and Time Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a always,exit -F arch=b32 -S adjtimex -S settimeofday -S stime -k time-change'\n      - '-a always,exit -F arch=b32 -S clock_settime -k time-change'\n      - '-w /etc/localtime -p wa -k time-change'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"32\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.4\n\n  - name: 8.1.5,7,8,9,15,16,17 Record Events That Modify User/Group Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-w /etc/group -p wa -k identity'\n      - '-w /etc/passwd -p wa -k identity'\n      - '-w /etc/gshadow -p wa -k identity'\n      - '-w /etc/shadow -p wa -k identity'\n      - '-w /etc/security/opasswd -p wa -k identity'\n      - '-w /var/log/faillog -p wa -k logins'\n      - '-w /var/log/lastlog -p wa -k logins'\n      - '-w /var/log/tallylog -p wa -k logins'\n      - '-w /var/run/utmp -p wa -k session'\n      - '-w /var/log/wtmp -p wa -k session'\n      - '-w /var/log/btmp -p wa -k session'\n      - '-w /etc/selinux/ -p wa -k MAC-policy'\n      - '-w /etc/sudoers -p wa -k scope'\n      - '-w /var/log/sudo.log -p wa -k actions'\n      - '-w /sbin/insmod -p x -k modules'\n      - '-w /sbin/rmmod -px -k modules'\n      - '-w /sbin/modprobe -p x -k modules'\n    notify: restart auditd\n    tags:\n      - section8\n      - section8.1\n      - section8.1.5\n      - section8.1.7\n      - section8.1.8\n      - section8.1.9\n      - section8.1.15\n      - section8.1.16\n      - section8.1.17\n\n  - name: 8.1.6,10,11,13,14,17 Record Events That Modify the System's Network Environment (64b) (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a exit,always -F arch=b64 -S sethostname -S setdomainname -k system-locale'\n      - '-a exit,always -F arch=b32 -S sethostname -S setdomainname -k system-locale'\n      - '-w /etc/issue -p wa -k system-locale'\n      - '-w /etc/issue.net -p wa -k system-locale'\n      - '-w /etc/hosts -p wa -k system-locale'\n      - '-w /etc/network -p wa -k system-locale'\n      - '-a always,exit -F arch=b64 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b64 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b64 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b32 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b64 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b32 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b64 -S init_module -S delete_module -k modules'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"64\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.6\n      - section8.1.10\n      - section8.1.11\n      - section8.1.13\n      - section8.1.14\n      - section8.1.17\n\n  - name: 8.1.6,10,11,13,14,17 Record Events That Modify the System's Network Environment (32b) (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a exit,always -F arch=b32 -S sethostname -S setdomainname -k system-locale'\n      - '-w /etc/issue -p wa -k system-locale'\n      - '-w /etc/issue.net -p wa -k system-locale'\n      - '-w /etc/hosts -p wa -k system-locale'\n      - '-w /etc/network -p wa -k system-locale'\n      - '-a always,exit -F arch=b32 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b32 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b32 -S init_module -S delete_module -k modules'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"32\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.6\n      - section8.1.10\n      - section8.1.11\n      - section8.1.13\n      - section8.1.14\n      - section8.1.17\n\n  - name: 8.1.12 Collect Use of Privileged Commands (Scored)\n    shell: find / -xdev \\( -perm -4000 -o -perm -2000 \\) -type f | awk '{print \"-a always,exit -F path=\" $1 \" -F perm=x -F auid>=500 -F auid!=4294967295 -k privileged\" }'\n    register: audit_lines_for_find\n    changed_when: False\n    tags:\n      - section8\n      - section8.1\n      - section8.1.12\n\n  - name: 8.1.12 Collect Use of Privileged Commands (infos) (Scored)\n    lineinfile: >\n        dest=/etc/audit/audit.rules\n        line='{{ item }}'\n        state=present\n        create=yes\n    with_items: audit_lines_for_find.stdout_lines\n    tags:\n      - section8\n      - section8.1\n      - section8.1.12\n\n  - name: 8.1.18 Make the Audit Configuration Immutable (Scored)\n    lineinfile: >\n        dest='/etc/audit/audit.rules'\n        line='-e 2'\n        insertafter=EOF\n        state=present\n        create=yes\n    tags:\n      - section8\n      - section8.1\n      - section8.1.18\n\n  - name: 8.3.1 Install AIDE (Scored)\n    apt: name=aide state=present\n    register: aide_installed\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (init) (Scored)\n    command: aideinit\n    when: aide_installed.changed == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (Scored)\n    stat: path=/var/lib/aide/aide.db.new\n    register: aide_db_path\n    when:\n      - aide_installed.changed == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (copy db) (Scored)\n    command: mv /var/lib/aide/aide.db.new /var/lib/aide/aide.db\n    when:\n      - aide_installed.changed == True\n      - aide_db_path.stat.exists == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.2 Implement Periodic Execution of File Integrity (Scored)\n    cron: name=\"Check files integrity\" minute=\"0\" hour=\"5\" job=\"/usr/sbin/aide --check\"\n    tags:\n      - section8\n      - section8.3\n      - section8.3.2\n"}, {"commit_sha": "9ad67b6ef151d5fbaa05230e6cecb4bed1db7d9d", "sha": "def22b71e29a9b9485fc201fc28ff4cb2fc5b3fd", "filename": "tasks/section_04_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 4.1.1 Restrict Core Dumps (Scored)\n    lineinfile: dest='/etc/security/limits.conf' line=\"* hard core 0\" state=present\n    tags:\n      - section4\n      - section4.1\n      - section4.1.1\n\n  - name: 4.1.2 Restrict Core Dumps (Scored)\n    sysctl: >\n        name=fs.suid_dumpable\n        value=0\n        state=present\n    when: restrict_core_dumps == True\n    tags:\n      - section4\n      - section4.1\n      - section4.1.2\n\n  - name: 4.1.4 Restrict Core Dumps (stat file) (Scored)\n    stat: path='/etc/init/apport.conf'\n    register: apport_present\n    tags:\n      - section4\n      - section4.1\n      - section4.1.4\n\n  - name: 4.1.5 Restrict Core Dumps (Scored)\n    lineinfile: >\n        dest='/etc/init/apport.conf'\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n    when: apport_present.stat.exists == True\n    tags:\n      - section4\n      - section4.1\n      - section4.1.3\n\n  - name: 4.1.6 Restrict Core Dumps (stat file) (Scored)\n    stat: path='/etc/init/whoopsie.conf'\n    register: whoopsie_present\n    tags:\n      - section4\n      - section4.1\n      - section4.1.4\n\n  - name: 4.1.7 Restrict Core Dumps (Scored)\n    lineinfile: >\n        dest='/etc/init/whoopsie.conf'\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n    when: whoopsie_present.stat.exists == True\n    tags:\n      - section4\n      - section4.1\n      - section4.1.4\n\n  - name: 4.2 Enable XD/NX Support on 32-bit x86 Systems (read dmesg) (Not Scored)\n    shell: 'dmesg | grep NX'\n    register: nx_result\n    failed_when: nx_result.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section4\n      - section4.2\n\n  - name: 4.3 Enable Randomized Virtual Memory Region Placement (Scored)\n    sysctl: >\n       name=kernel.randomize_va_space\n       value=2\n       state=present\n    tags:\n      - section4\n      - section4.3\n\n  - name: 4.4 Disable Prelink (check) (Scored)\n    stat: path=/usr/bin/prelink\n    register: prelink_rc\n    tags:\n      - section4\n      - section4.4\n\n  - name: 4.4 Disable Prelink (restore) (Scored)\n    command: '/usr/bin/prelink -ua'\n    when: prelink_rc.stat.exists == True\n    tags:\n      - section4\n      - section4.4\n\n  - name: 4.4 Disable Prelink (remove) (Scored)\n    apt: purge=yes name='prelink' state=absent\n    when: prelink_rc.stat.exists == True\n    tags:\n      - section4\n      - section4.4\n"}, {"commit_sha": "dc73f16743fa376672b427980c6ca044dd6fa68a", "sha": "91b044bcee8d25e94d8bb74dfb29db0dbb6c87e0", "filename": "tasks/rpm_prepare.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Setup RPM specific variables (set_fact)\n  set_fact:\n    tor_user: toranon\n    tor_ConfDir: /etc/tor\n    tor_RunAsDaemon: 0\n    tor_DataDir: /var/lib/tor-instances\n  tags:\n   - reconfigure\n   - renewkey\n\n- name: Ensure EPEL repo is installed (yum)\n  become: yes\n  yum:\n    name: epel-release\n  when: ansible_pkg_mgr == 'yum'\n\n- name: Ensure SELinux dependencies are installed\n  become: yes\n  package:\n    name: libselinux-python,libsemanage-python\n    state: present\n  notify: re-gather facts\n\n# re-gathering facts after installing libselinux-python\n# is a workaround for https://github.com/ansible/ansible-modules-core/issues/2432\n- meta: flush_handlers\n\n- name: Ensure SELinux boolean (tor_can_network_relay) is set appropriately (Fedora)\n  become: yes\n  seboolean:\n    name: tor_can_network_relay\n    state: yes\n    persistent: yes\n  when: ansible_selinux.status == 'enabled'\n\n- name: Ensure systemd drop-in folder is present (RPM)\n  become: yes\n  file:\n    path: /etc/systemd/system/tor@.service.d\n    state: directory\n    owner: root\n    mode: 0755\n\n# this is needed for a small service file modification (allow it to write to /var/lib/tor-instances)\n# without replacing the maintainer's file, for details see\n# http://www.freedesktop.org/software/systemd/man/systemd.unit.html#id-1.11.3\n- name: Ensure service file drop-in is present (RPM)\n  become: yes\n  copy:\n    src: local.conf\n    dest: /etc/systemd/system/tor@.service.d/local.conf\n    owner: root\n    mode: 0644\n  notify: systemctl daemon-reload\n\n- meta: flush_handlers\n"}, {"commit_sha": "067d6cbb20adb31a1e2bd9f689b5b6e259c30288", "sha": "4bbaf74e0dfca0864005485ed5fa66027276a966", "filename": "tasks/section_09_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 9.1.1.1 Check that cron conf file exists (check) (Scored)\n    stat: path=/etc/init/cron.conf\n    register: cron_conf_stat\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.1\n\n  - name: 9.1.1.2 Enable cron Daemon (Scored)\n    service: >\n        name=cron\n        state=started\n        enabled=yes\n    when: not cron_conf_stat.stat.exists\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.2\n\n  - name: 9.1.2 Set User/Group Owner and Permission on /etc/crontab (Scored)\n    file: path='/etc/crontab' owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.2\n\n  - name: 9.1.3 Set User/Group Owner and Permission on /etc/cron.hourly (Scored)\n    file: path=/etc/cron.hourly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.3\n\n  - name: 9.1.4 Set User/Group Owner and Permission on /etc/cron.daily (Scored)\n    file: path=/etc/cron.daily owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.4\n\n  - name: 9.1.5 Set User/Group Owner and Permission on /etc/cron.weekly(Scored)\n    file: path=/etc/cron.weekly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.5\n\n  - name: 9.1.6 Set User/Group Owner and Permission on /etc/cron.monthly(Scored)\n    file: path=/etc/cron.monthly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.6\n\n  - name: 9.1.7 Set User/Group Owner and Permission on /etc/cron.d (Scored)\n    file: path=/etc/cron.d owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.7\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (Scored)\n    file: path={{ item }} state=absent\n    with_items:\n        - /etc/cron.deny\n        - /etc/at.deny\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n  \n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    stat: path=/etc/cron.allow\n    register: cron_allow_path\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    shell: touch /etc/cron.allow\n    when: cron_allow_path.stat.exists == False\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (Scored)\n    file: path=/etc/cron.allow owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    stat: path=/etc/at.allow\n    register: at_allow_path\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    shell: touch /etc/at.allow\n    when: at_allow_path.stat.exists == False\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (Scored)\n    file: path=/etc/at.allow owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n \n  - name: 9.2.1 Set Password Creation Requirement Parameters Using pam_cracklib (install) (Scored)\n    apt: name=libpam-cracklib state=present\n    when: use_pam_cracklib == True\n    tags:\n      - section9\n      - section9.2\n      - section9.2.1\n      \n  - name: 9.2.1 Set Password Creation Requirement Parameters Using pam_cracklib (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password'\n        regexp=\"pam_cracklib.so\"\n        line=\"password required pam_cracklib.so retry=3 minlen=14 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1\"\n        state=present\n    when: use_pam_cracklib == True\n    tags:\n      - section9\n      - section9.2\n      - section9.2.1\n\n#Note for section 9.2.2:\n#If a user has been locked out because they have reached the maximum consecutive failure count \n#defined by denied= in the pam_tally2.so module, the user can be unlocked by issuing the command\n#/sbin/pam_tally2 -u username --reset\n#This command sets the failed count to 0, effectively unlocking the user\n  - name: 9.2.2 Set Lockout for Failed Password Attempts (Not Scored)\n    lineinfile: >\n        dest='/etc/pam.d/login' \n        regexp='pam_tally2'\n        line=\"auth required pam_tally2.so onerr=fail audit silent deny=5 unlock_time=900\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.2\n\n  - name: 9.2.3 Limit Password Reuse (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password' \n        regexp='remember=5'\n        line=\"password sufficient pam_unix.so remember=5\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.3\n\n  - name: 9.3 Check if ssh is installed (check)\n    stat: path='/etc/ssh/sshd_config'\n    register: ssh_config_file\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n\n  - name: 9.3.1 Set SSH Protocol to 2 (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config' \n        regexp='^Protocol'\n        state=present\n        line='Protocol 2'\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n  - name: 9.3.2 Set LogLevel to INFO (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config' \n        regexp='^LogLevel'\n        state=present\n        line='LogLevel INFO'\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.2\n\n  - name: 9.3.3 Set Permissions on /etc/ssh/sshd_config (Scored)\n    file: path='/etc/ssh/sshd_config' owner=root group=root mode=600\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.3\n\n#Regroups sections 9.3.4 9.3.7 9.3.8 9.3.9 9.3.10\n  - name: 9.3.{4,7,8,9,10} Disable some SSH options (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^{{ item }}'\n        line='{{ item }} no'\n        state=present\n    with_items: \n      - X11Forwarding\n      - HostbasedAuthentication\n      - PermitRootLogin\n      - PermitEmptyPasswords\n      - PermitUserEnvironment\n    tags:\n      - section9\n      - section9.3\n      - section9.3.4\n      - section9.3.7\n      - section9.3.8\n      - section9.3.9\n      - section9.3.10\n\n  - name: 9.3.5 Set SSH MaxAuthTries to 4 or Less (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^MaxAuthTries'\n        line='MaxAuthTries 4'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.5\n\n  - name: 9.3.6 Set SSH IgnoreRhosts to Yes (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^IgnoreRhosts'\n        line='IgnoreRhosts yes'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.6\n\n  - name: 9.3.11 Use Only Approved Cipher in Counter Mode (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Ciphers'\n        line='Ciphers aes128-ctr,aes192-ctr,aes256-ctr'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.11\n\n  - name: 9.3.12.1 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveInterval'\n        line='ClientAliveInterval 300'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.1\n\n  - name: 9.3.12.2 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveCountMax'\n        line='ClientAliveCountMax 0'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.2\n\n  - name: 9.3.13.1 Limit Access via SSH (Scored)\n    shell: grep AllowUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.1\n\n  - name: 9.3.13.2 Limit Access via SSH (Scored)\n    shell: grep AllowGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.2\n\n  - name: 9.3.13.3 Limit Access via SSH (Scored)\n    shell: grep DenyUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.3\n\n  - name: 9.3.13.4 Limit Access via SSH (Scored)\n    shell: grep DenyGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.4\n\n  - name: 9.3.14 Set SSH Banner (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Banner'\n        line='Banner /etc/issue.net'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.14\n\n  - name: 9.4 Restrict root Login to System Console (Not Scored)\n    stat: path=/etc/securetty\n    register: securetty_file\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.4 Restrict root Login to System Console (Not Scored)\n    debug: msg='*** Check /etc/securetty for console allowed for root access ***'\n    when: securetty_file.stat.exists == True\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.5.1 Restrict Access to the su Command (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/su'\n        line='auth            required        pam_wheel.so use_uid'\n        state=present\n    tags:\n      - section9\n      - section9.5\n      - section9.5.1\n"}, {"commit_sha": "dc73f16743fa376672b427980c6ca044dd6fa68a", "sha": "5794ee3a8fa1f0b29fc49258c53842057b561b84", "filename": "tasks/apt_prepare.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Setup Debian specific variables (set_fact)\n  set_fact:\n    tor_user: debian-tor\n    tor_DataDir: /var/lib/tor-instances\n    tor_ConfDir: /etc/tor/instances\n    tor_RunAsDaemon: 0\n    tor_packages:\n        - deb.torproject.org-keyring\n        - tor\n  tags:\n   - reconfigure\n   - renewkey\n\n- name: Ensure torproject gpg key is installed (A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89)\n  become: yes\n  apt_key:\n    data: \"{{ lookup('file', 'deb.torproject.org_A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89.pub') }}\"\n    id: A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89\n    state: present\n\n- name: Ensure torproject.org repository is present (APT)\n  become: yes\n  apt_repository:\n    repo: 'deb http://deb.torproject.org/torproject.org {{ tor_distribution_release }} main'\n    state: present\n    update_cache: yes\n\n# Background:\n# https://github.com/nusenu/ansible-relayor/issues/72\n- name: Ensure systemd generator folder exists (Debian Testing and Ubuntu)\n  become: yes\n  file:\n    path: /etc/systemd/system-generators\n    state: directory\n    mode: 0755\n  when: ansible_lsb.codename != 'jessie'\n\n- name: Ensure custom systemd generator is in place (Debian/Ubuntu only)\n  become: yes\n  copy:\n    src: tor-generator\n    dest: \"{{ (ansible_lsb.codename == 'jessie')|ternary('/lib/systemd/system-generators/relayor-generator', '/etc/systemd/system-generators/tor-generator') }}\"\n    owner: root\n    mode: 0755\n\n- name: Ensure the maintainer's generator is disabled (Debian 8 only)\n  become: yes\n  command: dpkg-statoverride --update --add root root 644 /lib/systemd/system-generators/tor-generator\n  when: ansible_lsb.codename == 'jessie'\n  ignore_errors: yes\n\n#- name: Ensure AppArmor allows access to necessary files (Ubuntu)\n#  become: yes\n#  lineinfile: dest=/etc/apparmor.d/local/system_tor line={{ item }}\n#  with_items:\n#    - '/etc/tor/enabled/*\\ r,'\n#    - '/{,var/}run/tor/*.pid\\ w,'\n#    - '/var/lib/tor/**\\ w,'\n#  when: ansible_distribution == 'Ubuntu'\n#  notify: restart apparmor\n\n#- meta: flush_handlers\n"}, {"commit_sha": "f565940c5163524c7834123625c804e5f69c2b10", "sha": "cebc80ceddc5a368ea4c693bcfe863330ce48a06", "filename": "tasks/common.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/common.yml: Deploy configurations common to client and server for Sensu\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure the Sensu config directory is present\n    file:\n      dest: \"{{ sensu_config_path }}/conf.d\"\n      state: directory\n      recurse: true\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n\n  - name: Deploy Sensu Redis configuration\n    template:\n      dest: \"{{ sensu_config_path }}/conf.d/redis.json\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      src: sensu-redis.json.j2\n    notify:\n      - restart sensu-server service\n      - restart sensu-api service\n      - restart sensu-client service\n\n  - name: Deploy Sensu RabbitMQ configuration\n    template:\n      dest: \"{{ sensu_config_path }}/conf.d/rabbitmq.json\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      src: \"{{ sensu_rabbitmq_config }}\"\n    when: sensu_transport == \"rabbitmq\"\n    notify:\n      - restart sensu-server service\n      - restart sensu-api service\n      - restart sensu-client service\n\n  - name: Deploy Sensu transport configuration\n    template:\n      dest: \"{{ sensu_config_path }}/conf.d/transport.json\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      src: transport.json.j2\n    notify:\n      - restart sensu-server service\n      - restart sensu-api service\n      - restart sensu-client service\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "7d42c167ba603d2f24ca98e7f390151812aca4a9", "filename": "tasks/SmartOS/dashboard.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/SmartOS/dashboard.yml: Deployment of the Uchiwa dashboard\n# Specific to Joyent SmartOS\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure Uchiwa (dashboard) dependencies are installed\n    pkgin: name=go state=present\n\n  - name: Ensure Uchiwa directory exists\n    file:\n      dest: \"{{ uchiwa_path }}\"\n      state: directory\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      recurse: true\n\n  - name: Ensure Uchiwa Go/config directory exists\n    file:\n      dest: \"{{ uchiwa_path }}/{{ item }}\"\n      state: directory\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      recurse: true\n    with_items:\n      - etc\n      - go\n\n  - name: Ensure Uchiwa GOPATH exists\n    file:\n      dest: \"{{ uchiwa_path }}/go/{{ item }}\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      state: directory\n      recurse: true\n    with_items:\n      - bin\n      - pkg\n      - src\n\n  - name: Fetch Uchiwa from GitHub\n    command: go get github.com/sensu/uchiwa\n    environment:\n      GOPATH: \"{{ uchiwa_path }}/go\"\n    args:\n      creates: \"{{ uchiwa_path }}/go/src/github.com/sensu/uchiwa\"\n    notify: Build and deploy Uchiwa\n    become: true\n    become_user: \"{{ sensu_user_name }}\"\n\n  - meta: flush_handlers\n\n  - name: Deploy Uchiwa config\n    template:\n      src: uchiwa_config.json.j2\n      dest: \"{{ uchiwa_path }}/etc/config.json\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    notify: restart uchiwa service\n\n  - name: Deploy Uchiwa service script\n    template:\n      src: uchiwa.sh.j2\n      dest: /opt/local/lib/svc/method/uchiwa\n      owner: root\n      group: root\n      mode: 0755\n    notify: restart uchiwa service\n\n  - name: Deploy Uchiwa service manifest\n    template:\n      dest: /opt/local/lib/svc/manifest/uchiwa.xml\n      src: uchiwa.smartos_smf_manifest.xml.j2\n      owner: root\n      group: root\n      mode: 644\n    notify: import uchiwa service\n\n  - meta: flush_handlers\n\n  - name: Ensure Uchiwa server service is running\n    service: name=uchiwa state=started enabled=yes\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "581b9df2fc73d4980a15b8a7f423020925131553", "filename": "tasks/section_01_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 1.1.1 Install Updates, Patches and Additional Security Software (Not Scored)\n    apt: update_cache=yes cache_valid_time={{apt_cache_valid_time}}\n    tags:\n      - section1\n      - section1.1\n      - section1.1.1\n\n  - name: 1.1.2 Install Updates, Patches and Additional Security Software (Not Scored)\n    apt: upgrade=yes\n    when: apt_upgrade == True\n    tags:\n      - section1\n      - section1.1\n      - section1.1.2\n"}, {"commit_sha": "584d564218d6e2e63d3ecca157daf817fe4d533c", "sha": "1dd640e5461a1736062757ae8e75bd7b609443b7", "filename": "tasks/main.yml", "repository": "mikolak-net/ansible-raspi-config", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n- name: update all packages\n  apt: update_cache=yes upgrade=dist\n  when: raspi_config_update_packages\n- include: setup_replace_user.yml\n  when: raspi_config_replace_user[\"name\"] != ''\n- include: security_check.yml\n- name: ensure filesystem is resized\n  expand_fs:\n  when: raspi_config_expanded_filesystem\n- name: ensure mem split\n  pi_boot_config: config_vals=gpu_mem={{raspi_config_memory_split_gpu}}\n  notify:\n    - apply raspi-config\n    - reboot\n- name: ensure correct CPU parameters for Pi2\n  ensure_pi2_oc:\n  args:\n    cpu_types: \"{{raspi_config_pi_cpu}}\"\n  when: raspi_config_ensure_optimal_cpu_params\n  notify:\n    - apply raspi-config\n    - reboot\n- name: set camera state\n  include: camera.yml\n- name: set additional config vars\n  pi_boot_config:\n  args:\n    config_vals: \"{{raspi_config_other_options}}\"\n  notify:\n    - apply raspi-config\n    - reboot"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "afc4963f862038c519b93093521ec0c46606ba5d", "filename": "roles/mesos_maintenance/meta/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Alberto Garc\u00eda Lamela <alberto.garcial@hotmail.com>\n  description:\n  company: your company (optional)\n  # If the issue tracker for your role is not on github, uncomment the\n  # next line and provide a value\n  # issue_tracker_url: http://example.com/issue/tracker\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (GPLv2, CC-BY, etc)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  #platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Solaris\n  #  versions:\n  #  - all\n  #  - 10\n  #  - 11.0\n  #  - 11.1\n  #  - 11.2\n  #  - 11.3\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #  - 21\n  #  - 22\n  #  - 23\n  #- name: Windows\n  #  versions:\n  #  - all\n  #  - 2012R2\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 10.0\n  #  - 10.1\n  #  - 10.2\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  #  - 9.3\n  #- name: Ubuntu\n  #  versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n  #  - trusty\n  #  - utopic\n  #  - vivid\n  #  - wily\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - jessie\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  #categories:\n  #- cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  #- system\n  #- web\ndependencies: []\n  # List your role dependencies here, one per line.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "c33cf5e599f4b6371001bc660476ac0abb44b7c0", "filename": "roles/mesos_maintenance/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for mesos-maintenance\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "1bdc6712d3e0a3c455be733dced394110d5b2a85", "filename": "roles/docker/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for docker\n- name: restart docker\n  sudo: yes\n  service:\n   name: docker\n   state: restarted\n"}, {"commit_sha": "12d2d30c292e5749809cd7476458762a4de31554", "sha": "94bfba2ab93b886ed15dbd4f43a97dc036c0e725", "filename": "tasks/apt_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Setup Debian specific variables (set_fact)\n  set_fact:\n    tor_user: debian-tor\n  tags: configure\n\n- name: Ensure torproject gpg key is installed (A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89)\n  sudo: yes\n  apt_key: data=\"{{ lookup('file', 'deb.torproject.org_A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89.pub') }}\"\n    id=A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89\n    state=present\n\n- name: Ensure torproject.org repository is present (APT)\n  sudo: yes\n  apt_repository: repo='deb http://deb.torproject.org/torproject.org {{ tor_distribution_release }} main'\n    state=present \n    update_cache=yes\n\n# waiting for trac ticket #14997\n#- name: Ensure  torproject.org alpha repo is present (if enabled)\n#  apt_repository: >\n#    repo='deb http://deb.torproject.org/torproject.org  main'\n#    state=present \n#    update_cache=yes\n#  when: tor_alpha is True\n\n# we specifically opt for present over latest to improve performance\n# \"latest\" is covered by auto updates\n- name: Ensure Tor is installed (APT)\n  sudo: yes\n  apt: pkg=\"{{ item }}\" state=present\n  with_items: \n    - deb.torproject.org-keyring\n    - tor\n  # apt starts a tor client instance by default after installing the package\n  # we do not need that\n  notify:\n    - stop tor\n    - disable-sysv-debian tor\n\n- name: Ensure the presence of the multi-instance systemd unit file (Debian)\n  sudo: yes\n  template: src=debian_tor@.service dest=/lib/systemd/system/tor@.service owner=root mode=0644 backup=yes\n  when: ansible_distribution == 'Debian'\n  notify: systemctl daemon-reload\n\n- name: Ensure the presence of the multi-instance systemd unit file (Ubuntu)\n  sudo: yes\n  copy: src=ubuntu_tor@.service dest=/lib/systemd/system/tor@.service owner=root mode=0644 backup=yes\n  when: ansible_distribution == 'Ubuntu'\n  notify: systemctl daemon-reload\n\n- name: Ensure AppArmor allows access to necessary files (Ubuntu)\n  sudo: yes\n  lineinfile: dest=/etc/apparmor.d/local/system_tor line={{ item }}\n  with_items:\n    - '/etc/tor/enabled/*\\ r,'\n    - '/{,var/}run/tor/*.pid\\ w,'\n    - '/var/lib/tor/**\\ w,'\n  when: ansible_distribution == 'Ubuntu'\n  notify: restart apparmor\n\n- meta: flush_handlers\n"}, {"commit_sha": "1bb50a6149f6ff7f2e6399411418d088e2c52d01", "sha": "5a8bc0e6118f5e8b5177cbf68b6c95deb7d20137", "filename": "tasks/section_08_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n#  - name: 8.2 Configure rsyslog\n#  The rsyslog software is recommended as a replacement for the default syslogd daemon and\n#  provides improvements over syslogd, such as connection-oriented (i.e. TCP) transmission\n#  of logs, the option to log to database formats, and the encryption of log data en route to a\n#  central logging server.\n#  tags:\n#    - section8\n#    - section8.2\n\n\n  - name: 8.2.1 Install the rsyslog package (Scored)\n    apt: name=rsyslog state=present\n    tags:\n      - section8\n      - section8.2\n      - section8.2.1\n\n  - name: 8.2.2 Ensure the rsyslog Service is activated (Scored)\n    command: grep 'start on filesystem' /etc/rsyslog.conf\n    register: startonfilesystem\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.5.2 Configure rsyslog to Send Logs to a Remote Log Host (start rsyslog) (Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line='start on filesystem'\n       insertafter=EOF\n       state=present\n    when: startonfilesystem.rc == 1\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.3 Configure /etc/rsyslog.conf (Not Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line=\"{{ item }}\"\n       insertafter=EOF\n    with_items:\n      - '*.emerg :omusrmsg:*'\n      - 'mail.* -/var/log/mail'\n      - 'mail.info -/var/log/mail.info'\n      - 'mail.warning -/var/log/mail.warn'\n      - 'mail.err /var/log/mail.err'\n      - 'news.crit -/var/log/news/news.crit'\n      - 'news.err -/var/log/news/news.err'\n      - 'news.notice -/var/log/news/news.notice'\n      - '*.=warning;*.=err -/var/log/warn'\n      - '*.crit /var/log/warn'\n      - '*.*;mail.none;news.none -/var/log/messages'\n      - 'local0,local1.* -/var/log/localmessages'\n      - 'local2,local3.* -/var/log/localmessages'\n      - 'local4,local5.* -/var/log/localmessages'\n      - 'local6,local7.* -/var/log/localmessages'\n    changed_when: False\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.3\n\n  - name: 8.2.4.1 Create and Set Permissions on rsyslog Log Files (Scored)\n    shell: awk '{ print $NF }' /etc/rsyslog.d/* /etc/rsyslog.conf | grep /var/log | sed 's/^-//' | sed 's/)$//' \n    register: result\n    changed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.4.2 Create and Set Permissions on rsyslog Log Files (Scored)\n    shell: 'mkdir -p -- \"$(dirname -- {{ item }})\"; touch -- {{ item }}' \n    with_items: result.stdout_lines          \n    changed_when: False\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.4.3 Create and Set Permissions on rsyslog Log Files (Scored)\n    file: >\n        path='{{item}}' \n        owner=root \n        group=root \n        mode=\"og-rwx\" \n    with_items: result.stdout_lines\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.5.1 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    command: grep \"^*.*[^I][^I]*@\" /etc/rsyslog.conf\n    register: remoteloghost \n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.5.2 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line=\"*.* @@{{remote_logs_host_address}}\"\n       insertafter=EOF\n       state=present\n    when: set_rsyslog_remote == True and remoteloghost.rc == 1\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.6.1 Accept Remote rsyslog Messages Only on Designated Log Hosts (Not Scored)\n    command: grep '^$ModLoad imtcp' /etc/rsyslog.conf\n    register: moadloadpresent\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.6\n\n  - name: 8.2.6.2 Accept Remote rsyslog Messages Only on Designated Log Hosts (Not Scored)\n    lineinfile: >\n        dest=/etc/rsyslog.conf\n        regexp='^#({{ item }})'\n        line='{{ item }}'\n        state=present\n    with_items:\n        - '$ModLoad imtcp'\n        - '$InputTCPServerRun 514'\n    when: set_rsyslog_remote == True and moadloadpresent.rc == 1\n    changed_when: False\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.6\n"}, {"commit_sha": "9ad67b6ef151d5fbaa05230e6cecb4bed1db7d9d", "sha": "7e5e505661a5357db1dae855ef1fdb3bfe181740", "filename": "tasks/section_02_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: Check the presence of the file \"cis.conf\" under modprobe.d\n    stat: >\n        path=/etc/modprobe.d/CIS.conf\n    register: cis_conf_file\n    tags:\n      - section2\n      - section2.18\n\n  - name: Create the file \"cis.conf\" under modprobe.d if doesn't exist\n    file: >\n        dest=/etc/modprobe.d/CIS.conf state=touch\n    when: not cis_conf_file.stat.exists\n    tags:\n      - section2\n      - section2.18\n\n  - name: 2.18 Disable Mounting of cramfs Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install cramfs /bin/true'\n        state=present\n    tags:\n      - section2\n      - section2.18\n\n  - name: 2.19 Disable Mounting of freevxfs Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install freevxfs /bin/true'\n        state=present\n    tags:\n      - section2\n      - section2.19\n\n  - name: 2.20 Disable Mounting of jffs2 Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install jffs2 /bin/true'\n        state=present\n    tags:\n      - section2\n      - section2.20\n\n  - name: 2.21 Disable Mounting of hfs Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install hfs /bin/true'\n        state=present\n    tags:\n      - section2\n      - section2.21\n\n  - name: 2.22 Disable Mounting of hfsplus Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install hfsplus /bin/true'\n        state=present\n    tags:\n      - section2\n      - section2.22\n\n  - name: 2.23 Disable Mounting of squashfs Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install squashfs /bin/true'\n        state=present\n    tags:\n      - section2\n      - section2.23\n\n  - name: 2.24 Disable Mounting of udf Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install udf /bin/true'\n        state=present\n    tags:\n      - section2\n      - section2.24\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "3f2f545e8641ff37bac88d65c203197007755b2a", "filename": "tasks/Debian/main.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/Debian/main.yml: Debian specific set-up\n# This takes care of base prerequisites for Debian\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure the Sensu APT repo GPG key is present\n    apt_key:\n      url: https://sensu.global.ssl.fastly.net/apt/pubkey.gpg\n      state: present\n\n  - name: Ensure the Sensu Core APT repo is present\n    apt_repository:\n      repo: \"deb     https://sensu.global.ssl.fastly.net/apt {{ ansible_distribution_release }} main\"\n      state: present\n      update_cache: true\n\n  - name: Ensure Sensu is installed\n    apt: name={{ sensu_package }} state={{ sensu_pkg_state }}\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "5e7ecfe115bbb33929889b2225ec14a333098c9c", "filename": "roles/cadvisor/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "# tasks for running cadvisor\n- name: deploy cadvisor service\n  become: yes\n  become_user: root\n  template:\n    src: cadvisor.service.j2\n    dest: /etc/systemd/system/cadvisor.service\n  notify:\n    - reload systemd\n    - restart cadvisor\n  tags:\n    - cadvisor\n\n# Attach to the running container, or start it if needed\n# and forward all signals so that the process manager can detect\n# when a container stops and correctly restart it.\n- name: ensure cadvisor is running (and enable it at boot)\n  become: yes\n  service:\n    name: cadvisor\n    state: started\n    enabled: yes\n  tags:\n    - cadvisor\n\n- name: get cadvisor container ip\n  become: yes\n  command: >\n    docker inspect -f \\{\\{' '.NetworkSettings.IPAddress' '\\}\\} cadvisor\n  register: cadvisor_container_ip\n  tags:\n    - cadvisor\n\n- name: Set cadvisor consul service definition\n  become: yes\n  template:\n    src: cadvisor-consul.j2\n    dest: \"{{ cadvisor_consul_dir }}/cadvisor.json\"\n  notify:\n    - restart consul\n  tags:\n    - cadvisor\n"}, {"commit_sha": "af3dfdf7cf37437f5609f1a12e4ac7cbaebd4867", "sha": "e55d80da5c0e27f1e4a7dbaeeefe1f134d77f21b", "filename": "roles/mesos/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for mesos\nmesos_zk_port: 2181\nmesos_zookeeper_group: zookeeper_servers\nmesos_master_port: 5050\nconsul_dir: /etc/consul.d\nmesos_executor_registration_timeout: 10mins\nmesos_cluster_name: \"Cluster01\"\nmesos_containerizers: \"docker,mesos\"\nmesos_resources: \"ports(*):[31000-32000]\"\nmesos_slave_work_dir: \"/tmp/mesos\"\nmesos_ip: \"{{ ansible_default_ipv4.address }}\"\nmesos_hostname: \"{{ ansible_ssh_host }}\"\n"}, {"commit_sha": "32211ebd2a9f45112f8dceda80bc95d0db029fb4", "sha": "1612e24a60a6865ea84c8dc17c90079a9617547b", "filename": "tasks/linux_service.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n# Linux/systemd section (uses service module)\n# ===========================================\n\n- name: Ensure systemd drop-in folder is present\n  become: yes\n  file: path=/etc/systemd/system/tor@.service.d\n    state=directory\n    owner=root\n    mode=0755\n  when: ansible_os_family == 'RedHat'\n\n# this is needed for a small service file modification (allow it to write to /var/lib/tor-instances)\n# # without replacing the maintainer's file, for details see\n# # http://www.freedesktop.org/software/systemd/man/systemd.unit.html#id-1.11.3\n- name: Ensure service file drop-in is present\n  become: yes\n  copy: src=local.conf\n   dest=/etc/systemd/system/tor@.service.d/local.conf\n   owner=root\n   mode=640\n  when: ansible_os_family == 'RedHat'\n  notify: systemctl daemon-reload\n\n- meta: flush_handlers\n \n- name: Ensure Tor instances are reloaded if its torrc changed (Linux/systemd)\n  become: yes\n  service: name=tor@{{ item.item.0.ipv4 }}_{{ item.item.1.orport }}.service state=reloaded\n  with_items: \"{{ instances.results }}\"\n  when: item.changed == True\n  tags:\n   - reconfigure\n\n- name: Ensure Tor instances are enabled and started (Linux/systemd)\n  become: yes\n  service: name=tor@{{ item.0.ipv4 }}_{{ item.1.orport }}.service enabled=yes state=started\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n"}, {"commit_sha": "e8eb28b4b4b1c4fb2490b8198570166b9ca23ab2", "sha": "e3c052d398c2d79b3cc848c87dacdbd94824507e", "filename": "roles/mysql/handlers/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "- name: restart mysql\n  sudo: true\n  service:\n    name: mysql\n    state: restarted\n"}, {"commit_sha": "7a3aa0de9bf76ff1b18e6da304031150e4550142", "sha": "b375687b711425020707141895930fc8cd7431d3", "filename": "tasks/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- include: apt_install.yml\n  when: ansible_pkg_mgr == 'apt'\n\n- include: yum_install.yml\n  when: ansible_pkg_mgr == 'yum'\n\n- include: openbsd_install.yml\n  when: ansible_pkg_mgr == 'openbsd_pkg'\n\n- include: freebsd_install.yml\n  when: ansible_pkg_mgr == 'pkgng'\n\n- include: configure.yml\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "fe029596904171da395f4a84c222e8e532480fe0", "filename": "tasks/section_09_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 9.1.1.1 Check that cron conf file exists (check) (Scored)\n    stat: path=/etc/init/cron.conf\n    register: cron_conf_stat\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.1\n\n  - name: 9.1.1.2 Enable cron Daemon (Scored)\n    service: >\n        name=cron\n        state=started\n        enabled=yes\n    when: not cron_conf_stat.stat.exists\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.2\n\n  - name: 9.1.2 Set User/Group Owner and Permission on /etc/crontab (Scored)\n    file: path='/etc/crontab' owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.2\n\n  - name: 9.1.3 Set User/Group Owner and Permission on /etc/cron.hourly (Scored)\n    file: path=/etc/cron.hourly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.3\n\n  - name: 9.1.4 Set User/Group Owner and Permission on /etc/cron.daily (Scored)\n    file: path=/etc/cron.daily owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.4\n\n  - name: 9.1.5 Set User/Group Owner and Permission on /etc/cron.weekly (Scored)\n    file: path=/etc/cron.weekly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.5\n\n  - name: 9.1.6 Set User/Group Owner and Permission on /etc/cron.monthly (Scored)\n    file: path=/etc/cron.monthly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.6\n\n  - name: 9.1.7 Set User/Group Owner and Permission on /etc/cron.d (Scored)\n    file: path=/etc/cron.d owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.7\n\n  - name: 9.1.8.1 Restrict at/cron to Authorized Users (remove deny) (Scored)\n    file: path={{ item }} state=absent\n    with_items:\n        - /etc/cron.deny\n        - /etc/at.deny\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8.2 Restrict at/cron to Authorized Users (create cron allow) (Scored)\n    copy:\n        dest: /etc/cron.allow\n        owner: root\n        group: root\n        mode: \"og-rwx\"\n        content: \"\"\n        force: no\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8.3 Restrict at/cron to Authorized Users (create at allow) (Scored)\n    copy:\n        dest: /etc/at.allow\n        owner: root\n        group: root\n        mode: \"og-rwx\"\n        content: \"\"\n        force: no\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.2.1.1 Set Password Creation Requirement Parameters Using pam_cracklib (install) (Scored)\n    apt: name=libpam-cracklib state=present\n    when: use_pam_cracklib == True\n    tags:\n      - section9\n      - section9.2\n      - section9.2.1\n\n  - name: 9.2.1.2 Set Password Creation Requirement Parameters Using pam_cracklib (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password'\n        regexp=\"pam_cracklib.so\"\n        line=\"password required pam_cracklib.so retry=3 minlen=14 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1\"\n        state=present\n    when: use_pam_cracklib == True\n    tags:\n      - section9\n      - section9.2\n      - section9.2.1\n\n#Note for section 9.2.2:\n#If a user has been locked out because they have reached the maximum consecutive failure count\n#defined by denied= in the pam_tally2.so module, the user can be unlocked by issuing the command\n#/sbin/pam_tally2 -u username --reset\n#This command sets the failed count to 0, effectively unlocking the user\n  - name: 9.2.2 Set Lockout for Failed Password Attempts (Not Scored)\n    lineinfile: >\n        dest='/etc/pam.d/login'\n        regexp='pam_tally2'\n        line=\"auth required pam_tally2.so onerr=fail audit silent deny=5 unlock_time=900\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.2\n\n  - name: 9.2.3 Limit Password Reuse (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password'\n        regexp='remember=5'\n        line=\"password sufficient pam_unix.so remember=5\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.3\n\n  - name: 9.3 Check if ssh is installed (check) (Not Scored)\n    stat: path='/etc/ssh/sshd_config'\n    register: ssh_config_file\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n  - include: section_09_level1_03.yml\n    when: ssh_config_file.stat.exists == True\n\n  - name: 9.4.1 Restrict root Login to System Console (check) (Not Scored)\n    stat: path=/etc/securetty\n    register: securetty_file\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.4.2 Restrict root Login to System Console (Not Scored)\n    debug: msg='*** Check /etc/securetty for console allowed for root access ***'\n    when: securetty_file.stat.exists == True\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.5.1 Restrict Access to the su Command (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/su'\n        line='auth            required        pam_wheel.so use_uid'\n        state=present\n    tags:\n      - section9\n      - section9.5\n      - section9.5.1\n"}, {"commit_sha": "92d2f38d01d7b33610c667cfdc03e28ab2912edc", "sha": "bccd8efc39edda220dcde5ca32f03a06cbade5e2", "filename": "tasks/section_12_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 12.1 Verify Permissions on /etc/passwd (Scored)\n    file: path=/etc/passwd mode=0644\n    tags:\n      - section12\n      - section12.1\n\n  - name: 12.2 Verify Permissions on /etc/shadow (Scored)\n    file: path=/etc/shadow mode='o-rwx,g-rw'\n    tags:\n      - section12\n      - section12.2\n\n  - name: 12.3 Verify Permissions on /etc/group (Scored)\n    file: path=/etc/group mode=0644\n    tags:\n      - section12\n      - section12.3\n\n  - name: 12.4 Verify User/Group Ownership on /etc/passwd (Scored)\n    file: path=/etc/passwd owner=root group=root\n    tags:\n      - section12\n      - section12.4\n\n  - name: 12.5 Verify User/Group Ownership on /etc/shadow (Scored)\n    file: path=/etc/shadow owner=root group=shadow\n    tags:\n      - section12\n      - section12.5\n\n  - name: 12.6 Verify User/Group Ownership on /etc/group (Scored)\n    file: path=/etc/group owner=root group=root\n    tags:\n      - section12\n      - section12.6\n\n  - name: 12.7 Find World Writable Files (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -0002 -print\n    changed_when: False\n    failed_when: False\n    register: world_files\n    tags:\n      - section12\n      - section12.7\n\n  - name: 12.7 Find World Writable Files (Not Scored)\n    debug: msg=\"{{ item }}\"\n    with_items: \"{{world_files.stdout_lines}}\"\n    tags:\n      - section12\n      - section12.7\n\n  - name: 12.8 Find Un-owned Files and Directories (check) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -nouser -ls\n    changed_when: False\n    failed_when: False\n    register: unowned_files\n    tags:\n      - section12\n      - section12.8\n\n  - name: 12.8 Find Un-owned Files and Directories (Scored)\n    debug: msg=\"{{ item }}\"\n    with_items: \"{{unowned_files.stdout_lines}}\"\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.9 Find Un-grouped Files and Directories (check) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -nogroup -ls\n    changed_when: False\n    failed_when: False\n    register: ungrouped_files\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.9 Find Un-grouped Files and Directories (Scored)\n    debug: >\n        msg=\"{{ item }}\"\n    with_items: \"{{ungrouped_files.stdout_lines}}\"\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.10 Find SUID System Executables (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -4000 -print\n    changed_when: False\n    failed_when: False\n    register: suid_files\n    tags:\n      - section12\n      - section12.10\n\n  - name: 12.10 Find SUID System Executables (Not Scored)\n    debug: msg=\"{{ item }}\"\n    with_items: \"{{suid_files.stdout_lines}}\"\n    tags:\n      - section12\n      - section12.10\n\n  - name: 12.11 Find SGID System Executables (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -2000 -print\n    changed_when: False\n    failed_when: False\n    register: gsuid_files\n    tags:\n      - section12\n      - section12.11\n\n  - name: 12.11 Find SGID System Executables (Not Scored)\n    debug: msg=\"{{ item }}\"\n    with_items: \"{{gsuid_files.stdout_lines}}\"\n    tags:\n      - section12\n      - section12.10\n"}, {"commit_sha": "ec4de12ae75f7191a5f71aa775e0344679ea1477", "sha": "14fad3e18b1ae9fd6de0fdd0ae89ca3a59dd72cc", "filename": "tasks/configure.yml", "repository": "UnderGreen/ansible-role-mongodb", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Create keyFile\n  copy:\n    dest: \"{{ mongodb_conf_keyFile }}\"\n    content: \"{{ mongodb_keyfile_content }}\"\n    owner: \"{{ mongodb_user }}\"\n    group: \"root\"\n    mode: 0600\n  when: mongodb_conf_replSet != ''\n\n- name: Configure log rotation\n  template: src=logrotate.conf.j2 dest=/etc/logrotate.d/mongodb.conf\n  when: mongodb_logrotate\n\n- name: ensure mongodb started and enabled\n  service: name={{ mongodb_daemon_name }} state=started enabled=yes\n\n- name: wait MongoDB port is listening\n  wait_for: host=\"{{ mongodb_conf_bind_ip }}\"port=\"{{ mongodb_conf_port }}\" delay=10 timeout=60 state=started\n  #when: systemd.stat.exists == true\n\n- include: auth_initialization.yml\n  when: mongodb_conf_auth\n\n- name: Create mongodb user\n  user: name={{mongodb_user}} group={{mongodb_user}}\n\n- name: Configure database directory\n  file: state=directory path={{ mongodb_conf_dbpath }} owner={{mongodb_user}} group={{mongodb_user}} mode=0755\n\n- name: Configure logs\n  file: state=file path={{ mongodb_conf_logpath }} owner={{mongodb_user}} group={{mongodb_user}} mode=0644\n\n- name: Configure mongodb\n  template: src=mongod.conf.j2 dest=/etc/mongod.conf owner=root group=root mode=0644\n  register: config_result\n\n- name: mongodb restart\n  service: name={{ mongodb_daemon_name }} state=restarted\n  when: config_result|changed\n"}, {"commit_sha": "ec4de12ae75f7191a5f71aa775e0344679ea1477", "sha": "619b33592ce3b6737bf76cf92768bb97a5f4dbaf", "filename": "tasks/replication.yml", "repository": "UnderGreen/ansible-role-mongodb", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Replication configuration\n  mongodb_replication:\n    login_host: \"{{ mongodb_login_host|default('localhost') }}\"\n    login_port: \"{{ mongodb_login_port|default(27017) }}\"\n    login_user: \"{{ mongodb_root_admin_name }}\"\n    login_password: \"{{ mongodb_root_admin_password }}\"\n    replica_set: \"{{ mongodb_conf_replSet }}\"\n    host_name: \"{{ item.host_name }}\"\n    host_port: \"{{ item.host_port|default(27017) }}\"\n    host_type: \"{{ item.host_type|default('replica') }}\"\n  when: mongodb_conf_auth and mongodb_replication_params is defined\n  with_items:\n    - \"{{ mongodb_replication_params }}\"\n\n- name: Replication configuration without auth\n  mongodb_replication:\n    login_host: \"{{ mongodb_login_host|default('localhost') }}\"\n    login_port: \"{{ mongodb_login_port|default(27017) }}\"\n    replica_set: \"{{ mongodb_conf_replSet }}\"\n    host_name: \"{{ item.host_name }}\"\n    host_port: \"{{ item.host_port|default(27017) }}\"\n    host_type: \"{{ item.host_type|default('replica') }}\"\n  when: not mongodb_conf_auth and mongodb_replication_params is defined\n  with_items:\n    - \"{{ mongodb_replication_params }}\"\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "57fb450e1407d1e424ccc1270712634885d834be", "filename": "roles/zookeeper/vars/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# vars file for zookeeper\nzookeeper_leader_port: \"2888\"\nzookeeper_election_port: \"3888\"\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "1b105e22a94c34948fb084ff5dba7536e9be94d1", "filename": "meta/main.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# File: main.yml - Meta main\ngalaxy_info:\n  author: Brian Shumate\n  description: Consul cluster role\n  company: Brian Shumate\n  license: BSD\n  min_ansible_version: 2.5\n\n  platforms:\n    - name: Alpine\n      versions:\n        - all\n    - name: ArchLinux\n      versions:\n        - all\n    - name: EL\n      versions:\n        - 6\n        - 7\n    - name: Fedora\n      versions:\n        - 26\n        - 27\n        - 28\n    - name: FreeBSD\n      versions:\n        - 10.0\n        - 11.0\n    - name: Ubuntu\n      versions:\n        - xenial\n        - bionic\n    - name: Debian\n      versions:\n        - jessie\n        - stretch\n    - name: Windows\n      versions:\n        - 2012R2\n\n  galaxy_tags:\n    - clustering\n    - monitoring\n    - networking\n    - system\n\ndependencies: []\n"}, {"commit_sha": "7f02cba4441b5367d6916857c9b41f3abae915db", "sha": "160803ff60a260cebf3ea11498ed622c8d39d869", "filename": "tasks/rpm_prepare.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Ensure EPEL repo is installed (yum)\n  become: yes\n  yum:\n    name: epel-release\n  when: ansible_pkg_mgr == 'yum'\n\n- name: Ensure SELinux dependencies are installed\n  become: yes\n  package:\n    name: libselinux-python,libsemanage-python\n    state: present\n  notify: re-gather facts\n\n# re-gathering facts after installing ansible SELinux dependencies (libselinux-python)\n- meta: flush_handlers\n\n- name: Ensure SELinux boolean (tor_can_network_relay) is set appropriately\n  become: yes\n  seboolean:\n    name: tor_can_network_relay\n    state: yes\n    persistent: yes\n  when: ansible_selinux.status == 'enabled'\n\n- name: Ensure systemd drop-in folder is present (RPM)\n  become: yes\n  file:\n    path: /etc/systemd/system/tor@.service.d\n    state: directory\n    owner: root\n    mode: 0755\n\n# this is needed for a small service file modification (allow it to write to /var/lib/tor-instances)\n# without replacing the maintainer's file, for details see\n# http://www.freedesktop.org/software/systemd/man/systemd.unit.html#id-1.11.3\n- name: Ensure service file drop-in is present (RPM)\n  become: yes\n  copy:\n    src: local.conf\n    dest: /etc/systemd/system/tor@.service.d/local.conf\n    owner: root\n    mode: 0644\n  notify: systemctl daemon-reload\n\n- meta: flush_handlers\n"}, {"commit_sha": "35ca6852d9333ef6c3ed223239f45b840c487d60", "sha": "78598b03eb7162fd1a7de5161a5ac9a033112eba", "filename": "roles/zookeeper/meta/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Graham Taylor\n  description:\n  company: Capgemini\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (MIT)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: Ubuntu\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n     - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies:\n  - role: consul\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "47e56546d65789b5157a788416793568d70f8e28", "filename": "handlers/start_snapshot.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n- name: start consul snapshot on linux\n  service:\n    name: consul_snapshot\n    state: started\n    enabled: true\n  when: ansible_os_family != \"Windows\"\n  listen: 'start snapshot'\n"}, {"commit_sha": "92d2f38d01d7b33610c667cfdc03e28ab2912edc", "sha": "6075ddacb80cef74ca3806932a89802353021455", "filename": "tasks/section_11_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 11.1.1 Set Warning Banner for Standard Login Services (Scored)\n    lineinfile: >\n        dest={{ item }}\n        create=yes\n        line='Authorized uses only. All activity may be monitored and reported.'\n        state=present\n        mode=644\n        owner=root\n        group=root\n    with_items:\n        - /etc/motd\n        - /etc/issue\n        - /etc/issue.net\n    tags:\n      - section11\n      - section11.1\n\n  - name: 11.2.1 Remove OS Information from Login Warning Banners (Scored)\n    shell: egrep '(\\\\v|\\\\r|\\\\m|\\\\s)' {{ item }}\n    register: egrep_os_infos\n    failed_when: egrep_os_infos.rc == 0\n    changed_when: False\n    with_items:\n        - /etc/motd\n        - /etc/issue\n        - /etc/issue.net\n    tags:\n      - section11\n      - section11.2\n\n  - name: 11.3.1 Set Graphical Warning Banner (Not Scored)\n    debug: msg=\"*** Set a banner for the display manager ***\"\n    tags:\n      - section11\n      - section11.3\n"}, {"commit_sha": "35ca6852d9333ef6c3ed223239f45b840c487d60", "sha": "d0c593cda43c5f488006dae263e8ce20688dbed2", "filename": "roles/marathon/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for marathon\n# Restart service marathon, in all cases\n- name: Restart marathon\n  sudo: yes\n  service:\n    name: marathon\n    state: restarted\n"}, {"commit_sha": "1510f92858b85f9f623690db747bdfff9b5b0515", "sha": "001f3234ed104d5fffb5b7135559e5f848c5c448", "filename": "meta/main.yml", "repository": "dev-sec/ansible-mysql-hardening", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\ngalaxy_info:\n  author: \"Sebastian Gumprich\"\n  description: 'This Ansible playbook provides security configuration for mysql.'\n  company: Hardening Framework Team\n  license: Apache License 2.0\n  min_ansible_version: '1.9'\n  platforms:\n    - name: EL\n      versions:\n        - 6\n        - 7\n    - name: Ubuntu\n      versions:\n        - precise\n        - trusty\n        - xenial\n    - name: Debian\n      versions:\n        - wheezy\n        - jessie\n  galaxy_tags:\n    - system\n    - security\n    - hardening\n    - database\n    - mysql\ndependencies: []\n"}, {"commit_sha": "1818facd0a58a2b42203a403130b71825b960653", "sha": "1b42a49f96b8fea2292faca248f222d1c00b4b65", "filename": "tasks/section_09_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 9.1.1.1 Check that cron conf file exists (check) (Scored)\n    stat: path=/etc/init/cron.conf\n    register: cron_conf_stat\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.1\n\n  - name: 9.1.1.2 Enable cron Daemon (Scored)\n    service: >\n        name=cron\n        state=started\n        enabled=yes\n    when: not cron_conf_stat.stat.exists\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.2\n\n  - name: 9.1.2 Set User/Group Owner and Permission on /etc/crontab (Scored)\n    file: path='/etc/crontab' owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.2\n\n  - name: 9.1.3 Set User/Group Owner and Permission on /etc/cron.hourly (Scored)\n    file: path=/etc/cron.hourly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.3\n\n  - name: 9.1.4 Set User/Group Owner and Permission on /etc/cron.daily (Scored)\n    file: path=/etc/cron.daily owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.4\n\n  - name: 9.1.5 Set User/Group Owner and Permission on /etc/cron.weekly(Scored)\n    file: path=/etc/cron.weekly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.5\n\n  - name: 9.1.6 Set User/Group Owner and Permission on /etc/cron.monthly(Scored)\n    file: path=/etc/cron.monthly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.6\n\n  - name: 9.1.7 Set User/Group Owner and Permission on /etc/cron.d (Scored)\n    file: path=/etc/cron.d owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.7\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (remove deny) (Scored)\n    file: path={{ item }} state=absent\n    with_items:\n        - /etc/cron.deny\n        - /etc/at.deny\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (stat cron allow) (Scored)\n    stat: path=/etc/cron.allow\n    register: cron_allow_path\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation create cron) (Scored)\n    shell: touch /etc/cron.allow\n    when: cron_allow_path.stat.exists == False\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (create cron allow) (Scored)\n    file: path=/etc/cron.allow owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (stat at allow) (Scored)\n    stat: path=/etc/at.allow\n    register: at_allow_path\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation create at) (Scored)\n    shell: touch /etc/at.allow\n    when: at_allow_path.stat.exists == False\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (create at allow) (Scored)\n    file: path=/etc/at.allow owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.2.1 Set Password Creation Requirement Parameters Using pam_cracklib (install) (Scored)\n    apt: name=libpam-cracklib state=present\n    when: use_pam_cracklib == True\n    tags:\n      - section9\n      - section9.2\n      - section9.2.1\n\n  - name: 9.2.1 Set Password Creation Requirement Parameters Using pam_cracklib (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password'\n        regexp=\"pam_cracklib.so\"\n        line=\"password required pam_cracklib.so retry=3 minlen=14 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1\"\n        state=present\n    when: use_pam_cracklib == True\n    tags:\n      - section9\n      - section9.2\n      - section9.2.1\n\n#Note for section 9.2.2:\n#If a user has been locked out because they have reached the maximum consecutive failure count\n#defined by denied= in the pam_tally2.so module, the user can be unlocked by issuing the command\n#/sbin/pam_tally2 -u username --reset\n#This command sets the failed count to 0, effectively unlocking the user\n  - name: 9.2.2 Set Lockout for Failed Password Attempts (Not Scored)\n    lineinfile: >\n        dest='/etc/pam.d/login'\n        regexp='pam_tally2'\n        line=\"auth required pam_tally2.so onerr=fail audit silent deny=5 unlock_time=900\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.2\n\n  - name: 9.2.3 Limit Password Reuse (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password'\n        regexp='remember=5'\n        line=\"password sufficient pam_unix.so remember=5\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.3\n\n  - name: 9.3 Check if ssh is installed (check) (Not Scored)\n    stat: path='/etc/ssh/sshd_config'\n    register: ssh_config_file\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n\n  - name: 9.3.1 Set SSH Protocol to 2 (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Protocol'\n        state=present\n        line='Protocol 2'\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n  - name: 9.3.2 Set LogLevel to INFO (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^LogLevel'\n        state=present\n        line='LogLevel INFO'\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.2\n\n  - name: 9.3.3 Set Permissions on /etc/ssh/sshd_config (Scored)\n    file: path='/etc/ssh/sshd_config' owner=root group=root mode=600\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.3\n\n#Regroups sections 9.3.4 9.3.7 9.3.8 9.3.9 9.3.10\n  - name: 9.3.{4,7,8,9,10} Disable some SSH options (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^{{ item }}'\n        line='{{ item }} no'\n        state=present\n    with_items:\n      - X11Forwarding\n      - HostbasedAuthentication\n      - PermitRootLogin\n      - PermitEmptyPasswords\n      - PermitUserEnvironment\n    tags:\n      - section9\n      - section9.3\n      - section9.3.4\n      - section9.3.7\n      - section9.3.8\n      - section9.3.9\n      - section9.3.10\n\n  - name: 9.3.5 Set SSH MaxAuthTries to 4 or Less (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^MaxAuthTries'\n        line='MaxAuthTries 4'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.5\n\n  - name: 9.3.6 Set SSH IgnoreRhosts to Yes (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^IgnoreRhosts'\n        line='IgnoreRhosts yes'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.6\n\n  - name: 9.3.11 Use Only Approved Cipher in Counter Mode (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Ciphers'\n        line='Ciphers aes128-ctr,aes192-ctr,aes256-ctr'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.11\n\n  - name: 9.3.12.1 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveInterval'\n        line='ClientAliveInterval 300'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.1\n\n  - name: 9.3.12.2 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveCountMax'\n        line='ClientAliveCountMax 0'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.2\n\n  - name: 9.3.13.1 Limit Access via SSH (Scored)\n    shell: grep AllowUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.1\n\n  - name: 9.3.13.2 Limit Access via SSH (Scored)\n    shell: grep AllowGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.2\n\n  - name: 9.3.13.3 Limit Access via SSH (Scored)\n    shell: grep DenyUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.3\n\n  - name: 9.3.13.4 Limit Access via SSH (Scored)\n    shell: grep DenyGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.4\n\n  - name: 9.3.14 Set SSH Banner (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Banner'\n        line='Banner /etc/issue.net'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.14\n\n  - name: 9.4 Restrict root Login to System Console (stat securetty) (Not Scored)\n    stat: path=/etc/securetty\n    register: securetty_file\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.4 Restrict root Login to System Console (Not Scored)\n    debug: msg='*** Check /etc/securetty for console allowed for root access ***'\n    when: securetty_file.stat.exists == True\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.5.1 Restrict Access to the su Command (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/su'\n        line='auth            required        pam_wheel.so use_uid'\n        state=present\n    tags:\n      - section9\n      - section9.5\n      - section9.5.1\n"}, {"commit_sha": "9eb1a8fa8e281ef06687c1851f51fa0beec3e232", "sha": "5db3ab6d07aef9878d52305772f2dcf9af678795", "filename": "tasks/section_12_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 12.1 Verify Permissions on /etc/passwd (Scored)\n    file: path=/etc/passwd mode=0644\n    tags:\n      - section12\n      - section12.1\n\n  - name: 12.2 Verify Permissions on /etc/shadow (Scored)\n    file: path=/etc/shadow mode='o-rwx,g-rw'\n    tags:\n      - section12\n      - section12.2\n\n  - name: 12.3 Verify Permissions on /etc/group (Scored)\n    file: path=/etc/group mode=0644\n    tags:\n      - section12\n      - section12.3\n\n  - name: 12.4 Verify User/Group Ownership on /etc/passwd (Scored)\n    file: path=/etc/passwd owner=root group=root\n    tags:\n      - section12\n      - section12.4\n\n  - name: 12.5 Verify User/Group Ownership on /etc/shadow (Scored)\n    file: path=/etc/shadow owner=root group=shadow\n    tags:\n      - section12\n      - section12.5\n\n  - name: 12.6 Verify User/Group Ownership on /etc/group (Scored)\n    file: path=/etc/group owner=root group=root\n    tags:\n      - section12\n      - section12.6\n\n  - name: 12.7 Find World Writable Files (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -0002 -print\n    changed_when: False\n    failed_when: False\n    register: world_files\n    tags:\n      - section12\n      - section12.7\n\n  - name: 12.7 Find World Writable Files (Not Scored)\n    debug: msg=\"{{ item }}\"\n    with_items:\n        world_files.stdout_lines\n    tags:\n      - section12\n      - section12.7\n\n  - name: 12.8 Find Un-owned Files and Directories (check) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -nouser -ls\n    changed_when: False\n    failed_when: False\n    register: unowned_files\n    tags:\n      - section12\n      - section12.8\n\n  - name: 12.8 Find Un-owned Files and Directories (Scored)\n    debug: msg=\"{{ item }}\"\n    with_items:\n        unowned_files.stdout_lines\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.9 Find Un-grouped Files and Directories (check) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -nogroup -ls\n    changed_when: False\n    failed_when: False\n    register: ungrouped_files\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.9 Find Un-grouped Files and Directories (Scored)\n    debug: >\n        msg=\"{{ item }}\"\n    with_items:\n        ungrouped_files.stdout_lines\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.10 Find SUID System Executables (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -4000 -print\n    changed_when: False\n    failed_when: False\n    register: suid_files\n    tags:\n      - section12\n      - section12.10\n\n  - name: 12.10 Find SUID System Executables (Not Scored)\n    debug: msg=\"{{ item }}\"\n    with_items:\n        suid_files.stdout_lines\n    tags:\n      - section12\n      - section12.10\n\n  - name: 12.11 Find SGID System Executables (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -2000 -print\n    changed_when: False\n    failed_when: False\n    register: gsuid_files\n    tags:\n      - section12\n      - section12.11\n\n  - name: 12.11 Find SGID System Executables (Not Scored)\n    debug: msg=\"{{ item }}\"\n    with_items:\n        gsuid_files.stdout_lines\n    tags:\n      - section12\n      - section12.10\n"}, {"commit_sha": "32211ebd2a9f45112f8dceda80bc95d0db029fb4", "sha": "141c3817fae1f6a7444ecf2563a4eab5c988ba27", "filename": "meta/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: nusenu\n  description: An Ansible role for Tor Relay Operators\n  license: GPLv3\n  platforms:\n  - name: Debian\n    versions:\n    - jessie\n    - stretch\n  - name: FreeBSD\n    versions:\n    - 10.1\n    - 10.2\n    - 10.3\n  - name: OpenBSD\n    versions:\n    - 5.9\n  - name: EL\n    versions:\n    - 7\n  - name: Ubuntu\n    versions:\n    - xenial\n  - name: Fedora\n    versions:\n    - 24\n  galaxy_tags:\n    - tor\n    - ipv6\n    - anonymity\n    - networking\n  min_ansible_version: 1.9.6\ndependencies: []\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "7041a7920ed56a1c466fe9811a841b01744327d9", "filename": "roles/vault/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for vault\n- include: install.yml\n- include: bootstrap.yml\n"}, {"commit_sha": "bf6e08dcb2440421477b6536ff6a8d11adc2be17", "sha": "70bcee16de04a4e151434138160d7a05ca816b12", "filename": "roles/haproxy/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for haproxy\n- name: \"assures {{ consul_template_dir }} dirs exists\"\n  file:\n    path: \"{{ consul_template_dir }}/{{ item.path }}\"\n    state: directory\n  with_items:\n    - { path: 'config' }\n    - { path: 'templates' }\n  tags:\n    - haproxy\n\n- name: upload template config files\n  template:\n    src: consul.cfg.j2\n    dest: \"{{ consul_template_dir }}/config/consul.cfg\"\n    mode: 0644\n  sudo: yes\n  tags:\n    - haproxy\n\n- name: upload static config files\n  copy:\n    src: \"{{ item.src }}\"\n    dest: \"{{ consul_template_dir }}/{{ item.dst }}\"\n    mode: 0644\n  sudo: yes\n  with_items:\n    - { src: haproxy.cfg, dst: 'config/haproxy.cfg' }\n    - { src: haproxy.tmpl, dst: 'templates/haproxy.tmpl' }\n  tags:\n    - haproxy\n\n- name: run haproxy container\n  docker:\n    name: haproxy\n    image: \"{{ haproxy_image }}\"\n    state: started\n    net: host\n    restart_policy: always\n    ports:\n      - \"80:80\"\n    env:\n      HAPROXY_DOMAIN: \"{{ haproxy_domain }}\"\n      CONSUL_TEMPLATE_VERSION: \"{{ consul_template_version }}\"\n      CONSUL_LOGLEVEL: \"{{ consul_template_loglevel }}\"\n      CONSUL_CONNECT: \"{{ consul_backend }}\"\n      CONSUL_CONFIG: \"/config\"\n      SERVICE_NAME: haproxy\n    volumes:\n    - \"{{ consul_template_dir }}/config:/config\"\n    - \"{{ consul_template_dir }}/templates:/templates\"\n  tags:\n    - haproxy\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "41818cae24b8452e248585871aa310912f313ea2", "filename": "roles/zookeeper/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- name: create zookeeper config directory\n  file:\n    path: \"{{ zookeeper_config_dir }}\"\n    state: directory\n    follow: yes\n    mode: 0755\n  become: yes\n  tags:\n    - zookeeper\n\n- name: Create zookeeper config files\n  template:\n    src: \"{{ item.src }}\"\n    dest: \"{{ item.dest }}\"\n  become: yes\n  with_items:\n    - src: zoo.cfg.j2\n      dest: \"{{ zookeeper_config_dir }}/zoo.cfg\"\n    - src: environment.j2\n      dest: \"{{ zookeeper_config_dir }}/environment\"\n    - src: configuration.xsl.j2\n      dest: \"{{ zookeeper_config_dir }}/configuration.xsl\"\n    - src: log4j.properties.j2\n      dest: \"{{ zookeeper_config_dir }}/log4j.properties\"\n  notify:\n    - reload systemd\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: Create zookeeper myid file\n  copy:\n    content: \"{{ zookeeper_id }}\"\n    dest: \"{{ zookeeper_config_dir }}/myid\"\n    mode: 0644\n  become: yes\n  notify:\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: deploy zookeeper service\n  become: yes\n  become_user: root\n  template:\n    src: zookeeper.service.j2\n    dest: /etc/systemd/system/zookeeper.service\n  notify:\n    - reload systemd\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: enable zookeeper\n  become: yes\n  service:\n    name: zookeeper\n    enabled: yes\n    state: started\n  tags:\n    - zookeeper\n\n- name: set zookeeper consul service definition\n  become: yes\n  template:\n    src: zookeeper-consul.j2\n    dest: \"{{ consul_dir }}/zookeeper.json\"\n  notify:\n    - restart consul\n  tags:\n    - zookeeper\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "b62a745d1a843b58fa9de30285f6db3c55036438", "filename": "roles/dockerbench/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for docker bench\n- name: checkout docker bench git repo\n  git:\n    repo: \"{{ dockerbench_repo }}\"\n    dest: \"{{ dockerbench_dest }}\"\n    accept_hostkey: true\n    version: \"{{ dockerbench_version }}\"\n\n- name: install docker bench threshold script\n  sudo: yes\n  template:\n    src: docker-bench-warn.sh.j2\n    dest: /usr/local/bin/docker-bench-warn.sh\n    mode: 0755\n\n- name: run docker bench script\n  command: /usr/local/bin/docker-bench-warn.sh\n  sudo: yes\n  args:\n    chdir: \"{{ dockerbench_dest }}\"\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "f7c2ba16ac1fdd5df1121ceac3f0b1bc6991e7a6", "filename": "roles/traefik/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n- name: restart traefik\n  become: yes\n  command: systemctl restart traefik\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "bd69e91cd037d34873d18829ed2401905e6794bd", "filename": "roles/dcos_cli/tasks/apps.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- include_vars: \"{{ item.name }}.yml\"\n  with_items:\n    - \"{{ dcos_cli_apps_list }}\"\n\n# Create the JSON files for apps\n- name: create json files for apps\n  when: \"dcos_cli_app_{{ item.name }}_enabled | bool\"\n  run_once: true\n  template:\n    src: '{{ item.name }}.json.j2'\n    dest: \"/etc/marathon/{{ item.name }}.json\"\n    mode: 0755\n  sudo: yes\n  tags:\n    - \"{{ item.name }}\"\n    - dcos_cli\n  with_items:\n    - \"{{ dcos_cli_apps_list }}\"\n\n- name: add marathon app via dcos-cli\n  when: \"dcos_cli_app_{{ item.name }}_enabled | bool\"\n  run_once: true\n  docker:\n    name: \"{{ item.name }}\"\n    image: \"{{ dcos_cli_image }}\"\n    state: started\n    command: \"marathon {{ item.type }} add /config/{{ item.name }}.json\"\n    volumes:\n      - \"/etc/marathon:/config\"\n    env:\n      MESOS_MASTER_URL: \"{{ dcos_cli_mesos_master_url }}\"\n      MARATHON_URL: \"{{ dcos_cli_marathon_url }}\"\n      SOURCES: \"{{ dcos_cli_sources }}\"\n  tags:\n    - \"{{ item.name }}\"\n    - dcos_cli\n  with_items:\n    - \"{{ dcos_cli_apps_list }}\"\n\n\n- name: remove marathon app via dcos-cli\n  when: \"not dcos_cli_app_{{ item.name }}_enabled | bool\"\n  run_once: true\n  docker:\n    name: \"{{ item.name }}\"\n    image: \"{{ dcos_cli_image }}\"\n    state: started\n    command: \"marathon {{ item.type }} remove {{ item.name }}\"\n    env:\n      MESOS_MASTER_URL: \"{{ dcos_cli_mesos_master_url }}\"\n      MARATHON_URL: \"{{ dcos_cli_marathon_url }}\"\n  tags:\n    - \"{{ item.name }}\"\n    - dcos_cli\n  with_items:\n    - \"{{ dcos_cli_apps_list }}\"\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "9706acb424c92cc45b6d7d499b54632eae15c45f", "filename": "tasks/section_05.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- include: section_05_level1.yml\n  tags:\n  - section05\n  - level1\n\n\n"}, {"commit_sha": "21712b74b7f5d936e70186bbed6bb37e3a7ad5e6", "sha": "2fe63390e34e1d1fa9942cd54afb86f03ad2a90e", "filename": "roles/frameworks/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for frameworks\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "81800958af84f562e49b02e1f3d3ccaf23bdfa26", "filename": "roles/vault/vars/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# vars file for marathon\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "ed06ab3778ef5e86a1ad1dfb37f3ea2b5871d0ac", "filename": "roles/cadvisor/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for cadvisor\ncadvisor_enabled: true\ncadvisor_version: 'latest'\ncadvisor_restart_policy: 'always'\ncadvisor_net: 'bridge'\ncadvisor_hostname: \"{{ ansible_ssh_host }}\"\ncadvisor_image: \"google/cadvisor:{{ cadvisor_version }}\"\ncadvisor_consul_dir: /etc/consul.d\ncadvisor_consul_service_id: \"{{ ansible_hostname }}:cadvisor:8080\"\ncadvisor_docker_socket: \"{{ docker_host }}\"\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "c2a97e39f6c9eba9875a4e1a41b4af4219837ee5", "filename": "roles/marathon/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- name: create marathon artifact store directory\n  when: marathon_artifact_store_dir is defined\n  file:\n    path: \"{{ marathon_artifact_store_dir }}\"\n    state: directory\n    mode: 0755\n  sudo: yes\n  tags:\n    - marathon\n\n- name: deploy marathon service\n  sudo: yes\n  sudo_user: root\n  template:\n    src: marathon.service.j2\n    dest: \"/etc/systemd/system/marathon.service\"\n  notify:\n    - restart marathon\n  tags:\n    - marathon\n\n# Attach to the running container, or start it if needed\n# and forward all signals so that the process manager can detect\n# when a container stops and correctly restart it.\n- name: ensure marathon is running (and enable it at boot)\n  sudo: yes\n  service:\n    name: marathon\n    state: started\n    enabled: yes\n  tags:\n    - marathon\n\n- name: Set marathon consul service definition\n  sudo: yes\n  template:\n    src: marathon-consul.j2\n    dest: \"{{ marathon_consul_dir }}/marathon.json\"\n  notify:\n    - restart consul\n  tags:\n    - marathon\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "595694ef7f6699720e39bbfb20337fc8bd6d92bb", "filename": "tasks/main.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - include: check_requirements.yml\n\n  - include: section_01.yml\n    tags: section01\n\n  - include: section_02.yml\n    tags: section02\n\n  - include: section_03.yml\n    tags: section03\n\n  - include: section_04.yml\n    tags: section04\n\n  - include: section_05.yml\n    tags: section05\n\n  - include: section_07.yml\n    tags: section07\n\n  - include: section_08.yml\n    tags: section08\n\n  - include: section_06.yml\n    tags: section06\n\n  - include: section_09.yml\n    tags: section09\n\n  - include: section_10.yml\n    tags: section10\n\n  - include: section_11.yml\n    tags: section11\n\n  - include: section_12.yml\n    tags: section12\n\n  - include: section_13.yml\n    tags: section13\n\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "4c142ec8196636f80f374ae6c38e07b2f138410b", "filename": "roles/st2web/tasks/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks file for st2web\n\n- name: Add nginx key\n  sudo: yes\n  apt_key:\n    url: http://nginx.org/keys/nginx_signing.key\n    state: present\n\n- name: Add nginx repos\n  sudo: yes\n  apt_repository:\n    repo: \"deb http://nginx.org/packages/ubuntu/ trusty nginx\"\n    state: present\n    update_cache: yes\n\n- name: Install nginx\n  sudo: yes\n  apt:\n    name: nginx=1.8.*\n    state: present\n\n- name: Install latest st2web package\n  sudo: yes\n  apt:\n    name: st2web\n    state: latest\n  when: st2_version == \"stable\"\n  notify:\n    - restart st2\n\n- name: Install exact st2web package\n  sudo: yes\n  apt:\n    name: st2web={{ st2_version }}-{{ st2web_revision }}\n    state: present\n  when: st2_version != \"stable\"\n  notify:\n    - restart st2\n\n- name: Create ssl cert dir\n  sudo: yes\n  file:\n    state: directory\n    dest: /etc/ssl/st2\n\n- name: Create ssl cert\n  sudo: yes\n  shell: openssl req -x509 -newkey rsa:2048 -keyout /etc/ssl/st2/st2.key -out /etc/ssl/st2/st2.crt -days 365 -nodes -subj \"/C=US/ST=California/L=Palo Alto/O=StackStorm/OU=Information Technology/CN=$(hostname)\"\n  args:\n    creates: /etc/ssl/st2/st2.key\n  notify:\n    - Restart nginx\n\n- name: Remove default site\n  sudo: yes\n  file:\n    path: /etc/nginx/sites-enabled/default\n    state: absent\n\n- name: Create nginx folders\n  sudo: yes\n  file:\n    state: directory\n    path: \"{{ item }}\"\n  with_items:\n    - /etc/nginx/sites-available/\n    - /etc/nginx/sites-enabled/\n\n- name: Ensure site-available is loaded\n  sudo: yes\n  lineinfile:\n    state: present\n    dest: /etc/nginx/nginx.conf\n    regexp: 'include /etc/nginx/sites-enabled/'\n    insertafter: '    include /etc/nginx/conf.d/'\n    line: 'include /etc/nginx/sites-enabled/*;'\n    \n- name: Copy Nginx config\n  sudo: yes\n  command: cp /usr/share/doc/st2/conf/nginx/st2.conf /etc/nginx/sites-available/\n  args:\n    creates: /etc/nginx/sites-available/st2.conf\n  notify: \n    - Restart nginx\n\n- name: Enable site\n  sudo: yes\n  file:\n    state: link\n    src: /etc/nginx/sites-available/st2.conf\n    dest: /etc/nginx/sites-enabled/st2.conf\n  notify:\n    - Restart nginx\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "cc028bec15e9ad0f93d6ab2578cf983e89499212", "filename": "roles/handlers/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- name: restart consul\n  service:\n    name: consul\n    state: restarted\n  sudo: yes\n  notify:\n    - wait for consul to listen\n\n- name: wait for consul to listen\n  wait_for:\n    port: 8500\n\n- name: restart docker\n  service:\n   name: docker\n   state: restarted\n  sudo: yes\n  notify:\n  - wait for weave to listen\n\n- name: wait for weave to listen\n  wait_for:\n    port: 6783\n    delay: 10\n"}, {"commit_sha": "fa66f2d6f5193cce5c2f9086e78f9bff39133e60", "sha": "ca88ce2542fe98f8a0e9e5b82f0310540dde1d67", "filename": "tasks/apt_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Setup Debian specific variables (set_fact)\n  set_fact:\n    tor_user: debian-tor\n    tor_DataDir: /var/lib/tor-instances\n    tor_ConfDir: /etc/tor/instances\n    tor_RunAsDaemon: 0\n  tags:\n   - reconfigure\n   - renewkey\n   - createdir\n\n- name: Ensure torproject gpg key is installed (A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89)\n  become: yes\n  apt_key: data=\"{{ lookup('file', 'deb.torproject.org_A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89.pub') }}\"\n    id=A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89\n    state=present\n\n- name: Ensure torproject.org repository is present (APT)\n  become: yes\n  apt_repository: repo='deb http://deb.torproject.org/torproject.org {{ tor_distribution_release }} main'\n    state=present \n    update_cache=yes\n\n# we specifically opt for present over latest to improve performance\n# \"latest\" is covered by auto updates\n- name: Ensure Tor is installed (APT)\n  become: yes\n  apt: pkg=\"{{ item }}\" state=present\n  with_items: \n    - deb.torproject.org-keyring\n    - tor\n  # apt starts a tor client instance by default after installing the package\n  # we do not need that\n  notify:\n    - stop-and-disable default tor\n\n\n- name: Ensure AppArmor allows access to necessary files (Ubuntu)\n  become: yes\n  lineinfile: dest=/etc/apparmor.d/local/system_tor line={{ item }}\n  with_items:\n    - '/etc/tor/enabled/*\\ r,'\n    - '/{,var/}run/tor/*.pid\\ w,'\n    - '/var/lib/tor/**\\ w,'\n  when: ansible_distribution == 'Ubuntu'\n  notify: restart apparmor\n\n- meta: flush_handlers\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "89ec1fb7bf802d6f1ff5740f06b4fe2161684fda", "filename": "roles/vault/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n- name: restart vault\n  sudo: yes\n  service:\n    name: vault\n    state: restarted\n    enabled: yes\n  tags:\n    - vault\n\n- name: reload vault\n  sudo: yes\n  service:\n    name: vault\n    state: reload\n    enabled: yes\n  tags:\n    - vault\n  notify:\n    - wait for vault to listen\n\n\n- name: wait for vault to listen\n  wait_for:\n    port: \"{{ vault_default_port }}\"\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "5a3068cbf9e118d494937105458dc0a694df5b87", "filename": "roles/handlers/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- name: reload systemd\n  become: yes\n  command: systemctl daemon-reload\n\n- name: restart consul\n  service:\n    name: consul\n    state: restarted\n  become: yes\n  notify:\n    - wait for consul to listen\n\n- name: wait for consul to listen\n  wait_for:\n    port: 8500\n\n- name: restart docker\n  service:\n   name: docker\n   state: restarted\n  become: yes\n  notify:\n  - wait for weave to listen\n\n- name: wait for weave to listen\n  wait_for:\n    port: 6783\n    delay: 10\n"}, {"commit_sha": "ec4de12ae75f7191a5f71aa775e0344679ea1477", "sha": "069fdccd88032ff4a1b1dc975533d8f15d5a3fcf", "filename": "meta/main.yml", "repository": "UnderGreen/ansible-role-mongodb", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\ndependencies: []\n\ngalaxy_info:\n  author: Sergei Antipov\n  company: 2GIS\n  description: Manage MongoDB (MMS) with authentication and replica sets\n  license: GPLv2\n  platforms:\n  - name: Ubuntu\n    versions:\n    - trusty\n  - name: Debian\n    versions:\n    - wheezy\n    - jessie\n  categories:\n  - database\n  - database:nosql\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "4f11af646525b65bc8003de828773f9631dd63d5", "filename": "roles/st2/meta/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\ngalaxy_info:\n  description: Install StackStorm and all its components\n  author: armab\n  company: StackStorm\n  license: Apache\n  min_ansible_version: 1.9\n  platforms:\n    - name: Ubuntu\n      versions:\n        - trusty\n        - precise\n  categories:\n    - system\ndependencies: \n  - role: st2repos\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "7504ae499ffc6daf166e0c6d0a58565ae837d8f5", "filename": "tasks/ssl.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/ssl.yml: Deploy the client SSL cert/key to client systems\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure Sensu SSL directory exists\n    file:\n      dest: \"{{ sensu_config_path }}/ssl\"\n      state: directory\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    when: sensu_ssl_gen_certs and sensu_ssl_manage_certs\n\n  - include: ssl_generate.yml\n    when: sensu_ssl_gen_certs\n    static: false\n\n  - name: Deploy the Sensu client SSL cert/key\n    copy:\n      src: \"{{ item.src }}\"\n      owner: \"{{ sensu_user_name }}\"\n      remote_src: \"{{ sensu_ssl_deploy_remote_src }}\"\n      group: \"{{ sensu_group_name }}\"\n      dest: \"{{ sensu_config_path }}/ssl/{{ item.dest }}\"\n    with_items:\n      - {src: \"{{ sensu_ssl_client_cert }}\", dest: cert.pem}\n      - {src: \"{{ sensu_ssl_client_key }}\", dest: key.pem}\n    notify: restart sensu-client service\n    when: sensu_ssl_manage_certs\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "735cc11101a37ecb6b0ee5aa5f580c696b11a67b", "filename": "tasks/Ubuntu/dashboard.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/Ubuntu/dashboard.yml: Deployment of the Uchiwa dashboard\n# Specific to Ubuntu\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Install Uchiwa\n    apt:\n      name: uchiwa\n      state: present\n\n  - name: Deploy Uchiwa config\n    template:\n      src: uchiwa_config.json.j2\n      dest: \"{{ sensu_config_path }}/uchiwa.json\"\n    notify: restart uchiwa service\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "a03836f560babfe6c954049f11be8c689b013802", "filename": "roles/prometheus/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "# tasks for running prometheus\n- name: create prometheus config dir\n  file:\n    path: \"{{ prometheus_config_dir }}\"\n    state: directory\n    mode: 0755\n  become: yes\n  tags:\n    - prometheus\n\n- name: upload prometheus config file\n  template:\n    src: prometheus.yml.j2\n    dest: \"{{ prometheus_config_dir }}/prometheus.yml\"\n    mode: 0755\n  become: yes\n  tags:\n    - prometheus\n\n- name: run prometheus node exporter container\n  docker:\n    name: node-exporter\n    image: \"{{ prometheus_node_exporter_image }}\"\n    state: started\n    restart_policy: always\n    net: host\n    ports:\n    - \"{{ prometheus_node_exporter_port }}:{{ prometheus_node_exporter_port }}\"\n  environment: \"{{ proxy_env }}\"\n  tags:\n    - prometheus\n\n- name: set node-exporter consul service definition\n  become: yes\n  template:\n    src: node-exporter-consul.j2\n    dest: \"{{ prometheus_consul_dir }}/node-exporter.json\"\n  notify:\n    - restart consul\n  tags:\n    - prometheus\n"}, {"commit_sha": "584d564218d6e2e63d3ecca157daf817fe4d533c", "sha": "639e439fd2d82ec886cdb75f534000ad22267f3c", "filename": "handlers/main.yml", "repository": "mikolak-net/ansible-raspi-config", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n- name: apply raspi-config\n  command: raspi-config --apply-os-config\n  # using the Ansible blog post solution:\n  # https://support.ansible.com/hc/en-us/articles/201958037-Reboot-a-server-and-wait-for-it-to-come-back\n- name: reboot\n  command: shutdown -r now\n  async: 0\n  poll: 0\n  ignore_errors: True\n  notify:\n    - wait for reboot\n- name: wait for reboot\n  local_action: wait_for host={{ inventory_hostname }}\n                state=started\n                timeout=30 # doesn't appear to work correctly now, instead a simple delay is imposed - that's fine for now\n  sudo: false\n- name: remove default user\n  when: \"raspi_config_replace_user['name'] != raspi_config_auth_test_username\"\n  user: name={{raspi_config_auth_test_username}} state=absent force=yes\n  async: 0\n  poll: 0\n  ignore_errors: True"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "5389e71e04dabfd49042d7f782ccb4fcaceae86c", "filename": "roles/mesos/tasks/master.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# Tasks for Master nodes\n- name: create mesos-master work directory\n  file:\n    path: \"{{ mesos_master_work_dir }}\"\n    state: directory\n    mode: 0755\n  sudo: yes\n  tags:\n    - mesos-master\n\n- name: deploy mesos-master service\n  sudo: yes\n  sudo_user: root\n  template:\n    src: mesos-master.service.j2\n    dest: /etc/systemd/system/mesos-master.service\n  notify:\n    - restart mesos master\n  tags:\n    - mesos-master\n\n- name: ensure mesos-master is running (and enable it at boot)\n  sudo: yes\n  service:\n    name: mesos-master\n    state: started\n    enabled: yes\n  tags:\n    - mesos-master\n\n#- name: run prometheus mesos master exporter container\n#  when: mesos_install_mode == \"master\" and prometheus_enabled|bool\n#  docker:\n#    name: mesos-exporter\n#    image: \"{{ prometheus_mesos_exporter_image }}\"\n#    command: \"-exporter.scrape-mode=master -exporter.url=http://{{ mesos_hostname }}:{{ mesos_master_port }}\"\n#    state: started\n#    restart_policy: always\n#    ports:\n#    - \"{{ prometheus_mesos_exporter_port }}:{{ prometheus_mesos_exporter_port }}\"\n#  environment: proxy_env\n#  tags:\n#    - prometheus\n#    - mesos_master\n\n#- name: Set mesos-exporter consul service definition\n#  when: mesos_install_mode == \"master\" and prometheus_enabled|bool\n#  sudo: yes\n#  template:\n#    src: mesos-exporter-consul.j2\n#    dest: \"{{ consul_dir }}/mesos-exporter.json\"\n#  notify:\n#    - restart consul\n#  tags:\n#    - prometheus\n#    - mesos_master\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "807ea4447e99ab56d6dd90bf2e1357b93b3578a5", "filename": "roles/st2repos/tasks/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks file for st2repos\n\n- name: Install prereqs\n  sudo: yes\n  apt:\n    name: \"{{ item }}\"\n    state: present\n    update_cache: yes\n  with_items:\n    - debian-archive-keyring\n    - apt-transport-https\n  \n- name: Add keys to keyring\n  sudo: yes\n  apt_key:\n    url: https://packagecloud.io/StackStorm/stable/gpgkey\n    state: present\n\n- name: Add StackStorm repos\n  sudo: yes\n  apt_repository:\n    repo: 'deb https://packagecloud.io/StackStorm/stable/ubuntu/ trusty main'\n    state: present\n    update_cache: yes\n"}, {"commit_sha": "584d564218d6e2e63d3ecca157daf817fe4d533c", "sha": "c2df7fccef67ba7c0eb8ed178042d6677bbfdac4", "filename": "tasks/setup_replace_user.yml", "repository": "mikolak-net/ansible-raspi-config", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n- name: Create user {{raspi_config_replace_user['name']}}\n  user: name={{raspi_config_replace_user['name']}}\n  changed_when: True #to force handler call\n  notify:\n    - remove default user\n- name: Add your login key to {{raspi_config_replace_user['name']}}\n  authorized_key: user={{raspi_config_replace_user['name']}} key=\"{{ lookup('file', raspi_config_replace_user['path_to_ssh_key']) }}\"\n- name: Add {{raspi_config_replace_user['name']}} to sudoers\n  lineinfile:\n  args:\n    dest: /etc/sudoers\n    line: \"{{raspi_config_replace_user['name']}} ALL=(ALL) NOPASSWD: ALL\""}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "ef51794bfc8a39d526b66d0f5092df494b005c54", "filename": "roles/dcos_cli/tasks/frameworks.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- include_vars: \"{{ item }}.yml\"\n  with_items: \"{{ dcos_cli_frameworks_list }}\"\n\n- name: create config directory\n  when: \"dcos_cli_framework_{{ item }}_enabled | bool\"\n  run_once: true\n  template:\n    src: \"{{ item }}-config.j2\"\n    dest: \"/tmp/{{ item }}-config\"\n    mode: 0755\n  become: yes\n  tags:\n    - \"{{ item }}\"\n  with_items:\n    - \"{{ dcos_cli_frameworks_list }}\"\n\n- name: install dcos-cli package\n  when: \"dcos_cli_framework_{{ item }}_enabled | bool\"\n  run_once: true\n  docker:\n    name: \"{{ item }}\"\n    image: \"{{ dcos_cli_image }}\"\n    state: started\n    command: \"package install --options=/config --yes {{ item }}\"\n    volumes:\n    - \"/tmp/{{ item }}-config:/config\"\n    env:\n      \"{{ dcos_cli_container_environment }}\"\n  tags:\n    - \"{{ item }}\"\n  with_items:\n    - \"{{ dcos_cli_frameworks_list }}\"\n\n- name: uninstall dcos-cli package\n  when: \"not dcos_cli_framework_{{ item }}_enabled | bool\"\n  run_once: true\n  docker:\n    name: \"{{ item }}\"\n    image: \"{{ dcos_cli_image }}\"\n    state: started\n    command: \"package uninstall {{ item }}\"\n    env:\n      \"{{ dcos_cli_container_environment }}\"\n  tags:\n    - \"{{ item }}\"\n  with_items:\n    - \"{{ dcos_cli_frameworks_list }}\"\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "5ab6b1e16d062da1adabb258279845e101668ba8", "filename": "roles/registrator/meta/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Alberto Garcia\n  description:\n  company: Capgemini\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (MIT)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: Ubuntu\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n     - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies:\n  - handlers\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "5c23fd14fc585d950a5e3162cc75491dbfdf763a", "filename": "roles/st2/tasks/user.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "# Create system user, on whose behalf remote/local action runners would work\n# See: http://docs.stackstorm.com/install/config.html#configure-ssh\n---\n- name: user | Create system user\n  sudo: yes\n  user:\n    name: \"{{ st2_system_user }}\"\n    home: \"/home/{{ st2_system_user }}\"\n    generate_ssh_key: yes\n    ssh_key_file: \"{{ st2_ssh_key_file }}\"\n    state: present\n  register: _user\n  tags: [st2, user]\n\n- name: user | Authorize key-based access for system user\n  sudo: yes\n  sudo_user: \"{{ st2_system_user }}\"\n  authorized_key:\n    user: \"{{ st2_system_user }}\"\n    key: \"{{ _user.ssh_public_key }}\"\n    state: present\n  tags: [st2, user]\n\n- name: user | Add system user to sudoers\n  sudo: yes\n  lineinfile:\n    create: yes\n    dest: /etc/sudoers.d/st2\n    mode: 0440\n    regexp: \"^{{ st2_system_user }} ALL=\"\n    line: \"{{ st2_system_user }} ALL=(ALL) NOPASSWD: SETENV: ALL\"\n    state: \"{{ 'present' if st2_system_user_in_sudoers else 'absent' }}\"\n    validate: 'visudo -cf %s'\n  tags: [st2, user]\n\n\n- name: Configure system user in /etc/st2/st2.conf\n  sudo: yes\n  ini_file:\n    dest: /etc/st2/st2.conf\n    section: system_user\n    option: user\n    value: \"{{ st2_system_user }}\"\n    backup: yes\n\n- name: Configure system user ssh key in /etc/st2/st2.conf\n  sudo: yes\n  ini_file:\n    dest: /etc/st2/st2.conf\n    section: system_user\n    option: ssh_key_file\n    value: \"{{ _user.ssh_key_file }}\"\n    backup: yes\n"}, {"commit_sha": "f565940c5163524c7834123625c804e5f69c2b10", "sha": "aa049c464e2d7bf6ce0e1285dec99ff50de1c970", "filename": "tasks/CentOS/dashboard.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/CentOS/dashboard.yml: Deployment of the Uchiwa dashboard\n# Specific to CentOS\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure Uchiwa is installed\n    yum:\n      name: \"{{ uchiwa_pkg_rpm_download_url }}\"\n      state: present\n\n  - name: Deploy Uchiwa config\n    template:\n      src: uchiwa_config.json.j2\n      dest: \"{{ sensu_config_path }}/uchiwa.json\"\n    notify: restart uchiwa service\n"}, {"commit_sha": "694a4890fcf0daa375d6a173511f6ff7dd0f2335", "sha": "4c020120eb2c679567264371b541d0244b425426", "filename": "tasks/freebsd_service.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Ensure Tor starts at boot (FreeBSD)\n  become: yes\n  lineinfile: dest=/etc/rc.local line=\"/usr/local/bin/tor -f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\" create=yes\n  with_nested:\n   - tor_ips\n   - tor_ports\n\n- name: Ensure PidDir exists (FreeBSD)\n  become: yes\n  file: path={{ tor_PidDir }}\n    state=directory\n    owner=root\n    mode=0755\n\n- name: Ensure PidDir is owned by per-instance tor_user (FreeBSD)\n  become: yes\n  file: path={{ tor_PidDir }}/{{ item[0] }}_{{ item.1.orport }}\n    state=directory\n    owner=_tor-{{ item[0] }}_{{ item.1.orport }}\n    mode=0700\n  with_nested:\n   - tor_ips\n   - tor_ports\n\n- name: Ensure Tor instances are reloaded if its torrc changed (FreeBSD)\n  become: yes\n  shell: \"kill -HUP `cat {{ tor_PidDir }}/{{ item.item[0] }}_{{ item.item.1.orport }}/pid`\"\n  ignore_errors: yes\n  with_items: instances.results\n  when: item.changed == True\n  tags:\n   - reconfigure\n\n- name: Ensure Tor instances are running (FreeBSD)\n  become: yes\n  shell: \"kill -0 `cat {{ tor_PidDir }}/{{ item[0] }}_{{ item.1.orport }}/pid` || tor -f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "b09cdd079871213ec3d977f92b7538f2142418b3", "filename": "roles/mistral/defaults/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "mistral_version: stable\nmistral_db_username: mistral\nmistral_db_password: StackStorm\nmistral_db: mistral\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "4c6cdcdf3b75b5075a48db96c54d9c922d888b8d", "filename": "roles/prometheus/meta/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Graham Taylor\n  description:\n  company: Capgemini\n  license: license (MIT)\n  min_ansible_version: 1.9\n  platforms:\n  - name: Ubuntu\n    versions:\n     - trusty\n\n  categories:\n  - cloud\n  - system\n\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "ff73e3dff34cb6ecd1afe00fdb3cd2774413b7ae", "filename": "roles/mesos_maintenance/tasks/start.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "# start maintenance\n- name: deploy machines template\n  sudo: yes\n  sudo_user: root\n  template:\n    src: \"{{ item.src }}\"\n    dest: \"{{ item.dest }}\"\n    mode: 0755\n  when: mesos_maintenance_start\n  tags:\n    - mesos-maintenance\n  with_items:\n    - src: machines.json.j2\n      dest: /tmp/machines.json\n    - src: wait-for-agent.sh.j2\n      dest: /tmp/wait-for-agent.sh\n\n- name: start maintenance\n  command: \"curl -XPOST -x '' http://{{ mesos_maintenance_master_url }}/master/machine/down -d@/tmp/machines.json -H 'Content-type: application/json'\"\n  register: start_content\n  when: mesos_maintenance_start\n\n"}, {"commit_sha": "92d2f38d01d7b33610c667cfdc03e28ab2912edc", "sha": "41882493c9a0a6ed35a78ac709a5da247ae733b1", "filename": "tasks/section_07_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 7.1.1 Disable IP Forwarding (Scored)\n    sysctl: >\n      name=net.ipv4.ip_forward\n      value={{net_ipv4_ip_forward}}\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.1\n\n  - name: 7.1.2.1 Disable Send Packet Redirects (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.2\n      - section7.1.2.1\n\n  - name: 7.1.2.2 Disable Send Packet Redirects (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.2\n      - section7.1.2.2\n\n  - name: 7.2.1.1 Disable Source Routed Packet Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.accept_source_route\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.1\n      - section7.2.1.1\n\n  - name: 7.2.1.2 Disable Source Routed Packet Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.accept_source_route\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.1\n      - section7.2.1.2\n\n  - name: 7.2.2.1 Disable ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.2\n      - section7.2.2.1\n\n  - name: 7.2.2.2 Disable ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.2\n      - section7.2.2.2\n\n  - name: 7.2.3.1 Disable Secure ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.secure_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.3\n      - section7.2.3.1\n\n  - name: 7.2.3.2 Disable Secure ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.secure_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.3\n      - section7.2.3.2\n\n  - name: 7.2.4.1 Log Suspicious Packets (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.log_martians\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.4\n      - section7.2.4.1\n\n  - name: 7.2.4.2 Log Suspicious Packets (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.log_martians\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.4\n      - section7.2.4.2\n\n  - name: 7.2.5 Enable Ignore Broadcast Requests (Scored)\n    sysctl: >\n      name=net.ipv4.icmp_echo_ignore_broadcasts\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.5\n\n  - name: 7.2.6 Enable Bad Error Message Protection (Scored)\n    sysctl: >\n      name=net.ipv4.icmp_ignore_bogus_error_responses\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.6\n\n  - name: 7.2.7.1 Enable RFC-recommended Source Route Validation (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.rp_filter\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.7\n      - section7.2.7.1\n\n  - name: 7.2.7.2 Enable RFC-recommended Source Route Validation (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.rp_filter\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.7\n      - section7.2.7.2\n\n  - name: 7.2.8 Enable TCP SYN Cookies (Scored)\n    sysctl: >\n      name=net.ipv4.tcp_syncookies\n      value=1\n      state=present\n    when: enable_tcp_syncookies\n    tags:\n      - section7\n      - section7.2\n      - section7.2.8\n\n  - name: 7.3.1.1 Disable IPv6 Router Advertisements (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.all.accept_ra\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.1\n      - section7.3.1.1\n\n  - name: 7.3.1.2 Disable IPv6 Router Advertisements (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.default.accept_ra\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.1\n      - section7.3.1.2\n\n  - name: 7.3.2.1 Disable IPv6 Redirect Acceptance (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.all.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.2\n      - section7.3.2.1\n\n  - name: 7.3.2.2 Disable IPv6 Redirect Acceptance (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.default.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.2\n      - section7.3.2.2\n\n  - name: 7.3.3 Disable IPv6 (Not Scored)\n    sysctl: >\n      name={{ item }}\n      value=1\n      state=present\n    with_items:\n      - net.ipv6.conf.all.disable_ipv6\n      - net.ipv6.conf.default.disable_ipv6\n      - net.ipv6.conf.lo.disable_ipv6\n    when: disable_ipv6 == True\n    tags:\n      - section7\n      - section7.3\n      - section7.3.3\n\n  - name: 7.4.1 Install TCP Wrappers (Scored)\n    apt: name=tcpd state=present\n    tags:\n      - section7\n      - section7.4\n      - section7.4.1\n\n  - name: 7.4.2 Create /etc/hosts.allow (Not Scored)\n    debug: msg=\"*** Verify /etc/hosts.allow ***\"\n    tags:\n      - section7\n      - section7.4\n      - section7.4.2\n\n  - name: 7.4.3 Verify Permissions on /etc/hosts.allow (Scored)\n    file: >\n        path=/etc/hosts.allow\n        owner=root\n        group=root\n        mode=0644\n    tags:\n      - section7\n      - section7.4\n      - section7.4.3\n\n  - name: 7.4.4 Create /etc/hosts.deny (Not Scored)\n    debug: msg='*** Verify /etc/hosts.deny ***'\n    tags:\n      - section7\n      - section7.4\n      - section7.4.4\n\n  - name: 7.4.5 Verify Permissions on /etc/hosts.deny (Scored)\n    file: >\n        path=/etc/hosts.deny\n        owner=root\n        group=root\n        mode=0644\n    tags:\n      - section7\n      - section7.4\n      - section7.4.5\n\n  - name: 7.5.0 Ensures /etc/modprobe.d/ exists (Not Scored)\n    file: >\n        path=/etc/modprobe.d\n        state=directory\n    register: cis_conf_file\n    tags:\n      - section7\n      - section7.5\n\n  - name: 7.5.1-4 Disable DCCP, SCTP, RDS, TIPC (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install {{ item }} /bin/true'\n        state=present\n        create=True\n    with_items:\n        - dccp\n        - sctp\n        - rds\n        - tipc\n    tags:\n      - section7\n      - section7.5\n      - section7.5.1\n      - section7.5.2\n      - section7.5.3\n      - section7.5.4\n\n  - name: 7.6 Deactivate Wireless Interfaces (Not Scored)\n    shell: 'lspci -k | grep -i wifi'\n    changed_when: False\n    register: lspci_wifi\n    failed_when: lspci_wifi.rc == 0\n    tags:\n      - section7\n      - section7.6\n\n  - name: 7.7 Ensure Firewall is active (install) (Scored)\n    apt: >\n        name=ufw\n        state=present\n    when: activate_ufw\n    tags:\n      - section7\n      - section7.7\n\n  - name: 7.7 Ensure Firewall is active (Scored)\n    service: >\n        name=ufw\n        state=started\n    when: activate_ufw\n    tags:\n      - section7\n      - section7.7\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "d416330867f7a7d3b80b521d922f83b1cd5e8f4e", "filename": "roles/prometheus/vars/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# vars file for prometheus\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "3444b58c8cd46486f7b0979c796ee4765d14a34f", "filename": "roles/docker/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for docker\n- name: configure docker consul dns\n  sudo: yes\n  lineinfile:\n    dest: /etc/sysconfig/docker\n    regexp: ^OPTIONS=\n    line: 'OPTIONS=\\\"--storage-driver=overlay --graph={{ docker_graph_dir }} --dns 172.17.0.1 --dns 8.8.8.8 --dns-search service.{{ consul_domain }} \\\"'\n    state: present\n    create: yes\n  notify:\n    - restart docker\n  tags:\n    - docker\n\n#- name: configure docker temporary directory\n#  sudo: yes\n#  lineinfile:\n#    dest: /etc/sysconfig/docker\n#    state: present\n#    line: 'DOCKER_TMPDIR=\\\"{{ docker_tmp_dir }}\\\"'\n#  notify:\n#    - restart docker\n\n#- name: configure docker proxy\n#  sudo: yes\n#  lineinfile:\n#    dest: /etc/sysconfig/docker\n#    state: present\n#    line: 'export http_proxy=\\\"{{ http_proxy }}\\\"'\n#  when: http_proxy is defined and http_proxy != ''\n\n- name: ensure docker is running (and enable it at boot)\n  sudo: yes\n  service:\n    name: docker\n    state: started\n    enabled: yes\n  tags:\n    - docker\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "32838ad94901e927f0a06e2ee43edbc3ab3e9608", "filename": "roles/registrator/meta/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Alberto Garcia\n  description:\n  company: Capgemini\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (MIT)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: Ubuntu\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n     - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies: []\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "7f02cba4441b5367d6916857c9b41f3abae915db", "sha": "64bce01f2f5b21233dba3bc1f532dfe89fd2f164", "filename": "handlers/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: stop-and-mask default tor instance\n  become: yes\n  systemd:\n    name: 'tor@default'\n    state: 'stopped'\n    enabled: False\n    masked: True\n  when: ansible_pkg_mgr == 'apt'\n\n- name: restart apparmor\n  become: yes\n  service: name=apparmor state=restarted\n\n- name: systemctl daemon-reload\n  become: yes\n  systemd:\n    daemon_reload: True\n\n- name: re-gather facts\n  setup:\n\n- name: disable default tor instance FreeBSD\n  become: yes\n  lineinfile:\n    dest: /etc/rc.conf\n    line: \"tor_disable_default_instance=\\\"YES\\\"\"\n    create: yes\n  when: ansible_system == 'FreeBSD'\n\n# TODO: this reloads all instances on a FreeBSD host even if just one torrc changed\n- name: Ensure Tor instances are reloaded if its torrc changed (FreeBSD)\n  become: yes\n  service:\n    name: tor\n    state: reloaded\n  when: ansible_system == 'FreeBSD'\n\n- name: Ensure Tor instances are reloaded if its torrc changed (Linux)\n  become: yes\n  service:\n    name: \"tor@{{ item.item.0.ipv4 }}_{{ item.item.1.orport }}.service\"\n    state: reloaded\n  with_items: \"{{ tor_instances_tmp.results }}\"\n  when: item.changed and ansible_system == 'Linux'\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "847c0414b06bc414d69f37dd1ab0449f0ac53d6d", "filename": "roles/vault/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults settings for vault\nvault_consul_dir: /etc/consul.d\nvault_version: '0.4.0'\nvault_url: \"https://releases.hashicorp.com/vault/{{ vault_version }}/vault_{{ vault_version }}_linux_amd64.zip\"\nvault_config_folder: '/etc/vault'\nvault_port: 8200\nvault_addr: \"http://127.0.0.1:{{ vault_port }}\"\nvault_health_status_command: 'curl -k http://localhost:{{ vault_port }}/v1/sys/health'\nvault_initialize_status_command: 'curl -k http://localhost:{{ vault_port }}/v1/sys/init'\nvault_initialize_command: \"curl -1 -X PUT -d '{{ vault_init_json }}' -k http://localhost:{{ vault_port }}/v1/sys/init\"\nvault_advertise_addr: \"{{ ansible_ssh_host }}\"\n\nvault_init_json: '{\n\t\"secret_shares\": 5,\n\t\"secret_threshold\": 3\n}'\n"}, {"commit_sha": "5eb44163b7f6328c1f30168fa86326458d5dbaff", "sha": "e590cc27c3e9d17b4819e3378de4964ad39d9679", "filename": "tasks/debian/main.yml", "repository": "ansiblebit/oracle-java", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# file: oracle-java/tasks/debian/main.yml\n#\n# Task file to install Oracle Java Development Kit in a system with a Debian based Linux distribution.\n#\n\n- name: accept Oracle license\n  shell: \"echo oracle-java{{ oracle_java_version }}-installer shared/accepted-oracle-license-v1-1 select true | sudo /usr/bin/debconf-set-selections\"\n  changed_when: no\n  sudo: yes\n\n- name: ensure Java is installed\n  apt:\n    name=\"oracle-java{{ oracle_java_version }}-installer\"\n    state={{ oracle_java_state }}\n    cache_valid_time={{ oracle_java_cache_valid_time }}\n    update_cache=yes\n  register: oracle_java_task_apt_install\n  sudo: yes\n\n- name: set Java version as default\n  apt:\n    name=\"oracle-java{{ oracle_java_version }}-set-default\"\n    state=latest\n  register: oracle_java_task_set_default\n  when: oracle_java_set_as_default\n  sudo: yes\n\n- name: in case there were changes, check host environment again\n  include: ../check_environment.yml\n  when: oracle_java_task_apt_install|changed or oracle_java_task_set_default|changed\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "8aaa7f5b2b0fef40dc41e13fd04cc51d52976988", "filename": "tasks/nix.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# Gathers facts (bind address) from servers not currently targeted.\n# 'delegate_facts' is currently rather buggy in Ansible so this might not\n# always work. Hence 'consul_gather_server_facts' defaults to 'no'.\n- name: Gather facts from other servers\n  setup:\n  delegate_to: \"{{ item }}\"\n  delegate_facts: true\n  with_items: \"{{ consul_servers | difference(play_hosts) }}\"\n  ignore_errors: true\n  when: consul_gather_server_facts | bool\n\n- name: Expose advertise_address(_wan) datacenter and node_role as facts\n  set_fact:\n    consul_advertise_address_wan: \"{{ consul_advertise_address_wan }}\"\n    consul_advertise_address: \"{{ consul_advertise_address }}\"\n    consul_bind_address: \"{{ consul_bind_address }}\"\n    consul_datacenter: \"{{ consul_datacenter }}\"\n    consul_node_role: \"{{ consul_node_role }}\"\n\n- name: Read bootstrapped state\n  stat:\n    path: \"{{ consul_bootstrap_state }}\"\n  register: bootstrap_state\n  ignore_errors: true\n  tags: always\n\n- name: Include user and group settings\n  import_tasks: user_group.yml\n\n- name: Include directory settings\n  import_tasks: dirs.yml\n\n- name: Check for existing Consul binary\n  stat:\n    path: \"{{ consul_binary }}\"\n  register: consul_binary_installed\n\n- name: Calculate whether to install consul binary\n  set_fact:\n    consul_install_binary: \"{{ consul_install_upgrade | bool or not consul_binary_installed.stat.exists }}\"\n\n- name: Install OS packages and consul - locally\n  include_tasks: install.yml\n  when:\n    - consul_install_binary | bool\n    - not consul_install_remotely | bool\n\n- name: Install OS packages and consul - remotely\n  include_tasks: install_remote.yml\n  when:\n    - consul_install_binary | bool\n    - consul_install_remotely | bool\n\n# XXX: Individual gossip tasks are deprecated and need to be removed\n# - include_tasks: ../tasks/encrypt_gossip.yml\n- block:\n    - block:\n        - name: Check for gossip encryption key on previously boostrapped server\n          slurp:\n            src: \"{{ consul_config_path }}/config.json\"\n          register: consul_config_b64\n          ignore_errors: true\n\n        - name: Deserialize existing configuration\n          set_fact:\n            consul_config: \"{{ consul_config_b64.content | b64decode | from_json }}\"\n          when: consul_config_b64.content is defined\n\n        - name: Save gossip encryption key from existing configuration\n          set_fact:\n            consul_raw_key: \"{{ consul_config.encrypt }}\"\n          when: consul_config is defined\n\n      no_log: true\n      when:\n        - consul_raw_key is not defined\n        - bootstrap_state.stat.exists | bool\n        - inventory_hostname in consul_servers\n\n    # Key provided by extra vars or the above block\n    - name: Write gossip encryption key locally for use with new servers\n      copy:\n        content: \"{{ consul_raw_key }}\"\n        dest: '/tmp/consul_raw.key'\n      become: false\n      vars:\n        ansible_become: false\n      no_log: true\n      register: consul_local_key\n      delegate_to: localhost\n      changed_when: false\n      when: consul_raw_key is defined\n\n    # Generate new key if none was found\n    - block:\n        - name: Generate gossip encryption key\n          shell: \"PATH={{ consul_bin_path }}:$PATH consul keygen\"\n          register: consul_keygen\n\n        - name: Write key locally to share with other nodes\n          copy:\n            content: \"{{ consul_keygen.stdout }}\"\n            dest: '/tmp/consul_raw.key'\n          become: false\n          vars:\n            ansible_become: false\n          delegate_to: localhost\n\n      no_log: true\n      run_once: true\n      when:\n        - not consul_local_key.changed\n        - not bootstrap_state.stat.exists | bool\n\n    - name: Read gossip encryption key for servers that require it\n      set_fact:\n        consul_raw_key: \"{{ lookup('file', '/tmp/consul_raw.key') }}\"\n      no_log: true\n      when:\n        - consul_raw_key is not defined\n\n    - name: Delete gossip encryption key file\n      file:\n        path: '/tmp/consul_raw.key'\n        state: absent\n      become: false\n      vars:\n        ansible_become: false\n      run_once: true\n      delegate_to: localhost\n      changed_when: false\n  no_log: true\n  when:\n    - consul_encrypt_enable | bool\n\n- name: Create ACL configuration\n  include_tasks: acl.yml\n  when: consul_acl_enable | bool\n\n- name: Create Consul configuration\n  import_tasks: config.yml\n\n- name: Create TLS configuration\n  include_tasks: tls.yml\n  when: consul_tls_enable | bool\n\n- name: Create syslog configuration\n  import_tasks: syslog.yml\n\n- name: Create BSD init script\n  template:\n    src: consul_bsdinit.j2\n    dest: /etc/rc.d/consul\n    owner: root\n    group: wheel\n    mode: 0755\n  when: ansible_os_family == \"FreeBSD\"\n\n- name: Create SYSV init script\n  template:\n    src: consul_sysvinit.j2\n    dest: /etc/init.d/consul\n    owner: root\n    group: root\n    mode: 0755\n  when:\n    - not ansible_service_mgr == \"systemd\"\n    - not ansible_os_family == \"Debian\"\n    - not ansible_os_family == \"FreeBSD\"\n    - not ansible_os_family == \"Solaris\"\n\n- name: Create Debian init script\n  template:\n    src: consul_debianinit.j2\n    dest: /etc/init.d/consul\n    owner: root\n    group: root\n    mode: 0755\n  when:\n    - not ansible_service_mgr == \"systemd\"\n    - ansible_os_family == \"Debian\"\n    - not ansible_os_family == \"FreeBSD\"\n    - not ansible_os_family == \"Solaris\"\n\n- name: Create systemd script\n  template:\n    src: consul_systemd.service.j2\n    dest: /lib/systemd/system/consul.service\n    owner: root\n    group: root\n    mode: 0644\n  register: systemd_unit\n  notify: restart consul\n  when:\n    - ansible_service_mgr == \"systemd\"\n    - not ansible_os_family == \"FreeBSD\"\n    - not ansible_os_family == \"Solaris\"\n\n- name: Reload systemd\n  systemd:\n    daemon_reload: true\n  when: systemd_unit is changed\n\n- name: Create smf manifest\n  template:\n    src: consul_smf_manifest.j2\n    dest: \"{{ consul_smf_manifest }}\"\n    owner: root\n    group: root\n    mode: 0644\n  when: ansible_os_family == \"Solaris\"\n  register: smfmanifest\n\n- name: Import smf manifest\n  shell: \"svccfg import {{ consul_smf_manifest }}\"\n  when:\n    - smfmanifest is changed\n    - ansible_os_family == \"Solaris\"\n  tags: skip_ansible_lint\n- name: Import smf script\n  shell: \"svcadm refresh consul\"\n  when:\n    - smfmanifest is changed\n    - ansible_os_family == \"Solaris\"\n  tags: skip_ansible_lint\n\n- name: Enable Consul Snapshots on servers\n  include_tasks: snapshot.yml\n  when:\n    - ansible_service_mgr == \"systemd\"\n    - not ansible_os_family == \"FreeBSD\"\n    - not ansible_os_family == \"Solaris\"\n    - consul_snapshot | bool\n\n- block:\n\n    - name: Start Consul\n      service:\n        name: consul\n        state: started\n        enabled: true\n\n    - name: Check Consul HTTP API (via TCP socket)\n      wait_for:\n        delay: 15\n        port: \"{{ consul_ports.http|int }}\"\n        host: \"{{ consul_addresses.http }}\"\n      when: (consul_ports.http|int > -1) and (consul_addresses.http|ipaddr)\n\n    - name: Check Consul HTTP API (via unix socket)\n      wait_for:\n        delay: 15\n        path: \"{{ consul_addresses.http | replace('unix://', '', 1) }}\"\n      when: consul_addresses.http is match(\"unix://*\")\n\n    - name: Create bootstrapped state file\n      file:\n        dest: \"{{ consul_bootstrap_state }}\"\n        state: touch\n\n    - include_tasks: ../tasks/iptables.yml\n      when: consul_iptables_enable | bool\n\n  when: not bootstrap_state.stat.exists\n\n- include_tasks: ../tasks/dnsmasq.yml\n  when: consul_dnsmasq_enable | bool\n"}, {"commit_sha": "af3dfdf7cf37437f5609f1a12e4ac7cbaebd4867", "sha": "333ff805c701bae0dd81623a3c20b5f77e0b5fbb", "filename": "roles/dnsmasq/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for dnsmasq\n- name: remove dnsmasq override\n  file:\n    path: /etc/init/dnsmasq.override\n    state: absent\n  notify:\n    - restart dnsmasq\n  tags:\n    - dnsmasq\n\n- name: ensure dnsmasq is running (and enable it at boot)\n  service:\n    name: dnsmasq\n    state: started\n    enabled: yes\n  tags:\n    - dnsmasq\n\n- name: configure dnsmasq\n  sudo: yes\n  template:\n    src: 10-consul.j2\n    dest: /etc/dnsmasq.d/10-consul\n    owner: root\n    group: root\n    mode: 0644\n  notify:\n    - restart dnsmasq\n  tags:\n    - dnsmasq\n"}, {"commit_sha": "e8eb28b4b4b1c4fb2490b8198570166b9ca23ab2", "sha": "39b3b38e8725ddd142056c805057d310c48fc02f", "filename": "roles/mistral/tasks/gather_facts.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "- name: Pick Mistral branch\n  set_fact:\n    mistral_branch: \"{{ item.then }}\"\n  when: \"version | version_compare(item.if, operator='ge')\"\n  with_items: mistral_branches\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "c460d09606a3f186d380d6d258cf7615742fae2a", "filename": "roles/mistral/tasks/install_actions.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "- name: Create actions directory\n  sudo: true\n  file:\n    path: /etc/mistral/actions\n    state: directory\n\n- name: Clone Mistral actions repo\n  sudo: true\n  git:\n    repo: https://github.com/StackStorm/st2mistral.git\n    version: \"{{ mistral_branch }}\"\n    dest: /etc/mistral/actions/st2mistral\n\n- name: Install Mistral actions\n  sudo: true\n  shell: /opt/openstack/mistral/.venv/bin/python setup.py install\n  args:\n    chdir: /etc/mistral/actions/st2mistral\n"}, {"commit_sha": "6d51642c8f7babe4c8185b60872420333a5d3caa", "sha": "8f964796611995ebe03b702bc1933eaa87c12861", "filename": "tasks/plugins.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/plugins.yml: Deploy available checks/plugins/handlers/filters/mutators\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure Sensu plugin directory exists\n    file:\n      dest: \"{{ sensu_config_path }}/plugins\"\n      state: directory\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n\n  - name: Ensure any remote plugins defined are present\n    shell: sensu-install -p {{ item }}\n    with_items: sensu_remote_plugins\n    changed_when: false\n    when: sensu_remote_plugins > 0\n\n  - name: Register available checks\n    local_action: command ls {{ static_data_store }}/sensu/checks\n    register: sensu_available_checks\n    changed_when: false\n    become: false\n\n  - name: Deploy check plugins\n    copy:\n      src: \"{{ static_data_store }}/sensu/checks/{{ item }}/\"\n      dest: \"{{ sensu_config_path }}/plugins/\"\n      mode: 0755\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    when: \"'{{ item }}' in sensu_available_checks.stdout_lines\"\n    with_flattened:\n      - group_names\n    notify: restart sensu-client service\n\n  - name: Deploy handler plugins\n    copy:\n      src: \"{{ static_data_store }}/sensu/handlers/\"\n      dest: \"{{ sensu_config_path }}/plugins/\"\n      mode: 0755\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    notify: restart sensu-client service\n\n  - name: Deploy filter plugins\n    copy:\n      src: \"{{ static_data_store }}/sensu/filters/\"\n      dest: \"{{ sensu_config_path }}/plugins/\"\n      mode: 0755\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    notify: restart sensu-client service\n\n  - name: Deploy mutator plugins\n    copy:\n      src: \"{{ static_data_store }}/sensu/mutators/\"\n      dest: \"{{ sensu_config_path }}/plugins/\"\n      mode: 0755\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    notify: restart sensu-client service\n\n  - name: Deploy check/handler/filter/mutator definitions to the master\n    template:\n      src: \"{{ item }}\"\n      dest: \"{{ sensu_config_path }}/conf.d/{{ item | basename | regex_replace('.j2', '')}}\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    when: sensu_master\n    with_fileglob:\n      - \"{{ static_data_store }}/sensu/definitions/*\"\n    notify:\n      - restart sensu-server service\n      - restart sensu-api service\n"}, {"commit_sha": "584d564218d6e2e63d3ecca157daf817fe4d533c", "sha": "7bc8caca4b1c764cd7509e52bb9b8cfc36f65fad", "filename": "tasks/security_check.yml", "repository": "mikolak-net/ansible-raspi-config", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n- name: ensure utility present\n  apt: name=sshpass state=present\n- name: check for login\n  command: sshpass -p {{raspi_config_auth_test_password}} ssh {{raspi_config_auth_test_username}}@localhost -o NoHostAuthenticationForLocalhost=yes \"echo {{raspi_config_auth_test_string}}\"\n  register: auth_test\n  changed_when: False\n  failed_when: False\n- name: optional warning\n  debug: msg=\"{{raspi_config_auth_test_fail_msg}}\"\n  when: \"raspi_config_auth_test_string == auth_test.stdout\"\n  changed_when: \"raspi_config_auth_test_string == auth_test.stdout\" # for highlighting purposes\n  failed_when: \"raspi_config_fail_on_auth_test and raspi_config_replace_user['name'] == ''\"\n- name: additional info\n  debug: msg=\"{{raspi_config_auth_test_replace_info}}\"\n  when: \"raspi_config_auth_test_string == auth_test.stdout and raspi_config_replace_user['name'] != ''\""}, {"commit_sha": "0f46bc2b1f4dac71c882be0ee48a25332a90ed40", "sha": "da43529dfb132726a9c59f4b2550e6dea4267893", "filename": "roles/dnsmasq/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks file for dnsmasq\n- name: remove dnsmasq override\n  command: /bin/rm -f /etc/init/dnsmasq.override\n\n- name: ensure dnsmasq is running (and enable it at boot)\n  service: name=dnsmasq state=started enabled=yes\n"}, {"commit_sha": "92d2f38d01d7b33610c667cfdc03e28ab2912edc", "sha": "b99e071d3191e7190ca8dc8ebd0adc4ee1089c58", "filename": "tasks/section_09_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 9.1.1.1 Check that cron conf file exists (check) (Scored)\n    stat: path=/etc/init/cron.conf\n    register: cron_conf_stat\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.1\n\n  - name: 9.1.1.2 Enable cron Daemon (Scored)\n    service: >\n        name=cron\n        state=started\n        enabled=yes\n    when: not cron_conf_stat.stat.exists\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.2\n\n  - name: 9.1.2 Set User/Group Owner and Permission on /etc/crontab (Scored)\n    file: path='/etc/crontab' owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.2\n\n  - name: 9.1.3 Set User/Group Owner and Permission on /etc/cron.hourly (Scored)\n    file: path=/etc/cron.hourly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.3\n\n  - name: 9.1.4 Set User/Group Owner and Permission on /etc/cron.daily (Scored)\n    file: path=/etc/cron.daily owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.4\n\n  - name: 9.1.5 Set User/Group Owner and Permission on /etc/cron.weekly (Scored)\n    file: path=/etc/cron.weekly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.5\n\n  - name: 9.1.6 Set User/Group Owner and Permission on /etc/cron.monthly (Scored)\n    file: path=/etc/cron.monthly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.6\n\n  - name: 9.1.7 Set User/Group Owner and Permission on /etc/cron.d (Scored)\n    file: path=/etc/cron.d owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.7\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (remove deny) (Scored)\n    file: path={{ item }} state=absent\n    with_items:\n        - /etc/cron.deny\n        - /etc/at.deny\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (create cron allow) (Scored)\n    copy:\n        dest: /etc/cron.allow\n        owner: root\n        group: root\n        mode: \"og-rwx\"\n        content: \"\"\n        force: no\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (create at allow) (Scored)\n    copy:\n        dest: /etc/at.allow\n        owner: root\n        group: root\n        mode: \"og-rwx\"\n        content: \"\"\n        force: no\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.2.1 Set Password Creation Requirement Parameters Using pam_cracklib (install) (Scored)\n    apt: name=libpam-cracklib state=present\n    when: use_pam_cracklib == True\n    tags:\n      - section9\n      - section9.2\n      - section9.2.1\n\n  - name: 9.2.1 Set Password Creation Requirement Parameters Using pam_cracklib (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password'\n        regexp=\"pam_cracklib.so\"\n        line=\"password required pam_cracklib.so retry=3 minlen=14 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1\"\n        state=present\n    when: use_pam_cracklib == True\n    tags:\n      - section9\n      - section9.2\n      - section9.2.1\n\n#Note for section 9.2.2:\n#If a user has been locked out because they have reached the maximum consecutive failure count\n#defined by denied= in the pam_tally2.so module, the user can be unlocked by issuing the command\n#/sbin/pam_tally2 -u username --reset\n#This command sets the failed count to 0, effectively unlocking the user\n  - name: 9.2.2 Set Lockout for Failed Password Attempts (Not Scored)\n    lineinfile: >\n        dest='/etc/pam.d/login'\n        regexp='pam_tally2'\n        line=\"auth required pam_tally2.so onerr=fail audit silent deny=5 unlock_time=900\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.2\n\n  - name: 9.2.3 Limit Password Reuse (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password'\n        regexp='remember=5'\n        line=\"password sufficient pam_unix.so remember=5\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.3\n\n  - name: 9.3 Check if ssh is installed (check) (Not Scored)\n    stat: path='/etc/ssh/sshd_config'\n    register: ssh_config_file\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n  - include: section_09_level1_03.yml\n    when: ssh_config_file.stat.exists == True\n\n  - name: 9.4 Restrict root Login to System Console (stat securetty) (Not Scored)\n    stat: path=/etc/securetty\n    register: securetty_file\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.4 Restrict root Login to System Console (Not Scored)\n    debug: msg='*** Check /etc/securetty for console allowed for root access ***'\n    when: securetty_file.stat.exists == True\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.5.1 Restrict Access to the su Command (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/su'\n        line='auth            required        pam_wheel.so use_uid'\n        state=present\n    tags:\n      - section9\n      - section9.5\n      - section9.5.1\n"}, {"commit_sha": "f565940c5163524c7834123625c804e5f69c2b10", "sha": "e2d7de358f73433c45a79f02ecebb9baf762d476", "filename": "tasks/Amazon/dashboard.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/Amazon/dashboard.yml: Deployment of the Uchiwa dashboard\n# Specific to CentOS\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure Uchiwa is installed\n    yum:\n      name: \"{{ uchiwa_pkg_rpm_download_url }}\"\n      state: present\n\n  - name: Deploy Uchiwa config\n    template:\n      src: uchiwa_config.json.j2\n      dest: \"{{ sensu_config_path }}/uchiwa.json\"\n    notify: restart uchiwa service\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "721472d64b008cd88ea32a8d1d95df8f4128d3f6", "filename": "roles/consul/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for consul\nconsul_dc: dc1\nconsul_servers_group: consul_servers\nconsul_advertise: \"{{ ansible_ssh_host }}\"\nconsul_bind_addr: \"{{ ansible_default_ipv4.address }}\"\nconsul_retry_join: \"{% for host in groups[consul_servers_group] %}\\\"{{ hostvars[host].ansible_default_ipv4.address }}\\\"{% if not loop.last %}, {% endif %}{% endfor %}\"\nconsul_bootstrap_expect: \"{{ groups[consul_servers_group] | length }}\"\nconsul_client_addr: \"0.0.0.0\"\nconsul_atlas_join: false\nconsul_node_name: \"{{ ansible_hostname }}\"\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "a7598e1defa852bc99d1b3f2566b85b412e246b8", "filename": "roles/haproxy/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for haproxy\n- name: \"assures {{ consul_template_dir }} dirs exists\"\n  file:\n    path: \"{{ consul_template_dir }}/{{ item.path }}\"\n    state: directory\n  with_items:\n    - { path: 'config' }\n    - { path: 'templates' }\n  tags:\n    - haproxy\n\n- name: upload template config files\n  template:\n    src: consul.cfg.j2\n    dest: \"{{ consul_template_dir }}/config/consul.cfg\"\n    mode: 0644\n  sudo: yes\n  tags:\n    - haproxy\n\n- name: upload static config files\n  copy:\n    src: \"{{ item.src }}\"\n    dest: \"{{ consul_template_dir }}/{{ item.dst }}\"\n    mode: 0644\n  sudo: yes\n  with_items:\n    - { src: haproxy.cfg, dst: 'config/haproxy.cfg' }\n    - { src: haproxy.tmpl, dst: 'templates/haproxy.tmpl' }\n  tags:\n    - haproxy\n\n- name: destroy old haproxy container\n  when: haproxy_rebuild_container\n  docker:\n    name: haproxy\n    image: \"{{ haproxy_image }}\"\n    state: absent\n\n- name: run haproxy container\n  docker:\n    name: haproxy\n    image: \"{{ haproxy_image }}\"\n    state: started\n    net: host\n    restart_policy: always\n    ports:\n      - \"80:80\"\n      - \"34180:34180\"\n    env:\n      HAPROXY_DOMAIN: \"{{ haproxy_domain }}\"\n      CONSUL_TEMPLATE_VERSION: \"{{ consul_template_version }}\"\n      CONSUL_LOGLEVEL: \"{{ consul_template_loglevel }}\"\n      CONSUL_CONNECT: \"{{ consul_backend }}\"\n      CONSUL_CONFIG: \"/config\"\n      SERVICE_NAME: haproxy\n    volumes:\n    - \"{{ consul_template_dir }}/config:/config\"\n    - \"{{ consul_template_dir }}/templates:/templates\"\n  tags:\n    - haproxy\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "8171897b37aff256c8e12221d32ec8d0559cd7de", "filename": "roles/serverspec/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for serverspec\n\n- name: upload serverspecs\n  synchronize:\n    src: ../../../tests\n    dest: \"{{ serverspec_tests_path }}\"\n    recursive: yes\n    delete: yes\n  when: serverspec_install_bundler|bool and serverspec_upload_folder|bool\n  tags:\n    - serverspec\n\n- name: upload marathon runtime serverspecs\n  template:\n    src: marathon_runtime_spec.rb.j2\n    dest: \"{{ serverspec_tests_path }}/tests/spec/marathon/marathon_runtime_spec.rb\"\n    mode: 0755\n  sudo: yes\n  when: serverspec_upload_folder|bool\n  tags:\n    - serverspec\n\n- name: install bundler\n  sudo: yes\n  command: gem install bundler --no-ri --no-rdoc\n  args:\n    creates: /usr/local/bin/bundler\n  when: serverspec_install_bundler|bool\n  tags:\n    - serverspec\n\n- name: install bundle files\n  sudo: yes\n  command: bundle install --path vendor\n  args:\n    chdir: \"{{ serverspec_tests_path }}/tests\"\n    creates: \"{{ serverspec_tests_path }}/tests/vendor\"\n  tags:\n    - serverspec\n\n- name: run serverspec tests\n  sudo: yes\n  command: \"bundle exec rake serverspec:{{ test_role }}\"\n  args:\n    chdir: \"{{ serverspec_tests_path }}/tests\"\n  when: test_role is defined\n  tags:\n    - serverspec\n"}, {"commit_sha": "80530fde7df1a94ad361434e02816b0816a2c47a", "sha": "ce89572f81ad8fe540ea373a5bf239b7605a1208", "filename": "roles/consul/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# handlers file for consul\n- name: Restart consul\n  shell: restart consul\n  sudo: yes\n\n- name: Start consul\n  shell: start consul\n  sudo: yes\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "3806b4c7ec0eb34f6909062906b41182717e89aa", "filename": "roles/docker/vars/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# vars file for docker\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "08dafb21195907a51cb93e7a68d0f61f328077c4", "filename": "roles/weave/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for weave\nweave_server_group: weave_servers\nweave_launch_peers: \"{% for host in groups[weave_server_group] %}{% if host != inventory_hostname %}{{ hostvars[host].ansible_default_ipv4.address }} {% endif %}{% endfor %}\"\nweave_version: 1.4.4\nweave_url: \"https://github.com/weaveworks/weave/releases/download/v{{ weave_version }}/weave\"\nweave_bin: /mnt/weave\n\n# scope\nscope_url: https://github.com/weaveworks/scope/releases/download/latest_release/scope\nscope_bin: /mnt/scope\n"}, {"commit_sha": "9966c6de1ed4ef5071a9bea83b4bb69a11dd32ba", "sha": "6728c21020d35ab3b34e9bbcb0feb554083f72ff", "filename": "roles/mesos/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for mesos\n- name: Start mesos master\n  shell: start mesos-master\n  sudo: yes\n\n- name: Start mesos slave\n  shell: start mesos-slave\n  sudo: yes\n\n- name: Restart mesos master\n  shell: restart mesos-master\n  sudo: yes\n\n- name: Restart mesos slave\n  shell: restart mesos-slave\n  sudo: yes\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "2242c87a15ee042fb3aa759e5b7449b9edc2aa82", "filename": "tasks/section_08_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n# Change order or the default auditd.conf file will not be created\n  - name: 8.1.2 Install and Enable auditd Service (Scored)\n    apt: name=auditd state=present\n    tags:\n      - section8\n      - section8.1\n      - section8.1.2\n      - section8.1.2\n\n  - name: 8.1.1-3.1 Check if the file auditd.conf exists (Not Scored)\n    stat: >\n        path=/etc/audit/auditd.conf\n    register: auditd_file\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n      - section8.1.1.2\n      - section8.1.1.3\n\n  - name: 8.1.1-3.2 Create the audit directory if it does not exists (Not Scored)\n    file: >\n        path=/etc/audit/\n        state=directory\n    when: not auditd_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n      - section8.1.1.2\n      - section8.1.1.3\n\n  - name: 8.1.1-3.3 Configure Data Retention (Not Scored)\n    lineinfile: >\n        dest=/etc/audit/auditd.conf\n        regexp=\"{{ item.rxp }}\"\n        line=\"{{ item.line }}\"\n        state=present\n        create=yes\n    with_items:\n      - { rxp: '^max_log_file ', line: 'max_log_file = {{ max_log_file_auditd }}' }\n      - { rxp: '^space_left_action', line: 'space_left_action = email' }\n      - { rxp: '^action_mail_acct', line: 'action_mail_acct = root' }\n      - { rxp: '^admin_space_left_action', line: 'admin_space_left_action = halt' }\n      - { rxp: '^max_log_file_action', line: 'max_log_file_action = keep_logs' }\n    notify: restart auditd\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n      - section8.1.1.2\n      - section8.1.1.3\n\n  - name: 8.1.3.1 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    stat: path=/etc/default/grub\n    register: grubcfg_file\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.3.2 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    file: >\n        path=/etc/default/grub\n        state=touch\n    when: not grubcfg_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.3.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    lineinfile: >\n        dest=/etc/default/grub\n        line='GRUB_CMDLINE_LINUX=\"audit=1\"'\n    when: not grubcfg_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.4.1 Record Events That Modify Date and Time Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a always,exit -F arch=b64 -S adjtimex -S settimeofday -k time-change'\n      - '-a always,exit -F arch=b32 -S adjtimex -S settimeofday -S stime -k time-change'\n      - '-a always,exit -F arch=b64 -S clock_settime -k time-change'\n      - '-a always,exit -F arch=b32 -S clock_settime -k time-change'\n      - '-w /etc/localtime -p wa -k time-change'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"64\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.4\n\n  - name: 8.1.4.2 Record Events That Modify Date and Time Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a always,exit -F arch=b32 -S adjtimex -S settimeofday -S stime -k time-change'\n      - '-a always,exit -F arch=b32 -S clock_settime -k time-change'\n      - '-w /etc/localtime -p wa -k time-change'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"32\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.4\n\n  - name: 8.1.5,7,8,9,15,16,17 Record Events That Modify User/Group Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-w /etc/group -p wa -k identity'\n      - '-w /etc/passwd -p wa -k identity'\n      - '-w /etc/gshadow -p wa -k identity'\n      - '-w /etc/shadow -p wa -k identity'\n      - '-w /etc/security/opasswd -p wa -k identity'\n      - '-w /var/log/faillog -p wa -k logins'\n      - '-w /var/log/lastlog -p wa -k logins'\n      - '-w /var/log/tallylog -p wa -k logins'\n      - '-w /var/run/utmp -p wa -k session'\n      - '-w /var/log/wtmp -p wa -k session'\n      - '-w /var/log/btmp -p wa -k session'\n      - '-w /etc/selinux/ -p wa -k MAC-policy'\n      - '-w /etc/sudoers -p wa -k scope'\n      - '-w /var/log/sudo.log -p wa -k actions'\n      - '-w /sbin/insmod -p x -k modules'\n      - '-w /sbin/rmmod -px -k modules'\n      - '-w /sbin/modprobe -p x -k modules'\n    notify: restart auditd\n    tags:\n      - section8\n      - section8.1\n      - section8.1.5\n      - section8.1.7\n      - section8.1.8\n      - section8.1.9\n      - section8.1.15\n      - section8.1.16\n      - section8.1.17\n\n  - name: 8.1.6,10,11,13,14,17.1 Record Events That Modify the System's Network Environment (64b) (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a exit,always -F arch=b64 -S sethostname -S setdomainname -k system-locale'\n      - '-a exit,always -F arch=b32 -S sethostname -S setdomainname -k system-locale'\n      - '-w /etc/issue -p wa -k system-locale'\n      - '-w /etc/issue.net -p wa -k system-locale'\n      - '-w /etc/hosts -p wa -k system-locale'\n      - '-w /etc/network -p wa -k system-locale'\n      - '-a always,exit -F arch=b64 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b64 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b64 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b32 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b64 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b32 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b64 -S init_module -S delete_module -k modules'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"64\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.6\n      - section8.1.10\n      - section8.1.11\n      - section8.1.13\n      - section8.1.14\n      - section8.1.17\n\n  - name: 8.1.6,10,11,13,14,17.2 Record Events That Modify the System's Network Environment (32b) (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a exit,always -F arch=b32 -S sethostname -S setdomainname -k system-locale'\n      - '-w /etc/issue -p wa -k system-locale'\n      - '-w /etc/issue.net -p wa -k system-locale'\n      - '-w /etc/hosts -p wa -k system-locale'\n      - '-w /etc/network -p wa -k system-locale'\n      - '-a always,exit -F arch=b32 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b32 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b32 -S init_module -S delete_module -k modules'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"32\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.6\n      - section8.1.10\n      - section8.1.11\n      - section8.1.13\n      - section8.1.14\n      - section8.1.17\n\n  - name: 8.3.1.1 Install AIDE (Scored)\n    apt: name=aide state=present\n    register: aide_installed\n    when: use_aide == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1.2 Install AIDE (init) (Scored)\n    command: aideinit\n    when:\n      - use_aide == True\n      - aide_installed.changed == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1.3 Install AIDE (Scored)\n    stat: path=/var/lib/aide/aide.db.new\n    register: aide_db_path\n    when:\n      - use_aide == True\n      - aide_installed.changed == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1.4 Install AIDE (copy db) (Scored)\n    command: mv /var/lib/aide/aide.db.new /var/lib/aide/aide.db\n    when:\n      - use_aide == True\n      - aide_installed.changed == True\n      - aide_db_path.stat.exists == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.2 Implement Periodic Execution of File Integrity (Scored)\n    cron: name=\"Check files integrity\" minute=\"0\" hour=\"5\" job=\"/usr/sbin/aide --check\"\n    when: use_aide == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.2\n\n  # We have to run the check after AIDE installation as postfix create new matched binaries\n  - name: 8.1.12.1 Collect Use of Privileged Commands (Scored)\n    shell: find / -xdev \\( -perm -4000 -o -perm -2000 \\) -type f | awk '{print \"-a always,exit -F path=\" $1 \" -F perm=x -F auid>=500 -F auid!=4294967295 -k privileged\" }'\n    register: audit_lines_for_find\n    changed_when: False\n    tags:\n      - section8\n      - section8.1\n      - section8.1.12\n\n  - name: 8.1.12.2 Collect Use of Privileged Commands (infos) (Scored)\n    lineinfile: >\n        dest=/etc/audit/audit.rules\n        line='{{ item }}'\n        state=present\n        create=yes\n    with_items: audit_lines_for_find.stdout_lines\n    tags:\n      - section8\n      - section8.1\n      - section8.1.12\n\n  - name: 8.1.18 Make the Audit Configuration Immutable (Scored)\n    lineinfile: >\n        dest='/etc/audit/audit.rules'\n        line='-e 2'\n        insertafter=EOF\n        state=present\n        create=yes\n    tags:\n      - section8\n      - section8.1\n      - section8.1.18\n"}, {"commit_sha": "f565940c5163524c7834123625c804e5f69c2b10", "sha": "e5e320efa8cfcaa6f19f8dea4d1bd92cd83a0f5c", "filename": "tasks/CentOS/main.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/CentOS/main.yml: CentOS specific set-up\n# This takes care of base prerequisites for CentOS\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure the Sensu Core Yum repo is present\n    copy:\n      dest: /etc/yum.repos.d/sensu.repo\n      content: |\n        [sensu]\n        name=sensu\n        baseurl=http://repositories.sensuapp.org/yum/$basearch/\n        gpgcheck=0\n        enabled=1\n      owner: root\n      group: root\n      mode: 0644\n\n  - name: Ensure Sensu is installed\n    yum: name={{ sensu_package }} state={{ sensu_pkg_state }}\n"}, {"commit_sha": "e8eb28b4b4b1c4fb2490b8198570166b9ca23ab2", "sha": "77ac3c8ad0b0853ce18322f520a92752eb7f49b0", "filename": "roles/st2/tasks/2.version.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "# StackStorm version checks and facts gathering\n# TODO: Rework as lookup plugin when Ansible 2.0 available: https://groups.google.com/forum/#!msg/ansible-devel/MF4TY-wa9Ww/mL9sVSMd5DwJ\n---\n- name: version | Lookup literal version\n  shell: >\n    curl -Ss -q https://downloads.stackstorm.net/deb/pool/trusty_{{ st2_version }}/main/s/st2api/ |\n    grep 'amd64.deb' |\n    sed -e \"s~.*>st2api_\\(.*\\)-.*<.*~\\1~g\" |\n    sort --version-sort -r |\n    uniq | head -n 1\n  when: st2_version == 'stable' or st2_version == 'unstable'\n  register: _st2_version\n  delegate_to: 127.0.0.1\n  changed_when: False\n  tags: [st2, version]\n\n- name: version | Save version number to install\n  set_fact: _st2_version=\"{{ _st2_version.stdout | default(st2_version) }}\"\n  tags: [st2, version]\n\n- name: version | Check that specified st2 version is available\n  uri:\n    url: \"https://downloads.stackstorm.net/releases/st2/{{ _st2_version }}/\"\n    status_code: 200\n  when: st2_version == _st2_version\n  delegate_to: 127.0.0.1\n  tags: [st2, version]\n\n- name: version | Lookup StackStorm revision to install\n  set_fact:\n    _st2_revision: \"{{ lookup('url', 'https://downloads.stackstorm.net/releases/st2/' + _st2_version + '/debs/' + st2_revision + '/VERSION.txt') }}\"\n  when: st2_revision == 'current'\n  tags: [st2, version]\n\n- name: version | Gather StackStorm package info\n  command: dpkg -s st2common\n  register: _st2_package_info\n  changed_when: no\n  ignore_errors: yes\n  tags: [st2, version]\n\n- name: version | Check if StackStorm is already installed\n  set_fact:\n    _st2_is_installed: \"{{ _st2_package_info.rc == 0 }}\"\n  tags: [st2, version]\n\n- name: version | Get installed StackStorm version and revision\n  set_fact:\n    _st2_installed_version: \"{{ _st2_package_info.stdout|regex_replace('[\\\\s\\\\S]*Version: (.*)-\\\\S+\\\\n[\\\\s\\\\S]*', '\\\\\\\\1') }}\"\n    _st2_installed_revision: \"{{ _st2_package_info.stdout|regex_replace('[\\\\s\\\\S]*Version: \\\\S+-(.*)\\\\n[\\\\s\\\\S]*', '\\\\\\\\1') }}\"\n  when: _st2_is_installed\n  tags: [st2, version]\n"}, {"commit_sha": "9eb1a8fa8e281ef06687c1851f51fa0beec3e232", "sha": "e6f5ecf3f5c972a89ddd5c7d26febdbe57158fe2", "filename": "tasks/section_02_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 2.1 Create Separate Partition for /tmp (Scored)\n    command: grep '\\s/tmp\\s' /etc/fstab\n    register: tmp_partition\n    failed_when: tmp_partition.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section2\n      - section2.1\n\n  - name: 2.2 - 4 Set nodev, nosuid, noexec option for /tmp Partition (Scored)\n    mount: name=\"/tmp\" src=\"/tmp\" state=\"mounted\" opts=\"nodev,nosuid,noexec\" fstype=ext4\n    when: partitioning == True\n    tags:\n      - section2\n      - section2.2\n      - section2.3\n      - section2.4\n\n  - name: 2.5 Create Separate Partition for /var (Scored)\n    command: grep '\\s/var\\s' /etc/fstab\n    register: var_partition\n    failed_when: var_partition.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section2\n      - section2.5\n\n  - name: 2.6 Bind Mount the /var/tmp directory to /tmp (Scored)\n    mount: name=\"/var/tmp\" src=\"/tmp\" opts=bind state=mounted fstype=ext4\n    when: partitioning == True\n    tags:\n      - section2\n      - section2.6\n\n  - name: 2.7 Create Separate Partition for /var/log (Scored)\n    command: grep '\\s/var\\/log\\s' /etc/fstab\n    register: var_log_partition\n    failed_when: var_log_partition.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section2\n      - section2.7\n\n  - name: 2.8 Create Separate Partition for /var/log/audit (Scored)\n    command: grep '\\s/var\\/log\\/audit\\s' /etc/fstab\n    register: var_log_audit_partition\n    failed_when: var_log_audit_partition.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section2\n      - section2.8\n\n  - name: 2.9 Create Separate Partition for /home (Scored)\n    command: grep '\\s/home\\s' /etc/fstab\n    register: home_partition\n    failed_when: home_partition.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section2\n      - section2.9\n\n  - name: 2.10 Add nodev Option to /home (Scored)\n    mount: name=\"/home\" src=\"/home\" state=mounted opts=remount,nodev fstype=\"ext4\"\n    when: partitioning == True\n    tags:\n      - section2\n      - section2.10\n\n  - name: 2.11 Add nodev Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nodev option\"\n    tags:\n      - section2\n      - section2.11\n\n  - name: 2.12 Add noexec Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have noexec option\"\n    tags:\n      - section2\n      - section2.12\n\n  - name: 2.13 Add nosuid Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nosuid option\"\n    tags:\n      - section2\n      - section2.13\n\n  - name: 2.14 - 16 Add nodev Option to /run/shm Partition (Scored)\n    mount: name=\"/run/shm\" src=\"/run/shm\" state=\"mounted\" opts=\"nodev,nosuid,noexec\" fstype=\"tmpfs\"\n    when: run_shm_read_only == False\n    tags:\n      - section2\n      - section2.14\n      - section2.15\n      - section2.16\n\n  - name: 2.17.1 Set Sticky Bit on All World-Writable Directories (preparation) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type d -perm -0002 -print 2>/dev/null\n    failed_when: False\n    changed_when: False\n    always_run: True\n    register: sticky_bit_dirs\n    tags:\n      - section2\n      - section2.17\n      - section2.17.1\n\n  - name: 2.17.2 Set Sticky Bit on All World-Writable Directories (Scored)\n    file:\n        path: \"{{ item }}\"\n        mode: \"a+t\"\n    with_items: sticky_bit_dirs.stdout_lines\n    tags:\n      - section2\n      - section2.17\n      - section2.17.2\n\n  - name: 2.25 Disable Automounting (stat) (Scored)\n    stat: >\n        path=/etc/init/autofs.conf\n    register: autofs_file\n    tags:\n      - section2\n      - section2.25\n      \n  - name: 2.25 Disable Automounting (Scored)\n    lineinfile: >\n        dest=/etc/init/autofs.conf\n        line='#start on runlevel [2345]'\n        regexp='start on runlevel'\n        state=present\n    when: autofs_file.stat.exists == True\n    tags:\n      - section2\n      - section2.25\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "5470a77e8443d42b2ffe0e3c2fb2379466396f8b", "filename": "tasks/CentOS/rabbit.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/CentOS/rabbit.yml: Deploy RabbitMQ\n# Specific to CentOS\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure Erlang & RabbitMQ are installed\n    yum:\n      name:\n        - erlang\n        - rabbitmq-server\n      state: present\n      enablerepo: \"{{ centos_repository }}\"\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "f6845be93c2994bf102e8410c3ef1ee88993b4e8", "filename": "roles/mistral/tasks/install_client.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "- name: Install Mistral client\n  sudo: true\n  pip:\n    name: ''\n    extra_args: '-U git+https://github.com/StackStorm/python-mistralclient.git@{{ mistral_branch }}'\n"}, {"commit_sha": "694a4890fcf0daa375d6a173511f6ff7dd0f2335", "sha": "990e5b7afc211e99c8dfe7ef65a45c5645b54ae3", "filename": "tasks/openbsd_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Setup OpenBSD specific variables (set_fact)\n  set_fact:\n    tor_DataDir: /var/tor-instances\n    tor_ConfDir: /etc/tor/enabled\n  tags:\n   - reconfigure\n   - renewkey\n   - createdir\n\n- name: Ensure Tor is installed (OpenBSD)\n  become: yes\n  openbsd_pkg: name=tor state=present\n  tags:\n   - install\n\n- name: Gather current system-wide file descriptor limits (OpenBSD)\n  shell: \"sysctl kern.maxfiles|cut -d= -f2\"\n  register: currentlimits\n\n- name: Ensure system-wide runtime file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  command: \"sysctl kern.maxfiles=20000\"\n  when: currentlimits.stdout|int < 20000\n\n- name: Ensure system-wide persistent file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  lineinfile: dest=/etc/sysctl.conf regexp=^kern.maxfiles line=\"kern.maxfiles=20000\" create=yes\n  when: currentlimits.stdout|int < 20000\n\n# We rise openfiles limits for every tor instance separately.\n# An instance is identified by its rc.d file name.\n- name: Ensure Tor process file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  lineinfile: \"dest=/etc/login.conf line='tor{{ item[0]| replace('.','_') }}_{{ item.1.orport }}::openfiles-max=13500::tc=daemon:'\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "5a5a190af8073fa9acadf7f81cb055493e544d80", "filename": "roles/docker/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for docker\n- name: restart docker\n  service:\n   name: docker\n   state: restarted\n  sudo: yes\n"}, {"commit_sha": "59bde5ac149cca3058d0b8a8bd4b2d0e21e8c861", "sha": "f2addede9fef134507b37ba1f3b153d3b05da88c", "filename": "tasks/section_06_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 6.1 Ensure the X Window system is not installed (Scored)\n    apt: name=xserver-xorg-core* purge=yes state=absent\n    tags:\n      - section6\n      - section6.1\n\n  - name: 6.2 Ensure Avahi Server is not enabled (check) (Scored)\n    stat: path='/etc/init/avahi-daemon.conf'\n    register: avahi_stat\n    tags:\n      - section6\n      - section6.2\n\n  - name: 6.2 Ensure Avahi Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on (filesystem'\n        state=present\n        regexp='start on (filesystem'\n        dest=/etc/init/.conf\n    when: avahi_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.2\n\n  - name: 6.3 Ensure print server is not enabled (check) (Not Scored)\n    stat: path='/etc/init/cups.conf'\n    register: cups_stat\n    tags:\n      - section6\n      - section6.3\n\n  - name: 6.3 Ensure print server is not enabled (Not Scored)\n    lineinfile: >\n        line='#start on (filesystem'\n        state=present\n        regexp='start on (filesystem'\n        dest=/etc/init/cups.conf\n    when: cups_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.3\n\n  - name: 6.4.1 Ensure DHCP Server is not enabled (check) (Scored)\n    stat: path='/etc/init/isc-dhcp-server.conf'\n    register: dhcp_stat\n    tags:\n      - section6\n      - section6.4\n      - section6.4.1\n\n  - name: 6.4.1 Ensure DHCP Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n        dest=/etc/init/isc-dhcp-server.conf\n    when: dhcp_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.4\n      - section6.4.1\n\n  - name: 6.4.2 Ensure DHCP Server is not enabled (check) (Scored)\n    stat: path='/etc/init/isc-dhcp-server6.conf'\n    register: dhcp6_stat\n    tags:\n      - section6\n      - section6.4\n      - section6.4.2\n\n  - name: 6.4.2 Ensure DHCP Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n        dest=/etc/init/isc-dhcp-server6.conf\n    when: dhcp6_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.4\n      - section6.4.2\n\n  - name: 6.5.1 Configure Network Time Protocol (install) (NTP) (Scored)\n    apt: name=ntp state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.1\n\n  - name: 6.5.2 Configure Network Time Protocol (restrict4) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='restrict -4 default kod nomodify notrap nopeer noquery'\n        regexp='^restrict -4 default'\n        state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.2\n\n  - name: 6.5.3 Configure Network Time Protocol (restrict6) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='restrict -6 default kod nomodify notrap nopeer noquery'\n        regexp='^restrict -6 default'\n        state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.3\n\n  - name: 6.5.4 Configure Network Time Protocol (server check) (NTP) (Scored)\n    command: 'grep \"^server\" /etc/ntp.conf'\n    register: ntp_server_rc\n    changed_when: False\n    always_run: True\n    tags:\n      - section6\n      - section6.5\n      - section6.5.4\n\n  - name: 6.5.4 Configure Network Time Protocol (server add) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='server 0.fr.pool.ntp.org'\n        state=present\n    when: ntp_server_rc.rc == 1\n    tags:\n      - section6\n      - section6.5\n      - section6.5.4\n\n  - name: 6.6 Ensure LDAP is not enabled (Not Scored)\n    apt: name=slapd purge=yes state=absent\n    tags:\n      - section6\n      - section6.6\n\n  - name: 6.7.1 Ensure NFS and RPC are not enabled (stat) (Not Scored)\n    stat: path=/etc/init/rpcbind-boot.conf\n    register: nfs_rpc_rc\n    tags:\n      - section6\n      - section6.7\n      - section6.7.1\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (Not Scored)\n    lineinfile: >\n        dest=/etc/init/rpcbind-boot.conf\n        line='#start on virtual-filesystems and net-device-up IFACE=lo'\n        state=present\n        regexp='start on virtual-filesystems and net'\n    when: nfs_rpc_rc.stat.exists == True\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (check) (Not Scored)\n    command: dpkg -S nfs-kernel-server\n    changed_when: False\n    failed_when: False\n    register: nfs_present\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (rc.d) (Not Scored)\n    service: >\n        name=nfs-kernel-server\n        enabled=no\n    when: nfs_present.rc == 0\n    register: nfs_service_result\n    failed_when: \"nfs_service_result|failed and 'service not found' not in nfs_service_result.msg\"\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.8-14 Ensure DNS,FTP,HTTP,IMAP,POP,Samba,Proxy,SNMP Servers are not enabled (Not Scored)\n    service: >\n        name={{ item }}\n        enabled=no\n    with_items:\n      - bind9\n      - vsftpd\n      - apache2\n      - dovecot\n      - smbd\n      - squid3\n      - snmpd\n    failed_when: False\n    tags:\n      - section6\n      - section6.8\n      - section6.9\n      - section6.10\n      - section6.11\n      - section6.12\n      - section6.13\n      - section6.14\n\n  - name: 6.15 Configure Mail Transfer Agent for Local-Only Mode (stat) (Scored)\n    stat: path=/etc/postfix/main.cf\n    register: postfix_main_cf\n    tags:\n      - section6\n      - section6.15\n\n  - name: 6.15 Configure Mail Transfer Agent for Local-Only Mode (Scored)\n    lineinfile: >\n        dest=/etc/postfix/main.cf\n        line='inet_interfaces = localhost'\n        state=present\n    when: postfix_main_cf.stat.exists == True\n    tags:\n      - section6\n      - section6.15\n\n  - name: 6.16 Ensure rsync service is not enabled (stat) (Scored)\n    stat: path=/etc/default/rsync\n    register: default_rsync\n    tags:\n      - section6\n      - section6.16\n\n  - name: 6.16 Ensure rsync service is not enabled (Scored)\n    lineinfile: >\n        dest='/etc/default/rsync'\n        regexp='^RSYNC_ENABLE'\n        line='RSYNC_ENABLE=false'\n    when: default_rsync.stat.exists == True\n    tags:\n      - section6\n      - section6.16\n\n  - name: 6.17 Ensure Biosdevname is not enabled (Scored)\n    apt: name=biosdevname purge=yes state=absent\n    tags:\n      - section6\n      - section6.17\n"}, {"commit_sha": "f5364b57f100ae9fa898af59b7812ec0c447ac42", "sha": "22cae057f979ca9cf9a02c8393eca244eb26390a", "filename": "tasks/apt_prepare.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Ensure torproject gpg key is installed (A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89)\n  become: yes\n  apt_key:\n    data: \"{{ lookup('file', 'deb.torproject.org_A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89.pub') }}\"\n    id: A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89\n    state: present\n\n- name: Ensure torproject.org repository is present (APT)\n  become: yes\n  apt_repository:\n    repo: 'deb http://deb.torproject.org/torproject.org {{ tor_distribution_release }} main'\n    state: present\n    update_cache: yes\n\n- name: Ensure torproject.org alpha repo is present if enabled (APT)\n  become: yes\n  apt_repository:\n    repo: 'deb http://deb.torproject.org/torproject.org tor-experimental-{{ tor_alpha_version }}.x-{{ tor_distribution_release }} main'\n    state: present\n    update_cache: yes\n  when: tor_alpha == True\n\n# Background:\n# https://github.com/nusenu/ansible-relayor/issues/72\n- name: Ensure systemd generator folder exists (Debian Testing and Ubuntu)\n  become: yes\n  file:\n    path: /etc/systemd/system-generators\n    state: directory\n    mode: 0755\n  when: ansible_lsb.codename != 'jessie'\n\n- name: Ensure custom systemd generator is in place (Debian/Ubuntu only)\n  become: yes\n  copy:\n    src: tor-generator\n    dest: \"{{ (ansible_lsb.codename == 'jessie')|ternary('/lib/systemd/system-generators/relayor-generator', '/etc/systemd/system-generators/tor-generator') }}\"\n    owner: root\n    mode: 0755\n\n- name: Ensure the maintainer's generator is disabled (Debian 8 only)\n  become: yes\n  command: dpkg-statoverride --update --add root root 644 /lib/systemd/system-generators/tor-generator\n  when: ansible_lsb.codename == 'jessie'\n  ignore_errors: yes\n\n#- name: Ensure AppArmor allows access to necessary files (Ubuntu)\n#  become: yes\n#  lineinfile: dest=/etc/apparmor.d/local/system_tor line={{ item }}\n#  with_items:\n#    - '/etc/tor/enabled/*\\ r,'\n#    - '/{,var/}run/tor/*.pid\\ w,'\n#    - '/var/lib/tor/**\\ w,'\n#  when: ansible_distribution == 'Ubuntu'\n#  notify: restart apparmor\n\n#- meta: flush_handlers\n"}, {"commit_sha": "9eb1a8fa8e281ef06687c1851f51fa0beec3e232", "sha": "12b04a119f58fb81863345bf21cf8e1b3cc56853", "filename": "tasks/section_07_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 7.1.1 Disable IP Forwarding (Scored)\n    sysctl: >\n      name=net.ipv4.ip_forward\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.1\n\n  - name: 7.1.2.1 Disable Send Packet Redirects (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.2\n      - section7.1.2.1\n\n  - name: 7.1.2.2 Disable Send Packet Redirects (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.2\n      - section7.1.2.2\n\n  - name: 7.2.1.1 Disable Source Routed Packet Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.accept_source_route\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.1\n      - section7.2.1.1\n\n  - name: 7.2.1.2 Disable Source Routed Packet Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.accept_source_route\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.1\n      - section7.2.1.2\n\n  - name: 7.2.2.1 Disable ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.2\n      - section7.2.2.1\n\n  - name: 7.2.2.2 Disable ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.2\n      - section7.2.2.2\n\n  - name: 7.2.3.1 Disable Secure ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.secure_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.3\n      - section7.2.3.1\n\n  - name: 7.2.3.2 Disable Secure ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.secure_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.3\n      - section7.2.3.2\n\n  - name: 7.2.4.1 Log Suspicious Packets (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.log_martians\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.4\n      - section7.2.4.1\n\n  - name: 7.2.4.2 Log Suspicious Packets (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.log_martians\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.4\n      - section7.2.4.2\n\n  - name: 7.2.5 Enable Ignore Broadcast Requests (Scored)\n    sysctl: >\n      name=net.ipv4.icmp_echo_ignore_broadcasts\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.5\n\n  - name: 7.2.6 Enable Bad Error Message Protection (Scored)\n    sysctl: >\n      name=net.ipv4.icmp_ignore_bogus_error_responses\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.6\n\n  - name: 7.2.7.1 Enable RFC-recommended Source Route Validation (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.rp_filter\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.7\n      - section7.2.7.1\n\n  - name: 7.2.7.2 Enable RFC-recommended Source Route Validation (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.rp_filter\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.7\n      - section7.2.7.2\n\n  - name: 7.2.8 Enable TCP SYN Cookies (Scored)\n    sysctl: >\n      name=net.ipv4.tcp_syncookies\n      value=1\n      state=present\n    when: enable_tcp_syncookies\n    tags:\n      - section7\n      - section7.2\n      - section7.2.8\n\n  - name: 7.3.1.1 Disable IPv6 Router Advertisements (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.all.accept_ra\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.1\n      - section7.3.1.1\n\n  - name: 7.3.1.2 Disable IPv6 Router Advertisements (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.default.accept_ra\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.1\n      - section7.3.1.2\n\n  - name: 7.3.2.1 Disable IPv6 Redirect Acceptance (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.all.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.2\n      - section7.3.2.1\n\n  - name: 7.3.2.2 Disable IPv6 Redirect Acceptance (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.default.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.2\n      - section7.3.2.2\n\n  - name: 7.3.3 Disable IPv6 (Not Scored)\n    sysctl: >\n      name={{ item }}\n      value=1\n      state=present\n    with_items:\n      - net.ipv6.conf.all.disable_ipv6\n      - net.ipv6.conf.default.disable_ipv6\n      - net.ipv6.conf.lo.disable_ipv6\n    when: disable_ipv6 == True\n    tags:\n      - section7\n      - section7.3\n      - section7.3.3\n\n  - name: 7.4.1 Install TCP Wrappers (Scored)\n    apt: name=tcpd state=present\n    tags:\n      - section7\n      - section7.4\n      - section7.4.1\n\n  - name: 7.4.2 Create /etc/hosts.allow (Not Scored)\n    debug: msg=\"*** Verify /etc/hosts.allow ***\"\n    tags:\n      - section7\n      - section7.4\n      - section7.4.2\n\n  - name: 7.4.3 Verify Permissions on /etc/hosts.allow (Scored)\n    file: >\n        path=/etc/hosts.allow\n        owner=root\n        group=root\n        mode=0644\n    tags:\n      - section7\n      - section7.4\n      - section7.4.3\n\n  - name: 7.4.4 Create /etc/hosts.deny (Not Scored)\n    debug: msg='*** Verify /etc/hosts.deny ***'\n    tags:\n      - section7\n      - section7.4\n      - section7.4.4\n\n  - name: 7.4.5 Verify Permissions on /etc/hosts.deny (Scored)\n    file: >\n        path=/etc/hosts.deny\n        owner=root\n        group=root\n        mode=0644\n    tags:\n      - section7\n      - section7.4\n      - section7.4.5\n\n  - name: 7.5.0 Create the file \"cis.conf\" under modprobe.d if doesn't exist (Not Scored)\n    copy:\n        dest: /etc/modprobe.d/CIS.conf\n        content: \"\"\n        force: no\n    tags:\n      - section7\n      - section7.5\n\n  - name: 7.5.0 Check the presence of the file \"cis.conf\" under modprobe.d (Not Scored)\n    stat: >\n        path=/etc/modprobe.d/CIS.conf\n    register: cis_conf_file\n    tags:\n      - section7\n      - section7.5\n\n\n  - name: 7.5.1-4 Disable DCCP, SCTP, RDS, TIPC (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install {{ item }} /bin/true'\n        state=present\n    when: cis_conf_file.stat.exists\n    with_items:\n        - dccp\n        - sctp\n        - rds\n        - tipc\n    tags:\n      - section7\n      - section7.5\n      - section7.5.1\n      - section7.5.2\n      - section7.5.3\n      - section7.5.4\n\n  - name: 7.6 Deactivate Wireless Interfaces (Not Scored)\n    shell: 'lspci -k | grep -i wifi'\n    changed_when: False\n    register: lspci_wifi\n    failed_when: lspci_wifi.rc == 0\n    tags:\n      - section7\n      - section7.6\n\n  - name: 7.7 Ensure Firewall is active (install) (Scored)\n    apt: >\n        name=ufw\n        state=present\n    when: activate_ufw\n    tags:\n      - section7\n      - section7.7\n\n  - name: 7.7 Ensure Firewall is active (Scored)\n    service: >\n        name=ufw\n        state=started\n    when: activate_ufw\n    tags:\n      - section7\n      - section7.7\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "1e126c4655b09b322a33d36ab06fbea6a4b17dd5", "filename": "handlers/restart_consul.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n- name: restart consul on Linux\n  service:\n    name: consul\n    state: restarted\n  when: ansible_os_family != \"Windows\"\n  listen: 'restart consul'\n\n- name: restart consul on windows\n  win_service:\n    name: consul\n    state: restarted\n  when: ansible_os_family == \"Windows\"\n  listen: 'restart consul'\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "f0aaf760821e1c40ce9b6e0b2f6137e24e81875b", "filename": "roles/vault/meta/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Alberto Lamela\n  description:\n  company: Capgemini\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (MIT)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: Ubuntu\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n     - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies:\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "ac47319a6f25dded960b5197e982fcb78a88d85d", "filename": "tasks/Amazon/rabbit.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/Amazon/rabbit.yml: Deploy RabbitMQ\n# Specific to Amazon Linux AMI\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure Erlang & RabbitMQ are installed\n    yum:\n      name:\n        - erlang\n        - rabbitmq-server\n      state: present\n      enablerepo: epel\n"}, {"commit_sha": "f565940c5163524c7834123625c804e5f69c2b10", "sha": "a5c92a439c787968d870fc2c6ebf7f951efc6815", "filename": "handlers/main.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n\n  - name: restart rabbitmq service\n    service: name={{ rabbitmq_service_name }} state=restarted\n\n  - name: restart redis service\n    service: name={{ redis_service_name }} state=restarted\n\n  - name: restart uchiwa service\n    service: name=uchiwa state=restarted\n\n  - name: restart sensu-server service\n    service: name=sensu-server state=restarted\n    when: sensu_master\n\n  - name: restart sensu-api service\n    service: name=sensu-api state=restarted\n    when: sensu_master\n\n  - name: restart sensu-client service\n    service: name=sensu-client state=restarted\n\n  # Joyent SmartOS specific handlers\n  - name: import sensu-server service\n    command: /usr/sbin/svccfg import /opt/local/lib/svc/manifest/sensu-server.xml\n\n  - name: import sensu-api service\n    command: /usr/sbin/svccfg import /opt/local/lib/svc/manifest/sensu-api.xml\n\n  - name: import sensu-client service\n    command: /usr/sbin/svccfg import /opt/local/lib/svc/manifest/sensu-client.xml\n\n  - name: import uchiwa service\n    command: /usr/sbin/svccfg import /opt/local/lib/svc/manifest/uchiwa.xml\n\n  - name: Build and deploy Uchiwa\n    shell: npm install --production\n    args:\n      chdir: \"{{ uchiwa_path }}/go/src/github.com/sensu/uchiwa\"\n    become: true\n    become_user: \"{{ sensu_user_name }}\"\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "1de3befbc84290df92290365574eecfee8939b5d", "filename": "roles/dcos_cli/vars/chronos.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "dcos_cli_framework_chronos_enabled: true\ndcos_cli_framework_chronos_mem: 512\ndcos_cli_framework_chronos_cpus: 0.5\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "d187a6d46b6a5cc1b1c5c5d1df6dfa0ba62bc663", "filename": "roles/traefik/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ntraefik_marathon_endpoint: http://marathon.service.consul:8080\ntraefik_marathon_domain: marathon.localhost\ntraefik_version: v1.0.alpha.341\ntraefik_image: \"emilevauge/traefik:{{ traefik_version }}\"\ntraefik_config_dir: /etc/traefik\ntraefik_frontend_port: 80\ntraefik_webui_port: 8888\ntraefik_log_level: DEBUG\ntraefik_consul_dir: /etc/consul.d\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "cc40be7c29bc50e8585ba666ab90a3cb50b05891", "filename": "roles/st2repos/handlers/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# handlers file for st2repos\n"}, {"commit_sha": "dc73f16743fa376672b427980c6ca044dd6fa68a", "sha": "2246944bb39d793f20b5ebbafd786dc27dd0325b", "filename": "tasks/openbsd_prepare.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Setup OpenBSD specific variables (set_fact)\n  set_fact:\n    tor_DataDir: /var/tor-instances\n    tor_ConfDir: /etc/tor/enabled\n  tags:\n   - reconfigure\n   - renewkey\n\n- name: Gather current system-wide file descriptor limits (OpenBSD)\n  shell: \"sysctl kern.maxfiles|cut -d= -f2\"\n  register: currentlimits\n\n- name: Ensure system-wide runtime file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  command: \"sysctl kern.maxfiles=20000\"\n  when: currentlimits.stdout|int < 20000\n\n- name: Ensure system-wide persistent file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  lineinfile:\n    dest: /etc/sysctl.conf\n    regexp: ^kern.maxfiles\n    line: \"kern.maxfiles=20000\"\n    create: yes\n  when: currentlimits.stdout|int < 20000\n\n# We rise openfiles limits for every tor instance separately.\n# An instance is identified by its rc.d file name.\n- name: Ensure Tor process file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  lineinfile:\n    dest: /etc/login.conf\n    line: \"tor{{ item.0.ipv4| replace('.','_') }}_{{ item.1.orport }}::openfiles-max=13500::tc=daemon:\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n"}, {"commit_sha": "32211ebd2a9f45112f8dceda80bc95d0db029fb4", "sha": "a637dd0203eb5c428729d376cfbfc9bdacc917b0", "filename": "handlers/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n- name: stop-and-mask default tor instance\n  become: yes\n  shell: systemctl stop tor@default && systemctl mask tor@default\n\n- name: restart apparmor\n  become: yes\n  service: name=apparmor state=restarted\n\n- name: systemctl daemon-reload\n  become: yes\n  command: systemctl daemon-reload\n\n- name: re-gather facts\n  setup:\n"}, {"commit_sha": "df06f3c3304c3f73f740d444222642fbad41bebb", "sha": "2344b0e4bf5e822c5109636f15ea012c3e0959e6", "filename": "tasks/configure.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Ensure Tor DataDir(s) exist and is owned by tor_user\n  become: yes\n  file: path={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}\n    state=directory\n    owner={{ tor_user }}\n    mode=0700\n    recurse=yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - debian\n   - centos\n   - fedora\n   - freebsd\n   - openbsd\n   - createdir\n\n- name: Ensure Tor config directory exists and has appropriate permissions\n  become: yes\n  file: path={{ tor_ConfDir }}\n    state=directory\n    owner=root\n    group={{ tor_user }}\n    mode=755\n  tags:\n   - debian\n   - centos\n   - fedora\n   - freebsd\n   - openbsd\n\n- name: Ensure LogDir exists and has appropriate permissions\n  become: yes\n  file: path={{ tor_LogDir }}\n    state=directory\n    owner={{ tor_user }}\n    mode=750\n  tags:\n   - debian\n   - centos\n   - fedora\n   - freebsd\n   - openbsd\n\n- name: Ensure PidDir is owned by tor_user\n  become: yes\n  file: path={{ tor_PidDir }}\n    state=directory\n    owner={{ tor_user }}\n    group={{ tor_user }}\n    mode=2750\n  tags:\n   - debian\n   - centos\n   - fedora\n   - freebsd\n   - openbsd\n\n- name: Generating temporary (without MyFamily) torrc file(s)...\n  become: yes\n  template: src=torrc\n    dest=\"{{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc-tmp\"\n    owner=root\n    mode=0644\n  with_nested:\n   - tor_ips\n   - tor_ports\n  tags:\n   - debian\n   - centos\n   - fedora\n   - freebsd\n   - openbsd\n\n- name: Collect relay fingerprints (for MyFamily)\n  become: yes\n  shell: \"tor --hush -f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc-tmp --list-fingerprint |cut -d' ' -f2-|sed -e 's, ,,g'\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n  register: tor_fingerprints\n  tags:\n   - debian\n   - centos\n   - fedora\n   - freebsd\n   - openbsd\n   - reconfigure\n\n- name: Generating final torrc file(s) (with MyFamily)\n  become: yes\n  template: >\n    src=torrc\n    dest=\"{{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\"\n    owner=root\n    mode=0644\n    backup=yes\n    validate=\"tor --verify-config -f %s\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n  register: instances\n  tags:\n   - debian\n   - centos\n   - fedora\n   - freebsd\n   - openbsd\n   - reconfigure\n\n# Linux/systemd section (uses service module)\n# ===========================================\n \n- name: Ensure Tor instances are reloaded if its torrc changed (Linux/systemd)\n  become: yes\n  service: name=tor@{{ item.item[0] }}_{{ item.item.1.orport }}.service state=reloaded\n  with_items: instances.results\n  when: ansible_system == 'Linux' and item.changed == True \n  tags:\n   - debian\n   - centos\n   - fedora\n   - reconfigure\n\n- name: Ensure Tor instances are enabled and started (Linux/systemd)\n  become: yes\n  service: name=tor@{{ item[0] }}_{{ item.1.orport }}.service enabled=yes state=started\n  with_nested:\n   - tor_ips\n   - tor_ports\n  when: ansible_system == 'Linux'\n  tags:\n   - debian\n   - centos\n   - fedora\n\n# OpenBSD section (uses service module)\n# This is basically a copy from the Linux\n# section, but it requires different service\n# names and additional arguments.\n# =====================================\n\n# OpenBSD does not support multi-instance rc.d\n# # so we link as many pseudo rc scripts as we need.\n# # OpenBSD does not like dots in rc filenames so\n# # we replace them with underscores.\n- name: Create links to the service files (OpenBSD)\n  become: yes\n  file: src=/etc/rc.d/tor state=link path=/etc/rc.d/tor{{ item[0]| replace('.','_') }}_{{ item.1.orport }}\n  with_nested:\n   - tor_ips\n   - tor_ports\n  when: ansible_system == 'OpenBSD'\n  tags:\n   - openbsd\n\n- name: Ensure Tor instances are enabled and started (OpenBSD)\n  become: yes\n  service: name=tor{{ item[0]|replace('.','_') }}_{{ item.1.orport }}\n   arguments=\"-f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\" enabled=yes state=started\n  with_nested:\n   - tor_ips\n   - tor_ports\n  when: ansible_system == 'OpenBSD'\n  tags:\n   - openbsd\n\n- name: Ensure Tor instances are reloaded if its torrc changed (OpenBSD)\n  become: yes\n  service: name=tor{{ item.item[0]|replace('.','_') }}_{{ item.item.1.orport }} state=reloaded\n  with_items: instances.results\n  when: ansible_system == 'OpenBSD' and item.changed == True\n  tags:\n   - openbsd\n   - reconfigure\n\n\n# FreeBSD section\n# ================\n\n- name: Ensure Tor instances are reloaded if its torrc changed (FreeBSD)\n  become: yes\n  shell: \"kill -HUP `cat {{ tor_PidDir }}/{{ item.item[0] }}_{{ item.item.1.orport }}.pid`\"\n  ignore_errors: yes\n  with_items: instances.results\n  when: item.changed == True and ansible_system == 'FreeBSD'\n  tags:\n   - freebsd\n   - reconfigure\n\n- name: Ensure Tor instances are running (FreeBSD)\n  become: yes\n  shell: \"kill -0 `cat {{ tor_PidDir }}/{{ item[0] }}_{{ item.1.orport }}.pid` || tor -f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n  when: ansible_system == 'FreeBSD'\n  tags:\n   - freebsd\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "1f1de192470bc39496f4676565f96d2758c1e5b4", "filename": "tasks/section_12.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - include: section_12_level1.yml\n    tags:\n      - section12\n      - level1\n\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "b24f9ed485e1687f699a215fc6da4ab11b8cc77a", "filename": "roles/mistral/handlers/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "- name: restart mistral\n  sudo: true\n  service:\n    name: mistral\n    state: restarted\n"}, {"commit_sha": "1bb50a6149f6ff7f2e6399411418d088e2c52d01", "sha": "a69c4b3113cd41d33f4a554fbec3c0c78d13a8b9", "filename": "tasks/section_06_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 6.1 Ensure the X Window system is not installed (Scored)\n    apt: name=xserver-xorg-core* purge=yes state=absent\n    when: remove_xserver == True\n    tags:\n      - section6\n      - section6.1\n\n  - name: 6.2 Ensure Avahi Server is not enabled (check) (Scored)\n    stat: path='/etc/init/avahi-daemon.conf'\n    register: avahi_stat\n    tags:\n      - section6\n      - section6.2\n\n  - name: 6.2 Ensure Avahi Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on (filesystem'\n        state=present\n        regexp='start on \\(filesystem'\n        dest=/etc/init/avahi-daemon.conf\n    when: avahi_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.2\n\n  - name: 6.3 Ensure print server is not enabled (check) (Not Scored)\n    stat: path='/etc/init/cups.conf'\n    register: cups_stat\n    tags:\n      - section6\n      - section6.3\n\n  - name: 6.3 Ensure print server is not enabled (Not Scored)\n    lineinfile: >\n        line='#start on (filesystem'\n        state=present\n        regexp='start on \\(filesystem'\n        dest=/etc/init/cups.conf\n    when: cups_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.3\n\n  - name: 6.4.1 Ensure DHCP Server is not enabled (check) (Scored)\n    stat: path='/etc/init/isc-dhcp-server.conf'\n    register: dhcp_stat\n    tags:\n      - section6\n      - section6.4\n      - section6.4.1\n\n  - name: 6.4.1 Ensure DHCP Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n        dest=/etc/init/isc-dhcp-server.conf\n    when: dhcp_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.4\n      - section6.4.1\n\n  - name: 6.4.2 Ensure DHCP Server is not enabled (check) (Scored)\n    stat: path='/etc/init/isc-dhcp-server6.conf'\n    register: dhcp6_stat\n    tags:\n      - section6\n      - section6.4\n      - section6.4.2\n\n  - name: 6.4.2 Ensure DHCP Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n        dest=/etc/init/isc-dhcp-server6.conf\n    when: dhcp6_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.4\n      - section6.4.2\n\n  - name: 6.5.1 Configure Network Time Protocol (install) (NTP) (Scored)\n    apt: name=ntp state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.1\n\n  - name: 6.5.2 Configure Network Time Protocol (restrict4) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='restrict -4 default kod nomodify notrap nopeer noquery'\n        regexp='^restrict -4 default'\n        state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.2\n\n  - name: 6.5.3 Configure Network Time Protocol (restrict6) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='restrict -6 default kod nomodify notrap nopeer noquery'\n        regexp='^restrict -6 default'\n        state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.3\n\n  - name: 6.5.4 Configure Network Time Protocol (server check) (NTP) (Scored)\n    command: 'grep \"^server\" /etc/ntp.conf'\n    register: ntp_server_rc\n    changed_when: False\n    always_run: True\n    tags:\n      - section6\n      - section6.5\n      - section6.5.4\n\n  - name: 6.5.4 Configure Network Time Protocol (server add) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='server 0.fr.pool.ntp.org'\n        state=present\n    when: ntp_server_rc.rc == 1\n    tags:\n      - section6\n      - section6.5\n      - section6.5.4\n\n  - name: 6.6 Ensure LDAP is not enabled (Not Scored)\n    apt: name=slapd purge=yes state=absent\n    tags:\n      - section6\n      - section6.6\n\n  - name: 6.7.1 Ensure NFS and RPC are not enabled (stat) (Not Scored)\n    stat: path=/etc/init/rpcbind-boot.conf\n    register: nfs_rpc_rc\n    tags:\n      - section6\n      - section6.7\n      - section6.7.1\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (Not Scored)\n    lineinfile: >\n        dest=/etc/init/rpcbind-boot.conf\n        line='#start on virtual-filesystems and net-device-up IFACE=lo'\n        state=present\n        regexp='start on virtual-filesystems and net'\n    when: nfs_rpc_rc.stat.exists == True\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (check) (Not Scored)\n    command: dpkg -S nfs-kernel-server\n    changed_when: False\n    failed_when: False\n    register: nfs_present\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (rc.d) (Not Scored)\n    service: >\n        name=nfs-kernel-server\n        enabled=no\n    when: nfs_present is defined and nfs_present.rc == 0\n    register: nfs_service_result\n    failed_when: \"nfs_service_result|failed and 'service not found' not in nfs_service_result.msg\"\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.8-14 Ensure DNS,FTP,HTTP,IMAP,POP,Samba,Proxy,SNMP Servers are not enabled (Not Scored)\n    service: >\n        name={{ item }}\n        enabled=no\n    with_items:\n      - bind9\n      - vsftpd\n      - apache2\n      - dovecot\n      - smbd\n      - squid3\n      - snmpd\n    failed_when: False\n    tags:\n      - section6\n      - section6.8\n      - section6.9\n      - section6.10\n      - section6.11\n      - section6.12\n      - section6.13\n      - section6.14\n\n  - name: 6.15 Configure Mail Transfer Agent for Local-Only Mode (stat) (Scored)\n    stat: path=/etc/postfix/main.cf\n    register: postfix_main_cf\n    tags:\n      - section6\n      - section6.15\n\n  - name: 6.15 Configure Mail Transfer Agent for Local-Only Mode (Scored)\n    lineinfile: >\n        dest=/etc/postfix/main.cf\n        regexp='^inet_interfaces ='\n        line='inet_interfaces = localhost'\n        state=present\n    when: postfix_main_cf.stat.exists == True\n    tags:\n      - section6\n      - section6.15\n\n  - name: 6.16 Ensure rsync service is not enabled (stat) (Scored)\n    stat: path=/etc/default/rsync\n    register: default_rsync\n    tags:\n      - section6\n      - section6.16\n\n  - name: 6.16 Ensure rsync service is not enabled (Scored)\n    lineinfile: >\n        dest='/etc/default/rsync'\n        regexp='^RSYNC_ENABLE'\n        line='RSYNC_ENABLE=false'\n    when: default_rsync.stat.exists == True\n    tags:\n      - section6\n      - section6.16\n\n  - name: 6.17 Ensure Biosdevname is not enabled (Scored)\n    apt: name=biosdevname purge=yes state=absent\n    tags:\n      - section6\n      - section6.17\n"}, {"commit_sha": "61b008311c40b377e57e166b778232a20224f7c6", "sha": "c6332873e7a52d61246ce83c720e16ff807c56be", "filename": "tasks/install.deb.yml", "repository": "UnderGreen/ansible-role-mongodb", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- include_vars: \"{{ansible_distribution}}.yml\"\n\n- name: Check if running on systemd\n  command: cat /proc/1/cmdline\n  register: systemd\n  changed_when: false\n\n- name: Add systemd configuration if present\n  copy: src=mongodb.service dest=/lib/systemd/system/mongodb.service owner=root group=root mode=0640\n  when: \"'systemd' in systemd.stdout\"\n\n- name: Add symlink for systemd\n  file: src=/lib/systemd/system/mongodb.service dest=/etc/systemd/system/multi-user.target.wants/mongodb.service state=link\n  when: \"'systemd' in systemd.stdout\"\n  notify: reload systemd\n\n- meta: flush_handlers\n  when: \"'systemd' in systemd.stdout\"\n\n- name: Add APT key\n  apt_key: url=\"{{mongodb_apt_key_url}}\" id=\"{{mongodb_apt_key_id}}\"\n\n- name: Add APT repository\n  apt_repository: repo=\"{{mongodb_repository}}\" update_cache=yes\n\n- name: Install MongoDB package\n  apt: name={{item}} state=present\n  with_items:\n    - \"{{mongodb_package}}\"\n    - numactl\n\n- name: Ensure dbpath directory\n  file: path={{mongodb_conf_dbpath}} state=directory owner=mongodb recurse=yes\n\n- name: reload systemd\n  shell: systemctl daemon-reload\n  changed_when: false\n  when: \"'systemd' in systemd.stdout\"\n\n- name: Install PyMongo package\n  apt: pkg=python-pymongo state=latest\n  when: not mongodb_pymongo_from_pip\n\n- name: Install PIP\n  apt: pkg={{ item }}\n  with_items:\n    - python-dev\n    - python-pip\n  when: mongodb_pymongo_from_pip\n\n- name: Install PyMongo from PIP\n  pip: name=pymongo version=\"{{ mongodb_pymongo_pip_version }}\" state=present\n  when: mongodb_pymongo_from_pip\n"}, {"commit_sha": "15d2da095f9bd54a50954dee18597710e1951943", "sha": "9bf8300d85e77ecf7f307f1f17a79f2729b2edd8", "filename": "tasks/debug.yml", "repository": "ansiblebit/oracle-java", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# file: oracle-java/tasks/debug.yml\n#\n# Task that prints variable debug information.\n#\n\n- debug:\n    var=\"{{ item }}\"\n  when: item is defined\n  with_items:\n    - oracle_java_cache_valid_time\n    - oracle_java_home\n    - oracle_java_installed\n    - oracle_java_os_supported\n    - oracle_java_rpm_filename\n    - oracle_java_set_as_default\n    - oracle_java_rpm_url\n    - oracle_java_state\n    - oracle_java_version_build\n    - oracle_java_version_installed\n    - oracle_java_version_string\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "dc35e6970f4ff6f54db608f2ff1d8ec5f1a39e59", "filename": "roles/dcos_cli/vars/prometheus.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "dcos_cli_app_prometheus_enabled: \"{{ prometheus_enabled }}\"\ndcos_cli_app_prometheus_mem: 128\ndcos_cli_app_prometheus_cpus: 0.5\ndcos_cli_app_prometheus_instances: 1\n"}, {"commit_sha": "dc73f16743fa376672b427980c6ca044dd6fa68a", "sha": "e58502e7b99758d1466ea93e4c12ff3ef5ab8dd5", "filename": "tasks/freebsd_prepare.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Setup FreeBSD specific variables (set_fact)\n  set_fact:\n    tor_DataDir: /var/db/tor-instances\n    tor_ConfDir: /usr/local/etc/tor/enabled\n    tor_PidDir: /var/run/tor-instances\n  tags:\n   - reconfigure\n   - renewkey\n\n- name: Ensure sequential IP IDs are avoided (FreeBSD)\n  become: yes\n  sysctl:\n    name: net.inet.ip.random_id\n    value: 1\n    reload: no\n    sysctl_set: yes\n\n- name: Gather current kern.ipc.somaxconn setting (FreeBSD)\n  shell: \"sysctl kern.ipc.somaxconn|cut -d' '  -f2\"\n  register: currentsomaxconn\n\n- name: Ensure somaxconn setting is reasonable (FreeBSD)\n  become: yes\n  sysctl:\n    name: kern.ipc.somaxconn\n    value: \"{{ freebsd_somaxconn }}\"\n    reload: no\n    sysctl_set: yes\n  when: currentsomaxconn.stdout|int < {{ freebsd_somaxconn }}\n\n- name: Gather current kern.ipc.nmbclusters setting (FreeBSD)\n  shell: \"sysctl kern.ipc.nmbclusters|cut -d' '  -f2\"\n  register: currentnmbc\n\n- name: Ensure nmbclusters setting is reasonable (FreeBSD)\n  become: yes\n  sysctl:\n    name: kern.ipc.nmbclusters\n    value: \"{{ freebsd_nmbclusters }}\"\n    reload: no\n    sysctl_set: yes\n  when: currentnmbc.stdout|int < {{ freebsd_nmbclusters }}\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "05fd804c5163f6af60ccb2a40963d7bdcf699c78", "filename": "tasks/FreeBSD/rabbit.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/FreeBSD/rabbit.yml: Deploy RabbitMQ\n# Specific to FreeBSD\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure RabbitMQ is installed\n    pkgng:\n      name: rabbitmq\n      state: \"{{ rabbitmq_pkg_state }}\"\n"}, {"commit_sha": "a2393d46f0b98700161c4cefd9260d7694bd0bf3", "sha": "7298a05b217bff1699236376ac9d7d5c85068a91", "filename": "tasks/section_13_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 13.1 Ensure Password Fields are Not Empty (Scored)\n    command: awk -F':' '($2 == \"\" ) { print $1 }' /etc/shadow\n    register: awk_empty_shadow\n    changed_when: False\n    failed_when: awk_empty_shadow.stdout != '' and lock_shadow_accounts == 'no'\n    tags:\n      - section13\n      - section13.1\n\n  - name: 13.1 Ensure Password Fields are Not Empty (locking accounts) (Scored)\n    command: passwd -l {{ item }}\n    with_items:\n        awk_empty_shadow.stdout_lines\n    when: lock_shadow_accounts\n    tags:\n      - section13\n      - section13.1\n\n  - name: 13.2 Verify No Legacy \"+\" Entries Exist in /etc/passwd File (Scored)\n    command: grep '^+:' /etc/passwd\n    register: plus_pass\n    failed_when: plus_pass.rc == 0\n    changed_when: plus_pass.rc == 0\n    tags:\n      - section13\n      - section13.2\n\n  - name: 13.3 Verify No Legacy \"+\" Entries Exist in /etc/shadow File (Scored)\n    command: grep '^+:' /etc/shadow\n    register: plus_shadow\n    failed_when: plus_shadow.rc == 0\n    changed_when: plus_shadow.rc == 0\n    tags:\n      - section13\n      - section13.3\n\n  - name: 13.4 Verify No Legacy \"+\" Entries Exist in /etc/group File (Scored)\n    command: grep '^+:' /etc/group\n    register: plus_group\n    failed_when: plus_group.rc == 0\n    changed_when: plus_group.rc == 0\n    tags:\n      - section13\n      - section13.4\n\n  - name: 13.5 Verify No UID 0 Accounts Exist Other Than root (Scored)\n    command: awk -F':' '($3 == 0) { print $1 }' /etc/passwd\n    register: uid_zero_root\n    changed_when: False\n    failed_when: uid_zero_root.stdout != 'root'\n    tags:\n      - section13\n      - section13.5\n\n  - name: 13.6.1 Ensure root PATH Integrity (empty value) (Scored)\n    shell: 'echo $PATH | grep ::'\n    register: path_colon\n    changed_when: False\n    failed_when: path_colon.rc == 0\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.2 Ensure root PATH Integrity (colon end) (Scored)\n    shell: 'echo $PATH | grep :$'\n    register: path_colon_end\n    changed_when: False\n    failed_when: path_colon_end.rc == 0\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.3 Ensure root PATH Integrity (dot in path) (Scored)\n    shell: \"echo $PATH | sed -e 's/::/:/' -e 's/:$//' -e 's/:/\\\\n/g'\"\n    register: dot_in_path\n    changed_when: False\n    failed_when: '\".\" in dot_in_path.stdout_lines'\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.4 Ensure root PATH Integrity (Scored)\n    file: >\n        path={{ item }}\n        state=directory\n        owner=root\n        mode='o-w,g-w'\n    with_items:\n        dot_in_path.stdout_lines\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.7.1 Check Permissions on User Home Directories (gather users) (Scored)\n    shell: /bin/egrep -v '(root|halt|sync|shutdown|false)' /etc/passwd | /usr/bin/awk -F':' '($7 != \"/usr/sbin/nologin\") { print $6 }'\n    register: home_users\n    changed_when: False\n    failed_when: False\n    tags:\n      - section13\n      - section13.7\n\n  - name: 13.7.2 Check Permissions on User Home Directories (Scored)\n    file: >\n        path={{ item }}\n        mode='g-w,o-rwx'\n        state=directory\n    with_items:\n        home_users.stdout_lines\n    when: modify_user_homes == True\n    tags:\n      - section13\n      - section13.7\n\n  - name: 13.8.1 Check User Dot File Permissions (gather dotfiles) (Scored)\n    shell: for pth in `/bin/egrep -v '(root|halt|sync|shutdown)' /etc/passwd | /usr/bin/awk -F':' '($7 != \"/usr/sbin/nologin\") { print $6 }'`; do ls -d -A -1 $pth/.* | egrep -v '[..]$'; done\n    changed_when: False\n    failed_when: False\n    always_run: True\n    register: home_dot_files\n    tags:\n      - section13\n      - section13.8\n\n  - name: 13.8.2 Check User Dot File Permissions (Scored)\n    file: >\n        path={{ item }}\n        mode='o-w,g-w'\n    with_items:\n        home_dot_files.stdout_lines\n    tags:\n      - section13\n      - section13.8\n\n  - name: 13.9 Check Permissions on User .netrc Files (Scored)\n    file: >\n        path={{ item }}/.netrc\n        mode='g-rwx,o-rwx'\n        recurse=yes\n        state=directory\n    with_items:\n        home_users.stdout_lines\n    tags:\n      - section13\n      - section13.9\n\n  - name: 13.10 Check for Presence of User .rhosts Files (Scored)\n    file: >\n        state=absent\n        path={{ item }}/.rhosts\n    with_items:\n        home_users.stdout_lines\n    tags:\n      - section13\n      - section13.10\n\n  - name: 13.11 Check Groups in /etc/passwd (preparation) (Scored)\n    command: cut -s -d':' -f4 /etc/passwd\n    register: groups_id_cut\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.11\n\n  - name: 13.11 Check Groups in /etc/passwd (Scored)\n    command: grep -q -P \"^.*?:[^:]*:{{ item }}:\" /etc/group\n    with_items:\n        groups_id_cut.stdout_lines\n    register: groups_present\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.11\n\n  - name: 13.12 Check That Users Are Assigned Valid Home Directories (Scored)\n    stat: path={{ item }}\n    with_items:\n        home_users.stdout_lines\n    register: rstat\n    failed_when: rstat is defined and rstat.stat.isdir == False\n    always_run: True\n    tags:\n      - section13\n      - section13.12\n\n  - name: 13.13 Check User Home Directory Ownership (Scored)\n    debug: msg=\"*** Hardcore ***\"\n    tags:\n      - section13\n      - section13.13\n\n  - name: 13.14 Check for Duplicate UIDs (Scored)\n    shell: cut -f3 -d':' /etc/passwd | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.14\n\n  - name: 13.15 Check for Duplicate GIDs (Scored)\n    shell: cut -f3 -d':' /etc/group | sort | uniq -d\n    register: gids_list\n    failed_when: gids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.15\n\n  - name: 13.16 Check for Duplicate User Names (Scored)\n    shell: cut -f1 -d':' /etc/passwd | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.16\n\n  - name: 13.17 Check for Duplicate Group Names (Scored)\n    shell: cut -f1 -d':' /etc/group | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.17\n\n  - name: 13.18 Check for Presence of User .netrc Files (stat) (Scored)\n    stat: path='{{ item }}/.netrc'\n    with_items: home_users.stdout_lines\n    register: netrc_files\n    tags:\n      - section13\n      - section13.18\n\n  - name: 13.18 Check for Presence of User .netrc Files (Scored)\n    file: >\n        path='{{ item }}'\n        state=absent\n    when: item.stat.exists == True\n    with_items: netrc_files.results\n    tags:\n      - section13\n      - section13.18\n\n  - name: 13.19 Check for Presence of User .forward Files (Scored)\n    file: >\n        path='{{ item }}/.forward'\n        state=absent\n    with_items:\n        home_users.stdout_lines\n    tags:\n      - section13\n      - section13.19\n\n  - name: 13.20.1 Ensure shadow group is empty (Scored)\n    shell: grep '^shadow' /etc/group | cut -f4 -d':'\n    register: shadow_group_empty\n    failed_when: shadow_group_empty.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.1\n\n  - name: 13.20.2 Ensure shadow group is empty (preparation) (Scored)\n    shell: grep '^shadow' /etc/group | cut -f1 -d':'\n    register: shadow_group_id\n    failed_when: False\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.1\n\n  - name: 13.20.2 Ensure shadow group is empty (Scored)\n    shell: awk -F':' '($4 == \"{{ item }}\") { print }' /etc/passwd\n    register: awk_passwd_shadow\n    with_items:\n        shadow_group_id.stdout_lines\n    changed_when: False\n    failed_when: awk_passwd_shadow.stdout != ''\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.2\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "3eab5e308c43d29bdefa648c16c6cabb86ca0583", "filename": "tasks/section_06_level1_05.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 6.5.2 Configure Network Time Protocol (restrict4) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='restrict -4 default kod nomodify notrap nopeer noquery'\n        regexp='^restrict -4 default'\n        state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.2\n\n  - name: 6.5.3 Configure Network Time Protocol (restrict6) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='restrict -6 default kod nomodify notrap nopeer noquery'\n        regexp='^restrict -6 default'\n        state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.3\n\n  - name: 6.5.4.1 Configure Network Time Protocol (server check) (NTP) (Scored)\n    command: 'grep \"^server\" /etc/ntp.conf'\n    register: ntp_server_rc\n    changed_when: False\n    always_run: True\n    ignore_errors: True\n    tags:\n      - section6\n      - section6.5\n      - section6.5.4\n\n  - name: 6.5.4.2 Configure Network Time Protocol (server add) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='server {{ ntp_server }}'\n        state=present\n    when: ntp_server_rc.rc == 1\n    tags:\n      - section6\n      - section6.5\n      - section6.5.4\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "ff20d4d028f8f0cc5d23813c9eba4845f3c7172e", "filename": "roles/st2web/vars/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# vars file for st2web\n"}, {"commit_sha": "f5364b57f100ae9fa898af59b7812ec0c447ac42", "sha": "a78e182aeadce254cb1a8396e0ca3b1898646609", "filename": "meta/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: nusenu\n  description: An Ansible role for Tor Relay Operators\n  license: GPLv3\n  platforms:\n  - name: Debian\n    versions:\n    - jessie\n    - stretch\n  - name: FreeBSD\n    versions:\n    - 10.3\n    - 11.0\n  - name: OpenBSD\n    versions:\n    - 6.0\n  - name: EL\n    versions:\n    - 7\n  - name: Ubuntu\n    versions:\n    - xenial\n  - name: Fedora\n    versions:\n    - 25\n  galaxy_tags:\n    - tor\n    - ipv6\n    - anonymity\n    - networking\n  min_ansible_version: 2.1.3\ndependencies: []\n"}, {"commit_sha": "92d2f38d01d7b33610c667cfdc03e28ab2912edc", "sha": "090199454399d10363b5a206107f3700ec476d76", "filename": "tasks/section_02_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 2.1 Create Separate Partition for /tmp (Scored)\n    command: grep '\\s/tmp\\s' /etc/fstab\n    register: tmp_partition\n    failed_when: tmp_partition.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section2\n      - section2.1\n\n  - name: 2.2 - 4 Set nodev, nosuid, noexec option for /tmp Partition (Scored)\n    mount: name=\"/tmp\" src=\"/tmp\" state=\"mounted\" opts=\"nodev,nosuid,noexec\" fstype=ext4\n    when: partitioning == True\n    tags:\n      - section2\n      - section2.2\n      - section2.3\n      - section2.4\n\n  - name: 2.5 Create Separate Partition for /var (Scored)\n    command: grep '\\s/var\\s' /etc/fstab\n    register: var_partition\n    failed_when: var_partition.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section2\n      - section2.5\n\n  - name: 2.6 Bind Mount the /var/tmp directory to /tmp (Scored)\n    mount: name=\"/var/tmp\" src=\"/tmp\" opts=bind state=mounted fstype=ext4\n    when: partitioning == True\n    tags:\n      - section2\n      - section2.6\n\n  - name: 2.7 Create Separate Partition for /var/log (Scored)\n    command: grep '\\s/var\\/log\\s' /etc/fstab\n    register: var_log_partition\n    failed_when: var_log_partition.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section2\n      - section2.7\n\n  - name: 2.8 Create Separate Partition for /var/log/audit (Scored)\n    command: grep '\\s/var\\/log\\/audit\\s' /etc/fstab\n    register: var_log_audit_partition\n    failed_when: var_log_audit_partition.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section2\n      - section2.8\n\n  - name: 2.9 Create Separate Partition for /home (Scored)\n    command: grep '\\s/home\\s' /etc/fstab\n    register: home_partition\n    failed_when: home_partition.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section2\n      - section2.9\n\n  - name: 2.10 Add nodev Option to /home (Scored)\n    mount: name=\"/home\" src=\"/home\" state=mounted opts=remount,nodev fstype=\"ext4\"\n    when: partitioning == True\n    tags:\n      - section2\n      - section2.10\n\n  - name: 2.11 Add nodev Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nodev option\"\n    tags:\n      - section2\n      - section2.11\n\n  - name: 2.12 Add noexec Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have noexec option\"\n    tags:\n      - section2\n      - section2.12\n\n  - name: 2.13 Add nosuid Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nosuid option\"\n    tags:\n      - section2\n      - section2.13\n\n  - name: 2.14 - 16 Add nodev Option to /run/shm Partition (Scored)\n    mount: name=\"/run/shm\" src=\"/run/shm\" state=\"mounted\" opts=\"nodev,nosuid,noexec\" fstype=\"tmpfs\"\n    when: run_shm_read_only == False\n    tags:\n      - section2\n      - section2.14\n      - section2.15\n      - section2.16\n\n  - name: 2.17.1 Set Sticky Bit on All World-Writable Directories (preparation) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type d -perm -0002 -print 2>/dev/null\n    failed_when: False\n    changed_when: False\n    always_run: True\n    register: sticky_bit_dirs\n    tags:\n      - section2\n      - section2.17\n      - section2.17.1\n\n  - name: 2.17.2 Set Sticky Bit on All World-Writable Directories (Scored)\n    file:\n        path: \"{{ item }}\"\n        mode: \"a+t\"\n    with_items: \"{{sticky_bit_dirs.stdout_lines}}\"\n    tags:\n      - section2\n      - section2.17\n      - section2.17.2\n\n  - name: 2.25 Disable Automounting (stat) (Scored)\n    stat: >\n        path=/etc/init/autofs.conf\n    register: autofs_file\n    tags:\n      - section2\n      - section2.25\n      \n  - name: 2.25 Disable Automounting (Scored)\n    lineinfile: >\n        dest=/etc/init/autofs.conf\n        line='#start on runlevel [2345]'\n        regexp='start on runlevel'\n        state=present\n    when: autofs_file.stat.exists == True\n    tags:\n      - section2\n      - section2.25\n"}, {"commit_sha": "35ca6852d9333ef6c3ed223239f45b840c487d60", "sha": "570649a0fd109b58625690284a1a398743e80cdc", "filename": "roles/weave/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for weave\n- name: include all interfaces.d\n  sudo: yes\n  lineinfile:\n    dest: /etc/network/interfaces\n    state: present\n    line: 'source /etc/network/interfaces.d/*.cfg'\n  tags:\n    - weave\n\n# Start docker as it is a requirement for weave create-bridge.\n- name: Start up docker\n  service:\n    name: docker\n    state: started\n  tags:\n    - weave\n\n- name: configure weave interface\n  sudo: yes\n  template:\n    src: interfaces.j2\n    dest: /etc/network/interfaces.d/weave.cfg\n    owner: root\n    group: root\n    mode: 0644\n  tags:\n    - weave\n\n# Create weave bridge.\n- name: bring up weave bridge\n  command: ifup weave\n  sudo: yes\n\n- name: upload weave template service\n  template:\n    src: weave.conf.j2\n    dest: \"/etc/init/weave.conf\"\n    mode: 0755\n  sudo: yes\n  tags:\n    - weave\n\n# Restart docker with weave bridge available and triggers weave service.\n- name: configure weave bridge for docker\n  sudo: yes\n  lineinfile:\n    dest: /etc/default/docker\n    state: present\n    regexp: ^DOCKER_OPTS=.*--bridge=weave.*\n    line: 'DOCKER_OPTS=\\\"$DOCKER_OPTS {{ weave_docker_opts }}\\\"'\n  notify:\n    - Restart docker\n  tags:\n    - weave\n"}, {"commit_sha": "7f02cba4441b5367d6916857c9b41f3abae915db", "sha": "fda1d8878b20341c46d510d2df39a36f6b446d4c", "filename": "tasks/freebsd_service.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n# tor_intances defines the number and configurations of instances\n# an instance is defined with the following fields:\n# inst_name:configfile:username:groupname:pidfile:data_dir\n# username/groupname is set to root to be able to bind to <1024 ports\n# but privileges are dropped afterwards (torrc User parameter)\n- name: Ensure Tor multi-instance configuration is present (FreeBSD)\n  become: yes\n  lineinfile:\n    dest: /etc/rc.conf\n    line: \"tor_instances=\\\"${tor_instances} {{ item.0.ipv4 }}_{{ item.1.orport }}:{{ tor_ConfDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}.torrc:root:root:{{ tor_PidDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/pid:{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\\\"\"\n    create: yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n# this task is a workaround, because 'service tor status'\n# fails if this line is not present (which in turn fails the ansible service module)\n- name: Ensure tor is enabled in /etc/rc.conf (FreeBSD)\n  become: yes\n  lineinfile:\n    dest: /etc/rc.conf\n    line: \"tor_enable=\\\"YES\\\"\"\n    create: yes\n\n# this affects all instances\n- name: Ensure Tor instances are running and enabled (FreeBSD)\n  become: yes\n  service:\n    name: tor\n    enabled: yes\n    state: started\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "4cf925bc431ea246662952d1d21b96d50933dc22", "filename": "roles/registrator/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for registrator\nregistrator_image: \"gliderlabs/registrator:master\"\nregistrator_uri: \"consul://{{ ansible_default_ipv4.address }}:8500\"\nregistrator_command: \"-internal -resync=10 {{ registrator_uri }}\"\nregistrator_docker_socket: \"{{ docker_host }}\"\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "0656f4a5f47a08599d45fa695e19d67676464c1e", "filename": "roles/haproxy/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for haproxy\nhaproxy_image: asteris/haproxy-consul\nhaproxy_image_tag: latest\n\n# Set the domain that haproxy uses to match URLs to internal apps.\n# For example, if all your apps will be\n#    app1.example.com, app2.example.com, etc.  set this to 'example.com'\nhaproxy_domain: example.com\n\nhaproxy_rebuild_container: False\n\nconsul_template_dir: /mnt/consul-template.d\nconsul_template_loglevel: debug\nconsul_backend: consul.service.consul:8500\nconsul_template_version: 0.10.0\n"}, {"commit_sha": "1510f92858b85f9f623690db747bdfff9b5b0515", "sha": "d5f883449e66e3a48089254ba30c95a859579f42", "filename": "tasks/mysql_secure_installation.yml", "repository": "dev-sec/ansible-mysql-hardening", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n\n# supported for ansible ver => 2.0\n#- name: Install python-mysqldb for Ansible\n#  package: pkg=python-mysqldb state=present\n\n\n- name: Install MySQL-python for Ansible\n  apt: name=python-mysqldb state=present\n  when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'\n\n- name: Install python-mysqldb for Ansible\n  yum: name=MySQL-python state=present\n  when: ansible_os_family == 'RedHat' or ansible_os_family == 'Oracle Linux'\n\n- debug: msg=\"WARNING - you have to change default mysql_root_password\"\n  when: mysql_root_password == '-----====>SetR00tPa$$wordH3r3!!!<====-----'\n\n- name: root password is present\n  mysql_user: name=root host={{item}} password={{mysql_root_password | mandatory}} state=present\n  with_items:\n    - '::1'\n    - '127.0.0.1'\n    - 'localhost'\n\n- name: install .my.cnf with credentials\n  template: src=my.cnf.j2 dest={{mysql_user_home}}/.my.cnf \n            mode=0400\n  tags: my_cnf\n\n- name: test database is absent\n  mysql_db: name=test state=absent\n  when: mysql_remove_test_database\n\n# Can use only if ansible ver => 2.1\n#- name: anonymous users are absent\n#  mysql_user: name='' state=absent host_all=yes\n#  when: mysql_remove_anonymous_users\n\n- name: copy mysql_remove_anonymous_users\n  copy: src='{{item}}.sql' dest='/tmp/{{item}}.sql'\n  with_items:\n    - mysql_remove_anonymous_users\n  when: mysql_remove_anonymous_users\n  changed_when: false\n\n- name: apply mysql_remove_anonymous_users\n  mysql_db: name='mysql' state=import target='/tmp/{{item}}.sql' \n  with_items:\n    - mysql_remove_anonymous_users\n  when: mysql_remove_anonymous_users\n  changed_when: false\n\n- name: copy mysql_remove_remote_root\n  copy: src='{{item}}.sql' dest='/tmp/{{item}}.sql'\n  with_items:\n    - mysql_remove_remote_root\n  when: mysql_remove_remote_root\n  changed_when: false\n\n- name: apply mysql_remove_remote_root\n  mysql_db: name='mysql' state=import target='/tmp/{{item}}.sql' \n  with_items:\n    - mysql_remove_remote_root\n  when: mysql_remove_remote_root\n  changed_when: false\n"}, {"commit_sha": "21712b74b7f5d936e70186bbed6bb37e3a7ad5e6", "sha": "7bfc1c42f6a3af360da3bcb87edeec5a89642d19", "filename": "roles/frameworks/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for frameworks\n- include_vars: \"{{ item }}.yml\"\n  with_items:\n    - \"{{ frameworks_list }}\"\n\n- name: \"create config directory\"\n  when: \"frameworks_{{ item }}_enabled | bool\"\n  run_once: true\n  template:\n    src: \"{{ item }}-config.j2\"\n    dest: \"/tmp/{{ item }}-config\"\n    mode: 0755\n  sudo: yes\n  tags:\n    - \"{{ item }}\"\n  with_items:\n    - \"{{ frameworks_list }}\"\n\n- name: \"install dcos-cli package\"\n  when: \"frameworks_{{ item }}_enabled | bool\"\n  run_once: true\n  docker:\n    name: \"{{ item }}\"\n    image: \"{{ frameworks_dcos_cli_image }}\"\n    state: started\n    command: \"package install --options=/config --yes {{ item }}\"\n    volumes:\n    - \"/tmp/{{ item }}-config:/config\"\n    env:\n      MESOS_MASTER_URL: \"{{ frameworks_mesos_master_url }}\"\n      MARATHON_URL: \"{{ frameworks_marathon_url }}\"\n      SOURCES: \"{{ frameworks_sources }}\"\n  tags:\n    - \"{{ item }}\"\n  with_items:\n    - \"{{ frameworks_list }}\"\n\n- name: \"uninstall dcos-cli package\"\n  when: \"not frameworks_{{ item }}_enabled | bool\"\n  run_once: true\n  docker:\n    name: \"{{ item }}\"\n    image: \"{{ frameworks_dcos_cli_image }}\"\n    state: started\n    command: \"package uninstall {{ item }}\"\n    env:\n      MESOS_MASTER_URL: \"{{ frameworks_mesos_master_url }}\"\n      MARATHON_URL: \"{{ frameworks_marathon_url }}\"\n  tags:\n    - \"{{ item }}\"\n  with_items:\n    - \"{{ frameworks_list }}\"\n\n"}, {"commit_sha": "df06f3c3304c3f73f740d444222642fbad41bebb", "sha": "b46fedf76dd34cb41fcca36bd8fe888f6a538db1", "filename": "tasks/yum_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Add tor rpm key\n  become: yes\n  rpm_key: state=present key=https://deb.torproject.org/torproject.org/rpm/RPM-GPG-KEY-torproject.org.asc\n\n- set_fact: tor_rpm_distribution_os=\"el\"\n  when: ansible_distribution == 'CentOS' or ansible_distribution == \"Red Hat Enterprise Linux\"\n\n# we do not actually support Fedora\n- set_fact: tor_rpm_distribution_os=\"fc\"\n  when: ansible_distribution == 'Fedora'\n\n# the tor_alpha var is taken into account here (template)\n- name: Add torproject.org repository (YUM)\n  become: yes\n  template: src=torproject.yum.repo dest=/etc/yum.repos.d/torproject.repo owner=root group=root\n\n# we specifically opt for present over latest to improve performance\n# \"latest\" is covered by auto updates\n- name: Ensure Tor package is installed (YUM)\n  become: yes\n  yum: name=tor state=present\n\n# we need this for the seboolean ansible module to work\n- name: Ensure setsebool (SELinux) dependencies are installed (CentOS)\n  become: yes\n  yum: name=libsemanage-python state=present\n  when: ansible_selinux.status == 'enabled'\n\n- name: Ensure the presence of the multi-instance systemd unit file (CentOS)\n  become: yes\n  copy: src=centos_tor@.service dest=/lib/systemd/system/tor@.service owner=root mode=0644 backup=yes setype=tor_unit_file_t\n  notify: systemctl daemon-reload\n\n- name: Ensure SELinux boolean (tor_can_network_relay) is set appropriately (CentOS)\n  become: yes\n  seboolean: name=tor_can_network_relay state=yes persistent=yes\n  when: ansible_selinux.status == 'enabled'\n\n- meta: flush_handlers\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "a5318e744de3b0d6662b3e45dd52994d1c2f9e07", "filename": "roles/cadvisor/meta/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Alberto Lamela\n  description:\n  company: Capgemini\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (MIT)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: Ubuntu\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n     - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies:\n  - role: handlers\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "15d2da095f9bd54a50954dee18597710e1951943", "sha": "8b2fb1acb8bc5c5d2f5732ed5670bcff30f192fa", "filename": "handlers/main.yml", "repository": "ansiblebit/oracle-java", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# file: oracle-java/handlers/main.yml\n#\n# Handlers file.\n#\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "f358c9db5bd43558d4e6fe3646663773e5e77c37", "filename": "tasks/main.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# File: main.yml - Main tasks for Consul\n\n- name: Install python dependencies\n  when:\n    - consul_install_dependencies | bool\n  block:\n    - name: Install netaddr dependency on controlling host (with --user)\n      pip:\n        name: netaddr\n        extra_args: --user\n      delegate_to: 127.0.0.1\n      become: false\n      vars:\n        ansible_become: false\n      run_once: true\n      when: not is_virtualenv or is_virtualenv == None\n\n    - name: Install netaddr dependency on controlling host (virtualenv)\n      pip:\n        name: netaddr\n      delegate_to: 127.0.0.1\n      become: false\n      vars:\n        ansible_become: false\n      run_once: true\n      when: is_virtualenv is defined\n\n- name: Include checks/asserts\n  import_tasks: asserts.yml\n\n- name: Include OS-specific variables\n  include_vars: \"{{ ansible_os_family }}.yml\"\n  tags: always\n\n# -----------------------------------------------------------------------\n# Tasks for all *NIX operating systems\n# -----------------------------------------------------------------------\n- name: Include NIX tasks\n  include_tasks: nix.yml\n  when: ansible_os_family != 'Windows'\n\n# -----------------------------------------------------------------------\n# Tasks for Windows\n# -----------------------------------------------------------------------\n- name: Include Windows tasks\n  include_tasks: windows.yml\n  when: ansible_os_family == 'Windows'\n\n- name: Include services management\n  import_tasks: services.yml\n  when: consul_services is defined and consul_services|length>0\n  tags:\n    - consul_services\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "43cb3f756d73bec6237f795020f74b8dc76f5cf6", "filename": "roles/mistral/tasks/gather_facts.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "- name: Pick Mistral branch\n  set_fact:\n    mistral_branch: \"{{ item.then }}\"\n  when: \"mistral_version | version_compare(item.if, operator='ge')\"\n  with_items: mistral_branches\n"}, {"commit_sha": "af3dfdf7cf37437f5609f1a12e4ac7cbaebd4867", "sha": "8a50e52bf1e859577842fb54f5319a9426fb27e1", "filename": "roles/marathon/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for marathon\n- name: restart marathon\n  sudo: yes\n  service:\n    name: marathon\n    state: restarted\n  sudo: yes\n  notify:\n    - wait for marathon to listen\n\n- name: wait for marathon to listen\n  command: /usr/local/bin/marathon-wait-for-listen.sh\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "d801d5ab81109abe0807da8f19e936d83eaf64b8", "filename": "tasks/section_04.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - include: section_04_level1.yml\n    tags:\n      - section04\n      - level1\n\n  - include: section_04_level2.yml\n    tags:\n      - section04\n      - level2\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "026249289dea029405ce63c3126fc5bee174ad3b", "filename": "roles/mistral/tasks/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n\n- name: Install latest st2mistral\n  sudo: yes\n  apt: \n    name: st2mistral\n    state: latest\n  when: mistral_version == \"stable\"\n\n- name: Install latest st2mistral\n  sudo: yes\n  apt:\n    name: st2mistral={{ mistral_version }}\n    state: present\n  when: mistral_version != \"stable\"\n\n- name: Configure mistral\n  sudo: yes\n  ini_file:\n    dest: /etc/mistral/mistral.conf\n    section: database\n    option: connection\n    value: postgresql://{{ mistral_db_username }}:{{ mistral_db_password }}@localhost/{{ mistral_db }}\n    backup: yes\n\n- name: Deploy database init script\n  sudo: yes\n  template:\n    src: init_mistral_db.SQL.j2\n    dest: /etc/mistral/init_mistral_db.SQL \n  notify: \n    - restart mistral\n\n- name: Initiate database\n  become: yes\n  become_user: postgres\n  shell: psql < /etc/mistral/init_mistral_db.SQL\n  args: \n    creates: /etc/mistral/init_mistral_db.SQL.ansible.has.run\n  notify:\n    - restart mistral\n\n- name: Make sure \"Initiate database\" doesn't run twice\n  sudo: yes\n  file:\n    path: /etc/mistral/init_mistral_db.SQL.ansible.has.run\n    state: touch\n\n- name: Setup Mistral DB tables, etc\n  sudo: yes\n  command: /opt/stackstorm/mistral/bin/mistral-db-manage --config-file /etc/mistral/mistral.conf upgrade head\n  args:\n    creates: /etc/mistral/mistral-db-manage.upgrade.head.ansible.has.run\n  notify: \n    - restart mistral\n\n- name: Make sure \"Setup Mistral DB tables, etc\" does not run again\n  sudo: yes\n  file:\n    path: /etc/mistral/mistral-db-manage.upgrade.head.ansible.has.run\n    state: touch\n\n- name: Register mistral actions\n  sudo: yes\n  command: /opt/stackstorm/mistral/bin/mistral-db-manage --config-file /etc/mistral/mistral.conf populate\n  args:\n    creates: /etc/mistral/mistral-db-manage.populate.ansible.has.run\n  notify:\n    - restart mistral\n\n- name: Make sure \"Register mistral actions\" does not run again\n  sudo: yes\n  file:\n    path: /etc/mistral/mistral-db-manage.upgrade.head.ansible.has.run\n    state: touch\n"}, {"commit_sha": "fa66f2d6f5193cce5c2f9086e78f9bff39133e60", "sha": "8c03638344ecdd2753792b206bcfbede32eb6e91", "filename": "tasks/linux_service.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n# Linux/systemd section (uses service module)\n# ===========================================\n \n- name: Ensure Tor instances are reloaded if its torrc changed (Linux/systemd)\n  become: yes\n  service: name=tor@{{ item.item[0] }}_{{ item.item.1.orport }}.service state=reloaded\n  with_items: instances.results\n  when: item.changed == True\n  tags:\n   - debian\n   - centos\n   - fedora\n   - reconfigure\n\n- name: Ensure Tor instances are enabled and started (Linux/systemd)\n  become: yes\n  service: name=tor@{{ item[0] }}_{{ item.1.orport }}.service enabled=yes state=started\n  with_nested:\n   - tor_ips\n   - tor_ports\n  tags:\n   - debian\n   - centos\n   - fedora\n"}, {"commit_sha": "7f02cba4441b5367d6916857c9b41f3abae915db", "sha": "b837956bb9cb84bdbeff0285fd6c3c4a3c5f7b2e", "filename": "tasks/apt_prepare.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Ensure lsb-release and apt-transport-https packages are installed\n  become: yes\n  apt:\n    name: lsb-release,apt-transport-https\n  notify:\n    - re-gather facts\n\n- meta: flush_handlers\n\n- name: Ensure torproject gpg key is installed (A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89)\n  become: yes\n  apt_key:\n    data: \"{{ lookup('file', 'deb.torproject.org_A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89.pub') }}\"\n    id: A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89\n    state: present\n\n- name: Ensure torproject.org repository is present (APT)\n  become: yes\n  apt_repository:\n    repo: 'deb https://deb.torproject.org/torproject.org {{ tor_distribution_release }} main'\n    state: present\n    update_cache: yes\n\n- name: Override tor_alpha_version if nightly builds repo is enabled (APT)\n  set_fact:\n    tor_alpha_version: nightly-master\n    tor_alpha: True\n  when: tor_nightly_builds\n\n- name: Ensure torproject.org alpha/nightly repo is present if enabled (APT)\n  become: yes\n  apt_repository:\n    repo: >\n        'deb https://deb.torproject.org/torproject.org\n        tor-{{ tor_alpha_version }}-{{ tor_distribution_release }} main'\n    state: present\n    update_cache: yes\n  when: tor_alpha\n\n# Background:\n# https://github.com/nusenu/ansible-relayor/issues/72\n- name: Ensure systemd generator folder exists (Debian/Ubuntu)\n  become: yes\n  file:\n    path: /etc/systemd/system-generators\n    state: directory\n    mode: 0755\n\n- name: Ensure custom systemd generator is in place (Debian/Ubuntu only)\n  become: yes\n  copy:\n    src: tor-generator\n    dest: /etc/systemd/system-generators/tor-generator\n    owner: root\n    mode: 0755\n\n#- name: Ensure AppArmor allows access to necessary files (Ubuntu)\n#  become: yes\n#  lineinfile: dest=/etc/apparmor.d/local/system_tor line={{ item }}\n#  with_items:\n#    - '/etc/tor/enabled/*\\ r,'\n#    - '/{,var/}run/tor/*.pid\\ w,'\n#    - '/var/lib/tor/**\\ w,'\n#  when: ansible_distribution == 'Ubuntu'\n#  notify: restart apparmor\n\n#- meta: flush_handlers\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "672364ac9d672ab9450a7eb8ce05b8aa434c45f9", "filename": "roles/mistral/meta/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\ngalaxy_info:\n  description: Install custom OpenStack Mistral, patched by StackStorm\n  author: armab\n  company: StackStorm\n  license: Apache\n  min_ansible_version: 1.9.1\n  platforms:\n    - name: Ubuntu\n      versions:\n        - trusty\n        - precise\n  categories:\n    - system\ndependencies:\n  - role: ANXS.postgresql\n    version: v1.2.1\n    tags: [db, postgresql]\n    sudo: yes\n    postgresql_databases:\n      - name: \"{{ mistral_db }}\"\n    postgresql_users:\n      - name: \"{{ mistral_db_username }}\"\n        pass: \"{{ mistral_db_password }}\"\n        encrypted: yes\n  - role: st2repos\n"}, {"commit_sha": "5eb44163b7f6328c1f30168fa86326458d5dbaff", "sha": "ef359a0ad31046500f6f863e29eb2923e3e0f256", "filename": "tasks/darwin/macosx.yml", "repository": "ansiblebit/oracle-java", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# file: oracle-java/tasks/darwin/macosx.yml\n#\n# Task file to install Oracle Java Development Kit in a system with a OSX based Darwin distribution.\n#\n\n- name: download DMG file\n  shell:\n    \"curl -L  -H 'Cookie:oraclelicense=accept-securebackup-cookie' -o {{ oracle_java_dir_source }}/{{ oracle_java_dmg_filename }} {{ oracle_java_dmg_url }}\"\n  when: not oracle_java_task_dmg_check|skipped and not oracle_java_task_dmg_check.stat.exists\n  args:\n    creates: \"{{ oracle_java_dir_source }}/{{ oracle_java_dmg_filename }}\"\n  tags:\n    - installation\n\n- name: mount DMG image\n  shell: echo TODO\n  tags:\n    - installation\n\n- name: install JDK\n  shell: echo TODO\n  tags:\n    - installation\n\n- name: unmount DMG image\n  shell: echo TODO\n  tags:\n    - installation\n\n- name: set Java version as default\n  shell: echo TODO\n  when: oracle_java_set_as_default\n  register: oracle_java_task_set_default\n  sudo: yes\n\n- name: in case there were changes, check host environment again\n  include: ../check_environment.yml\n\n"}, {"commit_sha": "067d6cbb20adb31a1e2bd9f689b5b6e259c30288", "sha": "7d7892e9531f26330476956bda3f90fe622354c7", "filename": "tasks/section_07_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 7.1.1 Disable IP Forwarding (Scored)\n    sysctl: >\n      name=net.ipv4.ip_forward\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.1\n\n  - name: 7.1.2.1 Disable Send Packet Redirects (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.2\n      - section7.1.2.1\n\n  - name: 7.1.2.2 Disable Send Packet Redirects (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.2\n      - section7.1.2.2\n\n  - name: 7.2.1.1 Disable Source Routed Packet Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.accept_source_route\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.1\n      - section7.2.1.1\n\n  - name: 7.2.1.2 Disable Source Routed Packet Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.accept_source_route\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.1\n      - section7.2.1.2\n\n  - name: 7.2.2.1 Disable ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.2\n      - section7.2.2.1\n\n  - name: 7.2.2.2 Disable ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.2\n      - section7.2.2.2\n\n  - name: 7.2.3.1 Disable Secure ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.secure_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.3\n      - section7.2.3.1\n\n  - name: 7.2.3.2 Disable Secure ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.secure_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.3\n      - section7.2.3.2\n\n  - name: 7.2.4.1 Log Suspicious Packets (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.log_martians\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.4\n      - section7.2.4.1\n\n  - name: 7.2.4.2 Log Suspicious Packets (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.log_martians\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.4\n      - section7.2.4.2\n\n  - name: 7.2.5 Enable Ignore Broadcast Requests (Scored)\n    sysctl: >\n      name=net.ipv4.icmp_echo_ignore_broadcasts\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.5\n\n  - name: 7.2.6 Enable Bad Error Message Protection (Scored)\n    sysctl: >\n      name=net.ipv4.icmp_ignore_bogus_error_responses\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.6\n\n  - name: 7.2.7.1 Enable RFC-recommended Source Route Validation (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.rp_filter\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.7\n      - section7.2.7.1\n\n  - name: 7.2.7.2 Enable RFC-recommended Source Route Validation (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.rp_filter\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.7\n      - section7.2.7.2\n\n  - name: 7.2.8 Enable TCP SYN Cookies (Scored)\n    sysctl: >\n      name=net.ipv4.tcp_syncookies\n      value=1\n      state=present\n    when: enable_tcp_syncookies\n    tags:\n      - section7\n      - section7.2\n      - section7.2.8\n\n  - name: 7.3.1.1 Disable IPv6 Router Advertisements (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.all.accept_ra\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.1\n      - section7.3.1.1\n\n  - name: 7.3.1.2 Disable IPv6 Router Advertisements (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.default.accept_ra\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.1\n      - section7.3.1.2\n\n  - name: 7.3.2.1 Disable IPv6 Redirect Acceptance (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.all.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.2\n      - section7.3.2.1\n\n  - name: 7.3.2.2 Disable IPv6 Redirect Acceptance (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.default.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.2\n      - section7.3.2.2\n\n  - name: 7.3.3 Disable IPv6 (Not Scored)\n    sysctl: >\n      name={{ item }}\n      value=1\n      state=present\n    with_items:\n      - net.ipv6.conf.all.disable_ipv6\n      - net.ipv6.conf.default.disable_ipv6\n      - net.ipv6.conf.lo.disable_ipv6\n    when: disable_ipv6 == True\n    tags:\n      - section7\n      - section7.3\n      - section7.3.3\n\n  - name: 7.4.1 Install TCP Wrappers (Scored)\n    apt: name=tcpd state=present\n    tags:\n      - section7\n      - section7.4\n      - section7.4.1\n\n  - name: 7.4.2 Create /etc/hosts.allow (Not Scored)\n    debug: msg=\"*** Verify /etc/hosts.allow ***\"\n    tags:\n      - section7\n      - section7.4\n      - section7.4.2\n\n  - name: 7.4.3 Verify Permissions on /etc/hosts.allow (Scored)\n    file: >\n        path=/etc/hosts.allow\n        owner=root\n        group=root\n        mode=0644\n    tags:\n      - section7\n      - section7.4\n      - section7.4.3\n\n  - name: 7.4.4 Create /etc/hosts.deny (Not Scored)\n    debug: msg='*** Verify /etc/hosts.deny ***'\n    tags:\n      - section7\n      - section7.4\n      - section7.4.4\n\n  - name: 7.4.5 Verify Permissions on /etc/hosts.deny (Scored)\n    file: >\n        path=/etc/hosts.deny\n        owner=root\n        group=root\n        mode=0644\n    tags:\n      - section7\n      - section7.4\n      - section7.4.5\n\n  - name: 7.5.0 Check the presence of the file \"cis.conf\" under modprobe.d\n    stat: >\n        path=/etc/modprobe.d/CIS.conf\n    register: cis_conf_file\n    tags:\n      - section7\n      - section7.5\n\n  - name: 7.5.0 Create the file \"cis.conf\" under modprobe.d if doesn't exist\n    file: >\n        dest=/etc/modprobe.d/CIS.conf state=touch\n    when: not cis_conf_file.stat.exists\n    tags:\n      - section7\n      - section7.5\n\n  - name: 7.5.1-4 Disable DCCP, SCTP, RDS, TIPC (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install {{ item }} /bin/true'\n        state=present\n    with_items:\n        - dccp\n        - sctp\n        - rds\n        - tipc\n    tags:\n      - section7\n      - section7.5\n      - section7.5.1\n      - section7.5.2\n      - section7.5.3\n      - section7.5.4\n\n  - name: 7.6 Deactivate Wireless Interfaces (Not Scored)\n    shell: 'lspci -k | grep -i wifi'\n    changed_when: False\n    register: lspci_wifi\n    failed_when: lspci_wifi.rc == 0\n    tags:\n      - section7\n      - section7.6\n\n  - name: 7.7 Ensure Firewall is active (install) (Scored)\n    apt: >\n        name=ufw\n        state=present\n    when: activate_ufw\n    tags:\n      - section7\n      - section7.7\n\n  - name: 7.7 Ensure Firewall is active (Scored)\n    service: >\n        name=ufw\n        state=started\n    when: activate_ufw\n    tags:\n      - section7\n      - section7.7\n"}, {"commit_sha": "e8eb28b4b4b1c4fb2490b8198570166b9ca23ab2", "sha": "625c46c7293b258f7eca96750c7687d427288c3c", "filename": "roles/mysql/defaults/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "mysql:\n  login: root\n  password: StackStorm\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "6d7266b35ac0526451c1520ef820a4173560a0f6", "filename": "roles/zookeeper/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for zookeeper\n- name: restart zookeeper\n  service:\n    name: zookeeper\n    state: restarted\n  sudo: yes\n\n- name: start zookeeper\n  service:\n    name: zookeeper\n    state: started\n  sudo: yes\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "e151e689e5b7bd121e89a60b5de2a16518905b86", "filename": "playbooks/coreos-bootstrap.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- name: bootstrap coreos hosts\n  hosts: all:!role=bastion\n  gather_facts: False\n  environment: \"{{ proxy_env }}\"\n  roles:\n    - coreos_bootstrap\n    - coreos_timezone\n  environment: \"{{ proxy_env }}\"\n\n- name: Install docker-py\n  hosts: all:!role=bastion\n  gather_facts: False\n  environment: \"{{ proxy_env }}\"\n  tasks:\n    - pip:\n        name: docker-py\n        version: 1.5.0\n"}, {"commit_sha": "8cf75eb68465f1126872131afd102e05068a9df2", "sha": "2dd84676cd679c2ba69222092c76584539179951", "filename": "tasks/openbsd_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Setup OpenBSD specific variables (set_fact)\n  set_fact:\n    tor_DataDir: /var/tor\n    tor_PidDir: /var/tor/pids\n  tags:\n   - configure\n   - createdir\n\n- name: Ensure Tor is installed (OpenBSD)\n  sudo: yes\n  openbsd_pkg: name=tor state=present\n\n- name: Gather current system-wide file descriptor limits (OpenBSD)\n  shell: \"sysctl kern.maxfiles|cut -d= -f2\"\n  register: currentlimits\n\n- name: Ensure system-wide runtime file descriptor limits are reasonable (OpenBSD)\n  sudo: yes\n  command: \"sysctl kern.maxfiles=20000\"\n  when: currentlimits.stdout|int < 20000\n\n- name: Ensure system-wide persistent file descriptor limits are reasonable (OpenBSD)\n  sudo: yes\n  lineinfile: dest=/etc/sysctl.conf regexp=^kern.maxfiles line=\"kern.maxfiles=20000\" create=yes\n  when: currentlimits.stdout|int < 20000\n\n# We rise openfiles limits for every tor instance separately.\n# An instance is identified by its rc.d file name.\n- name: Ensure Tor process file descriptor limits are reasonable (OpenBSD)\n  sudo: yes\n  lineinfile: \"dest=/etc/login.conf line='tor{{ item[0]| replace('.','_') }}_{{ item.1.orport }}::openfiles-max=13500::tc=daemon:'\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n  #TODO\n  #notify: restart tor\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "5904626bbd2891b7fdebab15a4bb4317e7a5a820", "filename": "roles/traefik/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ntraefik_marathon_hostname: marathon.service.{{ consul_domain }}\ntraefik_marathon_endpoint: \"http://{{ traefik_marathon_hostname }}:8080\"\ntraefik_marathon_domain: marathon.localhost\ntraefik_version: v1.0.alpha.481\ntraefik_image: \"emilevauge/traefik:{{ traefik_version }}\"\ntraefik_config_dir: /etc/traefik\ntraefik_frontend_port: 80\ntraefik_webui_port: 8888\ntraefik_log_level: DEBUG\ntraefik_consul_dir: /etc/consul.d\ntraefik_docker_socket: \"{{ docker_host }}\"\ntraefik_network_interface: \"{{ traefik_network_interface }}\"\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "7e85e1f8652f59d3a332fcaaa9a07ca92b4bb16f", "filename": "roles/weave/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n- name: download weave\n  sudo: yes\n  sudo_user: root\n  get_url:\n    url: \"{{ weave_url }}\"\n    dest: \"{{ weave_bin }}\"\n    mode: 0755\n    validate_certs: no\n  environment: proxy_env\n  tags:\n    - weave\n\n- name: deploy weave service\n  sudo: yes\n  sudo_user: root\n  template:\n    src: \"{{ item.src }}\"\n    dest: \"{{ item.dest }}\"\n  with_items:\n    - src: \"weave.service.j2\"\n      dest: \"/etc/systemd/system/weave.service\"\n    - src: \"weaveproxy.service.j2\"\n      dest: \"/etc/systemd/system/weaveproxy.service\"\n  tags:\n    - weave\n\n- name: ensure weave service is running.\n  sudo: yes\n  service:\n    name: weave\n    state: started\n    enabled: yes\n  tags:\n    - weave\n\n- name: ensure weaveproxy service is running.\n  sudo: yes\n  service:\n    name: weaveproxy\n    state: started\n    enabled: yes\n  tags:\n    - weave\n\n- name: wait for weave socket to be ready.\n  wait_for:\n    port: 6783\n    delay: 10\n\n# Flush handlers so we restart the Docker process here with the weave network\n# enabled and containers correctly start in the weave network.\n- meta: flush_handlers\n"}, {"commit_sha": "12d2d30c292e5749809cd7476458762a4de31554", "sha": "f01c985bd1961fc3d0d72ce475ed5fbb146ffe3f", "filename": "tasks/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- include: apt_install.yml\n  when: ansible_pkg_mgr == 'apt'\n  tags: debian\n\n- include: yum_install.yml\n  when: ansible_pkg_mgr == 'yum'\n  tags: centos\n\n- include: openbsd_install.yml\n  when: ansible_pkg_mgr == 'openbsd_pkg'\n  tags: openbsd\n\n- include: freebsd_install.yml\n  when: ansible_pkg_mgr == 'pkgng'\n  tags: freebsd\n\n- include: configure.yml\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "70cf3aa8effc872e8cdf61c54cb0056fbd7644f3", "filename": "tasks/section_09.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - include: section_09_level1.yml\n    tags:\n      - section09\n      - level1\n\n"}, {"commit_sha": "32211ebd2a9f45112f8dceda80bc95d0db029fb4", "sha": "890ab776110bcad3149fe65b79784ae23b13000d", "filename": "tasks/openbsd_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Setup OpenBSD specific variables (set_fact)\n  set_fact:\n    tor_DataDir: /var/tor-instances\n    tor_ConfDir: /etc/tor/enabled\n  tags:\n   - reconfigure\n   - renewkey\n\n- name: Ensure Tor is installed (OpenBSD)\n  become: yes\n  openbsd_pkg: name=tor state=present\n  tags:\n   - install\n\n- name: Gather current system-wide file descriptor limits (OpenBSD)\n  shell: \"sysctl kern.maxfiles|cut -d= -f2\"\n  register: currentlimits\n\n- name: Ensure system-wide runtime file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  command: \"sysctl kern.maxfiles=20000\"\n  when: currentlimits.stdout|int < 20000\n\n- name: Ensure system-wide persistent file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  lineinfile: dest=/etc/sysctl.conf regexp=^kern.maxfiles line=\"kern.maxfiles=20000\" create=yes\n  when: currentlimits.stdout|int < 20000\n\n# We rise openfiles limits for every tor instance separately.\n# An instance is identified by its rc.d file name.\n- name: Ensure Tor process file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  lineinfile: \"dest=/etc/login.conf line='tor{{ item.0.ipv4| replace('.','_') }}_{{ item.1.orport }}::openfiles-max=13500::tc=daemon:'\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n"}, {"commit_sha": "35ca6852d9333ef6c3ed223239f45b840c487d60", "sha": "d930a02dfc239b0272d3caf19dadcf5e816aa1e0", "filename": "roles/registrator/meta/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Alberto Garcia\n  description:\n  company: Capgemini\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (MIT)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: Ubuntu\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n     - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies:\n  - role: docker\n  - role: consul\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "ec4de12ae75f7191a5f71aa775e0344679ea1477", "sha": "5d9f5278cd5087e4a89f3353555e747d8691d1ef", "filename": "handlers/main.yml", "repository": "UnderGreen/ansible-role-mongodb", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: mongodb reload\n  service: name={{ mongodb_daemon_name }} state=reloaded\n\n- name: mongodb restart\n  service: name={{ mongodb_daemon_name }} state=restarted\n\n- name: mongodb-mms-automation-agent restart\n  service: name=mongodb-mms-automation-agent state=restarted\n\n- name: reload systemd\n  shell: systemctl daemon-reload\n  when: systemd.stat.exists == true\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "9cc9c246d277c9f314561ea72c9950498e4f48bc", "filename": "tasks/Amazon/main.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/Amazon/main.yml: CentOS specific set-up\n# This takes care of base prerequisites for Amazon Linux AMI\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure the Sensu Core Yum repo is present\n    copy:\n      dest: /etc/yum.repos.d/sensu.repo\n      content: |\n        [sensu]\n        name=sensu\n        baseurl=https://sensu.global.ssl.fastly.net/yum/$releasever/$basearch/\n        gpgcheck=0\n        enabled=1\n      owner: root\n      group: root\n      mode: 0644\n\n  - name: Ensure Sensu is installed\n    yum: name={{ sensu_package }} state={{ sensu_pkg_state }}\n"}, {"commit_sha": "067d6cbb20adb31a1e2bd9f689b5b6e259c30288", "sha": "b2f012a846291276803396aaec5e8efe504ecf0b", "filename": "tasks/section_08_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n# Change order or the default auditd.conf file will not be created\n  - name: 8.1.2 Install and Enable auditd Service (Scored)\n    apt: name=auditd state=present\n    tags:\n      - section8\n      - section8.1\n      - section8.1.2\n      - section8.1.2\n\n  - name: Check if the file auditd.conf exists\n    stat: >\n        path=/etc/audit/auditd.conf\n    register: auditd_file\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n\n  - name: Create the audit directory if it does not exists\n    file: >\n        path=/etc/audit/\n        state=directory\n    when: not auditd_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n\n  - name: 8.1.1-3 Configure Data Retention\n    lineinfile: >\n        dest=/etc/audit/auditd.conf\n        regexp=\"{{ item.rxp }}\"\n        line=\"{{ item.line }}\"\n        state=present\n        create=yes\n    with_items:\n      - { rxp: '^max_log_file ', line: 'max_log_file = {{ max_log_file_auditd }}' }\n      - { rxp: '^space_left_action', line: 'space_left_action = email' }\n      - { rxp: '^action_mail_acct', line: 'action_mail_acct = root' }\n      - { rxp: '^admin_space_left_action', line: 'admin_space_left_action = halt' }\n      - { rxp: '^max_log_file_action', line: 'max_log_file_action = keep_logs' }\n    notify: restart auditd\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n      - section8.1.1.2\n      - section8.1.1.3\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    stat: path=/etc/default/grub\n    register: grubcfg_file\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    file: >\n        path=/etc/default/grub\n        state=touch\n    when: not grubcfg_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    lineinfile: >\n        dest=/etc/default/grub\n        line='GRUB_CMDLINE_LINUX=\"audit=1\"'\n    when: not grubcfg_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.4 Record Events That Modify Date and Time Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a always,exit -F arch=b64 -S adjtimex -S settimeofday -k time-change'\n      - '-a always,exit -F arch=b32 -S adjtimex -S settimeofday -S stime -k time-change'\n      - '-a always,exit -F arch=b64 -S clock_settime -k time-change'\n      - '-a always,exit -F arch=b32 -S clock_settime -k time-change'\n      - '-w /etc/localtime -p wa -k time-change'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"64\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.4\n\n  - name: 8.1.4 Record Events That Modify Date and Time Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a always,exit -F arch=b32 -S adjtimex -S settimeofday -S stime -k time-change'\n      - '-a always,exit -F arch=b32 -S clock_settime -k time-change'\n      - '-w /etc/localtime -p wa -k time-change'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"32\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.4\n\n  - name: 8.1.5,7,8,9,15,16,17 Record Events That Modify User/Group Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-w /etc/group -p wa -k identity'\n      - '-w /etc/passwd -p wa -k identity'\n      - '-w /etc/gshadow -p wa -k identity'\n      - '-w /etc/shadow -p wa -k identity'\n      - '-w /etc/security/opasswd -p wa -k identity'\n      - '-w /var/log/faillog -p wa -k logins'\n      - '-w /var/log/lastlog -p wa -k logins'\n      - '-w /var/log/tallylog -p wa -k logins'\n      - '-w /var/run/utmp -p wa -k session'\n      - '-w /var/log/wtmp -p wa -k session'\n      - '-w /var/log/btmp -p wa -k session'\n      - '-w /etc/selinux/ -p wa -k MAC-policy'\n      - '-w /etc/sudoers -p wa -k scope'\n      - '-w /var/log/sudo.log -p wa -k actions'\n      - '-w /sbin/insmod -p x -k modules'\n      - '-w /sbin/rmmod -px -k modules'\n      - '-w /sbin/modprobe -p x -k modules'\n    notify: restart auditd\n    tags:\n      - section8\n      - section8.1\n      - section8.1.5\n      - section8.1.7\n      - section8.1.8\n      - section8.1.9\n      - section8.1.15\n      - section8.1.16\n      - section8.1.17\n\n  - name: 8.1.6,10,11,13,14,17 Record Events That Modify the System's Network Environment (64b) (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a exit,always -F arch=b64 -S sethostname -S setdomainname -k system-locale'\n      - '-a exit,always -F arch=b32 -S sethostname -S setdomainname -k system-locale'\n      - '-w /etc/issue -p wa -k system-locale'\n      - '-w /etc/issue.net -p wa -k system-locale'\n      - '-w /etc/hosts -p wa -k system-locale'\n      - '-w /etc/network -p wa -k system-locale'\n      - '-a always,exit -F arch=b64 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b64 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b64 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b32 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b64 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b32 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b64 -S init_module -S delete_module -k modules'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"64\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.6\n      - section8.1.10\n      - section8.1.11\n      - section8.1.13\n      - section8.1.14\n      - section8.1.17\n\n  - name: 8.1.6,10,11,13,14,17 Record Events That Modify the System's Network Environment (32b) (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a exit,always -F arch=b32 -S sethostname -S setdomainname -k system-locale'\n      - '-w /etc/issue -p wa -k system-locale'\n      - '-w /etc/issue.net -p wa -k system-locale'\n      - '-w /etc/hosts -p wa -k system-locale'\n      - '-w /etc/network -p wa -k system-locale'\n      - '-a always,exit -F arch=b32 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b32 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b32 -S init_module -S delete_module -k modules'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"32\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.6\n      - section8.1.10\n      - section8.1.11\n      - section8.1.13\n      - section8.1.14\n      - section8.1.17\n\n  - name: 8.1.12 Collect Use of Privileged Commands (Scored)\n    shell: find / -xdev \\( -perm -4000 -o -perm -2000 \\) -type f | awk '{print \"-a always,exit -F path=\" $1 \" -F perm=x -F auid>=500 -F auid!=4294967295 -k privileged\" }'\n    register: audit_lines_for_find\n    changed_when: False\n    tags:\n      - section8\n      - section8.1\n      - section8.1.12\n\n  - name: 8.1.12 Collect Use of Privileged Commands (infos) (Scored)\n    lineinfile: >\n        dest=/etc/audit/audit.rules\n        line='{{ item }}'\n        state=present\n        create=yes\n    with_items: audit_lines_for_find.stdout_lines\n    tags:\n      - section8\n      - section8.1\n      - section8.1.12\n\n  - name: 8.1.18 Make the Audit Configuration Immutable (Scored)\n    lineinfile: >\n        dest='/etc/audit/audit.rules'\n        line='-e 2'\n        insertafter=EOF\n        state=present\n        create=yes\n    tags:\n      - section8\n      - section8.1\n      - section8.1.18\n\n  - name: 8.3.1 Install AIDE (Scored)\n    apt: name=aide state=present\n    register: aide_installed\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (init) (Scored)\n    command: aideinit\n    when: aide_installed.changed == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (Scored)\n    stat: path=/var/lib/aide/aide.db.new\n    register: aide_db_path\n    when:\n      - aide_installed.changed == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (copy db) (Scored)\n    command: mv /var/lib/aide/aide.db.new /var/lib/aide/aide.db\n    when:\n      - aide_installed.changed == True\n      - aide_db_path.stat.exists == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.2 Implement Periodic Execution of File Integrity (Scored)\n    cron: name=\"Check files integrity\" minute=\"0\" hour=\"5\" job=\"/usr/sbin/aide --check\"\n    tags:\n      - section8\n      - section8.3\n      - section8.3.2\n"}, {"commit_sha": "ec4de12ae75f7191a5f71aa775e0344679ea1477", "sha": "b9cce2c09be17389157b60db11fba911e2b47ffc", "filename": "tasks/install.deb.yml", "repository": "UnderGreen/ansible-role-mongodb", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- include_vars: \"{{ansible_distribution}}.yml\"\n\n- name: Check if systemd is present\n  stat: path=/bin/systemd\n  register: systemd\n\n- name: Add systemd configuration if present\n  copy: src=mongodb.service dest=/lib/systemd/system/mongodb.service owner=root group=root mode=0640\n  when: systemd.stat.exists == true\n\n- name: Add symlink for systemd\n  file: src=/lib/systemd/system/mongodb.service dest=/etc/systemd/system/multi-user.target.wants/mongodb.service state=link\n  when: systemd.stat.exists == true\n  notify: reload systemd\n\n- meta: flush_handlers\n  when: systemd.stat.exists == true\n\n- name: Add APT key\n  apt_key: url=http://docs.mongodb.org/10gen-gpg-key.asc id=7F0CEB10\n  when: '\"mongodb-org\" in mongodb_package'\n\n- name: Add APT repository\n  apt_repository: repo=\"{{mongodb_repository}}\" update_cache=yes\n  when: '\"mongodb-org\" in mongodb_package'\n\n- name: Install MongoDB package\n  apt: pkg={{mongodb_package}} state=present\n\n- name: reload systemd\n  shell: systemctl daemon-reload\n  changed_when: false\n  when: systemd.stat.exists == true\n\n- name: Install additional packages\n  apt: pkg={{item}}\n  with_items: mongodb_additional_packages\n"}, {"commit_sha": "addbee435e20e706e7cf5d2f0a3723e17f79b527", "sha": "0548d7e2876838a36a4f58985849601e339c8bb4", "filename": "meta/main.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\nallow_duplicates: no\n\n\ngalaxy_info:\n  author: Aur\u00e9lien Wailly\n  description: Ansible role to meet CIS (Center for Internet Security) requirements on ubuntu\n  license: GPLv2\n  min_ansible_version: 1.6\n  platforms:\n    - name: Ubuntu\n      versions:\n        14.04\n  categories:\n    #- cloud\n    #- cloud:ec2\n    #- cloud:gce\n    #- cloud:rax\n    #- clustering\n    #- database\n    #- database:nosql\n    #- database:sql\n    #- development\n    - monitoring\n    #- networking\n    #- packaging\n    - system\n    #- web\n\n\n\ndependencies:\n"}, {"commit_sha": "9ad67b6ef151d5fbaa05230e6cecb4bed1db7d9d", "sha": "336b70faf9f07c24d4ce03b54b0822786ba0a582", "filename": "tasks/section_06_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 6.1 Ensure the X Window system is not installed (Scored)\n    apt: name=xserver-xorg-core* purge=yes state=absent\n    when: remove_xserver == True\n    tags:\n      - section6\n      - section6.1\n\n  - name: 6.2 Ensure Avahi Server is not enabled (check) (Scored)\n    stat: path='/etc/init/avahi-daemon.conf'\n    register: avahi_stat\n    tags:\n      - section6\n      - section6.2\n\n  - name: 6.2 Ensure Avahi Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on (filesystem'\n        state=present\n        regexp='start on \\(filesystem'\n        dest=/etc/init/avahi-daemon.conf\n    when: avahi_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.2\n\n  - name: 6.3 Ensure print server is not enabled (check) (Not Scored)\n    stat: path='/etc/init/cups.conf'\n    register: cups_stat\n    tags:\n      - section6\n      - section6.3\n\n  - name: 6.3 Ensure print server is not enabled (Not Scored)\n    lineinfile: >\n        line='#start on (filesystem'\n        state=present\n        regexp='start on \\(filesystem'\n        dest=/etc/init/cups.conf\n    when: cups_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.3\n\n  - name: 6.4.1 Ensure DHCP Server is not enabled (check) (Scored)\n    stat: path='/etc/init/isc-dhcp-server.conf'\n    register: dhcp_stat\n    tags:\n      - section6\n      - section6.4\n      - section6.4.1\n\n  - name: 6.4.1 Ensure DHCP Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n        dest=/etc/init/isc-dhcp-server.conf\n    when: dhcp_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.4\n      - section6.4.1\n\n  - name: 6.4.2 Ensure DHCP Server is not enabled (check) (Scored)\n    stat: path='/etc/init/isc-dhcp-server6.conf'\n    register: dhcp6_stat\n    tags:\n      - section6\n      - section6.4\n      - section6.4.2\n\n  - name: 6.4.2 Ensure DHCP Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n        dest=/etc/init/isc-dhcp-server6.conf\n    when: dhcp6_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.4\n      - section6.4.2\n\n  - name: 6.5.1 Configure Network Time Protocol (install) (NTP) (Scored)\n    apt: name=ntp state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.1\n\n  - name: 6.5.2 Configure Network Time Protocol (restrict4) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='restrict -4 default kod nomodify notrap nopeer noquery'\n        regexp='^restrict -4 default'\n        state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.2\n\n  - name: 6.5.3 Configure Network Time Protocol (restrict6) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='restrict -6 default kod nomodify notrap nopeer noquery'\n        regexp='^restrict -6 default'\n        state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.3\n\n  - name: 6.5.4 Configure Network Time Protocol (server check) (NTP) (Scored)\n    command: 'grep \"^server\" /etc/ntp.conf'\n    register: ntp_server_rc\n    changed_when: False\n    always_run: True\n    tags:\n      - section6\n      - section6.5\n      - section6.5.4\n\n  - name: 6.5.4 Configure Network Time Protocol (server add) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='server 0.fr.pool.ntp.org'\n        state=present\n    when: ntp_server_rc.rc == 1\n    tags:\n      - section6\n      - section6.5\n      - section6.5.4\n\n  - name: 6.6 Ensure LDAP is not enabled (Not Scored)\n    apt: name=slapd purge=yes state=absent\n    tags:\n      - section6\n      - section6.6\n\n  - name: 6.7.1 Ensure NFS and RPC are not enabled (stat) (Not Scored)\n    stat: path=/etc/init/rpcbind-boot.conf\n    register: nfs_rpc_rc\n    tags:\n      - section6\n      - section6.7\n      - section6.7.1\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (Not Scored)\n    lineinfile: >\n        dest=/etc/init/rpcbind-boot.conf\n        line='#start on virtual-filesystems and net-device-up IFACE=lo'\n        state=present\n        regexp='start on virtual-filesystems and net'\n    when: nfs_rpc_rc.stat.exists == True\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (check) (Not Scored)\n    command: dpkg -S nfs-kernel-server\n    changed_when: False\n    failed_when: False\n    register: nfs_present\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (rc.d) (Not Scored)\n    service: >\n        name=nfs-kernel-server\n        enabled=no\n    when: nfs_present.rc == 0\n    register: nfs_service_result\n    failed_when: \"nfs_service_result|failed and 'service not found' not in nfs_service_result.msg\"\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.8-14 Ensure DNS,FTP,HTTP,IMAP,POP,Samba,Proxy,SNMP Servers are not enabled (Not Scored)\n    service: >\n        name={{ item }}\n        enabled=no\n    with_items:\n      - bind9\n      - vsftpd\n      - apache2\n      - dovecot\n      - smbd\n      - squid3\n      - snmpd\n    failed_when: False\n    tags:\n      - section6\n      - section6.8\n      - section6.9\n      - section6.10\n      - section6.11\n      - section6.12\n      - section6.13\n      - section6.14\n\n  - name: 6.15 Configure Mail Transfer Agent for Local-Only Mode (stat) (Scored)\n    stat: path=/etc/postfix/main.cf\n    register: postfix_main_cf\n    tags:\n      - section6\n      - section6.15\n\n  - name: 6.15 Configure Mail Transfer Agent for Local-Only Mode (Scored)\n    lineinfile: >\n        dest=/etc/postfix/main.cf\n        line='inet_interfaces = localhost'\n        state=present\n    when: postfix_main_cf.stat.exists == True\n    tags:\n      - section6\n      - section6.15\n\n  - name: 6.16 Ensure rsync service is not enabled (stat) (Scored)\n    stat: path=/etc/default/rsync\n    register: default_rsync\n    tags:\n      - section6\n      - section6.16\n\n  - name: 6.16 Ensure rsync service is not enabled (Scored)\n    lineinfile: >\n        dest='/etc/default/rsync'\n        regexp='^RSYNC_ENABLE'\n        line='RSYNC_ENABLE=false'\n    when: default_rsync.stat.exists == True\n    tags:\n      - section6\n      - section6.16\n\n  - name: 6.17 Ensure Biosdevname is not enabled (Scored)\n    apt: name=biosdevname purge=yes state=absent\n    tags:\n      - section6\n      - section6.17\n"}, {"commit_sha": "21712b74b7f5d936e70186bbed6bb37e3a7ad5e6", "sha": "21f5b3d63b89d1343aea2b03018addd8a0a6897b", "filename": "roles/frameworks/vars/cassandra.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "frameworks_cassandra_enabled: false\nframeworks_cassandra_node_count: 1\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "d3ca2f1a4072c1e908bcd1914f28e112002db824", "filename": "roles/serverspec/vars/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# vars file for serverspec\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "82d93c169dafc815eff825ff8653664f8646562b", "filename": "tasks/Debian/redis.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/Debian/redis.yml: Deploy redis\n# Specific to Debian\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure redis is installed\n    apt:\n      name: \"{{ redis_pkg_name }}\"\n      state: \"{{ redis_pkg_state }}\"\n      update_cache: true\n\n  - name: Ensure redis binds to accessible IP\n    lineinfile:\n      dest: /etc/redis/redis.conf\n      regexp: '^bind'\n      line: 'bind 0.0.0.0'\n    notify: restart redis service\n\n  - meta: flush_handlers\n"}, {"commit_sha": "b02504a0a0a8b0e4169d0327a865dfe08866e9ec", "sha": "9eb4bd07e131ef3b35943c4a4cb964da5fc3dd75", "filename": "tasks/main.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/main.yml: \"Master\" playbook for the cmacrae.sensu role\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - include: \"{{ ansible_distribution }}/main.yml\"\n    tags: setup\n\n  - include: redis.yml\n    tags: redis\n    when: redis_server\n          and sensu_deploy_redis\n\n  - include: ssl.yml\n    tags: ssl\n\n  - include: rabbit.yml\n    tags: rabbitmq\n    when: rabbitmq_server\n          and sensu_deploy_rabbitmq\n\n  - include: server.yml\n    tags: server\n    when: sensu_master\n\n  - include: dashboard.yml\n    tags: dashboard\n    when: sensu_include_dashboard\n\n  - include: client.yml\n    tags: client\n\n  - include: plugins.yml\n    tags: plugins\n    when: sensu_include_plugins\n"}, {"commit_sha": "21712b74b7f5d936e70186bbed6bb37e3a7ad5e6", "sha": "71b41811c7dfc063382b0b0b244c07e7671ca818", "filename": "roles/cadvisor/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "# tasks for running cadvisor\n- name: run cadvisor container\n  when: cadvisor_enabled\n  docker:\n    name: cadvisor\n    image: \"{{ cadvisor_image }}\"\n    state: started\n    restart_policy: \"{{ cadvisor_restart_policy }}\"\n    net: \"{{ cadvisor_net }}\"\n    ports:\n      - \"{{ cadvisor_host_port }}:8080\"\n    hostname: \"{{ cadvisor_hostname }}\"\n    volumes:\n    - \"/var/lib/docker/:/var/lib/docker:ro\"\n    - \"/:/rootfs:ro\"\n    - \"/var/run:/var/run:rw\"\n    - \"/sys:/sys:ro\"\n  tags:\n    - cadvisor\n\n- name: upload cadvisor template service\n  when: cadvisor_enabled\n  template:\n    src: cadvisor.conf.j2\n    dest: /etc/init/cadvisor.conf\n    mode: 0755\n  sudo: yes\n  tags:\n    - cadvisor\n\n# Attach to the running container, or start it if needed\n# and forward all signals so that the process manager can detect\n# when a container stops and correctly restart it.\n- name: ensure cadvisor is running (and enable it at boot)\n  when: cadvisor_enabled\n  sudo: yes\n  service:\n    name: cadvisor\n    state: started\n    enabled: yes\n  tags:\n    - cadvisor\n\n- name: Set cadvisor consul service definition\n  sudo: yes\n  template:\n    src: cadvisor-consul.j2\n    dest: \"{{ cadvisor_consul_dir }}/cadvisor.json\"\n  notify:\n    - restart consul\n  when: cadvisor_enabled\n\n- name: ensure cadvisor is running (and enable it at boot)\n  when: not cadvisor_enabled\n  sudo: yes\n  service:\n    name: cadvisor\n    state: stopped\n    enabled: yes\n  tags:\n    - cadvisor\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "3d6a0323fa6b912513444ba4043ea32d2498bc41", "filename": "roles/st2/tasks/5.packages.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n- name: packages | Make temp directory\n  file:\n    path: /tmp/st2/{{ _st2_version }}/debs/{{ _st2_revision }}\n    state: directory\n  tags: [st2, packages]\n\n- name: packages | Download\n  get_url:\n    url: \"https://downloads.stackstorm.net/releases/st2/{{ _st2_version }}/debs/{{ _st2_revision }}/{{ item }}_{{ _st2_version }}-{{ _st2_revision }}_amd64.deb\"\n    dest: /tmp/st2/{{ _st2_version }}/debs/{{ _st2_revision }}/{{ item }}_{{ _st2_version }}-{{ _st2_revision }}_amd64.deb\n  with_items: st2_packages\n  register: package_files\n  tags: [st2, packages]\n\n- name: packages | Install\n  sudo: true\n  apt:\n    deb: \"{{ item.dest }}\"\n    force: yes\n    state: present\n  with_items: package_files.results\n  tags: [st2, packages]\n"}, {"commit_sha": "15d2da095f9bd54a50954dee18597710e1951943", "sha": "a1bcba389d6cd839f22bcef3124f1072c749f009", "filename": "tasks/debian/main.yml", "repository": "ansiblebit/oracle-java", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# file: oracle-java/tasks/debian/main.yml\n#\n# Task file to install Oracle Java Development Kit in a system with a Debian based Linux distribution.\n#\n\n- name: debian | ubuntu | add java ppa repo\n  apt_repository:\n    repo=ppa:webupd8team/java\n    state=present\n  become: yes\n  when: ansible_distribution == 'Ubuntu'\n\n- block:\n  - name: debian | ensure the webupd8 launchpad apt repository key is present\n    apt_key:\n      id=0xC2518248EEA14886\n      keyserver=keyserver.ubuntu.com\n      state=present\n    become: yes\n\n  - name: debian | ensure the webupd8 launchpad apt repository is present\n    apt_repository:\n      repo=\"{{ item }} http://ppa.launchpad.net/webupd8team/java/ubuntu trusty main\"\n      update_cache=yes\n      state=present\n    with_items:\n      - deb\n      - deb-src\n    become: yes\n\n  when: ansible_distribution == 'Debian'\n\n- name: debian | set license as accepted\n  debconf: name='oracle-java{{ oracle_java_version }}-installer' question='shared/accepted-oracle-license-v1-1' value='true' vtype='select'\n  become: yes\n\n- name: debian | ensure Java is installed\n  apt:\n    name=\"oracle-java{{ oracle_java_version }}-installer\"\n    state={{ oracle_java_state }}\n    cache_valid_time={{ oracle_java_cache_valid_time }}\n    update_cache=yes\n  register: oracle_java_task_apt_install\n  become: yes\n\n- name: debian | set Java version as default\n  apt:\n    name=\"oracle-java{{ oracle_java_version }}-set-default\"\n    state=latest\n  register: oracle_java_task_set_default\n  when: oracle_java_set_as_default\n  become: yes\n\n- name: debian | in case there were changes, check host environment again\n  include: ../check_environment.yml\n  when: oracle_java_task_apt_install|changed or oracle_java_task_set_default|changed\n"}, {"commit_sha": "f5364b57f100ae9fa898af59b7812ec0c447ac42", "sha": "e6234dbeed316c321388b1b537c0ea69c0078a46", "filename": "tasks/rpm_prepare.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Ensure EPEL repo is installed (yum)\n  become: yes\n  yum:\n    name: epel-release\n  when: ansible_pkg_mgr == 'yum'\n\n- name: Ensure SELinux dependencies are installed\n  become: yes\n  package:\n    name: libselinux-python,libsemanage-python\n    state: present\n  notify: re-gather facts\n\n# re-gathering facts after installing libselinux-python\n# is a workaround for https://github.com/ansible/ansible-modules-core/issues/2432\n- meta: flush_handlers\n\n- name: Ensure SELinux boolean (tor_can_network_relay) is set appropriately (Fedora)\n  become: yes\n  seboolean:\n    name: tor_can_network_relay\n    state: yes\n    persistent: yes\n  when: ansible_selinux.status == 'enabled'\n\n- name: Ensure systemd drop-in folder is present (RPM)\n  become: yes\n  file:\n    path: /etc/systemd/system/tor@.service.d\n    state: directory\n    owner: root\n    mode: 0755\n\n# this is needed for a small service file modification (allow it to write to /var/lib/tor-instances)\n# without replacing the maintainer's file, for details see\n# http://www.freedesktop.org/software/systemd/man/systemd.unit.html#id-1.11.3\n- name: Ensure service file drop-in is present (RPM)\n  become: yes\n  copy:\n    src: local.conf\n    dest: /etc/systemd/system/tor@.service.d/local.conf\n    owner: root\n    mode: 0644\n  notify: systemctl daemon-reload\n\n- meta: flush_handlers\n"}, {"commit_sha": "1818facd0a58a2b42203a403130b71825b960653", "sha": "255086c2a9f619f83ebf6af5697930379979c8e2", "filename": "handlers/main.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: restart auditd\n    service: name=auditd state=restarted\n    changed_when: False\n    ignore_errors: True\n\n  - name: restart rsyslog\n    service: name=rsyslog state=restarted\n    changed_when: False\n    ignore_errors: True\n"}, {"commit_sha": "7a3aa0de9bf76ff1b18e6da304031150e4550142", "sha": "d74f92e1323663028f3284f1d6e2d1feb654b947", "filename": "tasks/apt_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Ensure torproject gpg key is installed (A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89)\n  sudo: yes\n  apt_key: data=\"{{ lookup('file', 'deb.torproject.org_A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89.pub') }}\"\n    id=A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89\n    state=present\n\n- name: Ensure torproject.org repository is present (APT)\n  sudo: yes\n  apt_repository: repo='deb http://deb.torproject.org/torproject.org {{ tor_distribution_release }} main'\n    state=present \n    update_cache=yes\n\n# waiting for trac ticket #14997\n#- name: Ensure  torproject.org alpha repo is present (if enabled)\n#  apt_repository: >\n#    repo='deb http://deb.torproject.org/torproject.org  main'\n#    state=present \n#    update_cache=yes\n#  when: tor_alpha is True\n\n# we specifically opt for present over latest to improve performance\n# \"latest\" is covered by auto updates\n- name: Ensure Tor is installed (APT)\n  sudo: yes\n  apt: pkg=\"{{ item }}\" state=present\n  with_items: \n    - deb.torproject.org-keyring\n    - tor\n  register: aptresult\n\n# apt starts a tor client instance by default after installing the package\n# we do not need that\n- name: Stop default Tor config if we just installed the package (APT)\n  sudo: yes\n  service: name=tor state=stopped\n  when: aptresult.changed == True\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "ef1d5666cb23f8782ebb1ac677b2d7775807216c", "filename": "tasks/dirs.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# File: dirs.yml - Consul directories\n\n- name: Create directories\n  block:\n  - name: Configuration and data directories\n    file:\n      dest: \"{{ item }}\"\n      state: directory\n      owner: \"{{ consul_user }}\"\n      group: \"{{ consul_group }}\"\n      mode: 0700\n    with_items:\n      - \"{{ consul_config_path }}\"\n      - \"{{ consul_configd_path }}\"\n      - \"{{ consul_data_path }}\"\n  - name: Run directory\n    file:\n      dest: \"{{ consul_run_path }}\"\n      state: directory\n      owner: \"{{ consul_user }}\"\n      group: \"{{ consul_group }}\"\n      mode: 0750\n\n  when: ansible_os_family != 'Windows'\n\n- name: Create log directory\n  file:\n    dest: \"{{ consul_log_path }}\"\n    state: directory\n    owner: \"{{ consul_user }}\"\n    group: \"{{ consul_group }}\"\n  when:\n    - ansible_os_family != 'Windows'\n    - not consul_syslog_enable | bool\n    - not consul_configure_syslogd | bool\n\n- name: Create log directory\n  file:\n    dest: \"{{ item }}\"\n    state: directory\n    owner: \"{{ syslog_user }}\"\n    group: \"{{ syslog_group }}\"\n  with_items:\n    - \"{{ consul_log_path }}\"\n  when:\n    - ansible_os_family != 'Windows'\n    - consul_syslog_enable | bool\n    - consul_configure_syslogd | bool\n\n- name: Verify binary path\n  file:\n    path: \"{{ consul_bin_path }}\"\n    state: directory\n    owner: root\n    mode: 0755\n  when: ansible_os_family != 'Windows'\n\n- name: Create directories on Windows\n  win_file:\n    dest: \"{{ item }}\"\n    state: directory\n  with_items:\n    - \"{{ consul_config_path }}\"\n    - \"{{ consul_configd_path }}\"\n    - \"{{ consul_data_path }}\"\n    - \"{{ consul_log_path }}\"\n    - \"{{ consul_bin_path }}\"\n  when: ansible_os_family == 'Windows'\n"}, {"commit_sha": "1510f92858b85f9f623690db747bdfff9b5b0515", "sha": "83659fb6e0924423aff82e81c0f0f74dda957504", "filename": "tasks/main.yml", "repository": "dev-sec/ansible-mysql-hardening", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n\n- name: add the OS specific variables\n  include_vars: \"{{ ansible_os_family }}.yml\"\n  tags: always\n\n- include: configure.yml\n  when: mysql_hardening_enabled\n  tags: \n    - mysql_hardening\n\n- include: mysql_secure_installation.yml\n  when: mysql_hardening_enabled\n  tags: \n    - mysql_hardening\n    - mysql_secure_installation\n"}, {"commit_sha": "b02504a0a0a8b0e4169d0327a865dfe08866e9ec", "sha": "cb3d4006e0900816a3505cdbfbb46893e70a85f3", "filename": "tasks/Ubuntu/dashboard.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/Ubuntu/dashboard.yml: Deployment of the Uchiwa dashboard\n# Specific to Ubuntu\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Retrieve the Uchiwa deb package\n    get_url:\n      url: \"{{ uchiwa_pkg_download_url }}\"\n      dest: \"{{ uchiwa_pkg_download_path }}\"\n      sha256sum: \"{{ uchiwa_pkg_download_sha256sum }}\"\n\n  - name: Install Uchiwa from the retrieved deb package\n    apt: deb={{ uchiwa_pkg_download_path }} \n\n  - name: Deploy Uchiwa config\n    template:\n      src: uchiwa_config.json.j2\n      dest: \"{{ sensu_config_path }}/uchiwa.json\"\n    notify: restart uchiwa service\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "48875c70baa1d02105240582a07c3634ad6f2273", "filename": "tasks/CentOS/dashboard.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/CentOS/dashboard.yml: Deployment of the Uchiwa dashboard\n# Specific to CentOS\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure Uchiwa is installed\n    yum:\n      name: uchiwa\n      state: present\n    when: not se_enterprise\n\n  - name: Ensure Sensu Enterprise Dashboard is installed\n    yum:\n      name: \"{{ sensu_enterprise_dashboard_package }}\"\n      state: present\n    when: se_enterprise\n\n  - name: Deploy Uchiwa config\n    template:\n      src: uchiwa_config.json.j2\n      dest: \"{{ sensu_config_path }}/uchiwa.json\"\n    when: not se_enterprise\n    notify:\n      - restart uchiwa service\n\n\n  - name: Deploy Sensu Enterprise Dashboard\n    template:\n      src: sensu_enterprise_dashboard_config.json.j2\n      dest: \"{{ sensu_config_path}}/dashboard.json\"\n    when: se_enterprise\n    notify:\n      - restart sensu-enterprise-dashboard service\n"}, {"commit_sha": "7a3aa0de9bf76ff1b18e6da304031150e4550142", "sha": "6bc6b1b04df4a179331d4b4dd8d03f8a7a364f74", "filename": "tasks/openbsd_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# setting PKG_PATH is out of scope of this role\n# we assume it is set correctly.\n# We specifically opt for present over latest to improve performance\n# \"latest\" is covered by auto updates\n- name: Ensure Tor is installed (OpenBSD)\n  sudo: yes\n  openbsd_pkg: name=tor state=present\n\n- name: Gather current system-wide file descriptor limits (OpenBSD)\n  command: \"sysctl kern.maxfiles|cut -d= -f2\"\n  register: currentlimits\n\n- name: Ensure system-wide runtime file descriptor limits are reasonable (OpenBSD)\n  sudo: yes\n  command: \"sysctl kern.maxfiles=20000\"\n  when: currentlimits.stdout < \"20000\"\n\n- name: Ensure system-wide persistent file descriptor limits are reasonable (OpenBSD)\n  sudo: yes\n  lineinfile: dest=/etc/sysctl.conf line=\"kern.maxfiles=20000\" create=yes\n\n# 'tordaemon' is basically an arbitrary string here. We will use it afterwards\n# to assign that login class to the {{ tor_user }}\n- name: Ensure Tor process file descriptor limits are reasonable (OpenBSD)\n  sudo: yes\n  lineinfile: \"dest=/etc/login.conf line='tordaemon::openfiles-max=13500::tc=daemon:'\"\n  #TODO\n  #notify: restart tor\n\n- name: Gather tor_user's login class (OpenBSD)\n  shell: userinfo \"{{ tor_user }}\"|grep ^class|cut -f2\n  register: loginclass\n\n- name: Ensure 'tor_user' is in the tordaemon login class (OpenBSD)\n  sudo: yes\n  command: usermod -L tordaemon \"{{ tor_user }}\"\n  when: loginclass.stdout != 'tordaemon'\n  #TODO \n  #notify: restart tor\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "fb5ae39560e3f3cbf6db836dd989c3d939c8b8ba", "filename": "tasks/rabbit.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/rabbit.yml: Deploy RabbitMQ and set-up vhost for Sensu messaging\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - include: \"{{ ansible_distribution }}/rabbit.yml\"\n\n  - name: Ensure RabbitMQ SSL directory exists\n    file: dest={{ rabbitmq_config_path }}/ssl state=directory\n\n  - name: Ensure RabbitMQ SSL certs/keys are in place\n    copy: src={{ item }} dest={{ rabbitmq_config_path }}/ssl\n    with_items:\n      - \"{{ sensu_ssl_server_cacert }}\"\n      - \"{{ sensu_ssl_server_cert }}\"\n      - \"{{ sensu_ssl_server_key }}\"\n    notify:\n      - restart rabbitmq service\n      - restart sensu-api service\n      - restart sensu-server service\n      - restart sensu-enterprise service\n    when: sensu_ssl_manage_certs\n\n  - name: Deploy RabbitMQ config\n    template:\n      dest: \"{{ rabbitmq_config_path }}/rabbitmq.config\"\n      src: \"{{ rabbitmq_config_template }}\"\n      owner: root\n      group: \"{{ __root_group }}\"\n      mode: 0644\n    notify: restart rabbitmq service\n\n  - name: Ensure RabbitMQ is running\n    service:\n      name: \"{{ rabbitmq_service_name }}\"\n      state: started\n      enabled: true\n    register: rabbitmq_state\n\n  - name: Wait for RabbitMQ to be up and running before asking to create a vhost\n    pause: seconds=3\n    when: rabbitmq_state|changed\n\n  - block:\n    - name: Ensure Sensu RabbitMQ vhost exists\n      rabbitmq_vhost: name={{ rabbitmq_sensu_vhost }} state=present\n\n    - name: Ensure Sensu RabbitMQ user has access to the Sensu vhost\n      rabbitmq_user:\n        user: \"{{ rabbitmq_sensu_user_name }}\"\n        password: \"{{ rabbitmq_sensu_password }}\"\n        vhost: \"{{ rabbitmq_sensu_vhost }}\"\n        configure_priv: .*\n        read_priv: .*\n        write_priv: .*\n        state: present\n    become: true\n    become_user: rabbitmq\n"}, {"commit_sha": "fa66f2d6f5193cce5c2f9086e78f9bff39133e60", "sha": "9f61426bcd70b089e5359a0897bd8fec65b1930d", "filename": "handlers/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n#- name: restart tor\n#  service: name=tor state=restarted\n\n- name: stop-and-disable default tor\n  become: yes\n  service: name=tor state=stopped enabled=no\n\n- name: restart apparmor\n  become: yes\n  service: name=apparmor state=restarted\n\n- name: systemctl daemon-reload\n  become: yes\n  command: systemctl daemon-reload\n\n- name: re-gather facts\n  setup:\n"}, {"commit_sha": "8af8d9f258ac145b451e2f0db433e5e9ad335ea2", "sha": "99e350ff2e38e85446c539be0f9eb8972dab5610", "filename": "tasks/configure.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Ensure local DataDir folders exist (LOCAL)\n  file:\n    path: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    state: directory\n    mode: 0700\n  delegate_to: 127.0.0.1\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - createdir\n\n- name: Ensure all relay keys exist (LOCAL)\n  local_action: command tor --PublishServerDescriptor 0 --orport auto --list-fingerprint --datadirectory \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}\" --Log \"err stdout\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Generate new Ed25519 signing keys (LOCAL)\n  local_action: command tor --keygen --SigningKeyLifetime {{ tor_signingkeylifetime_days}}\\ days --datadirectory \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}\" --Log \"err stdout\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - renewkey\n\n- name: Detect duplicate relay keys across relays (LOCAL)\n  shell: sha1sum {{ tor_offline_masterkey_dir }}/*/keys/secret_id_key {{ tor_offline_masterkey_dir }}/*/keys/ed25519_master_id_secret_key|cut -d/ -f1|sort|uniq -d|wc -l\n  delegate_to: 127.0.0.1\n  run_once: true\n  register: dupcount\n\n- name: Abort on duplicate relay keys\n  fail: msg=\"Duplicate relay key detected! Aborting.\"\n  run_once: true\n  when: dupcount.stdout|int(1) != 0\n\n- name: Detect if Ed25519 master keys are on the relay\n  stat:\n    path: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/ed25519_master_id_secret_key\"\n  become: yes\n  register: masterkeycheck\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Abort if Ed25519 master keys are on the relay\n  fail: msg=\"\n\n            Ed25519 MASTER KEY detected on the relay - it is NOT supposed to be there! Aborting.\"\n  when: item.stat.exists == True\n  with_items: \"{{ masterkeycheck.results }}\"\n\n- name: Collect fingerprints for MyFamily (LOCAL)\n  shell: cut  -d\" \" -f2 {{ tor_offline_masterkey_dir }}/*/fingerprint|sort|xargs|sed -e 's/ /,/g'\n  delegate_to: 127.0.0.1\n  run_once: true\n  register: family\n  tags:\n   - reconfigure\n\n- name: Ensure per-instance tor users exist\n  become: yes\n  user:\n    name: _tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\n    system: yes\n    shell: /bin/false\n    createhome: no\n    home: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure per-instance config folders exist (Debian only)\n  become: yes\n  file:\n    path: \"{{ tor_ConfDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    state: directory\n    mode: 0755\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  when: ansible_pkg_mgr == 'apt'\n\n- name: Ensure DataDir exists\n  become: yes\n  file:\n    path: \"{{ tor_DataDir }}\"\n    state: directory\n    owner: root\n    mode: 0755\n\n- name: Ensure \"keys\" subfolder exists\n  become: yes\n  file:\n    path: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys\"\n    state: directory\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    group: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0700\n    recurse: yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure RSA key is in place (without overriding existing keys)\n  become: yes\n  copy:\n    src: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    dest: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0700\n    force: no\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'secret_id_key' ]\n\n- name: Fetch RSA key for comparision\n  become: yes\n  fetch:\n    src: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    dest: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}.untrustedremotekey\"\n    flat: yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'secret_id_key' ]\n\n- name: Compare local vs. remote RSA key (secret_id_key)\n  local_action: shell sha1sum {{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-\"{{ item.0.ipv4 }}_{{ item.1.orport }}\"/keys/secret_id_key*|cut -d/ -f1|uniq -d|wc -l\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  register: rsakey\n\n- name: Abort if local and remote RSA keys do not match\n  assert:\n    that:\n      - \"item.stdout|int == 1\"\n    msg: \"Key mismatch detected! Solution: http://bit.ly/2j6wc70 Affected instance: {{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.item.0.ipv4 }}_{{ item.item.1.orport }}/keys\"\n  with_items: \"{{ rsakey.results }}\"\n\n# this task is separated from the task named \"Ensure RSA key is in place\" because it is not run with 'force=no'\n- name: Transmit new Ed25519 signing keys\n  become: yes\n  copy:\n    src: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    dest: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0700\n    setype: tor_var_lib_t\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'ed25519_signing_cert', 'ed25519_signing_secret_key' ]\n  tags:\n   - renewkey\n\n# This needs to be at the end to fix SELinux contexts recursively\n- name: Ensure per-instance DataDir have proper permissions\n  become: yes\n  file:\n    path: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    state: directory\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    group: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0700\n    recurse: yes\n    setype: tor_var_lib_t\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure Tor config directory exists\n  become: yes\n  file:\n    path: \"{{ tor_ConfDir }}\"\n    state: directory\n    owner: root\n    group: \"{{ tor_user }}\"\n    mode: 0755\n\n- name: Ensure tor-exit-notice.html is present (if we are an exit)\n  become: yes\n  template:\n    src: tor-exit-notice.html\n    dest: \"{{ tor_ConfDir }}/tor-exit-notice.html\"\n    mode: 0444\n  when: tor_ExitRelay == True and tor_ExitNoticePage == True\n\n- name: Generating torrc file(s)\n  become: yes\n  template:\n    src: torrc\n    dest: \"{{ (ansible_pkg_mgr != 'apt')| ternary(tor_ConfDir ~ '/' ~ item.0.ipv4 ~ '_' ~ item.1.orport ~ '.torrc', tor_ConfDir ~ '/' ~ item.0.ipv4 ~ '_' ~ item.1.orport ~ '/torrc') }}\"\n    owner: root\n    mode: 0644\n    backup: yes\n    validate: \"tor --verify-config -f %s\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  register: instances\n  notify:\n    - Ensure Tor instances are reloaded if its torrc changed (FreeBSD)\n    - Ensure Tor instances are reloaded if its torrc changed (Linux)\n  tags:\n   - reconfigure\n"}, {"commit_sha": "bf6e08dcb2440421477b6536ff6a8d11adc2be17", "sha": "9137748e915cdb58b04f4d1c9a5118018697bd67", "filename": "roles/weave/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for weave\nweave_bridge: \"10.2.0.1/16\"\nweave_server_group: weave_servers\nweave_docker_subnet: \"\n    {%- for host in groups[weave_server_group] -%}\n      {%- if host == 'default' or host == inventory_hostname or host == ansible_fqdn or host in ansible_all_ipv4_addresses -%}\n        10.2.{{ loop.index }}.0/24\n      {%- endif -%}\n    {%- endfor -%}\n\"\nweave_launch_peers: \"\n  {%- set weave_peers = [] -%}\n  {%- for host in groups[weave_server_group] -%}\n    {%- if host != inventory_hostname and host not in weave_peers -%}\n      {% do weave_peers.append(hostvars[host]['ansible_eth0']['ipv4']['address']) %}\n    {%- endif -%}\n  {%- endfor -%}\n  {{ weave_peers|join(' ') }}\n\"\nweave_docker_opts: \"--bridge=weave --fixed-cidr={{ weave_docker_subnet }} --dns 172.17.42.1 --dns 8.8.8.8 --dns-search service.{{ consul_domain }}\"\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "e9b2b28eeb1903184e7c1d366cfc2198e5390b91", "filename": "roles/marathon/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- name: create marathon artifact store directory\n  when: marathon_artifact_store_dir is defined\n  file:\n    path: \"{{ marathon_artifact_store_dir }}\"\n    state: directory\n    mode: 0755\n  become: yes\n  tags:\n    - marathon\n\n- name: deploy marathon service\n  become: yes\n  become_user: root\n  template:\n    src: marathon.service.j2\n    dest: /etc/systemd/system/marathon.service\n  notify:\n    - reload systemd\n    - restart marathon\n  tags:\n    - marathon\n\n# Attach to the running container, or start it if needed\n# and forward all signals so that the process manager can detect\n# when a container stops and correctly restart it.\n- name: ensure marathon is running (and enable it at boot)\n  become: yes\n  service:\n    name: marathon\n    state: started\n    enabled: yes\n  tags:\n    - marathon\n\n- name: Set marathon consul service definition\n  become: yes\n  template:\n    src: marathon-consul.j2\n    dest: \"{{ marathon_consul_dir }}/marathon.json\"\n  notify:\n    - restart consul\n  tags:\n    - marathon\n"}, {"commit_sha": "c0a575a4d0d5cd8c461b6388abf28ee3a245fd42", "sha": "781840667532d973848f84c809e88c1cd7f76f0e", "filename": "tasks/main.yml", "repository": "threatstack/threatstack-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# Setup tasks\n\n- name: Fail if non-Ubuntu debian\n  fail: msg=\"We do not currently support your distribution\"\n  when: ansible_os_family == 'Debian' and ansible_distribution != \"Ubuntu\"\n\n- name: Run Apt configure and install Threat Stack\n  include: apt_install.yml\n  when: ansible_os_family == 'Debian' and ansible_distribution == 'Ubuntu'\n\n- name: Run Yum Configure and install Threat Stack\n  include: yum_install.yml\n  when: ansible_os_family == 'RedHat'\n\n- name: Fire cloudsight setup\n  include: cloudsight_setup.yml\n"}, {"commit_sha": "f5364b57f100ae9fa898af59b7812ec0c447ac42", "sha": "ded6fe8a37e9e97c45c20659820960cf5f5b977e", "filename": "tasks/openbsd_service.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n\n# OpenBSD section (uses service module)\n# This is basically a copy from the Linux\n# section, but it requires different service\n# names and additional arguments.\n# =====================================\n\n# OpenBSD does not support multi-instance rc.d\n# # so we link as many pseudo rc scripts as we need.\n# # OpenBSD does not like dots in rc filenames so\n# # we replace them with underscores.\n- name: Create links to the service files (OpenBSD)\n  become: yes\n  file:\n    src: /etc/rc.d/tor\n    state: link\n    path: \"/etc/rc.d/tor{{ item.0.ipv4| replace('.','_') }}_{{ item.1.orport }}\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure Tor instances are enabled and started (OpenBSD)\n  become: yes\n  service:\n    name: \"tor{{ item.0.ipv4|replace('.','_') }}_{{ item.1.orport }}\"\n    arguments: \"-f {{ tor_ConfDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}.torrc\"\n    enabled: yes\n    state: started\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure Tor instances are reloaded if its torrc changed (OpenBSD)\n  become: yes\n  service:\n    name: \"tor{{ item.item.0.ipv4|replace('.','_') }}_{{ item.item.1.orport }}\"\n    state: reloaded\n  with_items: \"{{ instances.results }}\"\n  when: item.changed == True\n  tags:\n   - reconfigure\n"}, {"commit_sha": "32211ebd2a9f45112f8dceda80bc95d0db029fb4", "sha": "32f5103b15c42801c90cee297893091bf910efb4", "filename": "tasks/openbsd_service.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n\n# OpenBSD section (uses service module)\n# This is basically a copy from the Linux\n# section, but it requires different service\n# names and additional arguments.\n# =====================================\n\n# OpenBSD does not support multi-instance rc.d\n# # so we link as many pseudo rc scripts as we need.\n# # OpenBSD does not like dots in rc filenames so\n# # we replace them with underscores.\n- name: Create links to the service files (OpenBSD)\n  become: yes\n  file: src=/etc/rc.d/tor state=link path=/etc/rc.d/tor{{ item.0.ipv4| replace('.','_') }}_{{ item.1.orport }}\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure Tor instances are enabled and started (OpenBSD)\n  become: yes\n  service: name=tor{{ item.0.ipv4|replace('.','_') }}_{{ item.1.orport }}\n   arguments=\"-f {{ tor_ConfDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}.torrc\" enabled=yes state=started\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure Tor instances are reloaded if its torrc changed (OpenBSD)\n  become: yes\n  service: name=tor{{ item.item.0.ipv4|replace('.','_') }}_{{ item.item.1.orport }} state=reloaded\n  with_items: \"{{ instances.results }}\"\n  when: item.changed == True\n  tags:\n   - reconfigure\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "79aeb4d8255e8d034b91636415b7d38a2a16cfa1", "filename": "roles/dcos_cli/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for dcos-cli\ndcos_cli_image: capgemini/dcos-cli\ndcos_cli_zk_master_peers: \"zk://{{ zookeeper_peers_nodes }}/mesos\"\ndcos_cli_mesos_master_url: \"http://{{ ansible_ssh_host }}:5050\"\ndcos_cli_marathon_url: \"http://{{ ansible_ssh_host }}:8080\"\ndcos_cli_sources: '[\"https://github.com/Capgemini/universe/archive/version-1.x.zip\",]'\ndcos_cli_frameworks_list:\n  - cassandra\n  - chronos\n# Type flag allows you to set up a command which you want to use to run an app.\n# To run one app use \"type: app\" and to run group of apps use \"type: group\".\ndcos_cli_apps_list:\n  - { name: prometheus, type: app }\n  - { name: promdash, type: group }\n\n# apps\nprometheus_image: prom/prometheus\nprometheus_image_tag: 0.16.1\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "335171ada610876bbe1045a8eddb48331578f1fc", "filename": "roles/marathon/meta/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Alberto Lamela\n  description:\n  company: Capgemini\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (MIT)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: CoreOS\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n  #   - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies:\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "78c487ec8514120759c55e24da8f8ae28ac3749e", "filename": "roles/weave/vars/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# vars file for weave\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "9b6adeec49d05260e0575bf53c7bebf9f665dbbd", "filename": "roles/mistral/tasks/install_mistral.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "- name: Create directory\n  sudo: true\n  file:\n    path: /opt/openstack\n    state: directory\n\n- name: Clone Mistral repo\n  sudo: true\n  git:\n    repo: https://github.com/StackStorm/mistral.git\n    version: \"{{ mistral_branch }}\"\n    dest: /opt/openstack/mistral\n    force: yes\n\n- name: Install requirements\n  sudo: true\n  pip:\n    requirements: /opt/openstack/mistral/requirements.txt\n    virtualenv: /opt/openstack/mistral/.venv\n\n- name: Install Mistral\n  sudo: true\n  shell: /opt/openstack/mistral/.venv/bin/python setup.py install\n  args:\n    chdir: /opt/openstack/mistral\n\n- name: Create mistral log dir\n  sudo: true\n  file:\n    path: /var/log/mistral/\n    state: directory"}, {"commit_sha": "7a3aa0de9bf76ff1b18e6da304031150e4550142", "sha": "6e30ade847f69debb46d0421cfe8cc8f8275ff49", "filename": "handlers/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n- name: restart tor\n  service: name=tor state=restarted\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "69bd8f8d88c0ffb22f4db66cf73079511374e087", "filename": "tasks/SmartOS/redis.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/SmartOS/redis.yml: Deploy redis\n# Specific to Ubuntu\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure redis is installed\n    pkgin: name=redis state={{ redis_pkg_state }}\n"}, {"commit_sha": "903181fe699ba052fc8c94ccf16e531b40064f51", "sha": "3cb27bb876cbdae833dc06aad9307aefb9fb04ef", "filename": "tasks/section_09_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 9.1.1.1 Check that cron conf file exists (check) (Scored)\n    stat: path=/etc/init/cron.conf\n    register: cron_conf_stat\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.1\n\n  - name: 9.1.1.2 Enable cron Daemon (Scored)\n    lineinfile: >\n        dest='/etc/init/cron.conf'\n        line='start on runlevel [2345]'\n        state=present\n    when: not cron_conf_stat.stat.exists\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.2\n\n  - name: 9.1.2 Set User/Group Owner and Permission on /etc/crontab (Scored)\n    file: path='/etc/crontab' owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.2\n\n  - name: 9.1.3 Set User/Group Owner and Permission on /etc/cron.hourly (Scored)\n    file: path=/etc/cron.hourly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.3\n\n  - name: 9.1.4 Set User/Group Owner and Permission on /etc/cron.daily (Scored)\n    file: path=/etc/cron.daily owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.4\n\n  - name: 9.1.5 Set User/Group Owner and Permission on /etc/cron.weekly(Scored)\n    file: path=/etc/cron.weekly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.5\n\n  - name: 9.1.6 Set User/Group Owner and Permission on /etc/cron.monthly(Scored)\n    file: path=/etc/cron.monthly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.6\n\n  - name: 9.1.7 Set User/Group Owner and Permission on /etc/cron.d (Scored)\n    file: path=/etc/cron.d owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.7\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (Scored)\n    file: path={{ item }} state=absent\n    with_items:\n        - /etc/cron.deny\n        - /etc/at.deny\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n  \n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    stat: path=/etc/cron.allow\n    register: cron_allow_path\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    shell: touch /etc/cron.allow\n    when: cron_allow_path.stat.exists == False\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (Scored)\n    file: path=/etc/cron.allow owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    stat: path=/etc/at.allow\n    register: at_allow_path\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    shell: touch /etc/at.allow\n    when: at_allow_path.stat.exists == False\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (Scored)\n    file: path=/etc/at.allow owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n \n  - name: 9.2.1 Set Password Creation Requirement Parameters Usingpam_cracklib (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password'\n        regexp=\"pam_cracklib.so\"\n        line=\"password required pam_cracklib.so retry=3 minlen=14 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.1\n\n#Note for section 9.2.2:\n#If a user has been locked out because they have reached the maximum consecutive failure count \n#defined by denied= in the pam_tally2.so module, the user can be unlocked by issuing the command\n#/sbin/pam_tally2 -u username --reset\n#This command sets the failed count to 0, effectively unlocking the user\n  - name: 9.2.2 Set Lockout for Failed Password Attempts (Not Scored)\n    lineinfile: >\n        dest='/etc/pam.d/login' \n        regexp='pam_tally2'\n        line=\"auth required pam_tally2.so onerr=fail audit silent deny=5 unlock_time=900\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.2\n\n  - name: 9.2.3 Limit Password Reuse (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password' \n        regexp='remember=5'\n        line=\"password sufficient pam_unix.so remember=5\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.3\n\n  - name: 9.3 Check if ssh is installed (check)\n    stat: path='/etc/ssh/sshd_config'\n    register: ssh_config_file\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n\n  - name: 9.3.1 Set SSH Protocol to 2 (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config' \n        regexp='^Protocol'\n        state=present\n        line='Protocol 2'\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n  - name: 9.3.2 Set LogLevel to INFO (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config' \n        regexp='^LogLevel'\n        state=present\n        line='LogLevel INFO'\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.2\n\n  - name: 9.3.3 Set Permissions on /etc/ssh/sshd_config (Scored)\n    file: path='/etc/ssh/sshd_config' owner=root group=root mode=600\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.3\n\n#Regroups sections 9.3.4 9.3.7 9.3.8 9.3.9 9.3.10\n  - name: 9.3.{4,7,8,9,10} Disable some SSH options (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^{{ item }}'\n        line='{{ item }} no'\n        state=present\n    with_items: \n      - X11Forwarding\n      - HostbasedAuthentication\n      - PermitRootLogin\n      - PermitEmptyPasswords\n      - PermitUserEnvironment\n    tags:\n      - section9\n      - section9.3\n      - section9.3.4\n      - section9.3.7\n      - section9.3.8\n      - section9.3.9\n      - section9.3.10\n\n  - name: 9.3.5 Set SSH MaxAuthTries to 4 or Less (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^MaxAuthTries'\n        line='MaxAuthTries 4'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.5\n\n  - name: 9.3.6 Set SSH IgnoreRhosts to Yes (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^IgnoreRhosts'\n        line='IgnoreRhosts yes'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.6\n\n  - name: 9.3.11 Use Only Approved Cipher in Counter Mode (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Ciphers'\n        line='Ciphers aes128-ctr,aes192-ctr,aes256-ctr'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.11\n\n  - name: 9.3.12.1 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveInterval'\n        line='ClientAliveInterval 300'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.1\n\n  - name: 9.3.12.2 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveCountMax'\n        line='ClientAliveCountMax 0'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.2\n\n  - name: 9.3.13.1 Limit Access via SSH (Scored)\n    shell: grep AllowUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.1\n\n  - name: 9.3.13.2 Limit Access via SSH (Scored)\n    shell: grep AllowGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.2\n\n  - name: 9.3.13.3 Limit Access via SSH (Scored)\n    shell: grep DenyUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.3\n\n  - name: 9.3.13.4 Limit Access via SSH (Scored)\n    shell: grep DenyGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.4\n\n  - name: 9.3.14 Set SSH Banner (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Banner'\n        line='Banner /etc/issue.net'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.14\n\n  - name: 9.3.14 Set SSH Banner File (Scored)\n    lineinfile: >\n        dest=/etc/ssh/sshd_config\n        line='Authorized uses only. All activity may be monitored and reported.'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.14\n\n  - name: 9.4 Restrict root Login to System Console (Not Scored)\n    stat: path=/etc/securetty\n    register: securetty_file\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.4 Restrict root Login to System Console (Not Scored)\n    debug: msg='*** Check /etc/securetty for console allowed for root access ***'\n    when: securetty_file.stat.exists == True\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.5.1 Restrict Access to the su Command (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/su'\n        line='auth            required        pam_wheel.so use_uid'\n        state=present\n    tags:\n      - section9\n      - section9.5\n      - section9.5.1\n"}, {"commit_sha": "7f02cba4441b5367d6916857c9b41f3abae915db", "sha": "782818990637bfd8d8594a9502dbe80851dffbca", "filename": "tasks/openbsd_prepare.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Gather current system-wide file descriptor limits (OpenBSD)\n  shell: \"sysctl kern.maxfiles|cut -d= -f2\"\n  become: no\n  register: tor_openbsd_maxfiles\n  changed_when: False\n\n- name: Ensure system-wide runtime file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  command: \"sysctl kern.maxfiles=20000\"\n  when: tor_openbsd_maxfiles.stdout|int < 20000\n\n- name: Ensure system-wide persistent file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  lineinfile:\n    dest: /etc/sysctl.conf\n    regexp: ^kern.maxfiles\n    line: \"kern.maxfiles=20000\"\n    create: yes\n  when: tor_openbsd_maxfiles.stdout|int < 20000\n\n# We rise openfiles limits for every tor instance separately.\n# An instance is identified by its rc.d file name.\n- name: Ensure Tor process file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  lineinfile:\n    dest: /etc/login.conf\n    line: \"tor{{ item.0.ipv4| replace('.','_') }}_{{ item.1.orport }}::openfiles-max=13500::tc=daemon:\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n"}, {"commit_sha": "bf6e08dcb2440421477b6536ff6a8d11adc2be17", "sha": "57853e9ca2d3ff026c7d2d95c03d006ce66d5925", "filename": "roles/marathon/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for marathon\n- name: upload marathon template service\n  template:\n    src: marathon.conf.j2\n    dest: /etc/init/marathon.conf\n    mode: 0755\n  notify:\n    - restart marathon\n  sudo: yes\n  tags:\n    - marathon\n\n- name: Set Marathon hostname\n  sudo: yes\n  copy:\n    content: \"{{ marathon_hostname }}\"\n    dest: /etc/marathon/conf/hostname\n    mode: 0644\n  notify:\n    - restart marathon\n  tags:\n    - marathon\n\n- name: remove marathon override\n  sudo: yes\n  file:\n    path: /etc/init/marathon.override\n    state: absent\n  notify:\n    - restart marathon\n  tags:\n    - marathon\n\n- name: install wait script\n  sudo: yes\n  template:\n    src: marathon-wait-for-listen.sh.j2\n    dest: /usr/local/bin/marathon-wait-for-listen.sh\n    mode: 0755\n  notify:\n    - restart marathon\n  tags:\n    - marathon\n\n- name: ensure marathon is running (and enable it at boot)\n  sudo: yes\n  service:\n    name: marathon\n    state: started\n    enabled: yes\n  notify:\n    - wait for marathon to listen\n  tags:\n    - marathon\n\n- meta: flush_handlers\n\n# This is here to workaround an issue where marathon does not receive an\n# acknowledgement correctly from Mesos.\n- name: force restart marathon\n  sudo: yes\n  service:\n    name: marathon\n    state: restarted\n  notify:\n    - wait for marathon to listen\n  tags:\n    - marathon\n\n- meta: flush_handlers\n\n- name: Set Marathon consul service definition\n  sudo: yes\n  template:\n    src: marathon-consul.j2\n    dest: \"{{ consul_dir }}/marathon.json\"\n  notify:\n    - restart consul\n  tags:\n    - marathon\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "e387139a55a752a4f1e041d36003a95b3b2aa6d6", "filename": "roles/cadvisor/meta/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Alberto Lamela\n  description:\n  company: Capgemini\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (MIT)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: Ubuntu\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n     - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies:\n  - role: handlers\n  # - role: registrator\n  # - role: zookeeper\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "fa66f2d6f5193cce5c2f9086e78f9bff39133e60", "sha": "8d16346f0b8e9948b65bf34e38a532d416e5ceb1", "filename": "tasks/rpm_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Setup RPM specific variables (set_fact)\n  set_fact:\n    tor_user: toranon\n    tor_ConfDir: /etc/tor\n    tor_RunAsDaemon: 0\n    tor_DataDir: /var/lib/tor-instances\n  tags:\n   - reconfigure\n   - renewkey\n   - createdir\n\n- name: Ensure tor package is installed (dnf)\n  become: yes\n  dnf: name=tor,libselinux-python,libsemanage-python state=present\n  when: ansible_pkg_mgr == 'dnf'\n  notify: re-gather facts\n\n# re-gathering facts after installing libselinux-python on F23\n# is a workaround for https://github.com/ansible/ansible-modules-core/issues/2432\n- meta: flush_handlers\n\n- name: Ensure EPEL repo is installed (yum)\n  become: yes\n  yum: name=epel-release\n  when: ansible_pkg_mgr == 'yum'\n\n- name: Ensure tor package is installed (yum)\n  become: yes\n  yum: name=tor,libsemanage-python state=present\n  when: ansible_pkg_mgr == 'yum'\n\n- name: Ensure SELinux boolean (tor_can_network_relay) is set appropriately (Fedora)\n  become: yes\n  seboolean: name=tor_can_network_relay state=yes persistent=yes\n  when: ansible_selinux.status == 'enabled'\n\n- name: Ensure systemd drop-in folder is present\n  become: yes\n  file: path=/etc/systemd/system/tor@.service.d\n    state=directory\n    owner=root\n    mode=0755\n\n# this is needed for a small service file modification (allow it to write to /var/lib/tor-instances)\n# without replacing the maintainer's file, for details see\n# http://www.freedesktop.org/software/systemd/man/systemd.unit.html#id-1.11.3\n- name: Ensure service file drop-in is present\n  become: yes\n  copy: src=local.conf\n   dest=/etc/systemd/system/tor@.service.d/local.conf\n   owner=root\n   mode=640\n  notify: systemctl daemon-reload\n\n- meta: flush_handlers\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "fedbe47ee8a39e586bb9a66fe6bb65aa660a044a", "filename": "roles/mistral/requirements.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n- src: ANXS.postgresql\n  version: v1.2.1\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "7c53a3d23cc0e3dc9e81c050aaa284db8d2543ce", "filename": "roles/dockerbench/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for dockerbench\ndockerbench_run_test: false\ndockerbench_dest: /opt/dockerbench\ndockerbench_repo: https://github.com/docker/docker-bench-security.git\ndockerbench_version: master\ndockerbench_warn_threshold: 100\n"}, {"commit_sha": "61b008311c40b377e57e166b778232a20224f7c6", "sha": "1f123a139e8a4f6d46c3842c9abddf01b3fdf8c4", "filename": "tasks/configure.yml", "repository": "UnderGreen/ansible-role-mongodb", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Create keyFile\n  copy:\n    dest: \"{{ mongodb_conf_keyFile }}\"\n    content: \"{{ mongodb_keyfile_content }}\"\n    owner: \"{{ mongodb_user }}\"\n    group: \"root\"\n    mode: 0600\n  when: mongodb_conf_replSet != ''\n\n- name: Configure log rotation\n  template: src=logrotate.conf.j2 dest=/etc/logrotate.d/mongodb.conf\n  when: mongodb_logrotate\n\n- name: set mongodb gid\n  group: name=mongodb gid={{ mongodb_gid }} state=present\n  when: mongodb_gid\n\n- name: set mongodb uid\n  user: name=mongodb uid={{ mongodb_uid }} group=mongodb state=present\n  when: mongodb_uid\n\n- name: reset mongodb folder and subfolders with new uid\n  file: path={{ mongodb_conf_dbpath }} owner=mongodb group=mongodb follow=yes recurse=yes state=directory\n  when: mongodb_uid\n\n- name: Create log dir if missing\n  file: state=directory recurse=yes dest={{ mongodb_conf_logpath|dirname }} owner={{ mongodb_user }} group={{mongodb_user}} mode=0755\n\n- name: Check than logfile exists\n  stat: path={{ mongodb_conf_logpath }}\n  register: logfile_stat\n\n- name: Create log if missing\n  file: state=touch dest={{ mongodb_conf_logpath }} owner={{ mongodb_user }} group={{mongodb_user}} mode=0755\n  when: logfile_stat is defined and not logfile_stat.stat.exists\n\n- name: Configure mongodb\n  template: src=mongod.conf.j2 dest=/etc/mongod.conf backup=yes owner=root group=root mode=0644\n  register: config_result\n\n- name: Install sysfsutils package\n  apt: name=sysfsutils state=present\n  when: ansible_os_family == 'Debian' and mongodb_disable_thp\n\n- name: Create /etc/sysfs.d direcroty\n  file:\n    path: /etc/sysfs.d\n    group: root\n    state: directory\n    mode: 0755\n    owner: root\n  when: ansible_os_family == 'Debian' and mongodb_disable_thp\n\n- name: Create sysfs config\n  copy:\n    src: hugepages.conf\n    dest: /etc/sysfs.d/hugepages.conf\n    owner: root\n    group: root\n    mode: 0644\n  when: ansible_os_family == 'Debian' and mongodb_disable_thp\n  notify: restart sysfsutils\n\n- name: mongodb restart\n  service: name={{ mongodb_daemon_name }} state=restarted\n  when: config_result|changed and mongodb_manage_service\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "31b34488ecb01d6738c4d1a59126870506c4e209", "filename": "roles/dnsmasq/vars/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# vars file for dnsmasq\n"}, {"commit_sha": "7f02cba4441b5367d6916857c9b41f3abae915db", "sha": "019844cf9ef417aa49cbc5d7bf08b01742a25019", "filename": "tasks/freebsd_prepare.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Choose tor alpha version package (FreeBSD)\n  set_fact:\n    tor_packages: tor-devel\n  when: tor_alpha\n\n- name: Ensure sequential IP IDs are avoided (FreeBSD)\n  become: yes\n  sysctl:\n    name: net.inet.ip.random_id\n    value: 1\n    reload: no\n    sysctl_set: yes\n\n- name: Gather current kern.ipc.somaxconn setting (FreeBSD)\n  shell: \"sysctl kern.ipc.somaxconn|cut -d' '  -f2\"\n  become: no\n  register: tor_currentsomaxconn\n  changed_when: False\n\n- name: Ensure somaxconn setting is reasonable (FreeBSD)\n  become: yes\n  sysctl:\n    name: kern.ipc.somaxconn\n    value: \"{{ tor_freebsd_somaxconn }}\"\n    reload: no\n    sysctl_set: yes\n  when: tor_currentsomaxconn.stdout|int < tor_freebsd_somaxconn\n\n- name: Gather current kern.ipc.nmbclusters setting (FreeBSD)\n  become: no\n  shell: \"sysctl kern.ipc.nmbclusters|cut -d' '  -f2\"\n  register: tor_currentnmbc\n  changed_when: False\n\n- name: Ensure nmbclusters setting is reasonable (FreeBSD)\n  become: yes\n  sysctl:\n    name: kern.ipc.nmbclusters\n    value: \"{{ tor_freebsd_nmbclusters }}\"\n    reload: no\n    sysctl_set: yes\n  when: tor_currentnmbc.stdout|int < tor_freebsd_nmbclusters\n"}, {"commit_sha": "af3dfdf7cf37437f5609f1a12e4ac7cbaebd4867", "sha": "38f9e19fd447b876177dfd1d1263ea66de1cac8e", "filename": "roles/dnsmasq/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for dnsmasq\n- name: restart dnsmasq\n  service:\n    name: dnsmasq\n    state: restarted\n  sudo: yes\n\n- name: reload dnsmasq\n  service:\n    name: dnsmasq\n    state: reloaded\n  sudo: yes\n"}, {"commit_sha": "694a4890fcf0daa375d6a173511f6ff7dd0f2335", "sha": "023d2b0e83a17a284c1ad905abeb035721aee1e7", "filename": "handlers/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n- name: stop-and-disable default tor\n  become: yes\n  service: name=tor state=stopped enabled=no\n\n- name: restart apparmor\n  become: yes\n  service: name=apparmor state=restarted\n\n- name: systemctl daemon-reload\n  become: yes\n  command: systemctl daemon-reload\n\n- name: re-gather facts\n  setup:\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "8afdfe0e23e699ece7b3dd20b68840316a4e7f32", "filename": "tasks/section_06_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 6.1 Ensure the X Window system is not installed (Scored)\n    apt: name=xserver-xorg-core* purge=yes state=absent\n    when: remove_xserver == True\n    tags:\n      - section6\n      - section6.1\n\n  - name: 6.2.1 Ensure Avahi Server is not enabled (check) (Scored)\n    stat: path='/etc/init/avahi-daemon.conf'\n    register: avahi_stat\n    tags:\n      - section6\n      - section6.2\n\n  - name: 6.2.2 Ensure Avahi Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on (filesystem'\n        state=present\n        regexp='start on \\(filesystem'\n        dest=/etc/init/avahi-daemon.conf\n    when: avahi_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.2\n\n  - name: 6.3.1 Ensure print server is not enabled (check) (Not Scored)\n    stat: path='/etc/init/cups.conf'\n    register: cups_stat\n    tags:\n      - section6\n      - section6.3\n\n  - name: 6.3.2 Ensure print server is not enabled (Not Scored)\n    lineinfile: >\n        line='#start on (filesystem'\n        state=present\n        regexp='start on \\(filesystem'\n        dest=/etc/init/cups.conf\n    when: cups_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.3\n\n  - name: 6.4.1.1 Ensure DHCP Server is not enabled (check) (Scored)\n    stat: path='/etc/init/isc-dhcp-server.conf'\n    register: dhcp_stat\n    tags:\n      - section6\n      - section6.4\n      - section6.4.1\n\n  - name: 6.4.1.2 Ensure DHCP Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n        dest=/etc/init/isc-dhcp-server.conf\n    when: dhcp_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.4\n      - section6.4.1\n\n  - name: 6.4.2.1 Ensure DHCP Server is not enabled (check) (Scored)\n    stat: path='/etc/init/isc-dhcp-server6.conf'\n    register: dhcp6_stat\n    tags:\n      - section6\n      - section6.4\n      - section6.4.2\n\n  - name: 6.4.2.2 Ensure DHCP Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n        dest=/etc/init/isc-dhcp-server6.conf\n    when: dhcp6_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.4\n      - section6.4.2\n\n  - name: 6.5.1.1 Configure Network Time Protocol (install) (NTP) (Scored)\n    apt: name=ntp state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.1\n\n  - name: 6.5.1.2 Check if /etc/ntp.conf file exists (stat)\n    stat:\n        path: /etc/ntp.conf\n    register: ntp_conf_file\n    tags:\n      - section6\n      - section6.5\n      - section6.5.1\n\n  - include: section_06_level1_05.yml\n    when: ntp_conf_file.stat.exists == True\n\n  - name: 6.6 Ensure LDAP is not enabled (Not Scored)\n    apt: name=slapd purge=yes state=absent\n    tags:\n      - section6\n      - section6.6\n\n  - name: 6.7.1 Ensure NFS and RPC are not enabled (stat) (Not Scored)\n    stat: path=/etc/init/rpcbind-boot.conf\n    register: nfs_rpc_rc\n    tags:\n      - section6\n      - section6.7\n      - section6.7.1\n\n  - name: 6.7.2.1 Ensure NFS and RPC are not enabled (Not Scored)\n    lineinfile: >\n        dest=/etc/init/rpcbind-boot.conf\n        line='#start on virtual-filesystems and net-device-up IFACE=lo'\n        state=present\n        regexp='start on virtual-filesystems and net'\n    when: nfs_rpc_rc.stat.exists == True\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.7.2.2 Ensure NFS and RPC are not enabled (check) (Not Scored)\n    command: dpkg -S nfs-kernel-server\n    changed_when: False\n    failed_when: False\n    always_run: True\n    register: nfs_present\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.7.2.3 Ensure NFS and RPC are not enabled (rc.d) (Not Scored)\n    service: >\n        name=nfs-kernel-server\n        enabled=no\n    when: nfs_present is defined and nfs_present.rc == 0\n    register: nfs_service_result\n    failed_when: \"nfs_service_result|failed and 'service not found' not in nfs_service_result.msg\"\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.8-14 Ensure DNS,FTP,HTTP,IMAP,POP,Samba,Proxy,SNMP Servers are not enabled (Not Scored)\n    service: >\n        name={{ item }}\n        enabled=no\n    with_items:\n      - bind9\n      - vsftpd\n      - apache2\n      - dovecot\n      - smbd\n      - squid3\n      - snmpd\n    failed_when: False\n    tags:\n      - section6\n      - section6.8\n      - section6.9\n      - section6.10\n      - section6.11\n      - section6.12\n      - section6.13\n      - section6.14\n\n  - name: 6.15.1 Configure Mail Transfer Agent for Local-Only Mode (check) (Scored)\n    stat: path=/etc/postfix/main.cf\n    register: postfix_main_cf\n    tags:\n      - section6\n      - section6.15\n\n  - name: 6.15.2 Configure Mail Transfer Agent for Local-Only Mode (Scored)\n    lineinfile: >\n        dest=/etc/postfix/main.cf\n        regexp='^inet_interfaces ='\n        line='inet_interfaces = localhost'\n        state=present\n    when: postfix_main_cf.stat.exists == True\n    tags:\n      - section6\n      - section6.15\n\n  - name: 6.15.3 Configure Mail Transfer Agent for Local-Only Mode (Scored)\n    lineinfile: >\n        dest=/etc/postfix/main.cf\n        regexp='^inet_protocols ='\n        line='inet_protocols = ipv4'\n        state=present\n    when: postfix_main_cf.stat.exists == True and disable_ipv6 == True\n    tags:\n      - section6\n      - section6.15\n\n  - name: 6.16.1 Ensure rsync service is not enabled (check) (Scored)\n    stat: path=/etc/default/rsync\n    register: default_rsync\n    tags:\n      - section6\n      - section6.16\n\n  - name: 6.16.2 Ensure rsync service is not enabled (Scored)\n    lineinfile: >\n        dest='/etc/default/rsync'\n        regexp='^RSYNC_ENABLE'\n        line='RSYNC_ENABLE=false'\n    when: default_rsync.stat.exists == True\n    tags:\n      - section6\n      - section6.16\n\n  - name: 6.17 Ensure Biosdevname is not enabled (Scored)\n    apt: name=biosdevname purge=yes state=absent\n    tags:\n      - section6\n      - section6.17\n"}, {"commit_sha": "72a9fefcabb6edccd82abb23946bd305035db334", "sha": "deb1482087285f99edc014a0f72593f656457bcd", "filename": "tasks/openbsd_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Setup OpenBSD specific variables (set_fact)\n  set_fact:\n    tor_DataDir: /var/tor\n    tor_PidDir: /var/tor/pids\n  tags:\n   - configure\n   - createdir\n\n- name: Gather current tor install state (OpenBSD)\n  command: \"pkg_info -qe tor-*\"\n  ignore_errors: yes\n  register: torpkg\n\n# the following task fails HARD on purpose (if ports are not there)\n# TODO: add an opt-in var that takes care of installing ports\n- name: Install tor from ports (OpenBSD)\n  sudo: yes\n  shell: \"cd /usr/ports/net/tor && make install\"\n  when: torpkg.rc == 1\n\n- name: Gather current system-wide file descriptor limits (OpenBSD)\n  shell: \"sysctl kern.maxfiles|cut -d= -f2\"\n  register: currentlimits\n\n- name: Ensure system-wide runtime file descriptor limits are reasonable (OpenBSD)\n  sudo: yes\n  command: \"sysctl kern.maxfiles=20000\"\n  when: currentlimits.stdout|int < 20000\n\n- name: Ensure system-wide persistent file descriptor limits are reasonable (OpenBSD)\n  sudo: yes\n  lineinfile: dest=/etc/sysctl.conf regexp=^kern.maxfiles line=\"kern.maxfiles=20000\" create=yes\n  when: currentlimits.stdout|int < 20000\n\n# We rise openfiles limits for every tor instance separately.\n# An instance is identified by its rc.d file name.\n- name: Ensure Tor process file descriptor limits are reasonable (OpenBSD)\n  sudo: yes\n  lineinfile: \"dest=/etc/login.conf line='tor{{ item[0]| replace('.','_') }}_{{ item.1.orport }}::openfiles-max=13500::tc=daemon:'\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n  #TODO\n  #notify: restart tor\n"}, {"commit_sha": "f565940c5163524c7834123625c804e5f69c2b10", "sha": "af2af2c89b8c2e56386236d6aa96343e5cf4a8fe", "filename": "tasks/Ubuntu/main.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/Ubuntu/main.yml: Ubuntu specific set-up\n# This takes care of base prerequisites for Ubuntu\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure the Sensu APT repo GPG key is present\n    apt_key:\n      url: http://repositories.sensuapp.org/apt/pubkey.gpg\n      state: present\n\n  - name: Ensure the Sensu Core APT repo is present\n    apt_repository:\n      repo: 'deb     http://repositories.sensuapp.org/apt sensu main'\n      state: present\n      update_cache: true\n\n  - name: Ensure Sensu is installed\n    apt: name={{ sensu_package }} state={{ sensu_pkg_state }}\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "257bd7880f9f0120e9ad4530574752262d656dc8", "filename": "tasks/section_05_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 5.1.1 Ensure NIS is not installed (Scored)\n    apt: name=nis state=absent purge=yes\n    tags:\n    - section5\n    - section5.1\n    - section5.1.1\n\n  - name: 5.1.2.1 Ensure rsh, rlogin, rexec, talk, telnet, chargen, daytime, echo, discard, time is not enabled (stat inetd) (Scored)\n    stat: path=/etc/inetd.conf\n    register: inetd_path\n    tags:\n    - section5\n    - section5.1\n    - section5.1.2\n\n  - name: 5.1.2.2 Ensure rsh, rlogin, rexec, talk, telnet, chargen, daytime, echo, discard, time is not enabled (Scored)\n    lineinfile: >\n        dest=/etc/inetd.conf\n        regexp='^({{ item }}.*)'\n        line='#\\1'\n        state=present\n        backrefs=yes\n        backup=yes\n    with_items:\n        - shell\n        - login\n        - exec\n        - talk\n        - ntalk\n        - telnet\n        - chargen\n        - daytime\n        - echo\n        - discard\n        - time\n    when: inetd_path.stat.exists == True\n    tags:\n    - section5\n    - section5.1\n    - section5.1.2\n\n  - name: 5.1.3.1 Ensure rsh client is not installed (Scored)\n    apt: name=rsh-client state=absent purge=yes\n    tags:\n    - section5\n    - section5.1\n    - section5.1.3\n\n  - name: 5.1.3.2 Ensure rsh client is not installed (Scored)\n    apt: name=rsh-redone-client state=absent purge=yes\n    tags:\n    - section5\n    - section5.1\n    - section5.1.3\n\n  - name: 5.1.5 Ensure talk client is not installed (Scored)\n    apt: name=talk state=absent purge=yes\n    tags:\n    - section5\n    - section5.1\n    - section5.1.5\n\n  - name: 5.1.8.1 Ensure xinetd is not enabled (stat xinetd) (Scored)\n    stat: path=/etc/init/xinetd.conf\n    register: xinetd_path\n    tags:\n    - section5\n    - section5.1\n    - section5.1.8\n\n  - name: 5.1.8.2 Ensure xinetd is not enabled (Scored)\n    lineinfile: >\n        dest=/etc/init/xinetd.conf\n        regexp='start on runlevel'\n        state=present\n        line='#start on runlevel [2345]'\n    when: xinetd_path.stat.exists == True\n    tags:\n    - section5\n    - section5.1\n    - section5.1.8\n"}, {"commit_sha": "0f46bc2b1f4dac71c882be0ee48a25332a90ed40", "sha": "bc0413a9f0cb87732cbffb9060dbdeb3faa314af", "filename": "roles/dnsmasq/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# handlers file for dnsmasq\n# Restart service dnsmasq, in all cases\n- name: Restart dnsmasq\n  service: name=dnsmasq state=restarted\n  sudo: yes\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "2f7d9b4e9eb4fddf346a4042a3311b9e0957d593", "filename": "tasks/Ubuntu/rabbit.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/Ubuntu/rabbit.yml: Deploy RabbitMQ\n# Specific to Ubuntu\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure the RabbitMQ APT repo GPG key is present\n    apt_key:\n      url: https://www.rabbitmq.com/rabbitmq-release-signing-key.asc\n      state: present\n\n  - name: Ensure the RabbitMQ APT repo is present\n    apt_repository:\n      repo: 'deb http://www.rabbitmq.com/debian/ testing main'\n      state: present\n      update_cache: true\n\n  - name: Ensure RabbitMQ is installed\n    apt:\n      name: rabbitmq-server\n      state: \"{{ rabbitmq_pkg_state }}\"\n      update_cache: true\n"}, {"commit_sha": "9ad67b6ef151d5fbaa05230e6cecb4bed1db7d9d", "sha": "9f75d88c4170f076577720ada65d19c6a2f575bb", "filename": "tasks/section_07_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 7.1.1 Disable IP Forwarding (Scored)\n    sysctl: >\n      name=net.ipv4.ip_forward\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.1\n\n  - name: 7.1.2.1 Disable Send Packet Redirects (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.2\n      - section7.1.2.1\n\n  - name: 7.1.2.2 Disable Send Packet Redirects (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.2\n      - section7.1.2.2\n\n  - name: 7.2.1 Modify Network Parameters (Host and Router)\n    sysctl: >\n      name=net.ipv4.conf.all.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.1\n\n  - name: 7.2.2 Modify Network Parameters (Host and Router)\n    sysctl: >\n      name=net.ipv4.conf.default.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.2\n\n  - name: 7.2.1.1 Disable Source Routed Packet Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.accept_source_route\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.1\n      - section7.2.1.1\n\n  - name: 7.2.1.2 Disable Source Routed Packet Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.accept_source_route\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.1\n      - section7.2.1.2\n\n  - name: 7.2.2.1 Disable ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.2\n      - section7.2.2.1\n\n  - name: 7.2.2.2 Disable ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.2\n      - section7.2.2.2\n\n  - name: 7.2.3.1 Disable Secure ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.secure_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.3\n      - section7.2.3.1\n\n  - name: 7.2.3.2 Disable Secure ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.secure_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.3\n      - section7.2.3.2\n\n  - name: 7.2.4.1 Log Suspicious Packets (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.log_martians\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.4\n      - section7.2.4.1\n\n  - name: 7.2.4.2 Log Suspicious Packets (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.log_martians\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.4\n      - section7.2.4.2\n\n  - name: 7.2.5 Enable Ignore Broadcast Requests (Scored)\n    sysctl: >\n      name=net.ipv4.icmp_echo_ignore_broadcasts\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.5\n\n  - name: 7.2.6 Enable Bad Error Message Protection (Scored)\n    sysctl: >\n      name=net.ipv4.icmp_ignore_bogus_error_responses\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.6\n\n  - name: 7.2.7.1 Enable RFC-recommended Source Route Validation (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.rp_filter\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.7\n      - section7.2.7.1\n\n  - name: 7.2.7.2 Enable RFC-recommended Source Route Validation (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.rp_filter\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.7\n      - section7.2.7.2\n\n  - name: 7.2.8 Enable TCP SYN Cookies (Scored)\n    sysctl: >\n      name=net.ipv4.tcp_syncookies\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.8\n\n  - name: 7.3 Configure IPv6\n    sysctl: >\n      name=net.ipv4.tcp_syncookies\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n\n  - name: 7.3.1.1 Disable IPv6 Router Advertisements (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.all.accept_ra\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.1\n      - section7.3.1.1\n\n  - name: 7.3.1.2 Disable IPv6 Router Advertisements (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.default.accept_ra\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.1\n      - section7.3.1.2\n\n  - name: 7.3.2.1 Disable IPv6 Redirect Acceptance (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.all.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.2\n      - section7.3.2.1\n\n  - name: 7.3.2.2 Disable IPv6 Redirect Acceptance (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.default.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.2\n      - section7.3.2.2\n\n  - name: 7.3.3 Disable IPv6 (Not Scored)\n    sysctl: >\n      name={{ item }}\n      value=1\n      state=present\n    with_items:\n      - net.ipv6.conf.all.disable_ipv6\n      - net.ipv6.conf.default.disable_ipv6\n      - net.ipv6.conf.lo.disable_ipv6\n    when: disable_ipv6 == True\n    tags:\n      - section7\n      - section7.3\n      - section7.3.3\n\n  - name: 7.4.1 Install TCP Wrappers (Scored)\n    apt: name=tcpd state=present\n    tags:\n      - section7\n      - section7.4\n      - section7.4.1\n\n  - name: 7.4.2 Create /etc/hosts.allow (Not Scored)\n    debug: msg=\"*** Verify /etc/hosts.allow ***\"\n    tags:\n      - section7\n      - section7.4\n      - section7.4.2\n\n  - name: 7.4.3 Verify Permissions on /etc/hosts.allow (Scored)\n    file: >\n        path=/etc/hosts.allow\n        owner=root\n        group=root\n        mode=0644\n    tags:\n      - section7\n      - section7.4\n      - section7.4.3\n\n  - name: 7.4.4 Create /etc/hosts.deny (Not Scored)\n    debug: msg='*** Verify /etc/hosts.deny ***'\n    tags:\n      - section7\n      - section7.4\n      - section7.4.4\n\n  - name: 7.4.5 Verify Permissions on /etc/hosts.deny (Scored)\n    file: >\n        path=/etc/hosts.deny\n        owner=root\n        group=root\n        mode=0644\n    tags:\n      - section7\n      - section7.4\n      - section7.4.5\n\n  - name: Check the presence of the file \"cis.conf\" under modprobe.d\n    stat: >\n        path=/etc/modprobe.d/CIS.conf\n    register: cis_conf_file\n    tags:\n      - section7\n      - section7.5\n\n  - name: Create the file \"cis.conf\" under modprobe.d if doesn't exist\n    file: >\n        dest=/etc/modprobe.d/CIS.conf state=touch\n    when: not cis_conf_file.stat.exists\n    tags:\n      - section7\n      - section7.5\n\n  - name: 7.5.1-4 Disable DCCP, SCTP, RDS, TIPC (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install {{ item }} /bin/true'\n        state=present\n    with_items:\n        - dccp\n        - sctp\n        - rds\n        - tipc\n    tags:\n      - section7\n      - section7.5\n      - section7.5.1\n      - section7.5.2\n      - section7.5.3\n      - section7.5.4\n\n  - name: 7.6 Deactivate Wireless Interfaces (Not Scored)\n    shell: 'lspci -k | grep -i wifi'\n    changed_when: False\n    register: lspci_wifi\n    failed_when: lspci_wifi.rc == 0\n    tags:\n      - section7\n      - section7.6\n\n  - name: 7.7 Ensure Firewall is active (install) (Scored)\n    apt: >\n        name=ufw\n        state=present\n    when: activate_ufw\n    tags:\n      - section7\n      - section7.7\n\n  - name: 7.7 Ensure Firewall is active (Scored)\n    service: >\n        name=ufw\n        state=started\n    when: activate_ufw\n    tags:\n      - section7\n      - section7.7\n"}, {"commit_sha": "7f02cba4441b5367d6916857c9b41f3abae915db", "sha": "bfa0853fbb1beae45bc1a0607f795731d442a496", "filename": "tasks/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Check for min. ansible version requirement\n  assert:\n    that:\n      - \"{{ ansible_version.full is version_compare('2.7.8', '>=') }}\"\n    msg: \"Your ansible version is too old, please upgrade to v2.7.8 or newer. Exiting.\"\n  run_once: true\n  delegate_to: 127.0.0.1\n  tags:\n    - always\n    - ansible-version-check\n\n- name: Check for local requirements\n  shell: >\n        command -V /bin/bash && command -V tor && command -V openssl && command -V sort\n        && command -V uniq && command -V wc && command -V cut && command -V xargs && command -V sed\n  run_once: true\n  become: no\n  delegate_to: 127.0.0.1\n  tags:\n    - always\n  changed_when: False\n\n- name: Ensure we do not create more than two instances per IP\n  assert:\n    that:\n      - \"tor_ports | length > 0\"\n      - \"tor_ports | length < 3\"\n    msg: \"You can not run more than 2 instances per IP address, please update your tor_ports configuration.\"\n  tags:\n    - always\n\n- name: Ensure preconditions for tor_dedicatedExitIP are met (enough public IP addresses on the system)\n  assert:\n    that:\n      - \"tor_available_public_ipv4s | length >= tor_maxPublicIPs*2 or tor_available_public_ipv6s | length >= tor_maxPublicIPs*2\"\n      - tor_ExitRelay\n      - tor_IPv6Exit\n      - tor_IPv6\n    msg: \"You have to few public IPv4 and IPv6 addresses for the tor_dedicatedExitIP feature (or you did not enable exiting)\"\n  when: tor_dedicatedExitIP\n  tags:\n    - always\n\n- name: Abort if we use a centralized/common DNS resolver (Google, Quad9, CloudFlare, OpenDNS, Level3). See https://torproject.org/relay-guide#DNSonExitRelays (Exits only)\n  command: \"{{ tor_grep_blacklisted_dnsresolvers }}\"\n  register: tor_dns_check\n  failed_when: tor_dns_check.rc == 0\n  changed_when: False\n  when: tor_ExitRelay\n\n- name: Set OS specific variables\n  include_vars: \"os_{{ ansible_os_family }}.yml\"\n  tags:\n   - always\n\n- import_tasks: ip-list.yml\n  tags:\n    - always\n\n- name: Preparation for Debian-based systems\n  include_tasks: apt_prepare.yml\n  when: ansible_pkg_mgr == 'apt'\n  tags:\n   - debian\n   - install\n\n- name: Preparation for RPM based systems\n  include_tasks: rpm_prepare.yml\n  when: ansible_os_family == 'RedHat'\n  tags:\n   - centos\n   - fedora\n   - install\n\n- name: Preparation for OpenBSD systems\n  include_tasks: openbsd_prepare.yml\n  when: ansible_system == 'OpenBSD'\n  tags:\n   - openbsd\n\n- name: Preparation for FreeBSD based systems\n  include_tasks: freebsd_prepare.yml\n  when: ansible_system == 'FreeBSD'\n  tags:\n   - freebsd\n\n# we specifically opt for present over latest to improve performance\n- name: Ensure tor is installed\n  become: yes\n  package:\n    name: \"{{ item }}\"\n    state: \"{{ tor_package_state }}\"\n  with_items: \"{{ tor_packages }}\"\n  # apt starts a tor client instance by default after installing the package\n  # we do not need that\n  notify:\n    - stop-and-mask default tor instance\n    - disable default tor instance FreeBSD\n  tags:\n   - openbsd\n   - freebsd\n   - debian\n   - centos\n   - fedora\n   - install\n\n- meta: flush_handlers\n\n- import_tasks: configure.yml\n  tags:\n   - debian\n   - centos\n   - fedora\n   - openbsd\n   - freebsd\n\n- name: Linux service configuration\n  include_tasks: linux_service.yml\n  when: ansible_system == 'Linux'\n  tags:\n   - debian\n   - centos\n   - fedora\n\n- name: OpenBSD service configuration\n  include_tasks: openbsd_service.yml\n  when: ansible_system == 'OpenBSD'\n  tags:\n   - openbsd\n\n- name: FreeBSD service configuration\n  include_tasks: freebsd_service.yml\n  when: ansible_system == 'FreeBSD'\n  tags:\n   - freebsd\n"}, {"commit_sha": "4e9fdb819a1d7565413b47dca677f7811946668d", "sha": "1f18beef314906f44bd21abf7303a1d82f7c4df4", "filename": "roles/registrator/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# defaults file for registrator\nregistrator_image: \"gliderlabs/registrator:master\"\nregistrator_uri: \"consul://consul.service.consul:8500\"\nhostname: \"{{ ansible_all_ipv4_addresses }}\"\n\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "af779d1e0835ca6e5e2e098bbb3dd8806b05e775", "filename": "roles/consul/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for consul\n- name: remove consul override\n  file:\n    path: /etc/init/consul.override\n    state: absent\n\n- name: configure consul\n  sudo: yes\n  template:\n    src: consul.json.j2\n    dest: /etc/consul.d/consul.json\n    owner: root\n    group: root\n    mode: 0644\n  notify:\n    - restart consul\n  tags:\n    - consul\n\n- name: configure atlas for consul\n  sudo: yes\n  template:\n    src: atlas.json.j2\n    dest: /etc/consul.d/atlas.json\n    owner: root\n    group: root\n    mode: 0644\n  when: consul_atlas_join\n  notify:\n    - restart consul\n  tags:\n    - consul\n\n- name: enable consul\n  sudo: yes\n  service:\n    name: consul\n    enabled: yes\n    state: started\n  tags:\n    - consul\n\n# Give some time for leader election to occur\n- name: wait for leader\n  wait_for:\n    host: \"{{ consul_bind_addr }}\"\n    port: 8301\n    delay: 10\n  tags:\n    - consul\n\n- name: remove consul-join override\n  file:\n    path: /etc/init/consul-join.override\n    state: absent\n  when: consul_join is defined\n  tags:\n    - consul\n\n- name: configure consul-join\n  sudo: yes\n  template:\n    src: consul-join.j2\n    dest: /etc/service/consul-join\n    owner: root\n    group: root\n    mode: 0644\n  notify:\n    - restart consul\n  when: consul_join is defined\n  tags:\n    - consul\n\n# We need to force reload here because sometimes Consul gets in a weird\n# state where it cannot elect a cluster leader. Simply restarting the service\n# seems to allow it to recover automatically.\n- name: force reload consul\n  sudo: yes\n  command: /sbin/restart consul\n  tags:\n    - consul\n\n- name: force wait for leader\n  wait_for:\n    host: \"{{ consul_bind_addr }}\"\n    port: 8301\n    delay: 10\n  tags:\n    - consul\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "7e64694f84f266ceb54258fd9a1f9fae46bf099b", "filename": "roles/mistral/tasks/config.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "- name: Add Mistral config\n  sudo: true\n  template:\n    src: mistral.conf.j2\n    dest: /etc/mistral/mistral.conf\n  notify:\n    - restart mistral\n\n- name: Copy Mistral log config\n  sudo: true\n  command: cp /opt/openstack/mistral/etc/wf_trace_logging.conf.sample /etc/mistral/wf_trace_logging.conf creates=/etc/mistral/wf_trace_logging.conf\n\n- name: Change Mistral log path\n  sudo: true\n  lineinfile:\n    dest: /etc/mistral/wf_trace_logging.conf\n    regexp: '^args=\\(\"/var/log/mistral.log'\n    line: 'args=(\"/var/log/mistral/mistral.log\",)'\n\n- name: Change Mistral trace path\n  sudo: true\n  lineinfile:\n    dest: /etc/mistral/wf_trace_logging.conf\n    regexp: '^args=\\(\"/var/log/mistral_wf_trace.log'\n    line: 'args=(\"/var/log/mistral/mistral_wf_trace.log\",)'\n\n- name: Create init config\n  sudo: true\n  template:\n    src: init.j2\n    dest: /etc/init/mistral.conf\n  notify:\n    - restart mistral\n"}, {"commit_sha": "067d6cbb20adb31a1e2bd9f689b5b6e259c30288", "sha": "4ca5380a2827c79510cd09d29ebfe9e26066951d", "filename": "tasks/section_03_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n#sections 3.3 and 3.4 have to happen before as the latter overwrite 3.1 and 3.2\n\n  - name: 3.0 Check for /boot/grub/grub.cfg file\n    stat: path=/boot/grub/grub.cfg\n    register: grub_cfg_file\n    tags:\n      - section3\n\n  - name: 3.3.1.1 Set Boot Loader Superuser (check) (Scored)\n    command: grep \"^set superusers\" /boot/grub/grub.cfg\n    register: boot_superusers \n    when: grub_cfg_file.stat.exists == True\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section3\n      - section3.3\n      - section3.3.1\n      - section3.3.1.1\n\n  - name: 3.3.1.2 Set Boot Loader Superuser (Scored)\n    lineinfile: >\n        dest='/etc/grub.d/40_custom'\n        regexp='^set superusers'\n        line='set superusers=\"root\"'\n        state=present\n        create=yes\n    when: grub_cfg_file.stat.exists == True and boot_superusers.rc == 1\n    tags:\n      - section3\n      - section3.3\n      - section3.3.1\n      - section3.3.1.2\n    \n  - name: 3.3.2.1 Set Boot Loader Password (check) (Scored)\n    command: grep \"^password\" /boot/grub/grub.cfg\n    register: boot_password\n    when: grub_cfg_file.stat.exists == True\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section3\n      - section3.3\n      - section3.3.2\n      - section3.3.2.1\n\n  - name: 3.3.2.2 Set Boot Loader Password (Scored)\n    lineinfile: >\n        dest='/etc/grub.d/40_custom' \n        regexp='^password'\n        line='password_pbkdf2 root grub.pbkdf2.sha512.10000.529DB4AF052F170948C1DB2A754CEA8A286804DA2D9A4EB5A7CCE4B8636775C83EAF8A1093CBDBC256954BCE789A58EFB3B75D23DFC76583C703922D5DADB69E.4D5BD1EC6736057095CA2EBF55C2DA02DFB0B0784F2105A396F1CEF11FEB1483D5C420F412E2E817E2570DDFC22ABCC329C5FF44091A0ACDE67171FF72E96CFD'\n        state=present\n    when: grub_cfg_file.stat.exists == True and boot_password.rc == 1\n    tags:\n      - section3\n      - section3.3\n      - section3.3.2\n      - section3.3.2.2\n\n  - name: 3.3.3 Disable password protection booting\n    lineinfile: >\n        dest='/etc/grub.d/10_linux'\n        create=yes\n        regexp='^CLASS='\n        line='CLASS=\"--class gnu-linux --class gnu --class os --unrestricted\"'\n        state=present\n    tags:\n      - section3\n      - section3.3\n      - section3.3.3\n\n\n  - name: 3.3.4 Update Grub configuration (Scored)\n    command: update-grub\n    when: grub_cfg_file.stat.exists == True and (boot_superusers.rc == 1 or boot_password.rc == 1)\n    tags:\n      - section3\n      - section3.3\n      - section3.3.4\n\n\n  - name: 3.4.1 Require Authentication for Single-User Mode (check) (Scored)\n    shell: 'grep \"^root:[*\\!]:\" /etc/shadow'\n    register: root_password_set\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section3\n      - section3.4\n      - section3.4.1\n\n  - name: 3.4.2 Require Authentication for Single-User Mode (Scored)\n    user: name=root state=present password='{{ root_password }}'\n    when: root_password_set.rc == 1\n    tags:\n      - section3\n      - section3.4\n      - section3.4.2\n\n  - name: 3.1 Set User/Group Owner on bootloader config (Scored)\n    file: path=/boot/grub/grub.cfg owner=root group=root\n    when: grub_cfg_file.stat.exists == True\n    tags:\n      - section3\n      - section3.1\n\n  - name: 3.2 Set Permissions on bootloader config (Scored)\n    file: path=/boot/grub/grub.cfg mode=\"o-rwx,g-rwx\"\n    when: grub_cfg_file.stat.exists == True\n    sudo: yes\n    tags:\n      - section3\n      - section3.2\n"}, {"commit_sha": "9966c6de1ed4ef5071a9bea83b4bb69a11dd32ba", "sha": "84401e3d3322807c46bae430a6efeac64fd382a5", "filename": "roles/registrator/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for registrator\nregistrator_image: \"gliderlabs/registrator:master\"\nregistrator_uri: \"consul://{{ ansible_default_ipv4.address }}:8500\"\nhostname: \"{{ ansible_all_ipv4_addresses }}\"\n\n"}, {"commit_sha": "9966c6de1ed4ef5071a9bea83b4bb69a11dd32ba", "sha": "858fad61f52a094350c75b9ff8b66a8fe6262f11", "filename": "roles/docker/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for docker\n- name: Restart docker\n  shell: restart docker\n  sudo: yes\n"}, {"commit_sha": "1bb50a6149f6ff7f2e6399411418d088e2c52d01", "sha": "b59e73102510bb66b2c70a1788aeb034f2ea0a05", "filename": "tasks/section_03_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n#sections 3.3 and 3.4 have to happen before as the latter overwrite 3.1 and 3.2\n\n  - name: 3.0 Check for /boot/grub/grub.cfg file (Not Scored)\n    stat: path=/boot/grub/grub.cfg\n    register: grub_cfg_file\n    tags:\n      - section3\n\n  - name: 3.3.1.1 Set Boot Loader Superuser (check) (Scored)\n    command: grep \"^set superusers\" /boot/grub/grub.cfg\n    register: boot_superusers\n    when: grub_cfg_file.stat.exists == True\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section3\n      - section3.3\n      - section3.3.1\n      - section3.3.1.1\n\n  - name: 3.3.1.2 Set Boot Loader Superuser (Scored)\n    lineinfile: >\n        dest='/etc/grub.d/40_custom'\n        regexp='^set superusers'\n        line='set superusers=\"root\"'\n        state=present\n        create=yes\n    when: grub_cfg_file.stat.exists == True and boot_superusers.rc == 1\n    tags:\n      - section3\n      - section3.3\n      - section3.3.1\n      - section3.3.1.2\n\n  - name: 3.3.2.1 Set Boot Loader Password (check) (Scored)\n    command: grep \"^password\" /boot/grub/grub.cfg\n    register: boot_password\n    when: grub_cfg_file.stat.exists == True\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section3\n      - section3.3\n      - section3.3.2\n      - section3.3.2.1\n\n  - name: 3.3.2.2 Set Boot Loader Password (Scored)\n    lineinfile: >\n        dest='/etc/grub.d/40_custom'\n        regexp='^password'\n        line='password_pbkdf2 root grub.pbkdf2.sha512.10000.529DB4AF052F170948C1DB2A754CEA8A286804DA2D9A4EB5A7CCE4B8636775C83EAF8A1093CBDBC256954BCE789A58EFB3B75D23DFC76583C703922D5DADB69E.4D5BD1EC6736057095CA2EBF55C2DA02DFB0B0784F2105A396F1CEF11FEB1483D5C420F412E2E817E2570DDFC22ABCC329C5FF44091A0ACDE67171FF72E96CFD'\n        state=present\n    when: grub_cfg_file.stat.exists == True and boot_password.rc == 1\n    tags:\n      - section3\n      - section3.3\n      - section3.3.2\n      - section3.3.2.2\n\n  - name: 3.3.3 Disable password protection booting (Scored)\n    lineinfile: >\n        dest='/etc/grub.d/10_linux'\n        create=yes\n        regexp='^CLASS='\n        line='CLASS=\"--class gnu-linux --class gnu --class os --unrestricted\"'\n        state=present\n    tags:\n      - section3\n      - section3.3\n      - section3.3.3\n\n\n  - name: 3.3.4 Update Grub configuration (Scored)\n    command: update-grub\n    when: grub_cfg_file.stat.exists == True and (boot_superusers.rc == 1 or boot_password.rc == 1)\n    tags:\n      - section3\n      - section3.3\n      - section3.3.4\n\n\n  - name: 3.4.1 Require Authentication for Single-User Mode (check) (Scored)\n    shell: 'grep \"^root:[*\\!]:\" /etc/shadow'\n    register: root_password_set\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section3\n      - section3.4\n      - section3.4.1\n\n  - name: 3.4.2 Require Authentication for Single-User Mode (Scored)\n    user: name=root state=present password='{{ root_password }}'\n    when: root_password_set.rc == 1\n    tags:\n      - section3\n      - section3.4\n      - section3.4.2\n\n  - name: 3.1 Set User/Group Owner on bootloader config (Scored)\n    file: path=/boot/grub/grub.cfg owner=root group=root\n    when: grub_cfg_file.stat.exists == True\n    tags:\n      - section3\n      - section3.1\n\n  - name: 3.2 Set Permissions on bootloader config (Scored)\n    file: path=/boot/grub/grub.cfg mode=\"o-rwx,g-rwx\"\n    when: grub_cfg_file.stat.exists == True\n    sudo: yes\n    tags:\n      - section3\n      - section3.2\n"}, {"commit_sha": "c0a575a4d0d5cd8c461b6388abf28ee3a245fd42", "sha": "fab6acee1e0766b79e297871d39291cd1b7b4a28", "filename": "meta/main.yml", "repository": "threatstack/threatstack-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Apollo Catlin\n  description: Ansible role to install the threatstack agent\n  company: Threat Stack\n  license: license (Apache)\n  min_ansible_version: 1.3\n  platforms:\n  - name: EL\n    versions:\n    - all\n    - 5\n    - 6\n    - 7\n  - name: Fedora\n    versions:\n    - all\n    - 16\n    - 17\n    - 18\n    - 19\n    - 20\n  - name: Amazon\n    versions:\n    - all\n    - 2013.03\n    - 2013.09\n  - name: Ubuntu\n    versions:\n    - all\n    - lucid\n    - maverick\n    - natty\n    - oneiric\n    - precise\n    - quantal\n    - raring\n    - saucy\n    - trusty\n  categories:\n  - cloud\n  - cloud:ec2\n  - monitoring\n  - system\ndependencies: []\n"}, {"commit_sha": "c0a575a4d0d5cd8c461b6388abf28ee3a245fd42", "sha": "eb80403d68abf0500b7e865c46f6732607cab6ba", "filename": "tasks/apt_install.yml", "repository": "threatstack/threatstack-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n- name: Install setup dependency.\n  apt:\n    name: python-apt\n    update_cache: yes\n    state: installed\n\n- name: Add Threat Stack apt repository key.\n  apt_key:\n    url: https://app.threatstack.com/APT-GPG-KEY-THREATSTACK\n    id: 6EE04BD4\n    validate_certs: no\n\n- name: Add Threat Stack apt repository.\n  apt_repository:\n    repo: \"deb {{ threatstack_pkg_url }}/Ubuntu {{ ansible_distribution_release }} main\"\n    state: present\n    update_cache: yes\n\n- name: Ensure Threat Stack is installed.\n  apt:\n    name: threatstack-agent\n    state: installed\n"}, {"commit_sha": "f565940c5163524c7834123625c804e5f69c2b10", "sha": "43350dab84d9b4391691b0ab3389f431759b8b67", "filename": "tasks/Amazon/main.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/Amazon/main.yml: CentOS specific set-up\n# This takes care of base prerequisites for Amazon Linux AMI\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure the Sensu Core Yum repo is present\n    copy:\n      dest: /etc/yum.repos.d/sensu.repo\n      content: |\n        [sensu]\n        name=sensu\n        baseurl=http://repositories.sensuapp.org/yum/$basearch/\n        gpgcheck=0\n        enabled=1\n      owner: root\n      group: root\n      mode: 0644\n\n  - name: Ensure Sensu is installed\n    yum: name={{ sensu_package }} state={{ sensu_pkg_state }}\n"}, {"commit_sha": "32211ebd2a9f45112f8dceda80bc95d0db029fb4", "sha": "82946090639bed3bc6cbc65dbed7be0a4b47d5eb", "filename": "tasks/freebsd_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Setup FreeBSD specific variables (set_fact)\n  set_fact:\n    tor_DataDir: /var/db/tor-instances\n    tor_ConfDir: /usr/local/etc/tor/enabled\n    tor_PidDir: /var/run/tor-instances\n  tags:\n   - reconfigure\n   - renewkey\n\n- name: Ensure Tor is installed (FreeBSD)\n  become: yes\n  pkgng: name=tor state=present\n  tags:\n   - install\n\n- name: Ensure sequential IP IDs are avoided (net.inet.ip.random_id)\n  become: yes\n  sysctl: name=net.inet.ip.random_id value=1 reload=no sysctl_set=yes\n\n- name: Gather current kern.ipc.somaxconn setting (FreeBSD)\n  shell: \"sysctl kern.ipc.somaxconn|cut -d' '  -f2\"\n  register: currentsomaxconn\n\n- name: Ensure somaxconn setting is reasonable (FreeBSD)\n  become: yes\n  sysctl: name=kern.ipc.somaxconn value={{ freebsd_somaxconn }} reload=no sysctl_set=yes\n  when: currentsomaxconn.stdout|int < {{ freebsd_somaxconn }}\n\n- name: Gather current kern.ipc.nmbclusters setting (FreeBSD)\n  shell: \"sysctl kern.ipc.nmbclusters|cut -d' '  -f2\"\n  register: currentnmbc\n\n- name: Ensure nmbclusters setting is reasonable (FreeBSD)\n  become: yes\n  sysctl: name=kern.ipc.nmbclusters value={{ freebsd_nmbclusters }} reload=no sysctl_set=yes\n  when: currentnmbc.stdout|int < {{ freebsd_nmbclusters }}\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "0beb5221b779361b35dbb0925b17fa6876e5ec7c", "filename": "tasks/section_01.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - include: section_01_level1.yml\n    tags:\n      - section01\n      - level1\n\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "1c13357d30125686ebbad84474af1518b47c4cff", "filename": "tasks/check_requirements.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: Check if OS is Debian-based (we do not support others)\n    debug: msg=\"Check OS family\"\n    failed_when: ansible_os_family != \"Debian\"\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "b7b2cad328fdc9492e800438081be90d758a66bd", "filename": "tasks/section_10.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - include: section_10_level1.yml\n    tags:\n      - section10\n      - level1\n\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "4b724f8a32d799d130d6885d4e628b8ee4116fa9", "filename": "tasks/install_remote.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# File: install_remote.yml - package installation tasks for Consul\n\n- name: Install OS packages\n  package:\n    name: \"{{ item }}\"\n    state: present\n  with_items: \"{{ consul_os_packages }}\"\n  tags: installation\n\n- name: Validate remote Consul directory\n  file:\n    path: /tmp/consul\n    state: directory\n\n- name: Read Consul package checksum file\n  stat:\n    path: \"/tmp/consul/consul_{{ consul_version }}_SHA256SUMS\"\n  register: consul_checksum\n  changed_when: false\n  tags: installation\n\n- name: Download Consul package checksum file\n  get_url:\n    url: \"{{ consul_checksum_file_url }}\"\n    dest: \"/tmp/consul/consul_{{ consul_version }}_SHA256SUMS\"\n    validate_certs: false\n  tags: installation\n  when: not consul_checksum.stat.exists | bool\n\n- name: Read Consul package checksum\n  shell: \"grep {{ consul_pkg }} /tmp/consul/consul_{{ consul_version }}_SHA256SUMS\"\n  register: consul_sha256\n  changed_when: false\n  tags:\n    - installation\n    - skip_ansible_lint\n\n- name: Check Consul package file\n  stat:\n    path: \"/tmp/consul/{{ consul_pkg }}\"\n  register: consul_package\n  tags: installation\n\n- name: Download Consul\n  get_url:\n    url: \"{{ consul_zip_url }}\"\n    dest: \"/tmp/consul/{{ consul_pkg }}\"\n    checksum: \"sha256:{{ consul_sha256.stdout.split(' ')|first }}\"\n    timeout: 42\n  register: consul_download\n  tags: installation\n\n- name: Unarchive Consul and install binary\n  unarchive:\n    remote_src: true\n    src: \"/tmp/consul/{{ consul_pkg }}\"\n    dest: \"{{ consul_bin_path }}\"\n    owner: \"{{ consul_user }}\"\n    group: \"{{ consul_group }}\"\n    mode: 0755\n  register: consul_install\n  notify:\n    - restart consul\n  when: consul_download is changed\n  tags: installation\n\n- name: Daemon reload systemd in case the binaries upgraded\n  systemd: daemon_reload=yes\n  become: true\n  when:\n    - ansible_service_mgr == \"systemd\"\n    - consul_install_upgrade | bool\n    - consul_install is changed\n\n- name: Cleanup\n  file:\n    path: \"/tmp/consul\"\n    state: absent\n  tags: installation\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "bc4dda6d38d89a0150eaeacd1cbbba9f123a8836", "filename": "roles/mesos_maintenance/tasks/schedule.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "# schedule maintenance\n- name: deploy schedule template\n  sudo: yes\n  sudo_user: root\n  template:\n    src: schedule.json.j2\n    dest: /tmp/schedule.json\n  run_once: true\n  when: mesos_maintenance_schedule\n"}, {"commit_sha": "8cf75eb68465f1126872131afd102e05068a9df2", "sha": "44617d6949d8b6bf3e0ad200b6f158d7436a298a", "filename": "tasks/configure.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Ensure Tor DataDir(s) exist and is owned by tor_user\n  sudo: yes\n  file: path={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}\n    state=directory\n    owner={{ tor_user }}\n    mode=0700\n    recurse=yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - debian\n   - centos\n   - freebsd\n   - openbsd\n   - createdir\n\n- name: Ensure Tor config directory exists and has appropriate permissions\n  sudo: yes\n  file: path={{ tor_ConfDir }}\n    state=directory\n    owner=root\n    group={{ tor_user }}\n    mode=755\n  tags:\n   - debian\n   - centos\n   - freebsd\n   - openbsd\n\n- name: Ensure LogDir exists and has appropriate permissions\n  sudo: yes\n  file: path={{ tor_LogDir }}\n    state=directory\n    owner={{ tor_user }}\n    mode=750\n  tags:\n   - debian\n   - centos\n   - freebsd\n   - openbsd\n\n- name: Ensure PidDir is owned by tor_user\n  sudo: yes\n  file: path={{ tor_PidDir }}\n    state=directory\n    owner={{ tor_user }}\n    group={{ tor_user }}\n    mode=2750\n  tags:\n   - debian\n   - centos\n   - freebsd\n   - openbsd\n\n- name: Generating temporary (without MyFamily) torrc file(s)...\n  sudo: yes\n  template: src=torrc\n    dest=\"{{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc-tmp\"\n    owner=root\n    mode=0644\n  with_nested:\n   - tor_ips\n   - tor_ports\n  tags:\n   - debian\n   - centos\n   - freebsd\n   - openbsd\n\n- name: Collect relay fingerprints (for MyFamily)\n  sudo: yes\n  shell: \"tor --hush -f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc-tmp --list-fingerprint |cut -d' ' -f2-|sed -e 's, ,,g'\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n  register: tor_fingerprints\n  tags:\n   - debian\n   - centos\n   - freebsd\n   - openbsd\n   - configure\n\n- name: Generating final torrc file(s) (with MyFamily)\n  sudo: yes\n  template: >\n    src=torrc\n    dest=\"{{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\"\n    owner=root\n    mode=0644\n    backup=yes\n    validate=\"tor --verify-config -f %s\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n  register: instances\n  tags:\n   - debian\n   - centos\n   - freebsd\n   - openbsd\n   - configure\n\n# Linux/systemd section (uses service module)\n# ===========================================\n \n- name: Ensure Tor instances are reloaded if its torrc changed (Linux/systemd)\n  sudo: yes\n  service: name=tor@{{ item.item[0] }}_{{ item.item.1.orport }}.service state=reloaded\n  with_items: instances.results\n  when: ansible_system == 'Linux' and item.changed == True \n  tags:\n   - debian\n   - centos\n   - configure\n\n- name: Ensure Tor instances are enabled and started (Linux/systemd)\n  sudo: yes\n  service: name=tor@{{ item[0] }}_{{ item.1.orport }}.service enabled=yes state=started\n  with_nested:\n   - tor_ips\n   - tor_ports\n  when: ansible_system == 'Linux'\n  tags:\n   - debian\n   - centos\n\n# OpenBSD section (uses service module)\n# This is basically a copy from the Linux\n# section, but it requires different service\n# names and additional arguments.\n# =====================================\n\n# OpenBSD does not support multi-instance rc.d\n# # so we link as many pseudo rc scripts as we need.\n# # OpenBSD does not like dots in rc filenames so\n# # we replace them with underscores.\n- name: Create links to the service files (OpenBSD)\n  sudo: yes\n  file: src=/etc/rc.d/tor state=link path=/etc/rc.d/tor{{ item[0]| replace('.','_') }}_{{ item.1.orport }}\n  with_nested:\n   - tor_ips\n   - tor_ports\n  when: ansible_system == 'OpenBSD'\n  tags:\n   - openbsd\n\n- name: Ensure Tor instances are enabled and started (OpenBSD)\n  sudo: yes\n  service: name=tor{{ item[0]|replace('.','_') }}_{{ item.1.orport }}\n   arguments=\"-f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\" enabled=yes state=started\n  with_nested:\n   - tor_ips\n   - tor_ports\n  when: ansible_system == 'OpenBSD'\n  tags:\n   - openbsd\n\n- name: Ensure Tor instances are reloaded if its torrc changed (OpenBSD)\n  sudo: yes\n  service: name=tor{{ item.item[0]|replace('.','_') }}_{{ item.item.1.orport }} state=reloaded\n  with_items: instances.results\n  when: ansible_system == 'OpenBSD' and item.changed == True\n  tags:\n   - openbsd\n   - configure\n\n\n# FreeBSD section\n# ================\n\n- name: Ensure Tor instances are reloaded if its torrc changed (FreeBSD)\n  sudo: yes\n  shell: \"kill -HUP `cat {{ tor_PidDir }}/{{ item.item[0] }}_{{ item.item.1.orport }}.pid`\"\n  ignore_errors: yes\n  with_items: instances.results\n  when: item.changed == True and ansible_system == 'FreeBSD'\n  tags:\n   - freebsd\n   - configure\n\n- name: Ensure Tor instances are running (FreeBSD)\n  sudo: yes\n  shell: \"kill -0 `cat {{ tor_PidDir }}/{{ item[0] }}_{{ item.1.orport }}.pid` || tor -f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n  when: ansible_system == 'FreeBSD'\n  tags:\n   - freebsd\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "c3f8ea513b12ead7523a3971b66f86f36f15fdc4", "filename": "roles/mesos/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- include: master.yml\n- include: slave.yml\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "db764e47527a2eaaf336463875eca3b804ace0fb", "filename": "roles/dcos_cli/vars/promdash.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "dcos_cli_app_promdash_enabled: \"{{ prometheus_enabled }}\"\ndcos_cli_app_promdash_mem: 128\ndcos_cli_app_promdash_cpus: 0.5\ndcos_cli_app_promdash_instances: 1\n"}, {"commit_sha": "2a8ca91248bb834daaa8c35f709d6f8158d81a38", "sha": "134bcfe867e1dacdc394357b1de5cbe96899dd26", "filename": "tasks/configure.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Ensure local DataDir folders exist (LOCAL)\n  file:\n    path: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    state: directory\n    mode: 0700\n  delegate_to: 127.0.0.1\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - createdir\n\n- name: Ensure all relay keys exist (LOCAL)\n  local_action: command tor --PublishServerDescriptor 0 --orport auto --list-fingerprint --datadirectory \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}\" --Log \"err stdout\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Generate new Ed25519 signing keys (LOCAL)\n  local_action: command tor --keygen --SigningKeyLifetime {{ tor_signingkeylifetime_days}}\\ days --datadirectory \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}\" --Log \"err stdout\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - renewkey\n\n- name: Detect duplicate relay keys across relays (LOCAL)\n  shell: sha1sum {{ tor_offline_masterkey_dir }}/*/keys/secret_id_key {{ tor_offline_masterkey_dir }}/*/keys/ed25519_master_id_secret_key|cut -d/ -f1|sort|uniq -d|wc -l\n  delegate_to: 127.0.0.1\n  register: dupcount\n\n- name: Abort on duplicate relay keys\n  fail: msg=\"Duplicate relay key detected! Aborting.\"\n  when: dupcount.stdout != \"0\"\n\n- name: Detect if Ed25519 master keys are on the relay\n  stat:\n    path: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/ed25519_master_id_secret_key\"\n  become: yes\n  register: masterkeycheck\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Abort if Ed25519 master keys are on the relay\n  fail: msg=\"\n\n            Ed25519 MASTER KEY detected on the relay - it is NOT supposed to be there! Aborting.\"\n  when: item.stat.exists == True\n  with_items: \"{{ masterkeycheck.results }}\"\n\n- name: Collect fingerprints for MyFamily (LOCAL)\n  shell: cut {{ tor_offline_masterkey_dir }}/*/fingerprint -d\" \" -f2|sort|xargs|sed -e 's/ /,/g'\n  delegate_to: 127.0.0.1\n  register: family\n  tags:\n   - reconfigure\n\n- name: Ensure per-instance tor users exist\n  become: yes\n  user:\n    name: _tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\n    system: yes\n    shell: /bin/false\n    createhome: no\n    home: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure per-instance config folders exist (Debian only)\n  become: yes\n  file:\n    path: \"{{ tor_ConfDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    state: directory\n    mode: 0755\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  when: ansible_pkg_mgr == 'apt'\n\n- name: Ensure DataDir exists\n  become: yes\n  file:\n    path: \"{{ tor_DataDir }}\"\n    state: directory\n    owner: root\n    mode: 0755\n\n- name: Ensure \"keys\" subfolder exists\n  become: yes\n  file:\n    path: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys\"\n    state: directory\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    group: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0700\n    recurse: yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure RSA key is in place (without overriding existing keys)\n  become: yes\n  copy:\n    src: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    dest: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0700\n    force: no\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'secret_id_key' ]\n\n- name: Fetch RSA key for comparision\n  become: yes\n  fetch:\n    src: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    dest: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}.untrustedremotekey\"\n    flat: yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'secret_id_key' ]\n\n- name: Compare local vs. remote RSA key (secret_id_key)\n  local_action: shell sha1sum {{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-\"{{ item.0.ipv4 }}_{{ item.1.orport }}\"/keys/secret_id_key*|cut -d/ -f1|uniq -d|wc -l\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  register: rsakey\n\n- name: Abort if local and remote RSA keys do not match\n  fail: 'msg=\"\n\n\n   Key MISMATCH detected: Remote RSA key does not match local key - manual intervention required.\n\n   We detected that the remote host uses an RSA key that was not generated by us.\n   We will not override it with our locally generated key.\n\n   If you want to make use of the remote RSA key you have to override the local key manually:\n\n\n   cd ~/.tor/offlinemasterkeys/<inventoryname>-<IP_port>/keys\n\n   mv secret_id_key.untrustedremotekey secret_id_key\"'\n  when: item.stdout != \"1\"\n  with_items: \"{{ rsakey.results }}\"\n\n# this task is separated from the task named \"Ensure RSA key is in place\" because it is not run with 'force=no'\n- name: Transmit new Ed25519 signing keys\n  become: yes\n  copy:\n    src: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    dest: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0700\n    setype: tor_var_lib_t\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'ed25519_signing_cert', 'ed25519_signing_secret_key' ]\n  tags:\n   - renewkey\n\n# This needs to be at the end to fix SELinux contexts recursively\n- name: Ensure per-instance DataDir have proper permissions\n  become: yes\n  file:\n    path: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    state: directory\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    group: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0700\n    recurse: yes\n    setype: tor_var_lib_t\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure Tor config directory exists\n  become: yes\n  file:\n    path: \"{{ tor_ConfDir }}\"\n    state: directory\n    owner: root\n    group: \"{{ tor_user }}\"\n    mode: 0755\n\n- name: Ensure tor-exit-notice.html is present (if we are an exit)\n  become: yes\n  template:\n    src: tor-exit-notice.html\n    dest: \"{{ tor_ConfDir }}/tor-exit-notice.html\"\n    mode: 0444\n  when: tor_ExitRelay == True and tor_ExitNoticePage == True\n\n- name: Generating torrc file(s)\n  become: yes\n  template:\n    src: torrc\n    dest: \"{{ (ansible_pkg_mgr != 'apt')| ternary(tor_ConfDir ~ '/' ~ item.0.ipv4 ~ '_' ~ item.1.orport ~ '.torrc', tor_ConfDir ~ '/' ~ item.0.ipv4 ~ '_' ~ item.1.orport ~ '/torrc') }}\"\n    owner: root\n    mode: 0644\n    backup: yes\n    validate: \"tor --verify-config -f %s\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  register: instances\n  notify:\n    - Ensure Tor instances are reloaded if its torrc changed (FreeBSD)\n    - Ensure Tor instances are reloaded if its torrc changed (Linux)\n  tags:\n   - reconfigure\n"}, {"commit_sha": "61b008311c40b377e57e166b778232a20224f7c6", "sha": "ad51da29f7d252a510c72892bdd29a2f3393f970", "filename": "tasks/replication.yml", "repository": "UnderGreen/ansible-role-mongodb", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Replication configuration\n  mongodb_replication:\n    login_host: \"{{ mongodb_login_host|default('localhost') }}\"\n    login_port: \"{{ mongodb_login_port|default(27017) }}\"\n    login_user: \"{{ mongodb_root_admin_name }}\"\n    login_password: \"{{ mongodb_root_admin_password }}\"\n    replica_set: \"{{ mongodb_conf_replSet }}\"\n    host_name: \"{{ item.host_name }}\"\n    host_port: \"{{ item.host_port|default(27017) }}\"\n    host_type: \"{{ item.host_type|default('replica') }}\"\n    hidden: \"{{ item.hidden|default(false) }}\"\n    priority: \"{{ item.priority|default(1.0) }}\"\n  when: mongodb_conf_auth and mongodb_replication_params is defined\n  with_items:\n    - \"{{ mongodb_replication_params }}\"\n\n- name: Replication configuration without auth\n  mongodb_replication:\n    login_host: \"{{ mongodb_login_host|default('localhost') }}\"\n    login_port: \"{{ mongodb_login_port|default(27017) }}\"\n    replica_set: \"{{ mongodb_conf_replSet }}\"\n    host_name: \"{{ item.host_name }}\"\n    host_port: \"{{ item.host_port|default(27017) }}\"\n    host_type: \"{{ item.host_type|default('replica') }}\"\n    hidden: \"{{ item.hidden|default(false) }}\"\n    priority: \"{{ item.priority|default(1.0) }}\"\n  when: not mongodb_conf_auth and mongodb_replication_params is defined\n  with_items:\n    - \"{{ mongodb_replication_params }}\"\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "61cb9e578478b8283a214846577e5410078334c6", "filename": "roles/marathon/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for marathon\nmarathon_consul_dir: /etc/consul.d\nmarathon_enabled: true\nmarathon_version: '0.11.1'\nmarathon_restart_policy: 'always'\nmarathon_net: 'host'\nmarathon_hostname: \"{{ ansible_ssh_host }}\"\nmarathon_port: '8080'\nmarathon_container_memory_limit: '512MB'\nmarathon_java_settings: '-Xmx512m -Xms512m -XX:+HeapDumpOnOutOfMemoryError'\nmarathon_artifact_store: 'file:///store'\nmarathon_artifact_store_dir: '/etc/marathon/store'\nmarathon_server_zk_group: marathon_servers\nmarathon_rebuild_container: False\nmarathon_image: \"mesosphere/marathon:v{{ marathon_version }}\"\nmarathon_master_peers: \"zk://{{ zookeeper_peers_nodes }}/mesos\"\nmarathon_zk_peers: \"zk://{{ zookeeper_peers_nodes }}/marathon\"\nmarathon_command: \"--artifact_store {{ marathon_artifact_store }} --hostname {{ marathon_hostname }} --master {{ marathon_master_peers }} --zk {{ marathon_zk_peers }}\"\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "41dad890a6bc3e0f56f1a7f63035362449e779b6", "filename": "tasks/section_13.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - include: section_13_level1.yml\n    tags:\n      - section13\n      - level1\n\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "0b2f633f1403cfb8fa95f21ecb01754165a17943", "filename": "roles/mesos_maintenance/vars/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# vars file for mesos-maintenance\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "fd15c68e96e6cabb8e36e4dae82f850c9c20978a", "filename": "roles/traefik/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n- name: create traefik config directory\n  become: yes\n  file:\n    path: \"{{ traefik_config_dir }}\"\n    state: directory\n    mode: 0755\n  tags:\n    - traefik\n\n- name: configure traefik\n  become: yes\n  template:\n    src: traefik.toml.j2\n    dest: \"{{ traefik_config_dir }}/traefik.toml\"\n    mode: 0644\n    backup: yes\n  tags:\n    - traefik\n\n- name: install check scripts\n  become: yes\n  copy:\n    src: wait-for-marathon.sh\n    dest: \"{{ traefik_config_dir }}\"\n    mode: 0755\n  tags:\n    - traefik\n\n- name: deploy traefik service\n  become: yes\n  template:\n    src: traefik.service.j2\n    dest: /etc/systemd/system/traefik.service\n  notify:\n    - restart traefik\n  tags:\n    - traefik\n\n- name: enable traefik\n  become: yes\n  service:\n    name: traefik\n    state: started\n    enabled: yes\n  tags:\n    - traefik\n\n- name: Set traefik consul service definition\n  become: yes\n  template:\n    src: traefik-consul.json.j2\n    dest: \"{{ traefik_consul_dir }}/traefik.json\"\n  notify:\n    - restart consul\n  tags:\n    - traefik\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "7d7bf5490ef95a9fe0a71379d744a66eb7326633", "filename": "roles/weave/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for weave\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "0b59b1fdeb20a39563a06a918ac62f4e14cedc07", "filename": "roles/mesos_maintenance/tasks/complete.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "# complete maintenance\n- name: complete maintenance\n  command: \"curl -XPOST -x '' http://{{ mesos_maintenance_master_url }}/master/machine/up -d@/tmp/machines.json -H 'Content-type: application/json'\"\n  register: complete_content\n  when: mesos_maintenance_complete\n\n- name: wait for agent to be healthy\n  sudo: yes\n  command: /tmp/wait-for-agent.sh\n  when: mesos_maintenance_complete\n"}, {"commit_sha": "f5364b57f100ae9fa898af59b7812ec0c447ac42", "sha": "f40f09e17c15f44734450898474f24f1090abac6", "filename": "tasks/freebsd_service.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n# tor_intances defines the number and configurations of instances\n# an instance is defined with the following fields:\n# inst_name:configfile:username:groupname:pidfile:data_dir\n# username/groupname is set to root to be able to bind to <1024 ports\n# but privileges are dropped afterwards (torrc User parameter)\n- name: Ensure Tor multi-instance configuration is present (FreeBSD)\n  become: yes\n  lineinfile:\n    dest: /etc/rc.conf\n    line: \"tor_instances=\\\"${tor_instances} {{ item.0.ipv4 }}_{{ item.1.orport }}:{{ tor_ConfDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}.torrc:root:root:{{ tor_PidDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/pid:{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\\\"\"\n    create: yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n# this task is a workaround, because 'service tor status'\n# fails if this line is not present (which in turn fails the ansible service module)\n- name: ensure tor instance FreeBSD\n  become: yes\n  lineinfile:\n    dest: /etc/rc.conf\n    line: \"tor_enable=\\\"YES\\\"\"\n    create: yes\n\n- name: Ensure PidDir exists (FreeBSD)\n  become: yes\n  file:\n    path: \"{{ tor_PidDir }}\"\n    state: directory\n    owner: root\n    mode: 0755\n\n- name: Ensure PidDir is owned by per-instance tor_user (FreeBSD)\n  become: yes\n  file:\n    path: \"{{ tor_PidDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    state: directory\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0700\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n# this affects all instances\n- name: Ensure Tor instances are running and enabled (FreeBSD)\n  become: yes\n  service:\n    name: tor\n    enabled: yes\n    state: started\n"}, {"commit_sha": "15d2da095f9bd54a50954dee18597710e1951943", "sha": "d2fb8dda2e5066ad4ae9a3572913dabf9d40d0b2", "filename": "tasks/darwin/macosx.yml", "repository": "ansiblebit/oracle-java", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# file: oracle-java/tasks/darwin/macosx.yml\n#\n# Task file to install Oracle Java Development Kit in a system with a OSX based Darwin distribution.\n#\n\n- name: download DMG file\n  shell:\n    \"curl -L  -H 'Cookie:oraclelicense=accept-securebackup-cookie' -o {{ oracle_java_dir_source }}/{{ oracle_java_dmg_filename }} {{ oracle_java_dmg_url }}\"\n  when: not oracle_java_task_dmg_check|skipped and not oracle_java_task_dmg_check.stat.exists\n  args:\n    creates: \"{{ oracle_java_dir_source }}/{{ oracle_java_dmg_filename }}\"\n  tags:\n    - installation\n\n- name: mount DMG image\n  shell: echo TODO\n  tags:\n    - installation\n\n- name: install JDK\n  shell: echo TODO\n  tags:\n    - installation\n\n- name: unmount DMG image\n  shell: echo TODO\n  tags:\n    - installation\n\n- name: set Java version as default\n  shell: echo TODO\n  when: oracle_java_set_as_default\n  register: oracle_java_task_set_default\n  become: yes\n\n- name: in case there were changes, check host environment again\n  include: ../check_environment.yml\n\n"}, {"commit_sha": "6d51642c8f7babe4c8185b60872420333a5d3caa", "sha": "2376e97aa48234643f7af970aae60860cc361e14", "filename": "tasks/Ubuntu/main.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/Ubuntu/main.yml: Ubuntu specific set-up\n# This takes care of base prerequisites for Ubuntu\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure the Sensu APT repo GPG key is present\n    apt_key:\n      url: http://repositories.sensuapp.org/apt/pubkey.gpg\n      state: present\n\n  - name: Ensure the Sensu Core APT repo is present\n    apt_repository:\n      repo: 'deb     http://repositories.sensuapp.org/apt sensu main'\n      state: present\n      update_cache: true\n\n  - name: Ensure Sensu is installed\n    apt: name=sensu state={{ sensu_pkg_state }}\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "9cf546442c04ec3b796302edf521e817f7c6a21f", "filename": "roles/haproxy/vars/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# vars file for haproxy\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "04160e02a998509c66165aa227b86d1e8e28aee8", "filename": "tasks/section_04_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 4.5.1 Check if the grub config file exists (Not Scored)\n    stat: path=/etc/default/grub\n    register: grub_cfg_file\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5.2 Determines if AppArmor is set in grub config (Not Scored)\n    command: \"grep 'GRUB_CMDLINE_LINUX' /etc/default/grub\"\n    register: grub_apparmor\n    changed_when: False\n    when: grub_cfg_file.stat.exists\n    always_run: True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5.3 Check if the extlinux config file exists (Not Scored)\n    stat: path=/extlinux.conf\n    register: extlinux_cfg_file\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5.4 Determines if AppArmor is set in extlinux (Not Scored)\n    command: \"grep 'apparmor' /extlinux.conf\"\n    register: extlinux_apparmor\n    changed_when: False\n    when: extlinux_cfg_file.stat.exists\n    always_run: True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5.5 Determines if AppArmor is already set in boot config (Not Scored)\n    command: \"grep CONFIG_DEFAULT_SECURITY_APPARMOR /boot/config-{{ ansible_kernel }}\"\n    register: boot_apparmor\n    changed_when: False\n    always_run: True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5.6 Activate AppArmor (install) (Scored)\n    apt: >\n        name=apparmor\n        state=present\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5.7 Activate AppArmor (Kernel LSM - grub) (Scored)\n    lineinfile: >\n        dest='/etc/default/grub'\n        regexp='^GRUB_CMDLINE_LINUX=\"\"'\n        line='GRUB_CMDLINE_LINUX=apparmor=\"1 security=apparmor\"'\n        state=present\n    when: \"(use_apparmor == True) and grub_cfg_file.stat.exists and ('apparmor' not in grub_apparmor['stdout']) and ('not set' in boot_apparmor['stdout'])\"\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5.8 Activate AppArmor (Kernel LSM - extlinux) (Scored)\n    lineinfile: >\n        dest='/extlinux.conf'\n        regexp=\"^append initrd=\"\n        line=\"append initrd={{ ansible_cmdline['initrd'] }} root={{ ansible_cmdline['root'] }} console=tty0 console={{ ansible_cmdline['console'] }} apparmor=1 security=apparmor ro quiet\"\n    when: \"(use_apparmor == True) and extlinux_cfg_file.stat.exists and ('apparmor' not in extlinux_apparmor['stdout']) and ('not set' in boot_cfg_apparmor['stdout'])\"\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5.9 Activate AppArmor (start) (Scored)\n    service: >\n        name=apparmor\n        state=started\n    when: use_apparmor == True\n    register: apparmor_status\n    ignore_errors: True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5.10 Determine if AppArmor started without error (Not Scored)\n    fail: msg=\"Apparmor can not be started. This is normal behavior if you run the playbook for the first time.\\nPlease reboot the machine and run it again to proceed with the rest of the playbook.\"\n    when: apparmor_status.failed is defined\n\n  - name: 4.5.11 Fix rsyslog /run/utmp permissions (Not Scored)\n    lineinfile: >\n        dest=\"/etc/apparmor.d/usr.sbin.rsyslogd\"\n        line=\"  /run/utmp rk,\"\n        insertbefore=\"  /var/spool/rsyslog/ r,\"\n        state=present\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5.12 Activate AppArmor (fix profiles) (Scored)\n    service: >\n        name=rsyslog\n        state=restarted\n    changed_when: False\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5.13 Activate AppArmor (Scored)\n    command: apparmor_status\n    register: aa_status_lines\n    failed_when: '\"0 profiles are loaded\" in aa_status_lines.stdout_lines or \"0 processes are in complain mode.\" not in aa_status_lines.stdout_lines or \"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n        # - '\"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n    changed_when: False\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5.14 Activate AppArmor (enforce install) (Scored)\n    apt: >\n        name=apparmor-utils\n        state=present\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5.15 Activate AppArmor (enforce) (Scored)\n    #shell: 'aa-enforce /etc/apparmor.d/*'\n    shell: for profile in /etc/apparmor.d/*; do aa-enforce $profile; done\n    register: aaenforce_rc\n    failed_when: aaenforce_rc.rc == 1\n    changed_when: False\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n"}, {"commit_sha": "af3dfdf7cf37437f5609f1a12e4ac7cbaebd4867", "sha": "5296050789e8283020af0548bef391988f46d335", "filename": "roles/marathon/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for marathon\n- name: upload marathon template service\n  template:\n    src: marathon.conf.j2\n    dest: /etc/init/marathon.conf\n    mode: 0755\n  notify:\n    - restart marathon\n  sudo: yes\n  tags:\n    - marathon\n\n- name: set marathon hostname\n  sudo: yes\n  copy:\n    content: \"{{ marathon_hostname }}\"\n    dest: /etc/marathon/conf/hostname\n    mode: 0644\n  notify:\n    - restart marathon\n  tags:\n    - marathon\n\n- name: create marathon artifact store directory\n  file:\n    path: \"{{ marathon_artifact_store_dir }}\"\n    state: directory\n    mode: 0755\n  when: marathon_artifact_store_dir is defined\n  sudo: yes\n  notify:\n    - restart marathon\n  tags:\n    - marathon\n\n- name: set marathon artifact store\n  sudo: yes\n  copy:\n    content: \"{{ marathon_artifact_store }}\"\n    dest: /etc/marathon/conf/artifact_store\n    mode: 0644\n  notify:\n    - restart marathon\n  tags:\n    - marathon\n\n- name: remove marathon override\n  sudo: yes\n  file:\n    path: /etc/init/marathon.override\n    state: absent\n  notify:\n    - restart marathon\n  tags:\n    - marathon\n\n- name: install wait script\n  sudo: yes\n  template:\n    src: marathon-wait-for-listen.sh.j2\n    dest: /usr/local/bin/marathon-wait-for-listen.sh\n    mode: 0755\n  notify:\n    - restart marathon\n  tags:\n    - marathon\n\n- name: ensure marathon is running (and enable it at boot)\n  sudo: yes\n  service:\n    name: marathon\n    state: started\n    enabled: yes\n  notify:\n    - wait for marathon to listen\n  tags:\n    - marathon\n\n- meta: flush_handlers\n\n# This is here to workaround an issue where marathon does not receive an\n# acknowledgement correctly from Mesos.\n- name: force restart marathon\n  sudo: yes\n  service:\n    name: marathon\n    state: restarted\n  notify:\n    - wait for marathon to listen\n  tags:\n    - marathon\n\n- meta: flush_handlers\n\n- name: set marathon consul service definition\n  sudo: yes\n  template:\n    src: marathon-consul.j2\n    dest: \"{{ consul_dir }}/marathon.json\"\n  notify:\n    - restart consul\n  tags:\n    - marathon\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "c96cc8d57c53bf9253caa09070624ff5374413af", "filename": "tasks/section_02_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 2.1 Create Separate Partition for /tmp (Scored)\n    command: grep '\\s/tmp\\s' /etc/fstab\n    register: tmp_partition\n    when: partitioning == True\n    failed_when: tmp_partition.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section2\n      - section2.1\n\n  - name: 2.2 - 4 Set nodev, nosuid, noexec option for /tmp Partition (Scored)\n    mount: name=\"/tmp\" src=\"/tmp\" state=\"mounted\" opts=\"nodev,nosuid,noexec\" fstype=ext4\n    when: partitioning == True\n    tags:\n      - section2\n      - section2.2\n      - section2.3\n      - section2.4\n\n  - name: 2.5 Create Separate Partition for /var (Scored)\n    command: grep '\\s/var\\s' /etc/fstab\n    when: partitioning == True\n    register: var_partition\n    failed_when: var_partition.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section2\n      - section2.5\n\n  - name: 2.6 Bind Mount the /var/tmp directory to /tmp (Scored)\n    mount: name=\"/var/tmp\" src=\"/tmp\" opts=bind state=mounted fstype=ext4\n    when: partitioning == True\n    tags:\n      - section2\n      - section2.6\n\n  - name: 2.7 Create Separate Partition for /var/log (Scored)\n    command: grep '\\s/var\\/log\\s' /etc/fstab\n    when: partitioning == True\n    register: var_log_partition\n    failed_when: var_log_partition.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section2\n      - section2.7\n\n  - name: 2.8 Create Separate Partition for /var/log/audit (Scored)\n    command: grep '\\s/var\\/log\\/audit\\s' /etc/fstab\n    when: partitioning == True\n    register: var_log_audit_partition\n    failed_when: var_log_audit_partition.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section2\n      - section2.8\n\n  - name: 2.9 Create Separate Partition for /home (Scored)\n    command: grep '\\s/home\\s' /etc/fstab\n    when: partitioning == True\n    register: home_partition\n    failed_when: home_partition.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section2\n      - section2.9\n\n  - name: 2.10 Add nodev Option to /home (Scored)\n    mount: name=\"/home\" src=\"/home\" state=mounted opts=remount,nodev fstype=\"ext4\"\n    when: partitioning == True\n    tags:\n      - section2\n      - section2.10\n\n  - name: 2.11 Add nodev Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nodev option\"\n    tags:\n      - section2\n      - section2.11\n\n  - name: 2.12 Add noexec Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have noexec option\"\n    tags:\n      - section2\n      - section2.12\n\n  - name: 2.13 Add nosuid Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nosuid option\"\n    tags:\n      - section2\n      - section2.13\n\n  - name: 2.14 - 16 Add nodev Option to /run/shm Partition (Scored)\n    mount: name=\"/run/shm\" src=\"/run/shm\" state=\"mounted\" opts=\"nodev,nosuid,noexec\" fstype=\"tmpfs\"\n    when: run_shm_read_only == False\n    tags:\n      - section2\n      - section2.14\n      - section2.15\n      - section2.16\n\n  - name: 2.17.1 Set Sticky Bit on All World-Writable Directories (check) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type d -perm -0002 -print 2>/dev/null\n    failed_when: False\n    changed_when: False\n    always_run: True\n    register: sticky_bit_dirs\n    tags:\n      - section2\n      - section2.17\n\n  - name: 2.17.2 Set Sticky Bit on All World-Writable Directories (Scored)\n    file:\n        path: \"{{ item }}\"\n        mode: \"a+t\"\n    with_items: \"{{sticky_bit_dirs.stdout_lines}}\"\n    tags:\n      - section2\n      - section2.17\n\n  - name: 2.25.1 Disable Automounting (check) (Scored)\n    stat: >\n        path=/etc/init/autofs.conf\n    register: autofs_file\n    tags:\n      - section2\n      - section2.25\n      \n  - name: 2.25.2 Disable Automounting (Scored)\n    lineinfile: >\n        dest=/etc/init/autofs.conf\n        line='#start on runlevel [2345]'\n        regexp='start on runlevel'\n        state=present\n    when: autofs_file.stat.exists == True\n    tags:\n      - section2\n      - section2.25\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "ac43644b4ddd0e7a3aa4f1cf9f0bb7dce0ae8094", "filename": "roles/st2/handlers/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "- name: restart st2\n  sudo: true\n  command: \"{{ item }}\"\n  with_items:\n    - st2ctl reload --register-all\n    - st2ctl restart\n\n- name: restart st2api/st2stream\n  sudo: true\n  command: \"st2ctl restart-component {{ item }}\"\n  with_items:\n    - st2api\n    - st2stream\n"}, {"commit_sha": "35ca6852d9333ef6c3ed223239f45b840c487d60", "sha": "5c30e313d97a8854a60589f89dec8df5752acc1e", "filename": "roles/zookeeper/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for zookeeper\nzookeeper_client_port: 2181\nzookeeper_leader_connect_port: 2888\nzookeeper_leader_election_port: 3888\nzookeeper_server_group: zookeeper_servers\nzookeeper_id: \"\n    {%- for host in groups[zookeeper_server_group] -%}\n      {%- if host == 'default' or host == inventory_hostname or host == ansible_fqdn or host in ansible_all_ipv4_addresses -%}\n        {{ loop.index }}\n      {%- endif -%}\n    {%- endfor -%}\n\"\nconsul_dir: /etc/consul.d\n"}, {"commit_sha": "af3dfdf7cf37437f5609f1a12e4ac7cbaebd4867", "sha": "f9433a9c086c1d9e8aa0786824cccb346eba0b9a", "filename": "roles/mesos/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "# used for leader election amongst masters\n- name: Set ZooKeeper URL\n  template:\n    src: zk.j2\n    dest: /etc/mesos/zk\n    mode: 0644\n  sudo: yes\n\n# Tasks for Master nodes\n- name: Set Mesos Master ip\n  copy:\n    content: \"{{ mesos_ip }}\"\n    dest: /etc/mesos-master/ip\n    mode: 0644\n  sudo: yes\n  notify:\n    - restart mesos master\n  when: mesos_install_mode == \"master\"\n\n- name: Set Mesos Master hostname\n  copy:\n    content: \"{{ mesos_hostname }}\"\n    dest: /etc/mesos-master/hostname\n    mode: 0644\n  sudo: yes\n  notify:\n    - restart mesos master\n  when: mesos_install_mode == \"master\"\n\n  # The Mesos quorum value is based on the number of Mesos Masters. Take the\n  # number of masters, divide by 2, and round-up to nearest integer. For example,\n  # if there are 1 or 2 masters the quorum count is 1. If there are 3 or 4\n  # masters then the quorum count is 2. For 5 or 6 masters it's 3 and so on.\n- name: Set Mesos Master quorum count\n  template:\n    src: quorum.j2\n    dest: /etc/mesos-master/quorum\n    mode: 0644\n  sudo: yes\n  notify:\n    - restart mesos master\n  when: mesos_install_mode == \"master\"\n\n- name: Set Mesos Master Cluster name\n  copy:\n    content: \"{{ mesos_cluster_name }}\"\n    dest: /etc/mesos-master/cluster\n    mode: 0644\n  sudo: yes\n  notify:\n    - restart mesos master\n  when: mesos_install_mode == \"master\"\n\n- name: Set Mesos Master consul service definition\n  sudo: yes\n  template:\n    src: mesos-master-consul.j2\n    dest: \"{{ consul_dir }}/mesos-master.json\"\n  notify:\n    - restart consul\n  when: mesos_install_mode == \"master\"\n\n- name: remove mesos-master override\n  file:\n    path: /etc/init/mesos-master.override\n    state: absent\n  notify:\n    - restart mesos master\n  when: mesos_install_mode == \"master\"\n\n- name: start mesos-master (and enable it at boot)\n  service:\n    name: mesos-master\n    state: started\n    enabled: yes\n  when: mesos_install_mode == \"master\"\n\n# Tasks for Slave nodes\n- name: remove mesos-slave override\n  file:\n    path: /etc/init/mesos-slave.override\n    state: absent\n  notify:\n    - restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: Set Mesos Slave hostname\n  copy:\n    content: \"{{ mesos_hostname }}\"\n    dest: /etc/mesos-slave/hostname\n    mode: 0644\n  sudo: yes\n  notify:\n    - restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: set executor registration timeout\n  sudo: yes\n  copy:\n    dest: /etc/mesos-slave/executor_registration_timeout\n    content: \"{{ mesos_executor_registration_timeout }}\"\n  notify:\n    - restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: set containerizers\n  sudo: yes\n  copy:\n    dest: /etc/mesos-slave/containerizers\n    content: \"{{ mesos_containerizers }}\"\n  notify:\n    - restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: set slave resources\n  sudo: yes\n  copy:\n    dest: /etc/mesos-slave/resources\n    content: \"{{ mesos_resources }}\"\n  notify:\n    - restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: Set Mesos Slave ip\n  copy:\n    content: \"{{ mesos_ip }}\"\n    dest: /etc/mesos-slave/ip\n    mode: 0644\n  sudo: yes\n  notify:\n    - restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: Create Mesos Slave work area\n  file:\n    dest: \"{{ mesos_slave_work_dir }}\"\n    mode: 0755\n    state: directory\n  sudo: yes\n  notify:\n    - restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: Set Mesos Slave work area\n  copy:\n    content: \"{{ mesos_slave_work_dir }}\"\n    dest: /etc/mesos-slave/work_dir\n    mode: 0644\n  sudo: yes\n  notify:\n    - restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: start mesos-slave (and enable it at boot)\n  service:\n    name: mesos-slave\n    state: started\n    enabled: yes\n  when: mesos_install_mode == \"slave\"\n\n- meta: flush_handlers\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "788b322b823a2f1bc195d3a527a6f0b989fb6273", "filename": "roles/dcos_cli/tasks/frameworks.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for frameworks\n- include_vars: \"{{ item }}.yml\"\n  with_items:\n    - \"{{ dcos_cli_frameworks_list }}\"\n\n- name: create config directory\n  when: \"dcos_cli_framework_{{ item }}_enabled | bool\"\n  run_once: true\n  template:\n    src: \"{{ item }}-config.j2\"\n    dest: \"/tmp/{{ item }}-config\"\n    mode: 0755\n  sudo: yes\n  tags:\n    - \"{{ item }}\"\n  with_items:\n    - \"{{ dcos_cli_frameworks_list }}\"\n\n- name: install dcos-cli package\n  when: \"dcos_cli_framework_{{ item }}_enabled | bool\"\n  run_once: true\n  docker:\n    name: \"{{ item }}\"\n    image: \"{{ dcos_cli_image }}\"\n    state: started\n    command: \"package install --options=/config --yes {{ item }}\"\n    volumes:\n    - \"/tmp/{{ item }}-config:/config\"\n    env:\n      MESOS_MASTER_URL: \"{{ dcos_cli_mesos_master_url }}\"\n      MARATHON_URL: \"{{ dcos_cli_marathon_url }}\"\n      SOURCES: \"{{ dcos_cli_sources }}\"\n  tags:\n    - \"{{ item }}\"\n  with_items:\n    - \"{{ dcos_cli_frameworks_list }}\"\n\n- name: uninstall dcos-cli package\n  when: \"not dcos_cli_framework_{{ item }}_enabled | bool\"\n  run_once: true\n  docker:\n    name: \"{{ item }}\"\n    image: \"{{ dcos_cli_image }}\"\n    state: started\n    command: \"package uninstall {{ item }}\"\n    env:\n      MESOS_MASTER_URL: \"{{ dcos_cli_mesos_master_url }}\"\n      MARATHON_URL: \"{{ dcos_cli_marathon_url }}\"\n  tags:\n    - \"{{ item }}\"\n  with_items:\n    - \"{{ dcos_cli_frameworks_list }}\"\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "665e710bdbf2363c365035a76e691311008dc21b", "filename": "roles/docker/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for docker\ndocker_graph_dir: /var/lib/docker\ndocker_tmp_dir: /var/lib/docker/tmp"}, {"commit_sha": "9eb1a8fa8e281ef06687c1851f51fa0beec3e232", "sha": "35c727eeca7606195c62106b864875b5cf2e9d37", "filename": "tasks/section_08_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n# Change order or the default auditd.conf file will not be created\n  - name: 8.1.2 Install and Enable auditd Service (Scored)\n    apt: name=auditd state=present\n    tags:\n      - section8\n      - section8.1\n      - section8.1.2\n      - section8.1.2\n\n  - name: Check if the file auditd.conf exists (Not Scored)\n    stat: >\n        path=/etc/audit/auditd.conf\n    register: auditd_file\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n\n  - name: Create the audit directory if it does not exists (Not Scored)\n    file: >\n        path=/etc/audit/\n        state=directory\n    when: not auditd_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n\n  - name: 8.1.1-3 Configure Data Retention (Not Scored)\n    lineinfile: >\n        dest=/etc/audit/auditd.conf\n        regexp=\"{{ item.rxp }}\"\n        line=\"{{ item.line }}\"\n        state=present\n        create=yes\n    with_items:\n      - { rxp: '^max_log_file ', line: 'max_log_file = {{ max_log_file_auditd }}' }\n      - { rxp: '^space_left_action', line: 'space_left_action = email' }\n      - { rxp: '^action_mail_acct', line: 'action_mail_acct = root' }\n      - { rxp: '^admin_space_left_action', line: 'admin_space_left_action = halt' }\n      - { rxp: '^max_log_file_action', line: 'max_log_file_action = keep_logs' }\n    notify: restart auditd\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n      - section8.1.1.2\n      - section8.1.1.3\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    stat: path=/etc/default/grub\n    register: grubcfg_file\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    file: >\n        path=/etc/default/grub\n        state=touch\n    when: not grubcfg_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    lineinfile: >\n        dest=/etc/default/grub\n        line='GRUB_CMDLINE_LINUX=\"audit=1\"'\n    when: not grubcfg_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.4 Record Events That Modify Date and Time Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a always,exit -F arch=b64 -S adjtimex -S settimeofday -k time-change'\n      - '-a always,exit -F arch=b32 -S adjtimex -S settimeofday -S stime -k time-change'\n      - '-a always,exit -F arch=b64 -S clock_settime -k time-change'\n      - '-a always,exit -F arch=b32 -S clock_settime -k time-change'\n      - '-w /etc/localtime -p wa -k time-change'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"64\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.4\n\n  - name: 8.1.4 Record Events That Modify Date and Time Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a always,exit -F arch=b32 -S adjtimex -S settimeofday -S stime -k time-change'\n      - '-a always,exit -F arch=b32 -S clock_settime -k time-change'\n      - '-w /etc/localtime -p wa -k time-change'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"32\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.4\n\n  - name: 8.1.5,7,8,9,15,16,17 Record Events That Modify User/Group Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-w /etc/group -p wa -k identity'\n      - '-w /etc/passwd -p wa -k identity'\n      - '-w /etc/gshadow -p wa -k identity'\n      - '-w /etc/shadow -p wa -k identity'\n      - '-w /etc/security/opasswd -p wa -k identity'\n      - '-w /var/log/faillog -p wa -k logins'\n      - '-w /var/log/lastlog -p wa -k logins'\n      - '-w /var/log/tallylog -p wa -k logins'\n      - '-w /var/run/utmp -p wa -k session'\n      - '-w /var/log/wtmp -p wa -k session'\n      - '-w /var/log/btmp -p wa -k session'\n      - '-w /etc/selinux/ -p wa -k MAC-policy'\n      - '-w /etc/sudoers -p wa -k scope'\n      - '-w /var/log/sudo.log -p wa -k actions'\n      - '-w /sbin/insmod -p x -k modules'\n      - '-w /sbin/rmmod -px -k modules'\n      - '-w /sbin/modprobe -p x -k modules'\n    notify: restart auditd\n    tags:\n      - section8\n      - section8.1\n      - section8.1.5\n      - section8.1.7\n      - section8.1.8\n      - section8.1.9\n      - section8.1.15\n      - section8.1.16\n      - section8.1.17\n\n  - name: 8.1.6,10,11,13,14,17 Record Events That Modify the System's Network Environment (64b) (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a exit,always -F arch=b64 -S sethostname -S setdomainname -k system-locale'\n      - '-a exit,always -F arch=b32 -S sethostname -S setdomainname -k system-locale'\n      - '-w /etc/issue -p wa -k system-locale'\n      - '-w /etc/issue.net -p wa -k system-locale'\n      - '-w /etc/hosts -p wa -k system-locale'\n      - '-w /etc/network -p wa -k system-locale'\n      - '-a always,exit -F arch=b64 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b64 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b64 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b32 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b64 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b32 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b64 -S init_module -S delete_module -k modules'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"64\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.6\n      - section8.1.10\n      - section8.1.11\n      - section8.1.13\n      - section8.1.14\n      - section8.1.17\n\n  - name: 8.1.6,10,11,13,14,17 Record Events That Modify the System's Network Environment (32b) (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a exit,always -F arch=b32 -S sethostname -S setdomainname -k system-locale'\n      - '-w /etc/issue -p wa -k system-locale'\n      - '-w /etc/issue.net -p wa -k system-locale'\n      - '-w /etc/hosts -p wa -k system-locale'\n      - '-w /etc/network -p wa -k system-locale'\n      - '-a always,exit -F arch=b32 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b32 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b32 -S init_module -S delete_module -k modules'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"32\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.6\n      - section8.1.10\n      - section8.1.11\n      - section8.1.13\n      - section8.1.14\n      - section8.1.17\n\n  - name: 8.3.1 Install AIDE (Scored)\n    apt: name=aide state=present\n    register: aide_installed\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (init) (Scored)\n    command: aideinit\n    when: aide_installed.changed == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (Scored)\n    stat: path=/var/lib/aide/aide.db.new\n    register: aide_db_path\n    when:\n      - aide_installed.changed == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (copy db) (Scored)\n    command: mv /var/lib/aide/aide.db.new /var/lib/aide/aide.db\n    when:\n      - aide_installed.changed == True\n      - aide_db_path.stat.exists == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.2 Implement Periodic Execution of File Integrity (Scored)\n    cron: name=\"Check files integrity\" minute=\"0\" hour=\"5\" job=\"/usr/sbin/aide --check\"\n    tags:\n      - section8\n      - section8.3\n      - section8.3.2\n\n  # We have to run the check after AIDE installation as postfix create new matched binaries\n  - name: 8.1.12 Collect Use of Privileged Commands (Scored)\n    shell: find / -xdev \\( -perm -4000 -o -perm -2000 \\) -type f | awk '{print \"-a always,exit -F path=\" $1 \" -F perm=x -F auid>=500 -F auid!=4294967295 -k privileged\" }'\n    register: audit_lines_for_find\n    changed_when: False\n    tags:\n      - section8\n      - section8.1\n      - section8.1.12\n\n  - name: 8.1.12 Collect Use of Privileged Commands (infos) (Scored)\n    lineinfile: >\n        dest=/etc/audit/audit.rules\n        line='{{ item }}'\n        state=present\n        create=yes\n    with_items: audit_lines_for_find.stdout_lines\n    tags:\n      - section8\n      - section8.1\n      - section8.1.12\n\n  - name: 8.1.18 Make the Audit Configuration Immutable (Scored)\n    lineinfile: >\n        dest='/etc/audit/audit.rules'\n        line='-e 2'\n        insertafter=EOF\n        state=present\n        create=yes\n    tags:\n      - section8\n      - section8.1\n      - section8.1.18\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "bfd26caf7ab11c290c6671bcab11bc5bd4a1b046", "filename": "handlers/main.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: restart auditd\n    service: name=auditd state=restarted\n    changed_when: False\n    ignore_errors: True\n\n  - name: restart rsyslog\n    service: name=rsyslog state=restarted\n    changed_when: False\n    ignore_errors: True\n\n  - name: restart ssh\n    service: name=ssh state=restarted\n    changed_when: False\n    ignore_errors: True\n"}, {"commit_sha": "a774d7f239841cdb705317557a11935ca87238ad", "sha": "dbc41cfae5a13d69813f189085f9705636204791", "filename": "tasks/section_09_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 9.1.1.1 Check that cron conf file exists (check) (Scored)\n    stat: path=/etc/init/cron.conf\n    register: cron_conf_stat\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.1\n\n  - name: 9.1.1.2 Enable cron Daemon (Scored)\n    lineinfile: >\n        dest='/etc/init/cron.conf'\n        line='start on runlevel [2345]'\n        state=present\n    when: not cron_conf_stat.stat.exists\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.2\n\n  - name: 9.1.2 Set User/Group Owner and Permission on /etc/crontab (Scored)\n    file: path='/etc/crontab' owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.2\n\n  - name: 9.1.3 Set User/Group Owner and Permission on /etc/cron.hourly (Scored)\n    file: path=/etc/cron.hourly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.3\n\n  - name: 9.1.4 Set User/Group Owner and Permission on /etc/cron.daily (Scored)\n    file: path=/etc/cron.daily owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.4\n\n  - name: 9.1.5 Set User/Group Owner and Permission on /etc/cron.weekly(Scored)\n    file: path=/etc/cron.weekly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.5\n\n  - name: 9.1.6 Set User/Group Owner and Permission on /etc/cron.monthly(Scored)\n    file: path=/etc/cron.monthly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.6\n\n  - name: 9.1.7 Set User/Group Owner and Permission on /etc/cron.d (Scored)\n    file: path=/etc/cron.d owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.7\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (Scored)\n    file: path={{ item }} state=absent\n    with_items:\n        - /etc/cron.deny\n        - /etc/at.deny\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n  \n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    stat: path=/etc/cron.allow\n    register: cron_allow_path\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    shell: touch /etc/cron.allow\n    when: cron_allow_path.stat.exists == False\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (Scored)\n    file: path=/etc/cron.allow owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    stat: path=/etc/at.allow\n    register: at_allow_path\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    shell: touch /etc/at.allow\n    when: at_allow_path.stat.exists == False\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (Scored)\n    file: path=/etc/at.allow owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n \n  - name: 9.2.1 Set Password Creation Requirement Parameters Usingpam_cracklib (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password'\n        regexp=\"pam_cracklib.so\"\n        line=\"password required pam_cracklib.so retry=3 minlen=14 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.1\n\n#Note for section 9.2.2:\n#If a user has been locked out because they have reached the maximum consecutive failure count \n#defined by denied= in the pam_tally2.so module, the user can be unlocked by issuing the command\n#/sbin/pam_tally2 -u username --reset\n#This command sets the failed count to 0, effectively unlocking the user\n  - name: 9.2.2 Set Lockout for Failed Password Attempts (Not Scored)\n    lineinfile: >\n        dest='/etc/pam.d/login' \n        regexp='pam_tally2'\n        line=\"auth required pam_tally2.so onerr=fail audit silent deny=5 unlock_time=900\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.2\n\n  - name: 9.2.3 Limit Password Reuse (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password' \n        regexp='remember=5'\n        line=\"password sufficient pam_unix.so remember=5\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.3\n\n  - name: 9.3 Check if ssh is installed (check)\n    stat: path='/etc/ssh/sshd_config'\n    register: ssh_config_file\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n\n  - name: 9.3.1 Set SSH Protocol to 2 (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config' \n        regexp='^Protocol'\n        state=present\n        line='Protocol 2'\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n  - name: 9.3.2 Set LogLevel to INFO (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config' \n        regexp='^LogLevel'\n        state=present\n        line='LogLevel INFO'\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.2\n\n  - name: 9.3.3 Set Permissions on /etc/ssh/sshd_config (Scored)\n    file: path='/etc/ssh/sshd_config' owner=root group=root mode=600\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.3\n\n#Regroups sections 9.3.4 9.3.7 9.3.8 9.3.9 9.3.10\n  - name: 9.3.{4,7,8,9,10} Disable some SSH options (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^{{ item }}'\n        line='{{ item }} no'\n        state=present\n    with_items: \n      - X11Forwarding\n      - HostbasedAuthentication\n      - PermitRootLogin\n      - PermitEmptyPasswords\n      - PermitUserEnvironment\n    tags:\n      - section9\n      - section9.3\n      - section9.3.4\n      - section9.3.7\n      - section9.3.8\n      - section9.3.9\n      - section9.3.10\n\n  - name: 9.3.5 Set SSH MaxAuthTries to 4 or Less (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^MaxAuthTries'\n        line='MaxAuthTries 4'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.5\n\n  - name: 9.3.6 Set SSH IgnoreRhosts to Yes (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^IgnoreRhosts'\n        line='IgnoreRhosts yes'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.6\n\n  - name: 9.3.11 Use Only Approved Cipher in Counter Mode (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Ciphers'\n        line='Ciphers aes128-ctr,aes192-ctr,aes256-ctr'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.11\n\n  - name: 9.3.12.1 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveInterval'\n        line='ClientAliveInterval 300'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.1\n\n  - name: 9.3.12.2 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveCountMax'\n        line='ClientAliveCountMax 0'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.2\n\n  - name: 9.3.13.1 Limit Access via SSH (Scored)\n    shell: grep AllowUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.1\n\n  - name: 9.3.13.2 Limit Access via SSH (Scored)\n    shell: grep AllowGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.2\n\n  - name: 9.3.13.3 Limit Access via SSH (Scored)\n    shell: grep DenyUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.3\n\n  - name: 9.3.13.4 Limit Access via SSH (Scored)\n    shell: grep DenyGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.4\n\n  - name: 9.3.14 Set SSH Banner (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Banner'\n        line='Banner /etc/issue.net'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.14\n\n  - name: 9.4 Restrict root Login to System Console (Not Scored)\n    stat: path=/etc/securetty\n    register: securetty_file\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.4 Restrict root Login to System Console (Not Scored)\n    debug: msg='*** Check /etc/securetty for console allowed for root access ***'\n    when: securetty_file.stat.exists == True\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.5.1 Restrict Access to the su Command (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/su'\n        line='auth            required        pam_wheel.so use_uid'\n        state=present\n    tags:\n      - section9\n      - section9.5\n      - section9.5.1\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "a3ac9c29ffc69b474e6707774f675767f295f727", "filename": "tasks/install_windows.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# File: install_remote.yml - package installation tasks for Consul\n\n- name: Validate remote Consul directory\n  win_file:\n    path: /tmp/consul\n    state: directory\n\n- name: Verify TLS1.2 is used\n  win_regedit:\n    path: HKLM:\\SOFTWARE\\Microsoft\\.NETFramework\\v4.0.30319\n    name: SchUseStrongCrypto\n    data: 1\n    type: dword\n\n- name: Read Consul package checksum file\n  win_stat:\n    path: \"/tmp/consul/consul_{{ consul_version }}_SHA256SUMS\"\n  register: consul_checksum\n  tags: installation\n\n- name: Download Consul package checksum file\n  win_get_url:\n    url: \"{{ consul_checksum_file_url }}\"\n    dest: \"/tmp/consul/consul_{{ consul_version }}_SHA256SUMS\"\n  tags: installation\n  when: not consul_checksum.stat.exists | bool\n\n- name: Read Consul package checksum\n  win_shell: \"findstr {{ consul_pkg }} /tmp/consul/consul_{{ consul_version }}_SHA256SUMS\"\n  args:\n    chdir: /tmp/consul\n  register: consul_pkg_checksum\n  tags: installation\n\n- name: Download Consul\n  win_get_url:\n    url: \"{{ consul_zip_url }}\"\n    dest: \"/tmp/consul/{{ consul_pkg }}\"\n  tags: installation\n\n- name: Calculate checksum\n  win_stat:\n    path: \"/tmp/consul/{{ consul_pkg }}\"\n    checksum_algorithm: sha256\n  register: consul_pkg_hash\n  tags: installation\n\n- name: Compare checksum to hashfile\n  fail:\n    msg: \"Checksum {{ consul_pkg_checksum.stdout.split(' ') | first }} did not match calculated SHA256 {{ consul_pkg_hash.stat.checksum }}!\"\n  when:\n    - consul_pkg_hash.stat.checksum != (consul_pkg_checksum.stdout.split(' ') | first)\n\n- name: Unarchive Consul and install binary\n  win_unzip:\n    src: \"/tmp/consul/{{ consul_pkg }}\"\n    dest: \"{{ consul_bin_path }}\"\n  tags: installation\n\n- name: Cleanup\n  win_file:\n    path: \"/tmp/consul\"\n    state: absent\n  tags: installation\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "36a968ff7377f794914e6debd617e30779dc0106", "filename": "roles/prometheus/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "# tasks for running prometheus\n- name: create prometheus config dir\n  file:\n    path: \"{{ prometheus_config_dir }}\"\n    state: directory\n    mode: 0755\n  sudo: yes\n  tags:\n    - prometheus\n\n- name: upload prometheus config file\n  template:\n    src: prometheus.yml.j2\n    dest: \"{{ prometheus_config_dir }}/prometheus.yml\"\n    mode: 0755\n  sudo: yes\n  tags:\n    - prometheus\n\n- name: run prometheus node exporter container\n  docker:\n    name: node-exporter\n    image: \"{{ prometheus_node_exporter_image }}\"\n    state: started\n    restart_policy: always\n    net: host\n    ports:\n    - \"{{ prometheus_node_exporter_port }}:{{ prometheus_node_exporter_port }}\"\n  environment: proxy_env\n  tags:\n    - prometheus\n\n- name: Set node-exporter consul service definition\n  sudo: yes\n  template:\n    src: node-exporter-consul.j2\n    dest: \"{{ prometheus_consul_dir }}/node-exporter.json\"\n  notify:\n    - restart consul\n  tags:\n    - prometheus\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "1deacc3ec3bdd440336d9d7676f550069d0493aa", "filename": "tasks/tls.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# File: tls.yml - TLS tasks for Consul\n\n- name: Create SSL directory\n  file:\n    dest: \"{{ consul_tls_dir }}\"\n    state: directory\n    owner: \"{{ consul_user }}\"\n    group: \"{{ consul_group }}\"\n    mode: 0755\n\n- block:\n    - name: Copy CA certificate\n      copy:\n        remote_src: \"{{ consul_tls_files_remote_src }}\"\n        src: \"{{ consul_tls_src_files }}/{{ consul_tls_ca_crt | basename }}\"\n        dest: \"{{ consul_tls_dir }}/{{ consul_tls_ca_crt }}\"\n        owner: \"{{ consul_user }}\"\n        group: \"{{ consul_group }}\"\n        mode: 0644\n      notify: restart consul\n\n    - name: Copy server certificate\n      copy:\n        remote_src: \"{{ consul_tls_files_remote_src }}\"\n        src: \"{{ consul_tls_src_files }}/{{ consul_tls_server_crt | basename }}\"\n        dest: \"{{ consul_tls_dir }}/{{ consul_tls_server_crt }}\"\n        owner: \"{{ consul_user }}\"\n        group: \"{{ consul_group }}\"\n        mode: 0644\n      notify: restart consul\n\n    - name: Copy server key\n      copy:\n        remote_src: \"{{ consul_tls_files_remote_src }}\"\n        src: \"{{ consul_tls_src_files }}/{{ consul_server_key | basename }}\"\n        dest: \"{{ consul_tls_dir }}/{{ consul_server_key }}\"\n        owner: \"{{ consul_user }}\"\n        group: \"{{ consul_group }}\"\n        mode: 0600\n      notify: restart consul\n\n  when: consul_tls_copy_keys | bool\n"}, {"commit_sha": "12d2d30c292e5749809cd7476458762a4de31554", "sha": "6521ef0c310ad497a047a432a94cc0b6a795eb9b", "filename": "tasks/freebsd_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Setup FreeBSD specific variables (set_fact)\n  set_fact:\n    tor_DataDir: /var/db/tor\n    tor_ConfDir: /usr/local/etc/tor/enabled\n  tags: configure\n\n- name: Ensure Tor is installed (FreeBSD)\n  sudo: yes\n  pkgng: name=tor state=present\n  when: tor_alpha == False\n\n# pkg will take care of removing tor stable\n# if installed\n- name: Ensure Tor alpha is installed (FreeBSD)\n  sudo: yes\n  pkgng: name=tor-devel state=present\n  when: tor_alpha == True\n\n# temporary solution until rc.d supports multiple instances\n- name: Ensure Tor starts at boot (FreeBSD)\n  sudo: yes\n  lineinfile: dest=/etc/rc.local line=\"/usr/local/bin/tor -f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\" create=yes\n  with_nested:\n   - tor_ips\n   - tor_ports\n\n- name: If LogDir is a file, rename it (FreeBSD)\n  sudo: yes\n  shell: \"test -f {{ tor_LogDir }} && mv {{ tor_LogDir }} {{ tor_LogDir }}.bk-`date '+%Y-%m-%d_%H%M%S'`\"\n  ignore_errors: yes\n"}, {"commit_sha": "1bb50a6149f6ff7f2e6399411418d088e2c52d01", "sha": "c630b20e31dc3b0b6daf661d940903e2a572c6df", "filename": "tasks/section_13_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 13.1 Ensure Password Fields are Not Empty (Scored)\n    command: awk -F':' '($2 == \"\" ) { print $1 }' /etc/shadow\n    register: awk_empty_shadow\n    changed_when: False\n    failed_when: awk_empty_shadow.stdout != '' and not lock_shadow_accounts\n    tags:\n      - section13\n      - section13.1\n\n  - name: 13.1 Ensure Password Fields are Not Empty (locking accounts) (Scored)\n    command: passwd -l '{{ item }}'\n    with_items:\n        awk_empty_shadow.stdout_lines\n    when: lock_shadow_accounts\n    tags:\n      - section13\n      - section13.1\n\n  - name: 13.2 Verify No Legacy \"+\" Entries Exist in /etc/passwd File (Scored)\n    command: grep '^+:' /etc/passwd\n    register: plus_pass\n    failed_when: plus_pass.rc == 0\n    changed_when: plus_pass.rc == 0\n    tags:\n      - section13\n      - section13.2\n\n  - name: 13.3 Verify No Legacy \"+\" Entries Exist in /etc/shadow File (Scored)\n    command: grep '^+:' /etc/shadow\n    register: plus_shadow\n    failed_when: plus_shadow.rc == 0\n    changed_when: plus_shadow.rc == 0\n    tags:\n      - section13\n      - section13.3\n\n  - name: 13.4 Verify No Legacy \"+\" Entries Exist in /etc/group File (Scored)\n    command: grep '^+:' /etc/group\n    register: plus_group\n    failed_when: plus_group.rc == 0\n    changed_when: plus_group.rc == 0\n    tags:\n      - section13\n      - section13.4\n\n  - name: 13.5 Verify No UID 0 Accounts Exist Other Than root (Scored)\n    command: awk -F':' '($3 == 0) { print $1 }' /etc/passwd\n    register: uid_zero_root\n    changed_when: False\n    failed_when: uid_zero_root.stdout != 'root'\n    tags:\n      - section13\n      - section13.5\n\n  - name: 13.6.1 Ensure root PATH Integrity (empty value) (Scored)\n    shell: 'echo $PATH | grep ::'\n    register: path_colon\n    changed_when: False\n    failed_when: path_colon.rc == 0\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.2 Ensure root PATH Integrity (colon end) (Scored)\n    shell: 'echo $PATH | grep :$'\n    register: path_colon_end\n    changed_when: False\n    failed_when: path_colon_end.rc == 0\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.3 Ensure root PATH Integrity (dot in path) (Scored)\n    shell: \"echo $PATH | sed -e 's/::/:/' -e 's/:$//' -e 's/:/\\\\n/g'\"\n    register: dot_in_path\n    changed_when: False\n    failed_when: '\".\" in dot_in_path.stdout_lines'\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.4 Ensure root PATH Integrity (Scored)\n    file: >\n        path='{{ item }}'\n        state=directory\n        owner=root\n        mode='o-w,g-w'\n    with_items:\n        dot_in_path.stdout_lines\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.7.1 Check Permissions on User Home Directories (gather users) (Scored)\n    shell: /bin/egrep -v '(root|halt|sync|shutdown|false)' /etc/passwd | /usr/bin/awk -F':' '($7 != \"/usr/sbin/nologin\") { print $6 }'\n    register: home_users\n    changed_when: False\n    failed_when: False\n    tags:\n      - section13\n      - section13.7\n\n  - name: 13.7.2 Check Permissions on User Home Directories (Scored)\n    file: >\n        path='{{ item }}'\n        mode='g-w,o-rwx'\n        state=directory\n    with_items:\n        home_users.stdout_lines\n    when: modify_user_homes == True\n    tags:\n      - section13\n      - section13.7\n\n  - name: 13.8.1 Check User Dot File Permissions (gather dotfiles) (Scored)\n    shell: for pth in `/bin/egrep -v '(root|halt|sync|shutdown)' /etc/passwd | /usr/bin/awk -F':' '($7 != \"/usr/sbin/nologin\") { print $6 }'`; do ls -d -A -1 $pth/.* | egrep -v '[..]$'; done\n    changed_when: False\n    failed_when: False\n    always_run: True\n    register: home_dot_files\n    tags:\n      - section13\n      - section13.8\n\n  - name: 13.8.2 Check User Dot File Permissions (Scored)\n    file: >\n        path='{{ item }}'\n        mode='o-w,g-w'\n    with_items:\n        home_dot_files.stdout_lines\n    tags:\n      - section13\n      - section13.8\n\n  - name: 13.9 Check Permissions on User .netrc Files (Scored)\n    file: >\n        path='{{ item }}/.netrc'\n        mode='g-rwx,o-rwx'\n        recurse=yes\n        state=directory\n    with_items:\n        home_users.stdout_lines\n    tags:\n      - section13\n      - section13.9\n\n  - name: 13.10 Check for Presence of User .rhosts Files (Scored)\n    file: >\n        state=absent\n        path='{{ item }}/.rhosts'\n    with_items:\n        home_users.stdout_lines\n    tags:\n      - section13\n      - section13.10\n\n  - name: 13.11 Check Groups in /etc/passwd (preparation) (Scored)\n    command: cut -s -d':' -f4 /etc/passwd\n    register: groups_id_cut\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.11\n\n  - name: 13.11 Check Groups in /etc/passwd (Scored)\n    command: grep -q -P \"^.*?:[^:]*:{{ item }}:\" /etc/group\n    with_items:\n        groups_id_cut.stdout_lines\n    register: groups_present\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.11\n\n  - name: 13.12 Check That Users Are Assigned Valid Home Directories (Scored)\n    stat: path='{{ item }}'\n    with_items:\n        home_users.stdout_lines\n    register: rstat\n    failed_when: rstat is defined and rstat.stat.isdir == False\n    always_run: True\n    tags:\n      - section13\n      - section13.12\n\n  - name: 13.13 Check User Home Directory Ownership (Scored)\n    debug: msg=\"*** Hardcore ***\"\n    tags:\n      - section13\n      - section13.13\n\n  - name: 13.14 Check for Duplicate UIDs (Scored)\n    shell: cut -f3 -d':' /etc/passwd | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.14\n\n  - name: 13.15 Check for Duplicate GIDs (Scored)\n    shell: cut -f3 -d':' /etc/group | sort | uniq -d\n    register: gids_list\n    failed_when: gids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.15\n\n  - name: 13.16 Check for Duplicate User Names (Scored)\n    shell: cut -f1 -d':' /etc/passwd | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.16\n\n  - name: 13.17 Check for Duplicate Group Names (Scored)\n    shell: cut -f1 -d':' /etc/group | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.17\n\n  - name: 13.18 Check for Presence of User .netrc Files (stat) (Scored)\n    stat: path='{{ item }}/.netrc'\n    with_items: home_users.stdout_lines\n    register: netrc_files\n    tags:\n      - section13\n      - section13.18\n\n  - name: 13.18 Check for Presence of User .netrc Files (Scored)\n    file: >\n        path='{{ item }}'\n        state=absent\n    when: item is defined and item.stat.exists == True\n    with_items: netrc_files.results\n    tags:\n      - section13\n      - section13.18\n\n  - name: 13.19 Check for Presence of User .forward Files (Scored)\n    file: >\n        path='{{ item }}/.forward'\n        state=absent\n    with_items:\n        home_users.stdout_lines\n    tags:\n      - section13\n      - section13.19\n\n  - name: 13.20.1 Ensure shadow group is empty (Scored)\n    shell: grep '^shadow' /etc/group | cut -f4 -d':'\n    register: shadow_group_empty\n    failed_when: shadow_group_empty.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.1\n\n  - name: 13.20.2 Ensure shadow group is empty (preparation) (Scored)\n    shell: grep '^shadow' /etc/group | cut -f1 -d':'\n    register: shadow_group_id\n    failed_when: False\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.1\n\n  - name: 13.20.2 Ensure shadow group is empty (Scored)\n    shell: awk -F':' '($4 == \"{{ item }}\") { print }' /etc/passwd\n    register: awk_passwd_shadow\n    with_items:\n        shadow_group_id.stdout_lines\n    changed_when: False\n    failed_when: awk_passwd_shadow.stdout != ''\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.2\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "223aa1bff3bd4996ac3a3b80d35cfeec07f7ec29", "filename": "tasks/config.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# File: config.yml - Consul configuration tasks\n\n- name: Create configuration\n  copy:\n    dest: \"{{ item.dest }}\"\n    owner: \"{{ consul_user }}\"\n    group: \"{{ consul_group }}\"\n    content: \"{{ lookup('template', 'templates/config.json.j2') | to_nice_json }}\"\n  with_items:\n    - dest: \"{{ consul_config_path }}/config.json\"\n      config_version: \"{{ consul_node_role }}\"\n      when: true\n    - dest: \"{{ consul_config_path }}/bootstrap.json\"\n      config_version: bootstrap\n      when: \"{{ consul_debug | bool }}\"\n    - dest: \"{{ consul_config_path }}/server.json\"\n      config_version: server\n      when: \"{{ consul_debug | bool }}\"\n    - dest: \"{{ consul_config_path }}/client.json\"\n      config_version: client\n      when: \"{{ consul_debug | bool }}\"\n  when:\n    - item.when\n  notify:\n    - restart consul\n\n- name: Create custom configuration\n  copy:\n    dest: \"{{ consul_configd_path }}/50custom.json\"\n    owner: \"{{ consul_user }}\"\n    group: \"{{ consul_group }}\"\n    content: \"{{ lookup('template', 'templates/configd_50custom.json.j2') | to_nice_json }}\"\n  when:\n    - consul_config_custom is defined\n  notify:\n    - restart consul\n\n- name: Set fact list with custom configuration file\n  set_fact:\n    managed_files: \"{{ managed_files |default([]) }} + \\\n      [ '{{ consul_configd_path }}/50custom.json' ]\"\n"}, {"commit_sha": "7a3aa0de9bf76ff1b18e6da304031150e4550142", "sha": "3209503e8a409acc47e62052f1eec6a2038bbae7", "filename": "tasks/yum_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Add tor rpm key\n  sudo: yes\n  rpm_key: state=present key=https://deb.torproject.org/torproject.org/rpm/RPM-GPG-KEY-torproject.org.asc\n\n- set_fact: tor_rpm_distribution_os=\"el\"\n  when: ansible_distribution == 'CentOS' or ansible_distribution == \"Red Hat Enterprise Linux\"\n\n- set_fact: tor_rpm_distribution_os=\"fc\"\n  when: ansible_distribution == 'Fedora'\n\n- name: Add torproject.org repository (YUM)\n  sudo: yes\n  template: src=torproject.yum.repo dest=/etc/yum.repos.d/torproject.repo owner=root group=root\n\n# we specifically opt for present over latest to improve performance\n# \"latest\" is covered by auto updates\n- name: Ensure Tor package is installed (YUM)\n  sudo: yes\n  yum: name=tor state=present\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "fd10062dcd8be403d4f3196caf1195755b24dccb", "filename": "roles/prometheus/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for prometheus\nprometheus_consul_host: \"{{ ansible_ssh_host }}\"\nprometheus_config_dir: /etc/prometheus\nprometheus_node_exporter_image: \"prom/node-exporter:latest\"\nprometheus_node_exporter_port: 9100\nprometheus_node_exporter_hostname: \"{{ ansible_ssh_host }}\"\nprometheus_node_exporter_consul_service_id: \"{{ ansible_hostname }}:node-exporter:9100\"\nprometheus_consul_dir: /etc/consul.d\n# promdash settings\npromdash_database_url: \"mysql2://promdash:promdash@promdash.mysql.service.consul/promdash\"\npromdash_image: \"capgemini/promdash\"\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "c2914d64ccc508181d0d5c576f5ef3140d724e5b", "filename": "tasks/SmartOS/main.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/SmartOS/main.yml: \"Set-up\" playbook for cmacrae.sensu role\n# This takes care of base prerequisites for Joyent SmartOS\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure the Sensu group is present\n    group: name={{ sensu_group_name }} state=present\n\n  - name: Ensure the Sensu user is present\n    user:\n      name: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      shell: /bin/false\n      home: \"{{ sensu_config_path }}\"\n      createhome: true\n      state: present\n\n  - name: Ensure Sensu dependencies are installed\n    pkgin: name=build-essential,ruby21-base state=present\n\n  - name: Ensure Sensu is installed\n    gem: name=sensu state={{ sensu_gem_state }} user_install=no\n    notify:\n      - restart sensu-client service\n\n  - name: Ensure Sensu 'plugins' gem is installed\n    gem: name=sensu-plugin state={{ sensu_plugin_gem_state }} user_install=no\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "99e7a9504ba8bad047191325d8ae9cec38f73822", "filename": "roles/weave/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n# defaults file for weave\nweave_server_group: weave_servers\nweave_launch_peers: \"\n  {%- set weave_peers = [] -%}\n  {%- for host in groups[weave_server_group] -%}\n    {%- if host != inventory_hostname and host not in weave_peers -%}\n      {% do weave_peers.append(hostvars[host]['ansible_eth0']['ipv4']['address']) %}\n    {%- endif -%}\n  {%- endfor -%}\n  {{ weave_peers|join(' ') }}\n\"\n\nweave_scope_url: https://github.com/weaveworks/scope/releases/download/latest_release/scope\nweave_scope_dest: /usr/local/bin/scope\nweave_scope_enabled: false\n"}, {"commit_sha": "f565940c5163524c7834123625c804e5f69c2b10", "sha": "4d0a9ebc782f6285a728883706bd1cc538dcbeb5", "filename": "tasks/CentOS/redis.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/CentOS/redis.yml: Deploy redis\n# Specific to CentOS\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure redis is installed\n    yum:\n      name: \"{{ redis_pkg_name }}\"\n      state: \"{{ redis_pkg_state }}\"\n      enablerepo: epel\n\n  - name: Ensure redis binds to accessible IP\n    lineinfile:\n      dest: /etc/redis.conf\n      regexp: '^bind'\n      line: 'bind 0.0.0.0'\n"}, {"commit_sha": "2a8ca91248bb834daaa8c35f709d6f8158d81a38", "sha": "2cdfbbdbd4c17d834fbf094d2f8d31fe0c357ca5", "filename": "tasks/apt_prepare.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Ensure torproject gpg key is installed (A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89)\n  become: yes\n  apt_key:\n    data: \"{{ lookup('file', 'deb.torproject.org_A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89.pub') }}\"\n    id: A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89\n    state: present\n\n- name: Ensure torproject.org repository is present (APT)\n  become: yes\n  apt_repository:\n    repo: 'deb http://deb.torproject.org/torproject.org {{ tor_distribution_release }} main'\n    state: present\n    update_cache: yes\n\n# known problem: requires manual adjustment with every major tor release 0.2.8.x, 0.2.9.x, ...\n- name: Ensure torproject.org alpha repo is present if enabled (APT)\n  become: yes\n  apt_repository:\n    repo: 'deb http://deb.torproject.org/torproject.org tor-experimental-0.2.9.x-{{ tor_distribution_release }} main'\n    state: present\n    update_cache: yes\n  when: tor_alpha == True\n\n# Background:\n# https://github.com/nusenu/ansible-relayor/issues/72\n- name: Ensure systemd generator folder exists (Debian Testing and Ubuntu)\n  become: yes\n  file:\n    path: /etc/systemd/system-generators\n    state: directory\n    mode: 0755\n  when: ansible_lsb.codename != 'jessie'\n\n- name: Ensure custom systemd generator is in place (Debian/Ubuntu only)\n  become: yes\n  copy:\n    src: tor-generator\n    dest: \"{{ (ansible_lsb.codename == 'jessie')|ternary('/lib/systemd/system-generators/relayor-generator', '/etc/systemd/system-generators/tor-generator') }}\"\n    owner: root\n    mode: 0755\n\n- name: Ensure the maintainer's generator is disabled (Debian 8 only)\n  become: yes\n  command: dpkg-statoverride --update --add root root 644 /lib/systemd/system-generators/tor-generator\n  when: ansible_lsb.codename == 'jessie'\n  ignore_errors: yes\n\n#- name: Ensure AppArmor allows access to necessary files (Ubuntu)\n#  become: yes\n#  lineinfile: dest=/etc/apparmor.d/local/system_tor line={{ item }}\n#  with_items:\n#    - '/etc/tor/enabled/*\\ r,'\n#    - '/{,var/}run/tor/*.pid\\ w,'\n#    - '/var/lib/tor/**\\ w,'\n#  when: ansible_distribution == 'Ubuntu'\n#  notify: restart apparmor\n\n#- meta: flush_handlers\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "16cbb7f5ce909e4841932548abd47210da4d6516", "filename": "roles/cadvisor/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- name: restart cadvisor\n  become: yes\n  service:\n    name: cadvisor\n    state: restarted\n"}, {"commit_sha": "ec4de12ae75f7191a5f71aa775e0344679ea1477", "sha": "03c6b8217beb504b787aed8744f319374605454b", "filename": "tasks/mms-agent.yml", "repository": "UnderGreen/ansible-role-mongodb", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Install MMS agent pt. 1\n  get_url: url={{mongodb_mms_agent_pkg}} dest={{mongodb_conf_dbpath}}/mms-agent.deb\n  register: mongodb_mms_agent_loaded\n\n- name: Install MMS agent pt. 2\n  apt: deb={{mongodb_conf_dbpath}}/mms-agent.deb\n  when: mongodb_mms_agent_loaded.changed\n\n- name: Configure the MMS agent pt. 1\n  file: state=directory path=/etc/mongodb-mms owner={{mongodb_user}} group={{mongodb_user}} mode=0755\n\n- name: Configure the MMS agent pt. 2\n  template: src=automation-agent.config.j2 dest=/etc/mongodb-mms/automation-agent.config\n  notify: mongodb-mms-automation-agent restart\n\n- name: Ensure that the MMS agent is started\n  service: name=mongodb-mms-automation-agent state=started enabled=yes\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "961c550ba6fd265b5960cb52ea8ede13db5d52d7", "filename": "handlers/main.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n\n  - name: restart rabbitmq service\n    service: name={{ rabbitmq_service_name }} state=restarted\n\n  - name: restart redis service\n    service: name={{ redis_service_name }} state=restarted\n\n  - name: restart uchiwa service\n    service: name={{ uchiwa_service_name }} state=restarted\n\n  - name: restart sensu-server service\n    service: name={{ sensu_server_service_name }} state=restarted\n    when: sensu_master and not se_enterprise\n\n  - name: restart sensu-api service\n    service: name={{ sensu_api_service_name }} state=restarted\n    when: sensu_master and not se_enterprise\n\n  - name: restart sensu-client service\n    service: name={{ sensu_client_service_name }} state=restarted\n\n  - name: restart sensu-enterprise service\n    service: name={{ sensu_enterprise_service_name }} state=restarted\n    when: se_enterprise and sensu_master\n\n  - name: restart sensu-enterprise-dashboard service\n    service: name={{ sensu_enterprise_dashboard_service_name }} state=restarted\n    when: se_enterprise and sensu_master\n\n  # Joyent SmartOS specific handlers\n  - name: import sensu-server service\n    command: /usr/sbin/svccfg import /opt/local/lib/svc/manifest/sensu-server.xml\n\n  - name: import sensu-api service\n    command: /usr/sbin/svccfg import /opt/local/lib/svc/manifest/sensu-api.xml\n\n  - name: import sensu-client service\n    command: /usr/sbin/svccfg import /opt/local/lib/svc/manifest/sensu-client.xml\n\n  - name: import uchiwa service\n    command: /usr/sbin/svccfg import /opt/local/lib/svc/manifest/uchiwa.xml\n\n  - name: Build and deploy Uchiwa\n    shell: npm install --production\n    args:\n      chdir: \"{{ uchiwa_path }}/go/src/github.com/sensu/uchiwa\"\n    become: true\n    become_user: \"{{ sensu_user_name }}\"\n\n  - name: Update pkgng database\n    command: /usr/sbin/pkg update\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "2b6e59f5ff6883e633f00651eac1c13891a4f28a", "filename": "roles/serverspec/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for serverspec\nserverspec_run_tests: false\nserverspec_upload_folder: false\nserverspec_tests_path: /vagrant\nserverspec_install_bundler: true\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "deaa10f5c9502fccd5d288ba00d500ccf451bae1", "filename": "tasks/common.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/common.yml: Deploy configurations common to client and server for Sensu\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure the Sensu config directory is present\n    file:\n      dest: \"{{ sensu_config_path }}/conf.d\"\n      state: directory\n      recurse: true\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n\n  - name: Deploy Sensu Redis configuration\n    template:\n      dest: \"{{ sensu_config_path }}/conf.d/redis.json\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      src: \"{{ sensu_redis_config }}\"\n    when: sensu_deploy_redis\n    notify:\n      - restart sensu-server service\n      - restart sensu-api service\n      - restart sensu-enterprise service\n      - restart sensu-client service\n\n  - name: Deploy Sensu RabbitMQ configuration\n    template:\n      dest: \"{{ sensu_config_path }}/conf.d/rabbitmq.json\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      src: \"{{ sensu_rabbitmq_config }}\"\n    when: sensu_transport == \"rabbitmq\"\n    notify:\n      - restart sensu-server service\n      - restart sensu-api service\n      - restart sensu-enterprise service\n      - restart sensu-client service\n\n  - name: Deploy Sensu transport configuration\n    template:\n      dest: \"{{ sensu_config_path }}/conf.d/transport.json\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      src: transport.json.j2\n    notify:\n      - restart sensu-server service\n      - restart sensu-api service\n      - restart sensu-enterprise service\n      - restart sensu-client service\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "cad375cbcf5d3e97a9262dfc507cf24717309308", "filename": "roles/st2smoketests/tasks/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# Small suite of smoke tests to execute to ensure that the playbook has deployed as expected\n\n- meta: flush_handlers\n  tags:\n    - smoke-tests\n\n\n- name: Make sure packs are reloaded\n  sudo: yes\n  command: st2ctl reload --register-all\n  tags:\n    - smoke-tests\n\n- name: st2 installed\n  command: st2 --version\n  tags:\n    - smoke-tests\n\n- name: get authentication token\n  command: st2 auth {{ st2_auth_username }} -p {{ st2_auth_password }} -t\n  register: st2_token\n  tags:\n    - smoke-tests\n\n- name: st2 run core.local -- date -R\n  command: st2 run core.local -- date -R\n  environment:\n    ST2_AUTH_TOKEN: \"{{ st2_token.stdout }}\"\n  tags:\n    - smoke-tests\n\n- name: Check web-ui is up\n  uri:\n    url: https://{{ ansible_hostname }}/\n    validate_certs: no\n  tags:\n    - smoke-tests\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "2d06a6c689c1ecc710a0e19330cafb3fc3dc3aaf", "filename": "tasks/user_group.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# File: user_group.yml - User and group settings\n\n# Add group\n- name: Add Consul group\n  group:\n    name: \"{{ consul_group }}\"\n    state: present\n  when:\n    - consul_manage_group | bool\n\n# Add user\n- name: Add Consul user\n  user:\n    name: \"{{ consul_user }}\"\n    comment: \"Consul user\"\n    group: \"{{ consul_group }}\"\n    system: true\n  when:\n    - consul_manage_user | bool\n"}, {"commit_sha": "4aaf839a9916f65d12b8964b23dbc6848a73ca67", "sha": "e77e29ec86b2e871364b3c9302b201018a83d62b", "filename": "roles/mesos/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# defaults file for mesos\nmesos_zk_port: 2181\nmesos_zookeeper_group: zookeeper_servers\nmesos_master_port: 5050\nconsul_dir: /etc/consul.d\nmesos_endpoint: \"{{ ansible_default_ipv4.address }}\"\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "15d4b3d37a8cefc348e4d1bad0377affbe3f42e6", "filename": "roles/st2web/handlers/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# handlers file for st2web\n- name: restart st2\n  sudo: true\n  command: st2ctl restart \n\n- name: Restart nginx\n  sudo: yes\n  service:\n     name: nginx\n     state: restarted\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "c94f1883fd0a358b44f4dd5c9cf6dd6fb8465b31", "filename": "roles/vault/tasks/bootstrap.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- name: ensure vault is running (and enable it at boot)\n  sudo: yes\n  service:\n    name: vault\n    state: started\n    enabled: yes\n  tags:\n    - vault\n\n- name: vault initialise status\n  sudo: yes\n  command: \"{{ vault_initialize_status_command }}\"\n  register: vault_initialized_output\n  tags:\n    - vault\n\n- name: vault health status\n  sudo: yes\n  command: \"{{ vault_health_status_command }}\"\n  register: vault_health_output\n  tags:\n    - vault\n\n- name: initialize vault\n  when: vault_initialized_output.stdout == \"{\\\"initialized\\\":false}\"\n  run_once: true\n  changed_when: no\n  sudo: yes\n  command: \"{{ vault_initialize_command }}\"\n  register: vault_init_output\n  tags:\n    - vault\n\n- name: set vault security values\n  when: vault_initialized_output.stdout == \"{\\\"initialized\\\":false}\"\n  run_once: true\n  changed_when: no\n  sudo: yes\n  set_fact:\n    vault_keys: \"{{ (vault_init_output.stdout | from_json)['keys'] }}\"\n    vault_root_token: \"{{ (vault_init_output.stdout | from_json)['root_token'] }}\"\n  tags:\n    - vault\n\n- name: upload vault unseal template\n  when: \"'\\\"sealed\\\":false' not in vault_health_output.stdout\"\n  changed_when: no\n  template:\n    src: unseal.j2\n    dest: \"{{ vault_config_folder }}/unseal\"\n    mode: 0744\n  sudo: yes\n  tags:\n    - vault\n  notify: restart vault\n\n- name: unseal vault\n  when: vault_keys is defined\n  sudo: yes\n  command: \"{{ vault_config_folder }}/unseal\"\n  tags:\n    - vault\n\n# This will be used to setup security for the entire stack later\n- name: store vault security values\n  when: vault_root_token is defined\n  local_action: template src=vault-security.yaml.j2 dest=./vault-security.yaml mode=0644\n  sudo: False\n  tags:\n    - vault\n\n- meta: flush_handlers\n"}, {"commit_sha": "35ca6852d9333ef6c3ed223239f45b840c487d60", "sha": "002953d6de58465657ee785cd5a3fe3239ba4802", "filename": "roles/marathon/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for marathon\nmarathon_port: 8080\nconsul_dir: /etc/consul.d\nmarathon_local_address: \"{{ansible_eth0.ipv4.address}}\"\n"}, {"commit_sha": "35ca6852d9333ef6c3ed223239f45b840c487d60", "sha": "21638613d81c6652628a5c8136502e976c4ff578", "filename": "roles/consul/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for consul\n- name: remove consul override\n  file:\n    path: /etc/init/consul.override\n    state: absent\n\n- name: configure consul\n  sudo: yes\n  template:\n    src: consul.json.j2\n    dest: /etc/consul.d/consul.json\n    owner: root\n    group: root\n    mode: 0644\n  notify:\n    - Restart consul\n  tags:\n    - consul\n\n- name: configure atlas for consul\n  sudo: yes\n  template:\n    src: atlas.json.j2\n    dest: /etc/consul.d/atlas.json\n    owner: root\n    group: root\n    mode: 0644\n  when: consul_atlas_join\n  notify:\n    - Restart consul\n  tags:\n    - consul\n\n- name: enable consul\n  sudo: yes\n  service:\n    name: consul\n    enabled: yes\n    state: started\n  tags:\n    - consul\n\n# Give some time for leader election to occur\n- name: wait for leader\n  wait_for:\n    host: \"{{ consul_bind_addr }}\"\n    port: 8301\n    delay: 10\n  tags:\n    - consul\n\n- name: remove consul-join override\n  file:\n    path: /etc/init/consul-join.override\n    state: absent\n  when: consul_join is defined\n  tags:\n    - consul\n\n- name: configure consul-join\n  sudo: yes\n  template:\n    src: consul-join.j2\n    dest: /etc/service/consul-join\n    owner: root\n    group: root\n    mode: 0644\n  notify:\n    - Restart consul\n  when: consul_join is defined\n  tags:\n    - consul\n\n# We need to force reload here because sometimes Consul gets in a weird\n# state where it cannot elect a cluster leader. Simply restarting the service\n# seems to allow it to recover automatically.\n- name: force reload consul\n  sudo: yes\n  command: /sbin/restart consul\n  tags:\n    - consul\n\n- name: force wait for leader\n  wait_for:\n    host: \"{{ consul_bind_addr }}\"\n    port: 8301\n    delay: 10\n  tags:\n    - consul\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "6d399362cfebd51fde7bf2cbc398d1d4a65c0d8b", "filename": "tasks/section_02.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - include: section_02_level1.yml\n    tags:\n      - section02\n      - level1\n\n  - include: section_02_level2.yml\n    tags:\n      - section02\n      - level2"}, {"commit_sha": "694a4890fcf0daa375d6a173511f6ff7dd0f2335", "sha": "e770518f778acf487f0d9c8cd53380bbcabd9bc7", "filename": "tasks/openbsd_service.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n\n# OpenBSD section (uses service module)\n# This is basically a copy from the Linux\n# section, but it requires different service\n# names and additional arguments.\n# =====================================\n\n# OpenBSD does not support multi-instance rc.d\n# # so we link as many pseudo rc scripts as we need.\n# # OpenBSD does not like dots in rc filenames so\n# # we replace them with underscores.\n- name: Create links to the service files (OpenBSD)\n  become: yes\n  file: src=/etc/rc.d/tor state=link path=/etc/rc.d/tor{{ item[0]| replace('.','_') }}_{{ item.1.orport }}\n  with_nested:\n   - tor_ips\n   - tor_ports\n\n- name: Ensure Tor instances are enabled and started (OpenBSD)\n  become: yes\n  service: name=tor{{ item[0]|replace('.','_') }}_{{ item.1.orport }}\n   arguments=\"-f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\" enabled=yes state=started\n  with_nested:\n   - tor_ips\n   - tor_ports\n\n- name: Ensure Tor instances are reloaded if its torrc changed (OpenBSD)\n  become: yes\n  service: name=tor{{ item.item[0]|replace('.','_') }}_{{ item.item.1.orport }} state=reloaded\n  with_items: instances.results\n  when: item.changed == True\n  tags:\n   - reconfigure\n"}, {"commit_sha": "53f9bc7e6a098557bf13ade27a1ec9206a39708c", "sha": "1b82f46d4c9db8a4b20b4882b10cc612f37f3a36", "filename": "tasks/windows.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# Gathers facts (bind address) from servers not currently targeted.\n# 'delegate_facts' is currently rather buggy in Ansible so this might not\n# always work. Hence 'consul_gather_server_facts' defaults to 'no'.\n- name: (Windows) Gather facts from other servers\n  setup:\n  delegate_to: \"{{ item }}\"\n  delegate_facts: true\n  with_items: \"{{ consul_servers | difference(play_hosts) }}\"\n  ignore_errors: true\n  when: consul_gather_server_facts | bool\n\n- name: (Windows) Expose bind_address, datacenter and node_role as facts\n  set_fact:\n    consul_bind_address: \"{{ consul_bind_address }}\"\n    consul_datacenter: \"{{ consul_datacenter }}\"\n    consul_node_role: \"{{ consul_node_role }}\"\n\n- name: (Windows) Read bootstrapped state\n  win_stat:\n    path: \"{{ consul_bootstrap_state }}\"\n  register: bootstrap_state\n  ignore_errors: true\n  tags: always\n\n- name: (Windows) Include directory settings\n  import_tasks: dirs.yml\n\n- name: (Windows) Check for existing Consul binary\n  win_stat:\n    path: \"{{ consul_binary }}\"\n  register: consul_binary_installed\n\n- name: (Windows) Install OS packages and consul\n  include_tasks: install_windows.yml\n  when:\n    - not consul_binary_installed.stat.exists | bool\n\n- block:\n    - block:\n        - name: (Windows) Check for gossip encryption key on previously boostrapped server\n          slurp:\n            src: \"{{ consul_config_path }}/config.json\"\n          register: consul_config_b64\n          ignore_errors: true\n\n        - name: (Windows) Deserialize existing configuration\n          set_fact:\n            consul_config: \"{{ consul_config_b64.content | b64decode | from_json }}\"\n          when: consul_config_b64.content is defined\n\n        - name: (Windows) Save gossip encryption key from existing configuration\n          set_fact:\n            consul_raw_key: \"{{ consul_config.encrypt }}\"\n          when: consul_config is defined\n\n      no_log: true\n      when:\n        - consul_raw_key is not defined\n        - bootstrap_state.stat.exists | bool\n        - inventory_hostname in consul_servers\n\n    # Key provided by extra vars or the above block\n    - name: (Windows) Write gossip encryption key locally for use with new servers\n      copy:\n        content: \"{{ consul_raw_key }}\"\n        dest: '/tmp/consul_raw.key'\n        mode: 0700\n      become: false\n      vars:\n        ansible_become: false\n      no_log: true\n      run_once: true\n      register: consul_local_key\n      delegate_to: localhost\n      when: consul_raw_key is defined\n\n    # Generate new key if non was found\n    - block:\n\n        - name: (Windows) Generate gossip encryption key\n          win_shell: \"{{ consul_binary }} keygen\"\n          register: consul_keygen\n\n        - name: (Windows) Write key locally to share with other nodes\n          copy:\n            content: \"{{ consul_keygen.stdout }}\"\n            dest: '/tmp/consul_raw.key'\n            mode: 0700\n          become: false\n          vars:\n            ansible_become: false\n          delegate_to: localhost\n\n      no_log: true\n      run_once: true\n      when:\n        - not consul_local_key.changed\n        - not bootstrap_state.stat.exists | bool\n\n    - name: (Windows) Read gossip encryption key for servers that require it\n      set_fact:\n        consul_raw_key: \"{{ lookup('file', '/tmp/consul_raw.key') }}\"\n      no_log: true\n      when:\n        - consul_raw_key is not defined\n\n    - name: (Windows) Delete gossip encryption key file\n      file:\n        path: '/tmp/consul_raw.key'\n        state: absent\n      become: false\n      vars:\n        ansible_become: false\n      run_once: true\n      delegate_to: localhost\n  no_log: true\n  when:\n    - consul_encrypt_enable\n\n- name: (Windows) Create Consul configuration\n  import_tasks: config_windows.yml\n\n- name: (Windows) Ensure neither ACL nor TLS are requested\n  fail:\n    msg: \"ACL and TLS are not supported on Windows hosts yet.\"\n  when:\n    - (consul_acl_enable | bool) or (consul_tls_enable | bool)\n\n- name: (Windows) Create ACL configuration\n  include_tasks: acl.yml\n  when: consul_acl_enable | bool\n\n- name: (Windows) Create TLS configuration\n  include_tasks: tls.yml\n  when: consul_tls_enable | bool\n\n- block:\n\n    - name: (Windows) Install NSSM\n      win_chocolatey:\n        name: nssm\n        state: present\n\n    - name: (Windows) Create Consul service on Windows\n      win_nssm:\n        name: consul\n        state: present\n        application: \"{{ consul_binary }}\"\n        app_parameters_free_form: \"agent -config-file={{ consul_config_path }}/config.json -config-dir={{ consul_configd_path }}\"\n        stdout_file: \"{{ consul_log_path }}/consul-nssm-output.log\"\n        stderr_file: \"{{ consul_log_path }}/consul-nssm-error.log\"\n\n    - name: (Windows) start consul on windows\n      win_service:\n        name: consul\n        start_mode: auto\n        state: started\n\n    - name: (Windows) Check Consul HTTP API\n      win_wait_for:\n        delay: 5\n        port: 8500\n\n    - name: (Windows) Create bootstrapped state file\n      win_file:\n        dest: \"{{ consul_bootstrap_state }}\"\n        state: touch\n      when: ansible_os_family == \"Windows\"\n\n    - include_tasks: ../tasks/iptables.yml\n      when: consul_iptables_enable | bool\n\n  when: not bootstrap_state.stat.exists\n\n- include_tasks: ../tasks/dnsmasq.yml\n  when: consul_dnsmasq_enable | bool\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "c37a8e2f7e39e49ffe63ffa6caab84089f1c153c", "filename": "tasks/Amazon/dashboard.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/Amazon/dashboard.yml: Deployment of the Uchiwa dashboard\n# Specific to CentOS\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure Uchiwa is installed\n    yum:\n      name: uchiwa\n      state: present\n\n  - name: Deploy Uchiwa config\n    template:\n      src: uchiwa_config.json.j2\n      dest: \"{{ sensu_config_path }}/uchiwa.json\"\n    notify: restart uchiwa service\n"}, {"commit_sha": "1510f92858b85f9f623690db747bdfff9b5b0515", "sha": "3a31d86ace5653a4661618585bd2186db57672b2", "filename": "handlers/main.yml", "repository": "dev-sec/ansible-mysql-hardening", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n\n- name: restart mysql\n  service: name='{{ mysql_daemon }}' state=restarted\n"}, {"commit_sha": "9ad67b6ef151d5fbaa05230e6cecb4bed1db7d9d", "sha": "e960fee3b42a85f6be469a0fa6109fe0c12d0b49", "filename": "tasks/section_03_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n#sections 3.3 and 3.4 have to happen before as the latter overwrite 3.1 and 3.2\n\n  - name: 3 Check for /boot/grub/grub.cfg file\n    stat: path=/boot/grub/grub.cfg\n    register: grub_cfg_file\n    tags:\n      - section3\n\n  - name: 3.3.1.1 Set Boot Loader Superuser (check) (Scored)\n    command: grep \"^set superusers\" /boot/grub/grub.cfg\n    register: boot_superusers \n    when: grub_cfg_file.stat.exists == True\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section3\n      - section3.3\n      - section3.3.1\n      - section3.3.1.1\n\n  - name: 3.3.1.2 Set Boot Loader Superuser (Scored)\n    lineinfile: >\n        dest='/etc/grub.d/40_custom'\n        regexp='^set superusers'\n        line='set superusers=\"root\"'\n        state=present\n    when: grub_cfg_file.stat.exists == True and boot_superusers.rc == 1\n    tags:\n      - section3\n      - section3.3\n      - section3.3.1\n      - section3.3.1.2\n    \n  - name: 3.3.2.1 Set Boot Loader Password (check) (Scored)\n    command: grep \"^password\" /boot/grub/grub.cfg\n    register: boot_password\n    when: grub_cfg_file.stat.exists == True\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section3\n      - section3.3\n      - section3.3.2\n      - section3.3.2.1\n\n  - name: 3.3.2.2 Set Boot Loader Password (Scored)\n    lineinfile: >\n        dest='/etc/grub.d/40_custom' \n        regexp='^password'\n        line='password_pbkdf2 root grub.pbkdf2.sha512.10000.529DB4AF052F170948C1DB2A754CEA8A286804DA2D9A4EB5A7CCE4B8636775C83EAF8A1093CBDBC256954BCE789A58EFB3B75D23DFC76583C703922D5DADB69E.4D5BD1EC6736057095CA2EBF55C2DA02DFB0B0784F2105A396F1CEF11FEB1483D5C420F412E2E817E2570DDFC22ABCC329C5FF44091A0ACDE67171FF72E96CFD'\n        state=present\n    when: grub_cfg_file.stat.exists == True and boot_password.rc == 1\n    tags:\n      - section3\n      - section3.3\n      - section3.3.2\n      - section3.3.2.2\n\n  - name: 3.3.3 Disable password protection booting\n    lineinfile: >\n        dest='/etc/grub.d/10_linux'\n        create=yes\n        regexp='^CLASS='\n        line='CLASS=\"--class gnu-linux --class gnu --class os --unrestricted\"'\n        state=present\n    tags:\n      - section3\n      - section3.3\n      - section3.3.3\n\n\n  - name: 3.3.4 Update Grub configuration (Scored)\n    command: update-grub\n    when: grub_cfg_file.stat.exists == True and (boot_superusers.rc == 1 or boot_password.rc == 1)\n    tags:\n      - section3\n      - section3.3\n      - section3.3.4\n\n\n  - name: 3.4.1 Require Authentication for Single-User Mode (check) (Scored)\n    shell: 'grep \"^root:[*\\!]:\" /etc/shadow'\n    register: root_password_set\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section3\n      - section3.4\n      - section3.4.1\n\n  - name: 3.4.2 Require Authentication for Single-User Mode (Scored)\n    user: name=root state=present password='{{ root_password }}'\n    when: root_password_set.rc == 1\n    tags:\n      - section3\n      - section3.4\n      - section3.4.2\n\n  - name: 3.1 Set User/Group Owner on bootloader config (Scored)\n    file: path=/boot/grub/grub.cfg owner=root group=root\n    when: grub_cfg_file.stat.exists == True\n    tags:\n      - section3\n      - section3.1\n\n  - name: 3.2 Set Permissions on bootloader config (Scored)\n    file: path=/boot/grub/grub.cfg mode=\"o-rwx,g-rwx\"\n    when: grub_cfg_file.stat.exists == True\n    sudo: yes\n    tags:\n      - section3\n      - section3.2\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "20d20890ae046888494a3f3c3e5a79aec797b1a9", "filename": "roles/dcos_cli/vars/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# vars file for dcos_cli\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "5ba1b00ffddf308d5b1b22565e89f06b46bffacc", "filename": "roles/haproxy/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for haproxy\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "5c49469b42ed8486c84d8550f05be243412769ee", "filename": "tasks/plugins.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/plugins.yml: Deploy available checks/plugins/handlers/filters/mutators\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure Sensu plugin directory exists\n    file:\n      dest: \"{{ sensu_config_path }}/plugins\"\n      state: directory\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n\n  - name: Ensure local directories exist\n    local_action: file state=directory dest=\"{{ static_data_store }}/sensu/{{ item }}\"\n    become: no\n    with_items:\n      - checks\n      - filters\n      - handlers\n      - mutators\n\n  - name: Ensure any remote plugins defined are present\n    shell: sensu-install -p {{ item }}\n    with_items: \"{{ sensu_remote_plugins }}\"\n    changed_when: false\n    when: sensu_remote_plugins > 0\n\n  - name: Register available checks\n    local_action: command ls {{ static_data_store }}/sensu/checks\n    register: sensu_available_checks\n    changed_when: false\n    become: false\n\n  - name: Deploy check plugins\n    copy:\n      src: \"{{ static_data_store }}/sensu/checks/{{ item }}/\"\n      dest: \"{{ sensu_config_path }}/plugins/\"\n      mode: 0755\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    when: \"sensu_available_checks is defined and item in sensu_available_checks.stdout_lines\"\n    with_flattened:\n      - \"{{ group_names }}\"\n    notify: restart sensu-client service\n\n  - name: Deploy handler plugins\n    copy:\n      src: \"{{ static_data_store }}/sensu/handlers/\"\n      dest: \"{{ sensu_config_path }}/plugins/\"\n      mode: 0755\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    notify: restart sensu-client service\n\n  - name: Deploy filter plugins\n    copy:\n      src: \"{{ static_data_store }}/sensu/filters/\"\n      dest: \"{{ sensu_config_path }}/plugins/\"\n      mode: 0755\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    notify: restart sensu-client service\n\n  - name: Deploy mutator plugins\n    copy:\n      src: \"{{ static_data_store }}/sensu/mutators/\"\n      dest: \"{{ sensu_config_path }}/plugins/\"\n      mode: 0755\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    notify: restart sensu-client service\n\n  - name: Deploy check/handler/filter/mutator definitions to the master\n    template:\n      src: \"{{ item }}\"\n      dest: \"{{ sensu_config_path }}/conf.d/{{ item | basename | regex_replace('.j2', '')}}\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    when: sensu_master\n    with_fileglob:\n      - \"{{ static_data_store }}/sensu/definitions/*\"\n    notify:\n      - restart sensu-server service\n      - restart sensu-api service\n      - restart sensu-enterprise service\n"}, {"commit_sha": "9ad67b6ef151d5fbaa05230e6cecb4bed1db7d9d", "sha": "b9ade387b5fc41816b497bfbe8f4d7aa93ad72ce", "filename": "tasks/section_13_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 13.1 Ensure Password Fields are Not Empty (Scored)\n    command: awk -F':' '($2 == \"\" ) { print $1 }' /etc/shadow\n    register: awk_empty_shadow\n    changed_when: False\n    failed_when: awk_empty_shadow.stdout != '' and lock_shadow_accounts == 'no'\n    tags:\n      - section13\n      - section13.1\n\n  - name: 13.1 Ensure Password Fields are Not Empty (locking accounts) (Scored)\n    command: passwd -l '{{ item }}'\n    with_items:\n        awk_empty_shadow.stdout_lines\n    when: lock_shadow_accounts\n    tags:\n      - section13\n      - section13.1\n\n  - name: 13.2 Verify No Legacy \"+\" Entries Exist in /etc/passwd File (Scored)\n    command: grep '^+:' /etc/passwd\n    register: plus_pass\n    failed_when: plus_pass.rc == 0\n    changed_when: plus_pass.rc == 0\n    tags:\n      - section13\n      - section13.2\n\n  - name: 13.3 Verify No Legacy \"+\" Entries Exist in /etc/shadow File (Scored)\n    command: grep '^+:' /etc/shadow\n    register: plus_shadow\n    failed_when: plus_shadow.rc == 0\n    changed_when: plus_shadow.rc == 0\n    tags:\n      - section13\n      - section13.3\n\n  - name: 13.4 Verify No Legacy \"+\" Entries Exist in /etc/group File (Scored)\n    command: grep '^+:' /etc/group\n    register: plus_group\n    failed_when: plus_group.rc == 0\n    changed_when: plus_group.rc == 0\n    tags:\n      - section13\n      - section13.4\n\n  - name: 13.5 Verify No UID 0 Accounts Exist Other Than root (Scored)\n    command: awk -F':' '($3 == 0) { print $1 }' /etc/passwd\n    register: uid_zero_root\n    changed_when: False\n    failed_when: uid_zero_root.stdout != 'root'\n    tags:\n      - section13\n      - section13.5\n\n  - name: 13.6.1 Ensure root PATH Integrity (empty value) (Scored)\n    shell: 'echo $PATH | grep ::'\n    register: path_colon\n    changed_when: False\n    failed_when: path_colon.rc == 0\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.2 Ensure root PATH Integrity (colon end) (Scored)\n    shell: 'echo $PATH | grep :$'\n    register: path_colon_end\n    changed_when: False\n    failed_when: path_colon_end.rc == 0\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.3 Ensure root PATH Integrity (dot in path) (Scored)\n    shell: \"echo $PATH | sed -e 's/::/:/' -e 's/:$//' -e 's/:/\\\\n/g'\"\n    register: dot_in_path\n    changed_when: False\n    failed_when: '\".\" in dot_in_path.stdout_lines'\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.4 Ensure root PATH Integrity (Scored)\n    file: >\n        path='{{ item }}'\n        state=directory\n        owner=root\n        mode='o-w,g-w'\n    with_items:\n        dot_in_path.stdout_lines\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.7.1 Check Permissions on User Home Directories (gather users) (Scored)\n    shell: /bin/egrep -v '(root|halt|sync|shutdown|false)' /etc/passwd | /usr/bin/awk -F':' '($7 != \"/usr/sbin/nologin\") { print $6 }'\n    register: home_users\n    changed_when: False\n    failed_when: False\n    tags:\n      - section13\n      - section13.7\n\n  - name: 13.7.2 Check Permissions on User Home Directories (Scored)\n    file: >\n        path='{{ item }}'\n        mode='g-w,o-rwx'\n        state=directory\n    with_items:\n        home_users.stdout_lines\n    when: modify_user_homes == True\n    tags:\n      - section13\n      - section13.7\n\n  - name: 13.8.1 Check User Dot File Permissions (gather dotfiles) (Scored)\n    shell: for pth in `/bin/egrep -v '(root|halt|sync|shutdown)' /etc/passwd | /usr/bin/awk -F':' '($7 != \"/usr/sbin/nologin\") { print $6 }'`; do ls -d -A -1 $pth/.* | egrep -v '[..]$'; done\n    changed_when: False\n    failed_when: False\n    always_run: True\n    register: home_dot_files\n    tags:\n      - section13\n      - section13.8\n\n  - name: 13.8.2 Check User Dot File Permissions (Scored)\n    file: >\n        path='{{ item }}'\n        mode='o-w,g-w'\n    with_items:\n        home_dot_files.stdout_lines\n    tags:\n      - section13\n      - section13.8\n\n  - name: 13.9 Check Permissions on User .netrc Files (Scored)\n    file: >\n        path='{{ item }}/.netrc'\n        mode='g-rwx,o-rwx'\n        recurse=yes\n        state=directory\n    with_items:\n        home_users.stdout_lines\n    tags:\n      - section13\n      - section13.9\n\n  - name: 13.10 Check for Presence of User .rhosts Files (Scored)\n    file: >\n        state=absent\n        path='{{ item }}/.rhosts'\n    with_items:\n        home_users.stdout_lines\n    tags:\n      - section13\n      - section13.10\n\n  - name: 13.11 Check Groups in /etc/passwd (preparation) (Scored)\n    command: cut -s -d':' -f4 /etc/passwd\n    register: groups_id_cut\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.11\n\n  - name: 13.11 Check Groups in /etc/passwd (Scored)\n    command: grep -q -P \"^.*?:[^:]*:{{ item }}:\" /etc/group\n    with_items:\n        groups_id_cut.stdout_lines\n    register: groups_present\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.11\n\n  - name: 13.12 Check That Users Are Assigned Valid Home Directories (Scored)\n    stat: path='{{ item }}'\n    with_items:\n        home_users.stdout_lines\n    register: rstat\n    failed_when: rstat is defined and rstat.stat.isdir == False\n    always_run: True\n    tags:\n      - section13\n      - section13.12\n\n  - name: 13.13 Check User Home Directory Ownership (Scored)\n    debug: msg=\"*** Hardcore ***\"\n    tags:\n      - section13\n      - section13.13\n\n  - name: 13.14 Check for Duplicate UIDs (Scored)\n    shell: cut -f3 -d':' /etc/passwd | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.14\n\n  - name: 13.15 Check for Duplicate GIDs (Scored)\n    shell: cut -f3 -d':' /etc/group | sort | uniq -d\n    register: gids_list\n    failed_when: gids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.15\n\n  - name: 13.16 Check for Duplicate User Names (Scored)\n    shell: cut -f1 -d':' /etc/passwd | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.16\n\n  - name: 13.17 Check for Duplicate Group Names (Scored)\n    shell: cut -f1 -d':' /etc/group | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.17\n\n  - name: 13.18 Check for Presence of User .netrc Files (stat) (Scored)\n    stat: path='{{ item }}/.netrc'\n    with_items: home_users.stdout_lines\n    register: netrc_files\n    tags:\n      - section13\n      - section13.18\n\n  - name: 13.18 Check for Presence of User .netrc Files (Scored)\n    file: >\n        path='{{ item }}'\n        state=absent\n    when: item.stat.exists == True\n    with_items: netrc_files.results\n    tags:\n      - section13\n      - section13.18\n\n  - name: 13.19 Check for Presence of User .forward Files (Scored)\n    file: >\n        path='{{ item }}/.forward'\n        state=absent\n    with_items:\n        home_users.stdout_lines\n    tags:\n      - section13\n      - section13.19\n\n  - name: 13.20.1 Ensure shadow group is empty (Scored)\n    shell: grep '^shadow' /etc/group | cut -f4 -d':'\n    register: shadow_group_empty\n    failed_when: shadow_group_empty.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.1\n\n  - name: 13.20.2 Ensure shadow group is empty (preparation) (Scored)\n    shell: grep '^shadow' /etc/group | cut -f1 -d':'\n    register: shadow_group_id\n    failed_when: False\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.1\n\n  - name: 13.20.2 Ensure shadow group is empty (Scored)\n    shell: awk -F':' '($4 == \"{{ item }}\") { print }' /etc/passwd\n    register: awk_passwd_shadow\n    with_items:\n        shadow_group_id.stdout_lines\n    changed_when: False\n    failed_when: awk_passwd_shadow.stdout != ''\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.2\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "68c4122a5fb0f34c5917f2cf1bac1dbf649398b8", "filename": "roles/st2repos/defaults/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# defaults file for st2repos\n"}, {"commit_sha": "80530fde7df1a94ad361434e02816b0816a2c47a", "sha": "a9d9c9b5693be336cae5c73a792879c384844a3b", "filename": "roles/consul/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# defaults file for consul\nconsul_is_server: no\nconsul_dc: dc1\nconsul_servers_group: consul_servers\nconsul_advertise: \"{{ ansible_default_ipv4.address }}\"\nconsul_bind_addr: \"{{ ansible_default_ipv4.address }}\"\nconsul_bootstrap_expect: \"{{ groups[consul_servers_group] | length }}\"\nconsul_client_addr: \"0.0.0.0\"\nconsul_atlas_join: false\n"}, {"commit_sha": "f5364b57f100ae9fa898af59b7812ec0c447ac42", "sha": "cab894aa41c6d342b6ab716ea92a3d28c354a047", "filename": "tasks/freebsd_prepare.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Ensure sequential IP IDs are avoided (FreeBSD)\n  become: yes\n  sysctl:\n    name: net.inet.ip.random_id\n    value: 1\n    reload: no\n    sysctl_set: yes\n\n- name: Gather current kern.ipc.somaxconn setting (FreeBSD)\n  shell: \"sysctl kern.ipc.somaxconn|cut -d' '  -f2\"\n  register: currentsomaxconn\n\n- name: Ensure somaxconn setting is reasonable (FreeBSD)\n  become: yes\n  sysctl:\n    name: kern.ipc.somaxconn\n    value: \"{{ freebsd_somaxconn }}\"\n    reload: no\n    sysctl_set: yes\n  when: currentsomaxconn.stdout|int < {{ freebsd_somaxconn }}\n\n- name: Gather current kern.ipc.nmbclusters setting (FreeBSD)\n  shell: \"sysctl kern.ipc.nmbclusters|cut -d' '  -f2\"\n  register: currentnmbc\n\n- name: Ensure nmbclusters setting is reasonable (FreeBSD)\n  become: yes\n  sysctl:\n    name: kern.ipc.nmbclusters\n    value: \"{{ freebsd_nmbclusters }}\"\n    reload: no\n    sysctl_set: yes\n  when: currentnmbc.stdout|int < {{ freebsd_nmbclusters }}\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "558ac8b5cdf98351e7ce8f6567a6727f292f0ab8", "filename": "roles/consul/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for consul\nconsul_dc: dc1\nconsul_servers_group: consul_servers\nconsul_bootstrap_expect: \"{{ groups[consul_servers_group] | length }}\"\nconsul_advertise: \"{{ ansible_ssh_host }}\"\nconsul_config_dir: /etc/consul.d\nconsul_data_dir: /var/lib/consul\nconsul_atlas_join: false\nconsul_bind_addr: \"{{ ansible_default_ipv4.address }}\"\nconsul_retry_join: \"{% for host in groups[consul_servers_group] %}\\\"{{ hostvars[host].ansible_default_ipv4.address }}\\\"{% if not loop.last %}, {% endif %}{% endfor %}\"\nconsul_client_addr: \"0.0.0.0\"\nconsul_node_name: \"{{ ansible_hostname }}\"\nconsul_version: 0.6\nconsul_image: \"\n  {%- if inventory_hostname in groups[consul_servers_group] -%}\n    gliderlabs/consul-server:{{ consul_version }}\n  {%- else -%}\n    gliderlabs/consul-agent:{{ consul_version }}\n  {%- endif -%}\n\"\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "cccea007ab10c7a19980deef8fdd3e5e56328b82", "filename": "roles/st2/tasks/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n\n- name: Install latest st2 package\n  sudo: yes\n  apt:\n    name: st2\n    state: latest\n  when: st2_version == \"stable\"\n  notify:\n    - restart st2\n\n- name: Install latest st2 package\n  sudo: yes\n  apt:\n    name: st2={{ st2_version }}-{{ st2_revision }}\n    state: present\n  when: st2_version != \"stable\"\n  notify:\n    - restart st2\n\n- include: user.yml\n\n- include: config_auth.yml\n  when: enable_auth\n"}, {"commit_sha": "32211ebd2a9f45112f8dceda80bc95d0db029fb4", "sha": "d24148aabc6dbeb8373c32adb5745958c1b86b44", "filename": "tasks/ip-list.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: setup IP list (1/2)\n  set_fact:\n    ips:\n        ipv4: \"{{ item.0 }}\"\n        ipv6: \"{{ item.1 }}\"\n  with_together:\n        - \"{{ tor_v4ips }}\"\n        - \"{{ tor_v6ips }}\"\n  register: ipsinterm\n\n- name: setup IP list (2/2)\n  set_fact: tor_ips=\"{{ ipsinterm.results | map(attribute='ansible_facts.ips')|list}}\"\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "48d2b27b80a82ad60a77230c1a6977f4a0905188", "filename": "tasks/FreeBSD/main.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/FreeBSD/main.yml: FreeBSD specific set-up\n# This takes care of base prerequisites for FreeBSD\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure the Sensu group is present\n    group: name={{ sensu_group_name }} state=present\n\n  - name: Ensure the Sensu user is present\n    user:\n      name: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      shell: /bin/false\n      home: \"{{ sensu_config_path }}\"\n      createhome: true\n      state: present\n\n  - name: Create pkgng custom repo config directory\n    file:\n      path: /usr/local/etc/pkg/repos/\n      state: directory\n\n  - name: Install sensu repo\n    template:\n      src: sensu-freebsd-repo.conf.j2\n      dest: /usr/local/etc/pkg/repos/sensu.conf\n    notify:\n      - Update pkgng database\n\n  - name: Install prerequisite packages\n    pkgng:\n      name: \"{{ item }}\"\n      state: present\n    with_items:\n      - bash\n      - ca_root_nss\n\n  - name: Install sensu\n    pkgng:\n      name: \"sensu{% if sensu_pkg_version %}-{{ sensu_pkg_version }}{% endif %}\"\n      state: present\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "0364570c95a6af92bc7d34fdeaa8207f10c39eae", "filename": "roles/vault/tasks/install.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- name: download vault binary\n  sudo: yes\n  get_url:\n    url: \"{{ vault_url }}\"\n    dest: /tmp/vault.zip\n    mode: 0755\n\n- name: uncompress vault\n  unarchive:\n    src: /tmp/vault.zip\n    dest: /usr/bin\n    copy: no\n\n- name: create vault config directory\n  file:\n    path: \"{{ vault_config_folder }}\"\n    state: directory\n    mode: 0755\n  sudo: yes\n  tags:\n    - vault\n\n- name: upload vault template config files\n  template:\n    src: \"{{ item.src }}\"\n    dest: \"{{ item.dst }}\"\n    mode: 0755\n  sudo: yes\n  with_items:\n  - { src: vault.conf.j2, dst: '/etc/init/vault.conf' }\n  - { src: default.j2, dst: '/etc/default/vault' }\n  - { src: config.hcl.j2, dst: \"{{ vault_config_folder }}/config.hcl\" }\n  tags:\n    - vault\n\n- name: upload wait for vault leader script\n  sudo: yes\n  template:\n    src: wait-for-vault-leader.sh.j2\n    dest: \"{{ vault_config_folder }}/wait-for-vault-leader.sh\"\n    mode: 0755\n  tags:\n    - vault\n\n- name: Set vault consul service definition\n  sudo: yes\n  template:\n    src: vault-consul.j2\n    dest: \"{{ vault_consul_dir }}/vault.json\"\n  notify:\n    - restart consul\n"}, {"commit_sha": "7a3aa0de9bf76ff1b18e6da304031150e4550142", "sha": "1fc2b6b4dc4fb9514a20161a1a52b698dab4c354", "filename": "tasks/freebsd_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Ensure Tor is installed (FreeBSD)\n  sudo: yes\n  pkgng: name=tor state=present\n  when: tor_alpha == False\n\n# pkg will take care of removing tor stable\n# if installed\n- name: Ensure Tor alpha is installed (FreeBSD)\n  sudo: yes\n  pkgng: name=tor-devel state=present\n  when: tor_alpha == True\n"}, {"commit_sha": "61b008311c40b377e57e166b778232a20224f7c6", "sha": "e51784575ed1a78492ad11f44c2e6532056d65b8", "filename": "tasks/main.yml", "repository": "UnderGreen/ansible-role-mongodb", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- include: install.deb.yml\n  when: ansible_os_family == 'Debian'\n  tags: [mongodb]\n\n- include: configure.yml\n  tags: [mongodb]\n\n- include: replication_init_auth.yml\n  when: ( mongodb_conf_replSet is defined and mongodb_conf_auth\n        and mongodb_master is defined and mongodb_master )\n  tags: [mongodb]\n\n- include: replication.yml\n  when: mongodb_conf_replSet is defined\n  tags: [mongodb]\n\n- include: auth_initialization.yml\n  when: mongodb_conf_auth and not mongodb_conf_replSet\n  tags: [mongodb]\n\n- include: mms-agent.yml\n  when: mongodb_mms_api_key != \"\"\n  tags: [mongodb]\n"}, {"commit_sha": "6d51642c8f7babe4c8185b60872420333a5d3caa", "sha": "7b6425a1b06532534bbd704aa4b0aa0b1f663c46", "filename": "tasks/CentOS/main.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/CentOS/main.yml: CentOS specific set-up\n# This takes care of base prerequisites for CentOS\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure the Sensu Core Yum repo is present\n    copy:\n      dest: /etc/yum.repos.d/sensu.repo\n      content: |\n        [sensu]\n        name=sensu\n        baseurl=http://repositories.sensuapp.org/yum/$basearch/\n        gpgcheck=0\n        enabled=1\n      owner: root\n      group: root\n      mode: 0644\n\n  - name: Ensure Sensu is installed\n    yum: name=sensu state={{ sensu_pkg_state }}\n"}, {"commit_sha": "af3dfdf7cf37437f5609f1a12e4ac7cbaebd4867", "sha": "e6452979500d46f533348ade6889f9eabd4e0e77", "filename": "roles/dockerbench/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for docker bench\n- name: checkout docker bench git repo\n  git: \n    repo: \"{{ dockerbench_repo }}\"\n    dest: \"{{ dockerbench_dest }}\"\n    accept_hostkey: true\n  when: dockerbench_run_test\n\n- name: install docker bench threshold script\n  sudo: yes\n  template:\n    src: docker-bench-warn.sh.j2\n    dest: /usr/local/bin/docker-bench-warn.sh\n    mode: 0755\n  when: dockerbench_run_test\n\n- name: run docker bench script\n  command: /usr/local/bin/docker-bench-warn.sh\n  sudo: yes\n  args:\n    chdir: \"{{ dockerbench_dest }}\"\n  when: dockerbench_run_test\n"}, {"commit_sha": "bf6e08dcb2440421477b6536ff6a8d11adc2be17", "sha": "a23c38c387fb316d6ff7f7873a36f28a8a10ef0b", "filename": "roles/registrator/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n# Install (docker-py) python package as is a docker module dependency.\n- pip:\n    name: docker-py\n    version: 1.1.0\n  tags:\n    - registrator\n\n# tasks file for docker registrator\n- name: run registrator container\n  docker:\n    name: registrator\n    image: \"{{ registrator_image }}\"\n    state: started\n    restart_policy: always\n    net: host\n    command: \"-internal {{ registrator_uri }}\"\n    volumes:\n    - \"/var/run/docker.sock:/tmp/docker.sock\"\n  tags:\n    - registrator\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "a9420601f248a200ad9261db79816d15be25030e", "filename": "roles/serverspec/meta/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: your name\n  description:\n  company: Capgemini\n  # If the issue tracker for your role is not on github, uncomment the\n  # next line and provide a value\n  # issue_tracker_url: http://example.com/issue/tracker\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (GPLv2, CC-BY, etc)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  #platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  #- name: Ubuntu\n  #  versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n  #  - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  #categories:\n  #- cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  #- system\n  #- web\ndependencies: []\n  # List your role dependencies here, one per line.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n\n"}, {"commit_sha": "12d2d30c292e5749809cd7476458762a4de31554", "sha": "afba135ee7f0ffd9268ca4129fe737347ee6b874", "filename": "tasks/configure.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Ensure Tor DataDir(s) exist and is owned by tor_user\n  sudo: yes\n  file: path={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}\n    state=directory\n    owner={{ tor_user }}\n    mode=0700\n    recurse=yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - debian\n   - centos\n   - freebsd\n   - openbsd\n\n- name: Ensure Tor config directory exists and has appropriate permissions\n  sudo: yes\n  file: path={{ tor_ConfDir }}\n    state=directory\n    owner=root\n    group={{ tor_user }}\n    mode=755\n  tags:\n   - debian\n   - centos\n   - freebsd\n   - openbsd\n\n- name: Ensure LogDir exists and has appropriate permissions\n  sudo: yes\n  file: path={{ tor_LogDir }}\n    state=directory\n    owner={{ tor_user }}\n    mode=750\n  tags:\n   - debian\n   - centos\n   - freebsd\n   - openbsd\n\n- name: Ensure PidDir is owned by tor_user\n  sudo: yes\n  file: path={{ tor_PidDir }}\n    state=directory\n    owner={{ tor_user }}\n    group={{ tor_user }}\n    mode=2750\n  tags:\n   - debian\n   - centos\n   - freebsd\n   - openbsd\n\n- name: Generating temporary (without MyFamily) torrc file(s)...\n  sudo: yes\n  template: src=torrc\n    dest=\"{{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc-tmp\"\n    owner=root\n    mode=0644\n  with_nested:\n   - tor_ips\n   - tor_ports\n  tags:\n   - debian\n   - centos\n   - freebsd\n   - openbsd\n\n- name: Collect relay fingerprints (for MyFamily)\n  sudo: yes\n  shell: \"tor --hush -f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc-tmp --list-fingerprint |cut -d' ' -f2-|sed -e 's, ,,g'\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n  register: tor_fingerprints\n  tags:\n   - debian\n   - centos\n   - freebsd\n   - openbsd\n   - configure\n\n- name: Generating final torrc file(s) (with MyFamily)\n  sudo: yes\n  template: >\n    src=torrc\n    dest=\"{{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\"\n    owner=root\n    mode=0644\n    backup=yes\n    validate=\"tor --verify-config -f %s\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n  register: instances\n  tags:\n   - debian\n   - centos\n   - freebsd\n   - openbsd\n   - configure\n\n# Linux/systemd section (uses service module)\n# ===========================================\n \n- name: Ensure Tor instances are reloaded if its torrc changed (Linux/systemd)\n  sudo: yes\n  service: name=tor@{{ item.item[0] }}_{{ item.item.1.orport }}.service state=reloaded\n  with_items: instances.results\n  when: ansible_system == 'Linux' and item.changed == True \n  tags:\n   - debian\n   - centos\n   - configure\n\n- name: Ensure Tor instances are enabled and started (Linux/systemd)\n  sudo: yes\n  service: name=tor@{{ item[0] }}_{{ item.1.orport }}.service enabled=yes state=started\n  with_nested:\n   - tor_ips\n   - tor_ports\n  when: ansible_system == 'Linux'\n  tags:\n   - debian\n   - centos\n\n# OpenBSD section (uses service module)\n# This is basically a copy from the Linux\n# section, but it requires different service\n# names and additional arguments.\n# =====================================\n\n# OpenBSD does not support multi-instance rc.d\n# # so we link as many pseudo rc scripts as we need.\n# # OpenBSD does not like dots in rc filenames so\n# # we replace them with underscores.\n- name: Create links to the service files (OpenBSD)\n  sudo: yes\n  file: src=/etc/rc.d/tor state=link path=/etc/rc.d/tor{{ item[0]| replace('.','_') }}_{{ item.1.orport }}\n  with_nested:\n   - tor_ips\n   - tor_ports\n  when: ansible_system == 'OpenBSD'\n  tags:\n   - openbsd\n\n- name: Ensure Tor instances are reloaded if its torrc changed (OpenBSD)\n  sudo: yes\n  service: name=tor{{ item.item[0]|replace('.','_') }}_{{ item.item.1.orport }} state=reloaded\n  with_items: instances.results\n  when: ansible_system == 'OpenBSD' and item.changed == True\n  tags:\n   - openbsd\n   - configure\n\n- name: Ensure Tor instances are enabled and started (OpenBSD)\n  sudo: yes\n  service: name=tor{{ item[0]|replace('.','_') }}_{{ item.1.orport }}\n   arguments=\"-f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\" enabled=yes state=started\n  with_nested:\n   - tor_ips\n   - tor_ports\n  when: ansible_system == 'OpenBSD'\n  tags:\n   - openbsd\n\n\n# FreeBSD section\n# ================\n\n- name: Ensure Tor instances are reloaded if its torrc changed (FreeBSD)\n  sudo: yes\n  shell: \"kill -HUP `cat {{ tor_PidDir }}/{{ item.item[0] }}_{{ item.item.1.orport }}.pid`\"\n  ignore_errors: yes\n  with_items: instances.results\n  when: item.changed == True and ansible_system == 'FreeBSD'\n  tags:\n   - freebsd\n   - configure\n\n- name: Ensure Tor instances are running (FreeBSD)\n  sudo: yes\n  shell: \"kill -0 `cat {{ tor_PidDir }}/{{ item[0] }}_{{ item.1.orport }}.pid` || tor -f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n  when: ansible_system == 'FreeBSD'\n  tags:\n   - freebsd\n"}, {"commit_sha": "35ca6852d9333ef6c3ed223239f45b840c487d60", "sha": "2656cd552f9584df7ff3f562b9d3f8f3dbb6fce0", "filename": "roles/docker/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for docker\n- name: Restart docker\n  service:\n   name: docker\n   state: restarted\n  sudo: yes\n"}, {"commit_sha": "35ca6852d9333ef6c3ed223239f45b840c487d60", "sha": "f23655c8e8bc97b4c08002412da39a92caf5b258", "filename": "roles/dnsmasq/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for dnsmasq\n- name: remove dnsmasq override\n  file:\n    path: /etc/init/dnsmasq.override\n    state: absent\n  tags:\n    - dnsmasq\n\n- name: ensure dnsmasq is running (and enable it at boot)\n  service:\n    name: dnsmasq\n    state: started\n    enabled: yes\n  tags:\n    - dnsmasq\n\n- name: configure dnsmasq\n  sudo: yes\n  template:\n    src: 10-consul.j2\n    dest: /etc/dnsmasq.d/10-consul\n    owner: root\n    group: root\n    mode: 0644\n  notify:\n    - Restart dnsmasq\n  tags:\n    - dnsmasq\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "2f43b2d11fb58c801cd8f7bb6ff7a77c7ef340c4", "filename": "roles/dcos_cli/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for dcos-cli\ndcos_cli_image: capgemini/dcos-cli\ndcos_cli_zk_master_peers: \"zk://{{ zookeeper_peers_nodes }}/mesos\"\ndcos_cli_mesos_master_url: \"http://{{ ansible_ssh_host }}:5050\"\ndcos_cli_marathon_url: \"http://{{ ansible_ssh_host }}:8080\"\ndcos_cli_no_proxy: \"{{ ansible_ssh_host }}:8080,{{ ansible_ssh_host }}:5050\"\ndcos_cli_sources: '[\"https://github.com/Capgemini/universe/archive/version-1.x.zip\",]'\ndcos_cli_container_environment:\n  http_proxy: \"{{ proxy_env.http_proxy }}\"\n  https_proxy: \"{{ proxy_env.https_proxy }}\"\n  HTTP_PROXY: \"{{ proxy_env.HTTP_PROXY }}\"\n  HTTPS_PROXY: \"{{ proxy_env.HTTPS_PROXY }}\"\n  no_proxy: \"{{ dcos_cli_no_proxy }}\"\n  NO_PROXY: \"{{ dcos_cli_no_proxy }}\"\n  MESOS_MASTER_URL: \"{{ dcos_cli_mesos_master_url }}\"\n  MARATHON_URL: \"{{ dcos_cli_marathon_url }}\"\n  SOURCES: \"{{ dcos_cli_sources }}\"\n\ndcos_cli_frameworks_list:\n  - cassandra\n  - chronos\n  - exhibitor\n\n# Type flag allows you to set up a command which you want to use to run an app.\n# To run one app use \"type: app\" and to run group of apps use \"type: group\".\ndcos_cli_apps_list:\n  - { name: prometheus, type: app }\n  - { name: promdash, type: group }\n"}, {"commit_sha": "b02504a0a0a8b0e4169d0327a865dfe08866e9ec", "sha": "fa5a668116d260dc603d0cccc2503f3bea71ad85", "filename": "tasks/rabbit.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/rabbit.yml: Deploy RabbitMQ and set-up vhost for Sensu messaging\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - include: \"{{ ansible_distribution }}/rabbit.yml\"\n\n  - name: Ensure RabbitMQ SSL directory exists\n    file: dest={{ rabbitmq_config_path }}/ssl state=directory\n\n  - name: Ensure RabbitMQ SSL certs/keys are in place\n    copy: src={{ item }} dest={{ rabbitmq_config_path }}/ssl\n    with_items:\n      - \"{{ sensu_ssl_server_cacert }}\"\n      - \"{{ sensu_ssl_server_cert }}\"\n      - \"{{ sensu_ssl_server_key }}\"\n    notify:\n      - restart rabbitmq service\n      - restart sensu-api service\n      - restart sensu-server service\n\n  - name: Deploy RabbitMQ config\n    template:\n      dest: \"{{ rabbitmq_config_path }}/rabbitmq.config\"\n      src: \"{{ rabbitmq_config_template }}\"\n      owner: root\n      group: \"{{ __root_group }}\"\n      mode: 0644\n    notify: restart rabbitmq service\n\n  - name: Ensure RabbitMQ is running\n    service:\n      name: \"{{ rabbitmq_service_name }}\"\n      state: started\n      enabled: true\n    register: rabbitmq_state\n\n  - name: Wait for RabbitMQ to be up and running before asking to create a vhost\n    pause: seconds=3\n    when: rabbitmq_state|changed\n\n  - block:\n    - name: Ensure Sensu RabbitMQ vhost exists\n      rabbitmq_vhost: name={{ rabbitmq_sensu_vhost }} state=present\n\n    - name: Ensure Sensu RabbitMQ user has access to the Sensu vhost\n      rabbitmq_user:\n        user: \"{{ rabbitmq_sensu_user_name }}\"\n        password: \"{{ rabbitmq_sensu_password }}\"\n        vhost: \"{{ rabbitmq_sensu_vhost }}\"\n        configure_priv: .*\n        read_priv: .*\n        write_priv: .*\n        state: present\n    become: true\n    become_user: rabbitmq\n"}, {"commit_sha": "9966c6de1ed4ef5071a9bea83b4bb69a11dd32ba", "sha": "2af660284841bf389715f654682f4f78069c993d", "filename": "roles/weave/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for weave\n- name: Up weave interface\n  shell: ifup weave\n  sudo: yes\n\n- name: Down weave interface\n  shell: ifdown weave\n  sudo: yes\n\n- name: Restart networking\n  service: name=networking state=restarted\n  sudo: yes\n\n- name: Weave launch\n  command: /usr/local/bin/weave launch {{ weave_launch_peers }}\n  sudo: yes\n  tags:\n    - weave\n"}, {"commit_sha": "8cf75eb68465f1126872131afd102e05068a9df2", "sha": "e5719908effba9837433672d417a807367e56803", "filename": "tasks/apt_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Setup Debian specific variables (set_fact)\n  set_fact:\n    tor_user: debian-tor\n  tags:\n   - configure\n   - createdir\n\n- name: Ensure torproject gpg key is installed (A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89)\n  sudo: yes\n  apt_key: data=\"{{ lookup('file', 'deb.torproject.org_A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89.pub') }}\"\n    id=A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89\n    state=present\n\n- name: Ensure torproject.org repository is present (APT)\n  sudo: yes\n  apt_repository: repo='deb http://deb.torproject.org/torproject.org {{ tor_distribution_release }} main'\n    state=present \n    update_cache=yes\n\n# waiting for trac ticket #14997\n#- name: Ensure  torproject.org alpha repo is present (if enabled)\n#  apt_repository: >\n#    repo='deb http://deb.torproject.org/torproject.org  main'\n#    state=present \n#    update_cache=yes\n#  when: tor_alpha is True\n\n# we specifically opt for present over latest to improve performance\n# \"latest\" is covered by auto updates\n- name: Ensure Tor is installed (APT)\n  sudo: yes\n  apt: pkg=\"{{ item }}\" state=present\n  with_items: \n    - deb.torproject.org-keyring\n    - tor\n  # apt starts a tor client instance by default after installing the package\n  # we do not need that\n  notify:\n    - stop tor\n    - disable-sysv-debian tor\n\n- name: Ensure the presence of the multi-instance systemd unit file (Debian)\n  sudo: yes\n  template: src=debian_tor@.service dest=/lib/systemd/system/tor@.service owner=root mode=0644 backup=yes\n  when: ansible_distribution == 'Debian'\n  notify: systemctl daemon-reload\n\n- name: Ensure the presence of the multi-instance systemd unit file (Ubuntu)\n  sudo: yes\n  copy: src=ubuntu_tor@.service dest=/lib/systemd/system/tor@.service owner=root mode=0644 backup=yes\n  when: ansible_distribution == 'Ubuntu'\n  notify: systemctl daemon-reload\n\n- name: Ensure AppArmor allows access to necessary files (Ubuntu)\n  sudo: yes\n  lineinfile: dest=/etc/apparmor.d/local/system_tor line={{ item }}\n  with_items:\n    - '/etc/tor/enabled/*\\ r,'\n    - '/{,var/}run/tor/*.pid\\ w,'\n    - '/var/lib/tor/**\\ w,'\n  when: ansible_distribution == 'Ubuntu'\n  notify: restart apparmor\n\n- meta: flush_handlers\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "91fe5c902f4b1022e0a136d8b4ce352a76448d0f", "filename": "roles/dockerbench/vars/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# vars file for dockerbench\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "43f9d94804c968a0d411c18c5f0b5b641c9ec24e", "filename": "tasks/dnsmasq.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# File: dnsmasq.yml - Dnsmasq tasks for Consul\n\n- name: Install Dnsmasq package\n  yum:\n    name: dnsmasq\n    state: present\n  when: ansible_os_family == \"RedHat\"\n  tags: dnsmasq, installation\n\n- name: Install Dnsmasq package\n  apt:\n    name: dnsmasq\n    state: present\n  when: ansible_os_family == \"Debian\"\n  tags: dnsmasq, installation\n\n- name: Install Dnsmasq package\n  pkgng:\n    name: dnsmasq\n    state: present\n  when: ansible_os_family == \"FreeBSD\"\n  tags: dnsmasq, installation\n\n- name: Enable dnsmasq service\n  service:\n    name: dnsmasq\n    enabled: true\n  tags: dnsmasq\n\n- name: Create Dnsmasq configuration directory\n  file:\n    path: /usr/local/etc/dnsmasq.d\n    state: directory\n    owner: root\n    group: wheel\n  when: ansible_os_family == \"FreeBSD\"\n  tags: dnsmasq\n\n- name: Create Dnsmasq configuration\n  template:\n    src: dnsmasq-10-consul.j2\n    dest: /etc/dnsmasq.d/10-consul\n    owner: root\n    group: root\n    mode: 0644\n  notify: restart dnsmasq\n  when: ansible_os_family in [\"Debian\", \"RedHat\"]\n  tags: dnsmasq\n\n- name: Create FreeBSD-specific configuration\n  lineinfile:\n    dest: /usr/local/etc/dnsmasq.conf\n    line: 'conf-dir=/usr/local/etc/dnsmasq.d/,*.conf'\n  notify: restart dnsmasq\n  when: ansible_os_family == \"FreeBSD\"\n  tags: dnsmasq\n\n- name: Create FreeBSD-specific Dnsmasq configuration\n  template:\n    src: dnsmasq-10-consul.j2\n    dest: /usr/local/etc/dnsmasq.d/consul.conf\n    owner: root\n    group: wheel\n    mode: 0644\n  notify: restart dnsmasq\n  when: ansible_os_family == \"FreeBSD\"\n  tags: dnsmasq\n"}, {"commit_sha": "cb054bd0ed781881ab5d259917184c0ff4b006a7", "sha": "74a56e51051f294d2be3795f9b9ef73c19d0638c", "filename": "tasks/section_12_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 12.1 Verify Permissions on /etc/passwd (Scored)\n    file: path=/etc/passwd mode=0644\n    tags:\n      - section12\n      - section12.1\n\n  - name: 12.2 Verify Permissions on /etc/shadow (Scored)\n    file: path=/etc/shadow mode='o-rwx,g-rw'\n    tags:\n      - section12\n      - section12.2\n\n  - name: 12.3 Verify Permissions on /etc/group (Scored)\n    file: path=/etc/group mode=0644\n    tags:\n      - section12\n      - section12.3\n\n  - name: 12.4 Verify User/Group Ownership on /etc/passwd (Scored)\n    file: path=/etc/passwd owner=root group=root\n    tags:\n      - section12\n      - section12.4\n\n  - name: 12.5 Verify User/Group Ownership on /etc/shadow (Scored)\n    file: path=/etc/shadow owner=root group=shadow\n    tags:\n      - section12\n      - section12.5\n\n  - name: 12.6 Verify User/Group Ownership on /etc/group (Scored)\n    file: path=/etc/group owner=root group=root\n    tags:\n      - section12\n      - section12.6\n\n  - name: 12.7 Find World Writable Files (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -0002 -print\n    changed_when: False\n    failed_when: False\n    register: world_files\n    tags:\n      - section12\n      - section12.7\n\n  - name: 12.7 Find World Writable Files (Not Scored)\n    debug: msg='{{ item }}'\n    with_items:\n        world_files.stdout_lines\n    tags:\n      - section12\n      - section12.7\n\n  - name: 12.8 Find Un-owned Files and Directories (check) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -nogroup -ls\n    changed_when: False\n    failed_when: False\n    register: unowned_files\n    tags:\n      - section12\n      - section12.8\n\n  - name: 12.8 Find Un-owned Files and Directories (Scored)\n    debug: msg='{{ item }}'\n    with_items:\n        unowned_files.stdout_lines\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.9 Find Un-grouped Files and Directories (check) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -nogroup -ls\n    changed_when: False\n    failed_when: False\n    register: ungrouped_files\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.9 Find Un-grouped Files and Directories (Scored)\n    debug: msg='{{ item }}'\n    with_items:\n        ungrouped_files.stdout_lines\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.10 Find SUID System Executables (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -4000 -print\n    changed_when: False\n    failed_when: False\n    register: suid_files\n    tags:\n      - section12\n      - section12.10\n\n  - name: 12.10 Find SUID System Executables (Not Scored)\n    debug: msg='{{ item }}'\n    with_items:\n        suid_files.stdout_lines\n    tags:\n      - section12\n      - section12.10\n\n  - name: 12.11 Find SGID System Executables (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -2000 -print\n    changed_when: False\n    failed_when: False\n    register: gsuid_files\n    tags:\n      - section12\n      - section12.11\n\n  - name: 12.11 Find SGID System Executables (Not Scored)\n    debug: msg='{{ item }}'\n    with_items:\n        gsuid_files.stdout_lines\n    tags:\n      - section12\n      - section12.10\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "4546928cdb815f68f638b5e6ed9d0271d4049455", "filename": "roles/weave/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: upload weave template service\n  template:\n    src: weave.conf.j2\n    dest: \"/etc/init/weave.conf\"\n    mode: 0755\n  sudo: yes\n  tags:\n    - weave\n\n- name: ensure weave service is running.\n  sudo: yes\n  service:\n    name: weave\n    state: started\n    enabled: yes\n\n- name: wait for weave socket to be ready.\n  wait_for:\n    port: 6783\n    delay: 10\n\n- name: download weave scope\n  get_url:\n    url: \"{{ weave_scope_url }}\"\n    dest: \"{{ weave_scope_dest }}\"\n    mode: 0755\n    validate_certs: no\n  environment: proxy_env\n  when: weave_scope_enabled\n  tags:\n    - weave\n\n- name: upload weave scope template service\n  template:\n    src: scope.conf.j2\n    dest: \"/etc/init/weavescope.conf\"\n    mode: 0755\n  sudo: yes\n  when: weave_scope_enabled\n  tags:\n    - weave\n\n# Flush handlers so we restart the Docker process here with the weave network\n# enabled and containers correctly start in the weave network.\n- meta: flush_handlers\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "06ddc217f9ccc0bc7856a3f9ab41a2341dfb308a", "filename": "meta/main.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "galaxy_info:\n  author: Calum MacRae\n  description: Deploy a full Sensu monitoring stack; including redis, RabbitMQ & the Uchiwa dashboard\n  license: MIT\n  min_ansible_version: 2.0\n  platforms:\n  - name: EL\n    versions:\n  #  - all\n  #  - 5\n  #  - 6\n    - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Solaris\n  #  versions:\n  #  - all\n  #  - 10\n  #  - 11.0\n  #  - 11.1\n  #  - 11.2\n  #  - 11.3\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #  - 21\n  #  - 22\n  #  - 23\n  #- name: Windows\n  #  versions:\n  #  - all\n  #  - 2012R2\n  - name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  # - name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  - name: FreeBSD\n    versions:\n  #  - all\n  #  - 10.0\n  #  - 10.1\n    - 10.2\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  #  - 9.3\n  - name: Ubuntu\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n  #  - trusty\n  #  - utopic\n    - vivid\n  #  - wily\n  #  - xenial\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  - name: Debian\n    versions:\n  #  - all\n  #  - etch\n    - jessie\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n\n  galaxy_tags:\n    - cloud\n    - monitoring\n    - system\n    - web\n    - sensu\n    - rabbitmq\n    - redis\n    - metrics\n    - amqp\n    - alerting\n    - stack\n    - dashboard\ndependencies: []\n  # List your role dependencies here, one per line.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "00873560d809017a23bc430ae9a087b3ec2fd2d9", "filename": "tasks/section_04_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 4.1.1 Restrict Core Dumps (Scored)\n    lineinfile: dest='/etc/security/limits.conf' line=\"* hard core 0\" state=present\n    tags:\n      - section4\n      - section4.1\n      - section4.1.1\n\n  - name: 4.1.2 Restrict Core Dumps (Scored)\n    sysctl: >\n        name=fs.suid_dumpable\n        value=0\n        state=present\n    when: restrict_core_dumps == True\n    tags:\n      - section4\n      - section4.1\n      - section4.1.2\n\n  - name: 4.1.4 Restrict Core Dumps (stat file) (Scored)\n    stat: path='/etc/init/apport.conf'\n    register: apport_present\n    tags:\n      - section4\n      - section4.1\n      - section4.1.4\n\n  - name: 4.1.5 Restrict Core Dumps (Scored)\n    lineinfile: >\n        dest='/etc/init/apport.conf'\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n    when: apport_present.stat.exists == True\n    tags:\n      - section4\n      - section4.1\n      - section4.1.3\n\n  - name: 4.1.6 Restrict Core Dumps (stat file) (Scored)\n    stat: path='/etc/init/whoopsie.conf'\n    register: whoopsie_present\n    tags:\n      - section4\n      - section4.1\n      - section4.1.4\n\n  - name: 4.1.7 Restrict Core Dumps (Scored)\n    lineinfile: >\n        dest='/etc/init/whoopsie.conf'\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n    when: whoopsie_present.stat.exists == True\n    tags:\n      - section4\n      - section4.1\n      - section4.1.4\n\n  - name: 4.2 Enable XD/NX Support on 32-bit x86 Systems (read dmesg) (Not Scored)\n    shell: 'dmesg | grep NX'\n    register: nx_result\n    failed_when: nx_result.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section4\n      - section4.2\n\n  - name: 4.3 Enable Randomized Virtual Memory Region Placement (Scored)\n    sysctl: >\n       name=kernel.randomize_va_space\n       value=2\n       state=present\n    when: enable_aslr\n    tags:\n      - section4\n      - section4.3\n\n  - name: 4.4.1 Disable Prelink (check) (Scored)\n    stat: path=/usr/sbin/prelink\n    register: prelink_rc\n    tags:\n      - section4\n      - section4.4\n\n  - name: 4.4.2 Disable Prelink (restore) (Scored)\n    command: '/usr/sbin/prelink -ua'\n    when: prelink_rc.stat.exists == True\n    tags:\n      - section4\n      - section4.4\n\n  - name: 4.4.3 Disable Prelink (remove) (Scored)\n    apt: purge=yes name='prelink' state=absent\n    when: prelink_rc.stat.exists == True\n    tags:\n      - section4\n      - section4.4\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "b044e772219734ae3782cd6e89d9e5fbb490b344", "filename": "roles/serverspec/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for serverspec\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "b60459ee38841ad11df7e8033d758e51a82be1c6", "filename": "roles/traefik/meta/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Graham Taylor\n  description:\n  company: Capgemini\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (MIT)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: CoreOS\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n  #   - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies:\n  - role: handlers\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "577dd25a8d24bfe2e1311dfc0fcce9be0ba238b7", "filename": "roles/prometheus/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "# tasks for running prometheus\n- name: create prometheus config dir\n  file:\n    path: \"{{ prometheus_config_dir }}\"\n    state: directory\n    mode: 0755\n  sudo: yes\n  tags:\n    - prometheus\n\n- name: upload prometheus config file\n  template:\n    src: prometheus.yml.j2\n    dest: \"{{ prometheus_config_dir }}/prometheus.yml\"\n    mode: 0755\n  sudo: yes\n  tags:\n    - prometheus\n\n- name: run prometheus node exporter container\n  docker:\n    name: node-exporter\n    image: \"{{ prometheus_node_exporter_image }}\"\n    state: started\n    restart_policy: always\n    net: host\n    ports:\n    - \"{{ prometheus_node_exporter_port }}:{{ prometheus_node_exporter_port }}\"\n  environment: proxy_env\n  tags:\n    - prometheus\n\n#- name: Set node-exporter consul service definition\n#  sudo: yes\n#  template:\n#    src: node-exporter-consul.j2\n#    dest: \"{{ prometheus_consul_dir }}/node-exporter.json\"\n#  notify:\n#    - restart consul\n#  tags:\n#    - prometheus\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "5493082be6cd2b672046bd6b5641dc00a0f84b86", "filename": "roles/mistral/tasks/install_deps.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "- name: Install dependencies\n  sudo: true\n  apt:\n    name: \"{{ item }}\"\n    update_cache: yes\n  with_items:\n    - git\n    - libssl-dev\n    - libyaml-dev\n    - libffi-dev\n    - libxml2-dev\n    - libxslt1-dev\n    - libpq-dev\n    - python-dev\n    - python-pip\n\n- name: Install pip virtualenv\n  sudo: true\n  pip:\n    name: virtualenv\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "3a984d47d799ee4688a3024abfde10fb4d17ea9f", "filename": "playbooks/requirements.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n- hosts: all\n  tasks:\n  - name: Install galaxy dependencies\n    command: ansible-galaxy install -r roles/mistral/requirements.yml\n    delegate_to: 127.0.0.1\n    run_once: true\n"}, {"commit_sha": "1bb50a6149f6ff7f2e6399411418d088e2c52d01", "sha": "e28a6fe7ab706577fb760c8d60789ea23b75deea", "filename": "tasks/section_04_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: Check if the grub config file exists (Not Scored)\n    stat: path=/etc/default/grub\n    register: grub_cfg_file\n\n  - name: Determines if apparmor is set in grub config (Not Scored)\n    command: \"grep 'GRUB_CMDLINE_LINUX' /etc/default/grub\"\n    register: grub_apparmor\n    changed_when: False\n    when: grub_cfg_file.stat.exists\n\n  - name: Check if the extlinux config file exists (Not Scored)\n    stat: path=/extlinux.conf\n    register: extlinux_cfg_file\n\n  - name: Determines if apparmor is set in extlinux (Not Scored)\n    command: \"grep 'apparmor' /extlinux.conf\"\n    register: extlinux_apparmor\n    changed_when: False\n    when: extlinux_cfg_file.stat.exists\n\n  - name: Determines if apparmor is already set in boot config (Not Scored)\n    command: \"grep CONFIG_DEFAULT_SECURITY_APPARMOR /boot/config-{{ ansible_kernel }}\"\n    register: boot_apparmor\n    changed_when: False\n\n  - name: 4.5 Activate AppArmor (install) (Scored)\n    apt: >\n        name=apparmor\n        state=present\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (Kernel LSM - grub) (Scored)\n    lineinfile: >\n        dest='/etc/default/grub'\n        regexp='^GRUB_CMDLINE_LINUX=\"\"'\n        line='GRUB_CMDLINE_LINUX=apparmor=\"1 security=apparmor\"'\n        state=present\n    when: \"(use_apparmor == True) and grub_cfg_file.stat.exists and ('apparmor' not in grub_apparmor['stdout']) and ('not set' in boot_apparmor['stdout'])\"\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (Kernel LSM - extlinux) (Scored)\n    lineinfile: >\n        dest='/extlinux.conf'\n        regexp=\"^append initrd=\"\n        line=\"append initrd={{ ansible_cmdline['initrd'] }} root={{ ansible_cmdline['root'] }} console=tty0 console={{ ansible_cmdline['console'] }} apparmor=1 security=apparmor ro quiet\"\n    when: \"(use_apparmor == True) and extlinux_cfg_file.stat.exists and ('apparmor' not in extlinux_apparmor['stdout']) and ('not set' in boot_cfg_apparmor['stdout'])\"\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (start) (Scored)\n    service: >\n        name=apparmor\n        state=started\n    when: use_apparmor == True\n    register: apparmor_status\n    ignore_errors: True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Determine if Apparmor started without error (Not Scored)\n    fail: msg=\"Apparmor can not be started. This is normal behavior if you run the playbook for the first time.\\nPlease reboot the machine and run it again to proceed with the rest of the playbook.\"\n    when: apparmor_status.failed is defined\n\n  - name: 4.5 Fix rsyslog /run/utmp permissions (Not Scored)\n    lineinfile: >\n        dest=\"/etc/apparmor.d/usr.sbin.rsyslogd\"\n        line=\"  /run/utmp rk,\"\n        insertbefore=\"  /var/spool/rsyslog/ r,\"\n        state=present\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (fix profiles) (Scored)\n    service: >\n        name=rsyslog\n        state=restarted\n    changed_when: False\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (Scored)\n    command: apparmor_status\n    register: aa_status_lines\n    failed_when: '\"0 profiles are loaded\" in aa_status_lines.stdout_lines or \"0 processes are in complain mode.\" not in aa_status_lines.stdout_lines or \"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n        # - '\"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n    changed_when: False\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (enforce install) (Scored)\n    apt: >\n        name=apparmor-utils\n        state=present\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (enforce) (Scored)\n    #shell: 'aa-enforce /etc/apparmor.d/*'\n    shell: for profile in /etc/apparmor.d/*; do aa-enforce $profile; done\n    register: aaenforce_rc\n    failed_when: aaenforce_rc.rc == 1\n    changed_when: False\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "644bf103420fb8b2f1717613a804d9d2a2f02c46", "filename": "roles/dcos_cli/tasks/apps.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- include_vars: \"{{ item.name }}.yml\"\n  with_items:\n    - \"{{ dcos_cli_apps_list }}\"\n\n# Create the JSON files for apps\n- name: create json files for apps\n  when: \"dcos_cli_app_{{ item.name }}_enabled | bool\"\n  run_once: true\n  template:\n    src: '{{ item.name }}.json.j2'\n    dest: \"/etc/marathon/{{ item.name }}.json\"\n    mode: 0755\n  become: yes\n  tags:\n    - \"{{ item.name }}\"\n    - dcos_cli\n  with_items:\n    - \"{{ dcos_cli_apps_list }}\"\n\n- name: add marathon app via dcos-cli\n  when: \"dcos_cli_app_{{ item.name }}_enabled | bool\"\n  run_once: true\n  docker:\n    name: \"{{ item.name }}\"\n    image: \"{{ dcos_cli_image }}\"\n    state: started\n    command: \"marathon {{ item.type }} add /config/{{ item.name }}.json\"\n    volumes:\n      - \"/etc/marathon:/config\"\n    env:\n      \"{{ dcos_cli_container_environment }}\"\n  tags:\n    - \"{{ item.name }}\"\n    - dcos_cli\n  with_items:\n    - \"{{ dcos_cli_apps_list }}\"\n\n\n- name: remove marathon app via dcos-cli\n  when: \"not dcos_cli_app_{{ item.name }}_enabled | bool\"\n  run_once: true\n  docker:\n    name: \"{{ item.name }}\"\n    image: \"{{ dcos_cli_image }}\"\n    state: started\n    command: \"marathon {{ item.type }} remove {{ item.name }}\"\n    env:\n      \"{{ dcos_cli_container_environment }}\"\n  tags:\n    - \"{{ item.name }}\"\n    - dcos_cli\n  with_items:\n    - \"{{ dcos_cli_apps_list }}\"\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "e1b353d696dcfa65d134ee1bd70b183088a50b2e", "filename": "roles/zookeeper/meta/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Graham Taylor\n  description:\n  company: Capgemini\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (MIT)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: CoreOS\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n  #- trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies:\n  - role: handlers\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "f78df9481cb2da316c9aa3add5f5ca27af2c3aa6", "filename": "roles/dcos_cli/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for dcos-cli\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "0db73efca087cbb62839ca672f89cb27c9fc8094", "filename": "roles/docker/meta/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Graham Taylor\n  description:\n  company: Capgemini\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (MIT)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: Ubuntu\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n     - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies: []\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "0f3f1a5a0c3b6c644d6274f03b2cfa6e62a437d2", "filename": "roles/zookeeper/meta/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Graham Taylor\n  description:\n  company: Capgemini\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (MIT)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: Ubuntu\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n     - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies:\n  - role: handlers\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "af3dfdf7cf37437f5609f1a12e4ac7cbaebd4867", "sha": "8e6cf647d542978608e58cd2ed9336342061b4fe", "filename": "roles/registrator/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for registrator\nregistrator_image: \"gliderlabs/registrator:master\"\nregistrator_uri: \"consul://{{ ansible_default_ipv4.address }}:8500\"\n\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "ce3131d53d4af010d6013ce86ecd1940818546a5", "filename": "roles/st2/tasks/1.requirements.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "# Check if system requirements were met to install StackStorm\n---\n- name: requirements | Check if there is enough memory\n  fail:\n    msg: \"At least {{ st2_required_memory }}MB is required for st2 installation! Current: {{ ansible_memtotal_mb }}MB.\"\n  when: ansible_memtotal_mb < st2_required_memory|int\n  tags: [st2, requirements]\n\n# TODO: Trigger disc space check only for fresh install, handle cases when Mongo config is not default\n- name: requirements | Get available disk space\n  shell: df -Pk /var/lib | grep -vE '^Filesystem|tmpfs|cdrom' | awk '{print $4}'\n  register: free_disk_space\n  changed_when: False\n  tags: [st2, requirements]\n\n- name: requirements | Check if there is enough disc space\n  fail:\n    msg: \"At least {{ st2_required_space }}MB in /var/lib is required for st2 installation!\"\n  when: free_disk_space.stdout < st2_required_space\n  tags: [st2, requirements]\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "465ac0a51eac1b2c048da66e52f4d783fc80f5f6", "filename": "roles/st2/tasks/6.upstart.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "# Create upstart scripts for st2 components\n---\n- name: upstart | Create init configs from templates\n  sudo: true\n  template:\n    src: \"{{ item }}\"\n    dest: \"/etc/init/{{ item | basename | regex_replace('.j2', '.conf') }}\"\n    mode: 0644\n    group: root\n    group: root\n  when: (item | dirname | basename) in st2_packages\n  with_fileglob:\n    - ../templates/*/*.j2\n  register: init_configs\n  tags: [st2, upstart]\n\n- name: upstart | Create st2actionrunner workers\n  sudo: true\n  template:\n    src: st2actions/st2actionrunner-worker.conf\n    dest: \"/etc/init/st2actionrunner-{{ item }}.conf\"\n    mode: 0644\n    group: root\n    group: root\n  with_sequence: count=\"{{ st2_action_runners }}\"\n  when: \"'st2actions' in st2_packages\"\n  tags: [st2, upstart]\n\n- name: upstart | Create list of st2 services\n  set_fact:\n    st2_services: \"{{ init_configs.results | selectattr('item', 'defined') | map(attribute='item') |\n                  map('basename') | map('regex_replace', '.j2', '') | list() }}\"\n  tags: [st2, upstart]\n\n- name: upstart | Enable st2 init services\n  sudo: true\n  service:\n    name: \"{{ item }}\"\n    enabled: yes\n  with_items: st2_services\n  notify:\n    - restart st2\n  tags: [st2, upstart]\n"}, {"commit_sha": "cb153a13ab607e1c015fec227d8f74cfbb3d9b8e", "sha": "8b5339299fbf40822d3e8aabbbf5f4437cbb21d3", "filename": "meta/main.yml", "repository": "willshersystems/ansible-sshd", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Matt Willsher\n  description: OpenSSH SSH deamon configuration\n  company: Willsher Systems\n  license: LGPLv3\n  min_ansible_version: 1.8\n  platforms:\n  - name: Debian\n    versions:\n    - wheezy\n    - jessie\n  - name: Ubuntu\n    versions:\n    - precise\n    - trusty\n  - name: FreeBSD\n    version:\n    - 10.1\n  - name: EL\n    versions:\n    - 6\n    - 7\n  - name: Fedora\n    versions:\n    - 22\n    - 23\n  galaxy_tags:\n  - networking\n  - system\n  - SSH \n  - OpenSSH\n  - sshd\n  - server\n  - ubuntu\n  - debian\n  - centos\n  - redhat\n  - freebsd\ndependencies: []\n"}, {"commit_sha": "b02504a0a0a8b0e4169d0327a865dfe08866e9ec", "sha": "11ba46fbac6c5358defbb5539a0a145ad9873ce3", "filename": "tasks/SmartOS/main.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/SmartOS/main.yml: \"Set-up\" playbook for cmacrae.sensu role\n# This takes care of base prerequisites for Joyent SmartOS\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure the Sensu group is present\n    group: name={{ sensu_group_name }} state=present\n             \n  - name: Ensure the Sensu user is present\n    user:\n      name: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      shell: /bin/false\n      home: \"{{ sensu_config_path }}\"\n      createhome: true\n      state: present\n\n  - name: Ensure the Sensu config directory is present\n    file:\n      dest: \"{{ sensu_config_path }}/conf.d\"\n      state: directory\n      recurse: true\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n\n  - name: Ensure Sensu dependencies are installed\n    pkgin: name=build-essential,ruby21-base state=present\n\n  - name: Ensure Sensu is installed\n    gem: name=sensu state={{ sensu_gem_state }} user_install=no\n    notify:\n      - restart sensu-client service\n    \n  - name: Ensure Sensu 'plugins' gem is installed\n    gem: name=sensu-plugin state={{ sensu_plugin_gem_state }} user_install=no\n"}, {"commit_sha": "c5ee48e16a5905db37ff878be57f5de16f769368", "sha": "5a03ce9abd50bd9d9028e72fa82a250b7834a51a", "filename": "tasks/section_04_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 4.5 Activate AppArmor (install) (Scored)\n    apt: >\n        name=apparmor\n        state=present\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (start) (Scored)\n    service: >\n        name=apparmor\n        state=started\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n      \n  - name: 4.5 Activate AppArmor (fix profiles) (Scored)\n    service: >\n        name=rsyslog\n        state=restarted\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (Scored)\n    command: apparmor_status\n    register: aa_status_lines\n    failed_when: '\"0 profiles are loaded\" in aa_status_lines.stdout_lines or \"0 processes are in complain mode.\" not in aa_status_lines.stdout_lines or \"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n        # - '\"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n    changed_when: False\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (enforce install) (Scored)\n    apt: >\n        name=apparmor-utils\n        state=present\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (enforce) (Scored)\n    #shell: 'aa-enforce /etc/apparmor.d/*'\n    shell: for profile in /etc/apparmor.d/*; do aa-enforce $profile; done\n    register: aaenforce_rc\n    failed_when: aaenforce_rc.rc == 1\n    changed_when: False\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "b5e2261dacdb32528cb24c0d30979fe787d560de", "filename": "tasks/Debian/dashboard.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/Debian/dashboard.yml: Deployment of the Uchiwa dashboard\n# Specific to Debian\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Install uchiwa\n    apt:\n      name: uchiwa\n      state: present\n\n  - name: Deploy Uchiwa config\n    template:\n      src: uchiwa_config.json.j2\n      dest: \"{{ sensu_config_path }}/uchiwa.json\"\n    notify: restart uchiwa service\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "0a7b9ab2ab4a04bb96eba918b1cacb765ddcfb11", "filename": "roles/mesos_maintenance/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for mesos-maintenance\nmesos_maintenance_server_group: mesos_slaves\nmesos_maintenance_server_master_group: mesos_masters\nmesos_maintenance_master_url: ''\nmesos_maintenance_starting_time: ''\nmesos_maintenance_duration: ''\nmesos_maintenance_schedule: false\nmesos_maintenance_start: false\nmesos_maintenance_complete: false\n"}, {"commit_sha": "15d2da095f9bd54a50954dee18597710e1951943", "sha": "29f8c7350cd28af48009cd23159fefc2ee93fac2", "filename": "tasks/check_environment.yml", "repository": "ansiblebit/oracle-java", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# file: oracle-java/tasks/check_environment.yml\n#\n# task to set host facts:\n#   - Java is installed?\n#   - which Java version is installed?\n#\n\n- name: determine if Java is already installed\n  shell: which java\n  register: oracle_java_task_installed\n  changed_when: oracle_java_task_installed.rc != 0\n  failed_when: no\n# oracle_java_installed.rc == 0 : installed\n# oracle_java_installed.rc == 1 : not installed\n\n- name: set fact oracle_java_installed\n  set_fact:\n    oracle_java_installed={{ not oracle_java_task_installed.changed }}\n\n- name: determine which Java version is installed\n  shell: java -version\n  when: oracle_java_installed\n  register: oracle_java_task_version\n  changed_when: False\n\n- name: set fact oracle_java_installed_version\n  set_fact:\n    oracle_java_version_installed=\"{{ oracle_java_task_version.stderr.split('\\n')[0]|regex_replace('.*\\\"(.*)\\\"','\\\\1') }}\"\n  when: oracle_java_task_version is defined and oracle_java_task_version.stdout is defined\n  changed_when: False\n\n- debug:\n    var=\"{{ item }}\"\n  when: item is defined and debug | default(false)\n  with_items:\n    - oracle_java_installed\n    - oracle_java_task_installed\n    - oracle_java_task_version\n    - oracle_java_version_installed\n    - oracle_java_version_string\n"}, {"commit_sha": "dc73f16743fa376672b427980c6ca044dd6fa68a", "sha": "85706f25e38ce19573014fe5e43a3391fcd02f4d", "filename": "tasks/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Get ansible version\n  shell:  ansible --version|head -1|cut -d\" \" -f2\n  delegate_to: 127.0.0.1\n  register: ansibleversion\n\n- name: Check for vulnerable ansible version (CVE-2016-8614, CVE-2016-8628)\n  assert:\n    that:\n      - \"{{ ansibleversion.stdout | version_compare('2.1.3.0', '>=') }}\"\n    msg: \"VULNERABLE ansible version DETECTED, please update to v2.1.3 or newer! Exiting.\"\n\n- include: ip-list.yml\n  tags:\n    - always\n\n- include: apt_prepare.yml\n  when: ansible_pkg_mgr == 'apt'\n  tags:\n   - debian\n   - install\n\n- include: rpm_prepare.yml\n  when: ansible_os_family == 'RedHat'\n  tags:\n   - centos\n   - fedora\n   - install\n\n- include: openbsd_prepare.yml\n  when: ansible_system == 'OpenBSD'\n  tags:\n   - openbsd\n\n- include: freebsd_prepare.yml\n  when: ansible_system == 'FreeBSD'\n  tags:\n   - freebsd\n\n# we specifically opt for present over latest to improve performance\n- name: Ensure tor is installed\n  become: yes\n  package:\n    name: \"{{ item }}\"\n    state: present\n  with_items: \"{{ tor_packages }}\"\n  # apt starts a tor client instance by default after installing the package\n  # we do not need that\n  notify:\n    - stop-and-mask default tor instance\n    - disable default tor instance FreeBSD\n  tags:\n   - openbsd\n   - freebsd\n   - debian\n   - centos\n   - fedora\n   - install\n\n- meta: flush_handlers\n\n- include: configure.yml\n  tags:\n   - debian\n   - centos\n   - fedora\n   - openbsd\n   - freebsd\n\n- include: linux_service.yml\n  when: ansible_system == 'Linux'\n  tags:\n   - debian\n   - centos\n   - fedora\n\n- include: openbsd_service.yml\n  when: ansible_system == 'OpenBSD'\n  tags:\n   - openbsd\n\n- include: freebsd_service.yml\n  when: ansible_system == 'FreeBSD'\n  tags:\n   - freebsd\n"}, {"commit_sha": "694a4890fcf0daa375d6a173511f6ff7dd0f2335", "sha": "14c8049b3d7fc1bfa59b8264c47fd11709d353fe", "filename": "tasks/configure.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Ensure local DataDir folders exist (LOCAL)\n  file: path={{ offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item[0] }}_{{ item.1.orport }}\n    state=directory mode=700\n  delegate_to: 127.0.0.1\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - createdir\n\n- name: Ensure all relay keys exist (LOCAL)\n  local_action: command tor --PublishServerDescriptor 0 --orport 1234 --list-fingerprint --datadirectory \"{{ offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item[0] }}_{{ item.1.orport }}\" --Log \"err stdout\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Generate new Ed25519 signing keys (LOCAL)\n  local_action: command tor --keygen --SigningKeyLifetime {{ tor_signingkeylifetime_days}}\\ days --datadirectory \"{{ offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item[0] }}_{{ item.1.orport }}\" --Log \"err stdout\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - renewkey\n\n- name: Detect duplicate relay keys across relays (LOCAL)\n  shell: sha1sum {{ offline_masterkey_dir }}/*/keys/secret_id_key {{ offline_masterkey_dir }}/*/keys/ed25519_master_id_secret_key|cut -d/ -f1|sort|uniq -d|wc -l\n  delegate_to: 127.0.0.1\n  register: dupcount\n\n- name: Abort on duplicate relay keys\n  fail: msg=\"Duplicate relay key detected! Aborting.\"\n  when: dupcount.stdout != \"0\"\n\n- name: Detect if Ed25519 master keys are on the relay\n  stat: path={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}/keys/ed25519_master_id_secret_key\n  become: yes\n  register: masterkeycheck\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Abort if Ed25519 master keys are on the relay\n  fail: msg=\"\n\n            Ed25519 MASTER KEY detected on the relay - it is NOT supposed to be there! Aborting.\"\n  when: item.stat.exists == True\n  with_items: masterkeycheck.results\n\n- name: Collect fingerprints for MyFamily (LOCAL)\n  shell: cut {{ offline_masterkey_dir }}/*/fingerprint -d\" \" -f2|xargs|sed -e 's/ /,/g'\n  delegate_to: 127.0.0.1\n  register: family\n  tags:\n   - reconfigure\n\n- name: Ensure per-instance tor users exist\n  become: yes\n  user: name=_tor-{{ item[0] }}_{{ item.1.orport }} system=yes shell=/bin/false createhome=no home={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure per-instance config folders exist (Debian only)\n  become: yes\n  file: path={{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }} state=directory mode=755\n  with_nested:\n   - tor_ips\n   - tor_ports\n  when: ansible_pkg_mgr == 'apt'\n\n- name: Ensure DataDir exists\n  become: yes\n  file: path={{ tor_DataDir }}\n    state=directory\n    owner=root\n    mode=0755\n\n- name: Ensure \"keys\" subfolder exists\n  become: yes\n  file: path={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}/keys\n    state=directory\n    owner=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n    group=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n    mode=0700\n    recurse=yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure RSA key is in place (without overriding existing keys)\n  become: yes\n  copy: src={{ offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}\n   dest={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}\n   owner=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n   mode=700 force=no\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'secret_id_key' ]\n\n- name: Fetch RSA key for comparision\n  become: yes\n  fetch: src={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}\n    dest={{ offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}.untrustedremotekey\n    flat=yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'secret_id_key' ]\n\n- name: Compare local vs. remote RSA key (secret_id_key)\n  local_action: shell sha1sum {{ offline_masterkey_dir }}/{{ inventory_hostname }}-\"{{ item[0] }}_{{ item.1.orport }}\"/keys/secret_id_key*|cut -d/ -f1|uniq -d|wc -l\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  register: rsakey\n\n- name: Abort if local and remote RSA keys do not match\n  fail: 'msg=\"\n\n\n   Key MISMATCH detected: Remote RSA key does not match local key - manual intervention required.\n\n   We detected that the remote host uses an RSA key that was not generated by us.\n   We will not override it with our locally generated key.\n\n   If you want to make use of the remote RSA key you have to override the local key manually:\n\n\n   cd ~/.tor/offlinemasterkeys/<inventoryname>-<IP_port>/keys\n\n   mv secret_id_key.untrustedremotekey secret_id_key\"'\n  when: item.stdout != \"1\"\n  with_items: rsakey.results\n\n# this task is separated from the task named \"Ensure RSA key is in place\" because it is not run with 'force=no'\n- name: Transmit new Ed25519 signing keys\n  become: yes\n  copy: src={{ offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}\n   dest={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}\n   owner=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n   mode=700\n   setype=tor_var_lib_t\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'ed25519_signing_cert', 'ed25519_signing_secret_key' ]\n  tags:\n   - renewkey\n\n# This needs to be at the end to fix SELinux contexts recursively\n- name: Ensure per-instance DataDir have proper permissions\n  become: yes\n  file: path={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}\n    state=directory\n    owner=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n    group=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n    mode=0700\n    recurse=yes\n    setype=tor_var_lib_t\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure Tor config directory exists\n  become: yes\n  file: path={{ tor_ConfDir }}\n    state=directory\n    owner=root\n    group={{ tor_user }}\n    mode=755\n\n- name: Generating torrc file(s)\n  become: yes\n  template: >\n    src=torrc\n    dest=\"{{ (ansible_pkg_mgr != 'apt')| ternary(tor_ConfDir ~ '/' ~ item[0] ~ '_' ~ item.1.orport ~ '.torrc', tor_ConfDir ~ '/' ~ item[0] ~ '_' ~ item.1.orport ~ '/torrc') }}\"\n    owner=root\n    mode=0644\n    backup=yes\n    validate=\"tor --verify-config -f %s\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n  register: instances\n  tags:\n   - reconfigure\n"}, {"commit_sha": "af3dfdf7cf37437f5609f1a12e4ac7cbaebd4867", "sha": "7de16555d0177a4322801c8d247bc41a7247c03d", "filename": "roles/zookeeper/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for zookeeper\nzookeeper_client_port: 2181\nzookeeper_leader_connect_port: 2888\nzookeeper_leader_election_port: 3888\nzookeeper_server_group: zookeeper_servers\nzookeeper_id: \"\n\t{%- if zookeeper_host_list is defined -%}\n\t\t{%- for host in zookeeper_host_list.split() -%}\n\t\t\t{%- if host == ansible_eth0.ipv4.address -%}\n\t        \t{{ loop.index }}\n\t\t\t{%- endif -%}\n\t\t{%- endfor -%}\n\t{%- else -%}\n    \t{%- for host in groups[zookeeper_server_group] -%}\n      \t\t{%- if host == 'default' or host == inventory_hostname or host == ansible_fqdn or host in ansible_all_ipv4_addresses -%}\n        \t\t{{ loop.index }}\n  \t\t\t{%- endif -%}\n    \t{%- endfor -%}\n    {%- endif -%}\n\"\nconsul_dir: /etc/consul.d\n"}, {"commit_sha": "af3dfdf7cf37437f5609f1a12e4ac7cbaebd4867", "sha": "04eab30065254275bece22cf99f0c7708e423a9b", "filename": "roles/dnsmasq/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for dnsmasq\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "604b2bab8a7ebd91846bb84a13aa25fcc371596a", "filename": "tasks/config_windows.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# File: config_windows.yml - Consul configuration tasks for Windows\n\n- name: Create configuration\n  win_copy:\n    dest: \"{{ item.dest }}\"\n    content: \"{{ lookup('template', 'templates/config.json.j2') | to_nice_json }}\"\n  with_items:\n    - dest: \"{{ consul_config_path }}/config.json\"\n      config_version: \"{{ consul_node_role }}\"\n      when: true\n    - dest: \"{{ consul_config_path }}/bootstrap.json\"\n      config_version: \"bootstrap\"\n      when: \"{{ consul_debug | bool }}\"\n    - dest: \"{{ consul_config_path }}/server.json\"\n      config_version: \"server\"\n      when: \"{{ consul_debug | bool }}\"\n    - dest: \"{{ consul_config_path }}/client.json\"\n      config_version: \"client\"\n      when: \"{{ consul_debug | bool }}\"\n  when:\n    - item.when\n  notify:\n    - restart consul\n\n- name: Create custom configuration\n  win_copy:\n    dest: \"{{ consul_configd_path }}/50custom.json\"\n    content: \"{{ lookup('template', 'templates/configd_50custom.json.j2') | to_nice_json }}\"\n  when:\n    - consul_config_custom is defined\n  notify:\n    - restart consul\n\n- name: Set fact list with custom configuration file\n  set_fact:\n    managed_files: \"{{ managed_files |default([]) }} + \\\n      [ '{{ consul_configd_path }}/50custom.json' ]\"\n"}, {"commit_sha": "b02504a0a0a8b0e4169d0327a865dfe08866e9ec", "sha": "f920e106bdab3c39722001cd68e28453f988a6cd", "filename": "tasks/FreeBSD/main.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/FreeBSD/main.yml: FreeBSD specific set-up\n# This takes care of base prerequisites for FreeBSD\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure the Sensu group is present\n    group: name={{ sensu_group_name }} state=present\n\n  - name: Ensure the Sensu user is present\n    user:\n      name: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      shell: /bin/false\n      home: \"{{ sensu_config_path }}\"\n      createhome: true\n      state: present\n\n  - name: Install prerequisite packages\n    pkgng:\n      name: \"{{ item }}\"\n      state: present\n    with_items:\n      - bash\n      - ca_root_nss\n\n  - name: Retrieve the sensu txz package\n    get_url:\n      url: \"{{ sensu_pkg_download_url }}\"\n      dest: \"{{ sensu_pkg_download_path }}\"\n    register: sensu_txz\n\n  - name: Install sensu from the retrieved txz package\n    command: \"pkg add {{ sensu_pkg_download_path }}\"\n    when: sensu_txz|changed\n\n  - name: Ensure the Sensu config directory is present\n    file:\n      dest: \"{{ sensu_config_path }}/conf.d\"\n      state: directory\n      recurse: true\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n"}, {"commit_sha": "af3dfdf7cf37437f5609f1a12e4ac7cbaebd4867", "sha": "55d62ee4deac63dfd10fbbac97ef106f007ae196", "filename": "roles/zookeeper/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- name: ensure zookeeper is running (and enable it at boot)\n  sudo: yes\n  service:\n    name: zookeeper\n    state: started\n    enabled: yes\n  tags:\n    - zookeeper\n\n- name: Create zookeeper config file\n  template:\n    src: zoo.cfg.j2\n    dest: /etc/zookeeper/conf/zoo.cfg\n  sudo: yes\n  notify:\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: Create zookeeper myid file\n  copy:\n    content: \"{{ zookeeper_id }}\"\n    dest: /etc/zookeeper/conf/myid\n    mode: 0644\n  sudo: yes\n  notify:\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: Set Zookeeper consul service definition\n  sudo: yes\n  template:\n    src: zookeeper-consul.j2\n    dest: \"{{ consul_dir }}/zookeeper.json\"\n  notify:\n    - restart consul\n  tags:\n    - zookeeper\n"}, {"commit_sha": "35ca6852d9333ef6c3ed223239f45b840c487d60", "sha": "797f75e5ee180a74c6af7cd9adaf801b4954a2f4", "filename": "roles/consul/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for consul\n- name: Restart consul\n  command: /sbin/restart consul\n  sudo: yes\n  notify:\n    - wait for consul to listen\n\n- name: wait for consul to listen\n  wait_for:\n    host: \"{{ consul_bind_addr }}\"\n    port: 8500\n"}, {"commit_sha": "0f46bc2b1f4dac71c882be0ee48a25332a90ed40", "sha": "a90b19bbe5dc47e6e98f0237fa3ed7dcfbcf467d", "filename": "roles/weave/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks file for weave\n- name: include all interfaces.d\n  sudo: yes\n  lineinfile: \"dest=/etc/network/interfaces state=present line='source /etc/network/interfaces.d/*.cfg'\"\n  notify:\n    - Restart networking\n\n- name: configure weave\n  sudo: yes\n  template: src=interfaces.j2 dest=/etc/network/interfaces.d/weave.cfg owner=root group=root mode=0644\n  notify:\n    - Up weave interface\n  tags:\n    - weave\n\n- name: configure weave bridge for docker\n  sudo: yes\n  lineinfile: \"dest=/etc/default/docker state=present regexp=^DOCKER_OPTS= line='DOCKER_OPTS=\\\"--bridge=weave --fixed-cidr={{ weave_docker_subnet }}\\\"'\"\n  notify:\n    - Restart docker\n    - Weave launch\n  tags:\n    - weave\n"}, {"commit_sha": "c0a575a4d0d5cd8c461b6388abf28ee3a245fd42", "sha": "8886fdec280fc878e565b084d2474a605d368cc5", "filename": "handlers/main.yml", "repository": "threatstack/threatstack-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- name: restart cloudsight\n  service: name=cloudsight state=restarted\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "8780bf9034c07be290cb748a3ff1eb9a51397e91", "filename": "tasks/SmartOS/server.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/SmartOS/server.yml: Deploy the necessary configuration for\n# a Sensu 'master' node.\n# Specific to SmartOS\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Deploy Sensu server service manifest\n    template:\n      dest: /opt/local/lib/svc/manifest/sensu-server.xml\n      src: sensu-server.smartos_smf_manifest.xml.j2\n      owner: root\n      group: root\n      mode: 0644\n    notify: import sensu-server service\n\n  - name: Deploy Sensu API service manifest\n    template:\n      dest: /opt/local/lib/svc/manifest/sensu-api.xml\n      src: sensu-api.smartos_smf_manifest.xml.j2\n      owner: root\n      group: root\n      mode: 0644\n    notify: import sensu-api service\n\n  - meta: flush_handlers\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "f9e64465b6f59f65a821aee284acf85b39faa59a", "filename": "roles/registrator/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: wait for weave socket to be ready.\n  wait_for:\n    port: 6783\n    delay: 10\n\n- name: destroy old marathon container\n  when: registrator_rebuild_container\n  docker:\n    name: registrator\n    image: \"{{ registrator_image }}\"\n    state: absent\n\n# tasks file for docker registrator\n- name: run registrator container\n  docker:\n    name: registrator\n    image: \"{{ registrator_image }}\"\n    state: started\n    restart_policy: always\n    net: host\n    command: \"-internal -resync=10 {{ registrator_uri }}\"\n    volumes:\n    - \"{{ registrator_docker_socket }}:/tmp/docker.sock\"\n  environment: proxy_env\n  tags:\n    - registrator\n"}, {"commit_sha": "bf6e08dcb2440421477b6536ff6a8d11adc2be17", "sha": "ebc231fccf37cc8ca48720e74be75a00f803bb22", "filename": "roles/weave/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for weave\n- name: include all interfaces.d\n  sudo: yes\n  lineinfile:\n    dest: /etc/network/interfaces\n    state: present\n    line: 'source /etc/network/interfaces.d/*.cfg'\n  tags:\n    - weave\n\n# Start docker as it is a requirement for weave create-bridge.\n- name: Start up docker\n  service:\n    name: docker\n    state: started\n  tags:\n    - weave\n\n- name: configure weave interface\n  sudo: yes\n  template:\n    src: interfaces.j2\n    dest: /etc/network/interfaces.d/weave.cfg\n    owner: root\n    group: root\n    mode: 0644\n  tags:\n    - weave\n\n# Create weave bridge.\n- name: bring up weave bridge\n  command: ifup weave\n  sudo: yes\n\n- name: upload weave template service\n  template:\n    src: weave.conf.j2\n    dest: \"/etc/init/weave.conf\"\n    mode: 0755\n  sudo: yes\n  tags:\n    - weave\n\n# Restart docker with weave bridge available and triggers weave service.\n- name: configure weave bridge for docker\n  sudo: yes\n  lineinfile:\n    dest: /etc/default/docker\n    state: present\n    regexp: ^DOCKER_OPTS=.*--bridge=weave.*\n    line: 'DOCKER_OPTS=\\\"$DOCKER_OPTS {{ weave_docker_opts }}\\\"'\n  notify:\n    - restart docker\n  tags:\n    - weave\n"}, {"commit_sha": "f5364b57f100ae9fa898af59b7812ec0c447ac42", "sha": "5e3caef9204c63c07f638687fa38ac81774205e4", "filename": "handlers/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n- name: stop-and-mask default tor instance\n  become: yes\n  shell: systemctl stop tor@default && systemctl mask tor@default\n  when: ansible_pkg_mgr == 'apt'\n\n- name: restart apparmor\n  become: yes\n  service: name=apparmor state=restarted\n\n- name: systemctl daemon-reload\n  become: yes\n  command: systemctl daemon-reload\n\n- name: re-gather facts\n  setup:\n  when: ansible_pkg_mgr == 'dnf'\n\n- name: disable default tor instance FreeBSD\n  become: yes\n  lineinfile:\n    dest: /etc/rc.conf\n    line: \"tor_disable_default_instance=\\\"YES\\\"\"\n    create: yes\n  when: ansible_system == 'FreeBSD'\n\n# TODO: this reloads all instances on a FreeBSD host even if just one torrc changed\n- name: Ensure Tor instances are reloaded if its torrc changed (FreeBSD)\n  become: yes\n  service:\n    name: tor\n    state: reloaded\n  when: ansible_system == 'FreeBSD'\n\n- name: Ensure Tor instances are reloaded if its torrc changed (Linux)\n  become: yes\n  service:\n    name: \"tor@{{ item.item.0.ipv4 }}_{{ item.item.1.orport }}.service\"\n    state: reloaded\n  with_items: \"{{ instances.results }}\"\n  when: item.changed == True and ansible_system == 'Linux'\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "7d2f5bf5c84d9fce247738ad20b0865b043e5d43", "filename": "roles/cadvisor/vars/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# vars file for cadvisor\n"}, {"commit_sha": "61b008311c40b377e57e166b778232a20224f7c6", "sha": "159774169112c49e2b2f41ada953add0e25e8784", "filename": "tasks/auth_initialization.yml", "repository": "UnderGreen/ansible-role-mongodb", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n- name: Move back mongod.conf\n  template: src=mongod_init.conf.j2 dest=/etc/mongod.conf owner=root group=root mode=0644\n\n- name: Restart mongodb service\n  service: name={{ mongodb_daemon_name }} state=restarted\n  when: mongodb_manage_service\n\n- name: wait MongoDB port is listening\n  wait_for: host=127.0.0.1 port=\"{{ mongodb_conf_port }}\" delay=5 state=started\n\n- name: get pid of mongodb for non daemon mode\n  shell: \"pidof mongod\"\n  register: pidof_mongod\n  when: mongodb_manage_service == false\n  ignore_errors: yes\n\n- name: start mongodb daemon\n  shell: \"LC_ALL=C /usr/bin/mongod --config /etc/mongod.conf --fork\"\n  when: mongodb_manage_service == false and pidof_mongod.rc == 1\n\n- name: create administrative user siteUserAdmin\n  mongodb_user:\n    database: admin\n    name: \"{{ item.name }}\"\n    password: \"{{ item.password }}\"\n    roles: \"{{ item.roles }}\"\n    login_port: \"{{ mongodb_conf_port }}\"\n  with_items:\n    - {\n      name: \"{{ mongodb_user_admin_name }}\",\n      password: \"{{ mongodb_user_admin_password }}\",\n      roles: \"userAdminAnyDatabase\"\n      }\n\n- name: create administrative user siteRootAdmin\n  mongodb_user:\n    database: admin\n    name: \"{{ item.name }}\"\n    password: \"{{ item.password }}\"\n    roles: \"{{ item.roles }}\"\n    login_port: \"{{ mongodb_conf_port }}\"\n  with_items:\n    - {\n      name: \"{{ mongodb_root_admin_name }}\",\n      password: \"{{ mongodb_root_admin_password }}\",\n      roles: \"root\"\n      }\n\n- name: create normal users\n  mongodb_user:\n    database: \"{{ item.database }}\"\n    name: \"{{ item.name }}\"\n    password: \"{{ item.password }}\"\n    roles: \"{{ item.roles }}\"\n    login_user: \"{{ mongodb_user_admin_name }}\"\n    login_password: \"{{ mongodb_user_admin_password }}\"\n    login_port: \"{{ mongodb_conf_port }}\"\n  with_items:\n    - \"{{ mongodb_users }}\"\n  when: mongodb_users is defined and mongodb_users\n\n- name: Move back mongod.conf\n  template: src=mongod.conf.j2 dest=/etc/mongod.conf owner=root group=root mode=0644\n\n- name: Restart mongodb service\n  service: name={{ mongodb_daemon_name }} state=restarted\n  when: mongodb_manage_service\n\n- name: wait MongoDB port is listening\n  wait_for: host=\"{{ mongodb_conf_bind_ip }}\" port=\"{{ mongodb_conf_port }}\" delay=5 state=started\n\n- name: stop mongodb if was not started\n  shell: \"kill {{ pidof_mongod.stdout }}\"\n  when: mongodb_manage_service == false and pidof_mongod.rc == 0\n"}, {"commit_sha": "92d2f38d01d7b33610c667cfdc03e28ab2912edc", "sha": "e2007ba30014f5687db14334ab96f96c4a6f5b12", "filename": "tasks/section_08_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n# Change order or the default auditd.conf file will not be created\n  - name: 8.1.2 Install and Enable auditd Service (Scored)\n    apt: name=auditd state=present\n    tags:\n      - section8\n      - section8.1\n      - section8.1.2\n      - section8.1.2\n\n  - name: Check if the file auditd.conf exists (Not Scored)\n    stat: >\n        path=/etc/audit/auditd.conf\n    register: auditd_file\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n\n  - name: Create the audit directory if it does not exists (Not Scored)\n    file: >\n        path=/etc/audit/\n        state=directory\n    when: not auditd_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n\n  - name: 8.1.1-3 Configure Data Retention (Not Scored)\n    lineinfile: >\n        dest=/etc/audit/auditd.conf\n        regexp=\"{{ item.rxp }}\"\n        line=\"{{ item.line }}\"\n        state=present\n        create=yes\n    with_items:\n      - { rxp: '^max_log_file ', line: 'max_log_file = {{ max_log_file_auditd }}' }\n      - { rxp: '^space_left_action', line: 'space_left_action = email' }\n      - { rxp: '^action_mail_acct', line: 'action_mail_acct = root' }\n      - { rxp: '^admin_space_left_action', line: 'admin_space_left_action = halt' }\n      - { rxp: '^max_log_file_action', line: 'max_log_file_action = keep_logs' }\n    notify: restart auditd\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n      - section8.1.1.2\n      - section8.1.1.3\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    stat: path=/etc/default/grub\n    register: grubcfg_file\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    file: >\n        path=/etc/default/grub\n        state=touch\n    when: not grubcfg_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    lineinfile: >\n        dest=/etc/default/grub\n        line='GRUB_CMDLINE_LINUX=\"audit=1\"'\n    when: not grubcfg_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.4 Record Events That Modify Date and Time Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a always,exit -F arch=b64 -S adjtimex -S settimeofday -k time-change'\n      - '-a always,exit -F arch=b32 -S adjtimex -S settimeofday -S stime -k time-change'\n      - '-a always,exit -F arch=b64 -S clock_settime -k time-change'\n      - '-a always,exit -F arch=b32 -S clock_settime -k time-change'\n      - '-w /etc/localtime -p wa -k time-change'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"64\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.4\n\n  - name: 8.1.4 Record Events That Modify Date and Time Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a always,exit -F arch=b32 -S adjtimex -S settimeofday -S stime -k time-change'\n      - '-a always,exit -F arch=b32 -S clock_settime -k time-change'\n      - '-w /etc/localtime -p wa -k time-change'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"32\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.4\n\n  - name: 8.1.5,7,8,9,15,16,17 Record Events That Modify User/Group Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-w /etc/group -p wa -k identity'\n      - '-w /etc/passwd -p wa -k identity'\n      - '-w /etc/gshadow -p wa -k identity'\n      - '-w /etc/shadow -p wa -k identity'\n      - '-w /etc/security/opasswd -p wa -k identity'\n      - '-w /var/log/faillog -p wa -k logins'\n      - '-w /var/log/lastlog -p wa -k logins'\n      - '-w /var/log/tallylog -p wa -k logins'\n      - '-w /var/run/utmp -p wa -k session'\n      - '-w /var/log/wtmp -p wa -k session'\n      - '-w /var/log/btmp -p wa -k session'\n      - '-w /etc/selinux/ -p wa -k MAC-policy'\n      - '-w /etc/sudoers -p wa -k scope'\n      - '-w /var/log/sudo.log -p wa -k actions'\n      - '-w /sbin/insmod -p x -k modules'\n      - '-w /sbin/rmmod -px -k modules'\n      - '-w /sbin/modprobe -p x -k modules'\n    notify: restart auditd\n    tags:\n      - section8\n      - section8.1\n      - section8.1.5\n      - section8.1.7\n      - section8.1.8\n      - section8.1.9\n      - section8.1.15\n      - section8.1.16\n      - section8.1.17\n\n  - name: 8.1.6,10,11,13,14,17 Record Events That Modify the System's Network Environment (64b) (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a exit,always -F arch=b64 -S sethostname -S setdomainname -k system-locale'\n      - '-a exit,always -F arch=b32 -S sethostname -S setdomainname -k system-locale'\n      - '-w /etc/issue -p wa -k system-locale'\n      - '-w /etc/issue.net -p wa -k system-locale'\n      - '-w /etc/hosts -p wa -k system-locale'\n      - '-w /etc/network -p wa -k system-locale'\n      - '-a always,exit -F arch=b64 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b64 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b64 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b32 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b64 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b32 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b64 -S init_module -S delete_module -k modules'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"64\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.6\n      - section8.1.10\n      - section8.1.11\n      - section8.1.13\n      - section8.1.14\n      - section8.1.17\n\n  - name: 8.1.6,10,11,13,14,17 Record Events That Modify the System's Network Environment (32b) (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a exit,always -F arch=b32 -S sethostname -S setdomainname -k system-locale'\n      - '-w /etc/issue -p wa -k system-locale'\n      - '-w /etc/issue.net -p wa -k system-locale'\n      - '-w /etc/hosts -p wa -k system-locale'\n      - '-w /etc/network -p wa -k system-locale'\n      - '-a always,exit -F arch=b32 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b32 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b32 -S init_module -S delete_module -k modules'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"32\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.6\n      - section8.1.10\n      - section8.1.11\n      - section8.1.13\n      - section8.1.14\n      - section8.1.17\n\n  - name: 8.3.1 Install AIDE (Scored)\n    apt: name=aide state=present\n    register: aide_installed\n    when: use_aide == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (init) (Scored)\n    command: aideinit\n    when:\n      - use_aide == True\n      - aide_installed.changed == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (Scored)\n    stat: path=/var/lib/aide/aide.db.new\n    register: aide_db_path\n    when:\n      - use_aide == True\n      - aide_installed.changed == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (copy db) (Scored)\n    command: mv /var/lib/aide/aide.db.new /var/lib/aide/aide.db\n    when:\n      - use_aide == True\n      - aide_installed.changed == True\n      - aide_db_path.stat.exists == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.2 Implement Periodic Execution of File Integrity (Scored)\n    cron: name=\"Check files integrity\" minute=\"0\" hour=\"5\" job=\"/usr/sbin/aide --check\"\n    when: use_aide == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.2\n\n  # We have to run the check after AIDE installation as postfix create new matched binaries\n  - name: 8.1.12 Collect Use of Privileged Commands (Scored)\n    shell: find / -xdev \\( -perm -4000 -o -perm -2000 \\) -type f | awk '{print \"-a always,exit -F path=\" $1 \" -F perm=x -F auid>=500 -F auid!=4294967295 -k privileged\" }'\n    register: audit_lines_for_find\n    changed_when: False\n    tags:\n      - section8\n      - section8.1\n      - section8.1.12\n\n  - name: 8.1.12 Collect Use of Privileged Commands (infos) (Scored)\n    lineinfile: >\n        dest=/etc/audit/audit.rules\n        line='{{ item }}'\n        state=present\n        create=yes\n    with_items: audit_lines_for_find.stdout_lines\n    tags:\n      - section8\n      - section8.1\n      - section8.1.12\n\n  - name: 8.1.18 Make the Audit Configuration Immutable (Scored)\n    lineinfile: >\n        dest='/etc/audit/audit.rules'\n        line='-e 2'\n        insertafter=EOF\n        state=present\n        create=yes\n    tags:\n      - section8\n      - section8.1\n      - section8.1.18\n"}, {"commit_sha": "35ca6852d9333ef6c3ed223239f45b840c487d60", "sha": "991a72ea211af11846e6c68403361374e99a4f73", "filename": "roles/dnsmasq/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for dnsmasq\n- name: Restart dnsmasq\n  service:\n    name: dnsmasq\n    state: restarted\n  sudo: yes\n\n- name: Reload dnsmasq\n  service:\n    name: dnsmasq\n    state: reloaded\n  sudo: yes\n"}, {"commit_sha": "80530fde7df1a94ad361434e02816b0816a2c47a", "sha": "926984841a77f9a9f614416f67e11efe862a4806", "filename": "roles/docker/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks file for docker\n- name: remove docker override\n  command: /bin/rm -f /etc/init/docker.override\n\n- name: ensure docker is running (and enable it at boot)\n  service: name=docker state=started enabled=yes\n"}, {"commit_sha": "dc73f16743fa376672b427980c6ca044dd6fa68a", "sha": "7914762f660d4715911f1539cb7308913d44fa48", "filename": "meta/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: nusenu\n  description: An Ansible role for Tor Relay Operators\n  license: GPLv3\n  platforms:\n  - name: Debian\n    versions:\n    - jessie\n    - stretch\n  - name: FreeBSD\n    versions:\n    - 10.3\n    - 11.0\n  - name: OpenBSD\n    versions:\n    - 6.0\n  - name: EL\n    versions:\n    - 7\n  - name: Ubuntu\n    versions:\n    - xenial\n  - name: Fedora\n    versions:\n    - 24\n  galaxy_tags:\n    - tor\n    - ipv6\n    - anonymity\n    - networking\n  min_ansible_version: 2.1.3\ndependencies: []\n"}, {"commit_sha": "d6b9aef3a890db0fa37a2812da7b3aa1b418c15f", "sha": "652bdc840882bcd10fa0b521a560196b0e4c1134", "filename": "tasks/main.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - include: section_01.yml\n    tags: section01\n\n  - include: section_02.yml\n    tags: section02\n\n  - include: section_03.yml\n    tags: section03\n\n  - include: section_04.yml\n    tags: section04\n\n  - include: section_05.yml\n    tags: section05\n\n  - include: section_06.yml\n    tags: section06\n\n  - include: section_07.yml\n    tags: section07\n\n  - include: section_08.yml\n    tags: section08\n\n  - include: section_09.yml\n    tags: section09\n\n  - include: section_10.yml\n    tags: section10\n\n  - include: section_11.yml\n    tags: section11\n\n  - include: section_12.yml\n    tags: section12\n\n  - include: section_13.yml\n    tags: section13\n\n"}, {"commit_sha": "4aaf839a9916f65d12b8964b23dbc6848a73ca67", "sha": "c5032c489020efd55af0e56aef8abe61ad0d57f3", "filename": "roles/registrator/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n\n# Install (docker-py) python package as is a docker module dependency.\n- pip: name=docker-py\n\n# tasks file for docker registrator\n- name: run registrator container\n  docker:\n    name: registrator\n    image: \"{{ registrator_image }}\"\n    state: started\n    command: \"-internal {{ registry_ip }}:{{ registry_port }}\"\n    hostname: \"{{ hostname }}\"\n    volumes:\n    - \"/var/run/docker.sock:/tmp/docker.sock\"\n"}, {"commit_sha": "af3dfdf7cf37437f5609f1a12e4ac7cbaebd4867", "sha": "d135e55ac4b34eb29734856b23bb94f8d33f06fb", "filename": "roles/marathon/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for marathon\nmarathon_port: 8080\nconsul_dir: /etc/consul.d\nmarathon_hostname: \"{{ ansible_ssh_host }}\"\nmarathon_artifact_store: \"file:///etc/marathon/store\"\nmarathon_artifact_store_dir: /etc/marathon/store\nmarathon_libprocess_ip: \"{{ ansible_ssh_host }}\""}, {"commit_sha": "92d2f38d01d7b33610c667cfdc03e28ab2912edc", "sha": "83e4d8f61d574ffcc7315e09c2a781aee38249fa", "filename": "tasks/main.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - include: check_requirements.yml\n\n  - include: section_01.yml\n    tags: section01\n\n  - include: section_02.yml\n    tags: section02\n\n  - include: section_03.yml\n    tags: section03\n\n  - include: section_04.yml\n    tags: section04\n\n  - include: section_05.yml\n    tags: section05\n\n  - include: section_06.yml\n    tags: section06\n\n  - include: section_07.yml\n    tags: section07\n\n  - include: section_08.yml\n    tags: section08\n\n  - include: section_09.yml\n    tags: section09\n\n  - include: section_10.yml\n    tags: section10\n\n  - include: section_11.yml\n    tags: section11\n\n  - include: section_12.yml\n    tags: section12\n\n  - include: section_13.yml\n    tags: section13\n\n"}, {"commit_sha": "694a4890fcf0daa375d6a173511f6ff7dd0f2335", "sha": "59e966357cb3bcdec09806325e0bccc69e08a69a", "filename": "tasks/linux_service.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n# Linux/systemd section (uses service module)\n# ===========================================\n\n- name: Ensure systemd drop-in folder is present\n  become: yes\n  file: path=/etc/systemd/system/tor@.service.d\n    state=directory\n    owner=root\n    mode=0755\n  when: ansible_os_family == 'RedHat'\n\n# this is needed for a small service file modification (allow it to write to /var/lib/tor-instances)\n# # without replacing the maintainer's file, for details see\n# # http://www.freedesktop.org/software/systemd/man/systemd.unit.html#id-1.11.3\n- name: Ensure service file drop-in is present\n  become: yes\n  copy: src=local.conf\n   dest=/etc/systemd/system/tor@.service.d/local.conf\n   owner=root\n   mode=640\n  when: ansible_os_family == 'RedHat'\n  notify: systemctl daemon-reload\n\n- meta: flush_handlers\n \n- name: Ensure Tor instances are reloaded if its torrc changed (Linux/systemd)\n  become: yes\n  service: name=tor@{{ item.item[0] }}_{{ item.item.1.orport }}.service state=reloaded\n  with_items: instances.results\n  when: item.changed == True\n  tags:\n   - reconfigure\n\n- name: Ensure Tor instances are enabled and started (Linux/systemd)\n  become: yes\n  service: name=tor@{{ item[0] }}_{{ item.1.orport }}.service enabled=yes state=started\n  with_nested:\n   - tor_ips\n   - tor_ports\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "96ab1173a232620013babda7bd4d7d9cc64c9fba", "filename": "tasks/Debian/rabbit.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/Debian/rabbit.yml: Deploy RabbitMQ\n# Specific to Debian\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure the RabbitMQ APT repo GPG key is present\n    apt_key:\n      url: https://www.rabbitmq.com/rabbitmq-release-signing-key.asc\n      state: present\n\n  - name: Ensure the RabbitMQ APT repo is present\n    apt_repository:\n      repo: 'deb http://www.rabbitmq.com/debian/ testing main'\n      state: present\n      update_cache: true\n\n  - name: Ensure RabbitMQ is installed\n    apt:\n      name: rabbitmq-server\n      state: \"{{ rabbitmq_pkg_state }}\"\n      update_cache: true\n"}, {"commit_sha": "d6b9aef3a890db0fa37a2812da7b3aa1b418c15f", "sha": "f6b3a84b78e594f199e7f76699f1c3306850dff1", "filename": "tasks/section_08_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n# Change order or the default auditd.conf file will not be created\n  - name: 8.1.2 Install and Enable auditd Service (Scored)\n    apt: name=auditd state=present\n    tags:\n      - section8\n      - section8.1\n      - section8.1.2\n      - section8.1.2\n\n  - name: Check if the file auditd.conf exists\n    stat: >\n        path=/etc/audit/auditd.conf\n    register: auditd_file\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n\n  - name: Create the audit directory if it does not exists\n    file: >\n        path=/etc/audit/\n        state=directory\n    when: not auditd_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n\n  - name: 8.1.1-3 Configure Data Retention\n    lineinfile: >\n        dest=/etc/audit/auditd.conf\n        regexp=\"{{ item.rxp }}\"\n        line=\"{{ item.line }}\"\n        state=present\n        create=yes\n    with_items:\n      - { rxp: '^max_log_file ', line: 'max_log_file = {{ Max_Log_File_Auditd }}' }\n      - { rxp: '^space_left_action', line: 'space_left_action = email' }\n      - { rxp: '^action_mail_acct', line: 'action_mail_acct = root' }\n      - { rxp: '^admin_space_left_action', line: 'admin_space_left_action = halt' }\n      - { rxp: '^max_log_file_action', line: 'max_log_file_action = keep_logs' }\n    notify: restart auditd\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n      - section8.1.1.2\n      - section8.1.1.3\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    stat: path=/etc/default/grub\n    register: grubcfg_file\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    file: >\n        path=/etc/default/grub\n        state=touch\n    when: not grubcfg_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    lineinfile: >\n        dest=/etc/default/grub\n        line='GRUB_CMDLINE_LINUX=\"audit=1\"'\n    when: not grubcfg_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.4 Record Events That Modify Date and Time Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a always,exit -F arch=b64 -S adjtimex -S settimeofday -k time-change'\n      - '-a always,exit -F arch=b32 -S adjtimex -S settimeofday -S stime -k time-change'\n      - '-a always,exit -F arch=b64 -S clock_settime -k time-change'\n      - '-a always,exit -F arch=b32 -S clock_settime -k time-change'\n      - '-w /etc/localtime -p wa -k time-change'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"64\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.4\n\n  - name: 8.1.4 Record Events That Modify Date and Time Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a always,exit -F arch=b32 -S adjtimex -S settimeofday -S stime -k time-change'\n      - '-a always,exit -F arch=b32 -S clock_settime -k time-change'\n      - '-w /etc/localtime -p wa -k time-change'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"32\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.4\n\n  - name: 8.1.5,7,8,9,15,16,17 Record Events That Modify User/Group Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-w /etc/group -p wa -k identity'\n      - '-w /etc/passwd -p wa -k identity'\n      - '-w /etc/gshadow -p wa -k identity'\n      - '-w /etc/shadow -p wa -k identity'\n      - '-w /etc/security/opasswd -p wa -k identity'\n      - '-w /var/log/faillog -p wa -k logins'\n      - '-w /var/log/lastlog -p wa -k logins'\n      - '-w /var/log/tallylog -p wa -k logins'\n      - '-w /var/run/utmp -p wa -k session'\n      - '-w /var/log/wtmp -p wa -k session'\n      - '-w /var/log/btmp -p wa -k session'\n      - '-w /etc/selinux/ -p wa -k MAC-policy'\n      - '-w /etc/sudoers -p wa -k scope'\n      - '-w /var/log/sudo.log -p wa -k actions'\n      - '-w /sbin/insmod -p x -k modules'\n      - '-w /sbin/rmmod -px -k modules'\n      - '-w /sbin/modprobe -p x -k modules'\n    notify: restart auditd\n    tags:\n      - section8\n      - section8.1\n      - section8.1.5\n      - section8.1.7\n      - section8.1.8\n      - section8.1.9\n      - section8.1.15\n      - section8.1.16\n      - section8.1.17\n\n  - name: 8.1.6,10,11,13,14,17 Record Events That Modify the System's Network Environment (64b) (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a exit,always -F arch=b64 -S sethostname -S setdomainname -k system-locale'\n      - '-a exit,always -F arch=b32 -S sethostname -S setdomainname -k system-locale'\n      - '-w /etc/issue -p wa -k system-locale'\n      - '-w /etc/issue.net -p wa -k system-locale'\n      - '-w /etc/hosts -p wa -k system-locale'\n      - '-w /etc/network -p wa -k system-locale'\n      - '-a always,exit -F arch=b64 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b64 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b64 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b32 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b64 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b32 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b64 -S init_module -S delete_module -k modules'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"64\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.6\n      - section8.1.10\n      - section8.1.11\n      - section8.1.13\n      - section8.1.14\n      - section8.1.17\n\n  - name: 8.1.6,10,11,13,14,17 Record Events That Modify the System's Network Environment (32b) (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a exit,always -F arch=b32 -S sethostname -S setdomainname -k system-locale'\n      - '-w /etc/issue -p wa -k system-locale'\n      - '-w /etc/issue.net -p wa -k system-locale'\n      - '-w /etc/hosts -p wa -k system-locale'\n      - '-w /etc/network -p wa -k system-locale'\n      - '-a always,exit -F arch=b32 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b32 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b32 -S init_module -S delete_module -k modules'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"32\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.6\n      - section8.1.10\n      - section8.1.11\n      - section8.1.13\n      - section8.1.14\n      - section8.1.17\n\n  - name: 8.1.12 Collect Use of Privileged Commands (Scored)\n    shell: find / -xdev \\( -perm -4000 -o -perm -2000 \\) -type f | awk '{print \"-a always,exit -F path=\" $1 \" -F perm=x -F auid>=500 -F auid!=4294967295 -k privileged\" }'\n    register: audit_lines_for_find\n    changed_when: False\n    tags:\n      - section8\n      - section8.1\n      - section8.1.12\n\n  - name: 8.1.12 Collect Use of Privileged Commands (infos) (Scored)\n    lineinfile: >\n        dest=/etc/audit/audit.rules\n        line='{{ item }}'\n        state=present\n        create=yes\n    with_items: audit_lines_for_find.stdout_lines\n    tags:\n      - section8\n      - section8.1\n      - section8.1.12\n\n  - name: 8.1.18 Make the Audit Configuration Immutable (Scored)\n    lineinfile: >\n        dest='/etc/audit/audit.rules'\n        line='-e 2'\n        insertafter=EOF\n        state=present\n        create=yes\n    tags:\n      - section8\n      - section8.1\n      - section8.1.18\n\n  - name: 8.3.1 Install AIDE (Scored)\n    apt: name=aide state=present\n    register: aide_installed\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (init) (Scored)\n    command: aideinit\n    when: aide_installed.changed == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (Scored)\n    stat: path=/var/lib/aide/aide.db.new\n    register: aide_db_path\n    when:\n      - aide_installed.changed == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (copy db) (Scored)\n    command: mv /var/lib/aide/aide.db.new /var/lib/aide/aide.db\n    when:\n      - aide_installed.changed == True\n      - aide_db_path.stat.exists == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.2 Implement Periodic Execution of File Integrity (Scored)\n    cron: name=\"Check files integrity\" minute=\"0\" hour=\"5\" job=\"/usr/sbin/aide --check\"\n    tags:\n      - section8\n      - section8.3\n      - section8.3.2\n"}, {"commit_sha": "72a9fefcabb6edccd82abb23946bd305035db334", "sha": "45eff103c7fc8fdadba9be304eec5266a89b711a", "filename": "tasks/freebsd_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Setup FreeBSD specific variables (set_fact)\n  set_fact:\n    tor_DataDir: /var/db/tor\n    tor_ConfDir: /usr/local/etc/tor/enabled\n  tags:\n   - configure\n   - createdir\n\n- name: Ensure Tor is installed (FreeBSD)\n  sudo: yes\n  pkgng: name=tor state=present\n  when: tor_alpha == False\n\n# pkg will take care of removing tor stable\n# if installed\n- name: Ensure Tor alpha is installed (FreeBSD)\n  sudo: yes\n  pkgng: name=tor-devel state=present\n  when: tor_alpha == True\n\n# temporary solution until rc.d supports multiple instances\n- name: Ensure Tor starts at boot (FreeBSD)\n  sudo: yes\n  lineinfile: dest=/etc/rc.local line=\"/usr/local/bin/tor -f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\" create=yes\n  with_nested:\n   - tor_ips\n   - tor_ports\n\n- name: If LogDir is a file, rename it (FreeBSD)\n  sudo: yes\n  shell: \"test -f {{ tor_LogDir }} && mv {{ tor_LogDir }} {{ tor_LogDir }}.bk-`date '+%Y-%m-%d_%H%M%S'`\"\n  ignore_errors: yes\n"}, {"commit_sha": "bf6e08dcb2440421477b6536ff6a8d11adc2be17", "sha": "f640fa076debe966d5d24e5246a05fbdf5dc8ddc", "filename": "roles/mesos/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "# used for leader election amongst masters\n- name: Set ZooKeeper URL\n  template:\n    src: zk.j2\n    dest: /etc/mesos/zk\n    mode: 0644\n  sudo: yes\n\n# Tasks for Master nodes\n- name: Set Mesos Master ip\n  copy:\n    content: \"{{ mesos_ip }}\"\n    dest: /etc/mesos-master/ip\n    mode: 0644\n  sudo: yes\n  notify:\n    - restart mesos master\n  when: mesos_install_mode == \"master\"\n\n- name: Set Mesos Master hostname\n  copy:\n    content: \"{{ mesos_hostname }}\"\n    dest: /etc/mesos-master/hostname\n    mode: 0644\n  sudo: yes\n  notify:\n    - restart mesos master\n  when: mesos_install_mode == \"master\"\n\n  # The Mesos quorum value is based on the number of Mesos Masters. Take the\n  # number of masters, divide by 2, and round-up to nearest integer. For example,\n  # if there are 1 or 2 masters the quorum count is 1. If there are 3 or 4\n  # masters then the quorum count is 2. For 5 or 6 masters it's 3 and so on.\n- name: Set Mesos Master quorum count\n  template:\n    src: quorum.j2\n    dest: /etc/mesos-master/quorum\n    mode: 0644\n  sudo: yes\n  notify:\n    - restart mesos master\n  when: mesos_install_mode == \"master\"\n\n- name: Set Mesos Master Cluster name\n  copy:\n    content: \"{{mesos_cluster_name}}\"\n    dest: /etc/mesos-master/cluster\n    mode: 0644\n  sudo: yes\n  notify:\n    - restart mesos master\n  when: mesos_install_mode == \"master\"\n\n- name: Set Mesos Master consul service definition\n  sudo: yes\n  template:\n    src: mesos-master-consul.j2\n    dest: \"{{ consul_dir }}/mesos-master.json\"\n  notify:\n    - restart consul\n  when: mesos_install_mode == \"master\"\n\n- name: remove mesos-master override\n  file:\n    path: /etc/init/mesos-master.override\n    state: absent\n  notify:\n    - restart mesos master\n  when: mesos_install_mode == \"master\"\n\n- name: start mesos-master (and enable it at boot)\n  service:\n    name: mesos-master\n    state: started\n    enabled: yes\n  when: mesos_install_mode == \"master\"\n\n# Tasks for Slave nodes\n- name: remove mesos-slave override\n  file:\n    path: /etc/init/mesos-slave.override\n    state: absent\n  notify:\n    - restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: Set Mesos Slave hostname\n  copy:\n    content: \"{{ mesos_hostname }}\"\n    dest: /etc/mesos-slave/hostname\n    mode: 0644\n  sudo: yes\n  notify:\n    - restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: set executor registration timeout\n  sudo: yes\n  copy:\n    dest: /etc/mesos-slave/executor_registration_timeout\n    content: \"{{ mesos_executor_registration_timeout }}\"\n  notify:\n    - restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: set containerizers\n  sudo: yes\n  copy:\n    dest: /etc/mesos-slave/containerizers\n    content: \"{{ mesos_containerizers }}\"\n  notify:\n    - restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: set slave resources\n  sudo: yes\n  copy:\n    dest: /etc/mesos-slave/resources\n    content: \"{{ mesos_resources }}\"\n  notify:\n    - restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: Set Mesos Slave ip\n  copy:\n    content: \"{{ mesos_ip }}\"\n    dest: /etc/mesos-slave/ip\n    mode: 0644\n  sudo: yes\n  notify:\n    - restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: Create Mesos Slave work area\n  file:\n    dest: \"{{mesos_slave_work_dir}}\"\n    mode: 0755\n    state: directory\n  sudo: yes\n  notify:\n    - restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: Set Mesos Slave work area\n  copy:\n    content: \"{{mesos_slave_work_dir}}\"\n    dest: /etc/mesos-slave/work_dir\n    mode: 0644\n  sudo: yes\n  notify:\n    - restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: start mesos-slave (and enable it at boot)\n  service:\n    name: mesos-slave\n    state: started\n    enabled: yes\n  when: mesos_install_mode == \"slave\"\n\n- meta: flush_handlers\n"}, {"commit_sha": "a2393d46f0b98700161c4cefd9260d7694bd0bf3", "sha": "8b2355999e3e04c6030801310f41bdee173224d6", "filename": "tasks/section_02_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 2.1 Create Separate Partition for /tmp (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /tmp\"\n    tags:\n      - section2\n      - section2.1\n\n  - name: 2.2 - 4 Set nodev, nosuid, noexec option for /tmp Partition (Scored)\n    mount: name=\"/tmp\" state=\"mounted\" opts=\"nodev,nosuid,noexec\"\n    when: partitioning==\"true\"\n    tags:\n      - section2\n      - section2.2\n      - section2.3\n      - section2.4\n\n  - name: 2.5 Create Separate Partition for /var (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var\"\n    tags:\n      - section2\n      - section2.5\n\n  - name: 2.6 Bind Mount the /var/tmp directory to /tmp (Scored)\n    mount: name=\"/var/tmp\" src=\"/tmp\" opts=bind state=mounted\n    when: partitioning==\"true\"\n    tags:\n      - section2\n      - section2.6\n\n  - name: 2.7 Create Separate Partition for /var/log (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var/log\"\n    tags:\n      - section2\n      - section2.7\n\n  - name: 2.8 Create Separate Partition for /var/log/audit (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var/log/audit\"\n    tags:\n      - section2\n      - section2.8\n\n  - name: 2.9 Create Separate Partition for /home (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /home\"\n    tags:\n      - section2\n      - section2.9\n\n  - name: 2.10 Add nodev Option to /home (Scored)\n    mount: name:/home state:mounted opts:remount,nodev\n    when: partitioning==\"true\"\n    tags:\n      - section2\n      - section2.10\n\n  - name: 2.11 Add nodev Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nodev option\"\n    tags:\n      - section2\n      - section2.11\n\n  - name: 2.12 Add noexec Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have noexec option\"\n    tags:\n      - section2\n      - section2.12\n\n  - name: 2.13 Add nosuid Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nosuid option\"\n    tags:\n      - section2\n      - section2.13\n\n  - name: 2.14 - 16 Add nodev Option to /run/shm Partition (Scored)\n    mount: name=\"/run/shm\" src=\"/run/shm\" state=\"mounted\" opts=\"nodev,nosuid,noexec\" fstype=\"tmpfs\"\n    tags:\n      - section2\n      - section2.14\n      - section2.15\n      - section2.16\n\n  - name: 2.17.1 Set Sticky Bit on All World-Writable Directories (preparation) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type d -perm -0002 -print 2>/dev/null\n    failed_when: False\n    changed_when: False\n    always_run: True\n    register: sticky_bit_dirs\n    tags:\n      - section2\n      - section2.17\n      - section2.17.1\n\n  - name: 2.17.2 Set Sticky Bit on All World-Writable Directories (Scored)\n    file: path={{ item }} mode=\"a+t\"\n    with_items: sticky_bit_dirs.stdout_lines\n    tags:\n      - section2\n      - section2.17\n      - section2.17.2\n\n  - name: 2.25 Disable Automounting (stat) (Scored)\n    stat: >\n        path=/etc/init/autofs.conf\n    register: autofs_file\n    tags:\n      - section2\n      - section2.25\n      \n  - name: 2.25 Disable Automounting (Scored)\n    lineinfile: >\n        dest=/etc/init/autofs.conf\n        line='#start on runlevel [2345]'\n        regexp='start on runlevel'\n        state=present\n    when: autofs_file.stat.exists == True\n    tags:\n      - section2\n      - section2.25\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "b09b7b24141a75026470923be2ccc7307ffd7e90", "filename": "roles/consul/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n- include: config.yml\n\n- name: enable consul\n  sudo: yes\n  service:\n    name: consul\n    enabled: yes\n    state: started\n  notify:\n    - restart consul\n  tags:\n    - consul\n\n- name: enable dnsmasq\n  sudo: yes\n  service:\n    name: dnsmasq\n    enabled: yes\n    state: started\n\n#- name: enable consul-discovery\n#  sudo: yes\n#  service:\n#    name: consul-discovery\n#    enabled: yes\n#    state: started\n#  notify:\n#    - restart consul systemd\n#  tags:\n#    - consul\n"}, {"commit_sha": "b02504a0a0a8b0e4169d0327a865dfe08866e9ec", "sha": "baac0eb6cfb695c1c676df46da3fddcedbb46c04", "filename": "tasks/client.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/client.yml: Deploy various client-side configurations for Sensu\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure the Sensu config directory is present\n    file:\n      dest: \"{{ sensu_config_path }}/conf.d\"\n      state: directory\n      recurse: true\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n\n  - name: Deploy Sensu client RabbitMQ configuration\n    template:\n      dest: \"{{ sensu_config_path }}/conf.d/rabbitmq.json\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      src: rabbitmq.json.j2\n    when: sensu_transport == \"rabbitmq\"\n\n  - name: Deploy Sensu client Redis configuration\n    template:\n      dest: \"{{ sensu_config_path }}/conf.d/redis.json\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      src: sensu-redis.json.j2\n    when: sensu_transport == \"redis\"\n\n  - name: Deploy Sensu client transport configuration\n    template:\n      dest: \"{{ sensu_config_path }}/conf.d/transport.json\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      src: transport.json.j2\n    notify: restart sensu-client service\n\n  - name: Deploy Sensu client service configuration\n    template:\n      dest: \"{{ sensu_config_path }}/conf.d/client.json\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      src: \"{{ sensu_client_config  }}\"\n    notify: restart sensu-client service\n\n  - include: SmartOS/client.yml\n    when: ansible_distribution == \"SmartOS\"\n\n  - name: Ensure Sensu client service is running\n    service: name=sensu-client state=started enabled=yes\n"}, {"commit_sha": "c0a575a4d0d5cd8c461b6388abf28ee3a245fd42", "sha": "5ba34d88d17662d0943f265bb3e67c9518d8a01a", "filename": "tasks/yum_install.yml", "repository": "threatstack/threatstack-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n- name: Ensure ThreatStack repo is installed.\n  template:\n    src: threatstack.j2\n    dest: /etc/yum.repos.d/threatstack.repo\n    owner: root\n    group: root\n    mode: 0644\n\n- name: Add ThreatStack repo GPG key.\n  rpm_key:\n    state: present\n    key: https://app.threatstack.com/RPM-GPG-KEY-THREATSTACK\n    validate_certs: no\n\n- name: Ensure Agent is installed.\n  yum:\n    name: threatstack-agent\n    state: latest\n    update_cache: yes\n"}, {"commit_sha": "e8eb28b4b4b1c4fb2490b8198570166b9ca23ab2", "sha": "1758b0982f4fe328f04794660f80c786d78d9381", "filename": "roles/mysql/tasks/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "- name: Install the server\n  sudo: true\n  apt:\n    name: \"{{ item }}\"\n    update_cache: yes\n  with_items:\n    - mysql-server\n\n- name: Enable the service\n  sudo: true\n  service:\n    name: mysql\n    enabled: yes\n    state: started\n\n- name: Install python-mysqldb\n  sudo: true\n  apt:\n    name: python-mysqldb\n\n- name: Change MySQL password\n  mysql_user:\n    name: \"{{ mysql.login }}\"\n    password: \"{{ mysql.password }}\"\n    login_user: \"{{ mysql.login }}\"\n    login_password: \"{{ mysql.password }}\"\n    check_implicit_admin: yes\n\n- name: Copy DB dump\n  template:\n    src: dump.j2\n    dest: /tmp/dump.sql\n\n- name: Create DB\n  mysql_db:\n    name: mistral\n    login_user: \"{{ mysql.login }}\"\n    login_password: \"{{ mysql.password }}\"\n\n# Q: Do we really want to wipe it every time?\n- name: Wipe DB\n  mysql_db:\n    name: mistral\n    state: import\n    target: /tmp/dump.sql\n    login_user: \"{{ mysql.login }}\"\n    login_password: \"{{ mysql.password }}\"\n"}, {"commit_sha": "9eb1a8fa8e281ef06687c1851f51fa0beec3e232", "sha": "1024f329ab13a1fe7409e6c18fb357183a3eb2fd", "filename": "tasks/section_10_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 10.1.1 Set Password Expiration Days (Scored)\n    lineinfile: >\n        dest='/etc/login.defs'\n        line='PASS_MAX_DAYS 90'\n        state=present\n        regexp='^PASS_MAX_DAYS'\n    tags:\n      - section10\n      - section10.1\n      - section10.1.1\n\n  - name: 10.1.2 Set Password Change Minimum Number of Days (Scored)\n    lineinfile: >\n        dest='/etc/login.defs'\n        line='PASS_MIN_DAYS 7'\n        regexp='^PASS_MIN_DAYS'\n    tags:\n      - section10\n      - section10.1\n      - section10.1.2\n\n  - name: 10.1.3 Set Password Expiring Warning Days (Scored)\n    lineinfile: >\n        dest='/etc/login.defs'\n        line='PASS_WARN_AGE'\n        regexp='^PASS_WARN_AGE'\n    tags:\n      - section10\n      - section10.1\n      - section10.1.3\n\n  - name: 10.2 Disable System Accounts (check) (Scored)\n    shell: awk -F':' '($1!=\"root\" && $1!=\"sync\" && $1!=\"shutdown\" &&$1!=\"halt\" && $3<500 && $7!=\"/usr/sbin/nologin\" && $7!=\"/bin/false\") {print $1}' /etc/passwd\n    register: awk_etc_passwd\n    changed_when: False\n    tags:\n      - section10\n      - section10.2\n\n  - name: 10.2 Disable System Accounts (Scored)\n    command: /usr/sbin/usermod -s /usr/sbin/nologin {{ item }}\n    with_items: awk_etc_passwd.stdout_lines\n    tags:\n      - section10\n      - section10.2\n\n  - name: 10.3 Set Default Group for root Account (Scored)\n    user: >\n        name=root\n        group=root\n    tags:\n      - section10\n      - section10.3\n\n  - name: 10.4 Set Default umask for Users (Scored)\n    lineinfile: >\n        dest=/etc/login.defs\n        line='UMASK\\t077'\n        regexp='^UMASK'\n        state=present\n    tags:\n      - section10\n      - section10.4\n\n  - name: 10.5 Lock Inactive User Accounts (check) (Scored)\n    command: grep INACTIVE /etc/login.defs\n    changed_when: False\n    failed_when: False\n    always_run: True\n    register: lock_inactive_rc\n    tags:\n      - section10\n      - section10.5\n        \n  - name: 10.5 Lock Inactive User Accounts (Scored)\n    lineinfile: >\n        dest=/etc/login.defs\n        line='INACTIVE=35'\n        state=present\n    when: lock_inactive_rc.rc == 1\n    tags:\n      - section10\n      - section10.5\n\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "e3bee6cde99a3b05950aece60f874e060e6cfa71", "filename": "roles/docker/meta/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Graham Taylor\n  description:\n  company: Capgemini\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (MIT)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: CoreOS\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n  #   - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies: []\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "d0474d044f9674b7a2629ff8fed2b5078ff70d81", "filename": "roles/docker/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for docker\n- name: reload systemd\n  become: yes\n  command: systemctl daemon-reload\n  notify:\n    - restart docker\n\n- name: restart docker\n  become: yes\n  service:\n   name: docker\n   state: restarted\n"}, {"commit_sha": "bf6e08dcb2440421477b6536ff6a8d11adc2be17", "sha": "b88a3a1133ad6c52a0c52427bb99a23702ad190b", "filename": "roles/zookeeper/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- name: ensure zookeeper is running (and enable it at boot)\n  sudo: yes\n  service:\n    name: zookeeper\n    state: started\n    enabled: yes\n  tags:\n    - zookeeper\n\n- name: Create zookeeper config file\n  template:\n    src: zoo.cfg.j2\n    dest: /etc/zookeeper/conf/zoo.cfg\n  sudo: yes\n  notify:\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: Create zookeeper myid file\n  copy:\n    content: \"{{zookeeper_id}}\"\n    dest: /etc/zookeeper/conf/myid\n    mode: 0644\n  sudo: yes\n  notify:\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: Set Zookeeper consul service definition\n  sudo: yes\n  template:\n    src: zookeeper-consul.j2\n    dest: \"{{ consul_dir }}/zookeeper.json\"\n  notify:\n    - restart consul\n  tags:\n    - zookeeper\n"}, {"commit_sha": "df06f3c3304c3f73f740d444222642fbad41bebb", "sha": "b3b1957dd28a0302f8acd1576aa48f859937ddd5", "filename": "tasks/apt_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Setup Debian specific variables (set_fact)\n  set_fact:\n    tor_user: debian-tor\n  tags:\n   - reconfigure\n   - createdir\n\n- name: Ensure torproject gpg key is installed (A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89)\n  become: yes\n  apt_key: data=\"{{ lookup('file', 'deb.torproject.org_A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89.pub') }}\"\n    id=A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89\n    state=present\n\n- name: Ensure torproject.org repository is present (APT)\n  become: yes\n  apt_repository: repo='deb http://deb.torproject.org/torproject.org {{ tor_distribution_release }} main'\n    state=present \n    update_cache=yes\n\n# waiting for trac ticket #14997\n#- name: Ensure  torproject.org alpha repo is present (if enabled)\n#  apt_repository: >\n#    repo='deb http://deb.torproject.org/torproject.org  main'\n#    state=present \n#    update_cache=yes\n#  when: tor_alpha is True\n\n# we specifically opt for present over latest to improve performance\n# \"latest\" is covered by auto updates\n- name: Ensure Tor is installed (APT)\n  become: yes\n  apt: pkg=\"{{ item }}\" state=present\n  with_items: \n    - deb.torproject.org-keyring\n    - tor\n  # apt starts a tor client instance by default after installing the package\n  # we do not need that\n  notify:\n    - stop tor\n    - disable-sysv-debian tor\n\n- name: Ensure the presence of the multi-instance systemd unit file (Debian)\n  become: yes\n  template: src=debian_tor@.service dest=/lib/systemd/system/tor@.service owner=root mode=0644 backup=yes\n  when: ansible_distribution == 'Debian'\n  notify: systemctl daemon-reload\n\n- name: Ensure the presence of the multi-instance systemd unit file (Ubuntu)\n  become: yes\n  copy: src=ubuntu_tor@.service dest=/lib/systemd/system/tor@.service owner=root mode=0644 backup=yes\n  when: ansible_distribution == 'Ubuntu'\n  notify: systemctl daemon-reload\n\n- name: Ensure AppArmor allows access to necessary files (Ubuntu)\n  become: yes\n  lineinfile: dest=/etc/apparmor.d/local/system_tor line={{ item }}\n  with_items:\n    - '/etc/tor/enabled/*\\ r,'\n    - '/{,var/}run/tor/*.pid\\ w,'\n    - '/var/lib/tor/**\\ w,'\n  when: ansible_distribution == 'Ubuntu'\n  notify: restart apparmor\n\n- meta: flush_handlers\n"}, {"commit_sha": "9966c6de1ed4ef5071a9bea83b4bb69a11dd32ba", "sha": "21750cc2430a1150a4ee9dd6695e9c60276e0546", "filename": "roles/dnsmasq/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for dnsmasq\n- name: Restart dnsmasq\n  service: name=dnsmasq state=restarted\n  sudo: yes\n\n- name: Reload dnsmasq\n  service: name=dnsmasq state=reloaded\n  sudo: yes\n"}, {"commit_sha": "e8eb28b4b4b1c4fb2490b8198570166b9ca23ab2", "sha": "6c835a8d10fd9fa8d231497f7091bd4dca065911", "filename": "roles/st2/tasks/4.dependencies.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n- name: dependencies | Install system dependencies\n  sudo: true\n  apt:\n    name: \"{{ item }}\"\n    update_cache: yes\n    state: present\n  with_items:\n    - git\n    - python-dev\n    - python-pip\n    - realpath\n  tags: [st2, dependencies]\n\n- name: dependencies | Upgrade pip\n  sudo: true\n  pip:\n    name: pip\n    extra_args: \"-U\"\n\n- name: dependencies | Install pip virtualenv\n  sudo: true\n  pip:\n    name: virtualenv\n  tags: [st2, dependencies]\n\n- name: dependencies | Install st2 pip dependencies\n  sudo: true\n  pip:\n    requirements: https://raw.githubusercontent.com/StackStorm/st2/master/requirements.txt\n  tags: [st2, dependencies]\n"}, {"commit_sha": "f565940c5163524c7834123625c804e5f69c2b10", "sha": "ed006ba5ad53b1acd98942256f45f73160edd1dc", "filename": "tasks/FreeBSD/main.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/FreeBSD/main.yml: FreeBSD specific set-up\n# This takes care of base prerequisites for FreeBSD\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure the Sensu group is present\n    group: name={{ sensu_group_name }} state=present\n\n  - name: Ensure the Sensu user is present\n    user:\n      name: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      shell: /bin/false\n      home: \"{{ sensu_config_path }}\"\n      createhome: true\n      state: present\n\n  - name: Install prerequisite packages\n    pkgng:\n      name: \"{{ item }}\"\n      state: present\n    with_items:\n      - bash\n      - ca_root_nss\n\n  - name: Retrieve the sensu txz package\n    get_url:\n      url: \"{{ sensu_pkg_download_url }}\"\n      dest: \"{{ sensu_pkg_download_path }}\"\n    register: sensu_txz\n\n  - name: Install sensu from the retrieved txz package\n    command: \"pkg add {{ sensu_pkg_download_path }}\"\n    when: sensu_txz|changed\n"}, {"commit_sha": "8cf75eb68465f1126872131afd102e05068a9df2", "sha": "2ecf11ba471a9fcee1632f7026c4867d14d55757", "filename": "tasks/freebsd_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Setup FreeBSD specific variables (set_fact)\n  set_fact:\n    tor_DataDir: /var/db/tor\n    tor_ConfDir: /usr/local/etc/tor/enabled\n  tags:\n   - configure\n   - createdir\n\n- name: Ensure Tor is installed (FreeBSD)\n  sudo: yes\n  pkgng: name=tor state=present\n\n# temporary solution until rc.d supports multiple instances\n- name: Ensure Tor starts at boot (FreeBSD)\n  sudo: yes\n  lineinfile: dest=/etc/rc.local line=\"/usr/local/bin/tor -f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\" create=yes\n  with_nested:\n   - tor_ips\n   - tor_ports\n\n- name: If LogDir is a file, rename it (FreeBSD)\n  sudo: yes\n  shell: \"test -f {{ tor_LogDir }} && mv {{ tor_LogDir }} {{ tor_LogDir }}.bk-`date '+%Y-%m-%d_%H%M%S'`\"\n  ignore_errors: yes\n"}, {"commit_sha": "bf6e08dcb2440421477b6536ff6a8d11adc2be17", "sha": "07694112839bfa048124eddb4ececefefac20b2f", "filename": "roles/handlers/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- name: restart consul\n  service:\n    name: consul\n    state: restarted\n  sudo: yes\n  notify:\n    - wait for consul to listen\n\n- name: wait for consul to listen\n  wait_for:\n    host: localhost\n    port: 8500\n\n- name: restart docker\n  service:\n   name: docker\n   state: restarted\n  sudo: yes\n"}, {"commit_sha": "e8eb28b4b4b1c4fb2490b8198570166b9ca23ab2", "sha": "d87f389f70a53ff41e8027d114ed2b76856e4e10", "filename": "roles/st2/tasks/3.user.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "# Create system user, on whose behalf remote/local action runners would work\n# See: http://docs.stackstorm.com/install/config.html#configure-ssh\n---\n- name: user | Create system user\n  sudo: yes\n  user:\n    name: \"{{ st2_system_user }}\"\n    home: \"/home/{{ st2_system_user }}\"\n    generate_ssh_key: yes\n    ssh_key_file: \"{{ st2_ssh_key_file }}\"\n    state: present\n  register: _user\n  tags: [st2, user]\n\n- name: user | Authorize key-based access for system user\n  sudo: yes\n  sudo_user: \"{{ st2_system_user }}\"\n  authorized_key:\n    user: \"{{ st2_system_user }}\"\n    key: \"{{ _user.ssh_public_key }}\"\n    state: present\n  tags: [st2, user]\n\n- name: user | Add system user to sudoers\n  sudo: yes\n  lineinfile:\n    create: yes\n    dest: /etc/sudoers.d/st2\n    mode: 0440\n    regexp: \"^{{ st2_system_user }} ALL=\"\n    line: \"{{ st2_system_user }} ALL=(ALL) NOPASSWD: SETENV: ALL\"\n    state: present\n    validate: 'visudo -cf %s'\n  tags: [st2, user]\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "77c0f642f62578b6fbe6dfddff651c059e311824", "filename": "tasks/section_09_level1_03.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 9.3.1 Set SSH Protocol to 2 (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Protocol'\n        state=present\n        line='Protocol 2'\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n  - name: 9.3.2 Set LogLevel to INFO (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^LogLevel'\n        state=present\n        line='LogLevel INFO'\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.2\n\n  - name: 9.3.3 Set Permissions on /etc/ssh/sshd_config (Scored)\n    file: path='/etc/ssh/sshd_config' owner=root group=root mode=600\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.3\n\n#Regroups sections 9.3.4 9.3.7 9.3.8 9.3.9 9.3.10\n  - name: 9.3.{4,7,8,9,10} Disable some SSH options (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^{{ item }}'\n        line='{{ item }} no'\n        state=present\n    with_items:\n      - X11Forwarding\n      - HostbasedAuthentication\n      - PermitRootLogin\n      - PermitEmptyPasswords\n      - PermitUserEnvironment\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.4\n      - section9.3.7\n      - section9.3.8\n      - section9.3.9\n      - section9.3.10\n\n  - name: 9.3.5 Set SSH MaxAuthTries to 4 or Less (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^MaxAuthTries'\n        line='MaxAuthTries 4'\n        state=present\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.5\n\n  - name: 9.3.6 Set SSH IgnoreRhosts to Yes (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^IgnoreRhosts'\n        line='IgnoreRhosts yes'\n        state=present\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.6\n\n  - name: 9.3.11 Use Only Approved Cipher in Counter Mode (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Ciphers'\n        line='Ciphers aes128-ctr,aes192-ctr,aes256-ctr'\n        state=present\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.11\n\n  - name: 9.3.12.1 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveInterval'\n        line='ClientAliveInterval 300'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.1\n\n  - name: 9.3.12.2 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveCountMax'\n        line='ClientAliveCountMax 0'\n        state=present\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.2\n\n  - name: 9.3.13.1 Limit Access via SSH (Scored)\n    shell: grep AllowUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    always_run: True\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.1\n\n  - name: 9.3.13.2 Limit Access via SSH (Scored)\n    shell: grep AllowGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    always_run: True\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.2\n\n  - name: 9.3.13.3 Limit Access via SSH (Scored)\n    shell: grep DenyUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    always_run: True\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.3\n\n  - name: 9.3.13.4 Limit Access via SSH (Scored)\n    shell: grep DenyGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    always_run: True\n    ignore_errors: True\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.4\n\n  - name: 9.3.14 Set SSH Banner (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Banner'\n        line='Banner /etc/issue.net'\n        state=present\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.14\n\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "95c14449a0b084e8cdc4f8469901171b8b244d74", "filename": "roles/prometheus/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for prometheus\nprometheus_consul_host: \"{{ ansible_ssh_host }}\"\nprometheus_config_dir: /etc/prometheus\nprometheus_node_exporter_image: \"prom/node-exporter:latest\"\nprometheus_node_exporter_port: 9100\nprometheus_node_exporter_hostname: \"{{ ansible_ssh_host }}\"\nprometheus_node_exporter_consul_service_id: \"{{ ansible_hostname }}:node-exporter:9100\"\nprometheus_consul_dir: /etc/consul.d\n"}, {"commit_sha": "15d2da095f9bd54a50954dee18597710e1951943", "sha": "51c0236278000ebcfa8c2b0390a7694e0f8ca16a", "filename": "tests/tasks/main.yml", "repository": "ansiblebit/oracle-java", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# file: primogen/tests/tasks\n#\n# Test tasks to verify role execution.\n#\n\n- name: is oracle_java_installed fact set?\n  fail:\n    msg=\"oracle_java_installed fact is not defined!\"\n  when: not oracle_java_installed is defined\n\n- name: is oracle_java_installed fact true?\n  fail:\n    msg=\"oracle_java_installed fact is false!\"\n  when: not oracle_java_installed\n\n- name: is oracle_java_version_installed fact set?\n  fail:\n    msg=\"oracle_java_installed fact is not defined!\"\n  when: not oracle_java_version_installed is defined\n\n- name: is oracle_java_version_installed value correct?\n  fail:\n    msg=\"oracle_java_version_installed value is {{ oracle_java_version_installed }} instead of {{ expected_java_version }}!\"\n  when: oracle_java_version_installed != expected_java_version\n\n- name: register result_java_version with host installed Java version\n  shell: java -version 2>&1 | head -n 1 | awk '{ print $3 }' | awk -F '\"' '{ print $2 }'\n  register: result_java_version\n  changed_when: no\n\n- name: is installed Java version on host correct?\n  fail:\n    msg=\"java -version output was {{ result_java_version.stdout }} instead of {{ expected_java_version }}\"\n  when: result_java_version.stdout != expected_java_version\n\n- name: ensure keytool and javadoc are present\n  shell: \"test -h /usr/bin/{{ item }}\"\n  changed_when: no\n  with_items:\n    - keytool\n    - java\n    - javadoc\n\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "c32430094cb038737cf676abb16082c4a153b1d9", "filename": "roles/weave/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for weave\n- name: restart weave\n  become: yes\n  service:\n    name: weave\n    state: restarted\n  notify:\n    - wait for weave socket\n\n- name: restart weaveproxy\n  become: yes\n  service:\n    name: weaveproxy\n    state: restarted\n\n- name: wait for weave socket\n  wait_for:\n    port: 6783\n    delay: 10\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "00eb0495f73f92553c722f8b35f3bd057259c0b9", "filename": "tasks/section_06.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - include: section_06_level1.yml\n    tags:\n      - section06\n      - level1\n\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "3fdd866daf4b68eb0f15e1801cd03ac7687ff3e3", "filename": "roles/registrator/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for registrator\n- name: restart registrator\n  become: yes\n  service:\n   name: registrator\n   state: restarted\n"}, {"commit_sha": "bf6e08dcb2440421477b6536ff6a8d11adc2be17", "sha": "0873c8c6b87152c21f4d57b6c024b193252a1555", "filename": "roles/haproxy/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for haproxy\nhaproxy_image: asteris/haproxy-consul\nhaproxy_image_tag: latest\n\n# Set the domain that haproxy uses to match URLs to internal apps.\n# For example, if all your apps will be\n#    app1.example.com, app2.example.com, etc.  set this to 'example.com'\nhaproxy_domain: example.com\n\nconsul_template_dir: /mnt/consul-template.d\nconsul_template_loglevel: debug\nconsul_backend: consul.service.consul:8500\nconsul_template_version: 0.8.0\n"}, {"commit_sha": "35ca6852d9333ef6c3ed223239f45b840c487d60", "sha": "41cede55a7723c6696bdd6f5536d3cc95908c440", "filename": "roles/docker/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for docker\n- name: remove docker override\n  file:\n    path: /etc/init/docker.override\n    state: absent\n  tags:\n    - docker\n\n- name: configure docker graph directory\n  sudo: yes\n  lineinfile:\n    dest: /etc/default/docker\n    state: present\n    regexp: ^DOCKER_OPTS=.*--graph.*\n    line: 'DOCKER_OPTS=\\\"$DOCKER_OPTS --graph={{ docker_graph_dir }}\\\"'\n\n- name: configure docker temporary directory\n  sudo: yes\n  lineinfile:\n    dest: /etc/default/docker\n    state: present\n    line: 'DOCKER_TMPDIR=\\\"{{ docker_tmp_dir }}\\\"'\n\n- name: ensure docker is running (and enable it at boot)\n  service:\n    name: docker\n    state: started\n    enabled: yes\n  tags:\n    - docker\n"}, {"commit_sha": "5eb44163b7f6328c1f30168fa86326458d5dbaff", "sha": "c162e9aaee23f1b06a5f1989ef29eca9e4f368f5", "filename": "tests/tasks/main.yml", "repository": "ansiblebit/oracle-java", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# file: primogen/tests/tasks\n#\n# Test tasks to verify role execution.\n#\n\n- name: is oracle_java_installed fact set?\n  fail:\n    msg=\"oracle_java_installed fact is not defined!\"\n  when: not oracle_java_installed is defined\n\n- name: is oracle_java_installed fact true?\n  fail:\n    msg=\"oracle_java_installed fact is false!\"\n  when: not oracle_java_installed\n\n- name: is oracle_java_version_installed fact set?\n  fail:\n    msg=\"oracle_java_installed fact is not defined!\"\n  when: not oracle_java_version_installed is defined\n\n- name: is oracle_java_version_installed value correct?\n  fail:\n    msg=\"oracle_java_version_installed value is {{ oracle_java_version_installed }} instead of {{ expected_java_version }}!\"\n  when: oracle_java_version_installed != expected_java_version\n\n- name: register result_java_version with host installed Java version\n  shell: java -version 2>&1 | head -n 1 | awk '{ print $3 }' | awk -F '\"' '{ print $2 }'\n  register: result_java_version\n  changed_when: no\n\n- name: is installed Java version on host correct?\n  fail:\n    msg=\"java -version output was {{ result_java_version.stdout }} instead of {{ expected_java_version }}\"\n  when: result_java_version.stdout != expected_java_version\n"}, {"commit_sha": "f565940c5163524c7834123625c804e5f69c2b10", "sha": "5c1f2a08c1875e00cd6fa6a40466c77398b37c06", "filename": "tasks/Ubuntu/dashboard.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/Ubuntu/dashboard.yml: Deployment of the Uchiwa dashboard\n# Specific to Ubuntu\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Retrieve the Uchiwa deb package\n    get_url:\n      url: \"{{ uchiwa_pkg_deb_download_url }}\"\n      dest: \"{{ uchiwa_pkg_download_path }}\"\n      sha256sum: \"{{ uchiwa_pkg_download_sha256sum }}\"\n\n  - name: Install Uchiwa from the retrieved deb package\n    apt: deb={{ uchiwa_pkg_download_path }}\n\n  - name: Deploy Uchiwa config\n    template:\n      src: uchiwa_config.json.j2\n      dest: \"{{ sensu_config_path }}/uchiwa.json\"\n    notify: restart uchiwa service\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "9115ef9fb36f874be67a63363240be34825f2fea", "filename": "tasks/section_03.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - include: section_03_level1.yml\n    tags:\n      - section03\n      - level1\n\n"}, {"commit_sha": "32211ebd2a9f45112f8dceda80bc95d0db029fb4", "sha": "59fb490cc93320cf28b104f435c9bf3549f7ce71", "filename": "tasks/rpm_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Setup RPM specific variables (set_fact)\n  set_fact:\n    tor_user: toranon\n    tor_ConfDir: /etc/tor\n    tor_RunAsDaemon: 0\n    tor_DataDir: /var/lib/tor-instances\n  tags:\n   - reconfigure\n   - renewkey\n\n- name: Ensure tor package is installed (dnf)\n  become: yes\n  dnf: name=tor,libselinux-python,libsemanage-python state=present\n  when: ansible_pkg_mgr == 'dnf'\n  notify: re-gather facts\n\n# re-gathering facts after installing libselinux-python on F23\n# is a workaround for https://github.com/ansible/ansible-modules-core/issues/2432\n- meta: flush_handlers\n\n- name: Ensure EPEL repo is installed (yum)\n  become: yes\n  yum: name=epel-release\n  when: ansible_pkg_mgr == 'yum'\n\n- name: Ensure tor package is installed (yum)\n  become: yes\n  yum: name=tor,libsemanage-python state=present\n  when: ansible_pkg_mgr == 'yum'\n\n- name: Ensure SELinux boolean (tor_can_network_relay) is set appropriately (Fedora)\n  become: yes\n  seboolean: name=tor_can_network_relay state=yes persistent=yes\n  when: ansible_selinux.status == 'enabled'\n"}, {"commit_sha": "fa66f2d6f5193cce5c2f9086e78f9bff39133e60", "sha": "195bbb694ee97b5ee742114e67c4a2314b3729fb", "filename": "tasks/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- include: apt_install.yml\n  when: ansible_pkg_mgr == 'apt'\n  tags:\n   - debian\n   - install\n\n- include: rpm_install.yml\n  when: ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'\n  tags:\n   - centos\n   - fedora\n   - install\n\n- include: openbsd_install.yml\n  when: ansible_pkg_mgr == 'openbsd_pkg'\n  tags:\n   - openbsd\n   - install\n\n- include: freebsd_install.yml\n  when: ansible_pkg_mgr == 'pkgng'\n  tags:\n   - freebsd\n   - install\n\n- include: configure.yml\n  tags:\n   - debian\n   - centos\n   - fedora\n   - openbsd\n   - freebsd\n\n- include: linux_service.yml\n  when: ansible_system == 'Linux'\n  tags:\n   - debian\n   - centos\n   - fedora\n\n- include: openbsd_service.yml\n  when: ansible_system == 'OpenBSD'\n  tags:\n   - openbsd\n\n- include: freebsd_service.yml\n  when: ansible_system == 'FreeBSD'\n  tags:\n   - freebsd\n"}, {"commit_sha": "9966c6de1ed4ef5071a9bea83b4bb69a11dd32ba", "sha": "641aeb87503b9c0ac82a3d792b277d8e19b6fd2a", "filename": "roles/serverspec/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for serverspec\n- name: install bundler\n  command: gem install bundler --no-ri --no-rdoc\n  args:\n    creates: /usr/local/bin/bundler\n  when: serverspec_run_tests and serverspec_install_bundler\n  tags:\n    - serverspec\n\n- name: install bundle files\n  command: bundle install --path vendor\n  args:\n    chdir: \"{{ serverspec_tests_path }}\"\n    creates: \"{{ serverspec_tests_path }}/vendor\"\n  when: serverspec_run_tests\n  tags:\n    - serverspec\n\n- name: run serverspec tests\n  command: \"bundle exec rake serverspec:{{ test_role }}\"\n  args:\n    chdir: \"{{ serverspec_tests_path }}\"\n  when: test_role is defined and serverspec_run_tests\n  tags:\n    - serverspec\n"}, {"commit_sha": "9eb1a8fa8e281ef06687c1851f51fa0beec3e232", "sha": "ae9970c7b84062eeff904c8b318bc530b96a8614", "filename": "tasks/check_requirements.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: Check if OS is Debian-based (we do not support others)\n    debug: msg=\"Check OS family\"\n    failed_when: ansible_os_family != \"Debian\"\n\n  - name: Check if Ansible version is supported\n    debug: msg=\"Check Ansible version\"\n    failed_when: ansible_version.full | version_compare('1.8', '<')\n"}, {"commit_sha": "35ca6852d9333ef6c3ed223239f45b840c487d60", "sha": "03b0f21cc926e2879289b3746d1d834df85d3169", "filename": "roles/zookeeper/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- name: ensure zookeeper is running (and enable it at boot)\n  sudo: yes\n  service:\n    name: zookeeper\n    state: started\n    enabled: yes\n  tags:\n    - zookeeper\n\n- name: Create zookeeper config file\n  template:\n    src: zoo.cfg.j2\n    dest: /etc/zookeeper/conf/zoo.cfg\n  sudo: yes\n  notify:\n    - Restart zookeeper\n  tags:\n    - zookeeper\n\n- name: Create zookeeper myid file\n  copy:\n    content: \"{{zookeeper_id}}\"\n    dest: /etc/zookeeper/conf/myid\n    mode: 0644\n  sudo: yes\n  notify:\n    - Restart zookeeper\n  tags:\n    - zookeeper\n\n- name: Set Zookeeper consul service definition\n  sudo: yes\n  template:\n    src: zookeeper-consul.j2\n    dest: \"{{ consul_dir }}/zookeeper.json\"\n  notify:\n    - Restart consul\n  tags:\n    - zookeeper\n"}, {"commit_sha": "f565940c5163524c7834123625c804e5f69c2b10", "sha": "759f8002ac3d63da5d5d18f318d8064bae8409fc", "filename": "tasks/CentOS/rabbit.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/CentOS/rabbit.yml: Deploy RabbitMQ\n# Specific to CentOS\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure Erlang & RabbitMQ are installed\n    yum:\n      name:\n        - erlang\n        - rabbitmq-server\n      state: present\n      enablerepo: epel\n"}, {"commit_sha": "f565940c5163524c7834123625c804e5f69c2b10", "sha": "7db0e3209729eafcfdd927b910cdc682f066d246", "filename": "tasks/Ubuntu/redis.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/Ubuntu/redis.yml: Deploy redis\n# Specific to Ubuntu\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure the redis APT repo is present\n    apt_repository:\n      repo: \"{{ redis_pkg_repo }}\"\n      state: present\n      update_cache: true\n\n  - name: Ensure redis is installed\n    apt:\n      name: \"{{ redis_pkg_name }}\"\n      state: \"{{ redis_pkg_state }}\"\n      update_cache: true\n\n  - name: Deploy redis systemd service manifest\n    copy:\n      src: redis_systemd.service\n      dest: /etc/systemd/system/redis.service\n"}, {"commit_sha": "694a4890fcf0daa375d6a173511f6ff7dd0f2335", "sha": "d44fc6c0048577d53181ed30da976c89ad16eb46", "filename": "tasks/rpm_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Setup RPM specific variables (set_fact)\n  set_fact:\n    tor_user: toranon\n    tor_ConfDir: /etc/tor\n    tor_RunAsDaemon: 0\n    tor_DataDir: /var/lib/tor-instances\n  tags:\n   - reconfigure\n   - renewkey\n   - createdir\n\n- name: Ensure tor package is installed (dnf)\n  become: yes\n  dnf: name=tor,libselinux-python,libsemanage-python state=present\n  when: ansible_pkg_mgr == 'dnf'\n  notify: re-gather facts\n\n# re-gathering facts after installing libselinux-python on F23\n# is a workaround for https://github.com/ansible/ansible-modules-core/issues/2432\n- meta: flush_handlers\n\n- name: Ensure EPEL repo is installed (yum)\n  become: yes\n  yum: name=epel-release\n  when: ansible_pkg_mgr == 'yum'\n\n- name: Ensure tor package is installed (yum)\n  become: yes\n  yum: name=tor,libsemanage-python state=present\n  when: ansible_pkg_mgr == 'yum'\n\n- name: Ensure SELinux boolean (tor_can_network_relay) is set appropriately (Fedora)\n  become: yes\n  seboolean: name=tor_can_network_relay state=yes persistent=yes\n  when: ansible_selinux.status == 'enabled'\n"}, {"commit_sha": "e90eac100980db35187b1c8829e3284cc5db3e30", "sha": "d031d701af8b73f2b3ec51a7b01ed7f6059e67ca", "filename": "tasks/section_09_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 9.1.1.1 Check that cron conf file exists (check) (Scored)\n    stat: path=/etc/init/cron.conf\n    register: cron_conf_stat\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.1\n\n  - name: 9.1.1.2 Enable cron Daemon (Scored)\n    service: >\n        name=cron\n        state=started\n        enabled=yes\n    when: not cron_conf_stat.stat.exists\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.2\n\n  - name: 9.1.2 Set User/Group Owner and Permission on /etc/crontab (Scored)\n    file: path='/etc/crontab' owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.2\n\n  - name: 9.1.3 Set User/Group Owner and Permission on /etc/cron.hourly (Scored)\n    file: path=/etc/cron.hourly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.3\n\n  - name: 9.1.4 Set User/Group Owner and Permission on /etc/cron.daily (Scored)\n    file: path=/etc/cron.daily owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.4\n\n  - name: 9.1.5 Set User/Group Owner and Permission on /etc/cron.weekly(Scored)\n    file: path=/etc/cron.weekly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.5\n\n  - name: 9.1.6 Set User/Group Owner and Permission on /etc/cron.monthly(Scored)\n    file: path=/etc/cron.monthly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.6\n\n  - name: 9.1.7 Set User/Group Owner and Permission on /etc/cron.d (Scored)\n    file: path=/etc/cron.d owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.7\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (Scored)\n    file: path={{ item }} state=absent\n    with_items:\n        - /etc/cron.deny\n        - /etc/at.deny\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n  \n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    stat: path=/etc/cron.allow\n    register: cron_allow_path\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    shell: touch /etc/cron.allow\n    when: cron_allow_path.stat.exists == False\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (Scored)\n    file: path=/etc/cron.allow owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    stat: path=/etc/at.allow\n    register: at_allow_path\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    shell: touch /etc/at.allow\n    when: at_allow_path.stat.exists == False\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (Scored)\n    file: path=/etc/at.allow owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n \n  - name: 9.2.1 Set Password Creation Requirement Parameters Using pam_cracklib (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password'\n        regexp=\"pam_cracklib.so\"\n        line=\"password required pam_cracklib.so retry=3 minlen=14 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.1\n\n#Note for section 9.2.2:\n#If a user has been locked out because they have reached the maximum consecutive failure count \n#defined by denied= in the pam_tally2.so module, the user can be unlocked by issuing the command\n#/sbin/pam_tally2 -u username --reset\n#This command sets the failed count to 0, effectively unlocking the user\n  - name: 9.2.2 Set Lockout for Failed Password Attempts (Not Scored)\n    lineinfile: >\n        dest='/etc/pam.d/login' \n        regexp='pam_tally2'\n        line=\"auth required pam_tally2.so onerr=fail audit silent deny=5 unlock_time=900\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.2\n\n  - name: 9.2.3 Limit Password Reuse (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password' \n        regexp='remember=5'\n        line=\"password sufficient pam_unix.so remember=5\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.3\n\n  - name: 9.3 Check if ssh is installed (check)\n    stat: path='/etc/ssh/sshd_config'\n    register: ssh_config_file\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n\n  - name: 9.3.1 Set SSH Protocol to 2 (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config' \n        regexp='^Protocol'\n        state=present\n        line='Protocol 2'\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n  - name: 9.3.2 Set LogLevel to INFO (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config' \n        regexp='^LogLevel'\n        state=present\n        line='LogLevel INFO'\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.2\n\n  - name: 9.3.3 Set Permissions on /etc/ssh/sshd_config (Scored)\n    file: path='/etc/ssh/sshd_config' owner=root group=root mode=600\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.3\n\n#Regroups sections 9.3.4 9.3.7 9.3.8 9.3.9 9.3.10\n  - name: 9.3.{4,7,8,9,10} Disable some SSH options (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^{{ item }}'\n        line='{{ item }} no'\n        state=present\n    with_items: \n      - X11Forwarding\n      - HostbasedAuthentication\n      - PermitRootLogin\n      - PermitEmptyPasswords\n      - PermitUserEnvironment\n    tags:\n      - section9\n      - section9.3\n      - section9.3.4\n      - section9.3.7\n      - section9.3.8\n      - section9.3.9\n      - section9.3.10\n\n  - name: 9.3.5 Set SSH MaxAuthTries to 4 or Less (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^MaxAuthTries'\n        line='MaxAuthTries 4'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.5\n\n  - name: 9.3.6 Set SSH IgnoreRhosts to Yes (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^IgnoreRhosts'\n        line='IgnoreRhosts yes'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.6\n\n  - name: 9.3.11 Use Only Approved Cipher in Counter Mode (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Ciphers'\n        line='Ciphers aes128-ctr,aes192-ctr,aes256-ctr'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.11\n\n  - name: 9.3.12.1 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveInterval'\n        line='ClientAliveInterval 300'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.1\n\n  - name: 9.3.12.2 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveCountMax'\n        line='ClientAliveCountMax 0'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.2\n\n  - name: 9.3.13.1 Limit Access via SSH (Scored)\n    shell: grep AllowUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.1\n\n  - name: 9.3.13.2 Limit Access via SSH (Scored)\n    shell: grep AllowGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.2\n\n  - name: 9.3.13.3 Limit Access via SSH (Scored)\n    shell: grep DenyUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.3\n\n  - name: 9.3.13.4 Limit Access via SSH (Scored)\n    shell: grep DenyGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.4\n\n  - name: 9.3.14 Set SSH Banner (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Banner'\n        line='Banner /etc/issue.net'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.14\n\n  - name: 9.4 Restrict root Login to System Console (Not Scored)\n    stat: path=/etc/securetty\n    register: securetty_file\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.4 Restrict root Login to System Console (Not Scored)\n    debug: msg='*** Check /etc/securetty for console allowed for root access ***'\n    when: securetty_file.stat.exists == True\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.5.1 Restrict Access to the su Command (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/su'\n        line='auth            required        pam_wheel.so use_uid'\n        state=present\n    tags:\n      - section9\n      - section9.5\n      - section9.5.1\n"}, {"commit_sha": "4aaf839a9916f65d12b8964b23dbc6848a73ca67", "sha": "dd0a6224ae61057d852d8e5e780aef32777a9bba", "filename": "roles/consul/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# defaults file for consul\nconsul_is_server: yes\nconsul_dc: dc1\nconsul_servers_group: consul_servers\nconsul_advertise: \"{{ ansible_default_ipv4.address }}\"\nconsul_bind_addr: \"{{ ansible_default_ipv4.address }}\"\nconsul_bootstrap_expect: \"{{ groups[consul_servers_group] | length }}\"\nconsul_client_addr: \"0.0.0.0\"\nconsul_atlas_join: false\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "802a27b16cafb882654708db2573b266963e0fd1", "filename": "roles/zookeeper/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for zookeeper\n- name: restart zookeeper\n  service:\n    name: zookeeper\n    state: restarted\n  become: yes\n\n- name: start zookeeper\n  service:\n    name: zookeeper\n    state: started\n  become: yes\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "9eaca3c8649e39365eb6be0f49812de32d7ef37b", "filename": "roles/cadvisor/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "# tasks for running cadvisor\n- name: deploy cadvisor service\n  sudo: yes\n  sudo_user: root\n  template:\n    src: cadvisor.service.j2\n    dest: /etc/systemd/system/cadvisor.service\n  tags:\n    - cadvisor\n\n# Attach to the running container, or start it if needed\n# and forward all signals so that the process manager can detect\n# when a container stops and correctly restart it.\n- name: ensure cadvisor is running (and enable it at boot)\n  sudo: yes\n  service:\n    name: cadvisor\n    state: started\n    enabled: yes\n  tags:\n    - cadvisor\n\n- name: get cadvisor container ip\n  sudo: yes\n  command: >\n    docker inspect -f \\{\\{' '.NetworkSettings.IPAddress' '\\}\\} cadvisor\n  register: cadvisor_container_ip\n  tags:\n    - cadvisor\n\n#- name: Set cadvisor consul service definition\n#  sudo: yes\n#  template:\n#   src: cadvisor-consul.j2\n#    dest: \"{{ cadvisor_consul_dir }}/cadvisor.json\"\n#  notify:\n#    - restart consul\n#  when: cadvisor_enabled\n#  tags:\n#    - cadvisor\n"}, {"commit_sha": "32211ebd2a9f45112f8dceda80bc95d0db029fb4", "sha": "c7efced2abf716b2e15e3b10a7b15800f9668a65", "filename": "tasks/configure.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Ensure local DataDir folders exist (LOCAL)\n  file: path={{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}\n    state=directory mode=700\n  delegate_to: 127.0.0.1\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - createdir\n\n- name: Ensure all relay keys exist (LOCAL)\n  local_action: command tor --PublishServerDescriptor 0 --orport auto --list-fingerprint --datadirectory \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}\" --Log \"err stdout\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Generate new Ed25519 signing keys (LOCAL)\n  local_action: command tor --keygen --SigningKeyLifetime {{ tor_signingkeylifetime_days}}\\ days --datadirectory \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}\" --Log \"err stdout\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - renewkey\n\n- name: Detect duplicate relay keys across relays (LOCAL)\n  shell: sha1sum {{ tor_offline_masterkey_dir }}/*/keys/secret_id_key {{ tor_offline_masterkey_dir }}/*/keys/ed25519_master_id_secret_key|cut -d/ -f1|sort|uniq -d|wc -l\n  delegate_to: 127.0.0.1\n  register: dupcount\n\n- name: Abort on duplicate relay keys\n  fail: msg=\"Duplicate relay key detected! Aborting.\"\n  when: dupcount.stdout != \"0\"\n\n- name: Detect if Ed25519 master keys are on the relay\n  stat: path={{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/ed25519_master_id_secret_key\n  become: yes\n  register: masterkeycheck\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Abort if Ed25519 master keys are on the relay\n  fail: msg=\"\n\n            Ed25519 MASTER KEY detected on the relay - it is NOT supposed to be there! Aborting.\"\n  when: item.stat.exists == True\n  with_items: \"{{ masterkeycheck.results }}\"\n\n- name: Collect fingerprints for MyFamily (LOCAL)\n  shell: cut {{ tor_offline_masterkey_dir }}/*/fingerprint -d\" \" -f2|xargs|sed -e 's/ /,/g'\n  delegate_to: 127.0.0.1\n  register: family\n  tags:\n   - reconfigure\n\n- name: Ensure per-instance tor users exist\n  become: yes\n  user: name=_tor-{{ item.0.ipv4 }}_{{ item.1.orport }} system=yes shell=/bin/false createhome=no home={{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure per-instance config folders exist (Debian only)\n  become: yes\n  file: path={{ tor_ConfDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }} state=directory mode=755\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  when: ansible_pkg_mgr == 'apt'\n\n- name: Ensure DataDir exists\n  become: yes\n  file: path={{ tor_DataDir }}\n    state=directory\n    owner=root\n    mode=0755\n\n- name: Ensure \"keys\" subfolder exists\n  become: yes\n  file: path={{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys\n    state=directory\n    owner=\"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    group=\"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode=0700\n    recurse=yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure RSA key is in place (without overriding existing keys)\n  become: yes\n  copy: src={{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\n   dest={{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\n   owner=\"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n   mode=700 force=no\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'secret_id_key' ]\n\n- name: Fetch RSA key for comparision\n  become: yes\n  fetch: src={{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\n    dest={{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}.untrustedremotekey\n    flat=yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'secret_id_key' ]\n\n- name: Compare local vs. remote RSA key (secret_id_key)\n  local_action: shell sha1sum {{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-\"{{ item.0.ipv4 }}_{{ item.1.orport }}\"/keys/secret_id_key*|cut -d/ -f1|uniq -d|wc -l\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  register: rsakey\n\n- name: Abort if local and remote RSA keys do not match\n  fail: 'msg=\"\n\n\n   Key MISMATCH detected: Remote RSA key does not match local key - manual intervention required.\n\n   We detected that the remote host uses an RSA key that was not generated by us.\n   We will not override it with our locally generated key.\n\n   If you want to make use of the remote RSA key you have to override the local key manually:\n\n\n   cd ~/.tor/offlinemasterkeys/<inventoryname>-<IP_port>/keys\n\n   mv secret_id_key.untrustedremotekey secret_id_key\"'\n  when: item.stdout != \"1\"\n  with_items: \"{{ rsakey.results }}\"\n\n# this task is separated from the task named \"Ensure RSA key is in place\" because it is not run with 'force=no'\n- name: Transmit new Ed25519 signing keys\n  become: yes\n  copy: src={{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\n   dest={{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\n   owner=\"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n   mode=700\n   setype=tor_var_lib_t\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'ed25519_signing_cert', 'ed25519_signing_secret_key' ]\n  tags:\n   - renewkey\n\n# This needs to be at the end to fix SELinux contexts recursively\n- name: Ensure per-instance DataDir have proper permissions\n  become: yes\n  file: path={{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\n    state=directory\n    owner=\"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    group=\"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode=0700\n    recurse=yes\n    setype=tor_var_lib_t\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure Tor config directory exists\n  become: yes\n  file: path={{ tor_ConfDir }}\n    state=directory\n    owner=root\n    group={{ tor_user }}\n    mode=755\n\n- name: Ensure tor-exit-notice.html is present (if we are an exit)\n  become: yes\n  template: src=tor-exit-notice.html dest={{ tor_ConfDir }}/tor-exit-notice.html mode=444\n  when: tor_ExitRelay == True and tor_ExitNoticePage == True\n\n- name: Generating torrc file(s)\n  become: yes\n  template: >\n    src=torrc\n    dest=\"{{ (ansible_pkg_mgr != 'apt')| ternary(tor_ConfDir ~ '/' ~ item.0.ipv4 ~ '_' ~ item.1.orport ~ '.torrc', tor_ConfDir ~ '/' ~ item.0.ipv4 ~ '_' ~ item.1.orport ~ '/torrc') }}\"\n    owner=root\n    mode=0644\n    backup=yes\n    validate=\"tor --verify-config -f %s\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  register: instances\n  tags:\n   - reconfigure\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "c6d4254bb064590c79e386f25d5294c07e3722b6", "filename": "roles/mesos/tasks/master.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# Tasks for Master nodes\n- name: create mesos-master work directory\n  file:\n    path: \"{{ mesos_master_work_dir }}\"\n    state: directory\n    mode: 0755\n  become: yes\n  tags:\n    - mesos-master\n\n- name: deploy mesos-master service\n  become: yes\n  become_user: root\n  template:\n    src: mesos-master.service.j2\n    dest: /etc/systemd/system/mesos-master.service\n  notify:\n    - reload systemd\n    - restart mesos master\n  tags:\n    - mesos-master\n\n- name: ensure mesos-master is running (and enable it at boot)\n  become: yes\n  service:\n    name: mesos-master\n    state: started\n    enabled: yes\n  tags:\n    - mesos-master\n\n- name: Set mesos-master consul service definition\n  become: yes\n  template:\n    src: mesos-master-consul.j2\n    dest: \"{{ consul_dir }}/mesos-master.json\"\n  notify:\n    - restart consul\n  tags:\n    - mesos-master\n\n- name: run prometheus mesos master exporter container\n  when: prometheus_enabled|bool\n  docker:\n    name: mesos-exporter\n    image: \"{{ prometheus_mesos_exporter_image }}\"\n    command: \"-exporter.scrape-mode=master -exporter.url=http://{{ mesos_hostname }}:{{ mesos_master_port }}\"\n    state: started\n    restart_policy: always\n    ports:\n    - \"{{ prometheus_mesos_exporter_port }}:{{ prometheus_mesos_exporter_port }}\"\n  environment: \"{{ proxy_env }}\"\n  tags:\n    - prometheus\n    - mesos_master\n\n- name: Set mesos-exporter consul service definition\n  when: prometheus_enabled|bool\n  become: yes\n  template:\n    src: mesos-exporter-consul.j2\n    dest: \"{{ consul_dir }}/mesos-exporter.json\"\n  notify:\n    - restart consul\n  tags:\n    - prometheus\n    - mesos_master\n"}, {"commit_sha": "21712b74b7f5d936e70186bbed6bb37e3a7ad5e6", "sha": "9ff1023cf1c7ecc37b2af2e65b82404f9a30130b", "filename": "roles/frameworks/vars/chronos.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "frameworks_chronos_enabled: true\nframeworks_chronos_mem: 512\nframeworks_chronos_cpus: 0.5\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "f4c6f93e6867a71ab88c3f522fc235849c1775b5", "filename": "roles/marathon/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for marathon\n- name: wait for marathon to listen\n  command: /usr/local/bin/marathon-wait-for-listen.sh\n\n- name: restart marathon\n  sudo: yes\n  service:\n    name: marathon\n    state: restarted\n"}, {"commit_sha": "61b008311c40b377e57e166b778232a20224f7c6", "sha": "719cc6af28b44d6cc3e62146597fc0234d277a19", "filename": "tasks/mms-agent.yml", "repository": "UnderGreen/ansible-role-mongodb", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Install MMS agent pt. 1\n  get_url: url={{mongodb_mms_agent_pkg}} dest={{mongodb_conf_dbpath}}/mms-agent.deb\n  register: mongodb_mms_agent_loaded\n\n- name: Install MMS agent pt. 2\n  apt: deb={{mongodb_conf_dbpath}}/mms-agent.deb\n  when: mongodb_mms_agent_loaded.changed\n\n- name: Configure the MMS agent pt. 1\n  file: state=directory path=/etc/mongodb-mms owner={{mongodb_user}} group={{mongodb_user}} mode=0755\n\n- name: Configure the MMS agent pt. 2\n  template: src=automation-agent.config.j2 dest=/etc/mongodb-mms/automation-agent.config\n  notify: mongodb-mms-automation-agent restart\n\n- name: Ensure that the MMS agent is started\n  service: name=mongodb-mms-automation-agent state=started enabled=yes\n  when: mongodb_manage_service\n"}, {"commit_sha": "bf6e08dcb2440421477b6536ff6a8d11adc2be17", "sha": "4b9f189fd78e1d72f4b8ff7f06e4b6cd40637f65", "filename": "roles/mesos/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for mesos\nmesos_zk_port: 2181\nmesos_zookeeper_group: zookeeper_servers\nmesos_master_port: 5050\nconsul_dir: /etc/consul.d\nmesos_executor_registration_timeout: 10mins\nmesos_cluster_name: \"Cluster01\"\nmesos_containerizers: \"docker,mesos\"\nmesos_resources: \"ports(*):[31000-32000]\"\nmesos_slave_work_dir: \"/tmp/mesos\"\nmesos_ip: \"{{ ansible_default_ipv4.address }}\"\nmesos_hostname: \"{{ inventory_hostname }}\"\n"}, {"commit_sha": "f565940c5163524c7834123625c804e5f69c2b10", "sha": "6f402937e53c88f8de366f8bf75ae43d120de952", "filename": "tasks/rabbit.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/rabbit.yml: Deploy RabbitMQ and set-up vhost for Sensu messaging\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - include: \"{{ ansible_distribution }}/rabbit.yml\"\n\n  - name: Ensure RabbitMQ SSL directory exists\n    file: dest={{ rabbitmq_config_path }}/ssl state=directory\n\n  - name: Ensure RabbitMQ SSL certs/keys are in place\n    copy: src={{ item }} dest={{ rabbitmq_config_path }}/ssl\n    with_items:\n      - \"{{ sensu_ssl_server_cacert }}\"\n      - \"{{ sensu_ssl_server_cert }}\"\n      - \"{{ sensu_ssl_server_key }}\"\n    notify:\n      - restart rabbitmq service\n      - restart sensu-api service\n      - restart sensu-server service\n    when: sensu_ssl_manage_certs\n\n  - name: Deploy RabbitMQ config\n    template:\n      dest: \"{{ rabbitmq_config_path }}/rabbitmq.config\"\n      src: \"{{ rabbitmq_config_template }}\"\n      owner: root\n      group: \"{{ __root_group }}\"\n      mode: 0644\n    notify: restart rabbitmq service\n\n  - name: Ensure RabbitMQ is running\n    service:\n      name: \"{{ rabbitmq_service_name }}\"\n      state: started\n      enabled: true\n    register: rabbitmq_state\n\n  - name: Wait for RabbitMQ to be up and running before asking to create a vhost\n    pause: seconds=3\n    when: rabbitmq_state|changed\n\n  - block:\n    - name: Ensure Sensu RabbitMQ vhost exists\n      rabbitmq_vhost: name={{ rabbitmq_sensu_vhost }} state=present\n\n    - name: Ensure Sensu RabbitMQ user has access to the Sensu vhost\n      rabbitmq_user:\n        user: \"{{ rabbitmq_sensu_user_name }}\"\n        password: \"{{ rabbitmq_sensu_password }}\"\n        vhost: \"{{ rabbitmq_sensu_vhost }}\"\n        configure_priv: .*\n        read_priv: .*\n        write_priv: .*\n        state: present\n    become: true\n    become_user: rabbitmq\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "a4573f3fe1008baedb64093b9cd257f57ff91971", "filename": "tasks/section_12_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 12.1 Verify Permissions on /etc/passwd (Scored)\n    file: path=/etc/passwd mode=0644\n    tags:\n      - section12\n      - section12.1\n\n  - name: 12.2 Verify Permissions on /etc/shadow (Scored)\n    file: path=/etc/shadow mode='o-rwx,g-rw'\n    tags:\n      - section12\n      - section12.2\n\n  - name: 12.3 Verify Permissions on /etc/group (Scored)\n    file: path=/etc/group mode=0644\n    tags:\n      - section12\n      - section12.3\n\n  - name: 12.4 Verify User/Group Ownership on /etc/passwd (Scored)\n    file: path=/etc/passwd owner=root group=root\n    tags:\n      - section12\n      - section12.4\n\n  - name: 12.5 Verify User/Group Ownership on /etc/shadow (Scored)\n    file: path=/etc/shadow owner=root group=shadow\n    tags:\n      - section12\n      - section12.5\n\n  - name: 12.6 Verify User/Group Ownership on /etc/group (Scored)\n    file: path=/etc/group owner=root group=root\n    tags:\n      - section12\n      - section12.6\n\n  - name: 12.7.1 Find World Writable Files (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -0002 -print\n    changed_when: False\n    failed_when: False\n    always_run: True\n    register: world_files\n    tags:\n      - section12\n      - section12.7\n\n  - name: 12.7.2 Find World Writable Files (Not Scored)\n    debug: msg=\"{{ item }}\"\n    with_items: \"{{world_files.stdout_lines}}\"\n    tags:\n      - section12\n      - section12.7\n\n  - name: 12.8.1 Find Un-owned Files and Directories (check) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -nouser -ls\n    changed_when: False\n    failed_when: False\n    always_run: True\n    register: unowned_files\n    tags:\n      - section12\n      - section12.8\n\n  - name: 12.8.2 Find Un-owned Files and Directories (Scored)\n    debug: msg=\"{{ item }}\"\n    with_items: \"{{unowned_files.stdout_lines}}\"\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.9.1 Find Un-grouped Files and Directories (check) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -nogroup -ls\n    changed_when: False\n    failed_when: False\n    always_run: True\n    register: ungrouped_files\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.9.2 Find Un-grouped Files and Directories (Scored)\n    debug: >\n        msg=\"{{ item }}\"\n    with_items: \"{{ungrouped_files.stdout_lines}}\"\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.10.1 Find SUID System Executables (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -4000 -print\n    changed_when: False\n    failed_when: False\n    always_run: True\n    register: suid_files\n    tags:\n      - section12\n      - section12.10\n\n  - name: 12.10.2 Find SUID System Executables (Not Scored)\n    debug: msg=\"{{ item }}\"\n    with_items: \"{{suid_files.stdout_lines}}\"\n    tags:\n      - section12\n      - section12.10\n\n  - name: 12.11.1 Find SGID System Executables (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -2000 -print\n    changed_when: False\n    failed_when: False\n    always_run: True\n    register: gsuid_files\n    tags:\n      - section12\n      - section12.11\n\n  - name: 12.11.2 Find SGID System Executables (Not Scored)\n    debug: msg=\"{{ item }}\"\n    with_items: \"{{gsuid_files.stdout_lines}}\"\n    tags:\n      - section12\n      - section12.10\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "b3299e03be4db24d915600fc74a0c5704b032345", "filename": "tasks/Ubuntu/redis.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/Ubuntu/redis.yml: Deploy redis\n# Specific to Ubuntu\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure redis is installed\n    apt:\n      name: \"{{ redis_pkg_name }}\"\n      state: \"{{ redis_pkg_state }}\"\n      update_cache: true\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "d248f1b3b4e4de1a633ce4f749d0f8378fb417cc", "filename": "tasks/snapshot.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# File: snapshot.yml - Create snapshot service\n# template: consul_snapshot.service\n# template: consul_snapshot.config /etc/consul/\n# set snaps to {{ snap storage location }}\n# create snaps folder\n# handler: start / enable service\n# add entry to tasks/main.yml\n# update readme\n# update defaults/main.yml\n# update my vars file\n\n- name: Create snapshot systemd script\n  template:\n    src: consul_systemd_snapshot.service.j2\n    dest: /lib/systemd/system/consul_snapshot.service\n    owner: root\n    group: root\n    mode: 0644\n  register: systemd_unit\n  notify: start snapshot\n  when:\n    - ansible_service_mgr == \"systemd\"\n    - not ansible_os_family == \"FreeBSD\"\n    - not ansible_os_family == \"Solaris\"\n    - consul_snapshot | bool\n\n- name: Create snapshot agent config\n  template:\n    src: consul_snapshot.json.j2\n    dest: \"{{ consul_config_path }}/consul_snapshot.json\"\n    owner: \"{{ consul_user }}\"\n    group: \"{{ consul_group }}\"\n    mode: 0644\n  notify: start snapshot\n  when:\n    - ansible_service_mgr == \"systemd\"\n    - not ansible_os_family == \"FreeBSD\"\n    - not ansible_os_family == \"Solaris\"\n    - consul_snapshot | bool\n\n- name: Reload systemd\n  systemd:\n    daemon_reload: true\n  when: systemd_unit | changed\n\n- name: Create snaps storage folder\n  file:\n    state: directory\n    path: \"{{ consul_snapshot_storage }}\"\n    owner: \"{{ consul_user }}\"\n    group: \"{{ consul_group }}\"\n    mode: 0744\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "7643b7128ec86501b4690806fcc4e04ea52df689", "filename": "playbooks/coreos-bootstrap.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- name: bootstrap coreos hosts\n  hosts: all\n  gather_facts: False\n  roles:\n    - coreos_bootstrap\n    - coreos_timezone\n\n- name: Install docker-py\n  hosts: all\n  gather_facts: False\n  tasks:\n    - pip:\n        name: docker-py\n        version: 1.5.0\n"}, {"commit_sha": "a774d7f239841cdb705317557a11935ca87238ad", "sha": "b356ef0f506abf91f932c83c23426c5ca1f8a20d", "filename": "tasks/section_02_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 2.1 Create Separate Partition for /tmp (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /tmp\"\n    tags:\n      - section2\n      - section2.1\n\n  - name: 2.2 - 4 Set nodev, nosuid, noexec option for /tmp Partition (Scored)\n    mount: name=\"/tmp\" state=\"mounted\" opts=\"nodev,nosuid,noexec\"\n    when: partitioning==\"true\"\n    tags:\n      - section2\n      - section2.2\n      - section2.3\n      - section2.4\n\n  - name: 2.5 Create Separate Partition for /var (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var\"\n    tags:\n      - section2\n      - section2.5\n\n  - name: 2.6 Bind Mount the /var/tmp directory to /tmp (Scored)\n    mount: name=\"/var/tmp\" src=\"/tmp\" opts=bind state=mounted\n    when: partitioning==\"true\"\n    tags:\n      - section2\n      - section2.6\n\n  - name: 2.7 Create Separate Partition for /var/log (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var/log\"\n    tags:\n      - section2\n      - section2.7\n\n  - name: 2.8 Create Separate Partition for /var/log/audit (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var/log/audit\"\n    tags:\n      - section2\n      - section2.8\n\n  - name: 2.9 Create Separate Partition for /home (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /home\"\n    tags:\n      - section2\n      - section2.9\n\n  - name: 2.10 Add nodev Option to /home (Scored)\n    mount: name:/home state:mounted opts:remount,nodev\n    when: partitioning==\"true\"\n    tags:\n      - section2\n      - section2.10\n\n  - name: 2.11 Add nodev Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nodev option\"\n    tags:\n      - section2\n      - section2.11\n\n  - name: 2.12 Add noexec Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have noexec option\"\n    tags:\n      - section2\n      - section2.12\n\n  - name: 2.13 Add nosuid Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nosuid option\"\n    tags:\n      - section2\n      - section2.13\n\n  - name: 2.14 - 16 Add nodev Option to /run/shm Partition (Scored)\n    mount: name=\"/run/shm\" src=\"/run/shm\" state=\"mounted\" opts=\"nodev,nosuid,noexec\" fstype=\"tmpfs\"\n    tags:\n      - section2\n      - section2.14\n      - section2.15\n      - section2.16\n\n  - name: 2.17.1 Set Sticky Bit on All World-Writable Directories (preparation) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type d -perm -0002 -print 2>/dev/null\n    failed_when: False\n    changed_when: False\n    always_run: True\n    register: sticky_bit_dirs\n    tags:\n      - section2\n      - section2.17\n      - section2.17.1\n\n  - name: 2.17.2 Set Sticky Bit on All World-Writable Directories (Scored)\n    file: path={{ item }} mode=\"a+t\"\n    with_items: sticky_bit_dirs.stdout_lines\n    tags:\n      - section2\n      - section2.17\n      - section2.17.2\n\n  - name: 2.25 Disable Automounting (Scored)\n    lineinfile: >\n        dest=/etc/init/autofs.conf\n        line='#start on runlevel [2345]'\n        regexp='start on runlevel'\n        state=present\n    tags:\n      - section2\n      - section2.25\n"}, {"commit_sha": "5eb44163b7f6328c1f30168fa86326458d5dbaff", "sha": "4831bf077bd9565b911c6313a7ad1b3b8a66c8eb", "filename": "tasks/debug.yml", "repository": "ansiblebit/oracle-java", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# file: oracle-java/tasks/debug.yml\n#\n# Task that prints variable debug information.\n#\n\n- name: echo oracle_java_cache_valid_time\n  debug:\n    var=oracle_java_cache_valid_time\n  when: oracle_java_cache_valid_time is defined\n\n- name: echo oracle_java_home\n  debug:\n    var=oracle_java_home\n  when: oracle_java_home is defined\n\n- name: echo oracle_java_installed\n  debug:\n    var=oracle_java_installed\n  when: oracle_java_installed is defined\n\n- name: echo oracle_java_os_supported\n  debug:\n    var=oracle_java_os_supported\n  when: oracle_java_os_supported is defined\n\n- name: echo oracle_java_rpm_filename\n  debug:\n    var=oracle_java_rpm_filename\n  when: oracle_java_rpm_filename is defined\n\n- name: echo oracle_java_set_as_default\n  debug:\n    var=oracle_java_set_as_default\n  when: oracle_java_set_as_default is defined\n\n- name: echo oracle_java_rpm_url\n  debug:\n    var=oracle_java_rpm_url\n  when: oracle_java_rpm_url is defined\n\n- name: echo oracle_java_state\n  debug:\n    var=oracle_java_state\n  when: oracle_java_state is defined\n\n- name: echo oracle_java_version_build\n  debug:\n    var=oracle_java_version_build\n  when: oracle_java_version_build is defined\n\n- name: echo oracle_java_version_installed\n  debug:\n    var=oracle_java_version_installed\n  when: oracle_java_version_installed is defined\n\n- name: echo oracle_java_version_string\n  debug:\n    var=oracle_java_version_string\n  when: oracle_java_version_string is defined\n"}, {"commit_sha": "b02504a0a0a8b0e4169d0327a865dfe08866e9ec", "sha": "c7c0b6e7c208f9d4954bda566902726ce4e99d5d", "filename": "tasks/plugins.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/plugins.yml: Deploy available checks/plugins/handlers/filters/mutators\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure Sensu plugin directory exists\n    file:\n      dest: \"{{ sensu_config_path }}/plugins\"\n      state: directory\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n\n  - name: Ensure any remote plugins defined are present\n    shell: sensu-install -p {{ item }}\n    with_items: \"{{ sensu_remote_plugins }}\"\n    changed_when: false\n    when: sensu_remote_plugins > 0\n\n  - name: Register available checks\n    local_action: command ls {{ static_data_store }}/sensu/checks\n    register: sensu_available_checks\n    changed_when: false\n    become: false\n\n  - name: Deploy check plugins\n    copy:\n      src: \"{{ static_data_store }}/sensu/checks/{{ item }}/\"\n      dest: \"{{ sensu_config_path }}/plugins/\"\n      mode: 0755\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    when: \"'{{ item }}' in sensu_available_checks.stdout_lines\"\n    with_flattened:\n      - \"{{ group_names }}\"\n    notify: restart sensu-client service\n\n  - name: Deploy handler plugins\n    copy:\n      src: \"{{ static_data_store }}/sensu/handlers/\"\n      dest: \"{{ sensu_config_path }}/plugins/\"\n      mode: 0755\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    notify: restart sensu-client service\n\n  - name: Deploy filter plugins\n    copy:\n      src: \"{{ static_data_store }}/sensu/filters/\"\n      dest: \"{{ sensu_config_path }}/plugins/\"\n      mode: 0755\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    notify: restart sensu-client service\n\n  - name: Deploy mutator plugins\n    copy:\n      src: \"{{ static_data_store }}/sensu/mutators/\"\n      dest: \"{{ sensu_config_path }}/plugins/\"\n      mode: 0755\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    notify: restart sensu-client service\n\n  - name: Deploy check/handler/filter/mutator definitions to the master\n    template:\n      src: \"{{ item }}\"\n      dest: \"{{ sensu_config_path }}/conf.d/{{ item | basename | regex_replace('.j2', '')}}\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    when: sensu_master\n    with_fileglob:\n      - \"{{ static_data_store }}/sensu/definitions/*\"\n    notify:\n      - restart sensu-server service\n      - restart sensu-api service\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "0c4007d181b6ca8241749b787b0957c387e91285", "filename": "roles/rabbitmq/tasks/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "\n- name: Install rabbitmq packages\n  sudo: true\n  apt:\n    name: \"{{ item }}\"\n    update_cache: true\n  with_items:\n    - rabbitmq-server\n"}, {"commit_sha": "92d2f38d01d7b33610c667cfdc03e28ab2912edc", "sha": "ddb435834a1e09440fea388bf54b1ead4ad93fc2", "filename": "tasks/section_09_level1_03.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 9.3.1 Set SSH Protocol to 2 (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Protocol'\n        state=present\n        line='Protocol 2'\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n  - name: 9.3.2 Set LogLevel to INFO (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^LogLevel'\n        state=present\n        line='LogLevel INFO'\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.2\n\n  - name: 9.3.3 Set Permissions on /etc/ssh/sshd_config (Scored)\n    file: path='/etc/ssh/sshd_config' owner=root group=root mode=600\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.3\n\n#Regroups sections 9.3.4 9.3.7 9.3.8 9.3.9 9.3.10\n  - name: 9.3.{4,7,8,9,10} Disable some SSH options (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^{{ item }}'\n        line='{{ item }} no'\n        state=present\n    with_items:\n      - X11Forwarding\n      - HostbasedAuthentication\n      - PermitRootLogin\n      - PermitEmptyPasswords\n      - PermitUserEnvironment\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.4\n      - section9.3.7\n      - section9.3.8\n      - section9.3.9\n      - section9.3.10\n\n  - name: 9.3.5 Set SSH MaxAuthTries to 4 or Less (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^MaxAuthTries'\n        line='MaxAuthTries 4'\n        state=present\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.5\n\n  - name: 9.3.6 Set SSH IgnoreRhosts to Yes (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^IgnoreRhosts'\n        line='IgnoreRhosts yes'\n        state=present\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.6\n\n  - name: 9.3.11 Use Only Approved Cipher in Counter Mode (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Ciphers'\n        line='Ciphers aes128-ctr,aes192-ctr,aes256-ctr'\n        state=present\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.11\n\n  - name: 9.3.12.1 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveInterval'\n        line='ClientAliveInterval 300'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.1\n\n  - name: 9.3.12.2 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveCountMax'\n        line='ClientAliveCountMax 0'\n        state=present\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.2\n\n  - name: 9.3.13.1 Limit Access via SSH (Scored)\n    shell: grep AllowUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.1\n\n  - name: 9.3.13.2 Limit Access via SSH (Scored)\n    shell: grep AllowGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.2\n\n  - name: 9.3.13.3 Limit Access via SSH (Scored)\n    shell: grep DenyUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.3\n\n  - name: 9.3.13.4 Limit Access via SSH (Scored)\n    shell: grep DenyGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.4\n\n  - name: 9.3.14 Set SSH Banner (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Banner'\n        line='Banner /etc/issue.net'\n        state=present\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.14\n\n"}, {"commit_sha": "694a4890fcf0daa375d6a173511f6ff7dd0f2335", "sha": "5d9587bde1a4340768aa3c07ba03a67857c0fc66", "filename": "tasks/apt_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Setup Debian specific variables (set_fact)\n  set_fact:\n    tor_user: debian-tor\n    tor_DataDir: /var/lib/tor-instances\n    tor_ConfDir: /etc/tor/instances\n    tor_RunAsDaemon: 0\n  tags:\n   - reconfigure\n   - renewkey\n   - createdir\n\n- name: Ensure torproject gpg key is installed (A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89)\n  become: yes\n  apt_key: data=\"{{ lookup('file', 'deb.torproject.org_A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89.pub') }}\"\n    id=A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89\n    state=present\n\n- name: Ensure torproject.org repository is present (APT)\n  become: yes\n  apt_repository: repo='deb http://deb.torproject.org/torproject.org {{ tor_distribution_release }} main'\n    state=present \n    update_cache=yes\n\n# we specifically opt for present over latest to improve performance\n# \"latest\" is covered by auto updates\n- name: Ensure Tor is installed (APT)\n  become: yes\n  apt: pkg=\"{{ item }}\" state=present\n  with_items: \n    - deb.torproject.org-keyring\n    - tor\n  # apt starts a tor client instance by default after installing the package\n  # we do not need that\n  notify:\n    - stop-and-disable default tor\n\n\n#- name: Ensure AppArmor allows access to necessary files (Ubuntu)\n#  become: yes\n#  lineinfile: dest=/etc/apparmor.d/local/system_tor line={{ item }}\n#  with_items:\n#    - '/etc/tor/enabled/*\\ r,'\n#    - '/{,var/}run/tor/*.pid\\ w,'\n#    - '/var/lib/tor/**\\ w,'\n#  when: ansible_distribution == 'Ubuntu'\n#  notify: restart apparmor\n\n- meta: flush_handlers\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "940368af1e31a6fb5daa87064c486ec415e59fef", "filename": "roles/registrator/vars/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# vars file for registrator\n"}, {"commit_sha": "80530fde7df1a94ad361434e02816b0816a2c47a", "sha": "098c031a3dac9fb15e86d0b9208242cb14de5eeb", "filename": "roles/marathon/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks file for marathon\n- name: Set Marathon hostname\n  copy:\n    content: \"{{marathon_local_address}}\"\n    dest: /etc/marathon/conf/hostname\n    mode: 0644\n  sudo: yes\n\n- name: remove marathon override\n  command: /bin/rm -f /etc/init/marathon.override\n\n- name: ensure marathon is running (and enable it at boot)\n  service: name=marathon state=started enabled=yes\n\n- name: Set Marathon consul service definition\n  sudo: yes\n  template:\n    src: marathon-consul.j2\n    dest: \"{{ consul_dir }}/marathon.json\"\n  notify:\n    - Restart consul\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "f5acd4e40078df5b3a70b565e246cf3f0b4576d4", "filename": "tasks/server.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/server.yml: Deploy Sensu Server/API\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Deploy Sensu server API configuration\n    template:\n      dest: \"{{ sensu_config_path }}/conf.d/api.json\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      src: sensu-api.json.j2\n    notify: restart sensu-api service\n\n  - include: SmartOS/server.yml\n    when: ansible_distribution == \"SmartOS\"\n    static: false\n\n  - name: Ensure Sensu server service is running\n    service: name={{ sensu_server_service_name if not se_enterprise else sensu_enterprise_service_name }} state=started enabled=yes\n\n  - name: Ensure Sensu API service is running\n    service: name=sensu-api state=started enabled=yes\n    when: not se_enterprise\n"}, {"commit_sha": "f565940c5163524c7834123625c804e5f69c2b10", "sha": "c9efd5fbb13ba3b6ecf0747b9ecc08fb510602dc", "filename": "tasks/Debian/dashboard.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/Debian/dashboard.yml: Deployment of the Uchiwa dashboard\n# Specific to Debian\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Retrieve the Uchiwa deb package\n    get_url:\n      url: \"{{ uchiwa_pkg_deb_download_url }}\"\n      dest: \"{{ uchiwa_pkg_download_path }}\"\n      sha256sum: \"{{ uchiwa_pkg_download_sha256sum }}\"\n    register: uchiwa_deb\n\n  - name: Install Uchiwa from the retrieved deb package\n    apt: deb={{ uchiwa_pkg_download_path }}\n    when: uchiwa_deb|changed\n\n  - name: Deploy Uchiwa config\n    template:\n      src: uchiwa_config.json.j2\n      dest: \"{{ sensu_config_path }}/uchiwa.json\"\n    notify: restart uchiwa service\n"}, {"commit_sha": "b02504a0a0a8b0e4169d0327a865dfe08866e9ec", "sha": "770cc38dedf2e6685ae64072cf33cfc1500c1c60", "filename": "tasks/CentOS/dashboard.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/CentOS/dashboard.yml: Deployment of the Uchiwa dashboard\n# Specific to CentOS\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure Uchiwa is installed\n    yum:\n      name: \"{{ uchiwa_pkg_download_url }}\"\n      state: present\n\n  - name: Deploy Uchiwa config\n    template:\n      src: uchiwa_config.json.j2\n      dest: \"{{ sensu_config_path }}/uchiwa.json\"\n    notify: restart uchiwa service\n"}, {"commit_sha": "15d2da095f9bd54a50954dee18597710e1951943", "sha": "6aba5d77c5efe0eae9f3d4cf64071f120b584ef9", "filename": "tasks/main.yml", "repository": "ansiblebit/oracle-java", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# file: oracle-java/tasks/main.yml\n#\n# tasks file\n#\n\n- name: check host environment\n  include: check_environment.yml\n\n## include OS family specific variables\n\n- name: include OS family/distribution specific variables\n  include_vars: \"{{ item }}\"\n  with_first_found:\n    - \"defaults/{{ ansible_os_family | lower }}-{{ ansible_distribution | lower }}.yml\"\n    - \"defaults/{{ ansible_os_family | lower }}.yml\"\n  tags: installation\n\n- include: debug.yml\n  when: debug | default(false)\n  tags: debug\n\n- name: check if operating system is suported\n  fail:\n    msg: \"The operating system ({{ ansible_os_family }}) of the target machine ({{ inventory_hostname }}) is not currently supported.\"\n  when: oracle_java_os_supported is not defined or not oracle_java_os_supported\n\n## include OS family specific task file\n\n- name: if darwin/macosx, include distribution specific task file\n  include: \"darwin/macosx.yml\"\n  when: ansible_os_family | lower == 'darwin' and ansible_distribution | lower == 'macosx'\n\n- name: if debian, include family specific task file\n  include: \"debian/main.yml\"\n  when: ansible_os_family | lower == 'debian'\n\n- name: if redhat, include family specific task file\n  include: \"redhat/main.yml\"\n  when: ansible_os_family | lower == 'redhat'\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "a7306882aff630ec286af778ea37944ebd366df7", "filename": "roles/consul/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for consul\n- name: wait for consul to listen\n  wait_for:\n    host: \"{{ consul_bind_addr }}\"\n    port: 8500\n\n- name: restart consul\n  sudo: yes\n  command: systemctl restart consul\n  notify:\n    - wait for consul to listen\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "9ef119c08138b621c256191f2a0310caaef9e4b3", "filename": "roles/dcos_cli/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for dcos-cli\ndcos_cli_image: capgemini/dcos-cli\ndcos_cli_zk_master_peers: \"zk://{{ zookeeper_peers_nodes }}/mesos\"\ndcos_cli_mesos_master_url: \"http://{{ ansible_ssh_host }}:5050\"\ndcos_cli_marathon_url: \"http://{{ ansible_ssh_host }}:8080\"\ndcos_cli_sources: '[\"https://github.com/Capgemini/universe/archive/version-1.x.zip\",]'\ndcos_cli_frameworks_list:\n  - cassandra\n  - chronos\ndcos_cli_apps_list:\n  - prometheus\n\n# apps\nprometheus_image: prom/prometheus\nprometheus_image_tag: 0.16.1\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "0e2202cb966477249c761c1b4b774e4b29861ef3", "filename": "tasks/client.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/client.yml: Deploy various client-side configurations for Sensu\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Deploy Sensu client service configuration\n    template:\n      dest: \"{{ sensu_config_path }}/conf.d/client.json\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      src: \"{{ sensu_client_config  }}\"\n    notify: restart sensu-client service\n\n  - include: SmartOS/client.yml\n    when: ansible_distribution == \"SmartOS\"\n    static: false\n\n  - name: Ensure Sensu client service is running\n    service:\n      name: \"{{ sensu_client_service_name }}\"\n      state: started\n      enabled: yes\n"}, {"commit_sha": "bf6e08dcb2440421477b6536ff6a8d11adc2be17", "sha": "b6f4b97021cd5fc1dcc2006ec37291a02c0e375b", "filename": "roles/marathon/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for marathon\nmarathon_port: 8080\nconsul_dir: /etc/consul.d\nmarathon_hostname: \"{{ inventory_hostname }}\"\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "c165587fe15308d602ecd08a9e57dbcf0681a9eb", "filename": "roles/st2/tasks/2.version.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "# StackStorm version checks and facts gathering\n# TODO: Rework as lookup plugin when Ansible 2.0 available: https://groups.google.com/forum/#!msg/ansible-devel/MF4TY-wa9Ww/mL9sVSMd5DwJ\n---\n\n- name: version | Lookup literal version\n  shell: >\n    curl -Ss -q https://downloads.stackstorm.net/deb/pool/trusty_{{ st2_version }}/main/s/st2api/ |\n    grep 'amd64.deb' |\n    sed -e \"s~.*>st2api_\\(.*\\)-.*<.*~\\1~g\" |\n    sort --version-sort -r |\n    uniq | head -n 1\n  when: st2_version == 'stable' or st2_version == 'unstable'\n  register: _st2_version\n  delegate_to: 127.0.0.1\n  changed_when: False\n  tags: [st2, version]\n\n- name: version | Save version number to install\n  set_fact: _st2_version=\"{{ _st2_version.stdout | default(st2_version) }}\"\n  tags: [st2, version]\n\n- name: version | Check that specified st2 version is available\n  uri:\n    url: \"https://downloads.stackstorm.net/releases/st2/{{ _st2_version }}/\"\n    status_code: 200\n  when: st2_version == _st2_version\n  delegate_to: 127.0.0.1\n  tags: [st2, version]\n\n- name: version | Lookup StackStorm revision to install\n  set_fact:\n      _st2_revision: \"{{ item }}\"\n  with_url:\n    - \"https://downloads.stackstorm.net/releases/st2/{{ _st2_version }}/debs/{{ st2_revision }}/VERSION.txt\"\n  tags: [st2, version]\n\n- name: version | Gather StackStorm package info\n  command: dpkg -s st2common\n  register: _st2_package_info\n  changed_when: no\n  ignore_errors: yes\n  tags: [st2, version]\n\n- name: version | Check if StackStorm is already installed\n  set_fact:\n    _st2_is_installed: \"{{ _st2_package_info.rc == 0 }}\"\n  tags: [st2, version]\n\n- name: version | Get installed StackStorm version and revision\n  set_fact:\n    _st2_installed_version: \"{{ _st2_package_info.stdout|regex_replace('[\\\\s\\\\S]*Version: (.*)-\\\\S+\\\\n[\\\\s\\\\S]*', '\\\\\\\\1') }}\"\n    _st2_installed_revision: \"{{ _st2_package_info.stdout|regex_replace('[\\\\s\\\\S]*Version: \\\\S+-(.*)\\\\n[\\\\s\\\\S]*', '\\\\\\\\1') }}\"\n  when: _st2_is_installed\n  tags: [st2, version]\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "0573e5c67a5355f84c7317452d7966ad2344e22b", "filename": "roles/consul/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for consul\n- name: wait for consul to listen\n  wait_for:\n    host: \"{{ consul_bind_addr }}\"\n    port: 8500\n\n- name: restart consul\n  become: yes\n  service:\n    name: consul\n    state: restarted\n  notify:\n    - wait for consul to listen\n"}, {"commit_sha": "f565940c5163524c7834123625c804e5f69c2b10", "sha": "8cfe6235c2385433f39b4d73c256be59ec5a0bb8", "filename": "tasks/plugins.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/plugins.yml: Deploy available checks/plugins/handlers/filters/mutators\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure Sensu plugin directory exists\n    file:\n      dest: \"{{ sensu_config_path }}/plugins\"\n      state: directory\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n\n  - name: Ensure any remote plugins defined are present\n    shell: sensu-install -p {{ item }}\n    with_items: \"{{ sensu_remote_plugins }}\"\n    changed_when: false\n    when: sensu_remote_plugins > 0\n\n  - name: Register available checks\n    local_action: command ls {{ static_data_store }}/sensu/checks\n    register: sensu_available_checks\n    changed_when: false\n    become: false\n\n  - name: Deploy check plugins\n    copy:\n      src: \"{{ static_data_store }}/sensu/checks/{{ item }}/\"\n      dest: \"{{ sensu_config_path }}/plugins/\"\n      mode: 0755\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    when: \"sensu_available_checks is defined and '{{ item }}' in sensu_available_checks.stdout_lines\"\n    with_flattened:\n      - \"{{ group_names }}\"\n    notify: restart sensu-client service\n\n  - name: Deploy handler plugins\n    copy:\n      src: \"{{ static_data_store }}/sensu/handlers/\"\n      dest: \"{{ sensu_config_path }}/plugins/\"\n      mode: 0755\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    notify: restart sensu-client service\n\n  - name: Deploy filter plugins\n    copy:\n      src: \"{{ static_data_store }}/sensu/filters/\"\n      dest: \"{{ sensu_config_path }}/plugins/\"\n      mode: 0755\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    notify: restart sensu-client service\n\n  - name: Deploy mutator plugins\n    copy:\n      src: \"{{ static_data_store }}/sensu/mutators/\"\n      dest: \"{{ sensu_config_path }}/plugins/\"\n      mode: 0755\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    notify: restart sensu-client service\n\n  - name: Deploy check/handler/filter/mutator definitions to the master\n    template:\n      src: \"{{ item }}\"\n      dest: \"{{ sensu_config_path }}/conf.d/{{ item | basename | regex_replace('.j2', '')}}\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    when: sensu_master\n    with_fileglob:\n      - \"{{ static_data_store }}/sensu/definitions/*\"\n    notify:\n      - restart sensu-server service\n      - restart sensu-api service\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "7fc8e317a733f132b8b6fa4d87e7d5aa18a24bd1", "filename": "roles/mistral/vars/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "mistral_branches:\n  - if: 0.0.0\n    then: st2-0.5.1\n  - if: 0.8.0\n    then: st2-0.8\n  - if: 0.8.1\n    then: st2-0.8.1\n  - if: 0.9.0\n    then: st2-0.9.0\n  - if: 0.13\n    then: st2-0.13.0\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "f5c1919f2cbf61513515717a14ad7bc55ae1fe76", "filename": "tasks/iptables.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# File: iptables.yml - iptables tasks for Consul\n\n- name: Install iptables\n  apt:\n    name: iptables\n\n- name: Redirect local DNS (1/4)\n  iptables:\n    table: nat\n    chain: PREROUTING\n    protocol: udp\n    match: udp\n    destination_port: 53\n    jump: REDIRECT\n    to_ports: 8600\n\n- name: Redirect local DNS (2/4)\n  iptables:\n    table: nat\n    chain: PREROUTING\n    protocol: tcp\n    match: tcp\n    destination_port: 53\n    jump: REDIRECT\n    to_ports: 8600\n\n- name: Redirect local DNS (3/4)\n  iptables:\n    table: nat\n    chain: OUTPUT\n    protocol: udp\n    match: udp\n    destination_port: 53\n    jump: REDIRECT\n    to_ports: 8600\n    destination: localhost\n\n- name: Redirect local DNS (4/4)\n  iptables:\n    table: nat\n    chain: OUTPUT\n    protocol: tcp\n    match: tcp\n    destination_port: 53\n    jump: REDIRECT\n    to_ports: 8600\n    destination: localhost\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "d16a11848fb570f49d34d223b685de56d727fe73", "filename": "roles/dcos_cli/tasks/apps.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- include_vars: \"{{ item }}.yml\"\n  with_items:\n    - \"{{ dcos_cli_apps_list }}\"\n\n# Create the JSON files for apps\n- name: create json files for apps\n  when: \"dcos_cli_app_{{ item }}_enabled | bool\"\n  run_once: true\n  template:\n    src: '{{ item }}.json.j2'\n    dest: \"/etc/marathon/{{ item }}.json\"\n    mode: 0755\n  sudo: yes\n  tags:\n    - \"{{ item }}\"\n    - dcos_cli\n  with_items:\n    - \"{{ dcos_cli_apps_list }}\"\n\n- name: add marathon app via dcos-cli\n  when: \"dcos_cli_app_{{ item }}_enabled | bool\"\n  run_once: true\n  docker:\n    name: \"{{ item }}\"\n    image: \"{{ dcos_cli_image }}\"\n    state: started\n    command: \"marathon app add /config/{{ item }}.json\"\n    volumes:\n    - \"/etc/marathon:/config\"\n    env:\n      MESOS_MASTER_URL: \"{{ dcos_cli_mesos_master_url }}\"\n      MARATHON_URL: \"{{ dcos_cli_marathon_url }}\"\n      SOURCES: \"{{ dcos_cli_sources }}\"\n  tags:\n    - \"{{ item }}\"\n    - dcos_cli\n  with_items:\n    - \"{{ dcos_cli_apps_list }}\"\n\n\n- name: remove marathon app via dcos-cli\n  when: \"not dcos_cli_app_{{ item }}_enabled | bool\"\n  run_once: true\n  docker:\n    name: \"{{ item }}\"\n    image: \"{{ dcos_cli_image }}\"\n    state: started\n    command: \"marathon app remove {{ item }}\"\n    env:\n      MESOS_MASTER_URL: \"{{ dcos_cli_mesos_master_url }}\"\n      MARATHON_URL: \"{{ dcos_cli_marathon_url }}\"\n  tags:\n    - \"{{ item }}\"\n    - dcos_cli\n  with_items:\n    - \"{{ dcos_cli_apps_list }}\"\n"}, {"commit_sha": "4e9fdb819a1d7565413b47dca677f7811946668d", "sha": "dce7422e110781bff2cb47afb018d5b24cecd1db", "filename": "roles/weave/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks file for weave\n- name: include all interfaces.d\n  sudo: yes\n  lineinfile: \"dest=/etc/network/interfaces state=present line='source /etc/network/interfaces.d/*.cfg'\"\n  notify:\n    - Restart networking\n  tags:\n    - weave\n\n- name: Start up docker\n  service: name=docker state=started\n  tags:\n    - weave\n\n- name: configure weave\n  sudo: yes\n  template: src=interfaces.j2 dest=/etc/network/interfaces.d/weave.cfg owner=root group=root mode=0644\n  tags:\n    - weave\n\n- name: bring up weave bridge\n  shell: ifup weave\n  sudo: yes\n  tags:\n    - weave\n\n- name: configure weave bridge for docker\n  sudo: yes\n  lineinfile: \"dest=/etc/default/docker state=present regexp=^DOCKER_OPTS= line='DOCKER_OPTS=\\\"--bridge=weave --fixed-cidr={{ weave_docker_subnet }}\\\"'\"\n  notify:\n    - Restart docker\n    - Weave launch\n  tags:\n    - weave\n"}, {"commit_sha": "8cf75eb68465f1126872131afd102e05068a9df2", "sha": "9230fb872722c90fa807cc8c6ce21bd993b3aabd", "filename": "tasks/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- include: apt_install.yml\n  when: ansible_pkg_mgr == 'apt'\n  tags:\n   - debian\n   - install\n\n- include: yum_install.yml\n  when: ansible_pkg_mgr == 'yum'\n  tags:\n   - centos\n   - install\n\n- include: openbsd_install.yml\n  when: ansible_pkg_mgr == 'openbsd_pkg'\n  tags:\n   - openbsd\n   - install\n\n- include: freebsd_install.yml\n  when: ansible_pkg_mgr == 'pkgng'\n  tags:\n   - freebsd\n   - install\n\n- include: configure.yml\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "ad332fdc790904f552c948574ff65b152634c3f4", "filename": "tasks/windows.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# Gathers facts (bind address) from servers not currently targeted.\n# 'delegate_facts' is currently rather buggy in Ansible so this might not\n# always work. Hence 'consul_gather_server_facts' defaults to 'no'.\n- name: (Windows) Gather facts from other servers\n  setup:\n  delegate_to: \"{{ item }}\"\n  delegate_facts: true\n  with_items: \"{{ consul_servers | difference(play_hosts) }}\"\n  ignore_errors: true\n  when: consul_gather_server_facts | bool\n\n- name: (Windows) Expose bind_address, datacenter and node_role as facts\n  set_fact:\n    consul_bind_address: \"{{ consul_bind_address }}\"\n    consul_datacenter: \"{{ consul_datacenter }}\"\n    consul_node_role: \"{{ consul_node_role }}\"\n\n- name: (Windows) Read bootstrapped state\n  win_stat:\n    path: \"{{ consul_bootstrap_state }}\"\n  register: bootstrap_state\n  ignore_errors: true\n  tags: always\n\n- name: (Windows) Include directory settings\n  import_tasks: dirs.yml\n\n- name: (Windows) Check for existing Consul binary\n  win_stat:\n    path: \"{{ consul_binary }}\"\n  register: consul_binary_installed\n\n- name: (Windows) Install OS packages and consul\n  include_tasks: install_windows.yml\n  when:\n    - not consul_binary_installed.stat.exists | bool\n\n- block:\n    - block:\n        - name: (Windows) Check for gossip encryption key on previously boostrapped server\n          slurp:\n            src: \"{{ consul_config_path }}/config.json\"\n          register: consul_config_b64\n          ignore_errors: true\n\n        - name: (Windows) Deserialize existing configuration\n          set_fact:\n            consul_config: \"{{ consul_config_b64.content | b64decode | from_json }}\"\n          when: consul_config_b64.content is defined\n\n        - name: (Windows) Save gossip encryption key from existing configuration\n          set_fact:\n            consul_raw_key: \"{{ consul_config.encrypt }}\"\n          when: consul_config is defined\n\n      no_log: true\n      when:\n        - consul_raw_key is not defined\n        - bootstrap_state.stat.exists | bool\n        - inventory_hostname in consul_servers\n\n    # Key provided by extra vars or the above block\n    - name: (Windows) Write gossip encryption key locally for use with new servers\n      copy:\n        content: \"{{ consul_raw_key }}\"\n        dest: '/tmp/consul_raw.key'\n        mode: 0700\n      become: false\n      vars:\n        ansible_become: false\n      no_log: true\n      run_once: true\n      register: consul_local_key\n      delegate_to: localhost\n      when: consul_raw_key is defined\n\n    # Generate new key if non was found\n    - block:\n\n        - name: (Windows) Generate gossip encryption key\n          win_shell: \"{{ consul_binary }} keygen\"\n          register: consul_keygen\n\n        - name: (Windows) Write key locally to share with other nodes\n          copy:\n            content: \"{{ consul_keygen.stdout }}\"\n            dest: '/tmp/consul_raw.key'\n            mode: 0700\n          become: false\n          vars:\n            ansible_become: false\n          delegate_to: localhost\n\n      no_log: true\n      run_once: true\n      when:\n        - not consul_local_key.changed\n        - not bootstrap_state.stat.exists | bool\n\n    - name: (Windows) Read gossip encryption key for servers that require it\n      set_fact:\n        consul_raw_key: \"{{ lookup('file', '/tmp/consul_raw.key') }}\"\n      no_log: true\n      when:\n        - consul_raw_key is not defined\n\n    - name: (Windows) Delete gossip encryption key file\n      file:\n        path: '/tmp/consul_raw.key'\n        state: absent\n      become: false\n      vars:\n        ansible_become: false\n      run_once: true\n      delegate_to: localhost\n  no_log: true\n  when:\n    - consul_encrypt_enable\n\n- name: (Windows) Create Consul configuration\n  import_tasks: config_windows.yml\n\n- name: (Windows) Ensure neither ACL nor TLS are requested\n  fail:\n    msg: \"ACL and TLS are not supported on Windows hosts yet.\"\n  when:\n    - (consul_acl_enable | bool) or (consul_tls_enable | bool)\n\n- name: (Windows) Create ACL configuration\n  include_tasks: acl.yml\n  when: consul_acl_enable | bool\n\n- name: (Windows) Create TLS configuration\n  include_tasks: tls.yml\n  when: consul_tls_enable | bool\n\n- block:\n\n    - name: Create Consul as a service\n      win_service:\n        name: Consul\n        path: \"{{ consul_binary }} agent -config-file={{ consul_config_path }}/config.json -config-dir={{ consul_configd_path }}\"\n        display_name: Consul Service\n        description: Consul\n        start_mode: auto\n        state: started\n\n    - name: (Windows) Check Consul HTTP API\n      win_wait_for:\n        delay: 5\n        port: 8500\n\n    - name: (Windows) Create bootstrapped state file\n      win_file:\n        dest: \"{{ consul_bootstrap_state }}\"\n        state: touch\n      when: ansible_os_family == \"Windows\"\n\n    - include_tasks: ../tasks/iptables.yml\n      when: consul_iptables_enable | bool\n\n  when: not bootstrap_state.stat.exists\n\n- include_tasks: ../tasks/dnsmasq.yml\n  when: consul_dnsmasq_enable | bool\n"}, {"commit_sha": "e8eb28b4b4b1c4fb2490b8198570166b9ca23ab2", "sha": "209c1d0633a273c162e41be24d69c382fabdc22b", "filename": "roles/st2/defaults/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# Required memory for st2 installation in MB\nst2_required_memory: 2000\n# MongoDB requires at least 3379MB available in /var/lib/mongo/journal\nst2_required_space: 3500\n\n# 'stable', 'unstable' to get latest version or numeric like '0.12.1'\nst2_version: stable\n# 'current' to get latest revision or numberic like '6'\nst2_revision: current\n\nst2_system_user: stanley\nst2_ssh_key_file: /home/{{ st2_system_user }}/.ssh/{{ st2_system_user }}_rsa\n\nst2_packages:\n  - st2common\n  - st2actions\n  - st2api\n  - st2auth\n  - st2client\n  - st2debug\n  - st2reactor\n\n# Number of action runners to register. Defaults to number of vCPUs, but not less than 2\nst2_action_runners: \"{{ [ansible_processor_vcpus, 2] | max }}\"\n\nst2_auth_username: testu\nst2_auth_password: testp\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "0b48f13b64f1bc7f2814ed7506bebd6661f65f4a", "filename": "roles/st2/tasks/config_auth.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "- name: Install auth pre-reqs\n  sudo: yes\n  apt:\n    name: \"{{ item }}\"\n    state: present\n  with_items:\n    - python-passlib\n    - apache2-utils\n\n- name: Create htpasswd file\n  sudo: true\n  htpasswd:\n    path: /etc/st2/htpasswd\n    name: \"{{ st2_auth_username }}\"\n    password: \"{{ st2_auth_password }}\"\n  notify:\n    - restart st2api/st2stream\n\n- name: Enable autentication\n  sudo: yes\n  ini_file:\n    dest: /etc/st2/st2.conf\n    section: auth\n    option: enable\n    value: True\n    backup: yes\n  notify: \n    - restart st2api/st2stream\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "ac953416bc6d93ae8434f79292773445854a392f", "filename": "roles/consul/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for consul\n- name: restart consul\n  service:\n    name: consul\n    state: restarted\n  sudo: yes\n  notify:\n    - wait for consul to listen\n\n- name: wait for consul to listen\n  wait_for:\n    host: \"{{ consul_bind_addr }}\"\n    port: 8500\n"}, {"commit_sha": "4e9fdb819a1d7565413b47dca677f7811946668d", "sha": "176e9b84b00024dc89d8ec93bb4b814d98fb3eb8", "filename": "roles/weave/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# defaults file for weave\nweave_bridge: \"10.2.0.1/16\"\nweave_server_group: weave_servers\nweave_docker_subnet: \"\n    {%- for host in groups[weave_server_group] -%}\n      {%- if host == 'default' or host == inventory_hostname or host == ansible_fqdn or host in ansible_all_ipv4_addresses -%}\n        10.2.{{ loop.index }}.0/24\n      {%- endif -%}\n    {%- endfor -%}\n\"\nweave_launch_peers: \"\n  {%- set weave_peers = [] -%}\n  {%- for host in groups[weave_server_group] -%}\n    {%- if host != inventory_hostname and host not in weave_peers -%}\n      {% do weave_peers.append(hostvars[host]['ansible_eth0']['ipv4']['address']) %}\n    {%- endif -%}\n  {%- endfor -%}\n  {{ weave_peers|join(' ') }}\n\"\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "3f14dc1576ebd935ac9e8ac56a15e069ba4ea700", "filename": "roles/consul/vars/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# vars file for consul\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "d2548eb500ff0fb50a6f7ecb57ce132a706a1935", "filename": "roles/mesos/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for mesos\n- name: start mesos master\n  sudo: yes\n  service:\n    name: mesos-master\n    state: started\n\n- name: start mesos slave\n  sudo: yes\n  service:\n    name: mesos-slave\n    state: started\n\n- name: restart mesos master\n  sudo: yes\n  service:\n    name: mesos-master\n    state: restarted\n\n- name: restart mesos slave\n  sudo: yes\n  service:\n    name: mesos-slave\n    state: restarted\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "e1abf95a717c7e92a112e9c4c4c2006457e2c72e", "filename": "roles/docker/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for docker\ndocker_tmp_dir: /var/lib/docker/tmp\ndocker_dns_config: \"--dns={{ ansible_default_ipv4.address }} --dns=8.8.8.8 --dns-search='service.{{ consul_domain }}'\"\ndocker_storage_config: --storage-driver=overlay\ndocker_endpoints: \"-H=tcp://{{ ansible_default_ipv4.address }}:2376 -H=unix:///var/run/docker.sock\"\ndocker_bridge_ip: ''\ndocker_proxy_exceptions: ''\ndocker_registry: ''\nprivate_docker_registry: false\n"}, {"commit_sha": "35ca6852d9333ef6c3ed223239f45b840c487d60", "sha": "0763c16c7de3eea6313212b8a8d08bceae484fd2", "filename": "roles/weave/meta/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Graham Taylor\n  description:\n  company: Capgemini\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (MIT)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: Ubuntu\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n     - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies:\n  - role: docker\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "87e4602b2738836e22623cf45b8c1fba3d9894af", "filename": "roles/handlers/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- name: reload systemd\n  sudo: yes\n  command: systemctl daemon-reload\n\n- name: restart consul\n  service:\n    name: consul\n    state: restarted\n  sudo: yes\n  notify:\n    - wait for consul to listen\n\n- name: wait for consul to listen\n  wait_for:\n    port: 8500\n\n- name: restart docker\n  service:\n   name: docker\n   state: restarted\n  sudo: yes\n  notify:\n  - wait for weave to listen\n\n- name: wait for weave to listen\n  wait_for:\n    port: 6783\n    delay: 10\n"}, {"commit_sha": "32211ebd2a9f45112f8dceda80bc95d0db029fb4", "sha": "5bb94e6804b7fa7f48b2ec66807932beed06764f", "filename": "tasks/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- include: ip-list.yml\n  tags:\n    - always\n\n- include: apt_install.yml\n  when: ansible_pkg_mgr == 'apt'\n  tags:\n   - debian\n   - install\n\n- include: rpm_install.yml\n  when: ansible_os_family == 'RedHat'\n  tags:\n   - centos\n   - fedora\n   - install\n\n- include: openbsd_install.yml\n  when: ansible_pkg_mgr == 'openbsd_pkg'\n  tags:\n   - openbsd\n\n- include: freebsd_install.yml\n  when: ansible_pkg_mgr == 'pkgng'\n  tags:\n   - freebsd\n\n- include: configure.yml\n  tags:\n   - debian\n   - centos\n   - fedora\n   - openbsd\n   - freebsd\n\n- include: linux_service.yml\n  when: ansible_system == 'Linux'\n  tags:\n   - debian\n   - centos\n   - fedora\n\n- include: openbsd_service.yml\n  when: ansible_system == 'OpenBSD'\n  tags:\n   - openbsd\n\n- include: freebsd_service.yml\n  when: ansible_system == 'FreeBSD'\n  tags:\n   - freebsd\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "afffceb0b396b17e113d6d9f3e6eb106e8376c0e", "filename": "playbooks/stackstorm.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n- name: Install st2\n  hosts: all\n  roles:\n    - mongodb\n    - rabbitmq\n    - st2repos\n    - mistral\n    - st2\n    - st2web\n    - st2smoketests\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "25369480d72065cfb14ed263d5aa23a7cf3c6aac", "filename": "roles/marathon/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for marathon\nmarathon_consul_dir: /etc/consul.d\nmarathon_enabled: true\nmarathon_version: '0.15.2'\nmarathon_restart_policy: 'always'\nmarathon_net: 'host'\nmarathon_hostname: \"{{ ansible_ssh_host }}\"\nmarathon_port: '8080'\nmarathon_container_memory_limit: '512MB'\nmarathon_java_settings: '-Xmx512m -Xms512m -XX:+HeapDumpOnOutOfMemoryError'\nmarathon_artifact_store: 'file:///store'\nmarathon_artifact_store_dir: '/etc/marathon/store'\nmarathon_server_zk_group: marathon_servers\nmarathon_image: \"mesosphere/marathon:v{{ marathon_version }}\"\nmarathon_master_peers: \"zk://{{ zookeeper_peers_nodes }}/mesos\"\nmarathon_zk_peers: \"zk://{{ zookeeper_peers_nodes }}/marathon\"\nmarathon_command: \"--event_subscriber http_callback --artifact_store {{ marathon_artifact_store }} --hostname {{ marathon_hostname }} --master {{ marathon_master_peers }} --zk {{ marathon_zk_peers }}\"\n"}, {"commit_sha": "21712b74b7f5d936e70186bbed6bb37e3a7ad5e6", "sha": "4e5ef1d33daa7ba180915c8a84ad07975716564d", "filename": "roles/weave/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: upload weave template service\n  template:\n    src: weave.conf.j2\n    dest: \"/etc/init/weave.conf\"\n    mode: 0755\n  sudo: yes\n  tags:\n    - weave\n\n- name: ensure weave service is running.\n  sudo: yes\n  service:\n    name: weave\n    state: started\n    enabled: yes\n\n- name: wait for weave socket to be ready.\n  wait_for:\n    port: 6783\n    delay: 10\n\n- name: download weave scope\n  get_url:\n    url: \"{{ weave_scope_url }}\"\n    dest: \"{{ weave_scope_dest }}\"\n    mode: 0755\n    validate_certs: no\n  environment: proxy_env\n  when: weave_scope_enabled\n  tags:\n    - weave\n\n- name: upload weave scope template service\n  template:\n    src: scope.conf.j2\n    dest: \"/etc/init/weavescope.conf\"\n    mode: 0755\n  sudo: yes\n  when: weave_scope_enabled\n  tags:\n    - weave\n"}, {"commit_sha": "addbee435e20e706e7cf5d2f0a3723e17f79b527", "sha": "ebad2f70d992292330f0092d77f72bd0f90fe8af", "filename": "tasks/section_02_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 2.1 Create Separate Partition for /tmp (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /tmp\"\n    tags:\n      - section2\n      - section2.1\n\n  - name: 2.2 - 4 Set nodev, nosuid, noexec option for /tmp Partition (Scored)\n    mount: name=\"/tmp\" state=\"mounted\" opts=\"nodev,nosuid,noexec\"\n    when: partitioning==\"true\"\n    tags:\n      - section2\n      - section2.2\n      - section2.3\n      - section2.4\n\n  - name: 2.5 Create Separate Partition for /var (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var\"\n    tags:\n      - section2\n      - section2.5\n\n  - name: 2.6 Bind Mount the /var/tmp directory to /tmp (Scored)\n    mount: name=\"/var/tmp\" src=\"/tmp\" opts=bind state=mounted\n    when: partitioning==\"true\"\n    tags:\n      - section2\n      - section2.6\n\n  - name: 2.7 Create Separate Partition for /var/log (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var/log\"\n    tags:\n      - section2\n      - section2.7\n\n  - name: 2.8 Create Separate Partition for /var/log/audit (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var/log/audit\"\n    tags:\n      - section2\n      - section2.8\n\n  - name: 2.9 Create Separate Partition for /home (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /home\"\n    tags:\n      - section2\n      - section2.9\n\n  - name: 2.10 Add nodev Option to /home (Scored)\n    mount: name:/home state:mounted opts:remount,nodev\n    when: partitioning==\"true\"\n    tags:\n      - section2\n      - section2.10\n\n  - name: 2.11 Add nodev Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nodev option\"\n    tags:\n      - section2\n      - section2.11\n\n  - name: 2.12 Add noexec Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have noexec option\"\n    tags:\n      - section2\n      - section2.12\n\n  - name: 2.13 Add nosuid Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nosuid option\"\n    tags:\n      - section2\n      - section2.13\n\n  - name: 2.14 - 16 Add nodev Option to /run/shm Partition (Scored)\n    mount: name=\"/run/shm\" src=\"/run/shm\" state=\"mounted\" opts=\"nodev,nosuid,noexec\" fstype=\"tmpfs\"\n    tags:\n      - section2\n      - section2.14\n      - section2.15\n      - section2.16\n\n  - name: 2.17.1 Set Sticky Bit on All World-Writable Directories (preparation) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type d -perm -0002 -print 2>/dev/null\n    failed_when: False\n    changed_when: False\n    always_run: True\n    register: sticky_bit_dirs\n    tags:\n      - section2\n      - section2.17\n      - section2.17.1\n\n  - name: 2.17.2 Set Sticky Bit on All World-Writable Directories (Scored)\n    file: path='{{ item }}' mode=\"a+t\"\n    with_items: sticky_bit_dirs.stdout_lines\n    tags:\n      - section2\n      - section2.17\n      - section2.17.2\n\n  - name: 2.25 Disable Automounting (stat) (Scored)\n    stat: >\n        path=/etc/init/autofs.conf\n    register: autofs_file\n    tags:\n      - section2\n      - section2.25\n      \n  - name: 2.25 Disable Automounting (Scored)\n    lineinfile: >\n        dest=/etc/init/autofs.conf\n        line='#start on runlevel [2345]'\n        regexp='start on runlevel'\n        state=present\n    when: autofs_file.stat.exists == True\n    tags:\n      - section2\n      - section2.25\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "c5582eb06f4b81f64ef3d0f4ed94a296e412ffe4", "filename": "tasks/install.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# File: install.yml - package installation tasks for Consul\n\n- name: Install OS packages\n  package:\n    name: \"{{ item }}\"\n    state: present\n  with_items: \"{{ consul_os_packages }}\"\n  tags: installation\n\n- name: Read package checksum file\n  stat:\n    path: \"{{ role_path }}/files/consul_{{ consul_version }}_SHA256SUMS\"\n  become: false\n  vars:\n    ansible_become: false\n  run_once: true\n  register: consul_checksum\n  tags: installation\n  delegate_to: 127.0.0.1\n\n- name: Download package checksum file\n  get_url:\n    url: \"{{ consul_checksum_file_url }}\"\n    dest: \"{{ role_path }}/files/consul_{{ consul_version }}_SHA256SUMS\"\n  become: false\n  vars:\n    ansible_become: false\n  run_once: true\n  tags: installation\n  when: not consul_checksum.stat.exists | bool\n  delegate_to: 127.0.0.1\n\n- name: Read package checksum\n  shell: grep \"{{ consul_pkg }}\" \"{{ role_path }}/files/consul_{{ consul_version }}_SHA256SUMS\" | awk '{print $1}'\n  become: false\n  vars:\n    ansible_become: false\n  register: consul_sha256\n  tags:\n    - installation\n    - skip_ansible_lint\n  run_once: true\n  delegate_to: 127.0.0.1\n\n- name: Check Consul package file\n  stat:\n    path: \"{{ role_path }}/files/{{ consul_pkg }}\"\n  become: false\n  vars:\n    ansible_become: false\n  register: consul_package\n  tags: installation\n  run_once: true\n  delegate_to: 127.0.0.1\n\n- name: Download Consul package\n  get_url:\n    url: \"{{ consul_zip_url }}\"\n    dest: \"{{ role_path }}/files/{{ consul_pkg }}\"\n    checksum: \"sha256:{{ consul_sha256.stdout }}\"\n    timeout: \"42\"\n  become: false\n  vars:\n    ansible_become: false\n  tags: installation\n  when: not consul_package.stat.exists | bool\n  run_once: true\n  delegate_to: 127.0.0.1\n\n- name: Update Alpine Package Manager (APK)\n  apk:\n    update_cache: true\n  run_once: true\n  when: ansible_os_family == \"Alpine\"\n  delegate_to: 127.0.0.1\n\n- name: Create Temporary Directory for Extraction\n  tempfile:\n    state: directory\n    prefix: ansible-consul.\n  become: false\n  vars:\n    ansible_become: false\n  register: install_temp\n  tags: installation\n  run_once: true\n  delegate_to: 127.0.0.1\n\n- name: Unarchive Consul package\n  unarchive:\n    src: \"{{ role_path }}/files/{{ consul_pkg }}\"\n    dest: \"{{ install_temp.path }}/\"\n    creates: \"{{ install_temp.path }}/consul\"\n  become: false\n  vars:\n    ansible_become: false\n  tags: installation\n  delegate_to: 127.0.0.1\n\n- name: Install Consul\n  copy:\n    src: \"{{ install_temp.path }}/consul\"\n    dest: \"{{ consul_bin_path }}/consul\"\n    owner: \"{{ consul_user }}\"\n    group: \"{{ consul_group }}\"\n    mode: 0755\n  notify:\n    - restart consul\n  tags: installation\n\n- name: Daemon reload systemd in case the binaries upgraded\n  systemd: daemon_reload=yes\n  become: true\n  when:\n    - ansible_service_mgr == \"systemd\"\n    - consul_install_upgrade | bool\n\n- name: Cleanup\n  file:\n    path: \"{{ install_temp.path }}\"\n    state: \"absent\"\n  become: false\n  vars:\n    ansible_become: false\n  tags: installation\n  run_once: true\n  delegate_to: 127.0.0.1\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "0d3bbf60bff35630cbad6fe526e7dd318ab1b6b2", "filename": "roles/consul/tasks/config.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- name: create consul dirs\n  sudo: yes\n  file:\n    path: \"{{ item }}\"\n    state: directory\n    mode: 0755\n  with_items:\n    - \"{{ consul_data_dir }}\"\n    - \"{{ consul_config_dir }}\"\n\n- name: configure consul\n  sudo: yes\n  template:\n    src: consul.json.j2\n    dest: /etc/consul.d/consul.json\n    owner: root\n    group: root\n    mode: 0644\n  notify:\n    - restart consul\n  tags:\n    - consul\n\n- name: deploy consul service\n  sudo: yes\n  sudo_user: root\n  template:\n    src: \"{{ item.src }}\"\n    dest: \"{{ item.dest }}\"\n  with_items:\n    - src: consul.service.j2\n      dest: /etc/systemd/system/consul.service\n    - src: dnsmasq.service.j2\n      dest: /etc/systemd/system/dnsmasq.service\n    - src: consul-discovery.service.j2\n      dest: /etc/systemd/system/consul-discovery.service\n  notify:\n    - reload systemd\n    - restart consul\n  tags:\n    - consul\n"}, {"commit_sha": "1bb50a6149f6ff7f2e6399411418d088e2c52d01", "sha": "7e3b399fe88cf8898024fecc8e25be04cdf726d2", "filename": "tasks/check_requirements.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: Check if OS is Debian-based (we do not support others)\n    debug: \"Check OS family\"\n    failed_when: ansible_os_family != \"Debian\"\n\n  - name: Check if Ansible version is supported\n    debug: \"Check Ansible version\"\n    failed_when: ansible_version.full | version_compare('1.8', '<')\n"}, {"commit_sha": "5eb44163b7f6328c1f30168fa86326458d5dbaff", "sha": "17c17884e1ffc5be1225a3938049c23c007acbc1", "filename": "tasks/main.yml", "repository": "ansiblebit/oracle-java", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# file: oracle-java/tasks/main.yml\n#\n# tasks file\n#\n\n- name: check host environment\n  include: check_environment.yml\n\n## include OS family specific variables\n\n- name: include OS family/distribution specific variables\n  include_vars: \"{{ item }}\"\n  with_first_found:\n    - \"../defaults/{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml\"\n    - \"../defaults/{{ ansible_distribution | lower }}.yml\"\n    - \"../defaults/{{ ansible_os_family | lower }}.yml\"\n\n- name: debug variables\n  include: debug.yml\n  tags:\n    - debug\n\n## include OS family specific task file\n\n- name: if darwin/macosx, include distribution specific task file\n  include: \"darwin/macosx.yml\"\n  when: ansible_os_family | lower == 'darwin' and ansible_distribution | lower == 'macosx'\n\n- name: if debian, include family specific task file\n  include: \"debian/main.yml\"\n  when: ansible_os_family | lower == 'debian'\n\n- name: if redhat, include family specific task file\n  include: \"redhat/main.yml\"\n  when: ansible_os_family | lower == 'redhat'\n\n- name: check if operating system is suported\n  fail:\n    msg: \"The operating system ({{ ansible_os_family }}) of the target machine ({{ inventory_hostname }}) is not currently supported.\"\n  when: oracle_java_os_supported is not defined or not oracle_java_os_supported\n"}, {"commit_sha": "9966c6de1ed4ef5071a9bea83b4bb69a11dd32ba", "sha": "a407191638843da2b4c6a2f94cdc6b1e2548502d", "filename": "roles/zookeeper/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for zookeeper\n- name: Restart zookeeper\n  shell: restart zookeeper\n  sudo: yes\n\n- name: Start zookeeper\n  shell: start zookeeper\n  sudo: yes\n"}, {"commit_sha": "f5364b57f100ae9fa898af59b7812ec0c447ac42", "sha": "28b4bf010226a17e035b8c5a9775c8a8dfc6b8b3", "filename": "tasks/openbsd_prepare.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Gather current system-wide file descriptor limits (OpenBSD)\n  shell: \"sysctl kern.maxfiles|cut -d= -f2\"\n  register: currentlimits\n\n- name: Ensure system-wide runtime file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  command: \"sysctl kern.maxfiles=20000\"\n  when: currentlimits.stdout|int < 20000\n\n- name: Ensure system-wide persistent file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  lineinfile:\n    dest: /etc/sysctl.conf\n    regexp: ^kern.maxfiles\n    line: \"kern.maxfiles=20000\"\n    create: yes\n  when: currentlimits.stdout|int < 20000\n\n# We rise openfiles limits for every tor instance separately.\n# An instance is identified by its rc.d file name.\n- name: Ensure Tor process file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  lineinfile:\n    dest: /etc/login.conf\n    line: \"tor{{ item.0.ipv4| replace('.','_') }}_{{ item.1.orport }}::openfiles-max=13500::tc=daemon:\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n"}, {"commit_sha": "92d2f38d01d7b33610c667cfdc03e28ab2912edc", "sha": "be822a231c6bd04d702370d98e72435a5bdcd92a", "filename": "tasks/section_06_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 6.1 Ensure the X Window system is not installed (Scored)\n    apt: name=xserver-xorg-core* purge=yes state=absent\n    when: remove_xserver == True\n    tags:\n      - section6\n      - section6.1\n\n  - name: 6.2 Ensure Avahi Server is not enabled (check) (Scored)\n    stat: path='/etc/init/avahi-daemon.conf'\n    register: avahi_stat\n    tags:\n      - section6\n      - section6.2\n\n  - name: 6.2 Ensure Avahi Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on (filesystem'\n        state=present\n        regexp='start on \\(filesystem'\n        dest=/etc/init/avahi-daemon.conf\n    when: avahi_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.2\n\n  - name: 6.3 Ensure print server is not enabled (check) (Not Scored)\n    stat: path='/etc/init/cups.conf'\n    register: cups_stat\n    tags:\n      - section6\n      - section6.3\n\n  - name: 6.3 Ensure print server is not enabled (Not Scored)\n    lineinfile: >\n        line='#start on (filesystem'\n        state=present\n        regexp='start on \\(filesystem'\n        dest=/etc/init/cups.conf\n    when: cups_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.3\n\n  - name: 6.4.1 Ensure DHCP Server is not enabled (check) (Scored)\n    stat: path='/etc/init/isc-dhcp-server.conf'\n    register: dhcp_stat\n    tags:\n      - section6\n      - section6.4\n      - section6.4.1\n\n  - name: 6.4.1 Ensure DHCP Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n        dest=/etc/init/isc-dhcp-server.conf\n    when: dhcp_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.4\n      - section6.4.1\n\n  - name: 6.4.2 Ensure DHCP Server is not enabled (check) (Scored)\n    stat: path='/etc/init/isc-dhcp-server6.conf'\n    register: dhcp6_stat\n    tags:\n      - section6\n      - section6.4\n      - section6.4.2\n\n  - name: 6.4.2 Ensure DHCP Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n        dest=/etc/init/isc-dhcp-server6.conf\n    when: dhcp6_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.4\n      - section6.4.2\n\n  - name: 6.5.1 Configure Network Time Protocol (install) (NTP) (Scored)\n    apt: name=ntp state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.1\n\n  - name: 6.5.1 Check if /etc/ntp.conf file exists (stat)\n    stat:\n        path: /etc/ntp.conf\n    register: ntp_conf_file\n    tags:\n      - section6\n      - section6.5\n      - section6.5.1\n\n  - include: section_06_level1_05.yml\n    when: ntp_conf_file.stat.exists == True\n\n  - name: 6.6 Ensure LDAP is not enabled (Not Scored)\n    apt: name=slapd purge=yes state=absent\n    tags:\n      - section6\n      - section6.6\n\n  - name: 6.7.1 Ensure NFS and RPC are not enabled (stat) (Not Scored)\n    stat: path=/etc/init/rpcbind-boot.conf\n    register: nfs_rpc_rc\n    tags:\n      - section6\n      - section6.7\n      - section6.7.1\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (Not Scored)\n    lineinfile: >\n        dest=/etc/init/rpcbind-boot.conf\n        line='#start on virtual-filesystems and net-device-up IFACE=lo'\n        state=present\n        regexp='start on virtual-filesystems and net'\n    when: nfs_rpc_rc.stat.exists == True\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (check) (Not Scored)\n    command: dpkg -S nfs-kernel-server\n    changed_when: False\n    failed_when: False\n    register: nfs_present\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (rc.d) (Not Scored)\n    service: >\n        name=nfs-kernel-server\n        enabled=no\n    when: nfs_present is defined and nfs_present.rc == 0\n    register: nfs_service_result\n    failed_when: \"nfs_service_result|failed and 'service not found' not in nfs_service_result.msg\"\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.8-14 Ensure DNS,FTP,HTTP,IMAP,POP,Samba,Proxy,SNMP Servers are not enabled (Not Scored)\n    service: >\n        name={{ item }}\n        enabled=no\n    with_items:\n      - bind9\n      - vsftpd\n      - apache2\n      - dovecot\n      - smbd\n      - squid3\n      - snmpd\n    failed_when: False\n    tags:\n      - section6\n      - section6.8\n      - section6.9\n      - section6.10\n      - section6.11\n      - section6.12\n      - section6.13\n      - section6.14\n\n  - name: 6.15 Configure Mail Transfer Agent for Local-Only Mode (stat) (Scored)\n    stat: path=/etc/postfix/main.cf\n    register: postfix_main_cf\n    tags:\n      - section6\n      - section6.15\n\n  - name: 6.15 Configure Mail Transfer Agent for Local-Only Mode (Scored)\n    lineinfile: >\n        dest=/etc/postfix/main.cf\n        regexp='^inet_interfaces ='\n        line='inet_interfaces = localhost'\n        state=present\n    when: postfix_main_cf.stat.exists == True\n    tags:\n      - section6\n      - section6.15\n\n  - name: 6.16 Ensure rsync service is not enabled (stat) (Scored)\n    stat: path=/etc/default/rsync\n    register: default_rsync\n    tags:\n      - section6\n      - section6.16\n\n  - name: 6.16 Ensure rsync service is not enabled (Scored)\n    lineinfile: >\n        dest='/etc/default/rsync'\n        regexp='^RSYNC_ENABLE'\n        line='RSYNC_ENABLE=false'\n    when: default_rsync.stat.exists == True\n    tags:\n      - section6\n      - section6.16\n\n  - name: 6.17 Ensure Biosdevname is not enabled (Scored)\n    apt: name=biosdevname purge=yes state=absent\n    tags:\n      - section6\n      - section6.17\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "47b8e120c848cc71376f9c3987c33817aaa9c828", "filename": "roles/marathon/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for marathon\n- name: wait for marathon to listen\n  command: /usr/local/bin/marathon-wait-for-listen.sh\n\n- name: restart marathon\n  become: yes\n  service:\n    name: marathon\n    state: restarted\n"}, {"commit_sha": "7f02cba4441b5367d6916857c9b41f3abae915db", "sha": "3c36c857e3d1f6bbf764b099972fe5fbc1491d6d", "filename": "tasks/openbsd_service.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n\n# OpenBSD section (uses service module)\n# This is basically a copy from the Linux\n# section, but it requires different service\n# names and additional arguments.\n# =====================================\n\n# OpenBSD does not support multi-instance rc.d\n# # so we link as many pseudo rc scripts as we need.\n# # OpenBSD does not like dots in rc filenames so\n# # we replace them with underscores.\n- name: Create links to the service files (OpenBSD)\n  become: yes\n  file:\n    src: /etc/rc.d/tor\n    state: link\n    path: \"/etc/rc.d/tor{{ item.0.ipv4| replace('.','_') }}_{{ item.1.orport }}\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure Tor instances are enabled and started (OpenBSD)\n  become: yes\n  service:\n    name: \"tor{{ item.0.ipv4|replace('.','_') }}_{{ item.1.orport }}\"\n    arguments: \"-f {{ tor_ConfDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}.torrc\"\n    enabled: yes\n    state: started\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure Tor instances are reloaded if its torrc changed (OpenBSD)\n  become: yes\n  service:\n    name: \"tor{{ item.item.0.ipv4|replace('.','_') }}_{{ item.item.1.orport }}\"\n    state: reloaded\n  with_items: \"{{ tor_instances_tmp.results }}\"\n  when: item.changed\n  tags:\n   - reconfigure\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "95ba49bf206f2e7b4fee8044fe18eaf24848b721", "filename": "tasks/Amazon/redis.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/Amazon/redis.yml: Deploy redis\n# Specific to Amazon Linux AMI\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure redis is installed\n    yum:\n      name: \"{{ redis_pkg_name }}\"\n      state: \"{{ redis_pkg_state }}\"\n      enablerepo: epel\n\n  - name: Ensure redis binds to accessible IP\n    lineinfile:\n      dest: /etc/redis.conf\n      regexp: '^bind'\n      line: 'bind 0.0.0.0'\n"}, {"commit_sha": "1bb50a6149f6ff7f2e6399411418d088e2c52d01", "sha": "7a78f90c264a87ebe7d6f6cfe29af3fb53958da9", "filename": "tasks/section_07_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 7.1.1 Disable IP Forwarding (Scored)\n    sysctl: >\n      name=net.ipv4.ip_forward\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.1\n\n  - name: 7.1.2.1 Disable Send Packet Redirects (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.2\n      - section7.1.2.1\n\n  - name: 7.1.2.2 Disable Send Packet Redirects (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.2\n      - section7.1.2.2\n\n  - name: 7.2.1.1 Disable Source Routed Packet Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.accept_source_route\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.1\n      - section7.2.1.1\n\n  - name: 7.2.1.2 Disable Source Routed Packet Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.accept_source_route\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.1\n      - section7.2.1.2\n\n  - name: 7.2.2.1 Disable ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.2\n      - section7.2.2.1\n\n  - name: 7.2.2.2 Disable ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.2\n      - section7.2.2.2\n\n  - name: 7.2.3.1 Disable Secure ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.secure_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.3\n      - section7.2.3.1\n\n  - name: 7.2.3.2 Disable Secure ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.secure_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.3\n      - section7.2.3.2\n\n  - name: 7.2.4.1 Log Suspicious Packets (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.log_martians\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.4\n      - section7.2.4.1\n\n  - name: 7.2.4.2 Log Suspicious Packets (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.log_martians\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.4\n      - section7.2.4.2\n\n  - name: 7.2.5 Enable Ignore Broadcast Requests (Scored)\n    sysctl: >\n      name=net.ipv4.icmp_echo_ignore_broadcasts\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.5\n\n  - name: 7.2.6 Enable Bad Error Message Protection (Scored)\n    sysctl: >\n      name=net.ipv4.icmp_ignore_bogus_error_responses\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.6\n\n  - name: 7.2.7.1 Enable RFC-recommended Source Route Validation (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.rp_filter\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.7\n      - section7.2.7.1\n\n  - name: 7.2.7.2 Enable RFC-recommended Source Route Validation (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.rp_filter\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.7\n      - section7.2.7.2\n\n  - name: 7.2.8 Enable TCP SYN Cookies (Scored)\n    sysctl: >\n      name=net.ipv4.tcp_syncookies\n      value=1\n      state=present\n    when: enable_tcp_syncookies\n    tags:\n      - section7\n      - section7.2\n      - section7.2.8\n\n  - name: 7.3.1.1 Disable IPv6 Router Advertisements (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.all.accept_ra\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.1\n      - section7.3.1.1\n\n  - name: 7.3.1.2 Disable IPv6 Router Advertisements (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.default.accept_ra\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.1\n      - section7.3.1.2\n\n  - name: 7.3.2.1 Disable IPv6 Redirect Acceptance (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.all.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.2\n      - section7.3.2.1\n\n  - name: 7.3.2.2 Disable IPv6 Redirect Acceptance (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.default.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.2\n      - section7.3.2.2\n\n  - name: 7.3.3 Disable IPv6 (Not Scored)\n    sysctl: >\n      name={{ item }}\n      value=1\n      state=present\n    with_items:\n      - net.ipv6.conf.all.disable_ipv6\n      - net.ipv6.conf.default.disable_ipv6\n      - net.ipv6.conf.lo.disable_ipv6\n    when: disable_ipv6 == True\n    tags:\n      - section7\n      - section7.3\n      - section7.3.3\n\n  - name: 7.4.1 Install TCP Wrappers (Scored)\n    apt: name=tcpd state=present\n    tags:\n      - section7\n      - section7.4\n      - section7.4.1\n\n  - name: 7.4.2 Create /etc/hosts.allow (Not Scored)\n    debug: msg=\"*** Verify /etc/hosts.allow ***\"\n    tags:\n      - section7\n      - section7.4\n      - section7.4.2\n\n  - name: 7.4.3 Verify Permissions on /etc/hosts.allow (Scored)\n    file: >\n        path=/etc/hosts.allow\n        owner=root\n        group=root\n        mode=0644\n    tags:\n      - section7\n      - section7.4\n      - section7.4.3\n\n  - name: 7.4.4 Create /etc/hosts.deny (Not Scored)\n    debug: msg='*** Verify /etc/hosts.deny ***'\n    tags:\n      - section7\n      - section7.4\n      - section7.4.4\n\n  - name: 7.4.5 Verify Permissions on /etc/hosts.deny (Scored)\n    file: >\n        path=/etc/hosts.deny\n        owner=root\n        group=root\n        mode=0644\n    tags:\n      - section7\n      - section7.4\n      - section7.4.5\n\n  - name: 7.5.0 Check the presence of the file \"cis.conf\" under modprobe.d (Not Scored)\n    stat: >\n        path=/etc/modprobe.d/CIS.conf\n    register: cis_conf_file\n    tags:\n      - section7\n      - section7.5\n\n  - name: 7.5.0 Create the file \"cis.conf\" under modprobe.d if doesn't exist (Not Scored)\n    file: >\n        dest=/etc/modprobe.d/CIS.conf state=touch\n    when: not cis_conf_file.stat.exists\n    tags:\n      - section7\n      - section7.5\n\n  - name: 7.5.1-4 Disable DCCP, SCTP, RDS, TIPC (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install {{ item }} /bin/true'\n        state=present\n    with_items:\n        - dccp\n        - sctp\n        - rds\n        - tipc\n    tags:\n      - section7\n      - section7.5\n      - section7.5.1\n      - section7.5.2\n      - section7.5.3\n      - section7.5.4\n\n  - name: 7.6 Deactivate Wireless Interfaces (Not Scored)\n    shell: 'lspci -k | grep -i wifi'\n    changed_when: False\n    register: lspci_wifi\n    failed_when: lspci_wifi.rc == 0\n    tags:\n      - section7\n      - section7.6\n\n  - name: 7.7 Ensure Firewall is active (install) (Scored)\n    apt: >\n        name=ufw\n        state=present\n    when: activate_ufw\n    tags:\n      - section7\n      - section7.7\n\n  - name: 7.7 Ensure Firewall is active (Scored)\n    service: >\n        name=ufw\n        state=started\n    when: activate_ufw\n    tags:\n      - section7\n      - section7.7\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "947f2e69f449ca68f6731248d2fa297a5d16d04e", "filename": "roles/traefik/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n- name: restart traefik\n  sudo: yes\n  command: systemctl restart traefik\n"}, {"commit_sha": "067d6cbb20adb31a1e2bd9f689b5b6e259c30288", "sha": "46d89aa68e3d2808b3448e1db064dcc073ade574", "filename": "tasks/section_06_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 6.1 Ensure the X Window system is not installed (Scored)\n    apt: name=xserver-xorg-core* purge=yes state=absent\n    when: remove_xserver == True\n    tags:\n      - section6\n      - section6.1\n\n  - name: 6.2 Ensure Avahi Server is not enabled (check) (Scored)\n    stat: path='/etc/init/avahi-daemon.conf'\n    register: avahi_stat\n    tags:\n      - section6\n      - section6.2\n\n  - name: 6.2 Ensure Avahi Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on (filesystem'\n        state=present\n        regexp='start on \\(filesystem'\n        dest=/etc/init/avahi-daemon.conf\n    when: avahi_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.2\n\n  - name: 6.3 Ensure print server is not enabled (check) (Not Scored)\n    stat: path='/etc/init/cups.conf'\n    register: cups_stat\n    tags:\n      - section6\n      - section6.3\n\n  - name: 6.3 Ensure print server is not enabled (Not Scored)\n    lineinfile: >\n        line='#start on (filesystem'\n        state=present\n        regexp='start on \\(filesystem'\n        dest=/etc/init/cups.conf\n    when: cups_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.3\n\n  - name: 6.4.1 Ensure DHCP Server is not enabled (check) (Scored)\n    stat: path='/etc/init/isc-dhcp-server.conf'\n    register: dhcp_stat\n    tags:\n      - section6\n      - section6.4\n      - section6.4.1\n\n  - name: 6.4.1 Ensure DHCP Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n        dest=/etc/init/isc-dhcp-server.conf\n    when: dhcp_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.4\n      - section6.4.1\n\n  - name: 6.4.2 Ensure DHCP Server is not enabled (check) (Scored)\n    stat: path='/etc/init/isc-dhcp-server6.conf'\n    register: dhcp6_stat\n    tags:\n      - section6\n      - section6.4\n      - section6.4.2\n\n  - name: 6.4.2 Ensure DHCP Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n        dest=/etc/init/isc-dhcp-server6.conf\n    when: dhcp6_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.4\n      - section6.4.2\n\n  - name: 6.5.1 Configure Network Time Protocol (install) (NTP) (Scored)\n    apt: name=ntp state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.1\n\n  - name: 6.5.2 Configure Network Time Protocol (restrict4) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='restrict -4 default kod nomodify notrap nopeer noquery'\n        regexp='^restrict -4 default'\n        state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.2\n\n  - name: 6.5.3 Configure Network Time Protocol (restrict6) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='restrict -6 default kod nomodify notrap nopeer noquery'\n        regexp='^restrict -6 default'\n        state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.3\n\n  - name: 6.5.4 Configure Network Time Protocol (server check) (NTP) (Scored)\n    command: 'grep \"^server\" /etc/ntp.conf'\n    register: ntp_server_rc\n    changed_when: False\n    always_run: True\n    tags:\n      - section6\n      - section6.5\n      - section6.5.4\n\n  - name: 6.5.4 Configure Network Time Protocol (server add) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='server 0.fr.pool.ntp.org'\n        state=present\n    when: ntp_server_rc.rc == 1\n    tags:\n      - section6\n      - section6.5\n      - section6.5.4\n\n  - name: 6.6 Ensure LDAP is not enabled (Not Scored)\n    apt: name=slapd purge=yes state=absent\n    tags:\n      - section6\n      - section6.6\n\n  - name: 6.7.1 Ensure NFS and RPC are not enabled (stat) (Not Scored)\n    stat: path=/etc/init/rpcbind-boot.conf\n    register: nfs_rpc_rc\n    tags:\n      - section6\n      - section6.7\n      - section6.7.1\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (Not Scored)\n    lineinfile: >\n        dest=/etc/init/rpcbind-boot.conf\n        line='#start on virtual-filesystems and net-device-up IFACE=lo'\n        state=present\n        regexp='start on virtual-filesystems and net'\n    when: nfs_rpc_rc.stat.exists == True\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (check) (Not Scored)\n    command: dpkg -S nfs-kernel-server\n    changed_when: False\n    failed_when: False\n    register: nfs_present\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (rc.d) (Not Scored)\n    service: >\n        name=nfs-kernel-server\n        enabled=no\n    when: nfs_present is defined and nfs_present.rc == 0\n    register: nfs_service_result\n    failed_when: \"nfs_service_result|failed and 'service not found' not in nfs_service_result.msg\"\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.8-14 Ensure DNS,FTP,HTTP,IMAP,POP,Samba,Proxy,SNMP Servers are not enabled (Not Scored)\n    service: >\n        name={{ item }}\n        enabled=no\n    with_items:\n      - bind9\n      - vsftpd\n      - apache2\n      - dovecot\n      - smbd\n      - squid3\n      - snmpd\n    failed_when: False\n    tags:\n      - section6\n      - section6.8\n      - section6.9\n      - section6.10\n      - section6.11\n      - section6.12\n      - section6.13\n      - section6.14\n\n  - name: 6.15 Configure Mail Transfer Agent for Local-Only Mode (stat) (Scored)\n    stat: path=/etc/postfix/main.cf\n    register: postfix_main_cf\n    tags:\n      - section6\n      - section6.15\n\n  - name: 6.15 Configure Mail Transfer Agent for Local-Only Mode (Scored)\n    lineinfile: >\n        dest=/etc/postfix/main.cf\n        line='inet_interfaces = localhost'\n        state=present\n    when: postfix_main_cf.stat.exists == True\n    tags:\n      - section6\n      - section6.15\n\n  - name: 6.16 Ensure rsync service is not enabled (stat) (Scored)\n    stat: path=/etc/default/rsync\n    register: default_rsync\n    tags:\n      - section6\n      - section6.16\n\n  - name: 6.16 Ensure rsync service is not enabled (Scored)\n    lineinfile: >\n        dest='/etc/default/rsync'\n        regexp='^RSYNC_ENABLE'\n        line='RSYNC_ENABLE=false'\n    when: default_rsync.stat.exists == True\n    tags:\n      - section6\n      - section6.16\n\n  - name: 6.17 Ensure Biosdevname is not enabled (Scored)\n    apt: name=biosdevname purge=yes state=absent\n    tags:\n      - section6\n      - section6.17\n"}, {"commit_sha": "bf6e08dcb2440421477b6536ff6a8d11adc2be17", "sha": "fa00f2d16f3e1727be23bc0034b12f738fdd9a1c", "filename": "roles/serverspec/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for serverspec\n\n- name: upload serverspecs\n  synchronize:\n    src: ../../../tests\n    dest: \"{{ serverspec_tests_path }}\"\n    recursive: yes\n    delete: yes\n  when: serverspec_run_tests and serverspec_install_bundler and serverspec_upload_folder\n  tags:\n    - serverspec\n\n- name: install bundler\n  command: gem install bundler --no-ri --no-rdoc\n  args:\n    creates: /usr/local/bin/bundler\n  when: serverspec_run_tests and serverspec_install_bundler\n  tags:\n    - serverspec\n\n- name: install bundle files\n  command: bundle install --path vendor\n  args:\n    chdir: \"{{ serverspec_tests_path }}/tests\"\n    creates: \"{{ serverspec_tests_path }}/tests/vendor\"\n  when: serverspec_run_tests\n  tags:\n    - serverspec\n\n- name: run serverspec tests\n  sudo: yes\n  command: \"bundle exec rake serverspec:{{ test_role }}\"\n  args:\n    chdir: \"{{ serverspec_tests_path }}/tests\"\n  when: test_role is defined and serverspec_run_tests\n  tags:\n    - serverspec\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "6af0a25fc99d05a287f0baf9610455ebace83d15", "filename": "roles/st2/tasks/4.dependencies.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n- name: dependencies | Install system dependencies\n  sudo: true\n  apt:\n    name: \"{{ item }}\"\n    update_cache: yes\n    state: present\n  with_items:\n    - git\n    - python-dev\n    - python-pip\n    - realpath\n  tags: [st2, dependencies]\n\n- name: dependencies | Upgrade pip\n  sudo: true\n  pip:\n    name: pip\n    extra_args: \"-U\"\n\n- name: dependencies | Install pip virtualenv\n  sudo: true\n  pip:\n    name: virtualenv\n  tags: [st2, dependencies]\n\n- name: dependencies | Install st2 pip dependencies\n  sudo: true\n  pip:\n    requirements: \"https://downloads.stackstorm.net/releases/st2/{{ _st2_version }}/requirements.txt\"\n  tags: [st2, dependencies]\n"}, {"commit_sha": "f565940c5163524c7834123625c804e5f69c2b10", "sha": "8ae05484fae20e81df7e7e6ad1e25fe41bf8fc8a", "filename": "tasks/Debian/main.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/Debian/main.yml: Debian specific set-up\n# This takes care of base prerequisites for Debian\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure the Sensu APT repo GPG key is present\n    apt_key:\n      url: http://repositories.sensuapp.org/apt/pubkey.gpg\n      state: present\n\n  - name: Ensure the Sensu Core APT repo is present\n    apt_repository:\n      repo: 'deb     http://repositories.sensuapp.org/apt sensu main'\n      state: present\n      update_cache: true\n\n  - name: Ensure Sensu is installed\n    apt: name={{ sensu_package }} state={{ sensu_pkg_state }}\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "dd191718b0f0faf3d6ae67b26c78fa25bce5e486", "filename": "tasks/section_11_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 11.1 Set Warning Banner for Standard Login Services (Scored)\n    lineinfile: >\n        dest={{ item }}\n        create=yes\n        line='Authorized uses only. All activity may be monitored and reported.'\n        state=present\n        mode=644\n        owner=root\n        group=root\n    with_items:\n        - /etc/motd\n        - /etc/issue\n        - /etc/issue.net\n    tags:\n      - section11\n      - section11.1\n\n  - name: 11.2 Remove OS Information from Login Warning Banners (Scored)\n    shell: egrep '(\\\\v|\\\\r|\\\\m|\\\\s)' {{ item }}\n    register: egrep_os_infos\n    failed_when: egrep_os_infos.rc == 0\n    changed_when: False\n    with_items:\n        - /etc/motd\n        - /etc/issue\n        - /etc/issue.net\n    tags:\n      - section11\n      - section11.2\n\n  - name: 11.3 Set Graphical Warning Banner (Not Scored)\n    debug: msg=\"*** Set a banner for the display manager ***\"\n    tags:\n      - section11\n      - section11.3\n"}, {"commit_sha": "21712b74b7f5d936e70186bbed6bb37e3a7ad5e6", "sha": "63c50b8051646dbd51776ddc080afc08959ff7a7", "filename": "roles/frameworks/vars/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# vars file for frameworks\n"}, {"commit_sha": "7f02cba4441b5367d6916857c9b41f3abae915db", "sha": "aa963c745fc2f0a920237d31302c7663601838bc", "filename": "meta/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: nusenu\n  description: An Ansible role for Tor Relay Operators\n  license: GPLv3\n  platforms:\n  - name: Debian\n    versions:\n    - stretch\n    - buster\n  - name: FreeBSD\n    versions:\n    - 11.2\n    - 12.0\n  - name: OpenBSD\n    versions:\n    - 6.4\n  - name: EL\n    versions:\n    - 7\n  - name: Ubuntu\n    versions:\n    - bionic\n  - name: Fedora\n    versions:\n    - 29\n  galaxy_tags:\n    - tor\n    - ipv6\n    - anonymity\n    - networking\n  min_ansible_version: 2.7.8\ndependencies: []\n"}, {"commit_sha": "7f02cba4441b5367d6916857c9b41f3abae915db", "sha": "40c2a0aab1694994d5a45958f0086449cf1d43e4", "filename": "tasks/linux_service.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n# Linux/systemd section (uses service module)\n# ===========================================\n\n- name: Ensure Tor instances are enabled and started (Linux/systemd)\n  become: yes\n  service:\n    name: \"tor@{{ item.0.ipv4 }}_{{ item.1.orport }}.service\"\n    enabled: yes\n    state: started\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "d769164cfde40519a665b8e4a270ad52167b5321", "filename": "handlers/restart_syslogng.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n- name: restart syslog-ng\n  service:\n    name: syslog-ng\n    state: restarted\n  listen: 'restart syslog-ng'\n"}, {"commit_sha": "af3dfdf7cf37437f5609f1a12e4ac7cbaebd4867", "sha": "f95484ae23d20cf16cb3e7edbc81ded04c16c3a0", "filename": "roles/haproxy/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for haproxy\n- name: \"assures {{ consul_template_dir }} dirs exists\"\n  file:\n    path: \"{{ consul_template_dir }}/{{ item.path }}\"\n    state: directory\n  with_items:\n    - { path: 'config' }\n    - { path: 'templates' }\n  tags:\n    - haproxy\n\n- name: upload template config files\n  template:\n    src: consul.cfg.j2\n    dest: \"{{ consul_template_dir }}/config/consul.cfg\"\n    mode: 0644\n  sudo: yes\n  tags:\n    - haproxy\n\n- name: upload static config files\n  copy:\n    src: \"{{ item.src }}\"\n    dest: \"{{ consul_template_dir }}/{{ item.dst }}\"\n    mode: 0644\n  sudo: yes\n  with_items:\n    - { src: haproxy.cfg, dst: 'config/haproxy.cfg' }\n    - { src: haproxy.tmpl, dst: 'templates/haproxy.tmpl' }\n  tags:\n    - haproxy\n\n- name: run haproxy container\n  docker:\n    name: haproxy\n    image: \"{{ haproxy_image }}\"\n    state: started\n    net: host\n    restart_policy: always\n    ports:\n      - \"80:80\"\n      - \"34180:34180\"\n    env:\n      HAPROXY_DOMAIN: \"{{ haproxy_domain }}\"\n      CONSUL_TEMPLATE_VERSION: \"{{ consul_template_version }}\"\n      CONSUL_LOGLEVEL: \"{{ consul_template_loglevel }}\"\n      CONSUL_CONNECT: \"{{ consul_backend }}\"\n      CONSUL_CONFIG: \"/config\"\n      SERVICE_NAME: haproxy\n    volumes:\n    - \"{{ consul_template_dir }}/config:/config\"\n    - \"{{ consul_template_dir }}/templates:/templates\"\n  tags:\n    - haproxy\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "4e835898a3a694339941f30875c415134c54f864", "filename": "roles/dcos_cli/meta/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Alberto Lamela\n  description:\n  company: Capgemini\n  # If the issue tracker for your role is not on github, uncomment the\n  # next line and provide a value\n  # issue_tracker_url: http://example.com/issue/tracker\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (GPLv2, CC-BY, etc)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  #platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #  - 21\n  #  - 22\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  #- name: Ubuntu\n  #  versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n  #  - trusty\n  #  - utopic\n  #  - vivid\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - jessie\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  #categories:\n  #- cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  #- system\n  #- web\ndependencies: []\n  # List your role dependencies here, one per line.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n\n"}, {"commit_sha": "9eb1a8fa8e281ef06687c1851f51fa0beec3e232", "sha": "6aecba1fdf92a536f853fa3c93b07a6401c4f7b6", "filename": "tasks/section_01_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 1.1.1 Install Updates, Patches and Additional Security Software (Not Scored)\n    apt: update_cache=yes\n    tags:\n      - section1\n      - section1.1\n      - section1.1.1\n\n  - name: 1.1.2 Install Updates, Patches and Additional Security Software (Not Scored)\n    apt: upgrade=yes\n    when: apt_upgrade == True\n    tags:\n      - section1\n      - section1.1\n      - section1.1.2\n"}, {"commit_sha": "af3dfdf7cf37437f5609f1a12e4ac7cbaebd4867", "sha": "0c664f0a8520f98924283c9288233bf39514053f", "filename": "roles/haproxy/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for haproxy\nhaproxy_image: asteris/haproxy-consul\nhaproxy_image_tag: latest\n\n# Set the domain that haproxy uses to match URLs to internal apps.\n# For example, if all your apps will be\n#    app1.example.com, app2.example.com, etc.  set this to 'example.com'\nhaproxy_domain: example.com\n\nconsul_template_dir: /mnt/consul-template.d\nconsul_template_loglevel: debug\nconsul_backend: consul.service.consul:8500\nconsul_template_version: 0.10.0\n"}, {"commit_sha": "af3dfdf7cf37437f5609f1a12e4ac7cbaebd4867", "sha": "f0e6703fcecfe3b5616dc20f71c18389e617846b", "filename": "roles/handlers/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- name: restart consul\n  service:\n    name: consul\n    state: restarted\n  sudo: yes\n  notify:\n    - wait for consul to listen\n\n- name: wait for consul to listen\n  wait_for:\n    port: 8500\n\n- name: restart docker\n  service:\n   name: docker\n   state: restarted\n  sudo: yes\n"}, {"commit_sha": "bf6e08dcb2440421477b6536ff6a8d11adc2be17", "sha": "4259b433d60d91ad26218840c86ef00445302aea", "filename": "roles/zookeeper/meta/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Graham Taylor\n  description:\n  company: Capgemini\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (MIT)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: Ubuntu\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n     - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies:\n  - handlers\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "c5ee48e16a5905db37ff878be57f5de16f769368", "sha": "8702a6e9d54f6bc987426560678dc92798e6fa84", "filename": "tasks/section_08_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n#  - name: 8.2 Configure rsyslog\n#  The rsyslog software is recommended as a replacement for the default syslogd daemon and\n#  provides improvements over syslogd, such as connection-oriented (i.e. TCP) transmission\n#  of logs, the option to log to database formats, and the encryption of log data en route to a\n#  central logging server.\n#  tags:\n#    - section8\n#    - section8.2\n\n\n  - name: 8.2.1 Install the rsyslog package (Scored)\n    apt: name=rsyslog state=present\n    tags:\n      - section8\n      - section8.2\n      - section8.2.1\n\n  - name: 8.2.2 Ensure the rsyslog Service is activated (Scored)\n    command: grep 'start on filesystem' /etc/rsyslog.conf\n    register: startonfilesystem\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.5.2 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line='start on filesystem'\n       insertafter=EOF\n       state=present\n    when: startonfilesystem.rc == 1\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.3 Configure /etc/rsyslog.conf (Not Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line=\"{{ item }}\"\n       insertafter=EOF\n    with_items:\n      - '*.emerg :omusrmsg:*'\n      - 'mail.* -/var/log/mail'\n      - 'mail.info -/var/log/mail.info'\n      - 'mail.warning -/var/log/mail.warn'\n      - 'mail.err /var/log/mail.err'\n      - 'news.crit -/var/log/news/news.crit'\n      - 'news.err -/var/log/news/news.err'\n      - 'news.notice -/var/log/news/news.notice'\n      - '*.=warning;*.=err -/var/log/warn'\n      - '*.crit /var/log/warn'\n      - '*.*;mail.none;news.none -/var/log/messages'\n      - 'local0,local1.* -/var/log/localmessages'\n      - 'local2,local3.* -/var/log/localmessages'\n      - 'local4,local5.* -/var/log/localmessages'\n      - 'local6,local7.* -/var/log/localmessages'\n    changed_when: False\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.3\n\n  - name: 8.2.4.1 Create and Set Permissions on rsyslog Log Files (Scored)\n    shell: awk '{ print $NF }' /etc/rsyslog.d/* /etc/rsyslog.conf | grep /var/log | sed 's/^-//' | sed 's/)$//' \n    register: result\n    changed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.4.2 Create and Set Permissions on rsyslog Log Files (Scored)\n    shell: 'mkdir -p -- \"$(dirname -- {{ item }})\"; touch -- {{ item }}' \n    with_items: result.stdout_lines          \n    changed_when: False\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.4.3 Create and Set Permissions on rsyslog Log Files (Scored)\n    file: >\n        path='{{item}}' \n        owner=root \n        group=root \n        mode=\"og-rwx\" \n    with_items: result.stdout_lines\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.5.1 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    command: grep \"^*.*[^I][^I]*@\" /etc/rsyslog.conf\n    register: remoteloghost \n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.5.2 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line=\"*.* @@{{remote_logs_host_address}}\"\n       insertafter=EOF\n       state=present\n    when: send_rsyslog_remote == True and remoteloghost.rc == 1\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.6.1 Accept Remote rsyslog Messages Only on Designated Log Hosts (Not Scored)\n    command: grep '^$ModLoad imtcp' /etc/rsyslog.conf\n    register: moadloadpresent\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.6\n\n  - name: 8.2.6.2 Accept Remote rsyslog Messages Only on Designated Log Hosts (Not Scored)\n    lineinfile: >\n        dest=/etc/rsyslog.conf\n        regexp='^#({{ item }})'\n        line='{{ item }}'\n        state=present\n    with_items:\n        - '$ModLoad imtcp'\n        - '$InputTCPServerRun 514'\n    when: send_rsyslog_remote == True and moadloadpresent.rc == 1\n    changed_when: False\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.6\n"}, {"commit_sha": "af3dfdf7cf37437f5609f1a12e4ac7cbaebd4867", "sha": "2dbe18f347709fd84a11f6fbe712fe0a35fea906", "filename": "roles/serverspec/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for serverspec\n\n- name: upload serverspecs\n  synchronize:\n    src: ../../../tests\n    dest: \"{{ serverspec_tests_path }}\"\n    recursive: yes\n    delete: yes\n  when: serverspec_run_tests and serverspec_install_bundler and serverspec_upload_folder\n  tags:\n    - serverspec\n\n- name: upload marathon runtime serverspecs\n  template:\n    src: marathon_runtime_spec.rb.j2\n    dest: \"{{ serverspec_tests_path }}/tests/spec/marathon/marathon_runtime_spec.rb\"\n    mode: 0755\n  sudo: yes\n  when: serverspec_run_tests and serverspec_upload_folder\n  tags:\n    - serverspec\n\n- name: install bundler\n  command: gem install bundler --no-ri --no-rdoc\n  args:\n    creates: /usr/local/bin/bundler\n  when: serverspec_run_tests and serverspec_install_bundler\n  tags:\n    - serverspec\n\n- name: install bundle files\n  command: bundle install --path vendor\n  args:\n    chdir: \"{{ serverspec_tests_path }}/tests\"\n    creates: \"{{ serverspec_tests_path }}/tests/vendor\"\n  when: serverspec_run_tests\n  tags:\n    - serverspec\n\n- name: run serverspec tests\n  sudo: yes\n  command: \"bundle exec rake serverspec:{{ test_role }}\"\n  args:\n    chdir: \"{{ serverspec_tests_path }}/tests\"\n  when: test_role is defined and serverspec_run_tests\n  tags:\n    - serverspec\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "4a75c4e5ca50a6ebfecd30a3d38aac8df8ed32f5", "filename": "roles/mesos/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# Common\nconsul_dir: /etc/consul.d\nmesos_executor_registration_timeout: 10mins\nmesos_cluster_name: \"Cluster01\"\nmesos_ip: \"{{ ansible_default_ipv4.address }}\"\nmesos_hostname: \"{{ ansible_ssh_host }}\"\nmesos_docker_socket: \"/var/run/weave/weave.sock\"\nmesos_version: \"0.27.1-2.0.226.ubuntu1404\"\n\n# Defaults file for mesos-salve\nmesos_slave_port: 5051\nmesos_containerizers: \"docker,mesos\"\nmesos_resources: \"ports(*):[31000-32000]\"\nmesos_slave_work_dir: \"/tmp/mesos\"\nmesos_slave_image: \"mesosphere/mesos-slave:{{ mesos_version }}\"\n\n# Defaults file for mesos-master\nmesos_zookeeper_group: zookeeper_servers\nmesos_master_port: 5050\nmesos_master_work_dir: \"/var/lib/mesos\"\nmesos_master_image: \"mesosphere/mesos-master:{{ mesos_version }}\"\nmesos_master_command: \"--registry=replicated_log\"\n\nprometheus_mesos_exporter_image: \"prom/mesos-exporter:latest\"\nprometheus_mesos_exporter_port: 9105\nprometheus_mesos_exporter_consul_service_id: \"{{ ansible_hostname }}:mesos-exporter:{{ prometheus_mesos_exporter_port }}\"\n\n# The Mesos quorum value is based on the number of Mesos Masters. Take the\n# number of masters, divide by 2, and round-up to nearest integer. For example,\n# if there are 1 or 2 masters the quorum count is 1. If there are 3 or 4\n# masters then the quorum count is 2. For 5 or 6 masters it's 3 and so on.\nmesos_quorum: \"\n{% if mesos_master_quorum is defined %}\n{{ mesos_master_quorum }}\n{% else %}\n{{ ( groups.mesos_masters|count / 2) | round(0, 'ceil') | int }}\n{%- endif -%}\n\"\n"}, {"commit_sha": "80530fde7df1a94ad361434e02816b0816a2c47a", "sha": "29822b92a18211ae736f0cad7d529eb3f077ccab", "filename": "roles/dnsmasq/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks file for dnsmasq\n- name: remove dnsmasq override\n  command: /bin/rm -f /etc/init/dnsmasq.override\n\n- name: ensure dnsmasq is running (and enable it at boot)\n  service: name=dnsmasq state=started enabled=yes\n\n- name: configure dnsmasq\n  sudo: yes\n  template: src=10-consul.j2 dest=/etc/dnsmasq.d/10-consul owner=root group=root mode=0644\n  notify:\n    - Restart dnsmasq\n  tags:\n    - dnsmasq\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "19306816093bea9fb28d032cf3d9917e3035b51a", "filename": "roles/mesos/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- include: master.yml\n  when: mesos_install_mode == \"master\"\n\n- include: slave.yml\n  when: mesos_install_mode == \"slave\"\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "2a0216f38ab1dcaa6d96fc0599795614d40a8708", "filename": "tasks/SmartOS/client.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/SmartOS/client.yml: Deploy various client-side configurations for Sensu\n# Specific to Joyent SmartOS\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Deploy Sensu client service manifest\n    template:\n      dest: /opt/local/lib/svc/manifest/sensu-client.xml\n      src: sensu-client.smartos_smf_manifest.xml.j2\n      owner: root\n      group: root\n      mode: 0644\n    notify:\n      - import sensu-client service\n      - restart sensu-client service\n\n  - meta: flush_handlers\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "e0ecde233fb1044c40cdfa8b0539f4c502a8d5f1", "filename": "tasks/dashboard.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/dashboard.yml: Deployment of the Uchiwa dashboard\n  - include: \"{{ ansible_distribution }}/dashboard.yml\"\n\n  - name: Ensure Uchiwa/Sensu Enterprise Dashboard server service is running\n    service:\n      name: \"{{ uchiwa_service_name if not se_enterprise else sensu_enterprise_dashboard_service_name }}\"\n      state: started\n      enabled: yes\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "c247ac827cdc982300fd8bfd98d1a15ef6437e05", "filename": "roles/consul/tasks/config.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- name: create consul dirs\n  become: yes\n  file:\n    path: \"{{ item }}\"\n    state: directory\n    mode: 0755\n  with_items:\n    - \"{{ consul_data_dir }}\"\n    - \"{{ consul_config_dir }}\"\n\n- name: configure consul\n  become: yes\n  template:\n    src: consul.json.j2\n    dest: /etc/consul.d/consul.json\n    owner: root\n    group: root\n    mode: 0644\n  notify:\n    - restart consul\n  tags:\n    - consul\n\n- name: deploy consul service\n  become: yes\n  become_user: root\n  template:\n    src: \"{{ item.src }}\"\n    dest: \"{{ item.dest }}\"\n  with_items:\n    - src: consul.service.j2\n      dest: /etc/systemd/system/consul.service\n    - src: consul-discovery.service.j2\n      dest: /etc/systemd/system/consul-discovery.service\n  notify:\n    - reload systemd\n    - restart consul\n  tags:\n    - consul\n"}, {"commit_sha": "35ca6852d9333ef6c3ed223239f45b840c487d60", "sha": "577c3e131c3fd90e448bbd73273eab6c27522f89", "filename": "roles/mesos/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for mesos\nmesos_zk_port: 2181\nmesos_zookeeper_group: zookeeper_servers\nmesos_master_port: 5050\nconsul_dir: /etc/consul.d\nmesos_local_address: \"{{ ansible_default_ipv4.address }}\"\nmesos_executor_registration_timeout: 10mins\nmesos_cluster_name: \"Cluster01\"\nmesos_containerizers: \"docker,mesos\"\nmesos_resources: \"ports(*):[31000-32000]\"\nmesos_slave_work_dir: \"/tmp/mesos\"\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "dee147ba45ebbc4e80cf926cb0d785551ff98866", "filename": "roles/registrator/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: deploy registrator service\n  become: yes\n  become_user: root\n  template:\n    src: \"{{ item.src }}\"\n    dest: \"{{ item.dest }}\"\n  with_items:\n    - src: registrator.service.j2\n      dest: /etc/systemd/system/registrator.service\n  notify:\n    - reload systemd\n    - restart registrator\n  tags:\n    - registrator\n\n- name: enable registrator\n  become: yes\n  service:\n    name: registrator\n    enabled: yes\n    state: started\n  notify:\n    - restart registrator\n  tags:\n    - registrator\n\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "cd6321e55f4ea79f7bac7ce3beaff1512e239f63", "filename": "tasks/section_07_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 7.1.1 Disable IP Forwarding (Scored)\n    sysctl: >\n      name=net.ipv4.ip_forward\n      value={{net_ipv4_ip_forward}}\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.1\n\n  - name: 7.1.2.1 Disable Send Packet Redirects (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.2\n\n  - name: 7.1.2.2 Disable Send Packet Redirects (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.2\n\n  - name: 7.2.1.1 Disable Source Routed Packet Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.accept_source_route\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.1\n\n  - name: 7.2.1.2 Disable Source Routed Packet Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.accept_source_route\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.1\n\n  - name: 7.2.2.1 Disable ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.2\n\n  - name: 7.2.2.2 Disable ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.2\n\n  - name: 7.2.3.1 Disable Secure ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.secure_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.3\n\n  - name: 7.2.3.2 Disable Secure ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.secure_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.3\n\n  - name: 7.2.4.1 Log Suspicious Packets (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.log_martians\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.4\n\n  - name: 7.2.4.2 Log Suspicious Packets (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.log_martians\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.4\n\n  - name: 7.2.4.3 Log Suspicious Packets (flushing tables) (Scored)\n    sysctl: >\n      name=net.ipv4.route.flush\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.4\n\n  - name: 7.2.5 Enable Ignore Broadcast Requests (Scored)\n    sysctl: >\n      name=net.ipv4.icmp_echo_ignore_broadcasts\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.5\n\n  - name: 7.2.6 Enable Bad Error Message Protection (Scored)\n    sysctl: >\n      name=net.ipv4.icmp_ignore_bogus_error_responses\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.6\n\n  - name: 7.2.7.1 Enable RFC-recommended Source Route Validation (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.rp_filter\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.7\n\n  - name: 7.2.7.2 Enable RFC-recommended Source Route Validation (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.rp_filter\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.7\n\n  - name: 7.2.8 Enable TCP SYN Cookies (Scored)\n    sysctl: >\n      name=net.ipv4.tcp_syncookies\n      value=1\n      state=present\n    when: enable_tcp_syncookies\n    tags:\n      - section7\n      - section7.2\n      - section7.2.8\n\n  - name: 7.3.1.1 Disable IPv6 Router Advertisements (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.all.accept_ra\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.1\n\n  - name: 7.3.1.2 Disable IPv6 Router Advertisements (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.default.accept_ra\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.1\n\n  - name: 7.3.2.1 Disable IPv6 Redirect Acceptance (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.all.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.2\n\n  - name: 7.3.2.2 Disable IPv6 Redirect Acceptance (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.default.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.2\n\n  - name: 7.3.3 Disable IPv6 (Not Scored)\n    sysctl: >\n      name={{ item }}\n      value=1\n      state=present\n    with_items:\n      - net.ipv6.conf.all.disable_ipv6\n      - net.ipv6.conf.default.disable_ipv6\n      - net.ipv6.conf.lo.disable_ipv6\n    when: disable_ipv6 == True\n    tags:\n      - section7\n      - section7.3\n      - section7.3.3\n\n  - name: 7.4.1 Install TCP Wrappers (Scored)\n    apt: name=tcpd state=present\n    tags:\n      - section7\n      - section7.4\n      - section7.4.1\n\n  - name: 7.4.2 Create /etc/hosts.allow (Not Scored)\n    debug: msg=\"*** Verify /etc/hosts.allow ***\"\n    tags:\n      - section7\n      - section7.4\n      - section7.4.2\n\n  - name: 7.4.3 Verify Permissions on /etc/hosts.allow (Scored)\n    file: >\n        path=/etc/hosts.allow\n        owner=root\n        group=root\n        mode=0644\n    tags:\n      - section7\n      - section7.4\n      - section7.4.3\n\n  - name: 7.4.4 Create /etc/hosts.deny (Not Scored)\n    debug: msg='*** Verify /etc/hosts.deny ***'\n    tags:\n      - section7\n      - section7.4\n      - section7.4.4\n\n  - name: 7.4.5 Verify Permissions on /etc/hosts.deny (Scored)\n    file: >\n        path=/etc/hosts.deny\n        owner=root\n        group=root\n        mode=0644\n    tags:\n      - section7\n      - section7.4\n      - section7.4.5\n\n  - name: 7.5.0 Ensures /etc/modprobe.d/ exists (Not Scored)\n    file: >\n        path=/etc/modprobe.d\n        state=directory\n    register: cis_conf_file\n    tags:\n      - section7\n      - section7.5\n\n  - name: 7.5.1-4 Disable DCCP, SCTP, RDS, TIPC (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install {{ item }} /bin/true'\n        state=present\n        create=True\n    with_items:\n        - dccp\n        - sctp\n        - rds\n        - tipc\n    tags:\n      - section7\n      - section7.5\n      - section7.5.1\n      - section7.5.2\n      - section7.5.3\n      - section7.5.4\n\n  - name: 7.6 Deactivate Wireless Interfaces (Not Scored)\n    shell: 'lspci -k | grep -i wifi'\n    changed_when: False\n    register: lspci_wifi\n    failed_when: lspci_wifi.rc == 0\n    tags:\n      - section7\n      - section7.6\n\n  - name: 7.7.1 Ensure Firewall is active (install) (Scored)\n    apt: >\n        name=ufw\n        state=present\n    when: activate_ufw\n    tags:\n      - section7\n      - section7.7\n\n  - name: 7.7.2 Ensure Firewall is active (Scored)\n    service: >\n        name=ufw\n        state=started\n    when: activate_ufw\n    tags:\n      - section7\n      - section7.7\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "a0fc192d72cf9ef286c3b9f84db10b31eb152f3d", "filename": "tasks/section_07.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - include: section_07_level1.yml\n    tags:\n      - section07\n      - level1\n\n"}, {"commit_sha": "5eb44163b7f6328c1f30168fa86326458d5dbaff", "sha": "ab4c089ddc802e16783ee03c3ee0097abc54adc8", "filename": "tasks/redhat/main.yml", "repository": "ansiblebit/oracle-java", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# file: oracle-java/tasks/redhat/main.yml\n#\n# Task file to install Oracle Java Development Kit in a system with a Redhat based Linux distribution.\n#\n\n- name: download Java RPM\n  shell:\n    \"curl -L  -H 'Cookie:oraclelicense=accept-securebackup-cookie' -o {{ oracle_java_dir_source }}/{{ oracle_java_rpm_filename }} {{ oracle_java_rpm_url }}\"\n  args:\n    creates: \"{{ oracle_java_dir_source }}/{{ oracle_java_rpm_filename }}\"\n  register: oracle_java_task_rpm_download\n  sudo: yes\n  tags:\n    - installation\n\n- name: install RPM\n  yum:\n    name=\"{{ oracle_java_dir_source }}/{{ oracle_java_rpm_filename }}\"\n    state=present\n  when: not oracle_java_task_rpm_download|skipped\n  sudo: yes\n  tags:\n    - installation\n\n- name: set Java version as default\n  alternatives:\n    name=\"{{ item.exe }}\"\n    link=\"/usr/bin/{{ item.exe }}\"\n    path=\"{{ item.path }}/{{ item.exe }}\"\n  when: oracle_java_set_as_default\n  with_items:\n    - { path: \"{{ oracle_java_home }}/jre/bin\", exe: 'java' }\n    - { path: \"{{ oracle_java_home }}/jre/bin\", exe: 'keytool' }\n    - { path: \"{{ oracle_java_home }}/bin\", exe: 'javac' }\n    - { path: \"{{ oracle_java_home }}/bin\", exe: 'javadoc' }\n  sudo: yes\n  when: oracle_java_task_rpm_download|changed or (oracle_java_installed and oracle_java_version_installed != oracle_java_version_string)\n  register: oracle_java_task_set_default\n\n- name: in case there were changes, check host environment again\n  include: ../check_environment.yml\n  when: not oracle_java_task_rpm_download|skipped or oracle_java_task_set_default|changed\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "db4e2580ba9554929aa41924e0d1ecf2b4a57b76", "filename": "roles/serverspec/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for serverspec\n\n- name: upload serverspecs\n  synchronize:\n    src: ../../../tests\n    dest: \"{{ serverspec_tests_path }}\"\n    recursive: yes\n    delete: yes\n  when: serverspec_run_tests and serverspec_install_bundler and serverspec_upload_folder\n  tags:\n    - serverspec\n\n- name: upload marathon runtime serverspecs\n  template:\n    src: marathon_runtime_spec.rb.j2\n    dest: \"{{ serverspec_tests_path }}/tests/spec/marathon/marathon_runtime_spec.rb\"\n    mode: 0755\n  sudo: yes\n  when: serverspec_run_tests and serverspec_upload_folder\n  tags:\n    - serverspec\n\n- name: install bundler\n  sudo: yes\n  command: gem install bundler --no-ri --no-rdoc\n  args:\n    creates: /usr/local/bin/bundler\n  when: serverspec_run_tests and serverspec_install_bundler\n  tags:\n    - serverspec\n\n- name: install bundle files\n  sudo: yes\n  command: bundle install --path vendor\n  args:\n    chdir: \"{{ serverspec_tests_path }}/tests\"\n    creates: \"{{ serverspec_tests_path }}/tests/vendor\"\n  when: serverspec_run_tests\n  tags:\n    - serverspec\n\n- name: run serverspec tests\n  sudo: yes\n  command: \"bundle exec rake serverspec:{{ test_role }}\"\n  args:\n    chdir: \"{{ serverspec_tests_path }}/tests\"\n  when: test_role is defined and serverspec_run_tests\n  tags:\n    - serverspec\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "0f7bc7f32302b9e2ed0fe835697ee064d52d5fde", "filename": "roles/dcos_cli/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- include: frameworks.yml\n- include: apps.yml\n\n"}, {"commit_sha": "f565940c5163524c7834123625c804e5f69c2b10", "sha": "1da25df40b3dcccaedd244301332c4dcc2ac2b0d", "filename": "tasks/dashboard.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/dashboard.yml: Deployment of the Uchiwa dashboard\n  - include: \"{{ ansible_distribution }}/dashboard.yml\"\n\n  - name: Ensure Uchiwa server service is running\n    service: name=uchiwa state=started enabled=yes\n"}, {"commit_sha": "b02504a0a0a8b0e4169d0327a865dfe08866e9ec", "sha": "dbbc9ecb9888f85a72d5a88fe608a94e196034ea", "filename": "tasks/Debian/dashboard.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/Debian/dashboard.yml: Deployment of the Uchiwa dashboard\n# Specific to Debian\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Retrieve the Uchiwa deb package\n    get_url:\n      url: \"{{ uchiwa_pkg_download_url }}\"\n      dest: \"{{ uchiwa_pkg_download_path }}\"\n      sha256sum: \"{{ uchiwa_pkg_download_sha256sum }}\"\n    register: uchiwa_deb\n\n  - name: Install Uchiwa from the retrieved deb package\n    apt: deb={{ uchiwa_pkg_download_path }} \n    when: uchiwa_deb|changed\n\n  - name: Deploy Uchiwa config\n    template:\n      src: uchiwa_config.json.j2\n      dest: \"{{ sensu_config_path }}/uchiwa.json\"\n    notify: restart uchiwa service\n"}, {"commit_sha": "b02504a0a0a8b0e4169d0327a865dfe08866e9ec", "sha": "b1d1cd503ca213e3182e09c1c107a824ab749eeb", "filename": "handlers/main.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n\n  - name: restart rabbitmq service\n    service: name={{ rabbitmq_service_name }} state=restarted\n\n  - name: restart redis service\n    service: name={{ redis_service_name }} state=restarted\n\n  - name: restart uchiwa service\n    service: name=uchiwa state=restarted\n\n  - name: restart sensu-server service\n    service: name=sensu-server state=restarted\n    delegate_to: \"{{ sensu_api_host }}\"\n\n  - name: restart sensu-api service\n    service: name=sensu-api state=restarted\n    delegate_to: \"{{ sensu_api_host }}\"\n\n  - name: restart sensu-client service\n    service: name=sensu-client state=restarted\n\n  # Joyent SmartOS specific handlers\n  - name: import sensu-server service\n    command: /usr/sbin/svccfg import /opt/local/lib/svc/manifest/sensu-server.xml\n\n  - name: import sensu-api service\n    command: /usr/sbin/svccfg import /opt/local/lib/svc/manifest/sensu-api.xml\n\n  - name: import sensu-client service\n    command: /usr/sbin/svccfg import /opt/local/lib/svc/manifest/sensu-client.xml\n\n  - name: import uchiwa service\n    command: /usr/sbin/svccfg import /opt/local/lib/svc/manifest/uchiwa.xml\n\n  - name: Build and deploy Uchiwa\n    shell: npm install --production\n    args:\n      chdir: \"{{ uchiwa_path }}/go/src/github.com/sensu/uchiwa\"\n    become: true\n    become_user: \"{{ sensu_user_name }}\"\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "50414c7dd0d3bbfa728b595422bc8a82d564c1d9", "filename": "roles/dockerbench/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for docker bench\n- name: checkout docker bench git repo\n  git:\n    repo: \"{{ dockerbench_repo }}\"\n    dest: \"{{ dockerbench_dest }}\"\n    accept_hostkey: true\n    version: \"{{ dockerbench_version }}\"\n  when: dockerbench_run_test\n\n- name: install docker bench threshold script\n  sudo: yes\n  template:\n    src: docker-bench-warn.sh.j2\n    dest: /usr/local/bin/docker-bench-warn.sh\n    mode: 0755\n  when: dockerbench_run_test\n\n- name: run docker bench script\n  command: /usr/local/bin/docker-bench-warn.sh\n  sudo: yes\n  args:\n    chdir: \"{{ dockerbench_dest }}\"\n  when: dockerbench_run_test\n"}, {"commit_sha": "a2393d46f0b98700161c4cefd9260d7694bd0bf3", "sha": "8efbf4d1f555516a2fe2ecbcf7287f7a49b2bfb8", "filename": "tasks/section_08_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n#  - name: 8.2 Configure rsyslog\n#  The rsyslog software is recommended as a replacement for the default syslogd daemon and\n#  provides improvements over syslogd, such as connection-oriented (i.e. TCP) transmission\n#  of logs, the option to log to database formats, and the encryption of log data en route to a\n#  central logging server.\n#  tags:\n#    - section8\n#    - section8.2\n\n\n  - name: 8.2.1 Install the rsyslog package (Scored)\n    apt: name=rsyslog state=present\n    tags:\n      - section8\n      - section8.2\n      - section8.2.1\n\n  - name: 8.2.2 Ensure the rsyslog Service is activated (Scored)\n    command: grep 'start on filesystem' /etc/rsyslog.conf\n    register: startonfilesystem\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.5.2 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line='start on filesystem'\n       insertafter=EOF\n       state=present\n    when: startonfilesystem.rc == 1\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.3 Configure /etc/rsyslog.conf (Not Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line=\"{{ item }}\"\n       insertafter=EOF\n    with_items:\n      - '*.emerg :omusrmsg:*'\n      - 'mail.* -/var/log/mail'\n      - 'mail.info -/var/log/mail.info'\n      - 'mail.warning -/var/log/mail.warn'\n      - 'mail.err /var/log/mail.err'\n      - 'news.crit -/var/log/news/news.crit'\n      - 'news.err -/var/log/news/news.err'\n      - 'news.notice -/var/log/news/news.notice'\n      - '*.=warning;*.=err -/var/log/warn'\n      - '*.crit /var/log/warn'\n      - '*.*;mail.none;news.none -/var/log/messages'\n      - 'local0,local1.* -/var/log/localmessages'\n      - 'local2,local3.* -/var/log/localmessages'\n      - 'local4,local5.* -/var/log/localmessages'\n      - 'local6,local7.* -/var/log/localmessages'\n    changed_when: False\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.3\n  \n  - name: 8.2.4.1 Create and Set Permissions on rsyslog Log Files (Scored)\n    shell: awk '{ print $NF }' /etc/rsyslog.d/* /etc/rsyslog.conf | grep /var/log | sed 's/^-//' | sed 's/)$//' \n    register: result\n    changed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.4.2 Create and Set Permissions on rsyslog Log Files (Scored)\n    shell: 'mkdir -p -- \"$(dirname -- {{ item }})\"; touch -- {{ item }}' \n    with_items: result.stdout_lines          \n    changed_when: False\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.4.3 Create and Set Permissions on rsyslog Log Files (Scored)\n    file: >\n        path={{item}}  \n        owner=root \n        group=root \n        mode=\"og-rwx\" \n    with_items: result.stdout_lines\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.5.1 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    command: grep \"^*.*[^I][^I]*@\" /etc/rsyslog.conf\n    register: remoteloghost \n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.5.2 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line=\"*.* @@{{Remote_Logs_Host_Address}}\"\n       insertafter=EOF\n       state=present\n    when: remoteloghost.rc == 1\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.6.1 Accept Remote rsyslog Messages Only on Designated Log Hosts (Not Scored)\n    command: grep '^$ModLoad imtcp' /etc/rsyslog.conf\n    register: moadloadpresent\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.6\n\n  - name: 8.2.6.2 Accept Remote rsyslog Messages Only on Designated Log Hosts (Not Scored)\n    lineinfile: >\n        dest=/etc/rsyslog.conf\n        regexp='^#({{ item }})'\n        line='{{ item }}'\n        state=present\n    with_items:\n        - '$ModLoad imtcp'\n        - '$InputTCPServerRun 514'\n    when: moadloadpresent.rc == 1\n    changed_when: False\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.6\n"}, {"commit_sha": "7f02cba4441b5367d6916857c9b41f3abae915db", "sha": "1b1263356bc2fd32d11d77c7fc6dd2cade8d5b06", "filename": "tasks/configure.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Ensure local DataDir folders exist (LOCAL)\n  become: no\n  file:\n    path: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    state: directory\n    mode: 0700\n  delegate_to: 127.0.0.1\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - createdir\n\n- name: Ensure all relay keys exist (LOCAL)\n  become: no\n  command: >\n          tor --list-fingerprint --DisableNetwork 1 --orport auto --PublishServerDescriptor 0 --ExitRelay 0\n          --ignore-missing-torrc -f /dev/null --defaults-torrc /dev/null --Log \"err stdout\"\n          --datadirectory \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n  delegate_to: 127.0.0.1\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  changed_when: False\n\n- name: Generate new Ed25519 signing keys (LOCAL)\n  become: no\n  command: >\n        tor --keygen --SigningKeyLifetime {{ tor_signingkeylifetime_days }}\\ days --ignore-missing-torrc -f /dev/null\n        --defaults-torrc /dev/null --Log \"err stdout\"\n        --datadirectory \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n  delegate_to: 127.0.0.1\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - renewkey\n  changed_when: False\n\n- name: Detect duplicate relay keys across relays (LOCAL)\n  become: no\n  shell: >\n        set -o pipefail && openssl sha256 -r\n        {{ tor_offline_masterkey_dir }}/*/keys/secret_id_key {{ tor_offline_masterkey_dir }}/*/keys/ed25519_master_id_secret_key |\n        cut -d' ' -f1|sort|uniq -d|wc -l\n  args:\n    executable: /bin/bash\n  delegate_to: 127.0.0.1\n  run_once: true\n  register: tor_dupkeycount\n  changed_when: False\n\n- name: Abort on duplicate relay keys\n  fail:\n    msg: \"Duplicate relay key detected! Aborting.\"\n  run_once: true\n  when: tor_dupkeycount.stdout|int(1) != 0\n\n- name: Detect if Ed25519 master keys are on the relay\n  become: yes\n  stat:\n    path: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/ed25519_master_id_secret_key\"\n  register: tor_masterkeyonline\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Abort if Ed25519 master keys are on the relay\n  fail:\n    msg: \"Ed25519 MASTER KEY detected on the relay - it is NOT supposed to be there! Aborting.\"\n  when: item.stat.exists\n  with_items: \"{{ tor_masterkeyonline.results }}\"\n\n# not relying on the datadir/fingerprint file is more robust\n- name: Collect fingerprints for MyFamily (LOCAL)\n  become: no\n  shell: >\n        set -o pipefail && for key in {{ tor_offline_masterkey_dir }}/*/keys/secret_id_key;\n            do openssl rsa -in $key -outform DER -RSAPublicKey_out 2> /dev/null| openssl sha1 -r;\n        done|cut -d\" \" -f1|sort|xargs|sed -e 's/ /,/g'\n  args:\n    executable: /bin/bash\n  delegate_to: 127.0.0.1\n  run_once: true\n  register: tor_family\n  tags:\n   - reconfigure\n  changed_when: False\n\n- name: Ensure per-instance tor users exist\n  become: yes\n  user:\n    name: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    system: yes\n    shell: /bin/false\n    createhome: no\n    home: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n# We only need to create this folder (used for ControlSocket and on FreeBSD for the pidfile) on:\n# - FreeBSD (regardless of tor_enableControlSocket)\n# - CentOS/Fedora/OpenBSD when tor_enableControlSocket is True\n# we never create it on Debian since the systemd service file creates it there (with different permissions)\n- name: Ensure PID/ControlSocket directory exists\n  become: yes\n  file:\n    path: \"{{ tor_PidDir }}\"\n    state: directory\n    owner: root\n    mode: 0755\n  when: ansible_system == 'FreeBSD' or (tor_enableControlSocket and (ansible_system == 'OpenBSD' or ansible_os_family == 'RedHat'))\n\n- name: Ensure PID/ControlSocket directory is owned by per-instance tor user\n  become: yes\n  file:\n    path: \"{{ tor_PidDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    state: directory\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    group: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0750\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  when: ansible_system == 'FreeBSD' or (tor_enableControlSocket and (ansible_system == 'OpenBSD' or ansible_os_family == 'RedHat'))\n\n- name: Ensure per-instance config folders exist (Debian only)\n  become: yes\n  file:\n    path: \"{{ tor_ConfDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    state: directory\n    mode: 0755\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  when: ansible_pkg_mgr == 'apt'\n\n- name: Ensure DataDir exists\n  become: yes\n  file:\n    path: \"{{ tor_DataDir }}\"\n    state: directory\n    owner: root\n    mode: 0755\n\n- name: Ensure \"keys\" subfolder exists\n  become: yes\n  file:\n    path: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys\"\n    state: directory\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    group: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: u=rwX,g=,o=\n    recurse: yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure RSA key is in place (without overriding existing keys)\n  become: yes\n  copy:\n    src: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    dest: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0600\n    force: no\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'secret_id_key' ]\n\n- name: Fetch RSA key for comparison\n  become: yes\n  fetch:\n    src: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    dest: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}.untrustedremotekey\"\n    flat: yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'secret_id_key' ]\n\n- name: Compare local vs. remote RSA key (secret_id_key)\n  become: no\n  shell: >\n        set -o pipefail && openssl sha256 -r\n        {{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-\"{{ item.0.ipv4 }}_{{ item.1.orport }}\"/keys/secret_id_key*\n        | cut -d' ' -f1|uniq -d|wc -l\n  args:\n    executable: /bin/bash\n  delegate_to: 127.0.0.1\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  register: tor_rsakey_match\n  changed_when: False\n\n- name: Abort if local and remote RSA keys do not match\n  assert:\n    that:\n      - \"item.stdout|int == 1\"\n    msg: >\n         \"Key mismatch detected! Solution: http://bit.ly/2j6wc70 Affected instance:\n         {{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.item.0.ipv4 }}_{{ item.item.1.orport }}/keys\"\n  with_items: \"{{ tor_rsakey_match.results }}\"\n\n# this task is separated from the task named \"Ensure RSA key is in place\" because it is not run with 'force=no'\n- name: Transmit new Ed25519 signing keys\n  become: yes\n  copy:\n    src: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    dest: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0600\n    setype: tor_var_lib_t\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'ed25519_signing_cert', 'ed25519_signing_secret_key' ]\n  changed_when: False\n  tags:\n   - renewkey\n\n# This needs to be at the end to fix SELinux contexts recursively\n- name: Ensure per-instance DataDir have proper permissions\n  become: yes\n  file:\n    path: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    state: directory\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    group: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: u=rwX,g=,o=\n    recurse: yes\n    setype: tor_var_lib_t\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure Tor config directory exists\n  become: yes\n  file:\n    path: \"{{ tor_ConfDir }}\"\n    state: directory\n    owner: root\n    group: \"{{ tor_user }}\"\n    mode: 0755\n\n- name: Ensure tor-exit-notice.html is present (if we are an exit)\n  become: yes\n  template:\n    src: \"{{ tor_exit_notice_file }}\"\n    dest: \"{{ tor_ConfDir }}/tor-exit-notice.html\"\n    mode: 0444\n  when: tor_ExitRelay and tor_ExitNoticePage\n\n- name: Ensure torrc configuration file(s) are in place\n  become: yes\n  template:\n    src: torrc\n    dest: \"{{ (ansible_pkg_mgr != 'apt')| ternary(tor_ConfDir ~ '/' ~ item.0.ipv4 ~ '_' ~ item.1.orport ~ '.torrc', tor_ConfDir ~ '/' ~ item.0.ipv4 ~ '_' ~ item.1.orport ~ '/torrc') }}\"\n    owner: root\n    mode: 0644\n    backup: \"{{ tor_backup_torrc }}\"\n    validate: \"tor --verify-config -f %s\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  register: tor_instances_tmp\n  loop_control:\n    index_var: loop_idx\n  notify:\n    - Ensure Tor instances are reloaded if its torrc changed (FreeBSD)\n    - Ensure Tor instances are reloaded if its torrc changed (Linux)\n  tags:\n   - reconfigure\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "641621f4b55e16e900dfb7961ec27f8c18dc7499", "filename": "roles/marathon/meta/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Alberto Lamela\n  description:\n  company: Capgemini\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (MIT)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: CoreOS\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n  #   - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies:\n  - role: handlers\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "5b1eef96698f2936f1da6c44e5b76ee879109bfe", "filename": "roles/dockerbench/meta/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Cam Parry\n  description:\n  company: Capgemini\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (MIT)\n  min_ansible_version: 1.2\n  min_docker_version: 1.6\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: Ubuntu\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n     - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies: []\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "21712b74b7f5d936e70186bbed6bb37e3a7ad5e6", "sha": "f3190aa6e2f3b89897a4154a1bbfaf7bf9864383", "filename": "roles/weave/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n# defaults file for weave\nweave_server_group: weave_servers\nweave_launch_peers: \"\n  {%- set weave_peers = [] -%}\n  {%- for host in groups[weave_server_group] -%}\n    {%- if host != inventory_hostname and host not in weave_peers -%}\n      {% do weave_peers.append(hostvars[host]['ansible_eth0']['ipv4']['address']) %}\n    {%- endif -%}\n  {%- endfor -%}\n  {{ weave_peers|join(' ') }}\n\"\n\nweave_scope_url: https://github.com/weaveworks/scope/releases/download/latest_release/scope\nweave_scope_dest: /usr/local/bin/scope\nweave_scope_enabled: True\n"}, {"commit_sha": "9eb1a8fa8e281ef06687c1851f51fa0beec3e232", "sha": "1af260a2a3247fa0b4dd466f5d48f2c7fad434b3", "filename": "tasks/section_08_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n#  - name: 8.2 Configure rsyslog\n#  The rsyslog software is recommended as a replacement for the default syslogd daemon and\n#  provides improvements over syslogd, such as connection-oriented (i.e. TCP) transmission\n#  of logs, the option to log to database formats, and the encryption of log data en route to a\n#  central logging server.\n#  tags:\n#    - section8\n#    - section8.2\n\n\n  - name: 8.2.1 Install the rsyslog package (Scored)\n    apt: name=rsyslog state=present\n    tags:\n      - section8\n      - section8.2\n      - section8.2.1\n\n  - name: 8.2.2 Ensure the rsyslog Service is activated (Scored)\n    command: grep 'start on filesystem' /etc/rsyslog.conf\n    register: startonfilesystem\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.5.2 Configure rsyslog to Send Logs to a Remote Log Host (start rsyslog) (Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line='start on filesystem'\n       insertafter=EOF\n       state=present\n    when: startonfilesystem.rc == 1\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.3 Configure /etc/rsyslog.conf (Not Scored)\n    lineinfile:\n        dest: /etc/rsyslog.conf\n        line: \"{{ item }}\"\n        insertafter: EOF\n    with_items:\n      - '*.emerg :omusrmsg:*'\n      - 'mail.* -/var/log/mail'\n      - 'mail.info -/var/log/mail.info'\n      - 'mail.warning -/var/log/mail.warn'\n      - 'mail.err /var/log/mail.err'\n      - 'news.crit -/var/log/news/news.crit'\n      - 'news.err -/var/log/news/news.err'\n      - 'news.notice -/var/log/news/news.notice'\n      - '*.=warning;*.=err -/var/log/warn'\n      - '*.crit /var/log/warn'\n      - '*.*;mail.none;news.none -/var/log/messages'\n      - 'local0,local1.* -/var/log/localmessages'\n      - 'local2,local3.* -/var/log/localmessages'\n      - 'local4,local5.* -/var/log/localmessages'\n      - 'local6,local7.* -/var/log/localmessages'\n    changed_when: False\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.3\n\n  - name: 8.2.4.1 Create and Set Permissions on rsyslog Log Files (Scored)\n    shell: awk '{ print $NF }' /etc/rsyslog.d/* /etc/rsyslog.conf | grep /var/log | sed 's/^-//' | sed 's/)$//' \n    register: result\n    changed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.4.2 Create and Set Permissions on rsyslog Log Files (Scored)\n    shell: 'mkdir -p -- \"$(dirname -- {{ item }})\"; touch -- {{ item }}' \n    with_items: result.stdout_lines          \n    changed_when: False\n    register: rsyslog_files_created\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.4.3 Create and Set Permissions on rsyslog Log Files (Scored)\n    file:\n        path: \"{{ item }}\"\n        owner: root \n        group: root \n        mode: \"og-rwx\" \n    when: \"(rsyslog_files_created.results|length > 0) and ('skipped' not in rsyslog_files_created.results[0])\"\n    with_items: result.stdout_lines\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.5.1 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    command: grep \"^*.*[^I][^I]*@\" /etc/rsyslog.conf\n    register: remoteloghost \n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.5.2 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    lineinfile:\n        dest: /etc/rsyslog.conf\n        line: \"*.* @@{{remote_logs_host_address}}\"\n        insertafter: EOF\n        state: present\n    when: set_rsyslog_remote == True and remoteloghost.rc == 1\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.6.1 Accept Remote rsyslog Messages Only on Designated Log Hosts (Not Scored)\n    command: grep '^$ModLoad imtcp' /etc/rsyslog.conf\n    register: moadloadpresent\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.6\n\n  - name: 8.2.6.2 Accept Remote rsyslog Messages Only on Designated Log Hosts (Not Scored)\n    lineinfile:\n        dest: /etc/rsyslog.conf\n        regexp: \"^#({{ item }})\"\n        line: \"{{ item }}\"\n        state: present\n    with_items:\n        - '$ModLoad imtcp'\n        - '$InputTCPServerRun 514'\n    when: set_rsyslog_remote == True and moadloadpresent.rc == 1\n    changed_when: False\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.6\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "91a06d8b3c8f73cc69e65c15368b7c238893df59", "filename": "roles/docker/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for docker\n- name: ensure docker config dir exists\n  become: yes\n  file:\n    path: /root/.docker\n    state: directory\n  tags:\n    - docker\n\n- name: setup private docker registry credentials\n  become: yes\n  when: private_docker_registry|bool\n  template:\n    src: config.json.j2\n    dest: /root/.docker/config.json\n  tags:\n    - docker\n\n- name: deploy docker service\n  become: yes\n  become_user: root\n  template:\n    src: docker.service.j2\n    dest: /etc/systemd/system/docker.service\n  notify:\n    - reload systemd\n    - restart docker\n  tags:\n    - docker\n\n- name: ensure docker is running (and enable it at boot)\n  become: yes\n  service:\n    name: docker\n    state: started\n    enabled: yes\n  tags:\n    - docker\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "2d91440b5f944c7e28e33e78197fe7c1928c883d", "filename": "roles/dnsmasq/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for dnsmasq\n- name: restart dnsmasq\n  service:\n    name: dnsmasq\n    state: restarted\n  sudo: yes\n\n"}, {"commit_sha": "92d2f38d01d7b33610c667cfdc03e28ab2912edc", "sha": "0348d9dc8ed13195ac7c462b7e09517253645122", "filename": "tasks/section_05_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 5.1.1 Ensure NIS is not installed (Scored)\n    apt: name=nis state=absent purge=yes\n    tags:\n    - section5\n    - section5.1\n    - section5.1.1\n\n  - name: 5.1.2 Ensure rsh, rlogin, rexec, talk, telnet, chargen, daytime, echo, discard, time is not enabled (stat inetd) (Scored)\n    stat: path=/etc/inetd.conf\n    register: inetd_path\n    tags:\n    - section5\n    - section5.1\n    - section5.1.2\n\n  - name: 5.1.2-.6 Ensure rsh, rlogin, rexec, talk, telnet, chargen, daytime, echo, discard, time is not enabled (Scored)\n    lineinfile: >\n        dest=/etc/inetd.conf\n        regexp='^({{ item }}.*)'\n        line='#\\1'\n        state=present\n        backrefs=yes\n        backup=yes\n    with_items:\n        - shell\n        - login\n        - exec\n        - talk\n        - ntalk\n        - telnet\n        - chargen\n        - daytime\n        - echo\n        - discard\n        - time\n    when: inetd_path.stat.exists == True\n    tags:\n    - section5\n    - section5.1\n    - section5.1.2\n\n  - name: 5.1.3.1 Ensure rsh client is not installed (Scored)\n    apt: name=rsh-client state=absent purge=yes\n    tags:\n    - section5\n    - section5.1\n    - section5.1.3\n    - section5.1.3.1\n\n  - name: 5.1.3.2 Ensure rsh client is not installed (Scored)\n    apt: name=rsh-redone-client state=absent purge=yes\n    tags:\n    - section5\n    - section5.1\n    - section5.1.3\n    - section5.1.3.2\n\n  - name: 5.1.5 Ensure talk client is not installed (Scored)\n    apt: name=talk state=absent purge=yes\n    tags:\n    - section5\n    - section5.1\n    - section5.1.5\n\n  - name: 5.1.8 Ensure xinetd is not enabled (stat xinetd) (Scored)\n    stat: path=/etc/init/xinetd.conf\n    register: xinetd_path\n    tags:\n    - section5\n    - section5.1\n    - section5.1.8\n\n  - name: 5.1.8 Ensure xinetd is not enabled (Scored)\n    lineinfile: >\n        dest=/etc/init/xinetd.conf\n        regexp='start on runlevel'\n        state=present\n        line='#start on runlevel [2345]'\n    when: xinetd_path.stat.exists == True\n    tags:\n    - section5\n    - section5.1\n    - section5.1.8\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "09e9b63c942a008e1867ad482d49b72b53213997", "filename": "tasks/section_08.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - include: section_08_level1.yml\n    tags:\n      - section08\n      - level1\n       \n\n  - include: section_08_level2.yml\n    tags:\n      - section08\n      - level2\n\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "8b137891791fe96927ad78e64b0aad7bded08bdc", "filename": "roles/dockerbench/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "\n"}, {"commit_sha": "f5364b57f100ae9fa898af59b7812ec0c447ac42", "sha": "6f01b4d54437d1f2462624e118b2f2499b6ecc96", "filename": "tasks/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Check for vulnerable ansible version (CVE-2016-8614, CVE-2016-8628)\n  assert:\n    that:\n      - \"{{ ansible_version.full | version_compare('2.1.3.0', '>=') }}\"\n    msg: \"VULNERABLE ansible version DETECTED, please update to v2.1.3 or newer! Exiting.\"\n  run_once: true\n  delegate_to: 127.0.0.1\n  tags:\n    - always\n\n- name: Check for local requirements\n  shell: command -V tor && command -V openssl && command -V sort && command -V uniq && command -V wc && command -V cut && command -V xargs && command -V sed\n  run_once: true\n  delegate_to: 127.0.0.1\n  tags:\n    - always\n\n- name: Set OS specific variables\n  include_vars: \"os_{{ ansible_os_family }}.yml\"\n  tags:\n   - always\n\n- include: ip-list.yml\n  tags:\n    - always\n\n- include: apt_prepare.yml\n  when: ansible_pkg_mgr == 'apt'\n  tags:\n   - debian\n   - install\n\n- include: rpm_prepare.yml\n  when: ansible_os_family == 'RedHat'\n  tags:\n   - centos\n   - fedora\n   - install\n\n- include: openbsd_prepare.yml\n  when: ansible_system == 'OpenBSD'\n  tags:\n   - openbsd\n\n- include: freebsd_prepare.yml\n  when: ansible_system == 'FreeBSD'\n  tags:\n   - freebsd\n\n# we specifically opt for present over latest to improve performance\n- name: Ensure tor is installed\n  become: yes\n  package:\n    name: \"{{ item }}\"\n    state: present\n  with_items: \"{{ tor_packages }}\"\n  # apt starts a tor client instance by default after installing the package\n  # we do not need that\n  notify:\n    - stop-and-mask default tor instance\n    - disable default tor instance FreeBSD\n  tags:\n   - openbsd\n   - freebsd\n   - debian\n   - centos\n   - fedora\n   - install\n\n- meta: flush_handlers\n\n- include: configure.yml\n  tags:\n   - debian\n   - centos\n   - fedora\n   - openbsd\n   - freebsd\n\n- include: linux_service.yml\n  when: ansible_system == 'Linux'\n  tags:\n   - debian\n   - centos\n   - fedora\n\n- include: openbsd_service.yml\n  when: ansible_system == 'OpenBSD'\n  tags:\n   - openbsd\n\n- include: freebsd_service.yml\n  when: ansible_system == 'FreeBSD'\n  tags:\n   - freebsd\n"}, {"commit_sha": "af3dfdf7cf37437f5609f1a12e4ac7cbaebd4867", "sha": "9473b3da710aab1fe28244f1484b25dbf6b06897", "filename": "roles/dockerbench/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for dockerbench\ndockerbench_run_test: false\ndockerbench_dest: /opt/dockerbench\ndockerbench_repo: https://github.com/docker/docker-bench-security.git\ndockerbench_warn_threshold: 52\n\n"}, {"commit_sha": "35ca6852d9333ef6c3ed223239f45b840c487d60", "sha": "ffd05717117ea72b48a9c933bc55addf2808f709", "filename": "roles/consul/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# defaults file for consul\nconsul_is_server: no\nconsul_dc: dc1\nconsul_servers_group: consul_servers\nconsul_advertise: \"{{ ansible_default_ipv4.address }}\"\nconsul_bind_addr: \"{{ ansible_default_ipv4.address }}\"\nconsul_bootstrap_expect: \"{{ groups[consul_servers_group] | length }}\"\nconsul_client_addr: \"0.0.0.0\"\nconsul_atlas_join: false\nconsul_node_name: \"{{ ansible_hostname }}\"\n"}, {"commit_sha": "35ca6852d9333ef6c3ed223239f45b840c487d60", "sha": "33fb67891aef6b0123fdec8da4f7adebd5361b0e", "filename": "roles/zookeeper/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# handlers file for zookeeper\n- name: Restart zookeeper\n  service:\n    name: zookeeper\n    state: restarted\n  sudo: yes\n\n- name: Start zookeeper\n  service:\n    name: zookeeper\n    state: started\n  sudo: yes\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "fc4ff6a816d92e2ea25d130f3cd8ddcf5483a69d", "filename": "roles/marathon/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- name: install wait script\n  when: marathon_enabled | bool\n  sudo: yes\n  template:\n    src: marathon-wait-for-listen.sh.j2\n    dest: /usr/local/bin/marathon-wait-for-listen.sh\n    mode: 0755\n  tags:\n    - marathon\n\n- name: create marathon artifact store directory\n  when: marathon_artifact_store_dir is defined and marathon_enabled | bool\n  file:\n    path: \"{{ marathon_artifact_store_dir }}\"\n    state: directory\n    mode: 0755\n  sudo: yes\n  tags:\n    - marathon\n\n- name: destroy old marathon container\n  when: marathon_rebuild_container\n  docker:\n    name: marathon\n    image: \"{{ marathon_image }}\"\n    state: absent\n\n- name: run marathon container\n  when: marathon_enabled | bool\n  docker:\n    name: marathon\n    image: \"{{ marathon_image }}\"\n    state: started\n    restart_policy: \"{{ marathon_restart_policy }}\"\n    ports:\n    - \"{{ marathon_port }}:{{ marathon_port }}\"\n    expose:\n    - \"{{ marathon_port }}\"\n    net: \"{{ marathon_net }}\"\n    command: \"{{ marathon_command }}\"\n    volumes:\n    - \"{{ marathon_artifact_store_dir }}:/store\"\n    memory_limit: \"{{ marathon_container_memory_limit }}\"\n    env:\n      JAVA_OPTS: \"{{ marathon_java_settings }}\"\n  notify:\n    - wait for marathon to listen\n\n- name: upload marathon template service\n  when: marathon_enabled | bool\n  template:\n    src: marathon.conf.j2\n    dest: /etc/init/marathon.conf\n    mode: 0755\n  sudo: yes\n  tags:\n    - marathon\n\n# Attach to the running container, or start it if needed\n# and forward all signals so that the process manager can detect\n# when a container stops and correctly restart it.\n- name: ensure marathon is running (and enable it at boot)\n  when: marathon_enabled | bool\n  sudo: yes\n  service:\n    name: marathon\n    state: started\n    enabled: yes\n  tags:\n    - marathon\n\n- name: Set marathon consul service definition\n  when: marathon_enabled | bool\n  sudo: yes\n  template:\n    src: marathon-consul.j2\n    dest: \"{{ marathon_consul_dir }}/marathon.json\"\n  notify:\n    - restart consul\n\n# tasks for stoping docker marathon\n- name: stop marathon container\n  when: not marathon_enabled | bool\n  service:\n    name: marathon\n    state: stopped\n    enabled: no\n  tags:\n    - marathon\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "bdebafc741bf0a0b3d738ec35a9979d778239c20", "filename": "tasks/section_13_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 13.1.1 Ensure Password Fields are Not Empty (check) (Scored)\n    command: awk -F':' '($2 == \"\" ) { print $1 }' /etc/shadow\n    register: awk_empty_shadow\n    changed_when: False\n    always_run: True\n    failed_when: awk_empty_shadow.stdout != '' and lock_shadow_accounts == False\n    tags:\n      - section13\n      - section13.1\n\n  - name: 13.1.2 Ensure Password Fields are Not Empty (locking accounts) (Scored)\n    command: passwd -l '{{ item }}'\n    with_items: \"{{awk_empty_shadow.stdout_lines}}\"\n    when: lock_shadow_accounts == True\n    tags:\n      - section13\n      - section13.1\n\n  - name: 13.2 Verify No Legacy \"+\" Entries Exist in /etc/passwd File (Scored)\n    command: grep '^+:' /etc/passwd\n    register: plus_pass\n    failed_when: plus_pass.rc == 0\n    changed_when: plus_pass.rc == 0\n    tags:\n      - section13\n      - section13.2\n\n  - name: 13.3 Verify No Legacy \"+\" Entries Exist in /etc/shadow File (Scored)\n    command: grep '^+:' /etc/shadow\n    register: plus_shadow\n    failed_when: plus_shadow.rc == 0\n    changed_when: plus_shadow.rc == 0\n    tags:\n      - section13\n      - section13.3\n\n  - name: 13.4 Verify No Legacy \"+\" Entries Exist in /etc/group File (Scored)\n    command: grep '^+:' /etc/group\n    register: plus_group\n    failed_when: plus_group.rc == 0\n    changed_when: plus_group.rc == 0\n    tags:\n      - section13\n      - section13.4\n\n  - name: 13.5 Verify No UID 0 Accounts Exist Other Than root (Scored)\n    command: awk -F':' '($3 == 0) { print $1 }' /etc/passwd\n    register: uid_zero_root\n    changed_when: False\n    failed_when: uid_zero_root.stdout != 'root'\n    tags:\n      - section13\n      - section13.5\n\n  - name: 13.6.1 Ensure root PATH Integrity (empty value) (Scored)\n    shell: 'echo $PATH | grep ::'\n    register: path_colon\n    changed_when: False\n    always_run: True\n    failed_when: path_colon.rc == 0\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.2 Ensure root PATH Integrity (colon end) (Scored)\n    shell: 'echo $PATH | grep :$'\n    register: path_colon_end\n    changed_when: False\n    always_run: True\n    failed_when: path_colon_end.rc == 0\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.3 Ensure root PATH Integrity (dot in path) (Scored)\n    shell: \"/bin/bash --login -c 'env | grep ^PATH=' | sed -e 's/PATH=//' -e 's/::/:/' -e 's/:$//' -e 's/:/\\\\n/g'\"\n    become: yes\n    register: dot_in_path\n    changed_when: False\n    always_run: True\n    failed_when: '\".\" in dot_in_path.stdout_lines'\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.4 Ensure root PATH Integrity (Scored)\n    file: >\n        path='{{ item }}'\n        follow=yes\n        state=directory\n        owner=root\n        mode='o-w,g-w'\n    with_items: \"{{dot_in_path.stdout_lines}}\"\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.7.1 Check Permissions on User Home Directories (gather users) (Scored)\n    shell: /bin/egrep -v '(root|halt|sync|shutdown|false)' /etc/passwd | /usr/bin/awk -F':' '($7 != \"/usr/sbin/nologin\") { print $6 }'\n    register: home_users\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.7\n\n  - name: 13.7.2 Check Permissions on User Home Directories (Scored)\n    file: >\n        path='{{ item }}'\n        mode='g-w,o-rwx'\n        state=directory\n    with_items: \"{{home_users.stdout_lines}}\"\n    when: modify_user_homes == True\n    tags:\n      - section13\n      - section13.7\n\n  - name: 13.8.1 Check User Dot File Permissions (check) (Scored)\n    shell: for pth in `/bin/egrep -v '(root|halt|sync|shutdown)' /etc/passwd | /usr/bin/awk -F':' '($7 != \"/usr/sbin/nologin\") { print $6 }'`; do ls -d -A -1 $pth/.* | egrep -v '[..]$'; done\n    changed_when: False\n    failed_when: False\n    always_run: True\n    register: home_dot_files\n    tags:\n      - section13\n      - section13.8\n\n  - name: 13.8.2 Check User Dot File Permissions (Scored)\n    file: >\n        path='{{ item }}'\n        follow=yes\n        mode='o-w,g-w'\n    with_items: \"{{home_dot_files.stdout_lines}}\"\n    tags:\n      - section13\n      - section13.8\n\n  - name: 13.9 Check Permissions on User .netrc Files (Scored)\n    file: >\n        path='{{ item }}/.netrc'\n        mode='g-rwx,o-rwx'\n        recurse=yes\n        state=directory\n    with_items: \"{{home_users.stdout_lines}}\"\n    tags:\n      - section13\n      - section13.9\n\n  - name: 13.10 Check for Presence of User .rhosts Files (Scored)\n    file: >\n        state=absent\n        path='{{ item }}/.rhosts'\n    with_items: \"{{home_users.stdout_lines}}\"\n    tags:\n      - section13\n      - section13.10\n\n  - name: 13.11.1 Check Groups in /etc/passwd (check) (Scored)\n    command: cut -s -d':' -f4 /etc/passwd\n    register: groups_id_cut\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.11\n\n  - name: 13.11.2 Check Groups in /etc/passwd (Scored)\n    command: grep -q -P \"^.*?:[^:]*:{{ item }}:\" /etc/group\n    with_items: \"{{groups_id_cut.stdout_lines}}\"\n    register: groups_present\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.11\n\n  - name: 13.12 Check That Users Are Assigned Valid Home Directories (Scored)\n    stat: path='{{ item }}'\n    with_items: \"{{home_users.stdout_lines}}\"\n    register: rstat\n    failed_when: rstat is defined and rstat.stat.isdir == False\n    always_run: True\n    tags:\n      - section13\n      - section13.12\n\n  - name: 13.13 Check User Home Directory Ownership (Scored)\n    debug: msg=\"*** Hardcore ***\"\n    tags:\n      - section13\n      - section13.13\n\n  - name: 13.14 Check for Duplicate UIDs (Scored)\n    shell: cut -f3 -d':' /etc/passwd | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.14\n\n  - name: 13.15 Check for Duplicate GIDs (Scored)\n    shell: cut -f3 -d':' /etc/group | sort | uniq -d\n    register: gids_list\n    failed_when: gids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.15\n\n  - name: 13.16 Check for Duplicate User Names (Scored)\n    shell: cut -f1 -d':' /etc/passwd | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.16\n\n  - name: 13.17 Check for Duplicate Group Names (Scored)\n    shell: cut -f1 -d':' /etc/group | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.17\n\n  - name: 13.18.1 Check for Presence of User .netrc Files (check) (Scored)\n    stat: path='{{ item }}/.netrc'\n    with_items: '{{ home_users.stdout_lines }}'\n    always_run: True\n    changed_when: False\n    register: netrc_files\n    tags:\n      - section13\n      - section13.18\n\n  - name: 13.18.2 Check for Presence of User .netrc Files (Scored)\n    debug: msg='Check if {{ item.stat.path}} is needed, and remove otherwise'\n    when: item is defined and item.stat.exists == True\n    with_items: '{{ netrc_files.results }}'\n    tags:\n      - section13\n      - section13.18\n\n  - name: 13.19 Check for Presence of User .forward Files (Scored)\n    file: >\n        path='{{ item }}/.forward'\n        state=absent\n    with_items: \"{{home_users.stdout_lines}}\"\n    tags:\n      - section13\n      - section13.19\n\n  - name: 13.20.1 Ensure shadow group is empty (check) (Scored)\n    shell: grep '^shadow' /etc/group | cut -f4 -d':'\n    register: shadow_group_empty\n    failed_when: shadow_group_empty.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.1\n\n  - name: 13.20.2 Ensure shadow group is empty (check) (Scored)\n    shell: grep '^shadow' /etc/group | cut -f1 -d':'\n    register: shadow_group_id\n    failed_when: False\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.1\n\n  - name: 13.20.3 Ensure shadow group is empty (check) (Scored)\n    shell: awk -F':' '($4 == \"{{ item }}\") { print }' /etc/passwd\n    register: awk_passwd_shadow\n    with_items: \"{{shadow_group_id.stdout_lines}}\"\n    changed_when: False\n    failed_when: awk_passwd_shadow.stdout != ''\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.2\n"}, {"commit_sha": "cb054bd0ed781881ab5d259917184c0ff4b006a7", "sha": "271354893c73535a4a8dc1b62e2641898cc36f53", "filename": "tasks/section_04_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: 4.5 Activate AppArmor (install) (Scored)\n    apt: >\n        name=apparmor\n        state=present\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (start) (Scored)\n    service: >\n        name=apparmor\n        state=started\n    when: use_apparmor == True\n    notify: restart rsyslog\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (Scored)\n    command: apparmor_status\n    register: aa_status_lines\n    failed_when: '\"0 profiles are loaded\" in aa_status_lines.stdout_lines or \"0 processes are in complain mode.\" not in aa_status_lines.stdout_lines or \"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n        # - '\"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n    changed_when: False\n    when: travis_env == False and use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (enforce install) (Scored)\n    apt: >\n        name=apparmor-utils\n        state=present\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (enforce) (Scored)\n    #shell: 'aa-enforce /etc/apparmor.d/*'\n    shell: for profile in /etc/apparmor.d/*; do aa-enforce $profile; done\n    register: aaenforce_rc\n    failed_when: aaenforce_rc.rc == 1\n    changed_when: False\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "a336c5a6cc4d182824d7b0ac2bf52349ece66209", "filename": "tasks/CentOS/redis.yml", "repository": "sensu/sensu-ansible", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# tasks/CentOS/redis.yml: Deploy redis\n# Specific to CentOS\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure redis is installed\n    yum:\n      name: \"{{ redis_pkg_name }}\"\n      state: \"{{ redis_pkg_state }}\"\n      enablerepo: \"{{ centos_repository }}\"\n\n  - name: Ensure redis binds to accessible IP\n    lineinfile:\n      dest: /etc/redis.conf\n      regexp: '^bind'\n      line: 'bind 0.0.0.0'\n"}, {"commit_sha": "92d2f38d01d7b33610c667cfdc03e28ab2912edc", "sha": "03b7f9f6cb7b9146c7e252de734691504b2c8198", "filename": "tasks/section_04_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n  - name: Check if the grub config file exists (Not Scored)\n    stat: path=/etc/default/grub\n    register: grub_cfg_file\n\n  - name: Determines if apparmor is set in grub config (Not Scored)\n    command: \"grep 'GRUB_CMDLINE_LINUX' /etc/default/grub\"\n    register: grub_apparmor\n    changed_when: False\n    when: grub_cfg_file.stat.exists\n    always_run: True\n\n  - name: Check if the extlinux config file exists (Not Scored)\n    stat: path=/extlinux.conf\n    register: extlinux_cfg_file\n\n  - name: Determines if apparmor is set in extlinux (Not Scored)\n    command: \"grep 'apparmor' /extlinux.conf\"\n    register: extlinux_apparmor\n    changed_when: False\n    when: extlinux_cfg_file.stat.exists\n    always_run: True\n\n  - name: Determines if apparmor is already set in boot config (Not Scored)\n    command: \"grep CONFIG_DEFAULT_SECURITY_APPARMOR /boot/config-{{ ansible_kernel }}\"\n    register: boot_apparmor\n    changed_when: False\n    always_run: True\n\n  - name: 4.5 Activate AppArmor (install) (Scored)\n    apt: >\n        name=apparmor\n        state=present\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (Kernel LSM - grub) (Scored)\n    lineinfile: >\n        dest='/etc/default/grub'\n        regexp='^GRUB_CMDLINE_LINUX=\"\"'\n        line='GRUB_CMDLINE_LINUX=apparmor=\"1 security=apparmor\"'\n        state=present\n    when: \"(use_apparmor == True) and grub_cfg_file.stat.exists and ('apparmor' not in grub_apparmor['stdout']) and ('not set' in boot_apparmor['stdout'])\"\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (Kernel LSM - extlinux) (Scored)\n    lineinfile: >\n        dest='/extlinux.conf'\n        regexp=\"^append initrd=\"\n        line=\"append initrd={{ ansible_cmdline['initrd'] }} root={{ ansible_cmdline['root'] }} console=tty0 console={{ ansible_cmdline['console'] }} apparmor=1 security=apparmor ro quiet\"\n    when: \"(use_apparmor == True) and extlinux_cfg_file.stat.exists and ('apparmor' not in extlinux_apparmor['stdout']) and ('not set' in boot_cfg_apparmor['stdout'])\"\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (start) (Scored)\n    service: >\n        name=apparmor\n        state=started\n    when: use_apparmor == True\n    register: apparmor_status\n    ignore_errors: True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Determine if Apparmor started without error (Not Scored)\n    fail: msg=\"Apparmor can not be started. This is normal behavior if you run the playbook for the first time.\\nPlease reboot the machine and run it again to proceed with the rest of the playbook.\"\n    when: apparmor_status.failed is defined\n\n  - name: 4.5 Fix rsyslog /run/utmp permissions (Not Scored)\n    lineinfile: >\n        dest=\"/etc/apparmor.d/usr.sbin.rsyslogd\"\n        line=\"  /run/utmp rk,\"\n        insertbefore=\"  /var/spool/rsyslog/ r,\"\n        state=present\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (fix profiles) (Scored)\n    service: >\n        name=rsyslog\n        state=restarted\n    changed_when: False\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (Scored)\n    command: apparmor_status\n    register: aa_status_lines\n    failed_when: '\"0 profiles are loaded\" in aa_status_lines.stdout_lines or \"0 processes are in complain mode.\" not in aa_status_lines.stdout_lines or \"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n        # - '\"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n    changed_when: False\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (enforce install) (Scored)\n    apt: >\n        name=apparmor-utils\n        state=present\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (enforce) (Scored)\n    #shell: 'aa-enforce /etc/apparmor.d/*'\n    shell: for profile in /etc/apparmor.d/*; do aa-enforce $profile; done\n    register: aaenforce_rc\n    failed_when: aaenforce_rc.rc == 1\n    changed_when: False\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n"}, {"commit_sha": "fa66f2d6f5193cce5c2f9086e78f9bff39133e60", "sha": "81339b6aeb0eb2caf66576e4691e2e3130e310b5", "filename": "tasks/freebsd_service.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- name: Ensure PidDir exists (FreeBSD)\n  become: yes\n  file: path={{ tor_PidDir }}\n    state=directory\n    owner=root\n    mode=0755\n\n- name: Ensure PidDir is owned by per-instance tor_user (FreeBSD)\n  become: yes\n  file: path={{ tor_PidDir }}/{{ item[0] }}_{{ item.1.orport }}\n    state=directory\n    owner=_tor-{{ item[0] }}_{{ item.1.orport }}\n    mode=0700\n  with_nested:\n   - tor_ips\n   - tor_ports\n\n- name: Ensure Tor instances are reloaded if its torrc changed (FreeBSD)\n  become: yes\n  shell: \"kill -HUP `cat {{ tor_PidDir }}/{{ item.item[0] }}_{{ item.item.1.orport }}/pid`\"\n  ignore_errors: yes\n  with_items: instances.results\n  when: item.changed == True\n  tags:\n   - reconfigure\n\n- name: Ensure Tor instances are running (FreeBSD)\n  become: yes\n  shell: \"kill -0 `cat {{ tor_PidDir }}/{{ item[0] }}_{{ item.1.orport }}/pid` || tor -f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n"}, {"commit_sha": "694a4890fcf0daa375d6a173511f6ff7dd0f2335", "sha": "f14854e4be56c06dbbdccdb0f83fb12ac2fd9c65", "filename": "tasks/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- include: apt_install.yml\n  when: ansible_pkg_mgr == 'apt'\n  tags:\n   - debian\n   - install\n\n- include: rpm_install.yml\n  when: ansible_os_family == 'RedHat'\n  tags:\n   - centos\n   - fedora\n   - install\n\n- include: openbsd_install.yml\n  when: ansible_pkg_mgr == 'openbsd_pkg'\n  tags:\n   - openbsd\n\n- include: freebsd_install.yml\n  when: ansible_pkg_mgr == 'pkgng'\n  tags:\n   - freebsd\n\n- include: configure.yml\n  tags:\n   - debian\n   - centos\n   - fedora\n   - openbsd\n   - freebsd\n\n- include: linux_service.yml\n  when: ansible_system == 'Linux'\n  tags:\n   - debian\n   - centos\n   - fedora\n\n- include: openbsd_service.yml\n  when: ansible_system == 'OpenBSD'\n  tags:\n   - openbsd\n\n- include: freebsd_service.yml\n  when: ansible_system == 'FreeBSD'\n  tags:\n   - freebsd\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "ebe88018ed9baf249123cfd2365e4d52de00e9bf", "filename": "handlers/main.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# File: main.yml - Handlers for Consul\n\n- name: restart consul\n  import_tasks: restart_consul.yml\n\n- name: start consul\n  import_tasks: start_consul.yml\n\n- name: reload consul configuration\n  import_tasks: reload_consul_conf.yml\n\n- name: restart dnsmasq\n  service:\n    name: dnsmasq\n    state: restarted\n\n- name: restart rsyslog\n  import_tasks: restart_rsyslog.yml\n\n- name: restart syslog-ng\n  import_tasks: restart_syslogng.yml\n\n- name: restart syslog-ng\n  import_tasks: restart_syslogng.yml\n\n- name: start snapshot\n  import_tasks: start_snapshot.yml\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "8eba9ef4a2d851bcb7c664e82dedbc8e7e5cd518", "filename": "roles/mesos/tasks/slave.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# Tasks for Slave nodes\n- name: create mesos-slave work directory\n  file:\n    path: \"{{ mesos_slave_work_dir }}\"\n    state: directory\n    mode: 0755\n  become: yes\n  tags:\n    - mesos-slave\n\n- name: deploy mesos-slave service\n  become: yes\n  become_user: root\n  template:\n    src: mesos-slave.service.j2\n    dest: /etc/systemd/system/mesos-slave.service\n  notify:\n    - reload systemd\n    - restart mesos slave\n  tags:\n    - mesos-slave\n\n- name: ensure mesos-slave is running (and enable it at boot)\n  become: yes\n  service:\n    name: mesos-slave\n    state: started\n    enabled: yes\n  tags:\n    - mesos-slave\n\n- name: run prometheus mesos slave exporter container\n  when: prometheus_enabled|bool\n  docker:\n    name: mesos-exporter\n    image: \"{{ prometheus_mesos_exporter_image }}\"\n    command: \"-exporter.scrape-mode=slave -exporter.url=http://{{ mesos_hostname }}:{{ mesos_slave_port }}\"\n    state: started\n    restart_policy: always\n    ports:\n    - \"{{ prometheus_mesos_exporter_port }}:{{ prometheus_mesos_exporter_port }}\"\n  environment: \"{{ proxy_env }}\"\n  tags:\n    - prometheus\n    - mesos_slave\n\n- name: Set mesos-exporter consul service definition\n  when: prometheus_enabled|bool\n  become: yes\n  template:\n    src: mesos-exporter-consul.j2\n    dest: \"{{ consul_dir }}/mesos-exporter.json\"\n  notify:\n    - restart consul\n  tags:\n    - prometheus\n    - mesos_slave\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "4dfd9c5d31ee1f909a2dfec3f23448fd1cc12b9b", "filename": "roles/dcos_cli/templates/exhibitor-config.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "{\n  \"exhibitor\": {\n    \"zk_servers\": \"{{ zookeeper_peers_nodes }}\",\n    \"app-id\": \"exhibitor\",\n    \"cpus\": {{ dcos_cli_framework_exhibitor_cpus }},\n    \"mem\": {{ dcos_cli_framework_exhibitor_mem }},\n    \"docker-image\": \"{{ dcos_cli_framework_exhibitor_image }}\"\n  }\n}\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "90929d88f73895ed88a26adeb15708e5282a7a92", "filename": "roles/st2/defaults/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# 'stable' to get latest version or numeric like '1.4.0'\nst2_version: stable\n# used only if 'st2_version' is numeric\nst2_revision: 1\n\nst2_system_user: stanley\nst2_ssh_key_file: /home/{{ st2_system_user }}/.ssh/{{ st2_system_user }}_rsa\n\nenable_auth: true\nst2_auth_username: testu\nst2_auth_password: testp\n\n# Set to no if you do not want the st2_system_user to be added in the sudoers file\nst2_system_user_in_sudoers: yes\n"}, {"commit_sha": "df06f3c3304c3f73f740d444222642fbad41bebb", "sha": "223c9b30d2e31cf204f7fc66ae13819bb17e79e7", "filename": "tasks/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n- include: apt_install.yml\n  when: ansible_pkg_mgr == 'apt'\n  tags:\n   - debian\n   - install\n\n- include: yum_install.yml\n  when: ansible_pkg_mgr == 'yum'\n  tags:\n   - centos\n   - install\n\n- include: openbsd_install.yml\n  when: ansible_pkg_mgr == 'openbsd_pkg'\n  tags:\n   - openbsd\n   - install\n\n- include: freebsd_install.yml\n  when: ansible_pkg_mgr == 'pkgng'\n  tags:\n   - freebsd\n   - install\n\n- include: dnf_install.yml\n  when: ansible_pkg_mgr == 'dnf'\n  tags:\n   - fedora\n   - install\n\n- include: configure.yml\n"}, {"commit_sha": "a2393d46f0b98700161c4cefd9260d7694bd0bf3", "sha": "a8b8d7eed0cbf561621b66cba9f7989b21b2e6ef", "filename": "tasks/section_03_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n#sections 3.3 and 3.4 have to happen before as the latter overwrite 3.1 and 3.2\n\n  - name: 3 Check for /boot/grub/grub.cfg file\n    stat: path=/boot/grub/grub.cfg\n    register: grub_cfg_file\n    tags:\n      - section3\n\n  - name: 3.3.1.1 Set Boot Loader Superuser (check) (Scored)\n    command: grep \"^set superusers\" /boot/grub/grub.cfg\n    register: boot_superusers \n    when: grub_cfg_file.stat.exists == True\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section3\n      - section3.3\n      - section3.3.1\n      - section3.3.1.1\n\n  - name: 3.3.1.2 Set Boot Loader Superuser (Scored)\n    lineinfile: >\n        dest='/etc/grub.d/40_custom'\n        regexp='^set superusers'\n        line='set superusers=\"root\"'\n        state=present\n    when: grub_cfg_file.stat.exists == True and boot_superusers.rc == 1\n    tags:\n      - section3\n      - section3.3\n      - section3.3.1\n      - section3.3.1.2\n    \n  - name: 3.3.2.1 Set Boot Loader Password (check) (Scored)\n    command: grep \"^password\" /boot/grub/grub.cfg\n    register: boot_password\n    when: grub_cfg_file.stat.exists == True\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section3\n      - section3.3\n      - section3.3.2\n      - section3.3.2.1\n\n  - name: 3.3.2.2 Set Boot Loader Password (Scored)\n    lineinfile: >\n        dest='/etc/grub.d/40_custom' \n        regexp='^password'\n        line='password_pbkdf2 root grub.pbkdf2.sha512.10000.529DB4AF052F170948C1DB2A754CEA8A286804DA2D9A4EB5A7CCE4B8636775C83EAF8A1093CBDBC256954BCE789A58EFB3B75D23DFC76583C703922D5DADB69E.4D5BD1EC6736057095CA2EBF55C2DA02DFB0B0784F2105A396F1CEF11FEB1483D5C420F412E2E817E2570DDFC22ABCC329C5FF44091A0ACDE67171FF72E96CFD'\n        state=present\n    when: grub_cfg_file.stat.exists == True and boot_password.rc == 1\n    tags:\n      - section3\n      - section3.3\n      - section3.3.2\n      - section3.3.2.2\n\n  - name: 3.3.3 Disable password protection booting\n    lineinfile: >\n        dest='/etc/grub.d/10_linux'\n        create=yes\n        regexp='^CLASS='\n        line='CLASS=\"--class gnu-linux --class gnu --class os --unrestricted\"'\n        state=present\n    tags:\n      - section3\n      - section3.3\n      - section3.3.3\n\n\n  - name: 3.3.4 Update Grub configuration (Scored)\n    command: update-grub\n    when: grub_cfg_file.stat.exists == True and (boot_superusers.rc == 1 or boot_password.rc == 1)\n    tags:\n      - section3\n      - section3.3\n      - section3.3.4\n\n\n  - name: 3.4.1 Require Authentication for Single-User Mode (check) (Scored)\n    shell: 'grep \"^root:[*\\!]:\" /etc/shadow'\n    register: root_password_set\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section3\n      - section3.4\n      - section3.4.1\n\n  - name: 3.4.2 Require Authentication for Single-User Mode (Scored)\n    user: name=root state=present password={{ root_password }}\n    when: root_password_set.rc == 1\n    tags:\n      - section3\n      - section3.4\n      - section3.4.2\n\n  - name: 3.1 Set User/Group Owner on bootloader config (Scored)\n    file: path=/boot/grub/grub.cfg owner=root group=root\n    when: grub_cfg_file.stat.exists == True\n    tags:\n      - section3\n      - section3.1\n\n  - name: 3.2 Set Permissions on bootloader config (Scored)\n    file: path=/boot/grub/grub.cfg mode=\"o-rwx,g-rwx\"\n    when: grub_cfg_file.stat.exists == True\n    sudo: yes\n    tags:\n      - section3\n      - section3.2\n"}, {"commit_sha": "d6b9aef3a890db0fa37a2812da7b3aa1b418c15f", "sha": "1fd1c3aefe697d2cfc2062e1261c7aa31b240d3d", "filename": "tasks/section_08_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n\n#  - name: 8.2 Configure rsyslog\n#  The rsyslog software is recommended as a replacement for the default syslogd daemon and\n#  provides improvements over syslogd, such as connection-oriented (i.e. TCP) transmission\n#  of logs, the option to log to database formats, and the encryption of log data en route to a\n#  central logging server.\n#  tags:\n#    - section8\n#    - section8.2\n\n\n  - name: 8.2.1 Install the rsyslog package (Scored)\n    apt: name=rsyslog state=present\n    tags:\n      - section8\n      - section8.2\n      - section8.2.1\n\n  - name: 8.2.2 Ensure the rsyslog Service is activated (Scored)\n    command: grep 'start on filesystem' /etc/rsyslog.conf\n    register: startonfilesystem\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.5.2 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line='start on filesystem'\n       insertafter=EOF\n       state=present\n    when: startonfilesystem.rc == 1\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.3 Configure /etc/rsyslog.conf (Not Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line=\"{{ item }}\"\n       insertafter=EOF\n    with_items:\n      - '*.emerg :omusrmsg:*'\n      - 'mail.* -/var/log/mail'\n      - 'mail.info -/var/log/mail.info'\n      - 'mail.warning -/var/log/mail.warn'\n      - 'mail.err /var/log/mail.err'\n      - 'news.crit -/var/log/news/news.crit'\n      - 'news.err -/var/log/news/news.err'\n      - 'news.notice -/var/log/news/news.notice'\n      - '*.=warning;*.=err -/var/log/warn'\n      - '*.crit /var/log/warn'\n      - '*.*;mail.none;news.none -/var/log/messages'\n      - 'local0,local1.* -/var/log/localmessages'\n      - 'local2,local3.* -/var/log/localmessages'\n      - 'local4,local5.* -/var/log/localmessages'\n      - 'local6,local7.* -/var/log/localmessages'\n    changed_when: False\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.3\n\n  - name: 8.2.4.1 Create and Set Permissions on rsyslog Log Files (Scored)\n    shell: awk '{ print $NF }' /etc/rsyslog.d/* /etc/rsyslog.conf | grep /var/log | sed 's/^-//' | sed 's/)$//' \n    register: result\n    changed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.4.2 Create and Set Permissions on rsyslog Log Files (Scored)\n    shell: 'mkdir -p -- \"$(dirname -- {{ item }})\"; touch -- {{ item }}' \n    with_items: result.stdout_lines          \n    changed_when: False\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.4.3 Create and Set Permissions on rsyslog Log Files (Scored)\n    file: >\n        path='{{item}}' \n        owner=root \n        group=root \n        mode=\"og-rwx\" \n    with_items: result.stdout_lines\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.5.1 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    command: grep \"^*.*[^I][^I]*@\" /etc/rsyslog.conf\n    register: remoteloghost \n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.5.2 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line=\"*.* @@{{Remote_Logs_Host_Address}}\"\n       insertafter=EOF\n       state=present\n    when: send_rsyslog_remote == True and remoteloghost.rc == 1\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.6.1 Accept Remote rsyslog Messages Only on Designated Log Hosts (Not Scored)\n    command: grep '^$ModLoad imtcp' /etc/rsyslog.conf\n    register: moadloadpresent\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.6\n\n  - name: 8.2.6.2 Accept Remote rsyslog Messages Only on Designated Log Hosts (Not Scored)\n    lineinfile: >\n        dest=/etc/rsyslog.conf\n        regexp='^#({{ item }})'\n        line='{{ item }}'\n        state=present\n    with_items:\n        - '$ModLoad imtcp'\n        - '$InputTCPServerRun 514'\n    when: send_rsyslog_remote == True and moadloadpresent.rc == 1\n    changed_when: False\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.6\n"}, {"commit_sha": "4aaf839a9916f65d12b8964b23dbc6848a73ca67", "sha": "077bb2b8373ec323666c28277aa9b2dc693c5bc2", "filename": "roles/registrator/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n# defaults file for registrator\nregistrator_image: \"gliderlabs/registrator:master\"\nregistry_ip: \"127.0.0.1\"\nregistry_port: 8500\nhostname: \"{{ ansible_all_ipv4_addresses }}\"\n\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "81b54f2409efabaf8c40ebbf73b6d7361ea08c57", "filename": "roles/dcos_cli/meta/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\ngalaxy_info:\n  author: Alberto Lamela\n  description:\n  company: Capgemini\n  license: MIT\n  min_ansible_version: 2.0\n  platforms:\n  - name: CoreOS\n    versions:\n    - all\n  categories:\n  - cloud\n  - cloud:ec2\n  - cloud:gce\n  - cloud:rax\ndependencies: []\n\n\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "47c83ece2e4dc17c459390436ba93c32eccbce2d", "filename": "handlers/start_consul.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": "", "release_ends_at": "", "decoded_content": "---\n- name: start consul on Linux\n  service:\n    name: consul\n    state: started\n  when: ansible_os_family != \"Windows\"\n  listen: 'start consul'\n\n- name: start consul on windows\n  win_service:\n    name: consul\n    state: started\n  when: ansible_os_family == \"Windows\"\n  listen: 'start consul'\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "2cd70a35a55debea55bdb0f3baa97680d2717db7", "filename": "roles/weave/tasks/scope.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "- name: download scope\n  become: yes\n  become_user: root\n  get_url:\n    url: \"{{ scope_url }}\"\n    dest: \"{{ scope_bin }}\"\n    mode: 0755\n    validate_certs: no\n    force: true\n  environment: \"{{ proxy_env }}\"\n  tags:\n    - scope\n\n- name: deploy scope service\n  become: yes\n  become_user: root\n  template:\n    src: scope.service.j2\n    dest: /etc/systemd/system/scope.service\n  tags:\n    - scope\n\n- name: ensure scope service is running.\n  become: yes\n  service:\n    name: scope\n    state: started\n    enabled: yes\n  tags:\n    - scope\n"}, {"commit_sha": "bf6e08dcb2440421477b6536ff6a8d11adc2be17", "sha": "86e6f45e6ad17439b35e06510487c2180946778a", "filename": "roles/docker/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "", "decoded_content": "---\n# tasks file for docker\n- name: remove docker override\n  file:\n    path: /etc/init/docker.override\n    state: absent\n  notify:\n    - restart docker\n  tags:\n    - docker\n\n- name: configure docker graph directory\n  sudo: yes\n  lineinfile:\n    dest: /etc/default/docker\n    state: present\n    regexp: ^DOCKER_OPTS=.*--graph.*\n    line: 'DOCKER_OPTS=\\\"$DOCKER_OPTS --graph={{ docker_graph_dir }}\\\"'\n  notify:\n    - restart docker\n\n- name: configure docker temporary directory\n  sudo: yes\n  lineinfile:\n    dest: /etc/default/docker\n    state: present\n    line: 'DOCKER_TMPDIR=\\\"{{ docker_tmp_dir }}\\\"'\n  notify:\n    - restart docker\n\n- name: ensure docker is running (and enable it at boot)\n  service:\n    name: docker\n    state: started\n    enabled: yes\n  tags:\n    - docker\n"}]