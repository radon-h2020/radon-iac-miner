[{"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "dcb28b999d3435400ccf64a3f5e17c9de1310cee", "filename": "roles/config-dns-server/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: restart named\n  service:\n    name: named\n    state: restarted\n\n- name: reload named\n  service:\n    name: named\n    state: reloaded\n"}, {"commit_sha": "79e29502fb4e0ff1c30c0b5396bfa1b48fb84a8e", "sha": "fb0088e50c469c741bf578e97b646a53e06cd2dd", "filename": "meta/main.yml", "repository": "Oefenweb/ansible-wordpress", "decoded_content": "# meta file for screen\n---\ngalaxy_info:\n  author: Mischa ter Smitten\n  company: Oefenweb.nl B.V.\n  description: Set up (multiple) wordpress installations in Debian-like systems (using wp-cli)\n  license: MIT\n  min_ansible_version: 1.4\n  platforms:\n    - name: Ubuntu\n      versions:\n        - lucid\n        - precise\n        - trusty\n    - name: Debian\n      versions:\n        - squeeze\n        - wheezy\n  categories:\n    - web\ndependencies: []\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "9e4ee86ab2a9da8b085553ae6bc1004e1a575e14", "filename": "playbooks/prep.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Configure RHSM usernames/passwords'\n  hosts: localhost\n  tasks:\n  - block:\n    - pause:\n        prompt: 'Please enter your Red Hat Subscription username'\n      register: username\n    - set_fact:\n        rhsm_username: \"{{ username.user_input }}\"\n    - pause:\n        prompt: 'Please enter your Red Hat Subscription password'\n        echo: no\n      no_log: True\n      register: password\n    - set_fact:\n        rhsm_password: \"{{ password.user_input }}\"\n      no_log: True\n    tags:\n    - configure_rhsm\n    when:\n    - rhsm_register|default(False)\n    - rhsm_activationkey is undefined\n    - rhsm_org_id is undefined\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "f0ffb9159a2a3e0b93ae646dd183e7131a9918da", "filename": "roles/dns_adblocking/tasks/ubuntu.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- name: Ubuntu | Dnsmasq profile for apparmor configured\n  template: src=usr.sbin.dnsmasq.j2 dest=/etc/apparmor.d/usr.sbin.dnsmasq owner=root group=root mode=0600\n  when: apparmor_enabled is defined and apparmor_enabled == true\n  notify:\n    - restart dnsmasq\n\n- name: Ubuntu | Enforce the dnsmasq AppArmor policy\n  shell: aa-enforce usr.sbin.dnsmasq\n  when: apparmor_enabled is defined and apparmor_enabled == true\n  tags: ['apparmor']\n\n- name: Ubuntu | Ensure that the dnsmasq service directory exist\n  file: path=/etc/systemd/system/dnsmasq.service.d/ state=directory mode=0755  owner=root group=root\n\n- name: Ubuntu | Setup the cgroup limitations for the ipsec daemon\n  template: src=100-CustomLimitations.conf.j2 dest=/etc/systemd/system/dnsmasq.service.d/100-CustomLimitations.conf\n  notify:\n    - daemon-reload\n    - restart dnsmasq\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "004386dd53f64c511a45c2888d3e8dc0aa7b0af2", "filename": "roles/config-quay-enterprise/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# Base Configurations\nquay_name: quay\nquay_service: \"{{ quay_name }}.service\"\nquay_server_hostname:\nquay_database_type: postgresql\n\n#Systemd\nsystemd_service_dir: /usr/lib/systemd/system\nsystemd_environmentfile_dir: /etc/sysconfig\n\n# Quay\nquay_image: quay.io/coreos/quay:v2.9.3\nquay_config_dir: /var/lib/quay/config\nquay_container_config_dir: /conf/stack\nquay_storage_dir: /var/lib/quay/storage\nquay_container_storage_dir: /datastorage\nquay_storage_selinux_relabel: True\n\n# External Databases\npostgresql_db_uri: \"postgresql://{{ quay_database_username }}:{{ quay_database_password }}@{{ quay_database_host }}:{{ quay_database_port | default('5432') }}/{{ quay_database_name }}\"\nmysql_db_uri: \"mysql+pymysql://{{ quay_database_username }}:{{ quay_database_password }}@{{ quay_database_host }}:{{ quay_database_port | default('3306') }}/{{ quay_database_name }}\"\n\n# Container Credentials\ncontainer_credentials_file: /root/.docker/config.json\ncontainer_credentials_file_content: {}\nquay_registry_server: quay.io\nquay_registry_auth:\nquay_registry_email:\n\n# Port Configurations\nquay_host_http_port: 80\nquay_container_http_port: 80\nquay_host_https_port: 443\nquay_container_https_port: 443\n\n# SSL\nquay_ssl_enable: True\nquay_ssl_key_file: \"\"\nquay_ssl_cert_file: \"\"\nquay_ssl_generate_city: Raleigh\nquay_ssl_generate_state: NC\nquay_ssl_generate_country: US\nquay_ssl_generate_organization: Red Hat\nquay_ssl_generate_organizational_unit: CoP\nquay_ssl_generate_days_validity: 365\nquay_ssl_local_tmp_dir: \"/tmp\"\nquay_ssl_delete_generated_cert: True\n\n# Clair\nquay_clair_enable: False\nquay_clair_endpoint: \"\"\n\n# Builder\nquay_builder_enable: False\n\n# Superuser Configuration\nquay_superuser_username: \"\"\nquay_superuser_password: \"\"\nquay_superuser_email: \"\""}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "1f47544bb0915a19aa2a46b96c936700b9dd5075", "filename": "tasks/main.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Set distribution facts\n  set_fact:\n    _docker_os_dist: \"{{ ansible_distribution }}\"\n    _docker_os_dist_release: \"{{ ansible_distribution_release }}\"\n    _docker_os_dist_major_version: \"{{ ansible_distribution_major_version }}\"\n    _docker_os_dist_check: yes\n  tags: [\"always\"]\n\n- name: Reinterpret distribution facts for Linux Mint 18\n  set_fact:\n    _docker_os_dist: \"Ubuntu\"\n    _docker_os_dist_release: \"xenial\"\n    _docker_os_dist_major_version: \"16\"\n  when:\n    _docker_os_dist == \"Linux Mint\" and\n    _docker_os_dist_major_version == \"18\"\n  tags: [\"always\"]\n\n- name: Reset role variables\n  set_fact:\n    docker_systemd_service_config_tweaks: []\n    docker_service_envs: {}\n  tags: [\"always\"]\n\n- name: Temporary handling of deprecated variable docker_enable_ce_edge (#54)\n  set_fact:\n    docker_channel: edge\n  when:\n    - docker_enable_ce_edge is defined\n    - docker_enable_ce_edge\n  tags: [\"always\"]\n\n- name: Temporary handling of deprecated variable docker_pkg_name\n  set_fact:\n    docker_version: \"{{ docker_pkg_name | regex_replace('^docker-ce.(.+)$', '\\\\1') }}\"\n  when: docker_pkg_name is match('docker-ce' + docker_os_pkg_version_separator[_docker_os_dist])\n  tags: [\"always\"]\n\n- name: Compatibility and distribution checks\n  include_tasks: checks.yml\n  when: docker_do_checks | bool\n  tags: [\"always\"]\n\n- name: Install and configure Docker CE\n  block:\n    - name: Network access disabled\n      debug:\n        msg: \"Tasks requiring network access will be skipped!\"\n      when: not docker_network_access\n      \n    - name: Setup Docker package repositories\n      include_tasks: setup-repository.yml\n      tags: [\"install\"]\n\n    - name: Remove Docker versions before Docker CE\n      include_tasks: remove-pre-docker-ce.yml\n      when: \n        - docker_remove_pre_ce | bool\n        - docker_network_access\n      tags: [\"install\"]\n\n    - name: Install Docker\n      include_tasks: install-docker.yml\n      when: docker_network_access\n      tags: [\"install\"]\n\n    - name: Configure audit logging\n      include_tasks: setup-audit.yml\n      tags: [\"configure\"]\n\n    - name: Apply workarounds for bugs and/or tweaks\n      include_tasks: bug-tweaks.yml\n      tags: [\"configure\"]\n\n    - name: Configure Docker\n      include_tasks: configure-docker.yml\n      tags: [\"configure\"]\n\n    - name: Postinstall tasks\n      include_tasks: postinstall.yml\n      when: docker_network_access\n      tags: [\"install\", \"postinstall\"]\n  when: not docker_remove | bool\n\n- name: Remove Docker CE and related configuration\n  include_tasks: remove-docker.yml\n  when: docker_remove | bool\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "2f04e4e7fe33d2c3cdca8edcf5ffe2186659e602", "filename": "roles/config-pxe/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: prep.yml\n- import_tasks: pxe.yml\n- import_tasks: kickstart.yml\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "7e6aa168bf44b348ff38c5d6639b15c3f426c7f0", "filename": "playbooks/generate-defaults.yml", "repository": "rocknsm/rock", "decoded_content": "---\n- hosts: all\n  tasks:\n  - name: Read in variables\n    include_vars: \"rocknsm_config.dist.yml\"\n\n  - name: Apply override settings, if available\n    include_vars: /etc/rocknsm/config.yml\n    ignore_errors: true\n    failed_when: false\n\n  - name: Create config directory\n    file:\n      state: directory\n      owner: root\n      group: root\n      mode:  0755\n      path: /etc/rocknsm\n\n  - name: Render template\n    template:\n      backup: yes\n      src: rock_config.yml.j2\n      dest: /etc/rocknsm/config.yml\n      owner: root\n      group: root\n      mode: 0644\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "d3927da63c64a204ef198a2f1956b6e174add784", "filename": "playbooks/bb8/deploy_fis.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- name: Deploy Monitoring\n  hosts: masters[0]\n  vars:\n    BASEURL: https://raw.githubusercontent.com/jboss-fuse/application-templates/GA\n  gather_facts: no\n  tasks:\n\n   - name: Switch to project 'Openshift'\n     command: oc project openshift\n\n   - name: Update FIS ImageStream\n     command: oc replace --force -n openshift -f {{BASEURL}}/fis-image-streams.json\n\n   - name: Update karaf2-camel-amq-template\n     command: oc replace --force -n openshift -f {{BASEURL}}/quickstarts/karaf2-camel-amq-template.json\n\n   - name: Update karaf2-camel-log-template\n     command: oc replace --force -n openshift -f {{BASEURL}}/quickstarts/karaf2-camel-log-template.json\n\n   - name: Update karaf2-camel-rest-sql-template\n     command: oc replace --force -n openshift -f {{BASEURL}}/quickstarts/karaf2-camel-rest-sql-template.json\n\n   - name: Update karaf2-cxf-rest-template\n     command: oc replace --force -n openshift -f {{BASEURL}}/quickstarts/karaf2-cxf-rest-template.json\n\n   - name: Update spring-boot-camel-template\n     command: oc replace --force -n openshift -f {{BASEURL}}/quickstarts/spring-boot-camel-template.json\n\n   - name: Update spring-boot-camel-amq-template\n     command: oc replace --force -n openshift -f {{BASEURL}}/quickstarts/spring-boot-camel-amq-template.json\n\n   - name: Update spring-boot-camel-config-template\n     command: oc replace --force -n openshift -f {{BASEURL}}/quickstarts/spring-boot-camel-config-template.json\n\n   - name: Update spring-boot-camel-drools-template\n     command: oc replace --force -n openshift -f {{BASEURL}}/quickstarts/spring-boot-camel-drools-template.json\n\n   - name: Update spring-boot-camel-infinispan-template\n     command: oc replace --force -n openshift -f {{BASEURL}}/quickstarts/spring-boot-camel-infinispan-template.json\n\n   - name: Update spring-boot-camel-rest-sql-template\n     command: oc replace --force -n openshift -f {{BASEURL}}/quickstarts/spring-boot-camel-rest-sql-template.json\n\n   - name: Update spring-boot-camel-teiid-template\n     command: oc replace --force -n openshift -f {{BASEURL}}/quickstarts/spring-boot-camel-teiid-template.json\n\n   - name: Update spring-boot-camel-xml-template\n     command: oc replace --force -n openshift -f {{BASEURL}}/quickstarts/spring-boot-camel-xml-template.json\n\n   - name: Update spring-boot-cxf-jaxws-template\n     command: oc replace --force -n openshift -f {{BASEURL}}/quickstarts/spring-boot-cxf-jaxws-template.json\n\n   - name: Update spring-boot-cxf-jaxws-template\n     command: oc replace --force -n openshift -f {{BASEURL}}/quickstarts/spring-boot-cxf-jaxws-template.json\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "2cd33ec11319398c3fec19c2c4f1aa001a89a12a", "filename": "roles/1-prep/templates/iiab-rpi-root-resize.service", "repository": "iiab/iiab", "decoded_content": "[Unit]\nDescription=Root Filesystem Auto-Resizer\n\n[Service]\nEnvironment=TERM=linux\nType=oneshot\nExecStart=/usr/sbin/iiab-rpi-max-rootfs.sh\nStandardError=syslog\nRemainAfterExit=no\n\n[Install]\nWantedBy=multi-user.target\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "84494e2fc065457c5079e8b3e9d063adbd896e72", "filename": "roles/ovirt-collect-logs/vars/engine.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\novirt_collect_logs_tar_optional_params: \"--exclude '*/jboss_runtime/*' --exclude '*/branding/*'\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "8cc7aadd4c3a5b464d1eda1e97033aaeda0f74c6", "filename": "roles/update-host/tasks/update-host.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Update the host\"\n  package:\n    name: \"*\"\n    state: latest\n  register: host_updated\n  when: \n    - pkg_update|default(False) \n  become: True\n\n\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "43ab17888d32e500b4fe34e2b59ef5a9cf8f3de8", "filename": "tasks/create_repo_pypi_hosted_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_pypi_hosted\n    args: \"{{ _nexus_repos_pypi_defaults|combine(item) }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "28f33a828f5c293241bd55368eb0d199391d5a81", "filename": "roles/network/templates/gateway/iptables-config", "repository": "iiab/iiab", "decoded_content": "## XS Config override\n##\n\n# Load additional iptables modules (nat helpers)\n#   Default: -none-\n# Space separated list of nat helpers (e.g. 'nf_nat_ftp nf_nat_irc'), which\n# are loaded after the firewall rules are applied. Options for the helpers are\n# stored in /etc/modprobe.conf.\nIPTABLES_MODULES=\"nf_conntrack nf_conntrack_ipv4 nf_nat_ftp nf_conntrack_ftp nf_nat_irc nf_conntrack_irc nf_nat_sip nf_conntrack_sip nf_nat_h323 nf_conntrack_h323 nf_nat_pptp nf_conntrack_pptp\"\n\n# Unload modules on restart and stop\n#   Value: yes|no,  default: yes\n# This option has to be 'yes' to get to a sane state for a firewall\n# restart or stop. Only set to 'no' if there are problems unloading netfilter\n# modules.\nIPTABLES_MODULES_UNLOAD=\"yes\"\n\n# Save current firewall rules on stop.\n#   Value: yes|no,  default: no\n# Saves all firewall rules to /etc/sysconfig/iptables if firewall gets stopped\n# (e.g. on system shutdown).\nIPTABLES_SAVE_ON_STOP=\"no\"\n\n# Save current firewall rules on restart.\n#   Value: yes|no,  default: no\n# Saves all firewall rules to /etc/sysconfig/iptables if firewall gets\n# restarted.\nIPTABLES_SAVE_ON_RESTART=\"no\"\n\n# Save (and restore) rule and chain counter.\n#   Value: yes|no,  default: no\n# Save counters for rules and chains to /etc/sysconfig/iptables if\n# 'service iptables save' is called or on stop or restart if SAVE_ON_STOP or\n# SAVE_ON_RESTART is enabled.\nIPTABLES_SAVE_COUNTER=\"no\"\n\n# Numeric status output\n#   Value: yes|no,  default: yes\n# Print IP addresses and port numbers in numeric format in the status output.\nIPTABLES_STATUS_NUMERIC=\"yes\"\n\n# Verbose status output\n#   Value: yes|no,  default: yes\n# Print info about the number of packets and bytes plus the \"input-\" and\n# \"outputdevice\" in the status output.\nIPTABLES_STATUS_VERBOSE=\"no\"\n\n# Status output with numbered lines\n#   Value: yes|no,  default: yes\n# Print a counter/number for every rule in the status output.\nIPTABLES_STATUS_LINENUMBERS=\"yes\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "c7e9512d0efd2975b100ab8bc52e5cc518b0161e", "filename": "roles/ansible/tower/manage-projects/tests/inventory/group_vars/tower.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nansible_tower:\n  admin_password: \"admin01\"\n  projects:\n  - name: \"Project1\"\n    description: \"My Project\"\n    scm_type: \"git\"\n    scm_url: \"https://github.com/redhat-cop/infra-ansible.git\"\n    scm_branch: \"master\"\n    organization: \"Default\"\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "58274792833010015e5eebb4f63197bafb0bef08", "filename": "roles/wp-cli/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Install WP-CLI\n  get_url:\n    url: \"{{ wp_cli_phar_url }}\"\n    dest: \"{{ wp_cli_bin_path }}\"\n    force: true\n    mode: 0755\n\n- name: Retrieve WP-CLI tab completions\n  command: curl -4Ls {{ wp_cli_completion_url }} -o /tmp/wp-completion-{{ wp_cli_version }}.bash\n  args:\n    creates: /tmp/wp-completion-{{ wp_cli_version }}.bash\n    warn: false\n\n- name: Install WP-CLI tab completions\n  command: rsync -c --chmod=0644 --info=name /tmp/wp-completion-{{ wp_cli_version }}.bash {{ wp_cli_completion_path }}\n  args:\n    warn: false\n  register: wp_cli_completion\n  changed_when: wp_cli_completion.stdout == \"wp-completion-{{ wp_cli_version }}.bash\"\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "fcf185d52b3d890c0c95bff6597a12bec80000e4", "filename": "playbooks/roles/bb0-openstack/templates/env.yml.j2", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "ocp_version: 3.11\napi_dns: {{ openshift_master_cluster_public_hostname }}\napps_dns: {{ openshift_master_default_subdomain }}\nbastion: bastion\nlb: bastion\nmasters:\n{% for h in groups['masters'] %}\n- {{ h }}\n{% endfor %}\ninfranodes:\n{% for h in groups['infranodes'] %}\n- {{ h }}\n{% endfor %}\nnodes:\n{% for h in groups['nodes'] %}\n- {{ h }}\n{% endfor %}\ncns:\n{% for h in groups['cns'] %}\n- {{ h }}\n{% endfor %}\ncontainer_disk: {{ hostvars['master0'].container_storage_disk.device | replace(\"/dev/\",\"\") | default('PLEASE SET')  }}\nocs_disk: {{ hostvars['master0'].glusterfs_disk.device | replace(\"/dev/\",\"\") | default('PLEASE SET') }}\nssh_user: {{ ansible_user }}\ninstall_logging: n\ninstall_metrics: n\n# ntp_servers:\n# - ntp1.hetzner.de\n# - ntp2.hetzner.com\n# - ntp3.hetzner.net\nrhn_username: {{ lookup('env','STC_RHN_USERNAME') | default('PLEASE SET') }} \nsubscription_pool_id: {{ lookup('env','STC_SUBSCRIPTION_POOL_ID') | default('PLEASE SET') }}\nregistry_token_user: {{ lookup('env','STC_REGISTRY_TOKEN_USER') | default('PLEASE SET') }}\nregistry_token: {{ lookup('env','STC_REGISTRY_TOKEN') | default('PLEASE SET') }}\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "816106a98c14e528ec9433c8949aac0ee9fa93b2", "filename": "playbooks/roles/common/tasks/pkginstall.yml", "repository": "rocknsm/rock", "decoded_content": "---\n# pkginstall.yml - Install packages that we'd like to have\n- name: Convenience packages\n  yum: name={{ item }} state=installed\n  with_items:\n    - vim\n    - tmux\n    - git\n    - facter\n  tags:\n    - pkginstall\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "9d9ca4ccc6d3effbc9ccf8744dea3fdab9800f8b", "filename": "roles/rachel/templates/header.html", "repository": "iiab/iiab", "decoded_content": "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">\n<html>\n<head>\n<title> RACHEL - HOME</title>\n<meta http-equiv=\"content-type\" content=\"text/html; charset=UTF-8\">\n<link rel=\"stylesheet\" type=\"text/css\" href=\"/rachel/style.css\">\n</head>\n\n<body OnLoad=\"document.search.query.focus();\">\n<a id=\"rachel\">Rachel</a>\n\n<div id=\"haut\">\n\t\t<ul class=\"menuhaut\" >\n\t\t\t<li><a href=\"{{ rachel_url }}/index.html\">HOME</a></li>\n\t\t\t<li><a href=\"{{ rachel_url }}/about.html\">ABOUT</a></li>\n\t\t</ul>\n<div id=\"searchdiv\">\n\n<form action=\"/sphider/search.php\" method=\"get\" id=\"searchform\" name=\"search\">\n<input type=\"text\" name=\"query\" id=\"query\" size=\"55\" value=\"\" action=\"include/js_suggest/suggest.php\" columns=\"2\" autocomplete=\"off\" delay=\"1500\"> <input type=\"submit\" value=\"Search RACHEL\">\n<input type=\"hidden\" name=\"search\" value=\"1\">\n</form>\n\n</div>\n</div>\n\n\n\n<div id=\"content\">\n\n\n\n<div class=\"thumblist\">\n<a name=\"search\"></a>\n<h3>Search Results</h3> \n\n<ul>\n<li>\n\n\n<!-- END HEADER -->\n\n\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "36a968ff7377f794914e6debd617e30779dc0106", "filename": "roles/prometheus/tasks/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "# tasks for running prometheus\n- name: create prometheus config dir\n  file:\n    path: \"{{ prometheus_config_dir }}\"\n    state: directory\n    mode: 0755\n  sudo: yes\n  tags:\n    - prometheus\n\n- name: upload prometheus config file\n  template:\n    src: prometheus.yml.j2\n    dest: \"{{ prometheus_config_dir }}/prometheus.yml\"\n    mode: 0755\n  sudo: yes\n  tags:\n    - prometheus\n\n- name: run prometheus node exporter container\n  docker:\n    name: node-exporter\n    image: \"{{ prometheus_node_exporter_image }}\"\n    state: started\n    restart_policy: always\n    net: host\n    ports:\n    - \"{{ prometheus_node_exporter_port }}:{{ prometheus_node_exporter_port }}\"\n  environment: proxy_env\n  tags:\n    - prometheus\n\n- name: Set node-exporter consul service definition\n  sudo: yes\n  template:\n    src: node-exporter-consul.j2\n    dest: \"{{ prometheus_consul_dir }}/node-exporter.json\"\n  notify:\n    - restart consul\n  tags:\n    - prometheus\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "bff9f48559d06036e2ad5d5717820c3a734aa6df", "filename": "roles/manage-aws-infra/tasks/create-subnet.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "# Create the Subnets use by the OCP cluster\n---\n\n- name: \"Create Subnets for the VPC (HA Mode)\"\n  ec2_vpc_subnet:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    cidr: 172.31.{{ item }}.0/20\n    region: \"{{ aws_region }}\"\n    vpc_id: \"{{ aws_vpc_id }}\"\n    map_public: yes\n    az: \"{{ aws_region }}{{ aws_region_az | default('a') }}\"\n    state: \"present\"\n    tags:\n      env_id: \"{{ env_id }}\"\n  with_sequence: start=0 end=64 stride=16\n  when: ha_mode\n  register: new_subnets\n\n- name: \"Create Subnet for the VPC (Non HA Mode)\"\n  ec2_vpc_subnet:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    cidr: \"{{ vpc_subnet_cidr | default('172.31.0.0/20') }}\"\n    region: \"{{ aws_region }}\"\n    vpc_id: \"{{ aws_vpc_id }}\"\n    map_public: yes\n    az: \"{{ aws_region }}{{ aws_region_az | default('a') }}\"\n    state: \"present\"\n    tags:\n      env_id: \"{{ env_id }}\"\n  when: not ha_mode\n  register: new_subnets\n\n- name: \"Store away the (new) subnet id for use later\"\n  set_fact:\n    aws_vpc_subnet_id: \"{{ new_subnets.subnet.id }}\"\n\n- name: \"Create Gateway subnet route table for the VPC\"\n  ec2_vpc_route_table:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    vpc_id: \"{{ aws_vpc_id }}\"\n    region: \"{{ aws_region }}\"\n    tags:\n      Name: \"{{ env_id }}-route-table-gw\"\n      env_id: \"{{ env_id }}\"\n    subnets:\n      - \"{{ new_subnets.subnet.id }}\"\n    routes:\n      - dest: \"0.0.0.0/0\"\n        gateway_id: \"{{ aws_vpc_ig }}\"\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "0a28c4e791476c064047d2c7e2828f7df3dedcce", "filename": "roles/config-chrony/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Reload chrony\" \n  service:\n    name: 'chronyd'\n    state: restarted\n\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "fc4ff6a816d92e2ea25d130f3cd8ddcf5483a69d", "filename": "roles/marathon/tasks/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "- name: install wait script\n  when: marathon_enabled | bool\n  sudo: yes\n  template:\n    src: marathon-wait-for-listen.sh.j2\n    dest: /usr/local/bin/marathon-wait-for-listen.sh\n    mode: 0755\n  tags:\n    - marathon\n\n- name: create marathon artifact store directory\n  when: marathon_artifact_store_dir is defined and marathon_enabled | bool\n  file:\n    path: \"{{ marathon_artifact_store_dir }}\"\n    state: directory\n    mode: 0755\n  sudo: yes\n  tags:\n    - marathon\n\n- name: destroy old marathon container\n  when: marathon_rebuild_container\n  docker:\n    name: marathon\n    image: \"{{ marathon_image }}\"\n    state: absent\n\n- name: run marathon container\n  when: marathon_enabled | bool\n  docker:\n    name: marathon\n    image: \"{{ marathon_image }}\"\n    state: started\n    restart_policy: \"{{ marathon_restart_policy }}\"\n    ports:\n    - \"{{ marathon_port }}:{{ marathon_port }}\"\n    expose:\n    - \"{{ marathon_port }}\"\n    net: \"{{ marathon_net }}\"\n    command: \"{{ marathon_command }}\"\n    volumes:\n    - \"{{ marathon_artifact_store_dir }}:/store\"\n    memory_limit: \"{{ marathon_container_memory_limit }}\"\n    env:\n      JAVA_OPTS: \"{{ marathon_java_settings }}\"\n  notify:\n    - wait for marathon to listen\n\n- name: upload marathon template service\n  when: marathon_enabled | bool\n  template:\n    src: marathon.conf.j2\n    dest: /etc/init/marathon.conf\n    mode: 0755\n  sudo: yes\n  tags:\n    - marathon\n\n# Attach to the running container, or start it if needed\n# and forward all signals so that the process manager can detect\n# when a container stops and correctly restart it.\n- name: ensure marathon is running (and enable it at boot)\n  when: marathon_enabled | bool\n  sudo: yes\n  service:\n    name: marathon\n    state: started\n    enabled: yes\n  tags:\n    - marathon\n\n- name: Set marathon consul service definition\n  when: marathon_enabled | bool\n  sudo: yes\n  template:\n    src: marathon-consul.j2\n    dest: \"{{ marathon_consul_dir }}/marathon.json\"\n  notify:\n    - restart consul\n\n# tasks for stoping docker marathon\n- name: stop marathon container\n  when: not marathon_enabled | bool\n  service:\n    name: marathon\n    state: stopped\n    enabled: no\n  tags:\n    - marathon\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "58cd496fa3e4d1043b19675982accc813ac753d8", "filename": "roles/network/templates/gateway/iptables", "repository": "iiab/iiab", "decoded_content": "#!/bin/bash\n/etc/init.d/netfilter-persistent reload\n"}, {"commit_sha": "49010188a985bfe713552eb8980cfa0d7a888daf", "sha": "b5b089d15103ab37a071979d152d183c58c5e515", "filename": "roles/README.md", "repository": "redhat-cop/casl-ansible", "decoded_content": "== The rhc-ose roles implementations\n\nBelow are the variables[Required and Optional] for each of the defined roles. They must be defined in the inventory files when running the related ansible playbook.\n\n##Roles:\n\n###dns\n\n  - Required\n    -\n    -\n    -\n  - Optional\n    -\n    -\n    -\n\n\n###openshift-provision\n\n  - Required\n    -\n    -\n    -\n  - Optional\n    -\n    -\n    -\n\n###openstack-create\n\n  - Required\n    -\n    -\n    -\n  - Optional\n    -\n    -\n    -\n\n###registry\n\n  - Required\n    -\n    -\n    -\n  - Optional\n    -\n    -\n    -\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "e0a173462fdced388f07754319f21ad3120e63d0", "filename": "roles/ovirt-engine-cleanup/defaults/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\novirt_engine_dwh: True\novirt_engine_type: 'ovirt-engine'\novirt_engine_version: '4.0'\n\novirt_engine_db_host: 'localhost'\novirt_engine_db_port: 5432\novirt_engine_db_name: 'engine'\novirt_engine_db_user: 'engine'\novirt_engine_db_password: 'AqbXg4dpkbcVRZwPbY8WOR'\n\novirt_engine_dwh_db_host: 'localhost'\novirt_engine_dwh_db_port: 5432\novirt_engine_dwh_db_name: 'ovirt_engine_history'\novirt_engine_dwh_db_user: 'ovirt_engine_history'\novirt_engine_dwh_db_password: '37xmBKECANQGm0z3SfylMp'"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "a51f190ffb8f0d646319e0a5b7448172829dfb52", "filename": "roles/network/tasks/dansguardian.yml", "repository": "iiab/iiab", "decoded_content": "- name: Install dansguardian packages\n  package: name={{ item }}\n           state=present\n  with_items:\n    - dansguardian\n  tags:\n    - download\n\n- name: Copy dansguardian config file\n  template: src=squid/dansguardian.conf.j2\n            dest=/etc/dansguardian/dansguardian.conf\n            owner=dansguardian\n            group=dansguardian\n            mode=0640\n  when: ansible_distribution == \"Fedora\"\n\n- name: Copy dansguardian config file\n  template: src=squid/dansguardian.conf.debian.j2\n            dest=/etc/dansguardian/dansguardian.conf\n            owner=dansguardian\n            group=dansguardian\n            mode=0640\n  when: is_debuntu\n\n- name: Copy dansguardian config file for CentOS\n  template: src=squid/dansguardian.conf.centos.j2\n            dest=/etc/dansguardian/dansguardian.conf\n            owner=dansguardian\n            group=vscan\n            mode=0640\n  when: ansible_distribution == \"CentOS\"\n\n- name: Create dansguardian log directory\n  file: path=/var/log/dansguardian\n        owner=dansguardian\n        group=dansguardian\n        mode=0750\n        state=directory\n  when: ansible_distribution != \"CentOS\"\n\n- name: Create dansguardian log directory for CentOS\n  file: path=/var/log/dansguardian\n        owner=dansguardian\n        group=vscan\n        mode=0750\n        state=directory\n  when: ansible_distribution == \"CentOS\"\n"}, {"commit_sha": "3c4d272a77f8aaeb300c8b841bb7e6d8dbd76c1f", "sha": "ef359a0ad31046500f6f863e29eb2923e3e0f256", "filename": "tasks/darwin/macosx.yml", "repository": "ansiblebit/oracle-java", "decoded_content": "---\n# file: oracle-java/tasks/darwin/macosx.yml\n#\n# Task file to install Oracle Java Development Kit in a system with a OSX based Darwin distribution.\n#\n\n- name: download DMG file\n  shell:\n    \"curl -L  -H 'Cookie:oraclelicense=accept-securebackup-cookie' -o {{ oracle_java_dir_source }}/{{ oracle_java_dmg_filename }} {{ oracle_java_dmg_url }}\"\n  when: not oracle_java_task_dmg_check|skipped and not oracle_java_task_dmg_check.stat.exists\n  args:\n    creates: \"{{ oracle_java_dir_source }}/{{ oracle_java_dmg_filename }}\"\n  tags:\n    - installation\n\n- name: mount DMG image\n  shell: echo TODO\n  tags:\n    - installation\n\n- name: install JDK\n  shell: echo TODO\n  tags:\n    - installation\n\n- name: unmount DMG image\n  shell: echo TODO\n  tags:\n    - installation\n\n- name: set Java version as default\n  shell: echo TODO\n  when: oracle_java_set_as_default\n  register: oracle_java_task_set_default\n  sudo: yes\n\n- name: in case there were changes, check host environment again\n  include: ../check_environment.yml\n\n"}, {"commit_sha": "ccab58ae5d697bb64abd86558f79c34161d2fb00", "sha": "f6415cffff925b9f267265eb455fc21477b80faa", "filename": "tasks/main.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n\n- name: Check requirements and deprecated features/vars\n  import_tasks: \"requirements_and_deprecated.yml\"\n\n- name: Include OS specific variables.\n  include_vars: \"configure-{{ ansible_os_family }}.yml\"\n\n- name: Include OS specific selinux libs and utils if needed\n  include_tasks: \"selinux-{{ ansible_os_family }}.yml\"\n  when: ansible_selinux.status is defined and ansible_selinux.status == \"enabled\"\n\n- name: Check if SystemD service is installed\n  stat:\n    path: /etc/systemd/system/nexus.service\n  register: nexus_systemd_service_file\n\n- name: Check if sysv service is installed\n  stat:\n    path: /etc/init.d/nexus\n  register: nexus_sysv_service_file\n\n- include_tasks: nexus_purge.yml\n  when: nexus_purge | default(false) | bool\n\n- import_tasks: nexus_install.yml\n\n- include_tasks: httpd_reverse_proxy_config.yml\n  when: httpd_setup_enable | bool\n\n- name: Configure nexus http proxy\n  include_tasks: call_script.yml\n  vars:\n    script_name: setup_http_proxy\n    args:\n      with_http_proxy: \"{{ nexus_with_http_proxy }}\"\n      http_proxy_host: \"{{ nexus_http_proxy_host }}\"\n      http_proxy_port: \"{{ nexus_http_proxy_port }}\"\n      http_proxy_username: \"{{ nexus_http_proxy_username }}\"\n      http_proxy_password: \"{{ nexus_http_proxy_password }}\"\n      with_https_proxy: \"{{ nexus_with_https_proxy }}\"\n      https_proxy_host: \"{{ nexus_https_proxy_host }}\"\n      https_proxy_port: \"{{ nexus_https_proxy_port }}\"\n      https_proxy_username: \"{{ nexus_https_proxy_username }}\"\n      https_proxy_password: \"{{ nexus_https_proxy_password }}\"\n      proxy_exclude_hosts: \"{{ nexus_proxy_exclude_hosts }}\"\n  when: nexus_with_http_proxy or nexus_with_https_proxy\n\n- name: Deleting default repositories\n  include_tasks: delete_repo_each.yml\n  with_items:\n    - maven-central\n    - maven-public\n    - maven-releases\n    - maven-snapshots\n    - nuget-group\n    - nuget-hosted\n    - nuget.org-proxy\n  when: (nexus_data_dir_contents.stdout | length == 0) and nexus_delete_default_repos\n\n- name: Deleting default blobstore\n  include_tasks: delete_blobstore_each.yml\n  with_items:\n    - name: default\n    - name: \"{{ nexus_blob_names.raw.blob }}\"\n    - name: \"{{ nexus_blob_names.pypi.blob }}\"\n    - name: \"{{ nexus_blob_names.docker.blob }}\"\n    - name: \"{{ nexus_blob_names.ruby.blob }}\"\n    - name: \"{{ nexus_blob_names.bower.blob }}\"\n    - name: \"{{ nexus_blob_names.npm.blob }}\"\n    - name: \"{{ nexus_blob_names.nuget.blob }}\"\n    - name: \"{{ nexus_blob_names.mvn.blob }}\"\n    - name: \"{{ nexus_blob_names.gitlfs.blob }}\"\n    - name: \"{{ nexus_blob_names.yum.blob }}\"\n    - name: \"{{ nexus_blob_names.apt.blob }}\"\n  when: (nexus_data_dir_contents.stdout | length == 0) and nexus_delete_default_blobstore\n\n- block:\n    - include_tasks: setup_ldap_each.yml\n      with_items: \"{{ ldap_connections }}\"\n\n    - include_tasks: create_content_selector_each.yml\n      with_items: \"{{ nexus_content_selectors }}\"\n\n    - name: apply defaults to privileges\n      # @todo: fix with easier syntax once the flip filter is released\n      # See more comments on this issue in process_repos_list.yml\n      set_fact:\n        nexus_privileges: >-\n          {%- set result=[] -%}\n          {%- for privilege in nexus_privileges -%}\n            {{ result.append(_nexus_privilege_defaults | combine(privilege)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: \"Digest splited blob list var\"\n      include_vars: blob_vars.yml\n      when: nexus_blob_split | bool\n\n    - name: Create/Check blobstores\n      when: nexus_restore_point is undefined\n      block:\n\n        - name: Create directories for blob stores.\n          file:\n            path: \"{{ item['path'] }}\"\n            owner: \"{{ nexus_os_user }}\"\n            group: \"{{ nexus_os_group }}\"\n            state: directory\n            recurse: true\n          when: item.path is defined\n          loop: \"{{ nexus_blobstores }}\"\n\n        - name: Create/Check blobstores\n          include_tasks: call_script.yml\n          vars:\n            script_name: create_blobstores_from_list\n            args: \"{{ nexus_blobstores }}\"\n          when: nexus_blobstores | length > 0\n\n\n  when: nexus_run_provisionning | default(true) | bool\n\n- name: \"Restore nexus backup\"\n  include_tasks: nexus-restore.yml\n  when: nexus_restore_point is defined\n\n- block:\n    - name: Create/check cleanup policies\n      include_tasks: call_script.yml\n      vars:\n        script_name: create_cleanup_policies_from_list\n        args: \"{{ nexus_repos_cleanup_policies }}\"\n      when: nexus_repos_cleanup_policies | length > 0\n\n    - name: Apply defaults to repositories configurations and process a single list\n      include_tasks: process_repos_list.yml\n\n    - name: Create configured repositories\n      include_tasks: call_script.yml\n      vars:\n        script_name: create_repos_from_list\n        args: \"{{ _nexus_repos_global_list }}\"\n\n    - name: Create/check privileges\n      include_tasks: call_script.yml\n      vars:\n        script_name: setup_privileges_from_list\n        args: \"{{ nexus_privileges }}\"\n      when: nexus_privileges | length > 0\n\n    - name: Create/check roles\n      include_tasks: call_script.yml\n      vars:\n        script_name: setup_roles_from_list\n        args: \"{{ nexus_roles }}\"\n      when: nexus_roles | length > 0\n\n    - name: Create/check local users\n      include_tasks: call_script.yml\n      vars:\n        script_name: setup_users_from_list\n        args: \"{{ nexus_local_users }}\"\n      when: nexus_local_users | length > 0\n\n    - name: Create/check ldap users\n      include_tasks: call_script.yml\n      vars:\n        script_name: setup_ldap_users_from_list\n        args: \"{{ nexus_ldap_users }}\"\n      when: nexus_ldap_users | length > 0\n\n  when: nexus_run_provisionning | default(true) | bool\n\n- include_tasks: call_script.yml\n  vars:\n    script_name: setup_anonymous_access\n    args:\n      anonymous_access: \"{{ nexus_anonymous_access }}\"\n\n- include_tasks: call_script.yml\n  vars:\n    script_name: setup_base_url\n    args:\n      base_url: \"{{ nexus_public_scheme }}://{{ nexus_public_hostname }}/\"\n\n- include_tasks: call_script.yml\n  vars:\n    script_name: setup_realms\n    args:\n      nuget_api_key_realm: \"{{ nexus_nuget_api_key_realm }}\"\n      npm_bearer_token_realm: \"{{ nexus_npm_bearer_token_realm }}\"\n      rut_auth_realm: \"{{ nexus_rut_auth_realm }}\"\n      ldap_realm: \"{{ nexus_ldap_realm }}\"\n      docker_bearer_token_realm: \"{{ nexus_docker_bearer_token_realm }}\"\n\n- name: Configure RUT Auth header\n  include_tasks: call_script.yml\n  vars:\n    script_name: setup_capability\n    args:\n      capability_typeId: \"rutauth\"\n      capability_enabled: true\n      capability_properties:\n        httpHeader: \"{{ nexus_rut_auth_header }}\"\n  when: nexus_rut_auth_header is defined\n\n- include_tasks: call_script.yml\n  vars:\n    script_name: setup_email\n    args:\n      email_server_enabled: \"{{ nexus_email_server_enabled }}\"\n      email_server_host: \"{{ nexus_email_server_host }}\"\n      email_server_port: \"{{ nexus_email_server_port }}\"\n      email_server_username: \"{{ nexus_email_server_username }}\"\n      email_server_password: \"{{ nexus_email_server_password }}\"\n      email_from_address: \"{{ nexus_email_from_address }}\"\n      email_subject_prefix: \"{{ nexus_email_subject_prefix }}\"\n      email_tls_enabled: \"{{ nexus_email_tls_enabled }}\"\n      email_tls_required: \"{{ nexus_email_tls_required }}\"\n      email_ssl_on_connect_enabled: \"{{ nexus_email_ssl_on_connect_enabled }}\"\n      email_ssl_check_server_identity_enabled: \"{{ nexus_email_ssl_check_server_identity_enabled }}\"\n      email_trust_store_enabled: \"{{ nexus_email_trust_store_enabled }}\"\n\n- name: Configure branding capability\n  include_tasks: call_script.yml\n  vars:\n    script_name: setup_capability\n    args:\n      capability_typeId: \"rapture.branding\"\n      capability_enabled: \"{{ (nexus_branding_footer | length > 0) and (nexus_branding_header | length > 0) }}\"\n      capability_properties:\n        footerHtml: \"{{ nexus_branding_footer }}\"\n        headerHtml: \"{{ nexus_branding_header }}\"\n        footerEnabled: \"{{ nexus_branding_footer | length > 0 }}\"\n        headerEnabled: \"{{ nexus_branding_header | length > 0 }}\"\n\n- name: Configure audit capability\n  include_tasks: call_script.yml\n  vars:\n    script_name: setup_capability\n    args:\n      capability_typeId: \"audit\"\n      capability_enabled: \"{{ nexus_audit_enabled | bool }}\"\n      capability_properties: {}\n\n- include_tasks: create_task_each.yml\n  with_items: \"{{ nexus_scheduled_tasks }}\"\n  when: nexus_run_provisionning | default(true) | bool\n\n- name: Configure nexus backup task\n  include_tasks: call_script.yml\n  vars:\n    script_name: create_task\n    args:\n      name: db and blobstores backup\n      typeId: script\n      cron: \"{{ nexus_backup_cron }}\"\n      taskProperties:\n        language: groovy\n        source: \"{{ lookup('template', './templates/backup.groovy.j2') }}\"\n  when: nexus_backup_configure | bool\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "366e5a9e8f533b392652fda2e0adce0cd4701b86", "filename": "roles/3-base-server/README.rst", "repository": "iiab/iiab", "decoded_content": "==================\nBase Server README\n==================\n\nThis role is a place to aggregate roles that are required to create a basic web server.\nThe functionality here is not packages that are not directly consumed by users, which are in common,\nnor specific applications, such as those found in the apps and tools roles.\n\nThe difference between this aggregate and server-options is that the roles here are required.\n\nEventually a graphical configuration console will be added here.\n\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "9bd6b2dbb7b208550327739f378f3ee4981f8301", "filename": "playbooks/roles/bb0-openstack/tasks/provisioning-dns-cloudflare.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "---\n- name: Validate CloudFlare env variables\n  assert:\n    that: \n      - lookup('env', item ) is defined\n    msg: \"CloudFlare env variable {{ item }} is NOT defined!\"\n  with_items:\n    - CLOUDFLARE_ACCOUNT_EMAIL \n    - CLOUDFLARE_ACCOUNT_API_TOKEN \n    - CLOUDFLARE_ZONE \n    - CLOUDFLARE_NAME_POSTFIX \n  when: ( instance_data.openstack.public_v4 != \"\" and inventory_hostname == \"bastion\" )\n\n- name: Set cloudflare vars\n  set_fact:\n    cloudflare_account_email: \"{{ lookup('env','CLOUDFLARE_ACCOUNT_EMAIL') }}\"\n    cloudflare_account_api_token: \"{{ lookup('env','CLOUDFLARE_ACCOUNT_API_TOKEN') }}\"\n    cloudflare_zone: \"{{ lookup('env','CLOUDFLARE_ZONE') }}\"\n    cloudflare_name_postfix: \"{{ lookup('env','CLOUDFLARE_NAME_POSTFIX') }}\"\n  when: ( instance_data.openstack.public_v4 != \"\" and inventory_hostname == \"bastion\" )\n\n- name: Create DNS record bastion{{cloudflare_name_postfix}} => {{ instance_data.openstack.public_v4 }}\n  cloudflare_dns:\n    zone: \"{{ cloudflare_zone }}\"\n    record: \"bastion{{ cloudflare_name_postfix }}\"\n    type: A\n    value: \"{{ instance_data.openstack.public_v4 }}\"\n    account_email: \"{{ cloudflare_account_email }}\"\n    account_api_token: \"{{ cloudflare_account_api_token }}\"\n  when: ( instance_data.openstack.public_v4 != \"\" and inventory_hostname == \"bastion\" )\n\n- name: Create DNS record  *.apps{{cloudflare_name_postfix}} => {{ instance_data.openstack.public_v4 }}\n  cloudflare_dns:\n    zone: \"{{ cloudflare_zone }}\"\n    record: \"*.apps{{ cloudflare_name_postfix }}\"\n    type: A\n    value: \"{{ instance_data.openstack.public_v4 }}\"\n    account_email: \"{{ cloudflare_account_email }}\"\n    account_api_token: \"{{ cloudflare_account_api_token }}\"\n  when: ( instance_data.openstack.public_v4 != \"\" and inventory_hostname == \"bastion\" )\n\n- name: Create DNS record api{{cloudflare_name_postfix}} => {{ instance_data.openstack.public_v4 }}\n  cloudflare_dns:\n    zone: \"{{ cloudflare_zone }}\"\n    record: \"api{{ cloudflare_name_postfix }}\"\n    type: A\n    value: \"{{ instance_data.openstack.public_v4 }}\"\n    account_email: \"{{ cloudflare_account_email }}\"\n    account_api_token: \"{{ cloudflare_account_api_token }}\"\n  when: ( instance_data.openstack.public_v4 != \"\" and inventory_hostname == \"bastion\" )\n\n- name: Set public name\n  set_fact:\n    openshift_master_cluster_public_hostname: \"api{{ cloudflare_name_postfix }}.{{ cloudflare_zone }}\"\n    openshift_master_default_subdomain: \"apps{{ cloudflare_name_postfix }}.{{ cloudflare_zone }}\"\n    bastion_public_hostname: \"bastion{{ cloudflare_name_postfix }}.{{ cloudflare_zone }}\"\n  when: ( instance_data.openstack.public_v4 != \"\" and inventory_hostname == \"bastion\" )\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "bf49cc50eb585ca911d077bf17f8d5227e14ae21", "filename": "playbooks/roles/common/tasks/epel.yml", "repository": "rocknsm/rock", "decoded_content": "---\n# epel.yml - Install EPEL repo\n- name: Install EPEL\n  yum: name=epel-release state=installed\n  tags:\n    - epel\n    - pkginstall\n    - online_repos\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "35c727eeca7606195c62106b864875b5cf2e9d37", "filename": "tasks/section_08_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n# Change order or the default auditd.conf file will not be created\n  - name: 8.1.2 Install and Enable auditd Service (Scored)\n    apt: name=auditd state=present\n    tags:\n      - section8\n      - section8.1\n      - section8.1.2\n      - section8.1.2\n\n  - name: Check if the file auditd.conf exists (Not Scored)\n    stat: >\n        path=/etc/audit/auditd.conf\n    register: auditd_file\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n\n  - name: Create the audit directory if it does not exists (Not Scored)\n    file: >\n        path=/etc/audit/\n        state=directory\n    when: not auditd_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n\n  - name: 8.1.1-3 Configure Data Retention (Not Scored)\n    lineinfile: >\n        dest=/etc/audit/auditd.conf\n        regexp=\"{{ item.rxp }}\"\n        line=\"{{ item.line }}\"\n        state=present\n        create=yes\n    with_items:\n      - { rxp: '^max_log_file ', line: 'max_log_file = {{ max_log_file_auditd }}' }\n      - { rxp: '^space_left_action', line: 'space_left_action = email' }\n      - { rxp: '^action_mail_acct', line: 'action_mail_acct = root' }\n      - { rxp: '^admin_space_left_action', line: 'admin_space_left_action = halt' }\n      - { rxp: '^max_log_file_action', line: 'max_log_file_action = keep_logs' }\n    notify: restart auditd\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n      - section8.1.1.2\n      - section8.1.1.3\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    stat: path=/etc/default/grub\n    register: grubcfg_file\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    file: >\n        path=/etc/default/grub\n        state=touch\n    when: not grubcfg_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    lineinfile: >\n        dest=/etc/default/grub\n        line='GRUB_CMDLINE_LINUX=\"audit=1\"'\n    when: not grubcfg_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.4 Record Events That Modify Date and Time Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a always,exit -F arch=b64 -S adjtimex -S settimeofday -k time-change'\n      - '-a always,exit -F arch=b32 -S adjtimex -S settimeofday -S stime -k time-change'\n      - '-a always,exit -F arch=b64 -S clock_settime -k time-change'\n      - '-a always,exit -F arch=b32 -S clock_settime -k time-change'\n      - '-w /etc/localtime -p wa -k time-change'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"64\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.4\n\n  - name: 8.1.4 Record Events That Modify Date and Time Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a always,exit -F arch=b32 -S adjtimex -S settimeofday -S stime -k time-change'\n      - '-a always,exit -F arch=b32 -S clock_settime -k time-change'\n      - '-w /etc/localtime -p wa -k time-change'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"32\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.4\n\n  - name: 8.1.5,7,8,9,15,16,17 Record Events That Modify User/Group Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-w /etc/group -p wa -k identity'\n      - '-w /etc/passwd -p wa -k identity'\n      - '-w /etc/gshadow -p wa -k identity'\n      - '-w /etc/shadow -p wa -k identity'\n      - '-w /etc/security/opasswd -p wa -k identity'\n      - '-w /var/log/faillog -p wa -k logins'\n      - '-w /var/log/lastlog -p wa -k logins'\n      - '-w /var/log/tallylog -p wa -k logins'\n      - '-w /var/run/utmp -p wa -k session'\n      - '-w /var/log/wtmp -p wa -k session'\n      - '-w /var/log/btmp -p wa -k session'\n      - '-w /etc/selinux/ -p wa -k MAC-policy'\n      - '-w /etc/sudoers -p wa -k scope'\n      - '-w /var/log/sudo.log -p wa -k actions'\n      - '-w /sbin/insmod -p x -k modules'\n      - '-w /sbin/rmmod -px -k modules'\n      - '-w /sbin/modprobe -p x -k modules'\n    notify: restart auditd\n    tags:\n      - section8\n      - section8.1\n      - section8.1.5\n      - section8.1.7\n      - section8.1.8\n      - section8.1.9\n      - section8.1.15\n      - section8.1.16\n      - section8.1.17\n\n  - name: 8.1.6,10,11,13,14,17 Record Events That Modify the System's Network Environment (64b) (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a exit,always -F arch=b64 -S sethostname -S setdomainname -k system-locale'\n      - '-a exit,always -F arch=b32 -S sethostname -S setdomainname -k system-locale'\n      - '-w /etc/issue -p wa -k system-locale'\n      - '-w /etc/issue.net -p wa -k system-locale'\n      - '-w /etc/hosts -p wa -k system-locale'\n      - '-w /etc/network -p wa -k system-locale'\n      - '-a always,exit -F arch=b64 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b64 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b64 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b32 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b64 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b32 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b64 -S init_module -S delete_module -k modules'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"64\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.6\n      - section8.1.10\n      - section8.1.11\n      - section8.1.13\n      - section8.1.14\n      - section8.1.17\n\n  - name: 8.1.6,10,11,13,14,17 Record Events That Modify the System's Network Environment (32b) (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a exit,always -F arch=b32 -S sethostname -S setdomainname -k system-locale'\n      - '-w /etc/issue -p wa -k system-locale'\n      - '-w /etc/issue.net -p wa -k system-locale'\n      - '-w /etc/hosts -p wa -k system-locale'\n      - '-w /etc/network -p wa -k system-locale'\n      - '-a always,exit -F arch=b32 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b32 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b32 -S init_module -S delete_module -k modules'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"32\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.6\n      - section8.1.10\n      - section8.1.11\n      - section8.1.13\n      - section8.1.14\n      - section8.1.17\n\n  - name: 8.3.1 Install AIDE (Scored)\n    apt: name=aide state=present\n    register: aide_installed\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (init) (Scored)\n    command: aideinit\n    when: aide_installed.changed == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (Scored)\n    stat: path=/var/lib/aide/aide.db.new\n    register: aide_db_path\n    when:\n      - aide_installed.changed == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (copy db) (Scored)\n    command: mv /var/lib/aide/aide.db.new /var/lib/aide/aide.db\n    when:\n      - aide_installed.changed == True\n      - aide_db_path.stat.exists == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.2 Implement Periodic Execution of File Integrity (Scored)\n    cron: name=\"Check files integrity\" minute=\"0\" hour=\"5\" job=\"/usr/sbin/aide --check\"\n    tags:\n      - section8\n      - section8.3\n      - section8.3.2\n\n  # We have to run the check after AIDE installation as postfix create new matched binaries\n  - name: 8.1.12 Collect Use of Privileged Commands (Scored)\n    shell: find / -xdev \\( -perm -4000 -o -perm -2000 \\) -type f | awk '{print \"-a always,exit -F path=\" $1 \" -F perm=x -F auid>=500 -F auid!=4294967295 -k privileged\" }'\n    register: audit_lines_for_find\n    changed_when: False\n    tags:\n      - section8\n      - section8.1\n      - section8.1.12\n\n  - name: 8.1.12 Collect Use of Privileged Commands (infos) (Scored)\n    lineinfile: >\n        dest=/etc/audit/audit.rules\n        line='{{ item }}'\n        state=present\n        create=yes\n    with_items: audit_lines_for_find.stdout_lines\n    tags:\n      - section8\n      - section8.1\n      - section8.1.12\n\n  - name: 8.1.18 Make the Audit Configuration Immutable (Scored)\n    lineinfile: >\n        dest='/etc/audit/audit.rules'\n        line='-e 2'\n        insertafter=EOF\n        state=present\n        create=yes\n    tags:\n      - section8\n      - section8.1\n      - section8.1.18\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "76f5a05ae02afd2859682adbd8f644ac94300a0f", "filename": "roles/vpn/tasks/client_configs.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- name: Register p12 PayloadContent\n  local_action: >\n    shell cat private/{{ item }}.p12 | base64\n  register:  PayloadContent\n  become: no\n  args:\n    chdir: \"configs/{{ IP_subject_alt_name }}/pki/\"\n  with_items: \"{{ users }}\"\n\n- name: Set facts for mobileconfigs\n  set_fact:\n    proxy_enabled: false\n    PayloadContentCA: \"{{ lookup('file' , 'configs/{{ IP_subject_alt_name }}/pki/cacert.pem')|b64encode }}\"\n\n- name: Build the mobileconfigs\n  local_action:\n    module: template\n    src: mobileconfig.j2\n    dest: configs/{{ IP_subject_alt_name }}/{{ item.0 }}.mobileconfig\n    mode: 0600\n  become: no\n  with_together:\n    - \"{{ users }}\"\n    - \"{{ PayloadContent.results }}\"\n  no_log: True\n\n- name: Build the strongswan app android config\n  local_action:\n    module: template\n    src: sswan.j2\n    dest: configs/{{ IP_subject_alt_name }}/{{ item.0 }}.sswan\n    mode: 0600\n  become: no\n  with_together:\n    - \"{{ users }}\"\n    - \"{{ PayloadContent.results }}\"\n  no_log: True\n\n- name: Build the client ipsec config file\n  local_action:\n    module: template\n    src: client_ipsec.conf.j2\n    dest: configs/{{ IP_subject_alt_name }}/ipsec_{{ item }}.conf\n    mode: 0600\n  become: no\n  with_items:\n    - \"{{ users }}\"\n\n- name: Build the client ipsec secret file\n  local_action:\n    module: template\n    src: client_ipsec.secrets.j2\n    dest: configs/{{ IP_subject_alt_name }}/ipsec_{{ item }}.secrets\n    mode: 0600\n  become: no\n  with_items:\n    - \"{{ users }}\"\n\n- name: Build the windows client powershell script\n  local_action:\n    module: template\n    src: client_windows.ps1.j2\n    dest: configs/{{ IP_subject_alt_name }}/windows_{{ item }}.ps1\n    mode: 0600\n  become: no\n  when: Win10_Enabled is defined and Win10_Enabled == \"Y\"\n  with_items: \"{{ users }}\"\n\n- name: Restrict permissions for the local private directories\n  local_action:\n    module: file\n    path: \"{{ item }}\"\n    state: directory\n    mode: 0700\n  become: no\n  with_items:\n    - configs/{{ IP_subject_alt_name }}\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "a2699e7631d169705685a19b64af668d4567a39e", "filename": "playbooks/roles/bb0-openstack/tasks/create-inventory-mini.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "---\n\n- set_fact:\n    int_iaas_image: \"{{ lookup('env','STC_IAAS_IMAGE') | default('rhel-server-7.6-x86_64-kvm',true) }}\"\n    int_iaas_machine_size: \"{{ lookup('env','STC_IAAS_MACHINE_SIZE') | default('m1.xlarge',true) }}\"\n    int_iaas_container_storage_disk: \"{{ lookup('env','STC_IAAS_CONTAINER_STORAGE_DISK') | default('15',true) }}\"\n    int_iaas_glusterfs_disk: \"{{ lookup('env','STC_IAAS_GLUSTERFS_DISK') | default('100',true) }}\"\n    int_iaas_internal_network: \"{{ lookup('env','STC_IAAS_INTERNAL_NETWORK') | default('admin',true) }}\"\n    int_dns_provider: \"{{ lookup('env','STC_DNS_PROVIDER') | default('nip.io',true) }}\"\n\n- name: Add masters\n  add_host:\n    name: \"master0\"\n    groups: \n    - openstack_instances\n    - masters\n    - cns\n    os_security_groups: \n    - default\n    - ssh_only\n    - ose3_master\n    - ose3_sdn\n    iaas_machine_size: \"{{ int_iaas_machine_size }}\"\n\n    iaas_image: \"{{ int_iaas_image }}\"\n    iaas_container_storage_disk: \"{{ int_iaas_container_storage_disk }}\"\n    iaas_glusterfs_disk: \"{{ int_iaas_glusterfs_disk }}\"\n    iaas_internal_network: \"{{ int_iaas_internal_network }}\"\n    dns_provider: \"{{ int_dns_provider }}\"\n\n    ansible_ssh_private_key_file: \"/work/q-root-id_rsa\"\n    ansible_user: \"cloud-user\"\n\n\n- name: Add infras\n  add_host:\n    name: \"infra0\"\n    groups: \n    - openstack_instances\n    - infranodes\n    - cns\n    os_security_groups: \n    - default\n    - ssh_only\n    - ose3_node\n    - ose3_sdn\n    iaas_machine_size: \"{{ int_iaas_machine_size }}\"\n\n    iaas_image: \"{{ int_iaas_image }}\"\n    iaas_container_storage_disk: \"{{ int_iaas_container_storage_disk }}\"\n    iaas_glusterfs_disk: \"{{ int_iaas_glusterfs_disk }}\"\n    iaas_internal_network: \"{{ int_iaas_internal_network }}\"\n    dns_provider: \"{{ int_dns_provider }}\"\n\n- name: Add nodes\n  add_host:\n    name: \"node0\"\n    groups: \n    - openstack_instances\n    - nodes\n    - cns\n    os_security_groups: \n    - default\n    - ssh_only\n    - ose3_node\n    - ose3_sdn\n    iaas_machine_size: \"{{ int_iaas_machine_size }}\"\n\n    iaas_image: \"{{ int_iaas_image }}\"\n    iaas_container_storage_disk: \"{{ int_iaas_container_storage_disk }}\"\n    iaas_glusterfs_disk: \"{{ int_iaas_glusterfs_disk }}\"\n    iaas_internal_network: \"{{ int_iaas_internal_network }}\"\n    dns_provider: \"{{ int_dns_provider }}\"\n\n# Import that bastion is the last host, because of creating the env.yml\n- name: bastion\n  add_host:\n    name: \"bastion\"\n    groups: openstack_instances\n    iaas_public_ip: true\n    iaas_container_storage_disk: 0 \n    iaas_glusterfs_disk: 0\n    os_security_groups: \n    - default\n    - ssh_only\n    - ose3_router\n    iaas_machine_size: \"m1.small\"\n    iaas_image: \"{{ int_iaas_image }}\"\n    dns_provider: \"{{ int_dns_provider }}\"\n    iaas_internal_network: \"{{ int_iaas_internal_network }}\"\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "638e98f35a5304e0b5c49a51b5d1257ca35990e3", "filename": "tasks/create_repo_nuget_hosted_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_nuget_hosted\n    args: \"{{ _nexus_repos_nuget_defaults|combine(item) }}\""}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "ce0486feb1b5792f8a702c69e59efeda3dad1f43", "filename": "roles/owncloud/tasks/F18.yml", "repository": "iiab/iiab", "decoded_content": "- name: Remove /etc/owncloud to avoid confusion as we use the config in {{ owncloud_prefix }}/owncloud/config/\n  file: path=/etc/owncloud\n        state=absent\n\n# but we use the tar file to get the latest version; really only benefits the xo4 on fedora 18\n- name: Get the owncloud software\n  get_url: url=\"{{ owncloud_dl_url }}\"/{{ owncloud_src_file }}  dest={{ downloads_dir }}/{{ owncloud_src_file }}\n  when: internet_available \n\n- name: Copy it to permanent location /opt\n  unarchive: src={{ downloads_dir }}/{{ owncloud_src_file }}  dest=/opt/\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "9b34d7c60b81ee2e0ec6b4b7c8171c9a969acea8", "filename": "roles/local/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: Add the instance to an inventory group\n  add_host:\n    name: \"{{ server_ip }}\"\n    groups: vpn-host\n    ansible_ssh_user: \"{{ server_user }}\"\n    ansible_python_interpreter: \"/usr/bin/python2.7\"\n    cloud_provider: local\n  when: server_ip != \"localhost\"\n\n- name: Add the instance to an inventory group\n  add_host:\n    name: \"{{ server_ip }}\"\n    groups: vpn-host\n    ansible_ssh_user: \"{{ server_user }}\"\n    ansible_python_interpreter: \"/usr/bin/python2.7\"\n    ansible_connection: local\n    cloud_provider: local\n  when: server_ip == \"localhost\"\n\n- set_fact:\n    cloud_instance_ip: \"{{ server_ip }}\"\n\n- name: Ensure the group local exists in the dynamic inventory file\n  lineinfile:\n    state: present\n    dest: configs/inventory.dynamic\n    line: '[local]'\n\n- name: Populate the dynamic inventory\n  lineinfile:\n    state: present\n    dest: configs/inventory.dynamic\n    insertafter: '\\[local\\]'\n    regexp: \"^{{ server_ip }}.*\"\n    line: \"{{ server_ip }}\"\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "8dc50832617f5431d836a463026f13315717ab43", "filename": "tasks/modules/install-xslt.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: All OSs) Install NGINX Open Source XSLT Module\"\n  package:\n    name: nginx-module-xslt\n    state: present\n  when: nginx_type == \"opensource\"\n\n- name: \"(Install: All OSs) Install NGINX Plus XSLT Module\"\n  package:\n    name: nginx-plus-module-xslt\n    state: present\n  when: nginx_type == \"plus\"\n\n- name: \"(Setup: All NGINX) Load NGINX XSLT Module\"\n  lineinfile:\n    path: /etc/nginx/nginx.conf\n    insertbefore: BOF\n    line: load_module modules/ngx_http_xslt_filter_module.so;\n  when: not nginx_main_template_enable\n  notify: \"(Handler: All OSs) Reload NGINX\"\n"}, {"commit_sha": "4e46e9eb277bc88f285dbc9dd980193e57f7bf48", "sha": "f1fd40fea6cd8c57e4c62c5ad95db7d3e5426c56", "filename": "tasks/checks.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- include_tasks: distribution-checks.yml\n  when:\n    _docker_os_dist_check | bool\n    \n- include_tasks: compatibility-checks.yml\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "e9eac5e2895af6992fd60cc08df50b6c0b4a4f11", "filename": "roles/network/tasks/iptables.yml", "repository": "iiab/iiab", "decoded_content": "- name: Disable firewalld service\n  service: name=firewalld\n           enabled=no\n  when: not is_debuntu\n\n- name: Use larger hammer to disable firewalld (2 symbolic links involved)\n  shell: \"systemctl disable firewalld.service\"\n  when: not is_debuntu\n\n- name: Mask firewalld service\n  shell: 'systemctl mask firewalld'\n  ignore_errors: yes\n  when: not installing and not is_debuntu\n\n- name: Stop firewalld service\n  service: name=firewalld\n           state=stopped\n  ignore_errors: yes\n  when: not installing and not is_debuntu\n\n- name: Remove iptables.service file from /etc\n  file: path=/etc/systemd/system/iptables.service\n        state=absent\n\n- name: Remove iptables-xs.service file from /etc\n  file: path=/etc/systemd/system/iptables-xs.service\n        state=absent\n\n- name: Install iptables service package\n  package: name=iptables-persistent\n           state=present\n  when: is_debuntu\n  tags:\n    - download\n\n- name: Install iptables service package\n  package: name=iptables-services\n           state=present\n  when: not is_debuntu\n  tags:\n    - download\n\n- name: Install iptables services\n  template: src={{ item.0 }}\n            dest={{ item.1 }}\n            owner='root'\n            group='root'\n            mode={{ item.2 }}\n  with_items:\n   - { 0: 'gateway/iptables-config', 1: '/etc/sysconfig/iptables-config', 2: '0644' }\n   - { 0: 'gateway/check-LAN', 1: '/usr/bin/check-LAN', 2: '0755' }\n\n- name: Install debian config\n  template: src=gateway/iptables dest=/etc/network/if-pre-up.d/iptables\n            mode=0755\n  when: is_debuntu\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "98f4848d1970546c3e17b5595b60a7f0f12bb193", "filename": "tasks/main.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n\n- name: Include OS specific variables.\n  include_vars: \"configure-{{ ansible_os_family }}.yml\"\n\n- name: Include OS specific selinux libs and utils if needed\n  include_tasks: \"selinux-{{ ansible_os_family }}.yml\"\n  when: ansible_selinux.status is defined and ansible_selinux.status == \"enabled\"\n\n- name: Check if SystemD service is installed\n  stat:\n    path: /etc/systemd/system/nexus.service\n  register: nexus_systemd_service_file\n\n- include_tasks: nexus_purge.yml\n  when: ((purge is defined) and (purge | bool))\n\n- import_tasks: nexus_install.yml\n\n- include_tasks: httpd_reverse_proxy_config.yml\n  when: httpd_setup_enable\n\n- import_tasks: admin_password_setup.yml\n\n- name: Deleting default repositories\n  include_tasks: delete_repo_each.yml\n  with_items:\n    - maven-central\n    - maven-public\n    - maven-releases\n    - maven-snapshots\n    - nuget-group\n    - nuget-hosted\n    - nuget.org-proxy\n  when: nexus_data_dir_contents.stdout == \"\" and nexus_delete_default_repos\n\n- name: Deleting default blobstore\n  include_tasks: delete_blobstore_each.yml\n  with_items:\n    - name: default\n    - name: \"{{ nexus_blob_names.raw.blob }}\"\n    - name: \"{{ nexus_blob_names.pypi.blob }}\"\n    - name: \"{{ nexus_blob_names.docker.blob }}\"\n    - name: \"{{ nexus_blob_names.ruby.blob }}\"\n    - name: \"{{ nexus_blob_names.bower.blob }}\"\n    - name: \"{{ nexus_blob_names.npm.blob }}\"\n    - name: \"{{ nexus_blob_names.nuget.blob }}\"\n    - name: \"{{ nexus_blob_names.mvn.blob }}\"\n    - name: \"{{ nexus_blob_names.gitlfs.blob }}\"\n    - name: \"{{ nexus_blob_names.yum.blob }}\"\n  when: nexus_data_dir_contents.stdout == \"\" and nexus_delete_default_blobstore\n\n- include_tasks: setup_ldap_each.yml\n  with_items: \"{{ ldap_connections }}\"\n\n- include_tasks: create_content_selector_each.yml\n  with_items: \"{{ nexus_content_selectors }}\"\n\n- include_tasks: setup_privilege_each.yml\n  with_items: \"{{ nexus_privileges }}\"\n\n- include_tasks: setup_role_each.yml\n  with_items: \"{{ nexus_roles }}\"\n\n- include_tasks: setup_user_each.yml\n  with_items: \"{{ nexus_local_users }}\"\n\n- name: \"Digest splited blob list var\"\n  include_vars: blob_vars.yml\n  when: nexus_blob_split\n\n- include_tasks: create_blobstore_each.yml\n  with_items: \"{{ nexus_blobstores }}\"\n  when: nexus_restore_point is undefined\n\n- name: \"Restore nexus backup\"\n  include_tasks: nexus-restore.yml\n  when: nexus_restore_point is defined\n\n- include_tasks: create_repo_maven_proxy_each.yml\n  with_items: \"{{ nexus_repos_maven_proxy }}\"\n\n- include_tasks: create_repo_maven_hosted_each.yml\n  with_items: \"{{ nexus_repos_maven_hosted }}\"\n\n- include_tasks: create_repo_maven_group_each.yml\n  with_items: \"{{ nexus_repos_maven_group }}\"\n\n- block:\n    - include_tasks: create_repo_docker_hosted_each.yml\n      with_items: \"{{ nexus_repos_docker_hosted }}\"\n\n    - include_tasks: create_repo_docker_proxy_each.yml\n      with_items: \"{{ nexus_repos_docker_proxy }}\"\n\n    - include_tasks: create_repo_docker_group_each.yml\n      with_items: \"{{ nexus_repos_docker_group }}\"\n  when: nexus_config_docker\n\n- block:\n    - include_tasks: create_repo_pypi_proxy_each.yml\n      with_items: \"{{ nexus_repos_pypi_proxy }}\"\n\n    - include_tasks: create_repo_pypi_hosted_each.yml\n      with_items: \"{{ nexus_repos_pypi_hosted }}\"\n\n    - include_tasks: create_repo_pypi_group_each.yml\n      with_items: \"{{ nexus_repos_pypi_group }}\"\n  when: nexus_config_pypi\n\n- block:\n    - include_tasks: create_repo_raw_proxy_each.yml\n      with_items: \"{{ nexus_repos_raw_proxy }}\"\n\n    - include_tasks: create_repo_raw_hosted_each.yml\n      with_items: \"{{ nexus_repos_raw_hosted }}\"\n\n    - include_tasks: create_repo_raw_group_each.yml\n      with_items: \"{{ nexus_repos_raw_group }}\"\n  when: nexus_config_raw\n\n- block:\n    - include_tasks: create_repo_rubygems_proxy_each.yml\n      with_items: \"{{ nexus_repos_rubygems_proxy }}\"\n\n    - include_tasks: create_repo_rubygems_hosted_each.yml\n      with_items: \"{{ nexus_repos_rubygems_hosted }}\"\n\n    - include_tasks: create_repo_rubygems_group_each.yml\n      with_items: \"{{ nexus_repos_rubygems_group }}\"\n  when: nexus_config_rubygems\n\n- block:\n    - include_tasks: create_repo_bower_proxy_each.yml\n      with_items: \"{{ nexus_repos_bower_proxy }}\"\n\n    - include_tasks: create_repo_bower_hosted_each.yml\n      with_items: \"{{ nexus_repos_bower_hosted }}\"\n\n    - include_tasks: create_repo_bower_group_each.yml\n      with_items: \"{{ nexus_repos_bower_group }}\"\n  when: nexus_config_bower\n\n- block:\n    - include_tasks: create_repo_npm_proxy_each.yml\n      with_items: \"{{ nexus_repos_npm_proxy }}\"\n\n    - include_tasks: create_repo_npm_hosted_each.yml\n      with_items: \"{{ nexus_repos_npm_hosted }}\"\n\n    - include_tasks: create_repo_npm_group_each.yml\n      with_items: \"{{ nexus_repos_npm_group }}\"\n  when: nexus_config_npm\n\n- block:\n    - include_tasks: create_repo_nuget_proxy_each.yml\n      with_items: \"{{ nexus_repos_nuget_proxy }}\"\n    - include_tasks: create_repo_nuget_hosted_each.yml\n      with_items: \"{{ nexus_repos_nuget_hosted }}\"\n    - include_tasks: create_repo_nuget_group_each.yml\n      with_items: \"{{ nexus_repos_nuget_group }}\"\n  when: nexus_config_nuget\n\n\n- include_tasks: create_repo_gitlfs_hosted_each.yml\n  with_items: \"{{ nexus_repos_gitlfs_hosted }}\"\n  when: nexus_config_gitlfs\n\n- block:\n    - include_tasks: create_repo_yum_hosted_each.yml\n      with_items: \"{{ nexus_repos_yum_hosted }}\"\n    - include_tasks: create_repo_yum_proxy_each.yml\n      with_items: \"{{ nexus_repos_yum_proxy }}\"\n    - include_tasks: create_repo_yum_group_each.yml\n      with_items: \"{{ nexus_repos_yum_group }}\"\n  when: nexus_config_yum\n\n- include_tasks: call_script.yml\n  vars:\n    script_name: setup_anonymous_access\n    args:\n      anonymous_access: \"{{ nexus_anonymous_access }}\"\n\n- include_tasks: call_script.yml\n  vars:\n    script_name: setup_base_url\n    args:\n      base_url: \"https://{{ public_hostname }}/\"\n\n- include_tasks: call_script.yml\n  vars:\n    script_name: setup_http_proxy\n    args:\n      with_http_proxy: \"{{ nexus_with_http_proxy }}\"\n      http_proxy_host: \"{{ nexus_http_proxy_host }}\"\n      http_proxy_port: \"{{ nexus_http_proxy_port }}\"\n      http_proxy_username: \"{{ nexus_http_proxy_username }}\"\n      http_proxy_password: \"{{ nexus_http_proxy_password }}\"\n      with_https_proxy: \"{{ nexus_with_https_proxy }}\"\n      https_proxy_host: \"{{ nexus_https_proxy_host }}\"\n      https_proxy_port: \"{{ nexus_https_proxy_port }}\"\n      https_proxy_username: \"{{ nexus_https_proxy_username }}\"\n      https_proxy_password: \"{{ nexus_https_proxy_password }}\"\n      proxy_exclude_hosts: \"{{ nexus_proxy_exclude_hosts }}\"\n\n- include_tasks: call_script.yml\n  vars:\n    script_name: setup_realms\n    args:\n      nuget_api_key_realm: \"{{ nexus_nuget_api_key_realm }}\"\n      npm_bearer_token_realm: \"{{ nexus_npm_bearer_token_realm }}\"\n      rut_auth_realm: \"{{ nexus_rut_auth_realm }}\"\n      ldap_realm: \"{{ nexus_ldap_realm }}\"\n      docker_bearer_token_realm: \"{{ nexus_docker_bearer_token_realm }}\"\n\n- name: Configure RUT Auth header\n  include_tasks: call_script.yml\n  vars:\n    script_name: setup_capability\n    args:\n      capability_typeId: \"rutauth\"\n      capability_properties:\n        httpHeader: \"{{ nexus_rut_auth_header }}\"\n  when: nexus_rut_auth_header is defined\n\n- include_tasks: call_script.yml\n  vars:\n    script_name: setup_email\n    args:\n      email_server_enabled: \"{{ nexus_email_server_enabled }}\"\n      email_server_host: \"{{ nexus_email_server_host }}\"\n      email_server_port: \"{{ nexus_email_server_port }}\"\n      email_server_username: \"{{ nexus_email_server_username }}\"\n      email_server_password: \"{{ nexus_email_server_password }}\"\n      email_from_address: \"{{ nexus_email_from_address }}\"\n      email_subject_prefix: \"{{ nexus_email_subject_prefix }}\"\n      email_tls_enabled: \"{{ nexus_email_tls_enabled }}\"\n      email_tls_required: \"{{ nexus_email_tls_required }}\"\n      email_ssl_on_connect_enabled: \"{{ nexus_email_ssl_on_connect_enabled }}\"\n      email_ssl_check_server_identity_enabled: \"{{ nexus_email_ssl_check_server_identity_enabled }}\"\n      email_trust_store_enabled: \"{{ nexus_email_trust_store_enabled }}\"\n\n- name: Configure branding capability\n  include_tasks: call_script.yml\n  vars:\n    script_name: setup_capability\n    args:\n      capability_typeId: \"rapture.branding\"\n      capability_properties:\n        footerHtml: \"{{ nexus_branding_footer }}\"\n        headerHtml: \"{{ nexus_branding_header }}\"\n        footerEnabled: \"{{ nexus_branding_footer != '' }}\"\n        headerEnabled: \"{{ nexus_branding_header != '' }}\"\n\n- include_tasks: create_task_each.yml\n  with_items: \"{{ nexus_scheduled_tasks }}\"\n\n- name: Configure nexus backup task\n  include_tasks: call_script.yml\n  vars:\n    script_name: create_task\n    args:\n      name: db and blobstores backup\n      typeId: script\n      cron: \"{{ nexus_backup_cron }}\"\n      taskProperties:\n        language: groovy\n        source: \"{{ lookup('template', './templates/backup.groovy.j2') }}\"\n  when: nexus_backup_configure | bool\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "920d631173cc5ec7efceca35c68d4a99d678f001", "filename": "roles/ansible/prep-for-ansible/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Force gather facts - an error is normal\"\n  setup:\n  check_mode: no\n  ignore_errors: True\n  register: facts\n\n- name: \"Install python2 and dnf stuff to allow for Ansible operation\"\n  raw: dnf -y install python-dnf libselinux-python\n  when:\n  - facts is failed\n\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "2bb6db8a47aa238370851772dc3795a46f8f2a5a", "filename": "roles/manage-confluence-space/tasks/copy_confluence_attachments.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Get attachment data\n  uri:\n    url: '{{ confluence_source_url }}/wiki/rest/api/content/{{ confluence_content_ids.key }}/child/attachment'\n    method: GET\n    user: '{{ confluence_source_username }}'\n    password: '{{ confluence_source_password }}'\n    force_basic_auth: yes\n    status_code: 200\n    return_content: yes\n  register: attachments_json\n\n- name: Create temp directory for downloaded attachments\n  tempfile:\n    state: directory\n  register: attachment_tempdir\n\n- include_tasks: download_attachment.yml\n  with_items: '{{ attachments_json.json.results }}'\n  loop_control:\n    loop_var: attachment_data\n"}, {"commit_sha": "abafe1581c6c78d784cf215b214947675d49eff8", "sha": "a37bf9cd1c505681f6e7308f7b178552bd2c9e3b", "filename": "roles/dns_adblocking/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: Gather Facts\n  setup:\n\n- name: Dnsmasq installed\n  apt: name=dnsmasq state=latest\n\n- name: Dnsmasq profile for apparmor configured\n  template: src=usr.sbin.dnsmasq.j2 dest=/etc/apparmor.d/usr.sbin.dnsmasq owner=root group=root mode=0600\n  notify:\n    - restart dnsmasq\n\n- name: The dnsmasq directory created\n  file: dest=/var/lib/dnsmasq state=directory mode=0755 owner=dnsmasq group=nogroup\n\n- name: Enforce the dnsmasq AppArmor policy\n  shell: aa-enforce usr.sbin.dnsmasq\n\n- name: Ensure that the dnsmasq service directory exist\n  file: path=/etc/systemd/system/dnsmasq.service.d/ state=directory mode=0755  owner=root group=root\n\n- name: Setup the cgroup limitations for the ipsec daemon\n  template: src=100-CustomLimitations.conf.j2 dest=/etc/systemd/system/dnsmasq.service.d/100-CustomLimitations.conf\n  notify:\n    - daemon-reload\n    - restart dnsmasq\n\n- meta: flush_handlers\n\n- name: Dnsmasq configured\n  template: src=dnsmasq.conf.j2 dest=/etc/dnsmasq.conf\n  notify:\n    - restart dnsmasq\n\n- name: Adblock script created\n  template: src=adblock.sh dest=/opt/adblock.sh owner=root group=root mode=0755\n\n- name: Adblock script added to cron\n  cron:\n    name: Adblock hosts update\n    minute: 10\n    hour: 2\n    job: /opt/adblock.sh\n    user: dnsmasq\n\n- name: Update adblock hosts\n  shell: >\n    /opt/adblock.sh\n  become: true\n  become_user: dnsmasq\n\n- name: Dnsmasq enabled and started\n  service: name=dnsmasq state=started enabled=yes\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "5c9529e05b21c0ea6ee5af4d0cd45893fab69d57", "filename": "roles/network/templates/named/named.service", "repository": "iiab/iiab", "decoded_content": "[Unit]\nDescription=BIND Domain Name Server\nDocumentation=man:named(8)\nAfter=network.target\n\n[Service]\nEnvironmentFile=-/etc/sysconfig/named\nExecStart=/usr/sbin/named -f -u named $OPTIONS\nExecReload=/usr/sbin/rndc reload\nExecStop=/usr/sbin/rndc stop\n\n[Install]\nWantedBy=multi-user.target\n"}, {"commit_sha": "96adc61e360141bb718b75d48c387b3680a8471b", "sha": "a8b7be4fc0f1c1e5ad4159e3dd45657efe2d8fd4", "filename": "handlers/main.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n# handlers file for ansible-role-docker-ce\n\n- name: restart docker\n  service:\n    name: docker\n    state: restarted\n  become: yes\n  tags: [\"install\", \"configure\"]\n\n# Workaround because systemd cannot be used: https://github.com/ansible/ansible/issues/22171\n- name: restart auditd\n  command: service auditd restart\n  args:\n    warn: no\n  become: yes\n  tags: [\"install\", \"configure\"]\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "a6ad64f54fdb6378c4d7bf361e79045a629dac37", "filename": "roles/kiwix/files/test_zim/index.html", "repository": "iiab/iiab", "decoded_content": "<!DOCTYPE html>\n<HTML>\n <HEAD>\n <TITLE>Kiwix in Internet-in-a-Box</TITLE>\n </HEAD>\n <BODY>\n   <h1>Welcome to Kiwix in Internet-in-a-Box</h1>\n   <p>This is a test page</p>\n </BODY>\n<HTML>\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "849169c71aa714dc6dc717e061b702a4b38752b9", "filename": "roles/config-bonding/tasks/prereq.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "388e8270b3eb0ae20924b478d6a59f8c54b92b0f", "filename": "tasks/Win32NT/fetch/web.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Download artifact from web\n  win_get_url:\n    url: '{{ transport_web }}'\n    dest: >-\n      {{ java_download_path }}\\{{ (transport_web | urlsplit('path')).split('/')[-1] }}\n    force: false\n  register: file_downloaded\n  retries: 5\n  delay: 2\n  until: file_downloaded is succeeded\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "73a934620e53a7efcaf0ea3af10af122cf6cb07f", "filename": "roles/ansible/tower/manage-inventories/tasks/process-group-member.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Associate the host(s) with the group\"\n  uri:\n    url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}/api/v2/groups/{{ group_id }}/hosts/\"\n    user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n    password: \"{{ ansible_tower.admin_password }}\"\n    force_basic_auth: yes\n    method: POST\n    body: \"{{ lookup('template', 'group-member.j2') }}\"\n    body_format: 'json'\n    headers:\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n    validate_certs: no\n    status_code: 200,201,204,400\n"}, {"commit_sha": "b7c6bfe0369646ca69beeb3dfe07e8218d61c940", "sha": "625b7ff9935b3d89941585b0694b961bcb004a29", "filename": "tasks/suid_sgid.yml", "repository": "dev-sec/ansible-os-hardening", "decoded_content": "---\n- name: remove suid/sgid bit from binaries in blacklist | os-06\n  file:\n    path: '{{ item }}'\n    mode: 'a-s'\n    state: 'file'\n    follow: 'yes'\n  failed_when: false\n  with_flattened:\n    - '{{ os_security_suid_sgid_system_blacklist }}'\n    - '{{ os_security_suid_sgid_blacklist }}'\n\n- name: find binaries with suid/sgid set | os-06\n  shell: find / -xdev \\( -perm -4000 -o -perm -2000 \\) -type f ! -path '/proc/*' -print 2>/dev/null\n  register: sbit_binaries\n  when: os_security_suid_sgid_remove_from_unknown\n  changed_when: False\n\n- name: gather files from which to remove suids/sgids and remove system white-listed files | os-06\n  set_fact:\n    suid: '{{ sbit_binaries.stdout_lines | difference(os_security_suid_sgid_system_whitelist) }}'\n  when: os_security_suid_sgid_remove_from_unknown\n\n- name: remove suid/sgid bit from all binaries except in system and user whitelist | os-06\n  file:\n    path: '{{ item }}'\n    mode: 'a-s'\n    state: 'file'\n    follow: 'yes'\n  with_flattened:\n    - '{{ suid | default([]) | difference(os_security_suid_sgid_whitelist) }}'\n  when: os_security_suid_sgid_remove_from_unknown\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "e0666eb9e201bbf4b1e25493a26f9e6c44eeb839", "filename": "playbooks/roles/check_docker_validation/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- name: Pull some basic docker images\n  command: \"docker pull {{item}}:{{docker_prepull_tag}}\"\n  with_items:\n  - \"{{docker_prepull}}\"\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "87202c34df5ab2e436cc4df8f432a3852113eb4b", "filename": "roles/manage-aws-infra/tasks/pre-reqs.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- name: Fail when delete_vpc is not defined\n  debug:\n    msg: \"delete_vpc boolean variable must be specified to remove the Cluster\"\n  failed_when:\n    - delete_vpc is not defined\n    - operation == \"absent\"\n\n- name: Fail when AWS KEY environment variables are not defined\n  debug:\n    msg: \"Both 'AWS_ACCESS_KEY_ID' and 'AWS_SECRET_ACCESS_KEY' environment variables must be defined\"\n  failed_when: (lookup('env','AWS_ACCESS_KEY_ID')  == \"\") or\n               (lookup('env','AWS_SECRET_ACCESS_KEY')  == \"\")\n\n- name: Set Default values\n  set_fact:\n    master_root_volume: \"{{ master_root_volume | default(default_root_volume) }}\"\n    master_root_volume_size: \"{{ master_root_volume_size | default(default_root_volume_size) }}\"\n    infra_node_root_volume: \"{{ infra_node_root_volume | default(default_root_volume) }}\"\n    infra_node_root_volume_size: \"{{ infra_node_root_volume_size | default(default_root_volume_size) }}\"\n    app_node_root_volume: \"{{ app_node_root_volume | default(default_root_volume) }}\"\n    app_node_root_volume_size: \"{{ app_node_root_volume_size | default(default_root_volume_size) }}\"\n    cns_node_root_volume: \"{{ cns_node_root_volume | default(default_root_volume) }}\"\n    cns_node_root_volume_size: \"{{ cns_node_root_volume_size | default(default_root_volume_size) }}\"\n    cns_node_glusterfs_volume: \"{{ cns_node_glusterfs_volume | default(default_cns_volume) }}\" \n    cns_node_glusterfs_volume_size: \"{{ cns_node_glusterfs_volume_size | default(default_cns_volume_size) }}\" \n    docker_storage_block_device: \"{{ docker_storage_block_device | default(default_docker_volume) }}\"\n    docker_storage_volume_size: \"{{ docker_storage_volume_size | default(default_docker_volume_size) }}\"\n \n"}, {"commit_sha": "836dc4dd0dacc490044a14c0e39469d162b9449b", "sha": "fbe50e246ee62c63a518ccae9d4344528e3ac9a4", "filename": "meta/main.yml", "repository": "florianutz/Ubuntu1604-CIS", "decoded_content": "---\ngalaxy_info:\n  author: \"\"\n  description: \"Ansible role to apply Ubuntu 16.04 CIS Baseline\"\n  company:\n  license: MIT\n  min_ansible_version: 2.4\n\n  platforms:\n    - name: Ubuntu\n      versions:\n        - xenial\n\n  galaxy_tags:\n    - system\n    - security\n    - cis\n    - hardening\n\ndependencies: []\n"}, {"commit_sha": "9662c15ce2e4260fac5cc2bfdf5aaaaf0a2191dd", "sha": "df9a525d38b48dac0393b2d4b4c9511c07dbd5e5", "filename": "tasks/section_02_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 2.1 Create Separate Partition for /tmp (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /tmp\"\n    tags:\n      - section2\n      - section2.1\n\n  - name: 2.2 - 4 Set nodev, nosuid, noexec option for /tmp Partition (Scored)\n    mount: name=\"/tmp\" state=\"mounted\" opts=\"nodev,nosuid,noexec\"\n    when: partitioning==\"true\"\n    tags:\n      - section2\n      - section2.2\n      - section2.3\n      - section2.4\n\n  - name: 2.5 Create Separate Partition for /var (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var\"\n    tags:\n      - section2\n      - section2.5\n\n  - name: 2.6 Bind Mount the /var/tmp directory to /tmp (Scored)\n    mount: name=\"/var/tmp\" src=\"/tmp\" opts=bind state=mounted\n    when: partitioning==\"true\"\n    tags:\n      - section2\n      - section2.6\n\n  - name: 2.7 Create Separate Partition for /var/log (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var/log\"\n    tags:\n      - section2\n      - section2.7\n\n  - name: 2.8 Create Separate Partition for /var/log/audit (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var/log/audit\"\n    tags:\n      - section2\n      - section2.8\n\n  - name: 2.9 Create Separate Partition for /home (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /home\"\n    tags:\n      - section2\n      - section2.9\n\n  - name: 2.10 Add nodev Option to /home (Scored)\n    mount: name:/home state:mounted opts:remount,nodev\n    when: partitioning==\"true\"\n    tags:\n      - section2\n      - section2.10\n\n  - name: 2.11 Add nodev Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nodev option\"\n    tags:\n      - section2\n      - section2.11\n\n  - name: 2.12 Add noexec Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have noexec option\"\n    tags:\n      - section2\n      - section2.12\n\n  - name: 2.13 Add nosuid Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nosuid option\"\n    tags:\n      - section2\n      - section2.13\n\n  - name: 2.14 - 16 Add nodev Option to /run/shm Partition (Scored)\n    mount: name=\"/run/shm\" src=\"/run/shm\" state=\"mounted\" opts=\"remount,nodev,nosuid,noexec\" fstype=\"tmpfs\"\n    tags:\n      - section2\n      - section2.14\n      - section2.15\n      - section2.16\n\n  - name: 2.17.1 Set Sticky Bit on All World-Writable Directories (preparation) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type d -perm -0002 -print 2>/dev/null\n    failed_when: False\n    changed_when: False\n    always_run: True\n    register: sticky_bit_dirs\n    tags:\n      - section2\n      - section2.17\n      - section2.17.1\n\n  - name: 2.17.2 Set Sticky Bit on All World-Writable Directories (Scored)\n    file: path={{ item }} mode=\"a+t\"\n    with_items: sticky_bit_dirs.stdout_lines\n    tags:\n      - section2\n      - section2.17\n      - section2.17.2\n\n  - name: 2.25 Disable Automounting (Scored)\n    lineinfile: >\n        dest=/etc/init/autofs.conf\n        line='start on runlevel [2345]'\n        regexp='^start on runlevel [2345]'\n        state=absent\n    tags:\n      - section2\n      - section2.25\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "da46534a5f1302359d9ba7cf84e87a66933d6878", "filename": "roles/cloud-ec2/tasks/encrypt_image.yml", "repository": "trailofbits/algo", "decoded_content": "- name: Check if the encrypted image already exist\n  ec2_ami_find:\n    aws_access_key: \"{{ aws_access_key | default(lookup('env','AWS_ACCESS_KEY_ID'))}}\"\n    aws_secret_key: \"{{ aws_secret_key | default(lookup('env','AWS_SECRET_ACCESS_KEY'))}}\"\n    owner: self\n    sort: creationDate\n    sort_order: descending\n    sort_end: 1\n    state: available\n    ami_tags:\n      Algo: \"encrypted\"\n    region: \"{{ region }}\"\n  register: search_crypt\n\n- set_fact:\n    ami_image: \"{{ search_crypt.results[0].ami_id }}\"\n  when: search_crypt.results\n\n- name: Copy to an encrypted image\n  ec2_ami_copy:\n    aws_access_key: \"{{ aws_access_key | default(lookup('env','AWS_ACCESS_KEY_ID'))}}\"\n    aws_secret_key: \"{{ aws_secret_key | default(lookup('env','AWS_SECRET_ACCESS_KEY'))}}\"\n    encrypted: yes\n    name: algo\n    kms_key_id: \"{{ kms_key_id | default(omit) }}\"\n    region: \"{{ region }}\"\n    source_image_id: \"{{ ami_image }}\"\n    source_region: \"{{ region }}\"\n    tags:\n      Algo: \"encrypted\"\n    wait: true\n  register: enc_image\n  when: not search_crypt.results\n\n- set_fact:\n    ami_image: \"{{ enc_image.image_id }}\"\n  when: not search_crypt.results\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "559c15b3970cb77aa259a252e63530c9885eebbd", "filename": "roles/pathagar/templates/wsgi.py", "repository": "iiab/iiab", "decoded_content": "\"\"\"\nWSGI config for pathagar project.\n\nIt exposes the WSGI callable as a module-level variable named ``application``.\n\"\"\"\n\nimport os\nos.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"pathagar.prod_settings\")\n\nfrom django.core.wsgi import get_wsgi_application\napplication = get_wsgi_application()\n"}, {"commit_sha": "7032aee7df1c2c6e96795067285efa3b2a6de32e", "sha": "855035fc330f4e9aeaa23965a0bb6d9b6ad065d0", "filename": "roles/dns/tasks/main.yml", "repository": "openshift/openshift-ansible-contrib", "decoded_content": "---\n- name: Remove DNS A records (if any)\n  lineinfile: dest=/var/named/static/{{ item.0.view }}-{{ item.0.zone }}.db state=absent regexp=\"^{{ item.1.hostname }}\\s+.+IN\\s+A\\s+{{ item.1.ip }}.*\"\n  with_subelements:\n   - dns_records_rm | default({})\n   - entries\n  when: item.1.type == \"A\"\n  notify: restart named\n\n- name: Add DNS A records (if any)\n  lineinfile: dest=/var/named/static/{{ item.0.view }}-{{ item.0.zone }}.db state=present regexp=\"^{{ item.1.hostname }}\\s+\\d\" line=\"{{ item.1.hostname }}      3600    IN      A       {{ item.1.ip }}\"\n  with_subelements:\n   - dns_records_add | default({})\n   - entries\n  when: item.1.type == \"A\"\n  notify: restart named\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "dca18f6f497d950d54480ce9d0845f3ced9b6be4", "filename": "roles/network/templates/named/named.broadcast", "repository": "iiab/iiab", "decoded_content": "$TTL    86400\n@               IN SOA  localhost.      root.localhost. (\n                                        42              ; serial (d. adams)\n                                        3H              ; refresh\n                                        15M             ; retry\n                                        1W              ; expiry\n                                        1D )            ; minimum\n\tIN\tNS\tlocalhost.\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "6d26ee0a58fb09a6cdef4eebf6a25f329680e7b3", "filename": "roles/monit/templates/httpd", "repository": "iiab/iiab", "decoded_content": "check process {{ apache_service }} with pidfile /var/run/{{ apache_service }}/{{ apache_service }}.pid\n   start program = \"/sbin/service {{ apache_service }} start\" \n   stop program = \"/sbin/service {{ apache_service }} stop\" \n   if cpu > 60% for 3 cycles then restart\n   if totalmem > 200.0 MB for 3 cycles then restart \n   if failed host localhost port 80 type tcp  then restart\n   if 3  restarts within 5 cycles then timeout\n"}, {"commit_sha": "96adc61e360141bb718b75d48c387b3680a8471b", "sha": "0ece5d0ee3b5e4aaac46f2363fc5037339eea25f", "filename": "tasks/setup-audit.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Ensure auditd is installed\n  package:\n    name: auditd\n    state: present\n  become: true\n  when: _docker_os_dist == \"Ubuntu\" or\n        _docker_os_dist == \"Debian\"\n\n- name: Copy Docker audit rules\n  copy:\n    src: files/etc/audit/rules.d/docker.rules\n    dest: /etc/audit/rules.d/docker.rules\n  become: yes\n  notify: restart auditd\n  when: docker_enable_audit | bool\n\n- name: Ensure Docker audit rules are removed\n  file:\n    path: /etc/audit/rules.d/docker.rules\n    state: absent\n  become: yes\n  notify: restart auditd\n  when: not docker_enable_audit | bool\n"}, {"commit_sha": "f3dd45a61b08de1b3351140cc442a705cb2fad82", "sha": "ca6f17641f9f1fb594695f157077a9c807ba9275", "filename": "handlers/main.yml", "repository": "geerlingguy/ansible-role-security", "decoded_content": "---\n- name: restart ssh\n  service: \"name={{ security_sshd_name }} state={{ security_ssh_restart_handler_state }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "af68ffa0410ea751ad5fa3c4155aa1d7c2873a13", "filename": "roles/ansible/tower/manage-workflow-templates/tasks/process-workflow-template.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Initilize workflow_template_id to None\"\n  set_fact:\n    workflow_template_id: -1\n\n- name: \"Grab workflow_template_id if already defined\"\n  set_fact:\n    workflow_template_id: \"{{ existing_workflow_template.id }}\"\n  when: existing_workflow_template.name == workflow_template.name\n  with_items:\n  - \"{{ existing_workflow_templates_output.rest_output }}\"\n  loop_control:\n    loop_var: existing_workflow_template\n\n- block:\n  - name: \"Load up the workflow template if not already defined\"\n    uri:\n      url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}/api/v2/workflow_job_templates/\"\n      user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      password: \"{{ ansible_tower.admin_password }}\"\n      force_basic_auth: yes\n      method: POST\n      body: \"{{ lookup('template', 'workflow-template.j2') }}\"\n      body_format: 'json'\n      headers:\n        Content-Type: \"application/json\"\n        Accept: \"application/json\"\n      validate_certs: no\n      status_code: 200,201,400\n    register: workflow_template_rest_output\n\n  - name: \"Save new workflow template id\"\n    set_fact:\n      workflow_template_id: \"{{ workflow_template_rest_output.json.id }}\"\n  when: workflow_template_id == -1\n\n- name: \"Get current workflow nodes\"\n  uri:\n    url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}/api/v2/workflow_job_templates/{{ workflow_template_id }}/workflow_nodes/\"\n    user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n    password: \"{{ ansible_tower.admin_password }}\"\n    force_basic_auth: yes\n    method: GET\n    headers:\n      Accept: \"application/json\"\n    validate_certs: no\n    status_code: 200,201,400\n  register: current_workflow_nodes\n\n- name: \"Delete current workflow nodes\"\n  uri:\n    url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}/api/v2/workflow_job_template_nodes/{{ workflow_node.id }}/\"\n    user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n    password: \"{{ ansible_tower.admin_password }}\"\n    force_basic_auth: yes\n    method: DELETE\n    headers:\n      Accept: \"application/json\"\n    validate_certs: no\n    status_code: 204\n  with_items: \"{{ current_workflow_nodes.json.results }}\"\n  loop_control:\n    loop_var: workflow_node\n\n- name: \"Process the inventory nodes\"\n  include_tasks: process-workflow-node.yml\n  with_items:\n  - \"{{ workflow_template.nodes | flatten_workflow_nodes }}\"\n  loop_control:\n    loop_var: workflow_node\n\n# Utilize the `rest_get` library routine to ensure REST pagination is handled\n- name: \"Obtain the current roles\"\n  rest_get:\n    host_url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}\"\n    rest_user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n    rest_password: \"{{ ansible_tower.admin_password }}\"\n    api_uri: \"/api/v2/roles/\"\n  register: existing_roles_output\n\n- name: \"Assign the Team(s) Permission(s)\"\n  vars:\n    permissions_object: \"teams\"\n    permissions_value: \"{{ team }}\"\n  include_tasks: set-permissions.yml\n  when:\n  - workflow_template.permissions is defined\n  - workflow_template.permissions.teams is defined\n  with_items:\n  - \"{{ workflow_template.permissions.teams }}\"\n  loop_control:\n    loop_var: team\n\n- name: \"Assign the User(s) Permission(s)\"\n  vars:\n    permissions_object: \"users\"\n    permissions_value: \"{{ user }}\"\n  include_tasks: set-permissions.yml\n  when:\n  - workflow_template.permissions is defined\n  - workflow_template.permissions.users is defined\n  with_items:\n  - \"{{ workflow_template.permissions.users }}\"\n  loop_control:\n    loop_var: user\n\n- name: \"Clear/Update facts\"\n  set_fact:\n    processed_workflow_templates: \"{{ processed_workflow_templates + [ {'name': workflow_template.name } ] }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "6f0a5cb413ca7e912c68dde2801845aa7519a00f", "filename": "playbooks/update-dhcp-config.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Update dhcpd config'\n  hosts: dhcp-servers\n  roles:\n  - role: dhcp\n  tags: \n  - update_dhcp_config\n\n\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "cfe3be2ebfd8f30a2a483ad9c5f6f0a3100f5dbc", "filename": "archive/roles/openshift-common/tasks/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- name: Setting OpenShift Common Facts\n  set_fact:\n    openshift_storage_disk_volume: \"{{ openshift_storage_disk_volume | default(default_openshift_storage_disk_volume) }}\"\n    openshift_master_count: \"{{ openshift_master_count | default(default_openshift_master_count) }}\"\n    openshift_node_count: \"{{ openshift_node_count | default(default_openshift_node_count) }}\"\n    openshift_app_domain: \"{{ openshift_app_domain | default(default_openshift_app_domain) }}\"\n    openshift_openstack_flavor_name: \"{{ openshift_openstack_flavor_name | default(default_openshift_openstack_flavor_name) }}\"\n    openshift_openstack_image_name: \"{{ openshift_openstack_image_name | default(default_openshift_openstack_image_name) }}\"\n    openshift_openstack_master_storage_size: \"{{ openshift_openstack_master_storage_size | default(default_openshift_openstack_master_storage_size) }}\"\n    openshift_openstack_node_storage_size: \"{{ openshift_openstack_node_storage_size | default(default_openshift_openstack_node_storage_size) }}\"\n    openshift_openstack_master_security_groups: \"{{ openshift_openstack_master_security_groups | default(default_openshift_openstack_master_security_groups) }}\"\n    openshift_openstack_node_security_groups: \"{{ openshift_openstack_node_security_groups | default(default_openshift_openstack_node_security_groups) }}\"\n    openshift_openstack_dns_security_groups: \"{{ openshift_openstack_dns_security_groups | default(default_openshift_openstack_dns_security_groups) }}\"\n    openshift_openstack_nfs_security_groups: \"{{ openshift_openstack_nfs_security_groups | default(default_openshift_openstack_nfs_security_groups) }}\"\n"}, {"commit_sha": "d7fbb1f61d1191166152acc249d0e910859619ca", "sha": "f8debff7cda55ca535488ffbf62b9ef11146d38f", "filename": "tasks/postinstall.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Reset internal variables for additional packages to be installed\n  set_fact:\n    _docker_additional_packages_os: []\n    _docker_additional_packages_pip: []\n\n- name: Set facts to ensure 'docker_container' module works\n  set_fact:\n    _docker_additional_packages_pip: \"{{ _docker_additional_packages_pip + docker_predefined_packages_pip[_docker_os_dist]['sdk'] }}\"\n  when:\n    - docker_container_deps\n\n- name: Set facts to ensure 'docker_service' module works\n  set_fact:\n    _docker_additional_packages_pip: \"{{ _docker_additional_packages_pip + docker_predefined_packages_pip[_docker_os_dist]['compose'] }}\"\n  when:\n    - docker_service_deps\n\n- name: Set facts to ensure 'docker_stack' module works\n  set_fact:\n    _docker_additional_packages_pip: \"{{ _docker_additional_packages_pip + docker_predefined_packages_pip[_docker_os_dist]['stack'] }}\"\n  when:\n    - docker_stack_deps\n\n- name: Set facts with additional package to be installed\n  set_fact:\n    _docker_additional_packages_pip: \"{{ _docker_additional_packages_pip + docker_additional_packages_pip }}\"\n    _docker_additional_packages_os: \"{{ _docker_additional_packages_os + docker_additional_packages_os }}\"\n\n- name: Set facts to ensure PiP is installed if required\n  set_fact:\n    _docker_additional_packages_os: \"{{ _docker_additional_packages_os + ['python-pip', 'python-virtualenv'] }}\"\n  when:\n    - _docker_additional_packages_pip | length > 0\n\n- name: Install additional packages (OS package manager)\n  become: true\n  package:\n    name: \"{{ item }}\"\n    state: present\n  with_items:\n    - \"{{ _docker_additional_packages_os }}\"\n  when: _docker_additional_packages_os | length > 0\n\n- name: Upgrade PiP\n  become: true\n  pip:\n    name: pip\n    state: forcereinstall\n  when: docker_pip_upgrade\n\n- name: Install additional packages (PiP)\n  become: true\n  pip:\n    name: \"{{ item }}\"\n    state: present\n  with_items:\n    - \"{{ _docker_additional_packages_pip }}\"\n  when: _docker_additional_packages_pip | length > 0\n  environment:\n    PYTHONWARNINGS: ignore"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "caa2a6568211de9cb4881644cbbda53a3198ccea", "filename": "tasks/nexus_purge.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- name: Make sure nexus is stopped\n  debug:\n    msg: \"trigger nexus stop\"\n  changed_when: true\n  notify:\n    - nexus-service-stop\n\n- meta: flush_handlers\n\n- name: \"Purge Nexus\"\n  file:\n    path: \"{{ item }}\"\n    state: absent\n  with_items:\n    - \"{{ nexus_data_dir }}\"\n    - \"{{ nexus_installation_dir }}/nexus-{{ nexus_version }}\"\n    - \"{{ nexus_restore_log }}\"\n    - \"{{ nexus_installation_dir }}/nexus-latest\"\n    # - \"{{ nexus_backup_dir }}\" # Optional\n\n- name: \"remove nexus package if present\"\n  package:\n    name: nexus\n    state: absent\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "800560606269737592d4aea772e3842d8d173072", "filename": "tasks/setup_ldap_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: setup_ldap\n    args:\n      name: \"{{ item.ldap_name }}\"\n      protocol: \"{{ item.ldap_protocol }}\"\n      hostname: \"{{ item.ldap_hostname }}\"\n      port: \"{{ item.ldap_port }}\"\n      auth: \"{{ item.ldap_auth | default('none') }}\"\n      username: \"{{ item.ldap_auth_username | default('') }}\"\n      password: \"{{ item.ldap_auth_password | default('') }}\"\n      search_base: \"{{ item.ldap_search_base }}\"\n      user_base_dn: \"{{ item.ldap_user_base_dn | default('ou=users') }}\"\n      user_ldap_filter: \"{{ item.ldap_user_filter | default('') }}\"\n      user_object_class: \"{{ item.ldap_user_object_class }}\"\n      user_id_attribute: \"{{ item.ldap_user_id_attribute }}\"\n      user_real_name_attribute: \"{{ item.ldap_user_real_name_attribute }}\"\n      user_email_attribute: \"{{ item.ldap_user_email_attribute }}\"\n      map_groups_as_roles: \"{{ item.ldap_map_groups_as_roles | default(false) }}\"\n      group_base_dn: \"{{ item.ldap_group_base_dn | default('ou=groups') }}\"\n      group_object_class: \"{{ item.ldap_group_object_class | default('groupOfNames') }}\"\n      group_id_attribute: \"{{ item.ldap_group_id_attribute | default('cn') }}\"\n      group_member_attribute: \"{{ item.ldap_group_member_attribute | default('member') }}\"\n      group_member_format: \"{{ item.ldap_group_member_format | default('uid=${username},ou=users,dc=yourcompany') }}\"\n      user_subtree: \"{{ item.ldap_user_subtree | default(false) }}\"\n      group_subtree: \"{{ item.ldap_group_subtree | default(false) }}\"\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "c1c6bc0100e107ca51f4affffbd5d4dc6b450ac2", "filename": "tasks/setup_user_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: setup_user\n    args: \"{{ item }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "ba60ef482b668e234b90520f8570ea84d03f969a", "filename": "playbooks/provision-dns-server/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# Please see `inventory/dns-server` for an example inventory to be used with\n# this playbook to provision a dns-server\n\n- import_playbook: ../prep.yml\n  tags:\n    - 'never'\n    - 'install'\n\n- import_playbook: ../osp/manage-user-network.yml\n  when:\n    - hosting_infrastructure == 'openstack'\n  tags:\n    - 'never'\n    - 'install'\n\n- import_playbook: ../osp/provision-osp-instance.yml\n  when:\n    - hosting_infrastructure == 'openstack'\n  tags:\n    - 'never'\n    - 'install'\n\n- import_playbook: ../rhsm.yml\n  tags:\n    - 'never'\n    - 'install'\n\n- hosts: dns-server\n  roles:\n    - role: update-host\n  tags:\n    - 'never'\n    - 'install'\n\n- import_playbook: configure-dns-server-bind.yml\n  tags:\n    - 'always'\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "e371e558923517701b00a5d97e36e81a288289e8", "filename": "playbooks/openshift/openstack/provision.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- hosts: localhost\n  pre_tasks:\n  - import_tasks: ../prep-inventory.yml\n  roles:\n  - role: openshift-ansible-contrib/roles/openstack-stack\n    stack_name: \"{{ env_id }}.{{ dns_domain }}\"\n    subnet_prefix: \"{{ openstack_subnet_prefix }}\"\n    ssh_public_key: \"{{ openstack_ssh_public_key }}\"\n    openstack_image: \"{{ openstack_default_image_name }}\"\n    lb_flavor: \"{{ openstack_lb_flavor | default('m1.small') }}\"\n    etcd_flavor: \"{{ openstack_etcd_flavor | default( openstack_default_flavor ) }}\"\n    master_flavor: \"{{ openstack_master_flavor | default( openstack_default_flavor ) }}\"\n    node_flavor: \"{{ openstack_node_flavor | default( openstack_default_flavor ) }}\"\n    infra_flavor: \"{{ openstack_infra_flavor | default( openstack_default_flavor ) }}\"\n    dns_flavor: \"{{ openstack_dns_flavor | default('m1.small') }}\"\n    external_network: \"{{ openstack_external_network_name }}\"\n    num_etcd: \"{{ openstack_num_etcd | default(0) }}\"\n    num_masters: \"{{ openstack_num_masters }}\"\n    num_nodes: \"{{ openstack_num_nodes }}\"\n    num_infra: \"{{ openstack_num_infra }}\"\n    num_dns: \"{{ openstack_num_dns | default(0) }}\"\n    master_volume_size: \"{{ docker_volume_size }}\"\n    node_volume_size: \"{{ docker_volume_size }}\"\n    infra_volume_size: \"{{ docker_volume_size }}\"\n\n- name: Refresh Server inventory\n  hosts: localhost\n  connection: local\n  gather_facts: False\n  tasks:\n  - meta: refresh_inventory\n\n- hosts: cluster_hosts\n  gather_facts: false\n  tasks:\n  - name: Debug hostvar\n    debug:\n      msg: \"{{ hostvars[inventory_hostname] }}\"\n      verbosity: 2\n  - name: waiting for server to come back\n    local_action: wait_for host={{ hostvars[inventory_hostname]['ansible_ssh_host'] }} port=22 delay=30 timeout=300\n    become: false\n\n- hosts: cluster_hosts\n  tasks:\n  - name: Copy the 'private_v4' address out of the 'openstack' section to make it generic\n    set_fact:\n      private_v4: \"{{ openstack.private_v4 }}\"\n  - name: Copy the 'public_v4' address out of the 'openstack' section to make it generic\n    set_fact:\n      public_v4: \"{{ openstack.public_v4 }}\"\n\n- import_playbook: post-provision.yml\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "b51d0ca414e16ea71dd47c32d48f9033ba59db08", "filename": "playbooks/post.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- name: Wait until SSH becomes ready...\n  local_action:\n    module: wait_for\n    port: 22\n    host: \"{{ cloud_instance_ip }}\"\n    search_regex: \"OpenSSH\"\n    delay: 10\n    timeout: 320\n    state: present\n\n- name: A short pause, in order to be sure the instance is ready\n  pause:\n    seconds: 10\n\n- include: local_ssh.yml\n"}, {"commit_sha": "abafe1581c6c78d784cf215b214947675d49eff8", "sha": "5a28f8f7437eedb128a4f27e8fb0e5eb4f710ffb", "filename": "roles/cloud-digitalocean/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: Set the DigitalOcean Access Token fact\n  set_fact:\n    do_token: \"{{ do_access_token }}\"\n\n- name: \"Getting your SSH key ID on Digital Ocean...\"\n  digital_ocean:\n    state: present\n    command: ssh\n    name: \"{{ do_ssh_name }}\"\n    api_token: \"{{ do_access_token }}\"\n  register: do_ssh_key\n\n- name: \"Creating a droplet...\"\n  digital_ocean:\n    state: present\n    command: droplet\n    name: \"{{ do_server_name }}\"\n    region_id: \"{{ do_region }}\"\n    size_id: \"512mb\"\n    image_id: \"ubuntu-16-04-x64\"\n    ssh_key_ids: \"{{ do_ssh_key.ssh_key.id }}\"\n    unique_name: yes\n    api_token: \"{{ do_access_token }}\"\n  register: do\n\n- name: Add the droplet to an inventory group\n  add_host:\n    name: \"{{ do.droplet.ip_address }}\"\n    groups: vpn-host\n    ansible_ssh_user: root\n    ansible_python_interpreter: \"/usr/bin/python2.7\"\n    do_access_token: \"{{ do_access_token }}\"\n    do_droplet_id: \"{{ do.droplet.id }}\"\n    easyrsa_p12_export_password: \"{{ easyrsa_p12_export_password }}\"\n    cloud_provider: digitalocean\n    ipv6_support: yes\n\n- name: Wait for SSH to become available\n  local_action: \"wait_for port=22 host={{ do.droplet.ip_address }} timeout=320\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "3ee3308e8f48c483adac46c6bf30930d1f0219d7", "filename": "roles/pathagar/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Remove if exist pathagar rpm version\n  package: name=pathagar\n           state=absent\n\n- name: Install pathagar pre requisites (both fedora and debian)\n  package: name={{ item }}\n           state=present\n  with_items:\n    - python-virtualenv\n    - python-pip\n    - python-psycopg2\n\n- name: Install pathagar pre requisites for debian\n  package: name={{ item }}\n           state=present\n  with_items:\n    - libapache2-mod-wsgi\n    - libxml2-dev\n    - libxslt-dev\n  when: is_debuntu\n\n- name: Install pathagar pre requisites not debian\n  package: name={{ item }}\n           state=present\n  with_items:\n    - mod_wsgi\n    - libxml2-devel\n    - libxslt-devel\n  when: not is_debuntu\n\n- name: Create destination folder\n  file: path={{ pathagar_src }}\n        state=directory\n        owner=root\n        group=root\n        mode=0755\n\n- name: Create books destination folder\n  file: path={{ pathagar_media }}\n        state=directory\n        owner={{ apache_user }}\n        group={{ apache_user }}\n        mode=0755\n\n- name: Determine if pathagar has already been downloaded from git\n  stat: path=\"{{ pathagar_src }}/settings.py\"\n  register: pathagar\n\n- name: Clone pathagar repo\n  git: repo=https://github.com/PathagarBooks/pathagar.git\n       dest={{ pathagar_src }}\n       update=yes\n       version=master\n  when: internet_available  and pathagar.stat.exists is defined and not pathagar.stat.exists\n\n- name: Install pathagar requirements in a virtualenv\n  pip: name={{ item }}\n  with_items:\n    - Django==1.4.5\n    - django-tagging==0.3.1\n    - django-sendfile==0.3.6\n    - lxml==3.4.4\n  when: internet_available\n\n- name: Install pathagar requirements in a virtualenv\n  pip: name={{ item }}\n       extra_args=\"--use-wheel\"\n       virtualenv={{ pathagar_venv }}\n       virtualenv_site_packages=yes\n  with_items:\n    - django-taggit==0.14\n\n- name: Create pathagar postgresql user\n  postgresql_user: name={{ pathagar_db_user }}\n                   password={{ pathagar_db_password }}\n                   role_attr_flags=NOSUPERUSER,NOCREATEROLE,NOCREATEDB\n                   state=present\n  become: yes\n  become_user: postgres\n\n- name: Start postgresql-iiab\n  service: name=postgresql-iiab\n           state=started\n\n- name: Enable pathagar postgresql user access by md5 method\n  lineinfile: backup=yes\n              dest=/library/pgsql-iiab/pg_hba.conf\n              regexp=\"^host\\s+pathagar\"\n              line=\"host    pathagar        pathagar     samehost     md5\"\n              state=present\n              insertafter=\"^# IPv4 local connections\"\n              owner=postgres\n              group=postgres\n  register: enable_pathagar_md5_access\n\n- name: Reload postgresql service\n  service: name=postgresql-iiab\n           state=reloaded\n  when: enable_pathagar_md5_access.changed\n\n- name: Create pathagar postgresql database\n  postgresql_db: name={{ pathagar_db_name }}\n                 encoding=utf8\n                 owner={{ pathagar_db_user }}\n                 state=present\n                 template=template0\n  become: yes\n  become_user: postgres\n\n- name: Install XS custom settings for patahgar\n  template: src=prod_settings.py\n            dest={{ pathagar_src }}/prod_settings.py\n            owner=root\n            group=root\n            mode=0644\n\n- name: Create pathagar initial db\n  django_manage: app_path={{ pathagar_src }}\n                 command=syncdb\n                 virtualenv={{ pathagar_venv }}\n                 settings=pathagar.prod_settings\n\n- name: Upload pathagar admin user\n  template: src=auth.User.json\n            dest={{ pathagar_dir }}/auth.User.json\n            owner=root\n            group=root\n            mode=0600\n\n- name: Load pathagar admin user\n  django_manage: app_path={{ pathagar_src }}\n                 command=loaddata\n                 virtualenv={{ pathagar_venv }}\n                 settings=pathagar.prod_settings\n                 fixtures={{ pathagar_dir }}/auth.User.json\n\n- name: Collect pathagar static files\n  django_manage: app_path={{ pathagar_src }}\n                 command=collectstatic\n                 virtualenv={{ pathagar_venv }}\n                 settings=pathagar.prod_settings\n\n- name: Install wsgi.py for patahgar\n  template: src=wsgi.py\n            dest={{ pathagar_dir }}/wsgi.py\n            owner=root\n            group=root\n            mode=0644\n\n- name: Install httpd conf for pathagar\n  template: src=pathagar.conf\n            backup=yes\n            dest=/etc/{{ apache_config_dir }}/pathagar.conf\n            mode=0644\n\n- name: Enable pathagar\n  file: path=/etc/apache2/sites-enabled/pathagar.conf\n        src=/etc/apache2/sites-available/pathagar.conf\n        state=link\n  when: pathagar_enabled and is_debuntu\n\n- name: Disable pathagar\n  file: path=/etc/apache2/sites-enabled/pathagar.conf\n        state=absent\n  when: not pathagar_enabled and is_debuntu\n\n- name: Restart http\n  service: name={{ apache_service }}\n           state=reloaded\n\n- name: add pathagar to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=pathagar\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: pathagar\n    - option: description\n      value: '\"Pathagar is a simple bookserver serving OPDS feeds\"'\n    - option: path\n      value: /books\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "cd21505a47e530a967e3c44bd2a772d1b8d08bd7", "filename": "roles/dns/manage-dns-records/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n"}, {"commit_sha": "7032aee7df1c2c6e96795067285efa3b2a6de32e", "sha": "0be6ef623ed65ca2a24acad5378fdc41bc797ee3", "filename": "roles/docker/handlers/main.yml", "repository": "openshift/openshift-ansible-contrib", "decoded_content": "---\n- name: enable docker\n  service: \n    name: docker\n    enabled: yes\n\n- name: restart docker\n  service:\n    name: docker\n    enabled: yes\n    state: restarted\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "06f7c613c443c1fbd4e8d6483787108a78ac1bc3", "filename": "roles/config-docker/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: restart docker\n  service:\n    name: docker\n    state: restarted\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "a90e086ef680c01aac6d84d9683c1010fe043382", "filename": "playbooks/README.md", "repository": "redhat-cop/casl-ansible", "decoded_content": "# The CASL Ansible playbooks\n\n## openshift-cluster-seed.yml (openshift-applier)\n\nThis playbook (and supporting components) have been moved to a separate repo: https://github.com/redhat-cop/openshift-applier\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "05e53d9aa894943a4dde80c1b4282a4ca63ea7dd", "filename": "playbooks/local_ssh.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- name: Ensure the local ssh directory is exist\n  local_action:\n    module: file\n    path: \"~/.ssh/\"\n    state: directory\n\n- name: Copy the algo ssh key to the local ssh directory\n  local_action:\n    module: copy\n    src: \"{{ SSH_keys.private }}\"\n    dest: ~/.ssh/algo.pem\n    mode: '0600'\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "90fd11d32975bbc0f4d852d35978f707895abd78", "filename": "roles/openvpn/templates/xsce-vpn.conf.in", "repository": "iiab/iiab", "decoded_content": "# this file allows changing the world accessable vpn server and its ip address\n#\n# copy this template file to /etc/openvpn/xsce-vpn.conf, and set properly\n\n#  VPNCONFIG=< put the name of the config file in /etc/openvpn you want to use>\n#  VPNIP=<put the ip address of server, pinged to test for existence of vpn tunnel>\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "c37987acff26f48e1cf82dd0529a01be667fbcdb", "filename": "roles/config-redis/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Restart Redis Service\n  systemd:\n    name: \"{{ redis_service }}\"\n    enabled: yes\n    state: restarted\n    daemon_reload: yes\n\n- name: restart firewalld\n  service:\n    name: firewalld\n    state: restarted\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "8d79d8a8515945376be30028eb9a7dd848ec3815", "filename": "playbooks/roles/check_ntp/templates/chrony.j2", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "# Use public servers from the pool.ntp.org project.\n# Please consider joining the pool (http://www.pool.ntp.org/join.html).\n{% for ntp in ntp_servers %}\nserver {{ntp}} iburst\n{% endfor %}\n\n# Record the rate at which the system clock gains/losses time.\ndriftfile /var/lib/chrony/drift\n\n# Allow the system clock to be stepped in the first three updates\n# if its offset is larger than 1 second.\nmakestep 1.0 3\n\n# Enable kernel synchronization of the real-time clock (RTC).\nrtcsync\n\n# Enable hardware timestamping on all interfaces that support it.\n#hwtimestamp *\n\n# Increase the minimum number of selectable sources required to adjust\n# the system clock.\n#minsources 2\n\n# Allow NTP client access from local network.\n#allow 192.168.0.0/16\n\n# Serve time even if not synchronized to a time source.\n#local stratum 10\n\n# Specify file containing keys for NTP authentication.\n#keyfile /etc/chrony.keys\n\n# Specify directory for log files.\nlogdir /var/log/chrony\n\n# Select which information is logged.\n#log measurements statistics tracking\n"}, {"commit_sha": "9662c15ce2e4260fac5cc2bfdf5aaaaf0a2191dd", "sha": "0548d7e2876838a36a4f58985849601e339c8bb4", "filename": "meta/main.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\nallow_duplicates: no\n\n\ngalaxy_info:\n  author: Aur\u00e9lien Wailly\n  description: Ansible role to meet CIS (Center for Internet Security) requirements on ubuntu\n  license: GPLv2\n  min_ansible_version: 1.6\n  platforms:\n    - name: Ubuntu\n      versions:\n        14.04\n  categories:\n    #- cloud\n    #- cloud:ec2\n    #- cloud:gce\n    #- cloud:rax\n    #- clustering\n    #- database\n    #- database:nosql\n    #- database:sql\n    #- development\n    - monitoring\n    #- networking\n    #- packaging\n    - system\n    #- web\n\n\n\ndependencies:\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "3699ffb7d55ccf326c76b4f233a9a02c87b36464", "filename": "roles/deploy/tasks/finalize.yml", "repository": "roots/trellis", "decoded_content": "---\n- include: \"{{ deploy_finalize_before | default('../hooks/example.yml') }}\"\n  tags: deploy-finalize-before\n\n- name: Finalize the deploy\n  deploy_helper:\n    path: \"{{ project_root }}\"\n    release: \"{{ deploy_helper.new_release }}\"\n    state: finalize\n\n- include: \"{{ deploy_finalize_after | default('../hooks/example.yml') }}\"\n  tags: deploy-finalize-after\n\n- debug:\n    msg: \"{{ project_version }}@{{ git_clone.after | truncate(7, True, '') }} deployed as release {{ deploy_helper.new_release }}\"\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "0d025fc07fc90e9fdd0e919f6351b96db450794f", "filename": "playbooks/facts/FreeBSD.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- set_fact:\n    config_prefix: \"/usr/local/\"\n    root_group: wheel\n    ssh_service_name: sshd\n    apparmor_enabled: false\n    strongswan_additional_plugins:\n      - kernel-pfroute\n      - kernel-pfkey\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "2e7d2b67b045b48eda0e11133bdd9449b089e089", "filename": "playbooks/roles/bb0-openstack/tasks/provisioning-dns-nip.io.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "---\n- name: Set public name\n  set_fact:\n    openshift_master_cluster_public_hostname: \"api.{{ instance_data.openstack.public_v4 }}.nip.io\"\n    openshift_master_default_subdomain: \"apps.{{ instance_data.openstack.public_v4 }}.nip.io\"\n    bastion_public_hostname: \"bastion.{{ instance_data.openstack.public_v4 }}.nip.io\"\n  when: ( instance_data.openstack.public_v4 != \"\" and inventory_hostname == \"bastion\" )\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "2cfce0b0cfb3f0c7e9f82daff23c566492069f9c", "filename": "roles/vnstat/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "---\n- name: Install required packages\n  package: name={{ item }}\n           state=present\n  with_items:\n    - vnstat\n  tags:\n    - download\n\n- name: put the config file in place\n  template: src=vnstat.conf.j2\n            dest=/etc/vnstat.conf\n            mode=0744\n            owner=root\n            group=root\n\n- name: create database for wan to collect vnstat data\n  shell: /usr/bin/vnstat -i {{ iiab_wan_iface }}\n\n- name: create database for lan to collect vnstat data if not appliace config\n  shell: /usr/bin/vnstat -i {{ iiab_lan_iface }}\n  when: not iiab_lan_iface == \"\"\n\n- name: start vnstat daemon via systemd\n  service: name=vnstat enabled=yes state=started\n\n- name: Add vnstat to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=vnstat\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: vnstat\n    - option: description\n      value: '\"vnStat is a console-based network traffic monitor for Linux and BSD that keeps a log of network traffic for the selected interface(s).\"'\n    - option: installed\n      value: \"{{ vnstat_install }}\"\n    - option: enabled\n      value: \"{{ vnstat_enabled }}\"\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "e27d909c735b7b339d577657983af9359ddee25a", "filename": "tasks/create_repo_nuget_proxy_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_nuget_proxy\n    args: \"{{ _nexus_repos_nuget_defaults|combine(item) }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "66c49e344024f03bf35a180f346d55138724871c", "filename": "roles/dhcp/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n# Location on target machine to place the config file\ndhcp_config_dest_file: /etc/dhcp/dhcpd.conf\n\n# default name for temp file that is created from the template\ndhcp_config_temp_file: dhcpTempConfigFile\n\n# Temp Directory\ndhcp_config_temp_dir: /tmp\n\n# default location on target machine for testing syntax\ndhcp_config_temp_loc: '{{dhcp_config_temp_dir }}/{{ dhcp_config_temp_file }}'\n\n#default null entries\ndhcp_host_entries: {}\ndhcp_group_entries: {}\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "7d8324770f7b61b664a29e9ae6af5f9f3e993e05", "filename": "roles/dns/manage-dns-zones/tasks/route53/process-views.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- include_tasks: process-zones.yml\n  with_items:\n    - \"{{ dns_data.views }}\"\n  loop_control:\n    loop_var: \"view\"\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "55cb95e3eb006a046d3c2c96e9a300469206f8e4", "filename": "roles/manage-aws-infra/tasks/remove_infra.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "# Remove OCP Cluster instances\n---\n- name: Register instances to be terminated\n  ec2_remote_facts:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    region: \"{{ aws_region }}\"\n    filters:\n      \"tag:env_id\": \"{{ env_id }}\"\n  register: destroy_instances\n\n- name: Ensure ec2 are stopped and terminate protection is disabled\n  ec2:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    region:  \"{{ aws_region }}\"\n    termination_protection: no\n    state: stopped\n    instance_ids: \"{{ item.id }}\"\n    wait: yes\n  with_items:\n    - \"{{ destroy_instances.instances }}\"\n\n- name: Ensure ec2 are terminated\n  ec2:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    region:  \"{{ aws_region }}\"\n    state: \"{{ operation }}\"\n    instance_ids: \"{{ item.id }}\"\n    wait: yes\n  with_items:\n    - \"{{ destroy_instances.instances }}\"\n\n- name: Remove env_id tag to avoid conflicts with same env_id clusters\n  ec2_tag:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    region:  \"{{ aws_region }}\"\n    resource: \"{{ item.id }}\"\n    tags:\n      env_id: terminated\n  with_items:\n    - \"{{ destroy_instances.instances }}\"\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "ad565fb8ef9b8d8a85b9aa79863db3e5042d0b72", "filename": "playbooks/roles/check_networking/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- name: check is net.ipv4.ip_forward turned on\n  command: sysctl -b net.ipv4.ip_forward\n  register: ip_forward_check\n- name: show error\n  debug:\n    msg: \"net.ipv4.ip_forward is 0 forcing it to 1\"\n  when: ip_forward_check.stdout == 0\n- name: force net.ipv4.ip_forward to 1\n  sysctl:\n    name: net.ipv4.ip_forward\n    value: 1\n    sysctl_set: yes\n    state: present\n    reload: yes\n  when: ip_forward_check.stdout == 0\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "ba51a21718ffce6b1687121adbd3a4b0c91bf4dd", "filename": "tasks/remove-docker.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "# Best effort to remove Docker CE and related configuration\n\n- name: Stop Docker service\n  become: yes\n  service:\n    name: docker\n    state: stopped\n  ignore_errors: yes\n\n- name: Ensure Docker CE is removed (CentOS/Fedora/RedHat)\n  become: yes\n  package:\n    name: \"{{ item }}\"\n    state: absent\n  with_items: \"{{ docker_packages }}\"\n  register: _pkg_result\n  until: _pkg_result is succeeded\n  when: _docker_os_dist != \"Ubuntu\" and\n        _docker_os_dist != \"Debian\"\n\n- name: Ensure Docker CE is removed (Ubuntu/Debian)\n  become: yes\n  apt:\n    name: \"{{ item }}\"\n    state: absent\n    purge: yes\n  with_items: \"{{ docker_packages }}\"\n  register: _pkg_result\n  until: _pkg_result is succeeded\n  when: _docker_os_dist == \"Ubuntu\" or\n        _docker_os_dist == \"Debian\"\n\n- name: Remove network interface docker0\n  become: yes\n  command: ip link del docker0\n  args:\n    warn: no\n  ignore_errors: yes\n  changed_when: no\n  tags:\n    - skip_ansible_lint\n\n- name: Remove dockerd from alternatives configuration\n  become: yes\n  shell: alternatives --remove dockerd /usr/bin/dockerd-ce\n  ignore_errors: yes\n  changed_when: no\n  tags:\n    - skip_ansible_lint\n\n- name: Clean yum cache (CentOS/RedHat)\n  become: yes\n  command: yum clean all --enablerepo=\\*\n  args:\n    warn: no\n  changed_when: no\n  when: _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Clean dnf cache\n  become: yes\n  command: dnf clean all --enablerepo=\\*\n  args:\n    warn: no\n  changed_when: no\n  when: _docker_os_dist == \"Fedora\"\n\n- name: Clean apt cache\n  become: yes\n  command: apt-get clean\n  changed_when: no\n  when: _docker_os_dist == \"Ubuntu\" or\n        _docker_os_dist == \"Debian\"\n  tags:\n    - skip_ansible_lint\n\n- name: Remove repository docker specific repo file\n  become: yes\n  yum_repository:\n    name: docker-ce\n    file: docker-ce\n    state: absent\n  when: _docker_os_dist != \"Ubuntu\" and\n        _docker_os_dist != \"Debian\"\n\n- name: Ensure Docker CE and configuration files are removed\n  become: yes\n  file:\n    path: \"{{ item }}\"\n    state: absent\n  with_items:\n    # all distributions\n    - \"{{ docker_envs_dir[_docker_os_dist] }}/docker\"\n    - \"{{ docker_envs_dir[_docker_os_dist] }}/docker-envs\"\n    - /etc/audit/rules.d/docker.rules\n    # centos\n    - /etc/yum.repos.d/docker-ce.repo\n    - /etc/systemd/system/docker.service.d\n    - /etc/docker\n    - /usr/bin/dockerd\n    - /run/docker\n    # ubuntu/debian\n    - /etc/apt/sources.list.d/docker-ce.list\n\n- name: Ensure additional files and data directories are removed\n  become: yes\n  file:\n    path: \"{{ item }}\"\n    state: absent\n  with_items:\n    - /var/lib/docker\n    - /var/lib/docker-engine\n    - \"{{ docker_remove_additional }}\"\n  when: docker_remove_all | bool\n\n- name: Find Docker related diretories in package cache\n  become: yes\n  find:\n    paths: \"{{ _os_pkg_cache_dirs[_docker_os_dist] }}\"\n    file_type: directory\n    recurse: yes\n    patterns: \"docker-ce*\"\n  vars:\n    _os_pkg_cache_dirs:\n      RedHat: /var/cache/yum\n      CentOS: /var/cache/yum\n      Fedora: /var/cache/dnf\n  register: _remove_cache_dirs\n  when: _docker_os_dist == \"Fedora\" or\n        _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Remove dangeling files/directories in package cache\n  become: yes\n  file:\n    path: \"{{ item.path }}\"\n    state: absent\n  with_items: \"{{ _remove_cache_dirs.files }}\"\n  when: _docker_os_dist == \"Fedora\" or\n        _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"RedHat\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "e024cb7d4510eb63e892c87767215250a1e8d6ae", "filename": "playbooks/infra-hosts.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Subscribe the hosts to RHSM'\n  hosts: infra_hosts\n  vars:\n    rhsm_username: \"{{ hostvars['localhost'].rhsm_username|default(omit) }}\"\n    rhsm_password: \"{{ hostvars['localhost'].rhsm_password|default(omit) }}\"\n  roles:\n  - role: rhsm\n  tags:\n  - configure_rhsm\n\n- name: 'Configure networking on the infrastructure hosts'\n  hosts: infra_hosts\n  roles:\n  - role: config-bonding\n  - role: config-vlans\n  - role: config-routes\n  tags: \n  - configure_infra_hosts_networking\n  \n- name: 'Make sure the host is running the latest'\n  hosts: infra_hosts\n  roles:\n  - role: update-host\n  tags: \n  - update_host\n\n- name: 'Setup iSCSI and MultiPathing - if applicable'\n  hosts: infra_hosts\n  roles:\n  - role: config-iscsi-client\n  tags:\n  - configure_iscsi_client\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a01c196db81219812b7e6a57c0b26f24cfe70b50", "filename": "roles/config-openvpn/tasks/prep.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Install required packages'\n  package:\n    name: '{{ item }}'\n    state: installed\n  with_items:\n  - \"{{ openvpn_rpm | default(default_openvpn_rpm) }}\"\n  - firewalld\n  - python-firewall\n\n- name: 'Ensure firewalld is running'\n  service:\n    name: firewalld\n    state: started \n    enabled: yes\n\n- name: 'Open Firewall for OpenVPN use'\n  firewalld: \n    port: \"{{ item }}\"\n    permanent: yes\n    state: enabled\n    immediate: yes\n  with_items:\n  - 443/tcp\n  - 943/tcp\n  - 1194/udp\n\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "f6068f4200221ee758f7a5d828042afbe1689d67", "filename": "tasks/create_repo_yum_group_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_yum_group\n    args: \"{{ _nexus_repos_yum_defaults|combine(item) }}\"\n"}, {"commit_sha": "9662c15ce2e4260fac5cc2bfdf5aaaaf0a2191dd", "sha": "b2162b6241d6055e60c3b057bf078cb25b044990", "filename": "tasks/section_04_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 4.1.1 Restrict Core Dumps (Scored)\n    lineinfile: dest='/etc/security/limits.conf' line=\"* hard core 0\" state=present\n    tags:\n      - section4\n      - section4.1\n      - section4.1.1\n\n  - name: 4.1.2 Restrict Core Dumps (Scored)\n    sysctl: >\n        name=fs.suid_dumpable\n        value=0\n        state=present\n    when: travis_env == False\n    tags:\n      - section4\n      - section4.1\n      - section4.1.2\n\n  - name: 4.1.4 Restrict Core Dumps (stat file) (Scored)\n    stat: path='/etc/init/apport.conf'\n    register: apport_present\n    tags:\n      - section4\n      - section4.1\n      - section4.1.4\n\n  - name: 4.1.5 Restrict Core Dumps (Scored)\n    lineinfile: >\n        dest='/etc/init/apport.conf'\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n    when: apport_present.stat.exists == True\n    tags:\n      - section4\n      - section4.1\n      - section4.1.3\n\n  - name: 4.1.6 Restrict Core Dumps (stat file) (Scored)\n    stat: path='/etc/init/whoopsie.conf'\n    register: whoopsie_present\n    tags:\n      - section4\n      - section4.1\n      - section4.1.4\n\n  - name: 4.1.7 Restrict Core Dumps (Scored)\n    lineinfile: >\n        dest='/etc/init/whoopsie.conf'\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n    when: whoopsie_present.stat.exists == True\n    tags:\n      - section4\n      - section4.1\n      - section4.1.4\n\n  - name: 4.2 Enable XD/NX Support on 32-bit x86 Systems (read dmesg) (Not Scored)\n    shell: 'dmesg | grep NX'\n    register: nx_result\n    failed_when: nx_result.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section4\n      - section4.2\n\n  - name: 4.3 Enable Randomized Virtual Memory Region Placement (Scored)\n    sysctl: >\n       name=kernel.randomize_va_space\n       value=2\n       state=present\n    tags:\n      - section4\n      - section4.3\n\n  - name: 4.4 Disable Prelink (check) (Scored)\n    stat: path=/usr/bin/prelink\n    register: prelink_rc\n    tags:\n      - section4\n      - section4.4\n\n  - name: 4.4 Disable Prelink (restore) (Scored)\n    command: '/usr/bin/prelink -ua'\n    when: prelink_rc.stat.exists == True\n    tags:\n      - section4\n      - section4.4\n\n  - name: 4.4 Disable Prelink (remove) (Scored)\n    apt: purge=yes name='prelink' state=absent\n    when: prelink_rc.stat.exists == True\n    tags:\n      - section4\n      - section4.4\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "7d2f5bf5c84d9fce247738ad20b0865b043e5d43", "filename": "roles/cadvisor/vars/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# vars file for cadvisor\n"}, {"commit_sha": "65a0d28b6ec721aa7a5396f559b1085d61ac3c90", "sha": "b356ef0f506abf91f932c83c23426c5ca1f8a20d", "filename": "tasks/section_02_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 2.1 Create Separate Partition for /tmp (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /tmp\"\n    tags:\n      - section2\n      - section2.1\n\n  - name: 2.2 - 4 Set nodev, nosuid, noexec option for /tmp Partition (Scored)\n    mount: name=\"/tmp\" state=\"mounted\" opts=\"nodev,nosuid,noexec\"\n    when: partitioning==\"true\"\n    tags:\n      - section2\n      - section2.2\n      - section2.3\n      - section2.4\n\n  - name: 2.5 Create Separate Partition for /var (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var\"\n    tags:\n      - section2\n      - section2.5\n\n  - name: 2.6 Bind Mount the /var/tmp directory to /tmp (Scored)\n    mount: name=\"/var/tmp\" src=\"/tmp\" opts=bind state=mounted\n    when: partitioning==\"true\"\n    tags:\n      - section2\n      - section2.6\n\n  - name: 2.7 Create Separate Partition for /var/log (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var/log\"\n    tags:\n      - section2\n      - section2.7\n\n  - name: 2.8 Create Separate Partition for /var/log/audit (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var/log/audit\"\n    tags:\n      - section2\n      - section2.8\n\n  - name: 2.9 Create Separate Partition for /home (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /home\"\n    tags:\n      - section2\n      - section2.9\n\n  - name: 2.10 Add nodev Option to /home (Scored)\n    mount: name:/home state:mounted opts:remount,nodev\n    when: partitioning==\"true\"\n    tags:\n      - section2\n      - section2.10\n\n  - name: 2.11 Add nodev Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nodev option\"\n    tags:\n      - section2\n      - section2.11\n\n  - name: 2.12 Add noexec Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have noexec option\"\n    tags:\n      - section2\n      - section2.12\n\n  - name: 2.13 Add nosuid Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nosuid option\"\n    tags:\n      - section2\n      - section2.13\n\n  - name: 2.14 - 16 Add nodev Option to /run/shm Partition (Scored)\n    mount: name=\"/run/shm\" src=\"/run/shm\" state=\"mounted\" opts=\"nodev,nosuid,noexec\" fstype=\"tmpfs\"\n    tags:\n      - section2\n      - section2.14\n      - section2.15\n      - section2.16\n\n  - name: 2.17.1 Set Sticky Bit on All World-Writable Directories (preparation) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type d -perm -0002 -print 2>/dev/null\n    failed_when: False\n    changed_when: False\n    always_run: True\n    register: sticky_bit_dirs\n    tags:\n      - section2\n      - section2.17\n      - section2.17.1\n\n  - name: 2.17.2 Set Sticky Bit on All World-Writable Directories (Scored)\n    file: path={{ item }} mode=\"a+t\"\n    with_items: sticky_bit_dirs.stdout_lines\n    tags:\n      - section2\n      - section2.17\n      - section2.17.2\n\n  - name: 2.25 Disable Automounting (Scored)\n    lineinfile: >\n        dest=/etc/init/autofs.conf\n        line='#start on runlevel [2345]'\n        regexp='start on runlevel'\n        state=present\n    tags:\n      - section2\n      - section2.25\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "6fa2d9166df503bb30536ffb9a82880f9e61cc05", "filename": "roles/docker/tasks/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# tasks file for docker\n- name: remove docker override\n  file:\n    path: /etc/init/docker.override\n    state: absent\n  notify:\n    - restart docker\n  tags:\n    - docker\n\n- name: configure docker graph directory\n  sudo: yes\n  lineinfile:\n    dest: /etc/default/docker\n    state: present\n    regexp: ^DOCKER_OPTS=.*--graph.*\n    line: 'DOCKER_OPTS=\\\"$DOCKER_OPTS --graph={{ docker_graph_dir }} --dns 172.17.0.1 --dns 8.8.8.8 --dns-search service.{{ consul_domain }} \\\"'\n  notify:\n    - restart docker\n\n- name: configure docker temporary directory\n  sudo: yes\n  lineinfile:\n    dest: /etc/default/docker\n    state: present\n    line: 'DOCKER_TMPDIR=\\\"{{ docker_tmp_dir }}\\\"'\n  notify:\n    - restart docker\n\n- name: configure docker proxy\n  sudo: yes\n  lineinfile:\n    dest: /etc/default/docker\n    state: present\n    line: 'export http_proxy=\\\"{{ http_proxy }}\\\"'\n  when: http_proxy is defined and http_proxy != ''\n\n- name: ensure docker is running (and enable it at boot)\n  service:\n    name: docker\n    state: started\n    enabled: yes\n  tags:\n    - docker\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "2bb988448bf49568509575b2985ac70e42b3b8dc", "filename": "tasks/Win32NT/fetch/openjdk-fallback.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: 'Fetch root page {{ openjdk_root_page }}'\n  win_uri:\n    url: '{{ openjdk_root_page }}'\n    return_content: true\n  register: root_page\n\n- name: Find GA release version\n  set_fact:\n    java_major_version: >-\n      {{ root_page['content']\n        | regex_findall('Ready for use:.*>JDK ([\\d]+)<')\n        | first\n      }}\n\n- name: Out java_major_version\n  debug:\n    var: java_major_version\n\n- name: Fetch GA release page\n  win_uri:\n    url: '{{ openjdk_root_page }}/{{ java_major_version }}/'\n    return_content: true\n    follow_redirects: all\n  register: ga_release_page\n\n- name: Find release url\n  set_fact:\n    release_url: >-\n      {{ ga_release_page['content'] |\n      regex_findall('(https://download[\\.\\w]+/java/GA/jdk' +\n      java_major_version|string +\n      '[.\\d]*/[\\d\\w]+/' +\n      '[.\\d]+/GPL/openjdk-' +\n      java_major_version|string +\n      '[\\d._]+windows-x64_bin[\\w\\d.]+)')\n      }}\n\n- name: Exit if OpenJDK version is not General-Availability Release\n  fail:\n    msg: 'OpenJDK version {{ java_major_version }} not GA Release, or maybe something wrong with java.net'\n  when: release_url[1] is not defined\n\n- name: 'Get artifact checksum {{ release_url[1] }}'\n  win_uri:\n    url: '{{ release_url[1] }}'\n    return_content: true\n  register: artifact_checksum\n\n- name: 'Download artifact from {{ release_url[0] }}'\n  win_get_url:\n    url: '{{ release_url[0] }}'\n    dest: '{{ java_download_path }}'\n    force: true\n    checksum: '{{ artifact_checksum.content }}'\n    checksum_algorithm: sha256\n  register: file_downloaded\n  retries: 20\n  delay: 5\n  until: file_downloaded is succeeded\n  when: ansible_version.full is version('2.8.0', '>=')\n\n- name: Old fetch (Ansible < 2.8)\n  include_tasks: fetch_fallback_old.yml\n  when: ansible_version.full is version('2.8.0', '<')\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "665241fd83881ef5886cf4437922eb9371cdc0fe", "filename": "roles/config-dns-server/test/inventory/group_vars/dns-server.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nnamed_config_recursion: 'no'\nnamed_config_dnssec_enable: 'yes'\nnamed_config_dnssec_validation: 'yes'\nnamed_config_dnssec_lookaside: 'no'\nnamed_config_views:\n- name: private\n  recursion: 'yes'\n  acl_entry: \n  - 192.168.10.0/24\n  zone:\n  - dns_domain: first.example.com\n  - dns_domain: second.example.com\n  - dns_domain: third.example.com\n  - dns_domain: fifth.example.com\n  - dns_domain: forward.example.com\n    type: forward\n    forwarders:\n    - 192.168.10.17\n- name: public\n  zone:\n  - dns_domain: first.example.com\n  - dns_domain: second.example.com\n  - dns_domain: third.example.com\n  - dns_domain: forth.example.com\n  default_forwarders:\n  - 8.8.8.8\n  - 8.8.4.4\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "1d5b833f03874ccf7dc344e91addbaad385e6145", "filename": "roles/deploy/tasks/initialize.yml", "repository": "roots/trellis", "decoded_content": "---\n- include: \"{{ deploy_initialize_before | default('../hooks/example.yml') }}\"\n  tags: deploy-initialize-before\n\n- name: Initialize\n  deploy_helper:\n    path: \"{{ project_root }}\"\n    state: present\n\n- include: \"{{ deploy_initialize_after | default('../hooks/example.yml') }}\"\n  tags: deploy-initialize-after\n"}, {"commit_sha": "c5ca8972146c84a12b80cd589c873884699d06bc", "sha": "a6beea0b093b1b548b749832c2667e1f240e13cd", "filename": "meta/main.yml", "repository": "dev-sec/ansible-nginx-hardening", "decoded_content": "---\ngalaxy_info:\n  author: \"Sebastian Gumprich\"\n  description: 'This Ansible role provides secure nginx configurations. http://dev-sec.io/'\n  company: Hardening Framework Team\n  license: Apache License 2.0\n  min_ansible_version: '1.9'\n  platforms:\n    - name: EL\n      versions:\n        - 6\n        - 7\n    - name: Ubuntu\n      versions:\n        - precise\n        - trusty\n        - xenial\n    - name: Debian\n      versions:\n        - wheezy\n        - jessie\n  galaxy_tags:\n    - system\n    - security\n    - hardening\n    - nginx\ndependencies: []\n"}, {"commit_sha": "481f7ad18dc225973e1d676d33e58c49cbbfe986", "sha": "88c506357dc544dd05c60aabcf7e1432345b920b", "filename": "handlers/main.yml", "repository": "openwisp/ansible-openwisp2", "decoded_content": "### openwisp2\n## handlers\n---\n\n- name: reload systemd\n  systemd: daemon_reload=yes\n  when: ansible_distribution_release in ['jessie', 'xenial']\n\n- name: reload supervisor\n  command: supervisorctl reload\n\n- name: restart nginx\n  service: name=nginx state=restarted\n\n- name: start redis\n  service: name=redis state=started\n\n# TODO: When debian 8 support is removed, this can\n# be removed as well and notify: redis-server can be\n# replaced with notify: redis\n- name: start redis-server\n  service: name=redis-server state=started\n"}, {"commit_sha": "a94f9ce4fa32273fd0fad7492d36db4101423cc3", "sha": "507f2d922e637484bc398f225cd0659a90b1a7b4", "filename": "tasks/remove-pre-docker-ce.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Determine Docker version\n  command: bash -c \"docker version | grep Version | awk '{print $2}'\"\n  ignore_errors: yes\n  changed_when: false\n  register: _cmd_docker_version\n\n- name: Set fact if old Docker installation shall be removed\n  set_fact:\n    remove_old_docker: \"{{ docker_remove_pre_ce | bool }} == true and {{ _cmd_docker_version.stdout_lines[0] | search('-ce') }} == false\"\n  when: _cmd_docker_version.stdout_lines is defined and _cmd_docker_version.stdout_lines[0] is defined\n\n- name: Check if Docker is running\n  become: true\n  command: systemctl status docker\n  ignore_errors: yes\n  changed_when: false\n  register: _service_docker_status\n  when: remove_old_docker | default(false) | bool == true\n\n- name: Stop Docker service\n  service:\n    name: docker\n    state: stopped\n  when: \"_service_docker_status.rc | default(1) == 0\"\n\n- name: Remove old Docker installation before Docker CE\n  become: true\n  package:\n    name: \"{{ item }}\"\n    state: absent\n  when: remove_old_docker|default(false) | bool == true\n  with_items:\n    - \"{{ docker_old_packages[_docker_os_dist] }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "68f0c332170a0ea60d6f2ef6ae814c5b65be13f2", "filename": "playbooks/provision-dns-server/README.md", "repository": "redhat-cop/infra-ansible", "decoded_content": "# DNS Server Playbook\n\nThis playbook directory has the playbook(s) necessary to manage your DNS server(s).\n\n## Prerequisites\n\nOne of the two:\n- a set of running instance(s)\n- a IaaS that allow for provisioning through these playbooks\n\n\n## Example\n\n### Inventory\n\nPlease see the **sample** inventory in the inventory area:\n\n- [dns-server](../../inventory/dns-server/README.md)\n\nYou will need to modify this sample inventory to fit your desired configuration.\n\n### Playbook execution\n\nDepending on how this is being hosted, the initial may need the `tags='install'` set to ensure all necessary software is installed:\n\n```bash\n> ansible-playbook -i inventory main.yml --tags='install'\n```\n\nAny consecutive runs can be done without the 'install' tag to speed up execution:\n```bash\n> ansible-playbook -i inventory main.yml\n```\n\nLicense\n-------\n\nApache License 2.0\n\n\nAuthor Information\n------------------\n\nRed Hat Community of Practice & staff of the Red Hat Open Innovation Labs.\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "e3fcddc5276f70f288bbb5172dba65aa1970fee0", "filename": "roles/sugarizer/meta/main.yml", "repository": "iiab/iiab", "decoded_content": "dependencies:\n#    - { role: mongodb, tags: ['generic','mongodb'], when: sugarizer_install }\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "989e9f1d82560b60b04f027ba26ec010a501c5e6", "filename": "roles/debian_schooltool/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "schooltool_version: schooltool-2.8.5\nschooltool_src: '{{ schooltool_version }}.tar.gz'\ndebian_schooltool_install: True\ndebian_schooltool_enabled: False\n\n"}, {"commit_sha": "481f7ad18dc225973e1d676d33e58c49cbbfe986", "sha": "10efd9f9d269bd2c1fd93b56284758ddd3e65316", "filename": "tasks/complete.yml", "repository": "openwisp/ansible-openwisp2", "decoded_content": "- name: Change superuser password hint\n  when: '\"created\" in load_initial_data_result.stdout'\n  debug:\n    msg: \"Change your admin password at https://{{ inventory_hostname }}/admin/password_change/\"\n"}, {"commit_sha": "79e29502fb4e0ff1c30c0b5396bfa1b48fb84a8e", "sha": "77eaddcc228fe8d7d5ae366a4ed216e7bbc740c0", "filename": "tasks/wp-cli.yml", "repository": "Oefenweb/ansible-wordpress", "decoded_content": "# tasks file for wordpress, wp-cli\n---\n- name: install (wp-cli)\n  get_url:\n    url: https://raw.githubusercontent.com/wp-cli/builds/gh-pages/phar/wp-cli.phar\n    dest: \"{{ wordpress_wp_cli_install_dir }}/wp-cli\"\n    force: true\n    owner: root\n    group: root\n    mode: 0755\n  tags: [configuration, wordpress, wordpress-wp-cli, wordpress-wp-cli-install]\n\n- name: check (wp-cli)\n  command: \"wp-cli --allow-root --no-color --info\"\n  register: check_info\n  failed_when: \"'WP-CLI' not in check_info.stdout\"\n  changed_when: False\n  tags: [configuration, wordpress, wordpress-wp-cli, wordpress-wp-cli-check]\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "75bf5d70ed409662d0ec0bfab1a0eb1a241c7778", "filename": "roles/scm/add-webhooks-github/tests/inventory/host_vars/localhost.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\nansible_connection: local\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "63c631ae92a9ec700fbb9590e642c49cf8ecfb4a", "filename": "roles/osp/admin-instance/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Manage OpenStack instance\n  os_server:\n    cloud: \"{{ item.cloud | default(osp_default_cloud) | default(omit) }}\"\n    state: \"{{ item.state | default(osp_resource_state) | default('present') }}\"\n    name: \"{{ item.name }}\"\n    image: \"{{ item.image | default(omit) }}\"\n    key_name: \"{{ item.key_name | default(omit) }}\"\n    timeout: 200\n    flavor: \"{{ item.flavor | default(omit) }}\"\n    network: \"{{ item.network | default(omit) }}\"\n    security_groups: \"{{ item.security_groups | default(omit) }}\"\n    auto_ip: \"{{ item.auto_ip | default(True) }}\"\n    delete_fip: \"{{ item.delete_fip | default(omit) }}\"\n    volumes: \"{{ item.volumes | default(omit) }}\"\n    meta: \"{{ item.meta | default(omit) }}\"\n  register: os_servers\n  with_items:\n  - \"{{ osp_instances | default([]) }}\"\n\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "96eaf17ea99cdb03b0f6158f0be4aee7e0cf5997", "filename": "tasks/create_repo_docker_hosted_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_docker_hosted\n    args: \"{{ _nexus_repos_docker_defaults|combine(item) }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "48f90166c7ddb736adf5caa58dfdb5d40008e48d", "filename": "roles/elgg/templates/elgg.conf", "repository": "iiab/iiab", "decoded_content": "RewriteEngine on\n\nAlias /elgg /opt/elgg\n<Directory /opt/elgg>\n\tAllowOverride all\n\trequire all granted\n</Directory>\n"}, {"commit_sha": "79e29502fb4e0ff1c30c0b5396bfa1b48fb84a8e", "sha": "8e740bea359aed922e64142595117196fe5fea97", "filename": "handlers/main.yml", "repository": "Oefenweb/ansible-wordpress", "decoded_content": "# handlers file for wordpress\n---\n"}, {"commit_sha": "7032aee7df1c2c6e96795067285efa3b2a6de32e", "sha": "8a4d8d06df6b7ebc6bab73a5e92749343d2ef157", "filename": "roles/subscription-manager/pre_tasks/pre_tasks.yml", "repository": "openshift/openshift-ansible-contrib", "decoded_content": "---\n- name: \"Set password fact\"\n  set_fact:\n    rhsm_password: \"{{ rhsm_password }}\"\n  no_log: true\n  when:\n    - rhsm_password is defined\n    - rhsm_password is not none\n    - rhsm_password|trim != ''\n\n- name: \"Initialize Subscription Manager fact\"\n  set_fact:\n    rhsm_register: true\n\n- name: \"Determine if Subscription Manager should be used\"\n  set_fact:\n    rhsm_register: false\n  when: \n    - rhsm_satellite is undefined or rhsm_satellite is none or rhsm_satellite|trim == ''\n    - rhsm_username is undefined or rhsm_username is none or rhsm_username|trim == ''\n    - rhsm_password is undefined or rhsm_password is none or rhsm_password|trim == ''\n    - rhsm_org is undefined or rhsm_org is none or rhsm_org|trim == ''\n    - rhsm_activationkey is undefined or rhsm_activationkey is none or rhsm_activationkey|trim == ''\n    - rhsm_pool is undefined or rhsm_pool is none or rhsm_pool|trim == ''\n\n- name: \"Validate Subscription Manager organization is set\"\n  fail: msg=\"Cannot register to a Satellite server without a value for the Organization via 'rhsm_org'\"\n  when: \n    - rhsm_org is undefined or rhsm_org is none or rhsm_org|trim == ''\n    - rhsm_satellite is defined\n    - rhsm_satellite is not none\n    - rhsm_satellite|trim != ''\n    - rhsm_register\n\n- name: \"Validate Subscription Manager authentication is defined\"\n  fail: msg=\"Cannot register without ('rhsm_username' and 'rhsm_password') or 'rhsm_activationkey' variables set. See the README.md for details on securely prompting for a password\"\n  when:\n    - (rhsm_username is undefined or rhsm_username is none or rhsm_username|trim == '') or (rhsm_password is undefined or rhsm_password is none or rhsm_password|trim == '')\n    - rhsm_activationkey is undefined or rhsm_activationkey is none or rhsm_activationkey|trim == ''\n    - rhsm_register\n\n- name: \"Validate activation key and Hosted are not requested together\"\n  fail: msg=\"Cannot register to RHSM Hosted with 'rhsm_activationkey'\"\n  when:\n    - rhsm_satellite is undefined or rhsm_satellite is none or rhsm_satellite|trim == ''\n    - rhsm_activationkey is defined\n    - rhsm_activationkey is not none\n    - rhsm_activationkey|trim != ''\n    - rhsm_register\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "aca4baf68132136e919a6ce17a531b3f0e467664", "filename": "roles/kiwix/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "kiwix_url: /kiwix\nkiwix_path: \"{{ iiab_base }}/kiwix\"\nkiwix_port: 3000\niiab_zim_path: /library/zims\nkiwix_library_xml: \"{{ iiab_zim_path }}/library.xml\"\nkiwix_content_path: \"{{ iiab_zim_path }}/content\"\nkiwix_install: True\nkiwix_enabled: True\nkiwix_content_found: False\nkiwix_first_pass: False\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "a4fcaa03610a84d060abaff3865fab613aa94970", "filename": "roles/ansible/tower/manage-job-templates/tests/inventory/group_vars/tower.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ntower_admin_password: \"admin01\"\n\nansible_tower_job_templates:\n- name: \"Job 1\"\n  description: \"My Job 1\"\n  inventory: \"Inventory1\"\n  project: \"Project1\"\n  playbook: \"playbooks/prep.yml\"\n  credential: \"Credential1\"\n  extra_vars: \"---\\\\nhello: world\\\\n\"\n  ask_variables_on_launch: true\n  permissions:\n    teams:\n    - name: team1\n      role: Execute\n    users:\n    - name: user1\n      role: Execute\n"}, {"commit_sha": "045ff4bb9f4720739632aac2951fbf2798a99c8c", "sha": "762740127540701edf488665df488d69d627badf", "filename": "playbooks/local.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- name: Generate the SSH private key\n  local_action: shell echo -e  'n' | ssh-keygen -b 2048 -C {{ SSH_keys.comment }} -t rsa -f {{ SSH_keys.private }} -q -N \"\"\n  args:\n    creates: configs/algo.pem\n\n- name: Generate the SSH public key\n  local_action: shell echo `ssh-keygen -y -f configs/algo.pem` {{ SSH_keys.comment }} > {{ SSH_keys.public }}\n  args:\n    creates: configs/algo.pem.pub\n\n- name: Change mode for the SSH private key\n  local_action: file path=configs/algo.pem mode=0600\n\n- name: Ensure the dynamic inventory exists\n  blockinfile:\n    dest: configs/inventory.dynamic\n    marker: \"# {mark} ALGO MANAGED BLOCK\"\n    create: yes\n    block: |\n      [algo:children]\n      {% for group in dynamic_inventory_groups %}\n      {{ group }}\n      {% endfor %}\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "43a66dc257dbc29cb95aae74ccdc809bef75696d", "filename": "roles/1-prep/tasks/raspberry_pi_2.yml", "repository": "iiab/iiab", "decoded_content": "# Setup specific to the Raspberry Pi\n#\n- name: Add a udev rule to transfer hwclock to system clock at dev creation\n  template: src=92-rtc-i2c.rules\n            dest=/etc/udev/rules.d/92-rtc-i2c.rules\n            owner=root\n            group=root\n            mode=0644\n  when: rtc_id is defined and rtc_id != \"none\"\n\n#\n# RTC requires a change to the device tree (and reboot)\n- name: Check for needing to enable i2c rtc device in config.txt\n  lineinfile: dest=/boot/config.txt\n              line=\"dtoverlay=i2c-rtc,{{ rtc_id }}=on\"\n              state=present\n  register: rpiconfig\n  when: rtc_id != \"none\"\n\n\n- name: Add a udev rule to transfer hwclock to system clock at dev creation\n  template: src=92-rtc-i2c.rules\n            dest=/etc/udev/rules.d/92-rtc-i2c.rules\n            owner=root\n            group=root\n            mode=0644\n  when: rtc_id != \"none\"\n\n- name: pre-Install packages\n  package: name={{ item }}\n           state=latest\n  with_items:\n    - ntp\n\n- name: increase the swap file size (kalite pip download fails)\n  lineinfile: regexp=\"^CONF_SWAPSIZE\"\n              line=CONF_SWAPSIZE=500\n              dest=/etc/dphys-swapfile\n  when: is_debuntu\n\n- name: restart the swap service\n  command: /etc/init.d/dphys-swapfile restart\n  when: is_debuntu\n\n- name: Add rpi rootfs resizing service\n  template: src={{ item.src }}\n            dest={{ item.dest }}\n            owner=root\n            group=root\n            mode={{ item.mode }}\n  with_items:\n    - { src: 'iiab-rpi-max-rootfs.sh', dest: '/usr/sbin/iiab-rpi-max-rootfs.sh', mode: '0755'}\n    - { src: 'iiab-rpi-root-resize.service', dest: '/etc/systemd/system/iiab-rpi-root-resize.service', mode: '0644'}\n\n- name: Enable rootfs resizing service\n  service: name=iiab-rpi-root-resize\n           enabled=yes\n\n"}, {"commit_sha": "7c574f3b148b4df43177a5c0fc398ce4bea6ae3e", "sha": "cd45624b1d723fa48a48310132515cf3dca649a6", "filename": "tasks/pacman_build_depends.yml", "repository": "zzet/ansible-rbenv-role", "decoded_content": "---\n- pacman: name=base-devel state=present update_cache=yes"}, {"commit_sha": "96adc61e360141bb718b75d48c387b3680a8471b", "sha": "856efa5272a2b6e42d7f889b59f268a79c0b1513", "filename": "tasks/setup-repository.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Ensure python and deps for Ansible modules\n  raw: dnf install -y python2 python2-dnf libselinux-python\n  become: true\n  changed_when: false\n  when: _docker_os_dist == \"Fedora\"\n\n- name: Update APT cache\n  apt:\n    update_cache: yes\n  changed_when: false\n  become: true\n  when: _docker_os_dist == \"Ubuntu\" or\n        _docker_os_dist == \"Debian\"\n\n- name: Ensure packages are installed for repository setup\n  package:\n    name: \"{{ item }}\"\n    state: present\n  with_items:\n    - \"{{ docker_repository_related_packages[_docker_os_dist] }}\"\n  become: true\n  when: _docker_os_dist == \"Ubuntu\" or\n        _docker_os_dist == \"Debian\" or\n        _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Add Docker official GPG key\n  apt_key:\n    url: https://download.docker.com/linux/{{ _docker_os_dist|lower }}/gpg\n    state: present\n  become: true\n  when: (_docker_os_dist == \"Ubuntu\" and _docker_os_dist_major_version > '14')\n        or _docker_os_dist == \"Debian\"\n\n- name: Add Docker APT key (alternative for older Ubuntu systems without SNI).\n  shell: \"curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\"\n  args:\n    warn: false\n  become: true\n  changed_when: false\n  when: _docker_os_dist == \"Ubuntu\" and\n        _docker_os_dist_major_version == '14'\n\n- name: Add Docker CE repository (Ubuntu/Debian)\n  apt_repository:\n    repo: deb [arch=amd64] https://download.docker.com/linux/{{ _docker_os_dist|lower }} {{ _docker_os_dist_release }} stable {{ (docker_enable_ce_edge == true) | ternary('edge','') }}\n    state: present\n    filename: 'docker-ce'\n  become: true\n  when: _docker_os_dist == \"Ubuntu\" or\n        _docker_os_dist == \"Debian\"\n\n- name: Add Docker CE repository (Fedora/CentOS/RedHat)\n  get_url:\n    url: \"{{ docker_repository_url[_docker_os_dist] }}\"\n    dest: /etc/yum.repos.d/docker-ce.repo\n    mode: 0644\n  become: true\n  register: docker_repo\n  when: _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"Fedora\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Determine Docker CE Edge repo status (Fedora/CentOS/RedHat)\n  shell: \"{{ docker_cmd_check_edge_repo_status[_docker_os_dist] }}\"\n  args:\n    warn: false\n  ignore_errors: yes\n  changed_when: false\n  register: cmd_docker_ce_edge_enabled\n  when: _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"Fedora\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Set current Docker CE Edge repo status fact (Fedora/CentOS/RedHat)\n  set_fact:\n    _fact_docker_ce_edge_enabled: \"{{ cmd_docker_ce_edge_enabled.stdout == 'enabled = True' }}\"\n  when: _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"Fedora\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Enable/Disable Docker CE Edge Repository (Fedora/CentOS/RedHat)\n  shell: \"{{ docker_cmd_enable_disable_edge_repo[_docker_os_dist] }}\"\n  become: true\n  when: (_docker_os_dist == \"CentOS\" or _docker_os_dist == \"Fedora\" or _docker_os_dist == \"RedHat\") and\n        _fact_docker_ce_edge_enabled != docker_enable_ce_edge\n\n# disable rt-beta so we don't get a 403 error retrieving repomd.xml\n- name: Check if rhel-7-server-rt-beta-rpms Repository is enabled (RedHat)\n  shell: \"subscription-manager repos --list-enabled | grep rhel-7-server-rt-beta-rpms\"\n  become: true\n  register: cmd_rhel_rt_beta_repo_enabled\n  when: _docker_os_dist == \"RedHat\"\n  changed_when: false\n  failed_when: cmd_rhel_rt_beta_repo_enabled.rc not in [ 0, 1 ]\n\n- name: Disable rhel-7-server-rt-beta-rpms Repository (RedHat)\n  shell: \"subscription-manager repos --disable=rhel-7-server-rt-beta-rpms\"\n  become: true\n  when: _docker_os_dist == \"RedHat\" and cmd_rhel_rt_beta_repo_enabled.rc == 0\n\n# container-selinux package wants this\n- name: Check if rhel-7-server-extras-rpms Repository is enabled (RedHat)\n  shell: \"subscription-manager repos --list-enabled | grep rhel-7-server-extras-rpms\"\n  become: true\n  register: cmd_rhel_extras_repo_enabled\n  when: _docker_os_dist == \"RedHat\"\n  changed_when: false\n  failed_when: cmd_rhel_extras_repo_enabled.rc not in [ 0, 1 ]\n\n- name: Enable rhel-7-server-extras-rpms Repository (RedHat)\n  shell: \"subscription-manager repos --enable=rhel-7-server-extras-rpms\"\n  become: true\n  when: _docker_os_dist == \"RedHat\" and cmd_rhel_extras_repo_enabled.rc == 1\n\n- name: Update repository cache\n  shell: \"{{ docker_cmd_update_repo_cache[_docker_os_dist] }}\"\n  args:\n    warn: false\n  become: true\n  when: docker_repo.changed"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "75ad5bdaedccb4d0fac8fbf50a211e78e61b15ab", "filename": "playbooks/roles/check_firewall/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- name: Check that all needed ports are open\n  wait_for:\n    host: \"{{item[0]}}\"\n    port: \"{{item[1]}}\"\n    delay: 0\n    timeout: 1\n  when: item[0] != nodes[0]\n  with_nested:\n  - \"{{ nodes }}\"\n  - \"{{ firewall_ports }}\"\n  ignore_errors: true\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "92ea14d6d0be7f4dde800247a5046f09b976980c", "filename": "roles/kiwix/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "#- name: Set kiwix source file name i686\n#  set_fact:\n#     kiwix_src_file: \"kiwix-linux-i686.tar.bz2\"\n#     kiwix_src_bin_only: False\n#  when: ansible_machine == \"i686\"\n\n- name: Set kiwix source file name x86_64\n  set_fact:\n     kiwix_src_file: \"kiwix-tools_linux64_2017-10-11.tar.gz\"\n     kiwix_src_bin_only: True\n  when: ansible_machine == \"x86_64\"\n\n- name: Set kiwix source file name armv7l\n  set_fact:\n     kiwix_src_file: \"kiwix-tools_armhf_2017-10-11.tar.gz\"\n     kiwix_src_bin_only: True\n  when: ansible_machine == \"armv7l\" or ansible_machine == \"armv6l\"\n\n- name: Get the kiwix software\n  get_url: url=\"{{ iiab_download_url }}/{{ kiwix_src_file }}\"  dest=\"{{ downloads_dir }}/{{ kiwix_src_file }}\"\n  when: internet_available\n\n- include: kiwix_install.yml\n  when: kiwix_src_file is defined\n  tags:\n    - kiwix\n\n- debug:  msg=\"WARNING kiwix source is not defined for your platform\"\n  when: not kiwix_src_file\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "3f654b4b74af2c4874ec403b632f0fe0734d3197", "filename": "roles/haproxy/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ntemp_new_file: '/etc/haproxy/haproxy.cfg.new'\n"}, {"commit_sha": "9662c15ce2e4260fac5cc2bfdf5aaaaf0a2191dd", "sha": "652bdc840882bcd10fa0b521a560196b0e4c1134", "filename": "tasks/main.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - include: section_01.yml\n    tags: section01\n\n  - include: section_02.yml\n    tags: section02\n\n  - include: section_03.yml\n    tags: section03\n\n  - include: section_04.yml\n    tags: section04\n\n  - include: section_05.yml\n    tags: section05\n\n  - include: section_06.yml\n    tags: section06\n\n  - include: section_07.yml\n    tags: section07\n\n  - include: section_08.yml\n    tags: section08\n\n  - include: section_09.yml\n    tags: section09\n\n  - include: section_10.yml\n    tags: section10\n\n  - include: section_11.yml\n    tags: section11\n\n  - include: section_12.yml\n    tags: section12\n\n  - include: section_13.yml\n    tags: section13\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "95dd40ed7fe9d02ed61a7f8816c72935b6e5be66", "filename": "roles/6-generic-apps/meta/main.yml", "repository": "iiab/iiab", "decoded_content": "dependencies:\n   - { role: mysql, tags: ['generic','mysql'], when: mysql_install }\n   - { role: elgg, tags: ['generic','elgg'], when: elgg_install }\n   - { role: owncloud, tags: ['generic','owncloud'], when: owncloud_install }\n   - { role: nextcloud, tags: ['generic','nextcloud'], when: nextcloud_install }\n   - { role: dokuwiki, tags: ['generic','dokuwiki'], when: dokuwiki_install }\n   - { role: wordpress, tags: ['generic','wordpress'], when: wordpress_install }\n   - { role: calibre, tags: ['generic','calibre'], when: calibre_install }\n   - { role: ejabberd, tags: ['generic','ejabberd'], when: ejabberd_install }\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "8028187b830c6ddbada41867715bf45515bd0852", "filename": "playbooks/update-dns-zones.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Update DNS zones'\n  hosts: dns-zones-manage-host\n  roles:\n  - role: dns/manage-dns-zones\n  tags:\n  - update_dns_zones\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "10c2940e5970dee2082e86d97e17a7517f4e1488", "filename": "roles/iiab-admin/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "---\n# must keep roles/0-once/defaults/main.yml sync'd\n# The values here are defaults.\n\niiab_admin_user: iiab-admin\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "fceec03c2b5fc023c0c244992ce2a3cfaae3b473", "filename": "playbooks/container-registry/quay-enterprise.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Preflight Checks\n  hosts: localhost\n  tasks:\n    - name: Validate Required Group Configuration\n      fail:\n        msg: \"'database', 'redis' and 'quay_enterprise' groups must be specified\"\n      when:\n        - \"'redis' not in groups or groups['redis']| length == 0 or 'database' not in groups or groups['database']| length == 0 or 'quay_enterprise' not in groups or groups['quay_enterprise']| length == 0\"\n\n- name: Install Docker\n  hosts: docker_hosts\n  tasks:\n    - name: Configure Docker\n      include_role:\n        name: config-container-storage-setup\n      when: docker_install|default(false)\n\n    - name: Install Docker\n      include_role:\n        name: config-docker\n      when: docker_install|default(false)\n\n- name: Install HAProxy\n  hosts: lb\n  pre_tasks:\n    - name: Setup\n      setup:\n      delegate_to: \"{{ item }}\"\n      delegate_facts: true\n      with_items:\n        - \"{{ groups['quay_enterprise'] }}\"\n  roles:\n    - role: load-balancers/manage-haproxy\n      lb_config:\n        stats_page:\n          enabled: True\n          host_vip: \"{{ haproxy_host_vip | default('*') }}\"\n          host_port: 8080\n          username: \"{{ haproxy_stats_username | default('admin') }}\"\n          password: \"{{ haproxy_stats_password | default('admin') }}\"\n        frontends:\n        - lb_name: quay_http\n          lb_host_vip: \"{{ haproxy_host_vip | default('*') }}\"\n          lb_host_port: 80\n        - lb_name: quay_https\n          lb_host_vip: \"{{ haproxy_host_vip | default('*') }}\"\n          lb_host_port: 443\n        - lb_name: redis\n          lb_host_vip: \"{{ haproxy_host_vip | default('*') }}\"\n          lb_host_port: 6379\n          lb_ssl_enabled: True\n      lb_backend_template: \"{{ playbook_dir }}/templates/haproxy_backend.cfg.j2\"\n\n- name: Install and Configure Database for Quay\n  hosts: database\n  become: True\n  tasks:\n    - name: Install MySQL\n      include_role:\n        name: config-mysql\n      vars:\n        mode: containerized\n        mysql_name: \"{{ quay_database_service_name | default('mysql-quay') }}\"\n        mysql_username: \"{{ quay_database_username }}\"\n        mysql_password: \"{{ quay_database_password }}\"\n        mysql_root_username: \"{{ quay_database_admin_username }}\"\n        mysql_root_password: \"{{ quay_database_admin_password }}\"\n        mysql_database: \"{{ quay_database_name }}\"\n      when: quay_database_type == \"mysql\"\n\n    - name: Install and Configure PostgreSQL for Quay\n      block:\n        - name: Install PostgreSQL for Quay\n          include_role:\n            name: config-postgresql\n          vars:\n            mode: containerized\n            postgresql_name: \"{{ quay_database_service_name | default('postgresql-quay') }}\"\n            postgresql_username: \"{{ quay_database_username }}\"\n            postgresql_password: \"{{ quay_database_password }}\"\n            postgresql_admin_user: \"{{ quay_database_admin_username }}\"\n            postgresql_admin_password: \"{{ quay_database_admin_password }}\"\n            postgresql_port: \"{{ quay_database_port | default('5432') }}\"\n            postgresql_database: \"{{ quay_database_name }}\"\n\n        - name: Flush Handlers\n          meta: flush_handlers\n\n        - name: Sleep to give PostgreSQL a chance to finish starting up\n          pause:\n            seconds: 10\n\n        - name: Locate PostgreSQL Container\n          command: docker ps --filter=name=\"{{ quay_database_service_name | default('postgresql-quay') }}\" -q\n          register: postgresql_container\n\n        - name: Configure PostgreSQL\n          shell: docker exec -i {{ postgresql_container.stdout }} /bin/bash -c 'PGPASSWORD={{ quay_database_admin_password }} psql {{ quay_database_name }} -c \"CREATE EXTENSION pg_trgm;\"'\n          register: shell_result\n          failed_when:\n            - shell_result.rc != 0\n            - \"'already exists' not in shell_result.stderr\"\n      when: quay_database_type == \"postgresql\"\n\n- name: Install Redis\n  hosts: redis\n  become: True\n  tasks:\n    - name: Install Redis\n      include_role:\n        name: config-redis\n      vars:\n        mode: containerized\n\n- name: Install Quay Enterprise\n  hosts: quay_enterprise\n  become: True\n  tasks:\n    - name: Set Quay Hostname When LB Defined\n      set_fact:\n        quay_hostname: \"{{ hostvars[groups['lb'][0]]['inventory_hostname'] }}\"\n      when: quay_hostname is undefined and groups['lb'] | length > 0\n    - name: Set Quay Hostname When LB Not Defined\n      set_fact:\n        quay_hostname: \"{{ hostvars[groups['quay_enterprise'][0]]['inventory_hostname'] }}\"\n      when: quay_hostname is undefined and groups['lb'] | length == 0\n    - name: Install Quay\n      include_role:\n        name: config-quay-enterprise\n      vars:\n        quay_database_username: \"{{ hostvars[groups['database'][0]]['quay_database_username'] }}\"\n        quay_database_password: \"{{ hostvars[groups['database'][0]]['quay_database_password'] }}\"\n        quay_database_name: \"{{ hostvars[groups['database'][0]]['quay_database_name'] }}\"\n        quay_database_port: \"{{ hostvars[groups['database'][0]]['quay_database_port'] }}\"\n        quay_database_host: \"{{ hostvars[groups['database'][0]]['ansible_eth0']['ipv4']['address'] }}\"\n        redis_host: \"{{ quay_hostname | default(hostvars[groups['lb'][0]]['inventory_hostname']) if groups['lb'] | length > 0 else hostvars[groups['redis'][0]]['ansible_eth0']['ipv4']['address'] }}\"\n        quay_server_hostname: \"{{ quay_hostname | default(inventory_hostname) }}\"\n        quay_clair_enable: \"{{ (groups['clair']| length > 0) | ternary('True','False') }}\"\n        quay_clair_endpoint: \"http://{{ hostvars[groups['clair'][0]]['ansible_eth0']['ipv4']['address'] if (groups['clair']| length > 0) else '' }}:{{ clair_endpoint_port | default('6060') }}\"\n        quay_builder_enable: \"{{ (groups['quay_builder']| length > 0) | ternary('True','False') }}\"\n\n- name: Install Clair Database\n  hosts: database\n  become: True\n  tasks:\n    - name: Install and Configure PostgreSQL for Clair\n      include_role:\n        name: config-postgresql\n      vars:\n        mode: containerized\n        postgresql_name: \"{{ clair_database_service_name | default('postgresql-clair') }}\"\n        postgresql_username: \"{{ clair_database_username }}\"\n        postgresql_password: \"{{ clair_database_password }}\"\n        postgresql_admin_user: \"{{ clair_database_admin_username }}\"\n        postgresql_admin_password: \"{{ clair_database_admin_password }}\"\n        postgresql_host_port: \"{{ clair_database_port | default('5433') }}\"\n        postgresql_database: \"{{ clair_database_name }}\"\n      when: groups['clair']| length > 0\n\n- name: Install Clair\n  hosts: clair\n  become: True\n  tasks:\n    - name: Gather facts from machine\n      setup:\n      with_items:\n        - \"{{ groups['quay_enterprise'] }}\"\n    - name: Set Quay Hostname When LB Defined\n      set_fact:\n        quay_hostname: \"{{ hostvars[groups['lb'][0]]['inventory_hostname'] }}\"\n      when: quay_hostname is undefined and groups['lb'] | length > 0\n    - name: Set Quay Hostname When LB Defined\n      set_fact:\n        quay_hostname: \"{{ hostvars[groups['quay_enterprise'][0]]['inventory_hostname'] }}\"\n      when: quay_hostname is undefined and groups['lb'] | length == 0\n\n    - name: Install Clair\n      include_role:\n        name: config-clair\n      vars:\n        database_host: \"{{ hostvars[groups['database'][0]]['ansible_eth0']['ipv4']['address'] }}\"\n        quay_enterprise_address: \"{{ hostvars[groups['quay_enterprise'][0]]['quay_http_protocol'] }}://{{ quay_hostname }}\"\n        clair_ssl_trust_configure: \"{{ hostvars[groups['quay_enterprise'][0]]['quay_ssl_enable']|bool }}\"\n        clair_ssl_trust_src_file: \"{{ hostvars[groups['quay_enterprise'][0]]['quay_ssl_cert_file'] if hostvars[groups['quay_enterprise'][0]]['quay_ssl_enable'] is defined and hostvars[groups['quay_enterprise'][0]]['quay_ssl_enable']|bool else '' }}\"\n        postgresql_port: \"{{ clair_database_port | default('5433') }}\"\n        clair_host_proxy_port: \"{{ clair_endpoint_port | default('6060') }}\"\n\n- name: Install Quay Builder\n  hosts: quay_builder\n  tasks:\n    - name: Gather facts from machine\n      setup:\n      with_items:\n        - \"{{ groups['quay_enterprise'] }}\"\n    - name: Install Quay Enterprise\n      include_role:\n        name: config-quay-builder\n      vars:\n        quay_enterprise_hostname: \"{{ quay_hostname }}\"\n        quay_builder_ssl_trust_configure: \"{{ hostvars[groups['quay_enterprise'][0]]['quay_ssl_enable']|bool }}\"\n        quay_builder_ssl_trust_src_file: \"{{ hostvars[groups['quay_enterprise'][0]]['quay_ssl_cert_file'] if hostvars[groups['quay_enterprise'][0]]['quay_ssl_enable'] is defined and hostvars[groups['quay_enterprise'][0]]['quay_ssl_enable']|bool else '' }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "4a22a90acc41eae83924a813218a9fa365277385", "filename": "roles/debian_schooltool/templates/buildout.cfg", "repository": "iiab/iiab", "decoded_content": "[buildout]\nextends = base.cfg\ndevelop = .\n\n[versions]\n# Unset versions of packages you want to develop\nschooltool =\n\n[package]\neggs += schooltool\n       schooltool.gradebook\n       schooltool.lyceum.journal\n       schooltool.intervention\n\n[test]\neggs = schooltool [test]\n\n# To run selenium tests:\n# - Download standalone selenium server from\n#     http://code.google.com/p/selenium/downloads/list\n# - Start the server: \"java -jar selenium-server-standalone-2.7.0.jar\"\n# - Uncomment the lines below:\n#\n#selenium.default = html_unit\n#selenium.html_unit.web_driver = remote\n#selenium.html_unit.capabilities = HTMLUNITWITHJS\n"}, {"commit_sha": "4eeee9eb934aff6fd8af0b32e75128c884379f1d", "sha": "35f6aa9b209bb1d0520974bfe24ba03854b08e1f", "filename": "tasks/main.yml", "repository": "geerlingguy/ansible-role-solr", "decoded_content": "---\n- include: user.yml\n  when: solr_create_user\n\n- name: Set solr_filename for Solr 4+.\n  set_fact:\n    solr_filename: \"solr-{{ solr_version }}\"\n  when: \"solr_version.split('.')[0] >= '4'\"\n\n- name: Set solr_filename for Solr 3.x.\n  set_fact:\n    solr_filename: \"apache-solr-{{ solr_version }}\"\n  when: \"solr_version.split('.')[0] == '3'\"\n\n- name: Download Solr.\n  get_url:\n    url: \"{{ solr_mirror }}/lucene/solr/{{ solr_version }}/{{ solr_filename }}.tgz\"\n    dest: \"{{ solr_workspace }}/{{ solr_filename }}.tgz\"\n    force: no\n\n- name: Expand Solr.\n  unarchive:\n    src: \"{{ solr_workspace }}/{{ solr_filename }}.tgz\"\n    dest: \"{{ solr_workspace }}\"\n    creates: \"{{ solr_workspace }}/{{ solr_filename }}/CHANGES.txt\"\n    copy: no\n\n# Install Solr < 5.\n- include: install-pre5.yml\n  when: \"solr_version.split('.')[0] < '5'\"\n\n# Install Solr 5+.\n- include: install.yml\n  when: \"solr_version.split('.')[0] >= '5'\"\n\n- name: Ensure solr is started and enabled on boot.\n  service:\n    name: \"{{ solr_service_name }}\"\n    state: started\n    enabled: yes\n"}, {"commit_sha": "8c72df4ecfaa4188202ab0872f4500384ffe5233", "sha": "2eead830a82381b0b3c4096a831aa87c2754a38d", "filename": "tasks/configure-docker.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Ensure /etc/docker directory exists\n  become: true\n  file:\n    path: /etc/docker\n    state: directory\n    mode: 0755\n\n- name: Configure Docker daemon (file)\n  become: true\n  copy:\n    src: \"{{ docker_daemon_config_file }}\"\n    dest: /etc/docker/daemon.json\n  notify: restart docker\n  when: docker_daemon_config_file is defined\n\n- name: Configure Docker daemon (variables)\n  become: true\n  copy:\n    content: \"{{ docker_daemon_config | to_nice_json }}\"\n    dest: /etc/docker/daemon.json\n  notify: restart docker\n  when: docker_daemon_config_file is not defined and\n        docker_daemon_config is defined\n\n- name: Ensure Docker default user namespace is defined in subuid and subgid\n  become: true\n  lineinfile:\n    path: \"{{ item }}\"\n    regexp: '^dockremap'\n    line: 'dockremap:500000:65536'\n  with_items:\n    - /etc/subuid\n    - /etc/subgid\n  when: (_docker_os_dist == \"CentOS\" or _docker_os_dist == \"RedHat\") and\n        ((docker_daemon_config is defined and\n        docker_daemon_config['userns-remap'] is defined and\n        docker_daemon_config['userns-remap'] == 'default') or\n        docker_bug_usermod|bool == true)\n\n- name: Ensure Docker users are added to the docker group\n  become: true\n  user:\n    name: \"{{ item }}\"\n    groups: docker\n    append: true\n  with_items: \"{{ docker_users }}\"\n\n- name: Ensure devicemapper prerequisites are fulfilled\n  block:\n    - name: Ensure lvm2 is installed\n      become: true\n      package:\n        name: lvm2\n        state: present\n\n    - name: Ensure thin-provisioning-tools is installed\n      become: true\n      package:\n        name: thin-provisioning-tools\n        state: present\n      when: (_docker_os_dist == \"Ubuntu\" or (_docker_os_dist == \"Debian\" and _docker_os_dist_major_version > '7'))\n  when:\n    - docker_daemon_config['storage-driver'] is defined\n    - docker_daemon_config['storage-driver'] == 'devicemapper'\n\n\n- name: Enable Docker service\n  become: true\n  service:\n    name: docker\n    enabled: yes\n  notify: restart docker\n  register: _docker_service\n\n- name: Trigger start/restart of Docker\n  service:\n    name: docker\n  notify: restart docker\n  changed_when: _docker_service.status.SubState != \"running\"\n  when: _docker_service.status is defined and _docker_service.status.SubState is defined\n"}, {"commit_sha": "7032aee7df1c2c6e96795067285efa3b2a6de32e", "sha": "d11d4a13f4e7bf4479454ca7fcacdf116644d964", "filename": "roles/dns-server/tasks/main.yml", "repository": "openshift/openshift-ansible-contrib", "decoded_content": "---\n- name: Install bind and bind-utils\n  action: \"{{ ansible_pkg_mgr }} name={{item}} state=latest\"\n  with_items:\n  - bind\n  - bind-utils\n\n- name: Enable named\n  service: name=named enabled=yes\n\n- name: Install firewalld\n  action: \"{{ ansible_pkg_mgr }} name=firewalld state=latest\"\n\n- name: Enable firewalld\n  service: name=firewalld enabled=yes state=started\n\n- name: Open Firewall for DNS\n  firewalld: port={{item}} permanent=yes state=enabled immediate=yes\n  with_items:\n  - 53/tcp\n  - 53/udp\n\n- name: Setup Zone Directory\n  file: \n    dest: /var/named/static \n    state: directory \n    owner: named \n    group: named \n    mode: 0770\n\n- name: Setup ACLs\n  template: \n    src: named.conf.acl.j2\n    dest: /etc/named/named.conf.acl \n    owner: named \n    group: named\n    mode: 0660\n\n- name: Setup DNS Logging configuration\n  template: \n    src: named.conf.logging.j2\n    dest: /etc/named/named.conf.logging\n    owner: named\n    group: named\n    mode: 0660\n\n- name: Setup Views and Zones configuration\n  template:\n    src: named.conf.view.j2\n    dest: /etc/named/named.conf.view\n    owner: named\n    group: named\n    mode: 0660\n\n- name: Setup Controls configuration\n  template:\n    src: named.conf.controls.j2\n    dest: /etc/named/named.conf.controls\n    owner: named\n    group: named\n    mode: 0660\n\n- name: Setup Domain Keys configuration\n  template:\n    src: named.conf.domain-keys.j2\n    dest: /etc/named/named.conf.domain-keys\n    owner: named\n    group: named\n    mode: 0660\n\n- name: Setup key for service named status to communicate with BIND\n  command: \"/sbin/rndc-confgen -a -r /dev/urandom\"\n\n- name: Ensure correct permissions and ownerships on rndc.key file\n  file: path=/etc/rndc.key owner=root group=named mode=0640\n\n- name: Clean out old key files\n  shell: \"rm -f /var/named/K{{ item.0.name }}-{{ item.1.dns_domain }}*\"\n  with_subelements:\n  - named_config_views\n  - zone\n\n- name: Generate keys for nsupdate\n  command: \"/sbin/dnssec-keygen -a HMAC-MD5 -b 512 -n USER -r /dev/urandom -K /var/named {{ item.0.name }}-{{ item.1.dns_domain }}\"\n  with_subelements:\n  - named_config_views\n  - zone\n\n- name: Gather keys for nsupdate\n  shell: \"grep Key: /var/named/K{{ item.0.name }}-{{ item.1.dns_domain }}*.private | cut -d ' ' -f 2\"\n  register: nsupdate_keys\n  with_subelements:\n  - named_config_views\n  - zone\n\n- name: Setup key files for nsupdate\n  template:\n    src: domain-key.j2\n    dest: /var/named/{{ item.item.0.name }}-{{ item.item.1.dns_domain }}.key\n    owner: named\n    group: named\n    mode: 0660\n  with_items: nsupdate_keys.results\n\n- name: Prepare Zone Files\n  template: \n    src: zone.db.j2\n    dest: /var/named/static/{{ item.0.name }}-{{ item.1.dns_domain }}.db\n    owner: named\n    group: named\n    mode: 0660\n  with_subelements:\n  - named_config_views\n  - zone\n\n- name: Configure named\n  copy:\n    src: named.conf\n    dest: /etc/named.conf\n    owner: named\n    group: named \n    mode: 0660\n  \n- name: Configure named options\n  template:\n    src: named.conf.options.j2\n    dest: /etc/named/named.conf.options\n    owner: named\n    group: named \n\n- name: Restart named\n  service: name=named state=restarted\n\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "b044e772219734ae3782cd6e89d9e5fbb490b344", "filename": "roles/serverspec/handlers/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# handlers file for serverspec\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "ef7f1405463aed21210a69c369c13790e01c28fc", "filename": "tasks/keys/apt-key.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: APT OSs) Set Default APT NGINX Signing Key URL\"\n  set_fact:\n    default_keysite: https://nginx.org/keys/nginx_signing.key\n\n- name: \"(Install: APT OSs) Set APT NGINX Signing Key URL\"\n  set_fact:\n    keysite: \"{{ nginx_signing_key | default(default_keysite) }}\"\n\n- name: \"(Install: APT OSs) Add APT NGINX Signing Key\"\n  apt_key:\n    url: \"{{ keysite }}\"\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "c1c06f2e46d8cdebc892409dd5027bf3fb8516b9", "filename": "roles/ansible/tower/manage-credentials/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Set default values\"\n  set_fact:\n    processed_credentials: []\n    existing_crede_output: []\n\n# Utilize the `rest_get` library routine to ensure REST pagination is handled\n- name: \"Get the existing organizations\"\n  rest_get:\n    host_url: \"{{ tower_url }}\"\n    api_uri: \"/api/v2/organizations/\"\n    rest_user: \"{{ tower_admin_username }}\"\n    rest_password: \"{{ tower_admin_password }}\"\n  register: existing_organizations_output\n\n# Utilize the `rest_get` library routine to ensure REST pagination is handled\n- name: \"Get the existing credentials\"\n  rest_get:\n    host_url: \"{{ tower_url }}\"\n    api_uri: \"/api/v2/credentials/\"\n    rest_user: \"{{ tower_admin_username }}\"\n    rest_password: \"{{ tower_admin_password }}\"\n  register: existing_credentials_output\n\n# Utilize the `rest_get` library routine to ensure REST pagination is handled\n- name: \"Get the existing credential types\"\n  rest_get:\n    host_url: \"{{ tower_url }}\"\n    api_uri: \"/api/v2/credential_types/\"\n    rest_user: \"{{ tower_admin_username }}\"\n    rest_password: \"{{ tower_admin_password }}\"\n  register: existing_credential_types_output\n\n- name: \"Process the inventory credentials\"\n  include_tasks: process-credential.yml\n  with_items:\n  - \"{{ ansible_tower_credentials }}\"\n  loop_control:\n    loop_var: credential\n\n- name: \"Elminate the credentials that should not be present\"\n  uri:\n    url: https://localhost/api/v2/credentials/{{ item.id }}/\n    method: DELETE\n    user: admin\n    password: \"{{ tower_admin_password }}\"\n    validate_certs: no\n    status_code: 200,204\n  with_items:\n  - \"{{ existing_credentials_output.rest_output | get_remaining_items(processed_credentials, 'name', 'name')}}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "c5e35b2f1a6274af4545f02621af9143e84a913d", "filename": "playbooks/osp/install-osp-cluster.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_playbook: ../infra-hosts.yml\n\n- hosts: infra_osp_hosts\n  roles:\n  - { role: config-software-src, when: '\"controller\" in osp_roles' }\n\n- hosts: infra_osp_hosts\n  roles:\n  - role: osp/packstack-install\n  - role: osp/packstack-post\n\n- import_playbook: update-osp-cluster-admin.yml\n\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "212a57e1edb23ba29c33a964c25eea86acda5675", "filename": "tasks/configure-docker/configure-systemd.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "- name: Combine all systemd service configuration options\n  set_fact:\n    _systemd_service_config: \"{{ docker_systemd_service_config_tweaks + docker_systemd_service_config }}\"\n\n- name: Ensure /etc/systemd/system/docker.service.d directory exists\n  become: true\n  file:\n    path: /etc/systemd/system/docker.service.d\n    state: directory\n    mode: 0755\n\n- name: Setup default Docker drop-in to enable use of environment file\n  become: true\n  template:\n    src: drop-ins/default.conf.j2\n    dest: /etc/systemd/system/docker.service.d/default.conf\n  register: _systemd_docker_dropin\n  notify: restart docker\n  vars:\n    systemd_envs_dir: \"{{ docker_envs_dir[_docker_os_dist] }}\"\n    systemd_service_conf: \"{{ _systemd_service_config }}\"\n\n- name: Combine Docker daemon environment variable configuration\n  set_fact:\n    docker_service_envs: \"{{ docker_service_envs | combine(_docker_service_opts) | combine(docker_daemon_envs) }}\"\n  vars:\n    _docker_service_opts:\n      DOCKER_OPTS: \"{{ docker_daemon_opts }}\"\n\n- name: Setup Docker environment file {{ docker_envs_dir[_docker_os_dist] }}/docker-envs\n  become: true\n  template:\n    src: docker-envs.j2\n    dest: \"{{ docker_envs_dir[_docker_os_dist] }}/docker-envs\"\n  notify: restart docker\n  vars:\n    docker_envs: \"{{ docker_service_envs }}\"\n\n- name: Force daemon reload of systemd\n  become: true\n  systemd:\n    daemon_reload: yes\n  notify: restart docker\n  when: _systemd_docker_dropin is changed\n  tags:\n    - skip_ansible_lint"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "739e1d363e8600cc45750e653f39fa79606f2a35", "filename": "roles/kalite/README.rst", "repository": "iiab/iiab", "decoded_content": "==============\nKA-Lite README\n==============\n\nThis role installs KA-Lite, an offline version of the Khan Academy (https://www.khanacademy.org/),\nwritten by Learning Equality (https://learningequality.org/ka-lite/).\n\nKA Lite has two servers, a light httpd server that serves KA videos, and a cron server that sets\nup cron jobs to download language packs and KA videos from the internet.  There are separate flags\nto enable these two servers.\n\nAccess\n------\n\nIf enabled and with the default settings KA Lite should be accessible at http://schoolserver:8008/\n\nTo login to kalite enter\n\nUser Name: Admin\nPassword: changme\n\nBulk Loading Videos\n-------------------\n\nVideos and their corresponding png images can be copied into /library/ka-lite/content and will\nbe recognized the next time kalite is started.  The kalite website has instructions on getting\nvideos with bitsync.  These videos are also smaller than the ones downloaded with the kalite\nadmin interface.\n\nConfiguration Parameters\n------------------------\n\nPlease look in defaults/main.yml for the default values of the various install parameters.  Everything\nin this readme assumes the default values.\n\nTrouble Shooting\n----------------\n\nStarting with kalite 0.15 you can run the server manually with the following commands:\n\n* systemctl stop kalite-serve (make sure the systemd service is not running)\n* export KALITE_HOME=/library/ka-lite (point kalite to the right environment)\n* kalite start (start the server; can take more than 10 minutes in some environment)\n\nTo return to using the systemd unit:\n\n* export KALITE_HOME=/library/ka-lite (point kalite to the right environment)\n* kalite stop\n* systemctl start kalite-serve\n"}, {"commit_sha": "51dcdf691a7801895b569a5a927e30030d8feb70", "sha": "e770518f778acf487f0d9c8cd53380bbcabd9bc7", "filename": "tasks/openbsd_service.yml", "repository": "nusenu/ansible-relayor", "decoded_content": "---\n\n\n# OpenBSD section (uses service module)\n# This is basically a copy from the Linux\n# section, but it requires different service\n# names and additional arguments.\n# =====================================\n\n# OpenBSD does not support multi-instance rc.d\n# # so we link as many pseudo rc scripts as we need.\n# # OpenBSD does not like dots in rc filenames so\n# # we replace them with underscores.\n- name: Create links to the service files (OpenBSD)\n  become: yes\n  file: src=/etc/rc.d/tor state=link path=/etc/rc.d/tor{{ item[0]| replace('.','_') }}_{{ item.1.orport }}\n  with_nested:\n   - tor_ips\n   - tor_ports\n\n- name: Ensure Tor instances are enabled and started (OpenBSD)\n  become: yes\n  service: name=tor{{ item[0]|replace('.','_') }}_{{ item.1.orport }}\n   arguments=\"-f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\" enabled=yes state=started\n  with_nested:\n   - tor_ips\n   - tor_ports\n\n- name: Ensure Tor instances are reloaded if its torrc changed (OpenBSD)\n  become: yes\n  service: name=tor{{ item.item[0]|replace('.','_') }}_{{ item.item.1.orport }} state=reloaded\n  with_items: instances.results\n  when: item.changed == True\n  tags:\n   - reconfigure\n"}, {"commit_sha": "b7c6bfe0369646ca69beeb3dfe07e8218d61c940", "sha": "5d3cacf7ee3b2a20e3db1ec28617f93c0cca252b", "filename": "tasks/profile.yml", "repository": "dev-sec/ansible-os-hardening", "decoded_content": "---\n- name: add pinerolo_profile.sh to profile.d\n  template:\n    src: 'profile.conf.j2'\n    dest: '/etc/profile.d/pinerolo_profile.sh'\n    owner: 'root'\n    group: 'root'\n    mode: '0750'\n  when: not os_security_kernel_enable_core_dump\n  \n- name: remove pinerolo_profile.sh from profile.d\n  file:\n    path: /etc/profile.d/pinerolo_profile.sh\n    state: absent\n  when: os_security_kernel_enable_core_dump\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "9a3f717c8fae226b9a9e8adf524b721e5c7622fe", "filename": "tasks/Linux/fetch/security-fetch/security-fetch-local.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Copy security policy artifact to destination\n  copy:\n    src: '{{ java_unlimited_policy_transport_local }}'\n    dest: '{{ java_download_path }}'\n  register: policy_file_downloaded\n  retries: 5\n  delay: 2\n  until: policy_file_downloaded is succeeded\n\n- name: Downloaded artifact\n  set_fact:\n    security_policy_java_artifact: '{{ policy_file_downloaded.dest }}'\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "4db354d08cd2ba946178f3b8fe3ecbcbe0e39bca", "filename": "roles/ovirt-guest-agent/handlers/main.yaml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\n- name: enable and start {{ ovirt_guest_agent_pkg_prefix }}-guest-agent\n  service:\n    name: \"{{ ovirt_guest_agent_pkg_prefix }}-guest-agent\"\n    state: started\n    enabled: yes\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "1b9624d62e2a3678762bff5ba535d6fd40d2ded2", "filename": "roles/osp/admin-network/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: \"manage-networks.yml\"\n\n- import_tasks: \"manage-subnets.yml\"\n\n- import_tasks: \"manage-routers.yml\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "5dcbb13c5ce3eab30ee0d33c18da4eec1a74e88a", "filename": "roles/4-server-options/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Server Options Installed\n  command: echo Server Options Installed\n\n# this script can be sourced to get iiab location\n- name: Create iiab.env file\n  template: src=roles/1-prep/templates/iiab.env.j2\n            dest=/etc/iiab/iiab.env\n            owner=root\n            group=root\n            mode=0644\n\n- name: put a python interface to iiab.env\n  template: src=roles/1-prep/templates/iiab_env.py.j2\n            dest=/etc/iiab/iiab_env.py\n\n- name: generate the offline documents\n  command: /usr/bin/iiab-refresh-wiki-docs\n  when: not nodocs\n\n- name: Stop postgresql service\n  command: \"/etc/init.d/postgresql stop\"\n  ignore_errors: True\n  when: postgresql_install and is_debuntu\n\n- name: Start postgresql service\n  service: name=postgresql-iiab\n           state=restarted\n           enabled=yes\n  when: postgresql_enabled\n\n- name: Stop authserver service\n  service: name=xs-authserver\n           state=stopped\n           enabled=no\n  when: not authserver_enabled and authserver_install\n\n- name: Start xs-authserver service\n  service: name=xs-authserver\n           state=restarted\n  when: authserver_enabled\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "cab27676d474763c70c26a13fcd0c65e0fd2b9e3", "filename": "roles/dns/manage-dns-zones/tasks/route53/prereq.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Fail when AWS KEY environment variables are not defined\n  debug:\n    msg: \"Both 'AWS_ACCESS_KEY_ID' and 'AWS_SECRET_ACCESS_KEY' environment variables must be defined\"\n  failed_when: (lookup('env','AWS_ACCESS_KEY_ID')|trim == \"\") or\n               (lookup('env','AWS_SECRET_ACCESS_KEY')|trim == \"\")\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "5aa35b925b6408217bc6c80845226c4f0f1ef644", "filename": "roles/config-nagios-target/tasks/nrpe.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Include Docker related configuration (if enabled)\n  when: '\"docker\" in nagios_services'\n  include_tasks: nrpe_docker.yml\n\n- name: Include DNS related configuration (if enabled)\n  when: '\"dns\" in nagios_services'\n  include_tasks: nrpe_dns.yml\n\n- name: Include NFS related configuration (if enabled)\n  when: '\"nfs\" in nagios_services'\n  include_tasks: nrpe_nfs.yml\n\n- name: Include Memory related configuration\n  import_tasks: nrpe_mem.yml\n\n- name: Include Disk related configuration\n  import_tasks: nrpe_disk.yml\n\n- name: Include OpenShift Master related configuration (if enabled)\n  when: '\"openshift-master\" in nagios_services'\n  include_tasks: nrpe_openshift_master.yml\n\n- name: Include OpenShift Node related configuration (if enabled)\n  when: '\"openshift-node\" in nagios_services'\n  include_tasks: nrpe_openshift_node.yml\n\n- name: Adjust the number of total processes allowed\n  lineinfile:\n    dest: /etc/nagios/nrpe.cfg\n    regexp: '^command.check_total_procs.=.+check_procs .*'\n    line: 'command[check_total_procs]=/usr/lib64/nagios/plugins/check_procs -w 350 -c 400'\n    state: present\n\n- name: Build list of nagios servers for use with access list\n  set_fact:\n    access_servers: \"{{ item }},{{ access_servers | default('') }}\"\n  with_items: \"{{groups['nagios-servers']}}\"\n\n- name: Ensure access is allowed for the nagios server(s)\n  lineinfile:\n    dest: /etc/nagios/nrpe.cfg\n    regexp: '^allowed_hosts='\n    line: \"allowed_hosts={{ access_servers }}\"\n\n- name: Set Firewall Configuration\n  set_fact:\n    firewall_port: 5666\n    firewall_protocol: \"tcp\"\n \n- name: Update the firewall configuration\n  import_tasks: firewall.yml\n\n- name: Ensure NRPE is enabled at boot\n  service:\n    name: nrpe\n    enabled: yes\n\n- name: Restart NRPE\n  service:\n    name: nrpe\n    state: restarted\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "93ef6f2344d0ae44313b455a1693bdc9d8cee114", "filename": "roles/teamviewer/tasks/install.yml", "repository": "iiab/iiab", "decoded_content": "# we need to install X11 and the xfce display manager\n- name: Install xfce group of packages\n  shell: \"yum groupinstall -y xfce\"\n  when: xo_model == \"none\" and internet_available  and ansible_distribution_version <= \"20\"\n  tags:\n    - download\n\n- name: Install X11 group of packages\n  shell: \"yum groupinstall -y 'X Window system'\"\n  when: xo_model == \"none\" and internet_available  and ansible_distribution_version <= \"20\"\n  tags:\n    - download\n\n- name: Install xfce group of packages\n  shell: yum groupinstall -y \"Xfce Desktop\" --exclude fedora-release\\*\n  when: xo_model == \"none\" and internet_available  and ansible_distribution_version >= \"21\"\n  tags:\n    - download\n\n- name: Install X Windows on CentOS\n  shell: yum groupinstall -y \"Server with GUI\"\n  when: internet_available  and ansible_distribution == \"CentOS\"\n  tags:\n    - download\n\n- name: Get the teamviewer software\n  get_url: url=\"{{ teamviewer_url }}/{{ teamviewer_rpm_file }}\"  dest=\"{{ yum_packages_dir }}/{{ teamviewer_rpm_file }}\"\n  when: internet_available\n  tags:\n    - download\n\n# F22 has issues with yum localinstall exclude for now\n- name: Do the install of teamviewer, pulling in any required dependencies\n  shell: \"yum localinstall -y {{ yum_packages_dir }}/{{ teamviewer_rpm_file }}\"\n  when: teamviewer_install and internet_available\n           and xo_model == \"none\" and ansible_distribution_version <= \"21\"\n\n- name: making local copy available\n  shell: createrepo {{ yum_packages_dir }}\n  when: teamviewer_install and xo_model == \"none\" and ansible_distribution_version >= \"22\"\n\n- name: using local copy\n  package: name={{ item }}\n           state=present\n  with_items:\n   - teamviewer*\n  when: teamviewer_install and xo_model == \"none\" and ansible_distribution_version >= \"22\"\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "8f8238e88b930ed68b794c24a667378510aa44b7", "filename": "roles/wordpress-setup/tasks/database.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Create database of sites\n  mysql_db:\n    name: \"{{ site_env.db_name }}\"\n    state: present\n    login_host: \"{{ site_env.db_host }}\"\n    login_user: \"{{ mysql_root_user }}\"\n    login_password: \"{{ mysql_root_password }}\"\n  with_dict: \"{{ wordpress_sites }}\"\n  when: not mysql_remote_database and item.value.db_create | default(True)\n\n- name: Create/assign database user to db and grant permissions\n  mysql_user:\n    name: \"{{ site_env.db_user }}\"\n    password: \"{{ site_env.db_password }}\"\n    append_privs: yes\n    priv: \"{{ site_env.db_name }}.*:ALL\"\n    state: present\n    login_host: \"{{ site_env.db_host }}\"\n    login_user: \"{{ mysql_root_user }}\"\n    login_password: \"{{ mysql_root_password }}\"\n  with_dict: \"{{ wordpress_sites }}\"\n  when: not mysql_remote_database and item.value.db_create | default(True)\n\n- name: Copy database dump\n  copy:\n    src: \"{{ item.value.db_import }}\"\n    dest: /tmp\n  with_dict: \"{{ wordpress_sites }}\"\n  when: item.value.db_import | default(False)\n\n- name: Import database\n  mysql_db:\n    name: \"{{ site_env.db_name }}\"\n    state: import\n    target: \"/tmp/{{ item.value.db_import | basename }}\"\n    login_host: \"{{ site_env.db_host }}\"\n    login_user: \"{{ site_env.db_user }}\"\n    login_password: \"{{ site_env.db_password }}\"\n  with_dict: \"{{ wordpress_sites }}\"\n  when: item.value.db_import | default(False)\n  notify: reload nginx\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "e27d2cf2f2f77ef098fd63836ab9a17d4b3f5aef", "filename": "roles/dns/manage-dns-zones-bind/tasks/process-one-zone.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Set Zone state\n  set_fact:\n    zone_state: \"{{ (zone.state is defined) | ternary(zone.state, view.state | default('present')) }}\"\n\n- name: Remove Zone files if state is 'absent'\n  file:\n    path: \"{{ item }}\"\n    state: absent\n  ignore_errors: True\n  with_items:\n    - \"/var/named/static/{{ view.name + '-' + zone.dns_domain }}.db\"\n  when:\n    - zone_state == 'absent'\n\n- block:\n  - name: Prepare Zone Files\n    vars:\n      zone_dns_domain: \"{{ zone.dns_domain }}\"\n    template:\n      src: zone.db.j2\n      dest: \"/var/named/static/{{ view.name + '-' + zone.dns_domain }}.db\"\n      owner: \"{{ bind_user }}\"\n      group: \"{{ bind_group }}\"\n      mode: 0660\n    notify: restart named\n\n  - name: Prepare the zone config content\n    vars:\n      zone_type: \"{{ zone.type | default('master') }}\"\n      zone_dns_domain: \"{{ zone.dns_domain }}\"\n      zone_forwarders: \"{{ zone.forwarders | default([]) }}\"\n      view_name: \"{{ view.name }}\"\n    template:\n      src: zone-config.j2\n      dest: \"{{ dns_zone_temp_config_dir }}/{{ view.name }}/0002-{{ zone.dns_domain }}.cfg\"\n      owner: \"{{ bind_user }}\"\n      group: \"{{ bind_group }}\"\n      mode: 0660\n\n  - name: \"Set flag that a zone was processed\"\n    set_fact:\n      processed_zones: True\n  when:\n    - zone.named is defined\n    - zone.named|bool != False\n    - zone_state == 'present'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a1fa87c8facc6fc308ec78bcf7651fa89590c69a", "filename": "roles/ansible/tower/manage-workflow-templates/tasks/process-workflow-node.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Find id of current job\"\n  set_fact:\n    job_template_id: \"{{ job_template.id }}\"\n  when:\n    - job_template.name == workflow_node.job_name\n  with_items:\n    - \"{{ existing_job_templates_output.rest_output }}\"\n  loop_control:\n    loop_var: job_template\n\n- name: \"Set the workflow template endpoint\"\n  set_fact:\n    workflow_template_endpoint: |-\n      {{'/api/v2/workflow_job_templates/{{ workflow_template_id }}/workflow_nodes/'\n      if (workflow_node.type == 'start') else\n      '/api/v2/workflow_job_template_nodes/{{ job_node_uids[workflow_node.parent_index] }}/{{ workflow_node.type }}/'}}\n\n- name: \"Load up the workflow nodes template\"\n  uri:\n    url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}{{ workflow_template_endpoint }}\"\n    user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n    password: \"{{ ansible_tower.admin_password }}\"\n    force_basic_auth: yes\n    method: POST\n    body: \"{{ lookup('template', 'workflow-node-template.j2') }}\"\n    body_format: 'json'\n    headers:\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n    validate_certs: no\n    status_code: 200,201,400\n  register: workflow_node_output\n\n- name: \"Add id to dictionary\"\n  set_fact:\n    job_node_uids: \"{{ job_node_uids|default({}) | combine({ workflow_node.index : workflow_node_output.json.id }) }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "8280be817930786d1743304211ede82b73f2e789", "filename": "playbooks/minishift-remote/configure-minishift-remote.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n\n- name: Configure Minishift Remote Machine\n  hosts: minishift_remote\n  tasks:\n    - name: Configure prerequisites\n      import_tasks: prerequisites.yml\n      when: (install_prerequisites | bool) | default(False)\n\n    - name: Setup Remote Machine to Host Minishift\n      import_role:\n        name: config-minishift-remote"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "737b5a1e7856cab4a465c774027d0b35bcbafd4b", "filename": "roles/setup-slack/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\nslack_channels: {}\nslack_users: {}\n"}, {"commit_sha": "a94f9ce4fa32273fd0fad7492d36db4101423cc3", "sha": "0a3d1ef72f190984235d6bd491ac362fe6df630c", "filename": "tasks/install-docker.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Set docker-ce package state to latest\n  set_fact:\n    docker_pkg_state: 'latest'\n  when: docker_latest_version|bool\n\n- name: Ensure docker-ce is installed\n  become: true\n  package:\n    name: \"{{ docker_pkg_name }}\"\n    state: \"{{ docker_pkg_state|default('present') }}\"\n  notify: restart docker\n"}, {"commit_sha": "51dcdf691a7801895b569a5a927e30030d8feb70", "sha": "81339b6aeb0eb2caf66576e4691e2e3130e310b5", "filename": "tasks/freebsd_service.yml", "repository": "nusenu/ansible-relayor", "decoded_content": "---\n\n- name: Ensure PidDir exists (FreeBSD)\n  become: yes\n  file: path={{ tor_PidDir }}\n    state=directory\n    owner=root\n    mode=0755\n\n- name: Ensure PidDir is owned by per-instance tor_user (FreeBSD)\n  become: yes\n  file: path={{ tor_PidDir }}/{{ item[0] }}_{{ item.1.orport }}\n    state=directory\n    owner=_tor-{{ item[0] }}_{{ item.1.orport }}\n    mode=0700\n  with_nested:\n   - tor_ips\n   - tor_ports\n\n- name: Ensure Tor instances are reloaded if its torrc changed (FreeBSD)\n  become: yes\n  shell: \"kill -HUP `cat {{ tor_PidDir }}/{{ item.item[0] }}_{{ item.item.1.orport }}/pid`\"\n  ignore_errors: yes\n  with_items: instances.results\n  when: item.changed == True\n  tags:\n   - reconfigure\n\n- name: Ensure Tor instances are running (FreeBSD)\n  become: yes\n  shell: \"kill -0 `cat {{ tor_PidDir }}/{{ item[0] }}_{{ item.1.orport }}/pid` || tor -f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "6de2b666d21a276d3f9c3542b8096be694188887", "filename": "roles/idm-host-cert/tasks/print-certs.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Print Host Cert - if requested\"\n  debug:\n    msg: \"{{ host_cert.json.result.result.certificate }}\"\n    verbosity: 2\n\n- name: \"Print Host Key - if requested\"\n  debug:\n    msg: \"{{ csr_content.key }}\"\n    verbosity: 2\n\n- name: \"Print CA cert - if requested\"\n  debug:\n    msg: \"{{ ca_cert.json.result.result.certificate }}\"\n    verbosity: 2\n"}, {"commit_sha": "79e29502fb4e0ff1c30c0b5396bfa1b48fb84a8e", "sha": "82032fd8f43a39349ed4da82507458c4a4c2de88", "filename": "tasks/plugins.yml", "repository": "Oefenweb/ansible-wordpress", "decoded_content": "# tasks file for wordpress, plugins\n---\n- name: identify installation (plugin)\n  shell: \"wp-cli --allow-root --no-color --path='{{ item.0.path }}' plugin is-installed {{ item.1 }}\"\n  register: check_installation_plugins\n  failed_when: False\n  changed_when: False\n  with_subelements:\n    - wordpress_installs\n    - plugins\n  when: item.1\n  tags: [configuration, wordpress, wordpress-plugins, wordpress-is-installed-plugin]\n\n- name: install (plugin)\n  shell: \"wp-cli --allow-root --no-color --path='{{ item.item.0.path }}' plugin install {{ item.item.1 }} --activate\"\n  with_items: check_installation_plugins.results\n  when: check_installation_plugins is defined and item.item.1 and item.rc != 0\n  tags: [configuration, wordpress, wordpress-plugins, wordpress-install-plugin]\n\n- name: check install (plugin)\n  shell: \"wp-cli --allow-root --no-color --path='{{ item.0.path }}' plugin is-installed {{ item.1 }}\"\n  changed_when: False\n  with_subelements:\n    - wordpress_installs\n    - plugins\n  when: item.1\n  tags: [configuration, wordpress, wordpress-plugins, wordpress-install-plugin-check]\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "7d7bf5490ef95a9fe0a71379d744a66eb7326633", "filename": "roles/weave/handlers/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# handlers file for weave\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "ff41469276338457cb4b2afc4198c4b47f7cbf3e", "filename": "roles/ansible/tower/manage-workflow-templates/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- block:\n  - name: \"Initialize facts\"\n    set_fact:\n      existing_workflow_templates_output: []\n      existing_job_templates_output: []\n      existing_users_output: []\n      existing_teams_output: []\n      processed_workflow_templates: []\n\n  # Utilize the `rest_get` library routine to ensure REST pagination is handled\n  - name: \"Get the existing workflow templates\"\n    rest_get:\n      host_url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}\"\n      rest_user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      rest_password: \"{{ ansible_tower.admin_password }}\"\n      api_uri: \"/api/v2/workflow_job_templates/\"\n    register: existing_workflow_templates_output\n\n  # Utilize the `rest_get` library routine to ensure REST pagination is handled\n  - name: \"Get the existing job templates\"\n    rest_get:\n      host_url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}\"\n      rest_user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      rest_password: \"{{ ansible_tower.admin_password }}\"\n      api_uri: \"/api/v2/job_templates/\"\n    register: existing_job_templates_output\n\n  # Utilize the `rest_get` library routine to ensure REST pagination is handled\n  - name: \"Get the existing users\"\n    rest_get:\n      host_url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}\"\n      rest_user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      rest_password: \"{{ ansible_tower.admin_password }}\"\n      api_uri: \"/api/v2/users/\"\n    register: existing_users_output\n\n  # Utilize the `rest_get` library routine to ensure REST pagination is handled\n  - name: \"Get the existing teams\"\n    rest_get:\n      host_url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}\"\n      rest_user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      rest_password: \"{{ ansible_tower.admin_password }}\"\n      api_uri: \"/api/v2/teams/\"\n    register: existing_teams_output\n\n  - name: \"Process the inventory workflow template\"\n    include_tasks: process-workflow-template.yml\n    with_items:\n    - \"{{ ansible_tower.workflow_templates }}\"\n    loop_control:\n      loop_var: workflow_template\n\n  - name: \"Elminate the workflow templates that should not be present\"\n    uri:\n      url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}/api/v2/workflow_job_templates/{{ item.id }}/\"\n      user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      password: \"{{ ansible_tower.admin_password }}\"\n      force_basic_auth: yes\n      method: DELETE\n      validate_certs: no\n      status_code: 200,204\n    with_items:\n    - \"{{ existing_workflow_templates_output.rest_output | get_remaining_items(processed_workflow_templates, 'name', 'name')}}\"\n\n  when:\n  - ansible_tower.workflow_templates is defined\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "b44e5ec5caa0f6d79e8d9fa2d306a5a886449c01", "filename": "playbooks/group_vars/all", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "file_inventory: ../inventory\nfile_env: ../env.yml\nfile_secrets: ../secrets.yml\nfile_ip_data: ../ip\nsku_name: Employee SKU\ndisk_free_space: 20\nnode_mem: 16384\nnode_vcpus: 4\nsizing: fixed\nbandwidth_limit: 1\nocp_version: \"3.11\"\nrepos:\n- rhel-7-server-rpms\n- rhel-7-server-extras-rpms\n- \"rhel-7-server-ose-{{ '%0.2f'| format(ocp_version|float) }}-rpms\"\n- \"{{ 'rhel-7-fast-datapath-rpms' if '%0.2f'| format(ocp_version|float) == '3.10' else 'rhel-7-server-extras-rpms'}}\"\npackages:\n- wget\n- git\n- net-tools\n- bind-utils\n- iptables-services\n- bridge-utils\n- bash-completion\n- kexec-tools\n- sos\n- psacct\npackages_jumphost:\n- openshift-ansible\nfirewall_ports:\n- 8443\n- 80\n- 443\n- 53\n- 10250\n- 2049\n- 2379\n- 2380\n- 4001\n- 4789\n- 9000\n- 1936\n- 9200\n- 9300\nproxy_whitelist:\n- github.com\n- redhat.com\ndocker_vg: ocp\ndocker_version: \"1.13\"\ndocker_prepull_tag: \"v{{ '%0.2f'| format(ocp_version|float) }}\"\ndocker_prepull:\n- registry.access.redhat.com/openshift3/ose-deployer\n- registry.access.redhat.com/openshift3/ose-node-problem-detector\n- registry.access.redhat.com/openshift3/ose-pod\n- registry.access.redhat.com/openshift3/ose-node\n- registry.access.redhat.com/openshift3/ose-docker-builder\npost_install_components:\n- console\n- monitoring\n- metering\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "8c075cc5a80195223949d75ed0d0cdea5fea361e", "filename": "roles/letsencrypt/library/test_challenges.py", "repository": "roots/trellis", "decoded_content": "#!/usr/bin/python\n# -*- coding: utf-8 -*-\n\nimport socket\nfrom httplib import HTTPConnection, HTTPException\n\nDOCUMENTATION = '''\n---\nmodule: test_challenges\nshort_description: Tests Let's Encrypt web server challenges\ndescription:\n     - The M(test_challenges) module verifies a list of hosts can access acme challenges for Let's Encrypt.\noptions:\n  hosts:\n    description:\n      - A list of hostnames/domains to test.\n    required: true\n    default: null\n    type: list\n  file:\n    description:\n      - The dummy filename in the URL to test.\n    required: no\n    default: ping.txt\n  path:\n    description:\n      - The path to the challenges in the URL.\n    required: no\n    default: /.well-known/acme-challenge\nauthor:\n    - Scott Walkinshaw\n'''\n\nEXAMPLES = '''\n# Example from Ansible Playbooks.\n- test_challenges:\n    hosts:\n      - example.com\n      - www.example.com\n      - www.mydomain.com\n'''\n\ndef get_status(host, path, file):\n    try:\n        conn = HTTPConnection(host)\n        conn.request('HEAD', '/{0}/{1}'.format(path, file))\n        res = conn.getresponse()\n    except (HTTPException, socket.timeout, socket.error):\n        return 0\n    else:\n        return res.status\n\ndef main():\n    module = AnsibleModule(\n        argument_spec = dict(\n            file  = dict(default='ping.txt'),\n            hosts = dict(required=True, type='list'),\n            path  = dict(default='.well-known/acme-challenge')\n        )\n    )\n\n    hosts = module.params['hosts']\n    path = module.params['path']\n    file = module.params['file']\n\n    failed_hosts = []\n\n    for host in hosts:\n        status = get_status(host, path, file)\n        if int(status) != 200:\n            failed_hosts.append(host)\n\n    rc = int(len(failed_hosts) > 0)\n\n    module.exit_json(\n        changed=False,\n        rc=rc,\n        failed_hosts=failed_hosts\n    )\n\nfrom ansible.module_utils.basic import *\nmain()\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "7fc3e4481935b4a5721256357f19fbb92a07f494", "filename": "roles/config-iscsi-client/tasks/lock-lvm.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Obtain currently configured LVMs (pvs)\"\n  shell: 'pvs | sed -ne \"s/\\(\\/dev\\/[^ ]*\\) .*/\\1/p\"'\n  register: pvs_device_list\n\n- name: \"Build fact for setting the LVM global_filter\"\n  set_fact:\n    lvm_global_filter: '{{ lvm_global_filter | default(\"\") }} \"a|^{{ item|trim }}$|\",'\n  with_items:\n  - \"{{ pvs_device_list.stdout_lines }}\"\n\n- name: \"Ensure LVM does NOT claim too many devices\"\n  lineinfile:\n    path: /etc/lvm/lvm.conf\n    state: present\n    regexp: \"\\t# global_filter = \"\n    line: \"\\tglobal_filter = [ {{ lvm_global_filter }} \\\"a/^/dev/loop.*/\\\", \\\"r/.*/\\\" ]\"\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "5618651a2af2a73c1d0362e43495e8bb77d2c584", "filename": "archive/roles/openshift-install/tasks/main.yaml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n  - name: \"Creating Inventory\"\n    template:\n      dest: \"{{rhc_ose_inv_dest | default('/tmp') }}/inventory_{{ hostvars['localhost'].env_id}}\"\n      src: \"{{ role_path }}/templates/inventory_template.j2\"\n      force: yes\n#    - include: /usr/share/ansible/openshift-ansible/playbooks/byo/config.yml\n#     when: ose_install | default(true) | bool\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "f5b2c8e562bc96c4f6c2a16e13f1318bf2ee9d8f", "filename": "cookbooks/yum/metadata.json", "repository": "rocknsm/rock", "decoded_content": "{\"name\":\"yum\",\"version\":\"3.6.1\",\"description\":\"Configures various yum components on Red Hat-like systems\",\"long_description\":\"\",\"maintainer\":\"Chef\",\"maintainer_email\":\"cookbooks@chef.io\",\"license\":\"Apache 2.0\",\"platforms\":{\"redhat\":\">= 0.0.0\",\"centos\":\">= 0.0.0\",\"scientific\":\">= 0.0.0\",\"amazon\":\">= 0.0.0\",\"fedora\":\">= 0.0.0\"},\"dependencies\":{},\"recommendations\":{},\"suggestions\":{},\"conflicting\":{},\"providing\":{},\"replacing\":{},\"attributes\":{},\"groupings\":{},\"recipes\":{}}"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "44584c266c43526ca41c9944dec3064a1a3087b9", "filename": "roles/config-iscsi-client/tasks/multipath-config.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Configure MultiPath configuration\"\n  blockinfile: \n    path: /etc/multipath.conf\n    block: |\n      blacklist {\n        devnode \"{{ multipath_blacklist_node | default('^sda') }}\"\n      }\n    create: yes\n    owner: root\n    group: root\n    mode: 0600\n    state: present\n  register: multipathconf\n\n- name: 'restart multipathd'\n  service:\n    name: multipathd\n    state: restarted\n  when: \n  - multipathconf.changed \n\n\n\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "96fe9e037778fb4098446be0cacd7f559a100693", "filename": "playbooks/roles/check_selinux/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- name: check if selinux is running and enforced\n  command: getenforce\n  register: sestatus\n  changed_when: false\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "9cf546442c04ec3b796302edf521e817f7c6a21f", "filename": "roles/haproxy/vars/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# vars file for haproxy\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "daef6ccbe576a3ab061bd8dbe7049c591c3effbb", "filename": "roles/config-selinux/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Test SELinux config\"\n  hosts: all\n  roles:\n    - role: config-selinux \n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "c08af46bc1baff9f68c9d7812c9db1d54bd95b9f", "filename": "roles/iiab-admin/tasks/admin-user.yml", "repository": "iiab/iiab", "decoded_content": "- name: Create iiab-admin user and password\n  user: name={{ iiab_admin_user }}\n        password={{ iiab_admin_passw_hash }}\n        update_password=on_create\n\n- name: Create a wheel group\n  group: name=wheel\n         state=present\n\n- name: Create a sudo group\n  group: name=sudo\n         state=present\n  when: is_redhat\n\n- name: Add user to wheel group\n  user: name={{ iiab_admin_user }} groups=wheel,sudo\n\n- name: Create root .ssh\n  file: path=/root/.ssh\n        mode=0700\n        owner=root\n        group=root\n        state=directory\n\n- name: Install dummy root keys as placeholder\n  copy: src=dummy_authorized_keys\n        dest=/root/.ssh/authorized_keys\n        force=no\n        owner=root\n        group=root\n        mode=0600\n\n#        backup=yes\n\n- name: edit the sudoers file--first make it editable\n  shell: chmod 0640 /etc/sudoers\n\n- name: have sudo log all commands it handles\n  lineinfile: regexp=logfile\n              line='Defaults     logfile = /var/log/sudo.log'\n              state=present\n              dest=/etc/sudoers\n\n- name: lets wheel sudo without password\n  lineinfile:\n     line: \"%wheel ALL= NOPASSWD: ALL\"\n     dest: /etc/sudoers\n\n- name: remove the line which requires tty\n  lineinfile: regexp=requiretty\n              state=absent\n              dest=/etc/sudoers\n\n- name: end editing the sudoers file-- protect it again\n  shell: chmod 0440 /etc/sudoers\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "fe1aae2149d081b6c174249d34923d792a975e07", "filename": "roles/scm/add-webhooks-github/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n# tasks file for add-webhooks\n\n- name: Add Webhooks\n  include_tasks: add-webhook.yml\n  vars:\n    url: \"{{ item.url }}\"\n    events: \"{{ item.events }}\"\n    is_active: \"{{ item.is_active }}\"\n  with_items: \"{{ webhooks }}\"\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "9c3a739cfd321c3fc0e7bb6927759acaa930c5e3", "filename": "roles/ansible/tower/config-ansibletower/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# ansible_tower_download_url: http://releases.ansible.com/ansible-tower/setup/ansible-tower-setup-latest.tar.gz\nansible_tower_download_url: https://releases.ansible.com/ansible-tower/setup/ansible-tower-setup-3.2.1.tar.gz\n\n# oc clients found at 'https://mirror.openshift.com/pub/openshift-v3/clients/'\noc_client_download_url: https://mirror.openshift.com/pub/openshift-v3/clients/3.7.18/linux/oc.tar.gz\n\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "9706acb424c92cc45b6d7d499b54632eae15c45f", "filename": "tasks/section_05.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n- include: section_05_level1.yml\n  tags:\n  - section05\n  - level1\n\n\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "b4586a84d920a0b770ae606ac5bbd776815b3662", "filename": "roles/ansible/tower/manage-projects/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ntower_url: 'https://localhost'\ntower_admin_username: 'admin'\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "b7b2cad328fdc9492e800438081be90d758a66bd", "filename": "tasks/section_10.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - include: section_10_level1.yml\n    tags:\n      - section10\n      - level1\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "9ed3310637804bd5b718f0cea7e9e1b6971efc48", "filename": "roles/config-versionlock/tasks/prereq-RedHat.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Install required packages\"\n  package:\n    name: \"{{ item }}\"\n    state: installed\n  with_items:\n  - yum-plugin-versionlock\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "3b3e68da3caeea3b0b8ded48bc2ccf90c0af84d4", "filename": "roles/ovirt-common/tasks/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\n# check variables setting ovirt source\n- name: complain if no ovirt source is specified\n  fail:\n    msg: \"At least one of: 'ovirt_repo_file', 'ovirt_rpm_repo' or 'ovirt_repo'\n      must be specified. More information in the README\"\n  when: \"{{ not (ovirt_repo_file or ovirt_rpm_repo is defined or ovirt_repo)\n    }}\"\n\n# install libselinux-python on machine - selinux policy\n- name: install libselinux-python for ansible\n  yum:\n    name: libselinux-python\n    state: \"present\"\n\n# backup repos\n- name: creating directory repo-backup in yum.repos.d\n  file:\n    path: /tmp/repo-backup\n    state: directory\n\n- name: create repository backup\n  shell: 'cp /etc/yum.repos.d/*.repo /tmp/repo-backup'\n  tags:\n    - skip_ansible_lint\n\n## OPTIONS\n# 1) get repository files\n- name: copy repository files\n  get_url:\n    url: \"{{ item.url }}\"\n    dest: \"/etc/yum.repos.d/{{ item.name | default('') }}\"\n    force_basic_auth: yes\n    force: \"{{ item.force | default('no') }}\"\n  with_items: \"{{ ovirt_repo_file }}\"\n\n# 2) install from rpm\n- name: install rpm repository package\n  yum:\n    name: \"{{ ovirt_rpm_repo }}\"\n    state: present\n  when: \"{{ ovirt_rpm_repo is defined }}\"\n\n# 3) create repository files\n- name: create repository files\n  yum_repository:\n    name: \"{{ item.name }}\"\n    description: \"{{ item.name }}\"\n    baseurl: \"{{ item.url }}\"\n    enabled: \"{{ item.enabled | default('yes') }}\"\n  with_items: \"{{ ovirt_repo }}\"\n"}, {"commit_sha": "2378736112ce798a1b1b6e66f372415b01cd5536", "sha": "86b5d39896ec718085e5b8e07f578ffa45d5b2b3", "filename": "tasks/redhat.yml", "repository": "CSCfi/ansible-role-cuda", "decoded_content": "---\n# tasks file for ansible-role-cuda\n#\n- name: add nvidia CUDA repo\n  template: src=nvidia.repo.j2 dest=/etc/yum.repos.d/nvidia.repo owner=root group=root mode=0644 backup=yes\n\n- name: install cuda software - this is slow - restart if cuda_restart_node_on_install is True\n  yum: name={{ item }} state=present\n  with_items: \"{{ cuda_packages | default({}) }}\"\n  when: cuda_packages.0 != \"\"\n  register: cuda_packages_installation\n  notify:\n   - ZZ CUDA Restart server\n   - ZZ CUDA Wait for server to restart\n\n- name: template in cuda_init.sh used during boot\n  template: src=cuda_init.sh.j2 \n            dest=/usr/local/bin/cuda_init.sh \n            owner=root group=root mode=0755 \n            backup=no\n  when: cuda_init\n\n- name: add the cuda_init.sh script to rc.local\n  lineinfile: \n      dest=/etc/rc.local \n      insertafter=EOF \n      regexp=\"^/bin/bash /usr/local/bin/cuda_init.sh$\"\n      line=\"/bin/bash /usr/local/bin/cuda_init.sh\" \n  when: cuda_init\n\n# This is here because if we in the same playbook try to start slurmd without having run the cuda_init.sh script then slurmd doesn't start and the play fails.\n- name: flush the handlers - so that the node is rebooted after CUDA is installed\n  meta: flush_handlers\n\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "e424ce8b36255dc6f705d981182f112d0d012663", "filename": "playbooks/templates/fsf-server-config.j2", "repository": "rocknsm/rock", "decoded_content": "#!/usr/bin/env python\n#\n# Basic configuration attributes for scanner. Used as default\n# unless the user overrides them. \n#\n\nSCANNER_CONFIG = { 'LOG_PATH' : '{{ fsf_data_dir }}',\n                   'YARA_PATH' : '/var/lib/yara-rules/rules.yara',\n                   'EXPORT_PATH' : '{{ fsf_archive_dir }}',\n                   'TIMEOUT' : 60,\n                   'PID_PATH': '/run/fsf/fsf.pid',\n                   'MAX_DEPTH' : 10,\n\t\t   'ACTIVE_LOGGING_MODULES': ['rockout', 'scan_log'] }\n\nSERVER_CONFIG = { 'IP_ADDRESS' : \"localhost\",\n                  'PORT' : 5800 }\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "9f5c20a8376b3434066f6ac42439d7b3f6d17100", "filename": "playbooks/templates/logrotate-suricata.conf", "repository": "rocknsm/rock", "decoded_content": "{{ suricata_data_dir }}/*.log {{ suricata_data_dir }}/*.json\n{\n    rotate 3\n    missingok\n    nocompress\n    create\n    sharedscripts\n    postrotate\n            /bin/kill -HUP $(cat /var/run/suricata.pid)\n    endscript\n}\n"}, {"commit_sha": "481f7ad18dc225973e1d676d33e58c49cbbfe986", "sha": "6c13ac32fd486aa0313770855db784b711462dec", "filename": "tasks/variables.yml", "repository": "openwisp/ansible-openwisp2", "decoded_content": "- name: Set supervisor path (Debian)\n  set_fact:\n    supervisor_path: '/etc/supervisor/conf.d/%s.conf'\n  when: ansible_os_family == 'Debian'\n\n- name: Set supervisor path (RedHat)\n  set_fact:\n    supervisor_path: '/etc/supervisord.d/%s.ini'\n  when: ansible_os_family == 'RedHat'\n\n- name: Set www user (Debian)\n  set_fact:\n    www_group: 'www-data'\n    www_user:  'www-data'\n  when: ansible_os_family == 'Debian'\n\n- name: Set www user (RedHat)\n  set_fact:\n    www_group: 'nginx'\n    www_user:  'nginx'\n  when: ansible_os_family == 'RedHat'\n\n- name: Set python3_package_prefix for CentOS/RedHat\n  set_fact:\n    python3_package_prefix: python34\n  when: ansible_distribution in ['RedHat', 'CentOS']\n\n- name: Set python3_package_prefix for Fedora\n  set_fact:\n    python3_package_prefix: python3\n  when: ansible_distribution == 'Fedora'\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "d50ecfa4b0e473acbaa4e435ceadfaa0c40ae28f", "filename": "roles/vpn/tasks/distribute_keys.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- name: Copy the keys to the strongswan directory\n  copy:\n    src: \"{{ item.src }}\"\n    dest: \"{{ item.dest }}\"\n    owner: \"{{ item.owner }}\"\n    group: \"{{ item.group }}\"\n    mode: \"{{ item.mode }}\"\n  with_items:\n    - src: \"configs/{{ IP_subject_alt_name }}/pki/cacert.pem\"\n      dest: \"{{ config_prefix|default('/') }}etc/ipsec.d/cacerts/ca.crt\"\n      owner: strongswan\n      group: \"{{ root_group|default('root') }}\"\n      mode: \"0600\"\n    - src: \"configs/{{ IP_subject_alt_name }}/pki/certs/{{ IP_subject_alt_name }}.crt\"\n      dest: \"{{ config_prefix|default('/') }}etc/ipsec.d/certs/{{ IP_subject_alt_name }}.crt\"\n      owner: strongswan\n      group: \"{{ root_group|default('root') }}\"\n      mode: \"0600\"\n    - src: \"configs/{{ IP_subject_alt_name }}/pki/private/{{ IP_subject_alt_name }}.key\"\n      dest: \"{{ config_prefix|default('/') }}etc/ipsec.d/private/{{ IP_subject_alt_name }}.key\"\n      owner: strongswan\n      group: \"{{ root_group|default('root') }}\"\n      mode: \"0600\"\n  notify:\n    - restart strongswan\n"}, {"commit_sha": "0183b10864f53eb0cf3405fb2a3a92a07d573349", "sha": "0c4d24d1f24f2cbb29127ed0e89c509bdcb20875", "filename": "tasks/main.yml", "repository": "angstwad/docker.ubuntu", "decoded_content": "---\n# tasks file for docker.ubuntu\n- name: Fail if not a new release of Ubuntu\n  fail: msg=\"{{ ansible_distribution_version }} is not an acceptable version of Ubuntu for this role\"\n  when: \"ansible_distribution_version not in ['12.04', '13.04', '13.10', '14.04', '14.10']\"\n  \n- name: Install raring kernel onto 12.04\n  apt:\n    pkg: \"{{ item }}\"\n    state: latest\n    update_cache: yes\n    cache_valid_time: 600\n  with_items:\n    - linux-image-generic-lts-raring\n    - linux-headers-generic-lts-raring\n  register: kernel_result\n  when: \"ansible_distribution_version == '12.04'\"\n\n- name: Install latest kernel extras for Ubuntu 13.04+\n  apt:\n    pkg: \"linux-image-extra-{{ ansible_kernel }}\"\n    state: \"{{ kernel_pkg_state }}\"\n    update_cache: yes\n    cache_valid_time: 600\n  when: \"ansible_distribution_version == '13.04' or ansible_distribution_version == '13.10'\"\n\n# Fix for https://github.com/dotcloud/docker/issues/4568\n- name: Install cgroup-lite for Ubuntu 13.10\n  apt:\n    pkg: cgroup-lite\n    state: \"{{ cgroup_lite_pkg_state }}\"\n    update_cache: yes\n    cache_valid_time: 600\n  register: cgroup_lite_result\n  when: \"ansible_distribution_version == '13.10'\"\n\n- name: Reboot instance\n  command: /sbin/shutdown -r now\n  register: reboot_result\n  when: \"(ansible_distribution_version == '12.04' and kernel_result|changed)\n      or (ansible_distribution_version == '13.10' and cgroup_lite_result|changed)\"\n\n- name: Wait for instance to come online\n  local_action:\n    module: wait_for\n    host: \"{{ ansible_ssh_host|default(inventory_hostname) }}\"\n    port: \"{{ ansible_ssh_port|default(ssh_port) }}\"\n    delay: 30\n    timeout: 600\n    state: started\n  when: \"(ansible_distribution_version == '12.04' and reboot_result|changed)\n      or (ansible_distribution_version == '13.10' and cgroup_lite_result|changed)\"\n\n- name: Add Docker repository key\n  apt_key:\n    id: \"{{ apt_key_sig }}\"\n    url: \"{{ apt_key_url }}\"\n    state: present\n\n- name: Add Docker repository\n  apt_repository:\n    repo: \"{{ apt_repository }}\"\n    update_cache: yes\n    state: present\n\n- name: Install (or update) docker.io\n  apt: \n    name: \"{{ docker_io_pkg }}\"\n    state: latest\n    update_cache: yes\n      \n- name: Install Docker\n  apt: pkg={{ docker_lxc_pkg }}\n  notify: \"Start Docker\"\n\n- name: Expose docker host\n  copy:\n    content: \"DOCKER_OPTS=\\\"{{ docker_opts }}\\\"\"\n    dest: /etc/default/docker\n    owner: root\n    group: root\n    mode: 0744\n  notify:\n    - Reload docker\n  when: \"export_docker_host\"    \n  \n- name: Install pip python package\n  apt:\n    pkg: \"{{ item }}\"\n    state: latest\n    update_cache: yes\n    cache_valid_time: 600\n  with_items:\n    - python-dev\n    - python-pip\n  register: kernel_result\n\n- name: Install Docker-py\n  pip: name=docker-py   \n\n- name: Check if /etc/updatedb.conf exists\n  stat: path=/etc/updatedb.conf\n  register: updatedb_conf_exists\n\n- name: Ensure updatedb does not index /var/lib/docker\n  shell: >\n    ex -s -c '/PRUNEPATHS=/v:/var/lib/docker:s:\"$: /var/lib/docker\"' -c 'wq' /etc/updatedb.conf\n  when: updatedb_conf_exists.stat.exists\n\n- name: Check if /etc/default/ufw exists\n  stat: path=/etc/default/ufw\n  register: ufw_default_exists\n\n- name: Change ufw default forward policy from drop to accept\n  lineinfile: dest=/etc/default/ufw regexp=\"^DEFAULT_FORWARD_POLICY=\" line=\"DEFAULT_FORWARD_POLICY=\\\"ACCEPT\\\"\"\n  when: ufw_default_exists.stat.exists\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "7338ccc95a55eb085bf736172a553ac2af1ff4e2", "filename": "archive/playbooks/ose-provision.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n# Provision OpenStack instances\n- hosts: localhost\n  pre_tasks:\n  - include: roles/openstack-create/pre_tasks/pre_tasks.yml\n  - include: roles/common/pre_tasks/pre_tasks.yml\n  - include: roles/subscription-manager/pre_tasks/pre_tasks.yml\n  roles:\n  - role: common\n  - role: openshift-common\n  # Provision Master\n  - role: openstack-create\n    type: \"master\"\n    image_name: \"{{ openshift_openstack_image_name }}\"\n    security_groups: \"{{ openshift_openstack_master_security_groups }}\"\n    key_name: \"{{ openstack_key_name }}\"\n    flavor_name: \"{{ openshift_openstack_flavor_name }}\"\n    register_host_group: \"masters,openshift\"\n    node_count: \"{{ openshift_master_count }}\"\n    disk_volume: \"{{ openshift_storage_disk_volume }}\"\n    volume_size: \"{{ openshift_openstack_master_storage_size }}\"\n  # Provision Nodes\n  - role: openstack-create\n    type: \"node\"\n    image_name: \"{{ openshift_openstack_image_name }}\"\n    security_groups: \"{{ openshift_openstack_node_security_groups }}\"\n    key_name: \"{{ openstack_key_name }}\"\n    flavor_name: \"{{ openshift_openstack_flavor_name }}\"\n    register_host_group: \"nodes,openshift\"\n    node_count: \"{{ openshift_node_count }}\"\n    disk_volume: \"{{ openshift_storage_disk_volume }}\"\n    volume_size: \"{{ openshift_openstack_node_storage_size }}\"\n  # Provision NFS\n  - role: openstack-create\n    type: \"nfs\"\n    image_name: \"{{ openshift_openstack_image_name }}\"\n    security_groups: \"{{ openshift_openstack_nfs_security_groups }}\"\n    key_name: \"{{ openstack_key_name }}\"\n    flavor_name: \"{{ openshift_openstack_flavor_name }}\"\n    register_host_group: \"nfs,openshift\"\n    node_count: \"1\"\n    disk_volume: \"{{ openshift_storage_disk_volume }}\"\n    volume_size: \"{{ openshift_openstack_master_storage_size }}\"\n    # Provision DNS\n\n- include: playbooks/dns-provision.yaml\n\n- hosts: openshift\n  remote_user: \"cloud-user\"\n  vars:\n    ansible_ssh_user: cloud-user\n  tasks:\n  - name: \"Enable direct root access\"\n    shell: \"cat ~/.ssh/authorized_keys | sudo tee /root/.ssh/authorized_keys >/dev/null\"\n\n- hosts: all:!dns:!localhost\n  pre_tasks:\n  - include: roles/common/pre_tasks/pre_tasks.yml\n  roles:\n  - role: hostnames\n\n- hosts: all:!localhost\n  roles:\n    - { role: subscription-manager, when: hostvars.localhost.rhsm_register, tags: 'subscription-manager', ansible_sudo: true }\n\n- hosts: localhost\n  pre_tasks:\n  - include: roles/common/pre_tasks/pre_tasks.yml\n  - name: \"Generate dns-server views\"\n    include: playbooks/dns_dual_view.yaml\n  - name: \"Generate dns records\"\n    include: playbooks/dns_records.yaml\n\n- hosts: dns\n  pre_tasks:\n  - name: \"Include the generated views\"\n    include_vars: /tmp/named_views.yaml\n    delegate_to: localhost\n  - name: \"Include generated dns records\"\n    include_vars: /tmp/records.yaml\n    delegate_to: localhost\n  roles:\n    - role: dns-server\n    - role: dns\n\n# Use newly configured DNS server for this container ...\n- hosts: localhost\n  tasks:\n  - name: \"Edit /etc/resolv.conf in container\"\n    shell: \"sed '0,/.*nameserver.*/s/.*nameserver.*/nameserver {%for host in groups['dns']%}{{ hostvars[host].dns_public_ip }}{% endfor %}\\\\n&/' /etc/resolv.conf > /tmp/resolv.conf && /bin/cp -f /tmp/resolv.conf /etc/resolv.conf\"\n\n\n# Install and configure OpenShift\n\n- hosts: openshift:!dns\n  tasks:\n  - name: \"Edit /etc/resolv.conf on masters/nodes\"\n    lineinfile:\n      state: present\n      dest: /etc/resolv.conf\n      regexp: \"nameserver {%for host in groups['dns']%} {{ hostvars[host].dns_private_ip }} {% endfor %}\"\n      line: \"nameserver {%for host in groups['dns']%} {{ hostvars[host].dns_private_ip }} {% endfor %}\"\n      insertafter: search*\n  - name: \"Include DHCP/DNS workaround for OSE 3.2\"\n    lineinfile:\n      state: present\n      dest: /etc/sysconfig/network\n      regexp: \"IP4_NAMESERVERS={%for host in groups['dns']%}{{ hostvars[host].dns_private_ip }}{% endfor %}\"\n      line: \"IP4_NAMESERVERS={%for host in groups['dns']%}{{ hostvars[host].dns_private_ip }}{% endfor %}\"\n  roles:\n    - { role: docker, tags: 'docker' }\n    - { role: openshift-prep, tags: 'openshift-prep', ansible_sudo: true }\n\n- hosts: localhost\n  roles:\n    - openshift-install\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "e420fc46cc0d0bdcd124527ecb49e19afd8ed601", "filename": "playbooks/roles/common/tasks/timedatectl.yml", "repository": "rocknsm/rock", "decoded_content": "---\n# timedatectl.yml - configure ntp\n- name: Install Chrony\n  yum:\n    name: chrony\n    state: installed\n\n- name: Enable and start chrony\n  service:\n    name: chronyd\n    enabled: yes\n    state: started\n\n- name: Set system timezone\n  command: /usr/bin/timedatectl set-timezone UTC\n  when: ansible_date_time.tz != \"UTC\"\n\n- name: Check if RTC set to UTC\n  shell: timedatectl | awk '/RTC in local/ { print $5 }'\n  changed_when: false\n  register: chrony_local_utc\n\n- name: Set system hardware clock to UTC\n  command: /usr/bin/timedatectl set-local-rtc no\n  when: chrony_local_utc == 'yes'\n\n- name: Check if NTP is enabled\n  shell: timedatectl | awk '/NTP enabled/ { print $3 }'\n  changed_when: false\n  register: chrony_ntp_enabled\n\n- name: Set NTP enabled\n  command: /usr/bin/timedatectl set-ntp yes\n  when: chrony_ntp_enabled == 'no'\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "9745bbf28ade9cac2e775a06b55ff9583576176c", "filename": "roles/users/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Ensure sudo group is present\n  group:\n    name: sudo\n    state: present\n\n- name: Ensure sudo group has sudo privileges\n  lineinfile:\n    dest: /etc/sudoers\n    state: present\n    regexp: \"^%sudo\"\n    line: \"%sudo ALL=(ALL:ALL) ALL\"\n    validate: \"/usr/sbin/visudo -cf %s\"\n\n- name: Fail if root login will be disabled but admin_user will not be a sudoer\n  assert:\n    that:\n      - \"{{ admin_user in (users | map(attribute='name') | list) }}\"\n      - \"{% for item in users if item.name == admin_user %}{{ 'sudo' in item.groups }}{% endfor %}\"\n      - \"{{ admin_user in sudoer_passwords.keys() }}\"\n    msg: \"When `sshd_permit_root_login: false`, you must add `sudo` to the `groups` for admin_user (in `users` hash), and set a password for admin_user in `sudoer_passwords`. Otherwise Ansible could lose the ability to run the necessary sudo commands.\"\n  when: not sshd_permit_root_login\n\n- name: Setup users\n  user:\n    name: \"{{ item.name }}\"\n    group: \"{{ item.groups[0] }}\"\n    groups: \"{{ item.groups | join(',') }}\"\n    password: \"{{ sudoer_passwords[item.name] | default(None) }}\"\n    state: present\n    shell: /bin/bash\n    update_password: always\n  with_items: \"{{ users }}\"\n\n- name: Add web user sudoers items for services\n  template:\n    src: sudoers.d.j2\n    dest: \"/etc/sudoers.d/{{ web_user }}-services\"\n    mode: 0440\n    owner: root\n    group: root\n    validate: \"/usr/sbin/visudo -cf %s\"\n  when: web_sudoers\n\n- name: Add SSH keys\n  authorized_key:\n    user: \"{{ item.0.name }}\"\n    key: \"{{ item.1 }}\"\n  with_subelements:\n    - \"{{ users | default([]) }}\"\n    - keys\n\n- name: Check whether Ansible can connect as admin_user\n  local_action: command ansible {{ inventory_hostname }} -m ping{{ (inventory_file == None) | ternary('', ' -i ' + inventory_file | string) }} -u {{ admin_user }}\n  failed_when: false\n  changed_when: false\n  become: no\n  register: admin_user_status\n  when: not sshd_permit_root_login\n\n- name: Fail if root login will be disabled but admin_user cannot connect\n  fail:\n    msg: 'The admin_user is unable to connect to the server. To prevent you from losing access to your server, the playbook has halted before disabling root login (`sshd_permit_root_login: false`). Ensure that the admin_user appears in your `users` hash with a valid entry for `keys`.'\n  when: not sshd_permit_root_login and admin_user_status | failed\n"}, {"commit_sha": "1d7d3a653c598355333e7c34a54a550ed3d79cc5", "sha": "d1b2909799c42ab3077ce5a2b790dcf52f1d6122", "filename": "tasks/repo_RedHat.yml", "repository": "RocketChat/Rocket.Chat.Ansible", "decoded_content": "---\n# tasks/repo_RedHat.yml: RedHat based distro repository configuration for RocketChat.Ansible\n\n  - name: Ensure the EPEL repository is present\n    yum:\n      name: epel-release\n      state: present\n\n  - name: Ensure the EPEL repository GPG key is imported\n    rpm_key:\n      key: /etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7\n      state: present\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "f0cc73d1c32a660d1009df35988018294770234d", "filename": "playbooks/vars/bb4.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "registry: bastion:5000\nregistry_packages:\n - docker-distribution\n - skopeo\n - openssl\nregistry_path: /etc/docker-distribution/registry\nregistry_conf: config.yml\nregistry_secret: changeme\nproxy_packages:\n - squid\nproxy_cidr: 192.168.0.0/24\n\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "9ef119c08138b621c256191f2a0310caaef9e4b3", "filename": "roles/dcos_cli/defaults/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# defaults file for dcos-cli\ndcos_cli_image: capgemini/dcos-cli\ndcos_cli_zk_master_peers: \"zk://{{ zookeeper_peers_nodes }}/mesos\"\ndcos_cli_mesos_master_url: \"http://{{ ansible_ssh_host }}:5050\"\ndcos_cli_marathon_url: \"http://{{ ansible_ssh_host }}:8080\"\ndcos_cli_sources: '[\"https://github.com/Capgemini/universe/archive/version-1.x.zip\",]'\ndcos_cli_frameworks_list:\n  - cassandra\n  - chronos\ndcos_cli_apps_list:\n  - prometheus\n\n# apps\nprometheus_image: prom/prometheus\nprometheus_image_tag: 0.16.1\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "0f9aa7c782b0913be9fad3c9fa991bb38262540d", "filename": "tasks/Win32NT/fetch/sapmachine-fallback.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: 'Prepare for latest minor version'\n  block:\n    - name: 'Fetch version page'\n      win_uri:\n        url: 'https://sap.github.io/SapMachine/latest/{{ java_major_version }}/'\n        return_content: true\n        status_code: [200, 404]\n      register: version_page\n\n    - name: Find release version\n      set_fact:\n        release_version: >-\n          {{ version_page.content | regex_search('(1.*[.|-]\\d)') }}\n  when: java_minor_version == '*'\n\n- name: 'Fetch artifact page'\n  win_uri:\n    url: '{{ release_page }}'\n    status_code: [200, 404]\n    return_content: true\n    headers: {\"user-agent\": \"Mozilla/5.0\"}\n  register: artifact_page\n\n- name: Exit if SapMachine version is wrong\n  fail:\n    msg: >-\n      {{ 'SapMachine version ' + java_major_version|string\n              + (java_minor_version == '*') | ternary('', '.' + java_minor_version|string)\n                  + '_' + java_arch|string + ' for Windows is not supported!' }}\n  when: artifact_page.status == 404\n\n- name: Get artifact link\n  set_fact:\n    artifact_link: \"{{ artifact_page.json | json_query(\\\"assets[?name=='\\\" + release_name + \\\".zip'].browser_download_url\\\") }}\"\n\n- name: Get checksum link\n  set_fact:\n    checksum_link: \"{{ artifact_page.json | json_query(\\\"assets[?name=='\\\" + release_name + \\\".sha256.txt'].browser_download_url\\\") }}\"\n\n- name: 'Fetch artifact checksum file'\n  win_uri:\n    url: '{{ checksum_link[0] }}'\n    return_content: true\n  register: artifact_checksum_file\n\n- name: Find artifact checksum\n  set_fact:\n    artifact_checksum: >-\n      {{ artifact_checksum_file.content | regex_search('(^\\w*)') }}\n\n- name: 'Download artifact'\n  win_get_url:\n    url: '{{ artifact_link[0] }}'\n    dest: '{{ java_download_path }}'\n    checksum: '{{ artifact_checksum }}'\n    checksum_algorithm: sha256\n    force: true\n  register: file_downloaded\n  retries: 20\n  delay: 5\n  until: file_downloaded is succeeded\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "fc5bf254a268d2e1f000c4173b9a95a70650e39d", "filename": "roles/osp/packstack-install/tasks/sync-keys.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Fetch the private SSH key from the first host'\n  fetch:\n    src: \"~/.ssh/id_rsa\"\n    dest: \"/tmp/id_rsa\"\n    flat: yes\n  run_once: true\n  delegate_to: \"{{ ansible_play_hosts | first }}\"\n\n- name: 'Fetch the public SSH key from the first host'\n  fetch:\n    src: \"~/.ssh/id_rsa.pub\"\n    dest: \"/tmp/id_rsa.pub\"\n    flat: yes\n  run_once: true\n  delegate_to: \"{{ ansible_play_hosts | first }}\"\n\n- name: 'Ensure hosts have the SSH private key loaded'\n  copy:\n    src: \"/tmp/id_rsa\"\n    dest: \"~/.ssh/id_rsa\"\n    force: yes\n    mode: 0600\n\n- name: 'Ensure hosts have the SSH public key loaded'\n  authorized_key:\n    user: root\n    state: present\n    key: \"{{ lookup('file', '/tmp/id_rsa.pub') }}\"\n\n- name: \"Clean up files\"\n  file:\n    path: \"{{ item }}\"\n    state: absent\n  with_items:\n  - '/tmp/id_rsa'\n  - '/tmp/id_rsa.pub'\n  run_once: true\n  delegate_to: \"localhost\"\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "5fc6b17a2c1838ea01c74d3a2c444b8c2ecdd58b", "filename": "playbooks/group_vars/all", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "file_inventory: ../inventory\nfile_env: ../env.yml\nfile_secrets: ../secrets.yml\nfile_ip_data: ../ip\nsku_name: Employee SKU\ndisk_free_space: 20\nnode_mem: 16384\nnode_vcpus: 4\nsizing: fixed\nbandwidth_limit: 1\nocp_version: \"3.11\"\nocs_version_tag: \"v3.11\"\nrepos:\n- rhel-7-server-rpms\n- rhel-7-server-extras-rpms\n- \"rhel-7-server-ose-{{ '%0.2f'| format(ocp_version|float) }}-rpms\"\n- \"{{ 'rhel-7-fast-datapath-rpms' if '%0.2f'| format(ocp_version|float) == '3.10' else 'rhel-7-server-extras-rpms'}}\"\npackages:\n- wget\n- git\n- net-tools\n- bind-utils\n- iptables-services\n- bridge-utils\n- bash-completion\n- kexec-tools\n- sos\n- psacct\npackages_jumphost:\n- openshift-ansible\nfirewall_ports:\n- 8443\n- 80\n- 443\n- 53\n- 10250\n- 2049\n- 2379\n- 2380\n- 4001\n- 4789\n- 9000\n- 1936\n- 9200\n- 9300\nproxy_whitelist:\n- github.com\n- redhat.com\ndocker_vg: ocp\ndocker_version: \"1.13\"\ndocker_prepull_tag: \"v{{ '%0.2f'| format(ocp_version|float) }}\"\ndocker_prepull:\n- registry.access.redhat.com/openshift3/ose-deployer\n- registry.access.redhat.com/openshift3/ose-node-problem-detector\n- registry.access.redhat.com/openshift3/ose-pod\n- registry.access.redhat.com/openshift3/ose-node\n- registry.access.redhat.com/openshift3/ose-docker-builder\npost_install_components:\n- console\n- monitoring\n- metering\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "3d0619e96152bde98bb5e1a5d67e0d5e6a3f75d2", "filename": "roles/network/templates/named/school.local.zone.db", "repository": "iiab/iiab", "decoded_content": "; this is a copy of school.internal.zone.db because named now does not\n;  permit (or can not distinguish read only attribute for) zones pointing to the same file\n@ in soa localhost. root 1 3H 15M 1W 1D\n  ns localhost.\n\n{{ iiab_hostname }}\tIN\tA\t172.18.96.1\nschoolserver\tIN\tA\t172.18.96.1\nschool\t\tIN\tA\t172.18.96.1\nwww\t\tIN\tA\t172.18.96.1\nntp\t\tIN\tA\t172.18.96.1\ntime\t\tIN\tA\t172.18.96.1\npresence\tIN\tA\t172.18.96.1\nxs\t\tIN\tA\t172.18.96.1\nlibrary\t\tIN\tA\t172.18.96.1\nbox\t\tIN\tA\t172.18.96.1\n\nconference.schoolserver\tIN\tA\t172.18.96.1\n\n\n; translations of school - in plain latin script\n; or un punycode of the utf-8 representation\n\n; es - escuela\nescuela         IN      CNAME       school\n\n; de - schule\nschule          IN      CNAME       school\n\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "9cce05582bef8742e4b72747ecdbec43470cb38f", "filename": "roles/ovirt-collect-logs/vars/db.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\novirt_collect_logs_tar_optional_params: \"\"\n"}, {"commit_sha": "1224adf2811c827a09ff0bf133fbb476901a547d", "sha": "a78e182aeadce254cb1a8396e0ca3b1898646609", "filename": "meta/main.yml", "repository": "nusenu/ansible-relayor", "decoded_content": "---\ngalaxy_info:\n  author: nusenu\n  description: An Ansible role for Tor Relay Operators\n  license: GPLv3\n  platforms:\n  - name: Debian\n    versions:\n    - jessie\n    - stretch\n  - name: FreeBSD\n    versions:\n    - 10.3\n    - 11.0\n  - name: OpenBSD\n    versions:\n    - 6.0\n  - name: EL\n    versions:\n    - 7\n  - name: Ubuntu\n    versions:\n    - xenial\n  - name: Fedora\n    versions:\n    - 25\n  galaxy_tags:\n    - tor\n    - ipv6\n    - anonymity\n    - networking\n  min_ansible_version: 2.1.3\ndependencies: []\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "8cf2b199fa566a541ca6d89a358c5de0c3a0ab2d", "filename": "roles/cups/templates/cups.conf", "repository": "iiab/iiab", "decoded_content": "ProxyPass /cups http://localhost:631\nProxyPassReverse /cups http://localhost:631\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "8cdeb6055a76fc77d089ab7b292b88d22adcbc16", "filename": "roles/ovirt-engine-install-packages/meta/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\ngalaxy_info:\n  author: \"Petr Kubica\"\n  description: \"oVirt packages installer\"\n  company: \"Red Hat\"\n  license: \"GPLv3\"\n  min_ansible_version: 1.9\n  platforms:\n  - name: EL\n    versions:\n    - all\n  galaxy_tags:\n    - installer\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "65b5bf2db2c94bb1f39b89679202a25b867e5e3c", "filename": "playbooks/vars/rocknsm_config.dist.yml", "repository": "rocknsm/rock", "decoded_content": "%YAML 1.1\n---\nrock_online_install: true\nrock_sysctl_file: /etc/sysctl.d/10-ROCK.conf\nrock_data_dir: /data\nrocknsm_dir: /opt/rocknsm\nrock_data_user: root\nrock_data_group: root\nrock_monifs: \"{{ ansible_interfaces | difference(['lo', ansible_default_ipv4.interface | default('lo') ])| list }}\"\nrock_hostname: \"{{ inventory_hostname_short }}\"\nrock_fqdn: \"{{ inventory_hostname }}\"\nrock_mgmt_nets: [ \"0.0.0.0/0\" ]\nrock_cache_dir: /srv/rocknsm/support\npulledpork_rules:\n  - { url: \"https://snort.org/downloads/community/\", file: \"community-rules.tar.gz\", apikey: \"Community\", test: \"{{not with_suricata and with_snort}}\" }\n  - { url: \"https://www.snort.org/reg-rules/\", file: \"snortrules-snapshot.tar.gz\", apikey: \"796f26a2188c4c953ced38ff3ec899d8ae543350\", test: \"{{not with_suricata and with_snort}}\" }\n  - { url: \"https://rules.emergingthreats.net/\", file: \"emerging.rules.tar.gz\", apikey: \"open-nogpl\" }\n  - { url: \"http://talosintel.com/feeds/ip-filter.blf\", file: \"IPBLACKLIST\", apikey: \"open\" }\n\n#### Retention Configuration ####\nelastic_close_interval: 15\nelastic_delete_interval: 60\nkafka_retention: 168\nsuricata_retention: 3\nbro_log_retention: 0\nbro_stats_retention: 0\n\n# Feature options - Don't flip these unless you know what you're doing\n# These control if the service is installed\nwith_stenographer: true\nwith_bro: true\nwith_suricata: true\nwith_snort: false\nwith_pulledpork: true\nwith_logstash: true\nwith_elasticsearch: true\nwith_kibana: true\nwith_filebeat: true\nwith_zookeeper: true\nwith_kafka: true\nwith_nginx: true\nwith_fsf: true\n\n# Feature options - Don't flip these unless you know what you're doing\n# These control if the systemd service is enabled\nenable_stenographer: false\nenable_bro: true\nenable_suricata: true\nenable_snort: false\nenable_pulledpork: true\nenable_logstash: true\nenable_elasticsearch: true\nenable_kibana: true\nenable_filebeat: true\nenable_zookeeper: true\nenable_kafka: true\nenable_nginx: true\nenable_fsf: false\n\nrocknsm_package_list:\n  - java-1.8.0-openjdk-headless\n  - jq\n  - GeoIP\n  - GeoIP-update\n  - tcpreplay\n  - tcpdump\n  - bats\n  - policycoreutils-python\n  - htop\n  - vim\n  - git\n  - tmux\n  - nmap-ncat\n  - logrotate\n  - kernel-ml\n  - perl-LWP-Protocol-https\n  - perl-Sys-Syslog\n  - perl-Crypt-SSLeay\n  - perl-Archive-Tar\n\nepel_baseurl: http://download.fedoraproject.org/pub/epel/$releasever/$basearch/\nepel_gpgurl:  https://dl.fedoraproject.org/pub/epel/RPM-GPG-KEY-EPEL-7\nelrepo_baseurl: http://elrepo.org/linux/kernel/el7/x86_64/\nelrepo_gpgurl: https://www.elrepo.org/RPM-GPG-KEY-elrepo.org\nelastic_baseurl: https://artifacts.elastic.co/packages/5.x/yum\nelastic_gpgurl: https://artifacts.elastic.co/GPG-KEY-elasticsearch\npulledpork_release: 0.7.2\npulledpork_url: \"https://github.com/shirkdog/pulledpork/archive/{{ pulledpork_release }}.tar.gz\"\npulledpork_filename: \"pulledpork-{{ pulledpork_release }}.tar.gz\"\npulledpork_engine_basepath: \"/etc/{{ \\\"suricata\\\" if with_suricata else \\\"snort\\\" }}\"\n\nrocknsm_baseurl: https://packagecloud.io/rocknsm/2/el/7/$basearch\nrocknsm_gpgurl: https://packagecloud.io/rocknsm/2/gpgkey\nrocknsm_local_baseurl: file:///srv/rocknsm\nbro_user: bro\nbro_group: bro\nbro_data_dir: \"{{ rock_data_dir }}/bro\"\nbro_cpu: \"{{ (ansible_processor_vcpus // 2) if (ansible_processor_vcpus <= 16) else 8 }}\"\nbro_rockscripts_repo: https://github.com/rocknsm/rock-scripts.git\nbro_rockscripts_branch: master\nbro_rockscripts_filename: \"rock-scripts_{{ bro_rockscripts_branch | replace('/', '-') }}.tar.gz\"\nrock_dashboards_repo: https://github.com/rocknsm/rock-dashboards.git\nrock_dashboards_branch: master\nrock_dashboards_url: \"https://github.com/rocknsm/rock-dashboards/archive/{{ rock_dashboards_branch }}.tar.gz\"\nrock_dashboards_filename: \"rock-dashboards_{{ rock_dashboards_branch | replace('/', '-') }}.tar.gz\"\nrock_dashboards_version: 2.0\nstenographer_user: stenographer\nstenographer_group: stenographer\nstenographer_data_dir: \"{{ rock_data_dir }}/stenographer\"\nsuricata_user: suricata\nsuricata_group: suricata\nsuricata_data_dir: \"{{ rock_data_dir }}/suricata\"\npulled_pork_repo: https://github.com/shirkdog/pulledpork.git\npulled_pork_oinkcode: 796f26a2188c4c953ced38ff3ec899d8ae543350\nfsf_user: fsf\nfsf_group: fsf\nfsf_data_dir: \"{{ rock_data_dir }}/fsf\"\nfsf_archive_dir: \"{{ fsf_data_dir }}/archive\"\nfsf_client_logfile: \"{{ fsf_data_dir }}/client.log\"\nkafka_user: kafka\nkafka_group: kafka\nkafka_data_dir: \"{{ rock_data_dir }}/kafka\"\nkafka_config_path: /etc/kafka/server.properties\nes_user: elasticsearch\nes_group: elasticsearch\nes_data_dir: \"{{ rock_data_dir }}/elasticsearch\"\nes_cluster_name: rocknsm\nes_node_name: \"{{ rock_hostname }}\"\nes_mem: \"{{ (ansible_memtotal_mb // 1024 // 2) if (ansible_memtotal_mb // 1024) < 64 else 31 }}\"\nes_url: \"http://localhost:9200\"\nes_memlock_override: |\n  [Service]\n  LimitMEMLOCK=infinity\nlogstash_user: logstash\nlogstash_group: logstash\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "a97143443b438d1bcb4fd69fc7f41060e9a429d3", "filename": "archive/playbooks/cicd-provision.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- hosts: localhost\n  pre_tasks:\n  - include: roles/common/pre_tasks/pre_tasks.yml\n  roles:\n    - role: common\n    - role: cicd-common\n    # Provision CICD Environment\n    - role: openstack-create\n      type: \"cicd\"\n      image_name: \"{{ cicd_openstack_image_name }}\"\n      security_groups: \"{{ cicd_openstack_security_groups }}\"\n      key_name: \"{{ openstack_key_name }}\"\n      flavor_name: \"{{ cicd_openstack_flavor_name }}\"\n      register_host_group: \"cicd\"\n      node_count: \"{{ cicd_instance_count }}\"\n      disk_volume: \"{{ cicd_storage_disk_volume }}\"\n      volume_size: \"{{ cicd_openstack_storage_size }}\"\n\n- hosts: cicd\n  remote_user: \"cloud-user\"\n  vars:\n    ansible_ssh_user: cloud-user\n  tasks:\n  - name: \"Enable direct root access\"\n    shell: \"cat ~/.ssh/authorized_keys | sudo tee /root/.ssh/authorized_keys >/dev/null\"\n\n- hosts: cicd\n  roles:\n    - role: subscription-manager\n\n- hosts: cicd\n  roles:\n  - cicd-common\n  - cicd\n"}, {"commit_sha": "045ff4bb9f4720739632aac2951fbf2798a99c8c", "sha": "0a67ae82a85e525acfc3f2bddacedd7b5d5cd6f6", "filename": "roles/cloud-azure/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- set_fact:\n    resource_group: \"Algo_{{ region }}\"\n\n- name: Create a resource group\n  azure_rm_resourcegroup:\n    secret: \"{{ azure_secret | default(lookup('env','AZURE_SECRET')) }}\"\n    tenant: \"{{ azure_tenant | default(lookup('env','AZURE_TENANT')) }}\"\n    client_id: \"{{ azure_client_id | default(lookup('env','AZURE_CLIENT_ID')) }}\"\n    subscription_id: \"{{ azure_subscription_id | default(lookup('env','AZURE_SUBSCRIPTION_ID')) }}\"\n    name: \"{{ resource_group }}\"\n    location: \"{{ region }}\"\n    tags:\n      Environment: Algo\n\n- name: Create a virtual network\n  azure_rm_virtualnetwork:\n    secret: \"{{ azure_secret | default(lookup('env','AZURE_SECRET')) }}\"\n    tenant: \"{{ azure_tenant | default(lookup('env','AZURE_TENANT')) }}\"\n    client_id: \"{{ azure_client_id | default(lookup('env','AZURE_CLIENT_ID')) }}\"\n    subscription_id: \"{{ azure_subscription_id | default(lookup('env','AZURE_SUBSCRIPTION_ID')) }}\"\n    resource_group: \"{{ resource_group }}\"\n    name: algo_net\n    address_prefixes: \"10.10.0.0/16\"\n    tags:\n      Environment: Algo\n\n- name: Create a subnet\n  azure_rm_subnet:\n    secret: \"{{ azure_secret | default(lookup('env','AZURE_SECRET')) }}\"\n    tenant: \"{{ azure_tenant | default(lookup('env','AZURE_TENANT')) }}\"\n    client_id: \"{{ azure_client_id | default(lookup('env','AZURE_CLIENT_ID')) }}\"\n    subscription_id: \"{{ azure_subscription_id | default(lookup('env','AZURE_SUBSCRIPTION_ID')) }}\"\n    resource_group: \"{{ resource_group }}\"\n    name: algo_subnet\n    address_prefix: \"10.10.0.0/24\"\n    virtual_network: algo_net\n    tags:\n      Environment: Algo\n\n- name: Create an instance\n  azure_rm_virtualmachine:\n    secret: \"{{ azure_secret | default(lookup('env','AZURE_SECRET')) }}\"\n    tenant: \"{{ azure_tenant | default(lookup('env','AZURE_TENANT')) }}\"\n    client_id: \"{{ azure_client_id | default(lookup('env','AZURE_CLIENT_ID')) }}\"\n    subscription_id: \"{{ azure_subscription_id | default(lookup('env','AZURE_SUBSCRIPTION_ID')) }}\"\n    resource_group: \"{{ resource_group }}\"\n    admin_username: ubuntu\n    virtual_network: algo_net\n    name: \"{{ azure_server_name }}\"\n    ssh_password_enabled: false\n    vm_size: Standard_D1\n    tags:\n      Environment: Algo\n    ssh_public_keys:\n      - { path: \"/home/ubuntu/.ssh/authorized_keys\", key_data: \"{{ lookup('file', '{{ SSH_keys.public }}') }}\" }\n    image:\n      offer: UbuntuServer\n      publisher: Canonical\n      sku: '16.04-LTS'\n      version: latest\n  register: azure_rm_virtualmachine\n\n- set_fact:\n    ip_address: \"{{ azure_rm_virtualmachine.ansible_facts.azure_vm.properties.networkProfile.networkInterfaces[0].properties.ipConfigurations[0].properties.publicIPAddress.properties.ipAddress }}\"\n\n- name: Add the instance to an inventory group\n  add_host:\n    name: \"{{ ip_address }}\"\n    groups: vpn-host\n    ansible_ssh_user: ubuntu\n    ansible_python_interpreter: \"/usr/bin/python2.7\"\n    ansible_ssh_private_key_file: \"{{ SSH_keys.private }}\"\n    cloud_provider: azure\n    ipv6_support: no\n\n- set_fact:\n    cloud_instance_ip: \"{{ ip_address }}\"\n\n- name: Ensure the group azure exists in the dynamic inventory file\n  lineinfile:\n    state: present\n    dest: configs/inventory.dynamic\n    line: '[azure]'\n\n- name: Populate the dynamic inventory\n  lineinfile:\n    state: present\n    dest: configs/inventory.dynamic\n    insertafter: '\\[azure\\]'\n    regexp: \"^{{ cloud_instance_ip }}.*\"\n    line: \"{{ cloud_instance_ip }}\"\n"}, {"commit_sha": "481f7ad18dc225973e1d676d33e58c49cbbfe986", "sha": "09207091fe7d8090d090f1d6e4204d82adcde044", "filename": "tasks/supervisor.yml", "repository": "openwisp/ansible-openwisp2", "decoded_content": "- name: uwsgi.ini\n  template:\n    src: ../templates/uwsgi.ini.j2\n    dest: \"{{ openwisp2_path }}/uwsgi.ini\"\n  notify: reload supervisor\n\n- name: supervisor uwsgi\n  template:\n    src: ../templates/supervisor/openwisp2.j2\n    dest: \"{{ supervisor_path | format('openwisp2') }}\"\n  notify: reload supervisor\n\n- name: supervisor runworker\n  template:\n    src: ../templates/supervisor/runworker.j2\n    dest: \"{{ supervisor_path | format('runworker') }}\"\n  notify: reload supervisor\n\n- name: supervisor daphne\n  template:\n    src: ../templates/supervisor/daphne.j2\n    dest: \"{{ supervisor_path | format('daphne') }}\"\n  notify: reload supervisor\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "4ddf1ccf0ac40e0ae530ba0b6d63666e52af4e2d", "filename": "roles/dns/manage-dns-zones/tasks/named/process-one-zone.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Set Zone state\n  set_fact:\n    zone_state: \"{{ (zone.state is defined) | ternary(zone.state, view.state | default('present')) }}\"\n\n- name: Remove Zone files if state is 'absent'\n  file:\n    path: \"{{ item }}\"\n    state: absent\n  ignore_errors: True\n  with_items:\n    - \"/var/named/static/{{ view.name + '-' + zone.dns_domain }}.db\"\n  when:\n    - zone_state == 'absent'\n\n- name: Prepare Zone Files\n  vars:\n    zone_dns_domain: \"{{ zone.dns_domain }}\"\n  template:\n    src: named/zone.db.j2\n    dest: \"/var/named/static/{{ view.name + '-' + zone.dns_domain }}.db\"\n    owner: named\n    group: named\n    mode: 0660\n  notify: restart named\n  when:\n    - zone.named is defined\n    - zone.named|bool != False\n    - zone_state == 'present'\n\n- name: Prepare the zone config content\n  vars:\n    zone_type: \"{{ zone.type | default('master') }}\"\n    zone_dns_domain: \"{{ zone.dns_domain }}\"\n    zone_forwarders: \"{{ zone.forwarders | default([]) }}\"\n    view_name: \"{{ view.name }}\"\n  template:\n    src: named/zone-config.j2\n    dest: \"{{ dns_zone_temp_config_dir }}/{{ view.name }}/0002-{{ zone.dns_domain }}.cfg\"\n    owner: named\n    group: named\n    mode: 0660\n  when:\n    - zone.named is defined\n    - zone.named|bool != False\n    - zone_state == 'present'\n\n- name: \"Set flag that a zone was processed\"\n  set_fact:\n    processed_zones: True\n  when:\n    - zone.named is defined\n    - zone.named|bool != False\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "3d8ff93e77d3c49e27f612992cb20bef163f36c6", "filename": "roles/config-iscsi-client/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: iscsi\n  roles:\n  - role: config-iscsi-client\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "6d9a0d1ebc181aa6a5b6b7730cff6b0afe38f135", "filename": "playbooks/openshift/start-cluster.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n- import_playbook: aws/start.yml\n  when:\n  - hosting_infrastructure == 'aws'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "26468133f3d02c6773a07bc3c7cc0331f3532c56", "filename": "playbooks/infra-virt-hosts.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Configure libvirt on the infrastructure hosts'\n  hosts: infra_virt_hosts\n  roles:\n  - role: config-libvirt\n  tags:\n  - configure_infra_hosts_libvirt\n\n- name: 'Configure the software source to ensure it is available for use'\n  hosts: infra_virt_hosts\n  roles:\n  - role: config-software-src\n  tags:\n  - configure_software_src\n\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "e498fc9b425af6f2195c605960e8dd12afd8b17c", "filename": "roles/ansible/tower/manage-job-templates/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Initilize facts\"\n  set_fact:\n    processed_job_templates: []\n    existing_job_templates_output: []\n    existing_inventories_output: []\n    existing_projects_output: []\n    existing_credentials_output: []\n\n# Utilize the `rest_get` library routine to ensure REST pagination is handled\n- name: \"Get the existing inventories\"\n  rest_get:\n    host_url: \"{{ tower_url }}\"\n    api_uri: \"/api/v2/inventories/\"\n    rest_user: \"{{ tower_admin_username }}\"\n    rest_password: \"{{ tower_admin_password }}\"\n  register: existing_inventories_output\n\n# Utilize the `rest_get` library routine to ensure REST pagination is handled\n- name: \"Get the existing projects\"\n  rest_get:\n    host_url: \"{{ tower_url }}\"\n    api_uri: \"/api/v2/projects/\"\n    rest_user: \"{{ tower_admin_username }}\"\n    rest_password: \"{{ tower_admin_password }}\"\n  register: existing_projects_output\n\n# Utilize the `rest_get` library routine to ensure REST pagination is handled\n- name: \"Get the existing job templates\"\n  rest_get:\n    host_url: \"{{ tower_url }}\"\n    api_uri: \"/api/v2/job_templates/\"\n    rest_user: \"{{ tower_admin_username }}\"\n    rest_password: \"{{ tower_admin_password }}\"\n  register: existing_job_templates_output\n\n# Utilize the `rest_get` library routine to ensure REST pagination is handled\n- name: \"Get the existing credentials\"\n  rest_get:\n    host_url: \"{{ tower_url }}\"\n    api_uri: \"/api/v2/credentials/\"\n    rest_user: \"{{ tower_admin_username }}\"\n    rest_password: \"{{ tower_admin_password }}\"\n  register: existing_credentials_output\n\n# Utilize the `rest_get` library routine to ensure REST pagination is handled\n- name: \"Get the existing users\"\n  rest_get:\n    host_url: \"{{ tower_url }}\"\n    api_uri: \"/api/v2/users/\"\n    rest_user: \"{{ tower_admin_username }}\"\n    rest_password: \"{{ tower_admin_password }}\"\n  register: existing_users_output\n\n# Utilize the `rest_get` library routine to ensure REST pagination is handled\n- name: \"Get the existing teams\"\n  rest_get:\n    host_url: \"{{ tower_url }}\"\n    api_uri: \"/api/v2/teams/\"\n    rest_user: \"{{ tower_admin_username }}\"\n    rest_password: \"{{ tower_admin_password }}\"\n  register: existing_teams_output\n\n- name: \"Process the inventory job template\"\n  include_tasks: process-job-template.yml\n  with_items:\n  - \"{{ ansible_tower_job_templates }}\"\n  loop_control:\n    loop_var: job_template\n\n- name: \"Elminate the job templates that should not be present\"\n  uri:\n    url: https://localhost/api/v2/job_templates/{{ item.id }}/\n    method: DELETE\n    user: admin\n    password: \"{{ tower_admin_password }}\"\n    validate_certs: no\n    status_code: 200,204\n  with_items:\n  - \"{{ existing_job_templates_output.rest_output | get_remaining_items(processed_job_templates, 'name', 'name')}}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "7a868d7ff9865dbfb154573f93772f9e1fe81ac2", "filename": "roles/docker/templates/docker.socket", "repository": "iiab/iiab", "decoded_content": "[unit]\nDescription=Docker Socket for the API\nPartOf=docker.service\n\n[Socket]\nListenStream=/var/run/docker.sock\nSocketMode=0660\nSocketUser=root\nSocketGroup=docker\n\n[Install]\nWantedBy=sockets.target\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "9a2249d35a7a3a140022248d423390f4a26f6122", "filename": "roles/idm-host-cert/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- hosts: localhost\n  vars:\n    idm_fqdn: \"idm.example.com\"\n    idm_user: \"admin\"\n    idm_password: \"admin!\"\n    csr_country: \"US\"\n    csr_state: \"North Carolina\"\n    csr_location: \"Raleigh\"\n    csr_org_name: \"Red Hat, Inc.\"\n    csr_org_unit: \"Open Innovation Labs\"\n    csr_email: \"myemail@example.com\"\n    host_name: \"host-1.example.com\"\n    host_realm: \"EXAMPLE.COM\"\n    host_description: \"Testing My Host Cert\"\n    target_host_cert_file: \"/tmp/{{ host_name }}.pem\"\n    target_host_key_file: \"/tmp/{{ host_name }}.key\"\n    target_ca_cert_file: \"/tmp/ca.pem\"\n  roles:\n  - idm-host-cert\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "513810698bf5161a255e0be31d83adf395c08b0e", "filename": "playbooks/roles/check_ntp/handlers/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "---\n- name: Restart chrony\n  service:\n    name: chrony\n    state: restarted\n\n- name: Restart ntp\n  service:\n    name: ntp\n    state: restarted\n\n\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "1e6eebd6b1a5e68fff5fd81158108f0257cd0fce", "filename": "archive/roles/cicd/tasks/docker.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n  \n- name: Install Docker\n  yum: \n    name: docker\n    state: present\n  tags: docker\n  \n- name: Docker Configuration File\n  lineinfile: \n    dest: /etc/sysconfig/docker \n    regexp: '^OPTIONS=.*$' \n    line: \"OPTIONS='--selinux-enabled --insecure-registry 172.30.0.0/16'\"\n  tags: docker\n\n- name: Docker Storage Setup Configuration File\n  copy:\n    content: >\n      DEVS={{ cicd_storage_disk_volume }}\\n\n      VG=docker_vg\n    dest: /etc/sysconfig/docker-storage-setup\n  register: docker_storage_setup\n  tags: docker\n  \n- name: Run Docker Storage Setup\n  command: docker-storage-setup\n  when: docker_storage_setup.changed == true\n  notify:\n  - restart docker\n  tags: docker\n\n- name: extend the vg\n  command: lvextend -l 90%VG /dev/docker_vg/docker-pool\n  when: docker_storage_setup.changed == true\n  notify:\n  - restart docker\n  tags: docker\n\n- name: Enable Docker Service\n  service: \n    name: docker\n    enabled: true\n  tags: docker"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "20da9090edfeede2c51e934e64334a16436cc377", "filename": "tasks/create_repo_yum_hosted_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_yum_hosted\n    args: \"{{ _nexus_repos_yum_defaults|combine(item) }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "e323d0b6c82aa96a999181a03f6b662ef33c041a", "filename": "roles/config-httpd/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: prep.yml\n- import_tasks: seed.yml\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "19f89ff8cdf0b4fd8caef673682d2b0e3775c097", "filename": "playbooks/openshift/fix-nfs-recycler.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n- hosts: masters:nodes\n  vars:\n    recycler_registry: registry.access.redhat.com\n    recycler_repository: openshift3\n    recycler_image: ose-recycler\n    recycler_tag: latest\n    recycler_serviceaccount: pv-recycler-controller\n    recycler_namespace: openshift-infra\n  tasks:\n\n    - name: Create Service Account\n      block:\n        - command: >\n            oc get serviceaccount {{ recycler_serviceaccount }} -n {{ recycler_namespace }}\n          ignore_errors: True\n          delegate_to: \"{{ groups.masters[0] }}\"\n          register: sa_exists\n        - command: >\n            oc create serviceaccount {{ recycler_serviceaccount }} -n {{ recycler_namespace }}\n          when: sa_exists.rc != 0\n          run_once: True\n          delegate_to: \"{{ groups.masters[0] }}\"\n\n    - name: Get OpenShift Version\n      command: >\n        oc version\n      run_once: True\n      delegate_to: \"{{ groups.masters[0] }}\"\n      register: ocp_version_result\n\n    - name: Set OpenShift Version\n      run_once: True\n      set_fact:\n        ocp_version: \"{{ ocp_version_result.stdout_lines[0].split(' ')[1] }}\"\n\n    - name: Pull Recycler Image\n      become: True\n      command: >\n        docker pull {{ recycler_registry }}/{{ recycler_repository }}/{{ recycler_image }}:{{ recycler_tag }}\n\n    - name: Tag Recycler Image\n      become: True\n      command: >\n        docker tag {{ recycler_registry }}/{{ recycler_repository }}/{{ recycler_image }}:{{ recycler_tag }} {{ recycler_registry }}/{{ recycler_repository }}/{{ recycler_image }}:{{ ocp_version }}\n\n    - name: Remove Recycler Latest Tag\n      become: True\n      command: >\n        docker rmi {{ recycler_registry }}/{{ recycler_repository }}/{{ recycler_image }}:{{ recycler_tag }}"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "ac77f536c8c3ae0b64070d9f560d8ac680fc1569", "filename": "roles/install-mongodb/tests/install_mongodb.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Install mongodb\n  hosts: dbserver\n  become: yes\n  vars:\n    mongodb_ver: 3.4\n    os_family: redhat\n    os_ver: 7\n  roles:\n    - install-mongodb"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "8bd0d05d7af9ef982757781c4f4d3f2bf228194c", "filename": "roles/dns/manage-dns-zones/tasks/named/prereq.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Use a unique temporary directory to store the config files pre-assemble'\n  tempfile:\n    state: directory\n    prefix: dns-zone\n  register: dns_zone_tempdir\n  notify:\n  - 'cleanup temp'\n\n- name: 'Store away the temporary configuration files directory name'\n  set_fact:\n    dns_zone_temp_config_dir: '{{ dns_zone_tempdir.path }}'\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "9a2fe0aa3e47c39595c8939e92359bbd1567e057", "filename": "roles/client/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: Gather Facts\n  setup:\n\n- name: Include system based facts and tasks\n  include: systems/main.yml\n\n- name: Checking the signature algorithm\n  local_action: >\n      shell openssl x509 -text -in certs/{{ IP_subject_alt_name }}.crt  | grep 'Signature Algorithm' | head -n1\n  become: no\n  register: sig_algo\n  args:\n    chdir: \"configs/{{ IP_subject_alt_name }}/pki/\"\n\n- name: Change the algorithm to RSA\n  set_fact:\n    Win10_Enabled: \"Y\"\n  when: '\"ecdsa\" not in sig_algo.stdout'\n\n- name: Install prerequisites\n  package: name=\"{{ item }}\" state=present\n  with_items:\n    - \"{{ prerequisites }}\"\n\n- name: Install strongSwan\n  package: name=strongswan state=present\n\n- name: Setup the ipsec config\n  template:\n    src: \"roles/vpn/templates/client_ipsec.conf.j2\"\n    dest: \"{{ configs_prefix }}/ipsec.{{ IP_subject_alt_name }}.conf\"\n    mode: '0644'\n  with_items:\n    - \"{{ vpn_user }}\"\n  notify:\n    - restart strongswan\n\n- name: Setup the ipsec secrets\n  template:\n    src: \"roles/vpn/templates/client_ipsec.secrets.j2\"\n    dest: \"{{ configs_prefix }}/ipsec.{{ IP_subject_alt_name }}.secrets\"\n    mode: '0600'\n  with_items:\n    - \"{{ vpn_user }}\"\n  notify:\n    - restart strongswan\n\n- name: Include additional ipsec config\n  lineinfile:\n    dest: \"{{ item.dest }}\"\n    line: \"{{ item.line }}\"\n    create: yes\n  with_items:\n    - dest: \"{{ configs_prefix }}/ipsec.conf\"\n      line: \"include ipsec.*.conf\"\n    - dest: \"{{ configs_prefix }}/ipsec.secrets\"\n      line: \"include ipsec.*.secrets\"\n  notify:\n    - restart strongswan\n\n- name: Setup the certificates and keys\n  template:\n    src: \"{{ item.src }}\"\n    dest: \"{{ item.dest }}\"\n  with_items:\n    - src: \"configs/{{ IP_subject_alt_name }}/pki/certs/{{ vpn_user }}.crt\"\n      dest: \"{{ configs_prefix }}/ipsec.d/certs/{{ IP_subject_alt_name }}_{{ vpn_user }}.crt\"\n    - src: \"configs/{{ IP_subject_alt_name }}/pki/cacert.pem\"\n      dest: \"{{ configs_prefix }}/ipsec.d/cacerts/{{ IP_subject_alt_name }}.pem\"\n    - src: \"configs/{{ IP_subject_alt_name }}/pki/private/{{ vpn_user }}.key\"\n      dest: \"{{ configs_prefix }}/ipsec.d/private/{{ IP_subject_alt_name }}_{{ vpn_user }}.key\"\n  notify:\n    - restart strongswan\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "cc9c26b2ca9989486ba8b38dc7434cd5137f00e1", "filename": "roles/nextcloud/tasks/nextcloud_enabled.yml", "repository": "iiab/iiab", "decoded_content": " # This should go in computed_network.yml, but here for now\n- name: Compute nextcloud listen ip addr for nextcloud.conf\n  set_fact:\n     nextcloud_required_ip: \"{{ ansible_default_ipv4.network }}/{{ ansible_default_ipv4.netmask }}\"\n  when: ansible_default_ipv4.network is defined\n\n- name: Enable nextcloud by copying template to httpd config\n  template: src=nextcloud.conf.j2\n            dest=/etc/{{ apache_config_dir }}/nextcloud.conf\n            owner=root\n            group=root\n            mode=0644\n  when: nextcloud_enabled\n\n- name: Enable nextcloud\n  file: path=/etc/apache2/sites-enabled/nextcloud.conf\n        src=/etc/apache2/sites-available/nextcloud.conf\n        state=link\n  when: nextcloud_enabled and is_debuntu\n\n- name: For redhat, remove the config file\n  file: path=/etc/{{ apache_config_dir }}/nextcloud.conf\n        state=absent\n  when: not nextcloud_enabled and is_redhat\n\n- name: Restart apache, so it picks up the new aliases\n  service: name={{ apache_service }} state=restarted\n\n# the install wizard does not succeed if already installed\n- name: Determine if nextcloud is installed\n  shell: >\n         sudo -u {{ apache_user }} php\n         '{{ nextcloud_prefix }}/nextcloud/occ' status |\n         gawk '/installed:/ { print $3 }'\n  register: returned\n\n- name: Run nextcloud initial install wizard\n  shell: >\n         cd {{ nextcloud_prefix }}/nextcloud;\n         sudo -u {{ apache_user }}  php occ maintenance:install\n         --database \"mysql\"\n         --database-name \"{{ nextcloud_dbname }}\"\n         --database-user \"{{ nextcloud_dbuser }}\"\n         --database-pass \"{{ nextcloud_dbpassword }}\"\n         --admin-user \"{{ nextcloud_admin_user }}\"\n         --admin-pass \"{{ nextcloud_admin_password }}\"\n  when: nextcloud_enabled and returned.stdout == \"false\"\n\n- name: allow access from all hosts and ips\n  command: php '{{ nextcloud_prefix }}/nextcloud/occ' config:system:set trusted_domains 1 --value=*\n  become: true\n  become_user: \"{{ apache_user }}\"\n  when: nextcloud_enabled and returned.stdout == \"false\"\n\n- name: Determine if nextcloud user exists already\n  shell: >\n         sudo -u {{ apache_user }} php\n         '{{ nextcloud_prefix }}/nextcloud/occ' user:list |\n         grep {{ nextcloud_user }} | wc | cut -d' ' -f1\n  register: returned_count\n\n# nextcloud wants to make users rather than just mysql users and not done\n- name: create the default user\n  shell: >\n        su -s /bin/sh {{ apache_user }} -c\n        'OC_PASS={{ nextcloud_user_password }};\n        php {{ nextcloud_prefix }}/nextcloud/occ user:add\n        --password-from-env --display-name={{ nextcloud_user }}\n        --group=\"users\" {{ nextcloud_user }}'\n  when: nextcloud_enabled and returned_count == \"0\"\n\n- name: Remove Rewrite URL\n  lineinfile: regexp='overwrite.cli.url'\n              state=absent\n              dest=\"{{ nextcloud_prefix }}/nextcloud/config/config.php\"\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "0898c261d8acb8e23ec5820d4adaffc51b3fdfa7", "filename": "playbooks/files/logstash-kafka-bro.conf", "repository": "rocknsm/rock", "decoded_content": "input {\n  kafka {\n    topics => [\"bro-raw\"]\n    add_field => { \"[@metadata][stage]\" => \"broraw_kafka\" }\n    # Set this to one per kafka partition to scale up\n    #consumer_threads => 4\n    group_id => \"bro_logstash\"\n    bootstrap_servers => \"127.0.0.1:9092\"\n    codec => json\n    auto_offset_reset => \"earliest\"\n  }\n}\n\nfilter {\n  if \"_jsonparsefailure\" in [tags] {\n    drop { }\n  }\n\n  if [@metadata][stage] == \"broraw_kafka\" {\n\n    # Set the timestamp\n    date { match => [ \"ts\", \"ISO8601\" ] }\n\n    # move metadata to new field\n    mutate {\n      rename => {\n        \"@stream\" => \"[@meta][stream]\"\n        \"@system\" => \"[@meta][system]\"\n        \"@proc\"   => \"[@meta][proc]\"\n      }\n    }\n\n    # Rename ID field from file analyzer logs\n    if [@meta][stream] in [\"pe\", \"x509\", \"files\"] {\n      mutate { rename => { \"id\" => \"fuid\" } }\n      mutate {\n        add_field => { \"[@meta][event_type]\" => \"file\" }\n        add_field => { \"[@meta][id]\" => \"%{fuid}\" }\n      }\n    } else if [@meta][stream] in [\"intel\", \"notice\", \"notice_alarm\", \"signatures\", \"traceroute\"] {\n      mutate { add_field => { \"[@meta][event_type]\" => \"detection\" } }\n    } else if [@meta][stream] in [ \"capture_loss\", \"cluster\", \"communication\", \"loaded_scripts\", \"packet_filter\", \"prof\", \"reporter\", \"stats\", \"stderr\", \"stdout\" ] {\n      mutate { add_field => { \"[@meta][event_type]\" => \"diagnostic\" } }\n    } else if [@meta][stream] in [\"netcontrol\", \"netcontrol_drop\", \"netcontrol_shunt\", \"netcontrol_catch_release\", \"openflow\"] {\n      mutate { add_field => { \"[@meta][event_type]\" => \"netcontrol\" } }\n    } else if [@meta][stream] in [\"known_certs\", \"known_devices\", \"known_hosts\", \"known_modbus\", \"known_services\", \"software\"] {\n      mutate { add_field => { \"[@meta][event_type]\" => \"observations\" } }\n    } else if [@meta][stream] in [\"barnyard2\", \"dpd\", \"unified2\", \"weird\"] {\n      mutate { add_field => { \"[@meta][event_type]\" => \"miscellaneous\" } }\n    } else {\n\n      # Network type\n      mutate {\n        convert => {\n          \"id_orig_p\" => \"integer\"\n          \"id_resp_p\" => \"integer\"\n        }\n        add_field => {\n          \"[@meta][event_type]\" => \"network\"\n          \"[@meta][id]\" => \"%{uid}\"\n          \"[@meta][orig_host]\" => \"%{id_orig_h}\"\n          \"[@meta][orig_port]\" => \"%{id_orig_p}\"\n          \"[@meta][resp_host]\" => \"%{id_resp_h}\"\n          \"[@meta][resp_port]\" => \"%{id_resp_p}\"\n        }\n      }\n      geoip {\n        source => \"id_orig_h\"\n        target => \"[@meta][geoip_orig]\"\n      }\n      geoip {\n        source => \"id_resp_h\"\n        target => \"[@meta][geoip_resp]\"\n      }\n    }\n\n    # Tie related records\n    mutate { add_field => { \"[@meta][related_ids]\" => [] }}\n    if [uid] {\n      mutate { merge => {\"[@meta][related_ids]\" => \"uid\" }}\n    }\n    if [fuid] {\n      mutate { merge => {\"[@meta][related_ids]\" => \"fuid\" }}\n    }\n    if [related_fuids] {\n      mutate { merge => { \"[@meta][related_ids]\" => \"related_fuids\" }}\n    }\n    if [orig_fuids] {\n      mutate { merge => { \"[@meta][related_ids]\" => \"orig_fuids\" }}\n    }\n    if [resp_fuids] {\n      mutate { merge => { \"[@meta][related_ids]\" => \"resp_fuids\" }}\n    }\n    if [conn_uids] {\n      mutate { merge => { \"[@meta][related_ids]\" => \"conn_uids\" }}\n    }\n    if [cert_chain_fuids] {\n      mutate { merge => { \"[@meta][related_ids]\" => \"cert_chain_fuids\" }}\n    }\n\n    # Nest the entire document\n    ruby {\n      code => \"\n      require 'logstash/event'\n\n      logtype = event.get('[@meta][stream]')\n      ev_hash = event.to_hash\n      meta_hash = ev_hash['@meta']\n      timestamp = ev_hash['@timestamp']\n\n      # Cleanup duplicate info\n      #meta_hash.delete('stream')\n      ev_hash.delete('@meta')\n      ev_hash.delete('@timestamp')\n      ev_hash.delete('tags')\n\n      result = {\n        logtype => ev_hash,\n        '@meta' => meta_hash,\n        '@timestamp' => timestamp\n      }\n      event.initialize( result )\n      \"\n    }\n    mutate { add_field => {\"[@metadata][stage]\" => \"broraw_kafka\" } }\n  }\n}\n\noutput {\n  if [@metadata][stage] == \"broraw_kafka\" {\n    kafka {\n     codec => json\n     topic_id => \"bro-clean\"\n     bootstrap_servers => \"127.0.0.1:9092\"\n    }\n\n    elasticsearch {\n      hosts => [\"127.0.0.1\"]\n      index => \"bro-%{+YYYY.MM.dd}\"\n      document_type => \"%{[@meta][event_type]}\"\n      manage_template => false\n    }\n  }\n}\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "4a6d8ae6098d1db674748e3de9f01b321308a1c7", "filename": "roles/httpd/files/html/credits.html", "repository": "iiab/iiab", "decoded_content": "<!DOCTYPE html>\n<META http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n<link rel=\"stylesheet\" type=\"text/css\" media=\"all\" href=\"xs-portal.css\" />\n<HTML>\n<HEAD>\n\n<TITLE>Credits</TITLE>\n\n</HEAD>\n<BODY>\n  <h1>Internet-in-a-Box Credits</h1>\n\n  The XSCE School Server known as Internet-in-a-Box includes a variety of educational and other content and applications which are attributed as follows:<br><br>\n\n  All Wikipedia content is available for free at  <a href=\"http://www.wikipedia.org/\">www.wikipedia.org</a>.<br>\n  All other Wikimedia content is available for free via links at  <a href=\"http://www.wikimedia.org/\">www.wikimedia.org</a>.<br>\n  All Khan Academy content is available for free at  <a href=\"http://www.khanacademy.org/\">www.khanacademy.org</a>.<br>\n  All CK-12 content is available for free at  <a href=\"http://www.ck-12.org/\">www.ck-12.org</a>.<br>\n  All PhET Interactive Simulations content is available for free at  <a href=\"http://phet.colorado.edu\">phet.colorado.edu</a>.<br>\n  All MedLine content is available for free at  <a href=\"http://www.nlm.nih.gov/medlineplus/\">www.nlm.nih.gov/medlineplus</a>.<br>\n  All Hesperian content is available for free at  <a href=\"http://www.hesperian.org/\">www.hesperian.org</a>.<br>\n  All Gutenberg content is available for free at  <a href=\"http://www.gutenberg.org/\">www.gutenberg.org</a>.<br>\n  All OLPC content is available for free at  <a href=\"http://wiki.laptop.org/go/Library_grid\">www.laptop.org</a>.<br>\n  All MIT Scratch content is available for free at  <a href=\"http://scratch.mit.edu\">scratch.mit.edu</a>.<br>\n  All UNESCO's IICBA content is available for free at  <a href=\"http://www.eng.unesco-iicba.org/elibrary\">www.eng.unesco-iicba.org</a>.<br>\n  All Math Expression content is available for free at  <a href=\"http://www.mathexpression.com\">www.mathexpression.com</a>.<br>\n  All Music Theory content is available for free at  <a href=\"http://www.musictheory.net\">www.musictheory.net</a>.<br><br>\n\n  Internet-in-a-Box also includes the work of content aggregators which we gratefully acknowledge:<br><br>\n\n  RACHEL is a curation of selected offline content at  <a href=\"http://www.rachel.worldpossible.org/\">www.rachel.worldpossible.org</a>.<br>\n  Kiwix is a Zim server and repository of Wikimedia and other content in a compressed Zim file format at <a href=\"http://www.kiwix.org/\">www.kiwix.org</a>.<br>\n  KA Lite is a server and repository of Khan Academy content in various languages at  <a href=\"http://learningequality.org/ka-lite/\">learningequality.org/ka-lite</a>.<br><br>\n\n  Internet-in-a-Box also contains a number of applications each of which has its own attribution information which is included.<br><br>\n\n  This Internet-in-a-Box distribution resides at <a href=\"http://github.com/XSCE/iiab\">github.com/XSCE/iiab</a>.<br><br>\n\n  It is licensed under the terms of the GNU Library General Public License as published by the Free Software Foundation; either version 2 of the License, or (at your option) any later version.<br><br>\n\n  Licensing information may be found at  <a href=\"http://github.com/XSCE/iiab/blob/master/LICENSE\">github.com/XSCE/iiab/blob/master/LICENSE</a>.<br>\n\n</BODY>\n<script type=\"text/javascript\" src=\"incl/xs-portal.js\"></script>\n</HTML>\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "c9c0af7e25d8980c9fe08ae2e96d912023d57472", "filename": "roles/ovirt-engine-install-packages/defaults/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\n# default vars for ovirt-ovirt-engine-install-packages-packages role\novirt_engine_dwh: True\novirt_engine_version: 4.1\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "568b5ab6c1b262fb582af225aade814d45d25043", "filename": "roles/xovis/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "---\n# The values here are defaults.\n# To override them edit the main var definitions in iiab/vars\n\nxovis_target_host: \"127.0.0.1:5984\"\nxovis_deployment_name: olpc\n\nxovis_db_name: xovis\nxovis_db_user: admin\nxovis_db_password: admin\nxovis_db_login: \"{{ xovis_db_user }}:{{ xovis_db_password }}\"\nxovis_db_url: \"http://{{ xovis_db_login }}@{{ xovis_target_host }}/{{ xovis_db_name }}\"\n\nxovis_root: \"/opt/xovis\"\nxovis_backup_dir: \"/library/users\"\nxovis_repo_url: \"https://github.com/XSCE/xovis.git\"\nxovis_chart_heading: \"My School: Usage Data Visualization\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "9f3cc1f8a19b50a9945d679bbe21de4fa24aae2c", "filename": "roles/config-openvpn/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# Default OpenVPN RPM to be installed\n# NOTE: this is the CentOS flavor \ndefault_openvpn_rpm: http://swupdate.openvpn.org/as/openvpn-as-2.1.9-CentOS7.x86_64.rpm\n\n"}, {"commit_sha": "51dcdf691a7801895b569a5a927e30030d8feb70", "sha": "b94910d066d3d639c7732d139e75d3a013cd06cb", "filename": "tasks/freebsd_install.yml", "repository": "nusenu/ansible-relayor", "decoded_content": "---\n\n- name: Setup FreeBSD specific variables (set_fact)\n  set_fact:\n    tor_DataDir: /var/db/tor\n    tor_ConfDir: /usr/local/etc/tor/enabled\n  tags:\n   - reconfigure\n   - renewkey\n   - createdir\n\n- name: Ensure Tor is installed (FreeBSD)\n  become: yes\n  pkgng: name=tor state=present\n\n# temporary solution until rc.d supports multiple instances\n- name: Ensure Tor starts at boot (FreeBSD)\n  become: yes\n  lineinfile: dest=/etc/rc.local line=\"/usr/local/bin/tor -f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\" create=yes\n  with_nested:\n   - tor_ips\n   - tor_ports\n\n- name: If LogDir is a file, rename it (FreeBSD)\n  become: yes\n  shell: \"test -f {{ tor_LogDir }} && mv {{ tor_LogDir }} {{ tor_LogDir }}.bk-`date '+%Y-%m-%d_%H%M%S'`\"\n  ignore_errors: yes\n\n- name: Ensure sequential IP IDs are avoided (net.inet.ip.random_id)\n  become: yes\n  sysctl: name=net.inet.ip.random_id value=1 reload=no sysctl_set=yes\n  tags:\n    - freebsdkern\n\n- name: Gather current kern.ipc.somaxconn setting (FreeBSD)\n  shell: \"sysctl kern.ipc.somaxconn|cut -d' '  -f2\"\n  register: currentsomaxconn\n  tags:\n   - freebsdkern\n\n- name: Ensure somaxconn setting is reasonable (FreeBSD)\n  become: yes\n  command: \"sysctl kern.ipc.somaxconn={{ freebsd_somaxconn }}\"\n  when: currentsomaxconn.stdout|int < {{ freebsd_somaxconn }}\n  tags:\n   - freebsdkern\n\n- name: Ensure somaxconn setting in sysctl.conf is reasonable (FreeBSD)\n  become: yes\n  lineinfile: dest=/etc/sysctl.conf regexp=^kern.ipc.somaxconn line=\"kern.ipc.somaxconn={{ freebsd_somaxconn }}\" create=yes\n  when: currentsomaxconn.stdout|int < {{ freebsd_somaxconn }}\n  tags:\n   - freebsdkern\n\n- name: Gather current kern.ipc.nmbclusters setting (FreeBSD)\n  shell: \"sysctl kern.ipc.nmbclusters|cut -d' '  -f2\"\n  register: currentnmbc\n  tags:\n   - freebsdkern\n\n- name: Ensure nmbclusters setting is reasonable (FreeBSD)\n  become: yes\n  command: \"sysctl kern.ipc.nmbclusters={{ freebsd_nmbclusters }}\"\n  when: currentnmbc.stdout|int < {{ freebsd_nmbclusters }}\n  tags:\n   - freebsdkern\n\n- name: Ensure nmbclusters setting in sysctl.conf is reasonable (FreeBSD)\n  become: yes\n  lineinfile: dest=/etc/sysctl.conf regexp=^kern.ipc.nmbclusters line=\"kern.ipc.nmbclusters={{ freebsd_nmbclusters }}\" create=yes\n  when: currentnmbc.stdout|int < {{ freebsd_nmbclusters }}\n  tags:\n   - freebsdkern\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "5a9fa044e1447502dbca05548c45199d7d5725ff", "filename": "playbooks/provision-bastion/install.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Prep the bastion host for Ansible runs\"\n  hosts: bastion\n  gather_facts: no\n  roles:\n  - role: ansible/prep-for-ansible\n\n# NOTE: it's important that the docker role is done after the ipa-client role\n- name: 'Install and Configure the bastion host'\n  hosts: bastion\n  roles:\n  - role: config-timezone\n  - role: update-host\n  - role: config-ipa-client\n  - role: config-docker\n  - role: config-docker-compose\n  - role: config-linux-desktop/config-gnome\n  - role: config-linux-desktop/config-xfce\n  - role: config-linux-desktop/config-lxde\n  - role: config-linux-desktop/config-mate\n  - role: config-vnc-server\n  - role: config-packages\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "7506f872bd2f3dc62451c80622cbd35e0bb5278b", "filename": "roles/manage-aws-infra/tasks/create-instance.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "# Tasks to deploy AWS ec2 instance(s) based in the requested parameters\n---\n\n- name: \"Create ec2 instance(s)\"\n  ec2:\n    image: \"{{ ec2_image }}\"\n    instance_type: \"{{ ec2_instance_type }}\"\n    group: \"{{ ec2_group }}\"\n    termination_protection: \"{{ aws_termination_protection }}\"\n    key_name: \"{{ aws_key_name }}\"\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    region: \"{{ aws_region }}\"\n    vpc_subnet_id: \"{{ aws_vpc_subnet_id }}\"\n    exact_count: 1\n    wait: yes\n    count_tag:\n      Name: \"{{ ec2_name }}-{{ item }}\"\n    instance_tags:\n      \"{{ ec2_instance_tags|combine({ 'Name': ec2_name + '-' + item,\n                                      'kubernetes.io/cluster/cluster-' + env_id: env_id } ) }}\"\n    volumes: \"{{ ec2_volumes }}\"\n  with_sequence:\n    count=\"{{ ec2_num_instances }}\"\n  register: ec2_instances\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "7582feb687858ed7493682946858a7c5b4c480cd", "filename": "tasks/checks/distribution-checks.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Fail if this roles does not support the distribution\n  fail:\n    msg: \"Distribution {{ _docker_os_dist }} is not supported by this role!\"\n  when: _docker_os_dist != \"Fedora\" and\n        _docker_os_dist != \"CentOS\" and\n        _docker_os_dist != \"RedHat\" and\n        _docker_os_dist != \"Ubuntu\" and\n        _docker_os_dist != \"Debian\"\n\n- name: Fail if kernel version is lower than 3.10\n  fail:\n    msg: \"Kernel version 3.10 or later is required!\"\n  when: ansible_kernel is version_compare(\"3.10\", '<')\n\n- name: Include distribution check tasks for {{ _docker_os_dist }}\n  include_tasks: distribution-checks-{{ _docker_os_dist }}.yml\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "164a60654f5040b5172ef70255734ef3701be020", "filename": "roles/config-dns-server/tasks/named.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Setup ACLs\n  template: \n    src: named.conf.acl.j2\n    dest: /etc/named/named.conf.acl \n    owner: named \n    group: named\n    mode: 0660\n  notify: restart named\n\n- name: Setup DNS Logging configuration\n  template: \n    src: named.conf.logging.j2\n    dest: /etc/named/named.conf.logging\n    owner: named\n    group: named\n    mode: 0660\n  notify: restart named\n\n- name: Setup Controls configuration\n  template:\n    src: named.conf.controls.j2\n    dest: /etc/named/named.conf.controls\n    owner: named\n    group: named\n    mode: 0660\n  notify: restart named\n\n- name: Configure named options\n  template:\n    src: named.conf.options.j2\n    dest: /etc/named/named.conf.options\n    owner: named\n    group: named \n  notify: restart named\n\n- name: Setup Domain Keys configuration\n  template:\n    src: named.conf.domain-keys.j2\n    dest: /etc/named/named.conf.domain-keys\n    owner: named\n    group: named\n    mode: 0660\n  notify: restart named\n\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "08a380e495096a6b5e0526250970b8c44ab58f00", "filename": "roles/cloud-gce/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "- set_fact:\n    credentials_file_path: \"{{ credentials_file | default(lookup('env','GCE_CREDENTIALS_FILE_PATH'), true) }}\"\n    ssh_public_key_lookup: \"{{ lookup('file', '{{ SSH_keys.public }}') }}\"\n\n- set_fact:\n    credentials_file_lookup: \"{{ lookup('file', '{{ credentials_file_path }}') }}\"\n\n- set_fact:\n    service_account_email: \"{{ credentials_file_lookup.client_email | default(lookup('env','GCE_EMAIL')) }}\"\n    project_id: \"{{ credentials_file_lookup.project_id | default(lookup('env','GCE_PROJECT')) }}\"\n\n- name: \"Creating a new instance...\"\n  gce:\n    instance_names: \"{{ server_name }}\"\n    zone: \"{{ zone }}\"\n    machine_type: \"{{ cloud_providers.gce.size }}\"\n    image: ubuntu-1604\n    service_account_email: \"{{ service_account_email }}\"\n    credentials_file: \"{{ credentials_file_path }}\"\n    project_id: \"{{ project_id }}\"\n    metadata: '{\"ssh-keys\":\"ubuntu:{{ ssh_public_key_lookup }}\"}'\n    # ip_forward: true\n    tags:\n      - \"environment-algo\"\n  register: google_vm\n\n- name: Add the instance to an inventory group\n  add_host:\n    name: \"{{ google_vm.instance_data[0].public_ip }}\"\n    groups: vpn-host\n    ansible_ssh_user: ubuntu\n    ansible_python_interpreter: \"/usr/bin/python2.7\"\n    ansible_ssh_private_key_file: \"{{ SSH_keys.private }}\"\n    cloud_provider: gce\n    ipv6_support: no\n\n- name: Firewall configured\n  local_action:\n    module: gce_net\n    name: \"{{ google_vm.instance_data[0].network }}\"\n    fwname: \"algo-ikev2\"\n    allowed: \"udp:500,4500;tcp:22\"\n    state: \"present\"\n    src_range: 0.0.0.0/0\n    service_account_email: \"{{ credentials_file_lookup.client_email }}\"\n    credentials_file: \"{{ credentials_file  }}\"\n    project_id: \"{{ credentials_file_lookup.project_id }}\"\n\n- set_fact:\n    cloud_instance_ip: \"{{ google_vm.instance_data[0].public_ip }}\"\n\n- name: Ensure the group gce exists in the dynamic inventory file\n  lineinfile:\n    state: present\n    dest: configs/inventory.dynamic\n    line: '[gce]'\n\n- name: Populate the dynamic inventory\n  lineinfile:\n    state: present\n    dest: configs/inventory.dynamic\n    insertafter: '\\[gce\\]'\n    regexp: \"^{{ google_vm.instance_data[0].public_ip }}.*\"\n    line: \"{{ google_vm.instance_data[0].public_ip }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "d3e4331585d951384f0d0b9b449a69144017864b", "filename": "roles/ansible/tower/config-ansible-tower/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: install.yml\n"}, {"commit_sha": "51dcdf691a7801895b569a5a927e30030d8feb70", "sha": "195bbb694ee97b5ee742114e67c4a2314b3729fb", "filename": "tasks/main.yml", "repository": "nusenu/ansible-relayor", "decoded_content": "---\n\n- include: apt_install.yml\n  when: ansible_pkg_mgr == 'apt'\n  tags:\n   - debian\n   - install\n\n- include: rpm_install.yml\n  when: ansible_pkg_mgr == 'yum' or ansible_pkg_mgr == 'dnf'\n  tags:\n   - centos\n   - fedora\n   - install\n\n- include: openbsd_install.yml\n  when: ansible_pkg_mgr == 'openbsd_pkg'\n  tags:\n   - openbsd\n   - install\n\n- include: freebsd_install.yml\n  when: ansible_pkg_mgr == 'pkgng'\n  tags:\n   - freebsd\n   - install\n\n- include: configure.yml\n  tags:\n   - debian\n   - centos\n   - fedora\n   - openbsd\n   - freebsd\n\n- include: linux_service.yml\n  when: ansible_system == 'Linux'\n  tags:\n   - debian\n   - centos\n   - fedora\n\n- include: openbsd_service.yml\n  when: ansible_system == 'OpenBSD'\n  tags:\n   - openbsd\n\n- include: freebsd_service.yml\n  when: ansible_system == 'FreeBSD'\n  tags:\n   - freebsd\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "a9e293f005007b61323cdd3a5c78fb100e46726b", "filename": "playbooks/notifications/email-notify-list-of-users.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Send HTML e-mail message to a list of users who are members of a group\"\n  hosts: mail-host\n  gather_facts: no\n  tasks:\n  - include_vars:\n      file: \"{{ email_content_file }}\"\n  - include_role:\n      name: notifications/md-to-html\n      vars:\n        markdown_content: \"{{ body }}\"\n  - set_fact:\n      mail:\n        subject: \"{{ subject }}\"\n        body: \"{{ md_to_html.html_body_message }}\"\n  - include_role:\n      name: roles/user-management/list-users-by-group\n  - set_fact:\n      list_of_mail_to: \"{{ list_of_mail_to | default([]) }} + [ {{ item.email }} ]\"\n    with_items: \n    - \"{{ list_of_users }}\"\n  - include_role:\n      name: notifications/send-email\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "5e93f5c3f82d9e39b6fdc4c07db1b1acff90d0fc", "filename": "roles/network/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- include: computed_network.yml\n  when: not installing\n  tags:\n    - network\n    - network-discover\n\n- name: Set hostname\n  template: dest=/etc/hostname\n            src=network/hostname.j2\n            owner=root\n            mode=0644\n  tags:\n    - network\n    - domain\n\n- name: Configure /etc/sysconfig/network\n  template: src=network/sysconfig.network.j2\n            dest=/etc/sysconfig/network\n            owner=root\n            group=root\n            mode=0644\n  tags:\n    - network\n    - domain\n\n- name: Create iiab_domain_name flag\n  template: src=network/{{ item }}.j2\n            dest=/etc/sysconfig/{{ item }}\n            mode=0644\n  with_items:\n    - iiab_domain_name\n  register: domainname\n  tags:\n    - network\n    - domain\n\n\n##### Start static ip address info for first run #####\n#- include: static.yml\n#  when: 'iiab_wan_iface != \"none\" and wan_ip != \"dhcp\"'\n##### End static ip address info\n\n- include: hosts.yml\n  tags:\n    - network\n\n- include: named.yml\n  tags:\n    - named\n    - network\n\n- include: dhcpd.yml\n  tags:\n    - dhcpd\n    - network\n\n- include: squid.yml\n  tags:\n    - squid\n    - network\n  when: squid_install\n\n- include: wondershaper.yml\n  tags:\n    - wondershaper\n    - network\n\n- include: iptables.yml\n  tags:\n    - iptables\n    - network\n\n- include: avahi.yml\n  tags:\n    - network\n\n- name: ask systemd to reread the unit files, picks up changes done\n  shell: systemctl daemon-reload\n  when: not installing\n\n- include: ifcfg_mods.yml\n  tags:\n    - network\n  when: is_redhat and not installing\n\n- include: debian.yml\n  tags:\n    - network\n  when: is_debuntu and not is_rpi  and not installing\n\n- include: rpi_debian.yml\n  tags:\n    - network\n  when: is_debuntu and is_rpi  and not installing\n\n- name: Create iiab network flags\n  template: src=network/{{ item }}.j2\n            dest=/etc/sysconfig/{{ item }}\n            mode=0644\n  with_items:\n    - iiab_wan_device\n    - iiab_lan_device\n  when: not installing\n  tags:\n    - network\n\n- include: computed_services.yml\n  tags:\n    - network\n\n- include: enable_services.yml\n  tags:\n    - network\n\n- include: restart.yml\n  when: not installing\n  tags:\n    - network\n\n- include: hostapd.yml\n  when: not installing\n  tags:\n    - network\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "f08240881af61ed76d392dddd20e767d3e001d96", "filename": "roles/manage-aws-infra/tasks/update_dns.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "# Create/update Route 53 zone with new records fro Infra and Master\n---\n- name: Ensure Route53 zone is present\n  route53_zone:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    zone: \"{{ dns_domain }}\"\n    state: present\n\n- name: Update Route53 with OCP master record\n  route53:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    zone: \"{{ dns_domain }}.\"\n    record: \"master-0.{{ env_id }}.{{ dns_domain }}.\"\n    type: A\n    value: \"{{ master_eip.public_ip }}\"\n    command: create\n    overwrite: yes\n    ttl: 300\n  when: not ha_mode\n\n- name: Update Route53 with OCP infra wildcard record\n  route53:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    zone: \"{{ dns_domain }}.\"\n    record: \"*.apps.{{ env_id }}.{{ dns_domain }}.\"\n    type: A\n    value: \"{{ infra_eip.public_ip }}\"\n    command: create\n    overwrite: yes\n    ttl: 300\n  when: not ha_mode\n"}, {"commit_sha": "6fada6f2a7515ab18178ae350168c3de147c4dd0", "sha": "35ee2c00de43b592a6b6bc4d86a41cb09e9b55a6", "filename": "meta/main.yml", "repository": "inkatze/wildfly", "decoded_content": "---\n\ngalaxy_info:\n  author: Juan Diego Romero Gonz\u00e1lez\n  description: Installs Wildfly's application runtime\n  license: BSD\n  min_ansible_version: 1.9\n  platforms:\n  - name: EL\n    versions:\n    - 7\n  categories:\n  - development\n  - web\ndependencies: []\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "8350c11de9c4e601180b144e548addbfc9920cbe", "filename": "playbooks/dns/vars/views.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\nnamed_config_views:\n- name: \"casl-private\"\n  zone:\n  - \"dns_domain\": \"private.example.com\"\n- name: \"casl-public\"\n  zone:\n  - \"dns_domain\": \"public.example.com\"\n  forwarder:\n  - \"8.8.8.8\"\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "32885b5fd081e8816fda07297b9c5bd3e841edac", "filename": "roles/vpn/handlers/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: restart strongswan\n  service: name=strongswan state=restarted\n\n- name: daemon-reload\n  shell: systemctl daemon-reload\n\n- name: restart apparmor\n  service: name=apparmor state=restarted\n\n- name: save iptables\n  shell: service netfilter-persistent save\n\n- name: restart iptables\n  service: name=netfilter-persistent state=restarted\n"}, {"commit_sha": "e91a55152358e890a05cf849abc7d58b8badecc2", "sha": "fc746eb7bf806586f7acb1dbe4c75dda928669a1", "filename": "tasks/main.yml", "repository": "fubarhouse/ansible-role-golang", "decoded_content": "---\n# main tasks file for fubarhouse-golang\n\n- name: \"Include tasks gathering system information\"\n  include: setup.yml\n\n- name: \"Include tasks to clean installation\"\n  include: cleanup.yml\n  when: go_install_clean|bool == true\n\n- name: \"Include tasks for installation\"\n  include: install.yml\n  when: (current_go_version is not defined) or\n        (expected_go_version_output|string not in current_go_version.stdout|default(''))\n\n- name: \"Include tasks for Go Get\"\n  include: go-get.yml\n  when: go_get.0 is defined\n\n- name: \"Include tasks for Go Install\"\n  include: go-install.yml\n  when: go_install.0 is defined\n\n- name: \"Include tasks for setting Go permissions\"\n  include: perm.yml"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "f10b1cfeb4bdf851b59ef8b7e18ca2618b604b1f", "filename": "roles/docker/templates/docker.service", "repository": "iiab/iiab", "decoded_content": "[unit]\nDescription=Docker Application Container Engine\nDocumentation=https://docs.docker.com\nAfter=network.target docker.socket\nRequires=docker.socket\n\n[Service]\nType=notify\n# the default is not to use systemd for cgroups because the delegate issues still\n# exists and systemd currently does not support the cgroup feature set required\n# for containers run by docker\nExecStart=/usr/bin/docker daemon \nMountFlags=slave\nLimitNOFILE=1048576\nLimitNPROC=1048576\nLimitCORE=infinity\n# Uncomment TasksMax if your systemd version supports it.\n# Only systemd 226 and above support this version.\n#TasksMax=infinity\nTimeoutStartSec=0\n# set delegate yes so that systemd does not reset the cgroups of docker containers\nDelegate=yes\n\n[Install]\nWantedBy=multi-user.target\n\n"}, {"commit_sha": "f958689395b3fc98cacf0c605ed7b8b4b19718da", "sha": "71426cf35b0d78f9ee70770912bd0c9e0aeaa81b", "filename": "handlers/main.yml", "repository": "lae/ansible-role-netbox", "decoded_content": "---\n# handlers file for lae.netbox\n- name: restart netbox.socket\n  systemd:\n    name: netbox.socket\n    state: restarted\n    daemon_reload: yes\n\n- name: restart netbox.service\n  systemd:\n    name: netbox.service\n    state: restarted\n    daemon_reload: yes\n\n- name: reload netbox.service\n  systemd:\n    name: netbox.service\n    state: reloaded\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "11e34c91f4c26dfce8cebbb7f54c990c5a44bc8d", "filename": "roles/authserver/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: check pip is installed\n  package: name=python-pip\n           state=present\n\n- name: Install xs-authserver from pypi\n  pip: name=xs-authserver\n  when: internet_available\n\n- name: install gunicorn\n  package: name=python-gunicorn\n           state=present\n\n- name: Configure xs-authserver\n  template: backup=yes\n            src={{ item.src }}\n            dest={{ item.dest }}\n            owner=root\n            group=root\n            mode={{ item.mode }}\n  with_items:\n    - src: xs-authserver.env.j2\n      dest: /etc/sysconfig/xs-authserver\n      mode: 0644\n    - src: xs-authserver.service.j2\n      dest: /etc/systemd/system/xs-authserver.service\n      mode: 0644\n\n- name: create database folder\n  file: state=directory\n        path=/var/lib/xs-authserver/\n        owner=root\n        group=root\n        mode=0644\n\n- name: init database\n  command: xs-authserverctl initdb\n  ignore_errors: yes\n  environment:\n    XS_AUTHSERVER_DATABASE: /var/lib/xs-authserver/data.db\n\n- name: Enable xs-authserver service\n  service: name=xs-authserver\n           enabled=yes\n  when: authserver_enabled\n\n- name: add xs-authserver to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=xs-authserver\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: XS-authserver\n    - option: description\n      value: '\"xs-authserver implements a seamless web authentication service\n             using XO laptop registration capabilities.  It is heavily inspired\n             by the Moodle OLPC-XS authentication plugin\"'\n    - option: port\n      value: 5000\n    - option: path\n      value: /\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "dfac6ae9cd375d2ad8bbc0233daeddc3f0b12e03", "filename": "playbooks/debug.yml", "repository": "rocknsm/rock", "decoded_content": "---\n- debug: msg=\"Dumping variables for debug\"\n- debug: var=rock_debug\n- debug: var=rock_online_install\n- debug: var=rock_data_dir\n- debug: var=bro_data_dir\n- debug: var=suricata_data_dir\n- debug: var=stenographer_data_dir\n- debug: var=rock_data_user\n- debug: var=es_mem\n- debug: var=bro_cpu\n- debug: var=rock_monifs\n- debug: var=rock_hostname\n- debug: var=rock_fqdn\n- debug: var=epel_baseurl\n- debug: var=epel_gpgurl\n- debug: var=elastic_baseurl\n- debug: var=elastic_gpgurl\n- debug: var=rocknsm_baseurl\n- debug: var=rocknsm_gpgurl\n- debug: var=rocknsm_local_baseurl\n- debug: var=http_proxy\n- debug: var=https_proxy\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "f1c0e2f81645325f18de87e4c4a67f91757fefe9", "filename": "roles/config-timezone/test/inventory/group_vars/all.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ntimezone: America/Denver\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "cf39a3328536b09e01098e523d3c063d3bb9332c", "filename": "roles/user-management/manage-users/tasks/create_user.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "--- \n  - name: Create IPA user\n    ipa_user:\n      ipa_host: \"{{ ipa_host | default(ansible_host)}}\"\n      ipa_user: \"{{ ipa_admin_user }}\"\n      ipa_pass: \"{{ ipa_admin_password }}\"\n      validate_certs: \"{{ ipa_validate_certs | default(False) }}\"\n      givenname: \"{{ item.first_name | trim }}\"\n      sn: \"{{ item.last_name | trim }}\"\n      name: \"{{ item.user_name | trim }}\"\n      mail: \"{{ item.email | default('') }}\"\n# The addition of expiration date is a request that will be submitted upstream\n#      expiration_date: \"{{ item.expiration_date | default('') }}\"\n    with_items: \"{{ users }}\"\n    register: idm_user_list\n\n  - name: \"Clear users before re-building list with additional data\"\n    set_fact: \n       users: []\n\n  - name: \"Create password generation dataset\"\n    set_fact: \n       users: \"{{ users + [idm_data.item | combine(idm_data | set_user_flags) ] }}\"\n    with_items: \"{{ idm_user_list.results }}\"\n    loop_control:\n      loop_var: idm_data\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "50d94e382c50218124656faa597da29ad5440c3f", "filename": "roles/config-httpd/tasks/prep.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Install required packages'\n  package:\n    name: '{{ item }}'\n    state: installed\n  with_items:\n  - httpd\n  - firewalld\n  - python-firewall\n\n- name: 'Ensure firewalld is running'\n  service:\n    name: firewalld\n    state: started\n    enabled: yes\n\n- name: 'Ensure httpd is running'\n  service:\n    name: httpd\n    state: started\n    enabled: yes\n\n- name: 'Open Firewall for httpd use'\n  firewalld:\n    port: \"{{ item }}\"\n    permanent: yes\n    state: enabled\n    immediate: yes\n  with_items:\n  - 80/tcp\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "0491c6dbef6fc6f51c29d748fbb8727a339f2704", "filename": "archive/roles/registry/tasks/auth_layer_nginx.yaml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- name: Install Nginx Repository\n  action: \"{{ ansible_pkg_mgr }} name={{ nginx_repo_url }} state=present\"\n\n- name: Install Nginx\n  action: \"{{ ansible_pkg_mgr }} name=nginx state=latest\"\n\n- name: Enable & Start Nginx\n  service: name=nginx enabled=yes state=started\n\n- name: Create SSL Certs\n  include: \"{{role_path}}/tasks/openssl.yaml\"\n  notify: reload nginx\n\n- name: Create SSL Config\n  template: src=\"{{role_path}}/templates/nginx.j2\" dest=\"/etc/nginx/nginx.conf\"\n  notify: reload nginx\n\n- easy_install: name=pip\n\n- pip: name=passlib\n\n- name: Setup Authentication\n  htpasswd: path=/etc/nginx/conf.d/nginx.htpasswd name=demo password=demo owner=root group=nginx mode=0640\n\n- name: Open Firewall for Nginx\n  firewalld: service=https permanent=yes state=enabled immediate=yes zone=public\n\n- name: Nginx SELinux Configurations\n  seboolean:\n    name: httpd_can_network_connect\n    state: yes\n    persistent: yes\n  tags: httpd\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "24a8b1a83da76400347ca2c17540fe1e7bece0ca", "filename": "roles/config-linux-desktop/config-xfce/tasks/xfce-Fedora.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: \"Install additional packages for XFCE\"\n  dnf:\n    name: \"{{ item }}\"\n    state: present\n  with_items:\n  - '@Xfce Desktop'\n\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "43857b2020dd4616192bc77a5e34db068f145c02", "filename": "archive/playbooks/registry/byo.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- hosts: registry\n  roles:\n    - role: registry\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "5f9ffe66e17c9791f02825e4be8c5dec92990e55", "filename": "tasks/Win32NT/fetch/sapjvm-fallback.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: 'Fetch root page {{ sapjvm_root_page }}'\n  win_uri:\n    url: '{{ sapjvm_root_page }}'\n    return_content: true\n  register: root_page\n\n- name: Find release url\n  set_fact:\n    release_url: >-\n      {{ root_page['content']\n        | regex_findall('(additional/sapjvm-'\n          + java_major_version|string\n          + '[\\d.]+-windows-x64.zip)')\n      }}\n\n- name: Download sapjvm artifact\n  win_get_url:\n    url: '{{ sapjvm_root_page }}/{{ release_url[0] }}'\n    headers:\n      Cookie: eula_3_1_agreed=tools.hana.ondemand.com/developer-license-3_1.txt\n    dest: '{{ java_download_path }}'\n    force: false\n  register: file_downloaded\n  retries: 20\n  delay: 5\n  until: file_downloaded is succeeded\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "3a04122d631d5b73c021c85e93bec75472f9791e", "filename": "roles/activity-server/templates/xs-activity-server.conf", "repository": "iiab/iiab", "decoded_content": "# xs-activity-server\n#\n# Copyright: On Laptop per Child\n# GPL v2\n# written by Douglas Bagnall <douglas@paradise.net.nz>\n#\n# This belongs in the apache conf.d directory.\n# (probably /etc/httpd/conf.d/)\n\nAlias /activities /library/xs-activity-server/www\n<Directory /library/xs-activity-server/www >\n      # Languages are set in 010-iiab.conf\n      \n      ExpiresActive On\n      ExpiresDefault now\n      Options +MultiViews\n      Require all granted\n      #NOTE: an index.html.var file is generated, which ought to make\n      # MultiViews redundant (by my reading) but it doesn't seem to\n      # work. Someone could look at that sometime.\n</Directory>\n\n#<Directory /activities >\n#      ExpiresActive On\n#      ExpiresDefault now\n#</Directory>\n#<Location /activities >\n#      ExpiresActive On\n#      ExpiresDefault now\n#</Location>"}, {"commit_sha": "3c4d272a77f8aaeb300c8b841bb7e6d8dbd76c1f", "sha": "4831bf077bd9565b911c6313a7ad1b3b8a66c8eb", "filename": "tasks/debug.yml", "repository": "ansiblebit/oracle-java", "decoded_content": "---\n# file: oracle-java/tasks/debug.yml\n#\n# Task that prints variable debug information.\n#\n\n- name: echo oracle_java_cache_valid_time\n  debug:\n    var=oracle_java_cache_valid_time\n  when: oracle_java_cache_valid_time is defined\n\n- name: echo oracle_java_home\n  debug:\n    var=oracle_java_home\n  when: oracle_java_home is defined\n\n- name: echo oracle_java_installed\n  debug:\n    var=oracle_java_installed\n  when: oracle_java_installed is defined\n\n- name: echo oracle_java_os_supported\n  debug:\n    var=oracle_java_os_supported\n  when: oracle_java_os_supported is defined\n\n- name: echo oracle_java_rpm_filename\n  debug:\n    var=oracle_java_rpm_filename\n  when: oracle_java_rpm_filename is defined\n\n- name: echo oracle_java_set_as_default\n  debug:\n    var=oracle_java_set_as_default\n  when: oracle_java_set_as_default is defined\n\n- name: echo oracle_java_rpm_url\n  debug:\n    var=oracle_java_rpm_url\n  when: oracle_java_rpm_url is defined\n\n- name: echo oracle_java_state\n  debug:\n    var=oracle_java_state\n  when: oracle_java_state is defined\n\n- name: echo oracle_java_version_build\n  debug:\n    var=oracle_java_version_build\n  when: oracle_java_version_build is defined\n\n- name: echo oracle_java_version_installed\n  debug:\n    var=oracle_java_version_installed\n  when: oracle_java_version_installed is defined\n\n- name: echo oracle_java_version_string\n  debug:\n    var=oracle_java_version_string\n  when: oracle_java_version_string is defined\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "372978aac16bb812c08615db6271d6f698f600f4", "filename": "playbooks/roles/print/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- debug:\n    msg: |\n      {{name}}\n      {{value}}\n      {{file}}\n- name: Print var to file\n  local_action: |\n    shell echo '{{name}}: \"{{value}}\"' >> {{file}}\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "276c573d7cc91eba783fe308ebde9d760ef10a8b", "filename": "roles/mysql/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "phpMyAdmin: \"phpMyAdmin-4.2.7.1-all-languages.zip\"\nmysql_install: True\nmysql_enabled: False\nphpmyadmin_enabled: False\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "c655cc6e9cf26691c9a108e4fcc7fa2042771aa1", "filename": "roles/user-management/manage-local-user-password/test/inventory/group_vars/all.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nuser_name: user1\nclear_text_password: test1234\n\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "7033dfa1afb2c95e35219b183d55cd9e432d0137", "filename": "playbooks/dns/config_dns_server.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n# Configure DNS Server(s)\n- hosts: dns\n  pre_tasks:\n  - name: \"Include the views\"\n    include_vars: vars/views.yml\n    delegate_to: localhost\n  roles:\n    - role: infra-ansible/roles/dns-server\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "82c8e49f3d6adab5b69a064af8a0c31c622c8c75", "filename": "tasks/prerequisites/install-prerequisites.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- import_tasks: setup-debian.yml\n  when: ansible_os_family == \"Debian\"\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "c2df15bb257f4b7d34480de2e0c71ede8575affc", "filename": "playbooks/roles/check_ntp/templates/ntp.j2", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "# For more information about this file, see the man pages\n# ntp.conf(5), ntp_acc(5), ntp_auth(5), ntp_clock(5), ntp_misc(5), ntp_mon(5).\n\ndriftfile /var/lib/ntp/drift\n\n# Permit time synchronization with our time source, but do not\n# permit the source to query or modify the service on this system.\nrestrict default nomodify notrap nopeer noquery\n\n# Permit all access over the loopback interface.  This could\n# be tightened as well, but to do so would effect some of\n# the administrative functions.\nrestrict 127.0.0.1 \nrestrict ::1\n\n# Hosts on local network are less restricted.\n#restrict 192.168.1.0 mask 255.255.255.0 nomodify notrap\n\n# Use public servers from the pool.ntp.org project.\n# Please consider joining the pool (http://www.pool.ntp.org/join.html).\n{% for ntp in ntp_servers %}\nserver {{ntp}} iburst\n{% endfor %}\n\n\n#broadcast 192.168.1.255 autokey        # broadcast server\n#broadcastclient                        # broadcast client\n#broadcast 224.0.1.1 autokey            # multicast server\n#multicastclient 224.0.1.1              # multicast client\n#manycastserver 239.255.254.254         # manycast server\n#manycastclient 239.255.254.254 autokey # manycast client\n\n# Enable public key cryptography.\n#crypto\n\nincludefile /etc/ntp/crypto/pw\n\n# Key file containing the keys and key identifiers used when operating\n# with symmetric key cryptography. \nkeys /etc/ntp/keys\n\n# Specify the key identifiers which are trusted.\n#trustedkey 4 8 42\n\n# Specify the key identifier to use with the ntpdc utility.\n#requestkey 8\n\n# Specify the key identifier to use with the ntpq utility.\n#controlkey 8\n\n# Enable writing of statistics records.\n#statistics clockstats cryptostats loopstats peerstats\n\n# Disable the monitoring facility to prevent amplification attacks using ntpdc\n# monlist command when default restrict does not include the noquery flag. See\n# CVE-2013-5211 for more details.\n# Note: Monitoring will not be disabled with the limited restriction flag.\ndisable monitor\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "b452958833a4e4bb9e20d0ffc2201f8944735160", "filename": "roles/network/templates/gateway/iiab-gen-iptables", "repository": "iiab/iiab", "decoded_content": "#!/bin/bash -x\n{% if is_debuntu %}\nIPTABLES=/sbin/iptables\nIPTABLES_DATA=/etc/iptables.up.rules\n{% else %}\nIPTABLES=/usr/sbin/iptables\nIPTABLES_DATA=/etc/sysconfig/iptables\n{% endif %}\nLANIF=`cat /etc/sysconfig/iiab_lan_device`\nWANIF=`cat /etc/sysconfig/iiab_wan_device`\nMODE=`grep iiab_network_mode_applied  /etc/iiab/iiab.ini | gawk '{print $3}'`\n\nclear_fw() {\n$IPTABLES -F\n$IPTABLES -t nat -F\n$IPTABLES -X\n\n# first match wins\n# Always accept loopback traffic\n$IPTABLES -A INPUT -i lo -j ACCEPT\n\n# Always drop rpc\n$IPTABLES -A INPUT -p tcp --dport 111 -j DROP\n$IPTABLES -A INPUT -p udp --dport 111 -j DROP\n# mysql\n$IPTABLES -A INPUT -p tcp --dport 3306 -j DROP\n$IPTABLES -A INPUT -p udp --dport 3306 -j DROP\n# postgre - not needed listens on lo only\n$IPTABLES -A INPUT -p tcp --dport 5432 -j DROP\n$IPTABLES -A INPUT -p udp --dport 5432 -j DROP\n# couchdb\n$IPTABLES -A INPUT -p tcp --dport 5984 -j DROP\n$IPTABLES -A INPUT -p udp --dport 5984 -j DROP\n}\n\nif [  \"x$WANIF\" == \"x\" ] || [ \"$MODE\" == 'Appliance' ]; then\n    clear_fw\n    # save the rule set\n\t{% if is_debuntu %}\n\tnetfilter-persistent save\n\t{% else %}\n\tiptables-save > $IPTABLES_DATA\n\t{% endif %}\n    exit 0\nfi\nlan=$LANIF\nwan=$WANIF\n\n# Good thing we replace this file should be treated like squid below\ngw_block_https={{ gw_block_https }}\nssh_port={{ ssh_port }}\ngui_wan={{ gui_wan }}\ngui_port={{ gui_port }}\niiab_gateway_enabled={{ iiab_gateway_enabled }}\nservices_externally_visible={{ services_externally_visible }}\ncalibre_port={{ calibre_port }}\nkiwix_port={{ kiwix_port }}\nkalite_server_port={{ kalite_server_port }}\nblock_DNS={{ block_DNS }}\n\necho \"Lan is $lan and WAN is $wan\"\n#\n# delete all existing rules.\n#\n\n/sbin/modprobe ip_tables\n/sbin/modprobe iptable_filter\n/sbin/modprobe ip_conntrack\n/sbin/modprobe iptable_nat\nclear_fw\n\n# Allow established connections, and those not coming from the outside\n$IPTABLES -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT\n$IPTABLES -A INPUT -m state --state NEW -i  $lan -j ACCEPT\n\n# Allow mDNS\n$IPTABLES -A INPUT -p udp --dport 5353 -j ACCEPT\n\n#when run as gateway\n$IPTABLES -A INPUT -p tcp --dport $ssh_port -m state --state NEW -i $wan -j ACCEPT\n\nif [ \"$gui_wan\" == \"True\" ]; then\n    $IPTABLES -A INPUT -p tcp --dport $gui_port -m state --state NEW -i $wan -j ACCEPT\nfi\n\nif [ \"$services_externally_visible\" == \"True\" ]; then\n    $IPTABLES -A INPUT -p tcp --dport $kiwix_port -m state --state NEW -i $wan -j ACCEPT\n    $IPTABLES -A INPUT -p tcp --dport $kalite_server_port -m state --state NEW -i $wan -j ACCEPT\n    $IPTABLES -A INPUT -p tcp --dport $calibre_port -m state --state NEW -i $wan -j ACCEPT\nfi\n\nif [ \"$iiab_gateway_enabled\" == \"True\" ]; then\n    $IPTABLES -A POSTROUTING -t nat -o $wan -j MASQUERADE\nfi\n\n$IPTABLES -A FORWARD -i $wan -o $lan -m state --state ESTABLISHED,RELATED -j ACCEPT\n\n#Block https traffic except if directed at server\nif [  \"$gw_block_https\" == \"True\" ]; then\n    $IPTABLES -A FORWARD -p tcp ! -d 172.18.96.1 --dport 443 -j DROP\nfi\n\n# Allow outgoing connections from the LAN side.\n$IPTABLES -A FORWARD -i $lan -o $wan -j ACCEPT\n\n# Don't forward from the outside to the inside.\n$IPTABLES -A FORWARD -i $wan -o $lan -j DROP\n$IPTABLES -A INPUT -i $wan -j DROP\n\nif [ \"$block_DNS\" == \"True\" ];then\n    $IPTABLES -t nat -A PREROUTING -i $lan -p tcp --dport 53 ! -d {{ lan_ip }} -j DNAT --to {{ lan_ip }}:53\n    $IPTABLES -t nat -A PREROUTING -i $lan -p udp --dport 53 ! -d {{ lan_ip }} -j DNAT --to {{ lan_ip }}:53\nfi\n\nif [ -f /etc/sysconfig/xs_httpcache_on ]; then\n    $IPTABLES  -t nat  -A PREROUTING -i $lan -p tcp --dport 80 ! -d 172.18.96.1 -j DNAT --to 172.18.96.1:3128\nfi\n\n# Enable routing.\necho 1 > /proc/sys/net/ipv4/ip_forward\n# save the whole rule set now\n{% if is_debuntu %}\nnetfilter-persistent save\n{% else %}\niptables-save > $IPTABLES_DATA\n{% endif %}\nexit 0\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "af8fca924a8a84dceb7aff858e4bcdf6ea952f36", "filename": "roles/manage-jira/tests/playbook.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Test Jira Role\n  hosts: jira\n  vars_files:\n  - vars/vars_atlassian\n  roles:\n  - manage-jira\n"}, {"commit_sha": "3c4d272a77f8aaeb300c8b841bb7e6d8dbd76c1f", "sha": "c162e9aaee23f1b06a5f1989ef29eca9e4f368f5", "filename": "tests/tasks/main.yml", "repository": "ansiblebit/oracle-java", "decoded_content": "---\n# file: primogen/tests/tasks\n#\n# Test tasks to verify role execution.\n#\n\n- name: is oracle_java_installed fact set?\n  fail:\n    msg=\"oracle_java_installed fact is not defined!\"\n  when: not oracle_java_installed is defined\n\n- name: is oracle_java_installed fact true?\n  fail:\n    msg=\"oracle_java_installed fact is false!\"\n  when: not oracle_java_installed\n\n- name: is oracle_java_version_installed fact set?\n  fail:\n    msg=\"oracle_java_installed fact is not defined!\"\n  when: not oracle_java_version_installed is defined\n\n- name: is oracle_java_version_installed value correct?\n  fail:\n    msg=\"oracle_java_version_installed value is {{ oracle_java_version_installed }} instead of {{ expected_java_version }}!\"\n  when: oracle_java_version_installed != expected_java_version\n\n- name: register result_java_version with host installed Java version\n  shell: java -version 2>&1 | head -n 1 | awk '{ print $3 }' | awk -F '\"' '{ print $2 }'\n  register: result_java_version\n  changed_when: no\n\n- name: is installed Java version on host correct?\n  fail:\n    msg=\"java -version output was {{ result_java_version.stdout }} instead of {{ expected_java_version }}\"\n  when: result_java_version.stdout != expected_java_version\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "537ee550e1c94a256b1f559ba72c858fd69db3e8", "filename": "playbooks/roles/check_glusterfs/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- name: Check if NTP enabled\n  shell: |\n    timedatectl | grep \"NTP enabled: yes\" \n  ignore_errors: true\n  register: ntp_enabled\n- name: Check if NTP synchronized\n  shell: |\n    timedatectl | grep \"NTP synchronized: yes\"\n  ignore_errors: true\n  register: ntp_synchronized\n- name: Signal if NTP is not enable or synchronized\n  debug:\n    msg: |\n      {{ ntp_enable.stdout }}\n  when: ntp_enabled.rc != 0 or ntp_synchronized.rc != 0\n\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "91fe5c902f4b1022e0a136d8b4ce352a76448d0f", "filename": "roles/dockerbench/vars/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# vars file for dockerbench\n"}, {"commit_sha": "abafe1581c6c78d784cf215b214947675d49eff8", "sha": "e1d8b9d36fa9d3812a1245c50002bcae59657d2b", "filename": "roles/proxy/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: Gather Facts\n  setup:\n\n- name: Privoxy installed\n  apt: name=privoxy state=latest\n\n- name: Privoxy configured\n  template: src=\"{{ item.src }}\" dest=\"{{ item.dest }}\"\n  with_items:\n    - { src: privoxy_config.j2, dest: /etc/privoxy/config }\n    - { src: default.filter.j2, dest: /etc/privoxy/default.filter }\n  notify:\n    - restart privoxy\n\n- name: Privoxy profile for apparmor configured\n  template: src=usr.sbin.privoxy.j2 dest=/etc/apparmor.d/usr.sbin.privoxy owner=root group=root mode=0600\n  notify:\n    - restart privoxy\n\n- name: Enforce the privoxy AppArmor policy\n  shell: aa-enforce usr.sbin.privoxy\n\n- name: Ensure that the privoxy service directory exist\n  file: path=/etc/systemd/system/privoxy.service.d/ state=directory mode=0755  owner=root group=root\n\n- name: Setup the cgroup limitations for the privoxy daemon\n  template: src=privoxy_100-CustomLimitations.conf.j2 dest=/etc/systemd/system/privoxy.service.d/100-CustomLimitations.conf\n  notify:\n    - daemon-reload\n    - restart privoxy\n\n- meta: flush_handlers\n\n- name: Privoxy enabled and started\n  service: name=privoxy state=started enabled=yes\n\n# PageSpeed\n\n- name: Apache installed\n  apt: name=apache2 state=latest\n\n- name: PageSpeed installed for x86_64\n  apt: deb=https://dl-ssl.google.com/dl/linux/direct/mod-pagespeed-stable_current_amd64.deb\n  when: ansible_architecture == \"x86_64\"\n\n- name: PageSpeed installed for i386\n  apt: deb=https://dl-ssl.google.com/dl/linux/direct/mod-pagespeed-stable_current_i386.deb\n  when: ansible_architecture != \"x86_64\"\n\n- name: PageSpeed configured\n  template: src=pagespeed.conf.j2 dest=/etc/apache2/mods-available/pagespeed.conf\n  notify:\n    - restart apache2\n\n- name: Modules enabled\n  apache2_module: state=present name=\"{{ item }}\"\n  with_items:\n    - proxy_http\n    - pagespeed\n    - cache\n    - proxy_connect\n    - proxy_html\n    - rewrite\n  notify:\n    - restart apache2\n\n- name: VirtualHost configured for the PageSpeed module\n  template: src=000-default.conf.j2 dest=/etc/apache2/sites-enabled/000-default.conf\n  notify:\n    - restart apache2\n\n- name: Apache ports configured\n  template: src=ports.conf.j2 dest=/etc/apache2/ports.conf\n  notify:\n    - restart apache2\n\n- name: Ensure that the apache2 service directory exist\n  file: path=/etc/systemd/system/apache2.service.d/ state=directory mode=0755  owner=root group=root\n\n- name: Setup the cgroup limitations for the apache2 daemon\n  template: src=apache2_100-CustomLimitations.conf.j2 dest=/etc/systemd/system/apache2.service.d/100-CustomLimitations.conf\n  notify:\n    - daemon-reload\n    - restart apache2\n\n- meta: flush_handlers\n\n- name: Set facts for mobileconfigs\n  set_fact:\n    proxy_enabled: true\n\n- name: Register p12 PayloadContent\n  shell: >\n    cat /{{ easyrsa_dir }}/easyrsa3//pki/private/{{ item }}.p12 | base64\n  register:  PayloadContent\n  with_items: \"{{ users }}\"\n\n- name: Register CA PayloadContent\n  shell: >\n    cat /{{ easyrsa_dir }}/easyrsa3/pki/ca.crt | base64\n  register:  PayloadContentCA\n\n- name: Build the mobileconfigs\n  template: src=roles/vpn/templates/mobileconfig.j2 dest=/{{ easyrsa_dir }}/easyrsa3//pki/private/{{ item.0 }}_proxy.mobileconfig mode=0600\n  with_together:\n    - \"{{ users }}\"\n    - \"{{ PayloadContent.results }}\"\n  no_log: True\n\n- name: Fetch users mobileconfig\n  fetch: src=/{{ easyrsa_dir }}/easyrsa3//pki/private/{{ item }}_proxy.mobileconfig dest=configs/{{ IP_subject_alt_name }}_{{ item }}_proxy.mobileconfig flat=yes\n  with_items: \"{{ users }}\"\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "e985f9270f6f9bca323e4a4310ac589c5ad05dc3", "filename": "roles/ssh_tunneling/meta/main.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\ndependencies:\n  - { role: common, tags: common }\n"}, {"commit_sha": "51dcdf691a7801895b569a5a927e30030d8feb70", "sha": "acc3b24db12b6ebe49435770498aa974e089fbd7", "filename": "tasks/openbsd_install.yml", "repository": "nusenu/ansible-relayor", "decoded_content": "---\n\n- name: Setup OpenBSD specific variables (set_fact)\n  set_fact:\n    tor_DataDir: /var/tor\n    tor_ConfDir: /etc/tor/enabled\n  tags:\n   - reconfigure\n   - renewkey\n   - createdir\n\n- name: Ensure Tor is installed (OpenBSD)\n  become: yes\n  openbsd_pkg: name=tor state=present\n\n- name: Gather current system-wide file descriptor limits (OpenBSD)\n  shell: \"sysctl kern.maxfiles|cut -d= -f2\"\n  register: currentlimits\n\n- name: Ensure system-wide runtime file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  command: \"sysctl kern.maxfiles=20000\"\n  when: currentlimits.stdout|int < 20000\n\n- name: Ensure system-wide persistent file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  lineinfile: dest=/etc/sysctl.conf regexp=^kern.maxfiles line=\"kern.maxfiles=20000\" create=yes\n  when: currentlimits.stdout|int < 20000\n\n# We rise openfiles limits for every tor instance separately.\n# An instance is identified by its rc.d file name.\n- name: Ensure Tor process file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  lineinfile: \"dest=/etc/login.conf line='tor{{ item[0]| replace('.','_') }}_{{ item.1.orport }}::openfiles-max=13500::tc=daemon:'\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n  #TODO\n  #notify: restart tor\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "f1124c7140ee873b4268c3376913e2a037a8ac94", "filename": "roles/httpd/templates/refresh-wiki-docs.sh", "repository": "iiab/iiab", "decoded_content": "#!/bin/bash -x\n\n# Pull down repo's entire wiki (and similar) to create offline docs\n\nset -e\nsource /etc/iiab/iiab.env\nINPUT=/tmp/iiab-wiki\nOUTPUT=/tmp/iiab-wiki.out\nDESTPATH=/library/www/html/info\n\nrm -rf $INPUT\nrm -rf $OUTPUT\nmkdir -p $INPUT\nmkdir -p $OUTPUT\n\ngit clone https://github.com/iiab/iiab.wiki.git $INPUT\n\nfor f in `ls $INPUT`; do\n    FTRIMMED=${f%.md}\n    if [ $FTRIMMED = \"Home\" ]; then FTRIMMED=index; fi\n    pandoc -s $INPUT/$f -o $OUTPUT/$FTRIMMED.html\ndone\n\nrsync -av $OUTPUT/ $DESTPATH\n\n# To Do: find more pages to d/l and offline links to fix, based on \"fieldback\" from truly remote implementer/operators\n\n# Download FAQ etc\nlynx -reload -source http://wiki.laptop.org/go/IIAB/FAQ > $DESTPATH/FAQ.html\nlynx -reload -source http://wiki.laptop.org/go/IIAB/Security > $DESTPATH/Security.html\nlynx -reload -source http://wiki.laptop.org/go/IIAB/local_vars.yml > $DESTPATH/local_vars.yml\nlynx -reload -source http://wiki.laptop.org/go/IIAB/local_vars_min.yml > $DESTPATH/local_vars_min.yml\nlynx -reload -source http://wiki.laptop.org/go/IIAB/local_vars_big.yml > $DESTPATH/local_vars_big.yml\n\n# Download older release notes\nlynx -reload -source https://github.com/XSCE/xsce/wiki/IIAB-6.2-Release-Notes > $DESTPATH/IIAB-6.2-Release-Notes.html\nlynx -reload -source https://github.com/XSCE/xsce/blob/release-6.2/ReleaseNotes6.0.md > $DESTPATH/ReleaseNotes6.0.html\nlynx -reload -source https://github.com/XSCE/xsce/blob/release-6.2/ReleaseNotes6.1.md > $DESTPATH/ReleaseNotes6.1.html\n\n# Make links refer to local items\nfor f in $DESTPATH/*.html; do\n    sed -i -r \"s|https://github.com/iiab/iiab/wiki/([-.A-Za-z0-9]*)|\\1.html|g\" $f\n\n    sed -i -e \"s|https://github.com/xsce/xsce/blob/release-6.2/\\(.*\\)\\.md\\\">|\\1.html\\\">|g\" $f\n    sed -i -e \"s|https://github.com/xsce/xsce/wiki/\\(.*\\)\\\">|\\1.html\\\">|g\" $f\n\n    sed -i -e \"s|http://wiki.laptop.org/go/IIAB/FAQ|FAQ.html|g\" $f\n    sed -i -e \"s|/go/IIAB/FAQ|FAQ.html|g\" $f\n    sed -i -e \"s|http://wiki.iiab.io/FAQ|FAQ.html|g\" $f\n    sed -i -e \"s|http://FAQ.IIAB.IO|FAQ.html|g\" $f\n    sed -i -e \"s|http://faq.iiab.io|FAQ.html|g\" $f\n    sed -i -e \"s|http://schoolserver.org/FAQ|FAQ.html|g\" $f\n    sed -i -e \"s|http://schoolserver.org/faq|FAQ.html|g\" $f\n    sed -i -e \"s|http://wiki.laptop.org/go/XS_Community_Edition/FAQ|FAQ.html|g\" $f\n\n    sed -i -e \"s|http://wiki.laptop.org/go/IIAB/Security|Security.html|g\" $f\n    sed -i -e \"s|/go/IIAB/Security|Security.html|g\" $f\n    sed -i -e \"s|http://wiki.iiab.io/Security|Security.html|g\" $f\n\n    sed -i -e \"s|http://wiki.laptop.org/go/IIAB/local_vars.yml|local_vars.yml|g\" $f\n    sed -i -e \"s|/go/IIAB/local_vars.yml|local_vars.yml|g\" $f\n    sed -i -e \"s|http://wiki.iiab.io/local_vars.yml|local_vars.yml|g\" $f\n\n    sed -i -e \"s|http://wiki.laptop.org/go/IIAB/local_vars_min.yml|local_vars_min.yml|g\" $f\n    sed -i -e \"s|/go/IIAB/local_vars_min.yml|local_vars_min.yml|g\" $f\n    sed -i -e \"s|http://wiki.iiab.io/local_vars_min.yml|local_vars_min.yml|g\" $f\n\n    sed -i -e \"s|http://wiki.laptop.org/go/IIAB/local_vars_big.yml|local_vars_big.yml|g\" $f\n    sed -i -e \"s|/go/IIAB/local_vars_big.yml|local_vars_big.yml|g\" $f\n    sed -i -e \"s|http://wiki.iiab.io/local_vars_big.yml|local_vars_big.yml|g\" $f\ndone\n\nexit 0\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "67d247d8654a5c42f79a5fc4db576c8278317fff", "filename": "roles/common/tasks/freebsd.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- set_fact:\n    tools:\n      - git\n      - subversion\n      - screen\n      - coreutils\n      - openssl\n      - bash\n      - wget\n    sysctl:\n      - item: net.inet.ip.forwarding\n        value: 1\n      - item: net.inet6.ip6.forwarding\n        value: 1\n  tags:\n    - always\n\n- name: Loopback included into the rc config\n  blockinfile:\n    dest: /etc/rc.conf\n    create: yes\n    block: |\n      cloned_interfaces=\"lo100\"\n      ifconfig_lo100=\"inet {{ local_service_ip }} netmask 255.255.255.255\"\n      ifconfig_lo100=\"inet6 FCAA::1/64\"\n  notify:\n    - restart loopback bsd\n  tags:\n    - always\n\n- name: Enable the gateway features\n  lineinfile: dest=/etc/rc.conf regexp='^{{ item.param }}.*' line='{{ item.param }}={{ item.value }}'\n  with_items:\n    - { param: firewall_enable, value: '\"YES\"' }\n    - { param: firewall_type, value: '\"open\"' }\n    - { param: gateway_enable, value: '\"YES\"' }\n    - { param: natd_enable, value: '\"YES\"' }\n    - { param: natd_interface, value: '\"{{ ansible_default_ipv4.device|default() }}\"' }\n    - { param: natd_flags, value: '\"-dynamic -m\"' }\n  notify:\n    - restart ipfw\n  tags:\n    - always\n\n- name: FreeBSD | Activate IPFW\n  shell: >\n    kldstat -n ipfw.ko || kldload ipfw ; sysctl net.inet.ip.fw.enable=0 &&\n    bash /etc/rc.firewall && sysctl net.inet.ip.fw.enable=1\n\n- meta: flush_handlers\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "0c0ef30fd2fe76f395ccd5073d7068f06cfd2b78", "filename": "roles/config-software-src/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: prep.yml\n- import_tasks: mount-software.yml\n\n\n"}, {"commit_sha": "a5a5c4d74b7b0fd14f534dda1f41f903d1a58abf", "sha": "4e12f3d564cb60b23c868a5d427ac6eb041312c6", "filename": "meta/main.yml", "repository": "fubarhouse/ansible-role-nodejs", "decoded_content": "---\ndependencies: []\n\ngalaxy_info:\n  author: fubarhouse\n  description: Installs NVM, NodeJS and NPM packages.\n  license: \"license (BSD, MIT)\"\n  min_ansible_version: 2.1.0.0\n  platforms:\n  - name: Ubuntu\n    versions:\n    - precise\n    - trusty\n    - xenial\n  - name: Debian\n    versions:\n    - all\n  - name: EL\n    versions:\n    - 6\n    - 7\n  categories:\n    - system\n    - database\n    - development\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a2535b9e3d11882bcf33485b9264a76d9a1ed89e", "filename": "roles/user-management/manage-local-user-password/tasks/password.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: \"Change {{ user_name }}'s password\"\n  user: \n    name: \"{{ user_name}}\"\n    password: \"{{ clear_text_password|encrypt_password }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "7a6b746905b4b48eff3fdaa5409c2c92664c4e52", "filename": "roles/usb-lib/templates/mount.d/70-usb-library", "repository": "iiab/iiab", "decoded_content": "#!/bin/bash\n# Create symlink in DocumentRoot/content to autmounted usb drive\n#\n# based on a similar script in the xs-rsync package\n# by Martin Langhoff <martin@laptop.org>\n#\n# and the adaptation for xs-activity-server by Douglas Bagnall\n# <douglas@paradise.net.nz>\n#\n# by Tim Moody tim@timmoody.com\n\nlogger -p user.notice -t \"70-usb-library\" -- \"Looking for /share, /Share, /Piratebox/Share, /USB, or /usb on $UM_MOUNTPOINT.\"\n\nVERBOSE=yes\n\nSHARE_DIR=\"\"\n# Only show content if in these directories\n\nif [ -d $UM_MOUNTPOINT/share ]; then\n  SHARE_DIR=\"$UM_MOUNTPOINT/share\"\nfi\nif [ -d $UM_MOUNTPOINT/Share ]; then\n  SHARE_DIR=\"$UM_MOUNTPOINT/Share\"\nfi\nif [ -d $UM_MOUNTPOINT/Piratebox/Share ]; then\n  SHARE_DIR=\"$UM_MOUNTPOINT/Piratebox/Share\"\nfi\nif [ -d $UM_MOUNTPOINT/USB ]; then\n  SHARE_DIR=\"$UM_MOUNTPOINT/USB\"\nfi\nif [ -d $UM_MOUNTPOINT/usb ]; then\n  SHARE_DIR=\"$UM_MOUNTPOINT/usb\"\nfi\n\nif [ ! -z \"$SHARE_DIR\" ]; then\n  logger -p user.notice -t \"70-usb-library\" -- \"Found Share Directory $SHARE_DIR.\"\nelse\n  logger -p user.notice -t \"70-usb-library\" -- \"did not find /share, /Share, /Piratebox/Share, /USB, or /usb on USB\"\nfi\n  \n\nif [ \"$SHARE_DIR\" != \"\" ];then\n  CONTENT_LINK_USB=`basename $UM_MOUNTPOINT | awk '{print toupper($0)}'`\n  CONTENT_LINK=\"{{ doc_root }}/local_content/$CONTENT_LINK_USB\"\n  logger -p user.notice -t \"70-usb-library\" -- \"Creating link to $CONTENT_LINK.\"\n  ln -s $SHARE_DIR $CONTENT_LINK\nfi\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "a152719aaf178c1188749346de15c9dec4be2d3a", "filename": "roles/network/tasks/named.yml", "repository": "iiab/iiab", "decoded_content": "- name: Install named packages\n  package: name={{ item }}\n           state=present\n  with_items:\n   - bind9\n   - bind9utils\n  when: is_debuntu\n  tags:\n    - download\n\n- name: Install named packages\n  package: name={{ item }}\n           state=present\n  with_items:\n   - bind\n   - bind-utils\n  when: not is_debuntu\n  tags:\n    - download\n\n# or we have to change the serial number in the config files.\n- name: Stop named before copying files\n  service: name={{ dns_service }} state=stopped\n  when: not installing\n\n- name: Set folder permission\n  file: path={{ item }}\n        owner={{ dns_user }}\n        group=root\n        mode=0755\n        state=directory\n  with_items:\n    - /var/named-iiab\n    - /var/named-iiab/data\n    - /etc/sysconfig/olpc-scripts/domain_config.d\n\n- name: Configure named\n  template: src={{ item.src }}\n            dest={{ item.dest }}\n            owner={{ item.owner }}\n            group=root\n            mode={{ item.mode }}\n  with_items:\n    - { src: 'named/named-iiab.conf.j2', dest: '/etc/named-iiab.conf', owner: \"root\" , mode: '0644' }\n    - { src: 'named/named.j2', dest: '/etc/sysconfig/named', owner: \"root\" , mode: '0644' }\n    - { src: 'named/named', dest: '/etc/sysconfig/olpc-scripts/domain_config.d/named', owner: \"root\" , mode: '0644' }\n    - { src: 'named/localdomain.zone', dest: '/var/named-iiab/localdomain.zone',owner: \"{{ dns_user }}\" , mode: '0644' }\n    - { src: 'named/localhost.zone', dest: '/var/named-iiab/localhost.zone', owner: \"{{ dns_user }}\" , mode: '0644' }\n    - { src: 'named/named.broadcast', dest: '/var/named-iiab/named.broadcast', owner: \"{{ dns_user }}\" , mode: '0644'}\n    - { src: 'named/named.ip6.local', dest: '/var/named-iiab/named.ip6.local' , owner: \"{{ dns_user }}\" , mode: '0644'}\n    - { src: 'named/named.local', dest: '/var/named-iiab/named.local' , owner: \"{{ dns_user }}\" , mode: '0644'}\n    - { src: 'named/named.rfc1912.zones', dest: '/var/named-iiab/named.rfc1912.zones' , owner: \"{{ dns_user }}\" , mode: '0644'}\n    - { src: 'named/named.root', dest: '/var/named-iiab/named.root' , owner: \"{{ dns_user }}\" , mode: '0644'}\n    - { src: 'named/named.root.hints', dest: '/var/named-iiab/named.root.hints' , owner: \"{{ dns_user }}\" , mode: '0644'}\n    - { src: 'named/named.zero', dest: '/var/named-iiab/named.zero' , owner: \"{{ dns_user }}\" , mode: '0644'}\n    - { src: 'named/school.external.zone.db', dest: '/var/named-iiab/school.external.zone.db' , owner: \"{{ dns_user }}\" , mode: '0644'}\n    - { src: 'named/school.internal.zone.16.in-addr.db.j2', dest: '/var/named-iiab/school.internal.zone.16.in-addr.db' , owner: \"{{ dns_user }}\" , mode: '0644'}\n    - { src: 'named/school.internal.zone.32.in-addr.db.j2', dest: '/var/named-iiab/school.internal.zone.32.in-addr.db' , owner: \"{{ dns_user }}\" , mode: '0644'}\n    - { src: 'named/school.internal.zone.48.in-addr.db.j2', dest: '/var/named-iiab/school.internal.zone.48.in-addr.db' , owner: \"{{ dns_user }}\" , mode: '0644'}\n# the following two files are not writeable by named, but bind 9.4 cannot discover that fact correctly\n    - { src: 'named/school.internal.zone.db', dest: '/var/named-iiab/school.internal.zone.db' , owner: \"root\" , mode: '0644'}\n    - { src: 'named/school.local.zone.db', dest: '/var/named-iiab/school.local.zone.db' , owner: \"root\" , mode: '0644'}\n    - { src: 'named/school.internal.zone.in-addr.db.j2', dest: '/var/named-iiab/school.internal.zone.in-addr.db' , owner: \"{{ dns_user }}\" , mode: '0644'}\n    - { src: 'named/dummy', dest: '/var/named-iiab/data/dummy' , owner: \"{{ dns_user }}\" , mode: '0644'}\n    - { src: 'named/named.blackhole', dest: '/var/named-iiab/named.blackhole' , owner: \"{{ dns_user }}\" , mode: '0644'}\n\n- name: substitute our unit file which uses $OPTIONS from sysconfig\n  template: src=named/{{ dns_service }}.service\n            dest=/etc/systemd/system/{{ dns_service }}.service\n            mode=0644\n\n- name: The dns-jail redirect requires the named.blackhole,disabling recursion\n#        in named-iiab.conf, and the redirection of 404 error documents to /\n  template: src=named/dns-jail.conf dest=/etc/{{ apache_config_dir }}/\n  when: dns_jail_enabled\n\n- name: Separate enabling required for debian\n  file: src=/etc/{{ apache_config_dir }}/dns-jail.conf\n        path=/etc/{{ apache_service }}/sites-enabled/dns-jail.conf\n        state=link\n  when: is_debuntu and dns_jail_enabled\n\n- name: Separate enabling/disabling required for debian\n  file: src=/etc/{{ apache_config_dir }}/dns-jail.conf\n        path=/etc/{{ apache_service }}/sites-enabled/dns-jail.conf\n        state=absent\n  when: is_debuntu and not dns_jail_enabled\n\n- name: Separate enabling/disabling required for non debian\n  file: path=/etc/{{ apache_config_dir }}/dns-jail.conf\n        state=absent\n  when: not is_debuntu and not dns_jail_enabled\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "fef8d9ee953c7bd868353e028a128ff2c2c1e2ba", "filename": "roles/config-quay-enterprise/tasks/complete_setup.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Configure Setup Process on 1st Quay Host\n  block:\n    - name: Set Setup Output File Location\n      set_fact:\n        tmp_setup_file_location: /tmp/quay\n\n    - name: Restart Quay\n      systemd:\n        name: \"{{ quay_service }}\"\n        enabled: yes\n        state: restarted\n        daemon_reload: yes\n\n    - name: Hit Quay Setup Endpoint\n      uri:\n        url: \"{{ quay_http_protocol }}://{{ quay_server_hostname }}/setup/\"\n        validate_certs: no\n        method: GET\n        return_content: yes\n      register: uri_setup\n      until: uri_setup.status == 200\n      retries: 30\n      delay: 10\n    - name: Write file\n      copy:\n        content: \"{{ uri_setup.content }}\"\n        dest: \"{{ tmp_setup_file_location }}\"\n    - name: Extract csrf token\n      shell: cat /tmp/quay | grep \"__token\" | awk -F\\' '{print $(NF-1)}'\n      register: token\n    - name: Create Superuser\n      uri:\n        url:  \"{{ quay_http_protocol }}://{{ quay_server_hostname }}/api/v1/superuser/config/createsuperuser?_csrf_token={{ token.stdout | urlencode }}\"\n        validate_certs: no\n        method: POST\n        body_format: json\n        body:\n          username: \"{{ quay_superuser_username }}\"\n          email: \"{{ quay_superuser_email }}\"\n          password: \"{{ quay_superuser_password }}\"\n        headers:\n          Cookie: \"{{ uri_setup.set_cookie }}\"\n\n    - name: Delete Temporary Setup File\n      file:\n        state: absent\n        path: \"{{ tmp_setup_file_location }}\"\n  when: inventory_hostname == groups['quay_enterprise'][0]\n\n- name: Set setup_complete Fact\n  set_fact:\n    quay_setup_complete: True\n\n- name: Setup initial quay configuration file\n  template:\n    src: config.yaml.j2\n    dest: \"{{ quay_config_dir }}/config.yaml\"\n    owner: root\n    group: root\n    mode: g+rw\n  notify: Restart quay service\n"}, {"commit_sha": "ccab58ae5d697bb64abd86558f79c34161d2fb00", "sha": "865b55273be72c130a7738db01cfde7df305f36b", "filename": "tasks/declare_script_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- name: Removing (potential) previously declared Groovy script {{ item }}\n  uri:\n    url: \"{{ nexus_api_scheme }}://{{ nexus_api_hostname }}:{{ nexus_api_port }}\\\n      {{ nexus_api_context_path }}{{ nexus_rest_api_endpoint }}/{{ item }}\"\n    user: 'admin'\n    password: \"{{ current_nexus_admin_password }}\"\n    method: DELETE\n    force_basic_auth: yes\n    status_code: 204,404\n    validate_certs: \"{{ nexus_api_validate_certs }}\"\n\n- name: Declaring Groovy script {{ item }}\n  uri:\n    url: \"{{ nexus_api_scheme }}://{{ nexus_api_hostname }}:{{ nexus_api_port }}\\\n      {{ nexus_api_context_path }}{{ nexus_rest_api_endpoint }}\"\n    user: 'admin'\n    password: \"{{ current_nexus_admin_password }}\"\n    body_format: json\n    method: POST\n    force_basic_auth: yes\n    status_code: 204\n    validate_certs: \"{{ nexus_api_validate_certs }}\"\n    body:\n      name: \"{{ item }}\"\n      type: 'groovy'\n      content: \"{{ lookup('file', 'groovy/' + item + '.groovy') }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "cc27d6006101232246395664be2fa6f0d338c5c3", "filename": "roles/config-iscsi-client/tasks/prereq.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Install required packages'\n  package:\n    name: '{{ item }}'\n    state: installed\n  with_items:\n  - iscsi-initiator-utils\n  - device-mapper-multipath\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "333ba515c1faa9366630bf0cae4046e08e98854e", "filename": "playbooks/dns/vars/inventory", "repository": "redhat-cop/casl-ansible", "decoded_content": "\n[dns]\ndns.example.com ansible_user=fedora ansible_become=yes\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "32b3d530d433c3cde2d993f8b4afb3a548d1f059", "filename": "roles/mariadb/defaults/main.yml", "repository": "roots/trellis", "decoded_content": "mariadb_binary_logging_disabled: true\nmariadb_keyserver_fingerprint: \"0xcbcb082a1bb943db\"\nmariadb_mirror: nyc2.mirrors.digitalocean.com\nmariadb_version: \"10.0\"\nmariadb_dist: trusty\nmysql_root_user: root\n\nsites_using_remote_db: \"[{% for name, site in wordpress_sites.iteritems() if site.env is defined and site.env.db_host | default('localhost') != 'localhost' %}'{{ name }}',{% endfor %}]\"\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "7d4955bdd434dcdadf109138df14311fb0477ee1", "filename": "tasks/selinux-RedHat.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n\n- name: Make sure we have the necessary yum packages available for selinux\n  yum:\n    name: \"{{ item }}\"\n    state: present\n  with_items:\n    - libselinux-python\n    - libsemanage-python\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "96ec57105bbf6960ed4f537cc065cff72e5cb135", "filename": "roles/config-httpd/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: web-server\n  roles:\n  - config-httpd \n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "3f19aab8dc71ba71755bff1b777b72cfe3ed319c", "filename": "roles/moodle/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "moodle_version: 31\nmoodle_repo_url: \"https://github.com/moodle/moodle.git\"\nmoodle_base: \"{{ iiab_base }}/moodle\"\nmoodle_user: moodle\nmoodle_install: True\nmoodle_enabled: False\nmoodle_data: '{{ content_base }}/moodle'\nmoodle_database_name: moodle\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "313924dccce2c424ed41b8d028cec34dd777f0ca", "filename": "roles/osp/admin-nova-service/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Disable nova compute services on selected hosts\"\n  shell: >\n    source {{ admin_keystonerc_file }};\n    openstack compute service set --disable {{ item }} nova-compute\n  with_items:\n  - \"{{ ansible_play_hosts }}\"\n  when:\n  - hostvars[item].nova_service is defined\n  - hostvars[item].nova_service == 'disabled'\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "b1d815f58f6d42aabb389f0a59672e5fcc836759", "filename": "roles/ovirt-collect-logs/meta/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\ngalaxy_info:\n  author: \"Lukas Bednar\"\n  description: \"Collects logs from oVirt deployment\"\n  company: \"Red Hat\"\n  license: \"GPLv3\"\n  min_ansible_version: 1.9\n  platforms:\n    - name: EL\n      versions:\n        - all\n  galaxy_tags:\n    - installer\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "da6bbc09a633c4ef01809f988abefea2322b7278", "filename": "roles/notifications/md-to-html/tests/inventory/group_vars/all.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nmarkdown_content: \"Hello, this is **bold** text\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "226d7ccd3e881e1278fd43af0f17fdceac0485e9", "filename": "playbooks/osp/update-osp-cluster-admin.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: infra_osp_hosts\n  roles:\n  - { role: config-software-src, when: '\"controller\" in osp_roles' }\n  - { role: osp/admin-keystone-domain, when: '\"controller\" in osp_roles' }\n  - { role: osp/admin-volume-type, when: '\"controller\" in osp_roles' }\n  - { role: osp/admin-nova-service, when: '\"controller\" in osp_roles' }\n  - { role: osp/admin-nova-flavor, when: '\"controller\" in osp_roles' }\n  - { role: osp/admin-image, when: '\"controller\" in osp_roles' }\n  - { role: osp/admin-project, when: '\"controller\" in osp_roles' }\n  - { role: osp/admin-network, when: '\"controller\" in osp_roles' }\n  - { role: osp/admin-user, when: '\"controller\" in osp_roles' }\n\n"}, {"commit_sha": "2a05a5032ce341d6a1d918453164c59ea2922f58", "sha": "e7a97d1a09ee8519d8e1e8c8026649fb40f32318", "filename": "roles/network_interface/README.md", "repository": "CSCfi/fgci-ansible", "decoded_content": "network_interface\n=================\n\n_WARNING: This role can be dangerous to use. If you lose network connectivity\nto your target host by incorrectly configuring your networking, you may be\nunable to recover without physical access to the machine._\n\nThis roles enables users to configure various network components on target\nmachines. The role can be used to configure:\n\n- Ethernet interfaces\n- Bridge interfaces\n- Bonded interfaces\n- VLAN tagged interfaces\n- Network routes\n\nRequirements\n------------\n\nThis role requires Ansible 1.4 or higher, and platform requirements are listed\nin the metadata file.\n\nRole Variables\n--------------\n\nThe variables that can be passed to this role and a brief description about\nthem are as follows:\n\n    # The list of ethernet interfaces to be added to the system\n    network_ether_interfaces: []\n\n    # The list of bridge interfaces to be added to the system\n    network_bridge_interfaces: []\n\n    # The list of bonded interfaces to be added to the system\n    network_bond_interfaces: []\n\n    # The list of vlan interfaces to be added to the system\n    network_vlan_interfaces: []\n\nNote: The values for the list are listed in the examples below.\n\nExamples\n--------\n\n1) Configure eth1 and eth2 on a host with a static IP and a dhcp IP. Also\ndefine static routes and a gateway.\n\n    - hosts: myhost\n      roles:\n        - role: network\n          network_ether_interfaces:\n           - device: eth1\n             bootproto: static\n             address: 192.168.10.18\n             netmask: 255.255.255.0\n             gateway: 192.168.10.1\n             route:\n              - network: 192.168.200.0\n                netmask: 255.255.255.0\n                gateway: 192.168.10.1\n              - network: 192.168.100.0\n                netmask: 255.255.255.0\n                gateway: 192.168.10.1\n           - device: eth2\n             bootproto: dhcp\n\n2) Configure a bridge interface with multiple NIcs added to the bridge.\n\n    - hosts: myhost\n      roles:\n        - role: network\n          network_bridge_interfaces:\n           -  device: br1\n              type: bridge\n              address: 192.168.10.10\n              netmask: 255.255.255.0\n              bootproto: static\n              stp: \"on\"\n              ports: [eth1, eth2]\n\nNote: Routes can also be added for this interface in the same way routes are\nadded for ethernet interfaces.\n\n3) Configure a bond interface with an \"active-backup\" slave configuration.\n\n    - hosts: myhost\n      roles:\n        - role: network\n          network_bond_interfaces:\n            - device: bond0\n              address: 192.168.10.128\n              netmask: 255.255.255.0\n              bootproto: static\n              bond_mode: active-backup\n              bond_miimon: 100\n              bond_slaves: [eth1, eth2]\n              route:\n              - network: 192.168.222.0\n                netmask: 255.255.255.0\n                gateway: 192.168.10.1\n\n4) Configure a bonded interface with \"802.3ad\" as the bonding mode and IP\naddress obtained via DHCP.\n\n    - hosts: myhost\n      roles:\n        - role: network\n          network_bond_interfaces:\n            - device: bond0\n              bootproto: dhcp\n              bond_mode: 802.3ad\n              bond_miimon: 100\n              bond_slaves: [eth1, eth2]\n\n5) Configure a VLAN interface with the vlan tag 2 for an ethernet interface\n\n    - hosts: myhost\n      roles:\n        - role: network\n          network_ether_interfaces:\n           - device: eth1\n             bootproto: static\n             address: 192.168.10.18\n             netmask: 255.255.255.0\n             gateway: 192.168.10.1\n          network_vlan_interfaces:\n\t   - device: eth1.2\n\t     bootproto: static\n\t     address: 192.168.20.18\n\t     netmask: 255.255.255.0\n\n6) All the above examples show how to configure a single host, The below\nexample shows how to define your network configurations for all your machines.\n\nAssume your host inventory is as follows:\n\n### /etc/ansible/hosts\n\n    [dc1]\n    host1\n    host2\n\nDescribe your network configuration for each host in host vars:\n\n### host_vars/host1\n\n    network_ether_interfaces:\n           - device: eth1\n             bootproto: static\n             address: 192.168.10.18\n             netmask: 255.255.255.0\n             gateway: 192.168.10.1\n             route:\n              - network: 192.168.200.0\n                netmask: 255.255.255.0\n                gateway: 192.168.10.1\n    network_bond_interfaces:\n            - device: bond0\n              bootproto: dhcp\n              bond_mode: 802.3ad\n              bond_miimon: 100\n              bond_slaves: [eth2, eth3]\n\n### host_vars/host2\n\n    network_ether_interfaces:\n           - device: eth0\n             bootproto: static\n             address: 192.168.10.18\n             netmask: 255.255.255.0\n             gateway: 192.168.10.1\n\nCreate a playbook which applies this role to all hosts as shown below, and run\nthe playbook. All the servers should have their network interfaces configured\nand routed updated.\n\n    - hosts: all\n      roles:\n        - role: network\n\nNote: Ansible needs network connectivity throughout the playbook process, you\nmay need to have a control interface that you do *not* modify using this\nmethod so that Ansible has a stable connection to configure the target\nsystems.\n\nDependencies\n------------\n\nNone\n\nLicense\n-------\n\nBSD\n\nAuthor Information\n------------------\n\nBenno Joy\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "43077ec815db6b45282c66354db8c9d98cc58386", "filename": "roles/config-quay-builder/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Validate Quay Hostname Provided\n  fail:\n    msg: \"Quay Hostname Must Be Provided!\"\n  when: quay_enterprise_hostname is undefined or quay_enterprise_hostname|trim == \"\"\n\n- name: Include Container Credentials\n  include_tasks: container_credentials.yml\n  when: (quay_registry_server | trim != \"\") and ((quay_registry_auth | trim != \"\") or (quay_registry_email | trim != \"\"))\n\n- name: Configure Configuration Directory\n  file:\n    state: directory\n    owner: root\n    group: root\n    mode: g+rw\n    path: \"{{ quay_builder_config_dir }}\"\n  \n- name: Configure Trusted SSL\n  block:\n    - name: Check if Trusted SSL file exists\n      become: false\n      stat:\n        path: \"{{ quay_builder_ssl_trust_src_file  }}\"\n      register: trusted_ssl_exists\n      changed_when: False\n      delegate_to: localhost\n    \n    - name: Fail if SSL source file does not exist\n      fail:\n        msg: \"Could not locate SSL trust certificate\"\n      when: trusted_ssl_exists.stat.exists == false\n  \n    - name: Copy SSL Certificate\n      copy:\n        src: \"{{ quay_builder_ssl_trust_src_file }}\"\n        dest: \"{{ quay_builder_ssl_trust_host_file }}\"\n        owner: root\n        group: root\n        mode: g+rw\n      notify: Restart Quay Builder Service\n  when: quay_builder_ssl_trust_configure|bool\n\n- name: Configure systemd environment files\n  template:\n    src: \"quay-builder.j2\"\n    dest: \"{{ systemd_environmentfile_dir}}/{{ quay_builder_name }}\"\n  notify: Restart Quay Builder Service\n\n- name: Configure systemd unit files\n  template:\n    src: \"quay-builder.service.j2\"\n    dest: \"{{ systemd_service_dir}}/{{ quay_builder_service }}\"\n  notify: Restart Quay Builder Service"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "7b0ac7d50fc022b588cf80702800a78c0b4e654c", "filename": "playbooks/provision-dns-server/subscribe-rhel.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Subscribe RHEL based instances\" \n  vars:\n    rhsm_username: \"{{ hostvars['localhost'].rhsm_username }}\"\n    rhsm_password: \"{{ hostvars['localhost'].rhsm_password }}\"\n  include_role: \n    name: rhsm\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "8db268c3733146a043215ff7f8e777b8c8447f97", "filename": "roles/2-common/tasks/yum.yml", "repository": "iiab/iiab", "decoded_content": "- name: install yum deps for arm!!!\n  shell: dnf install -y python-urlgrabber pyxattr yum-metadata-parser\n  when: ansible_distribution == \"Fedora\" and ansible_machine == \"armv7l\" and ansible_distribution_version|int >= 22\n\n- name: install yum from Fedora 23 for arm!!!\n  shell: dnf install -y https://kojipkgs.fedoraproject.org//packages/yum/3.4.3/506.fc23/noarch/yum-3.4.3-506.fc23.noarch.rpm python-dnf \n  when: ansible_distribution == \"Fedora\" and ansible_machine == \"armv7l\" and ansible_distribution_version|int >= 22\n\n- name: install yum if it has been dropped from our distribution -- Fedora 22 uses dnf!!!\n  shell: dnf install -y yum\n  when: ansible_distribution == \"Fedora\" and ansible_distribution_version|int >= 22 and ansible_machine != \"armv7l\"\n\n- name: get the createrepo program\n  package: name=createrepo\n           state=present\n  when: is_redhat\n\n- name: Create local repo\n  shell: createrepo {{ yum_packages_dir }}\n  when: is_redhat\n\n- name: Install local repo file.\n  template: dest=/etc/yum.repos.d/iiab-local.repo\n            src=local.repo\n            owner=root\n            mode=0644\n  when: is_redhat\n\n- name: Install yum packages\n  package: name={{ item }}\n           state=present\n  with_items:\n   - yum-utils\n   - createrepo\n   - wpa_supplicant\n   - linux-firmware\n   - syslog\n   - xml-common\n  when: is_redhat\n\n- name: Install yum packages for Debian\n  package: name={{ item }}\n           state=present\n  with_items:\n    - inetutils-syslogd\n    - wpasupplicant\n  when: is_debuntu\n\n- name: Install common packages\n  package: name={{ item }}\n           state=present\n  with_items:\n   - acpid\n   - mlocate\n   - rsync\n   - htop\n   - etckeeper\n   - python-passlib\n   - usbmount\n   - net-tools\n   - openssh-server\n   - sudo\n   - logrotate\n   - make\n   - tar\n   - unzip\n   - bzip2\n   - i2c-tools\n   - bridge-utils\n   - usbutils\n   - hostapd\n   - wget\n   - openssl   #FC 18 does not supply, but pear requires\n   - gawk\n   - sqlite3\n\n- name: Update common packages (not debian\n  package: name={{ item }}\n           state=latest\n  with_items:\n   - NetworkManager\n   - glibc # CVE-2015-7547\n   - bash\n   - iptables\n  when: is_redhat\n\n- name: Update common packages  (debian)\n  package: name={{ item }}\n           state=latest\n  with_items:\n   - libc6\n   - bash\n   - iptables\n  when: is_debuntu\n\n\n# instuctions state to start with a fully updated system before starting, stop using\n# ansible as a crutch for developers not following the directions and taking short-cuts\n\n#- name: If version of Network manager has changed, subsequent nmcli commands will fail,restart now\n#  service: name=NetworkManager\n#           state=restarted\n#  when: not installing\n# the above should use a handler - all reboots should wait until all \n# mods are preformed\n\n- name: Install optional exFAT packages for CentOS\n  shell: yum --enablerepo=li-nux-ro install exfat-utils fuse-exfat\n  when: exFAT_enabled == \"True\" and ansible_distribution == \"CentOS\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "649e97e5b7973323fec712ad98cce05ad9618e84", "filename": "roles/config-bonding/tests/infrahosts.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Configure bonding on the infrastructure hosts'\n  hosts: infra_hosts\n  roles:\n  - role: config_bonding\n  tags: \n  - configure_infra_hosts\n"}, {"commit_sha": "96adc61e360141bb718b75d48c387b3680a8471b", "sha": "645d83c9bbfccc0c2f7917f8136ec343ca2d4ca5", "filename": "tasks/configure-systemd.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "- name: Combine all systemd service configuration options\n  set_fact:\n    _systemd_service_config: \"{{ docker_systemd_service_config_tweaks + docker_systemd_service_config }}\"\n\n- name: Ensure /etc/systemd/system/docker.service.d directory exists\n  file:\n    path: /etc/systemd/system/docker.service.d\n    state: directory\n    mode: 0755\n  become: yes\n\n- name: Setup default Docker drop-in to enable use of environment file\n  template:\n    src: drop-ins/default.conf.j2\n    dest: /etc/systemd/system/docker.service.d/default.conf\n  become: yes\n  notify: restart docker\n  register: _systemd_docker_dropin\n  vars:\n    systemd_envs_dir: \"{{ docker_envs_dir[_docker_os_dist] }}\"\n    systemd_service_conf: \"{{ _systemd_service_config }}\"\n\n- name: Combine Docker daemon environment variable configuration\n  set_fact:\n    docker_service_envs: \"{{ docker_service_envs | combine(_docker_service_opts) | combine(docker_daemon_envs) }}\"\n  vars:\n    _docker_service_opts:\n      DOCKER_OPTS: \"{{ docker_daemon_opts }}\"\n\n- name: Setup Docker environment file {{ docker_envs_dir[_docker_os_dist] }}/docker-envs\n  template:\n    src: docker-envs.j2\n    dest: \"{{ docker_envs_dir[_docker_os_dist] }}/docker-envs\"\n  become: yes\n  notify: restart docker\n  vars:\n    docker_envs: \"{{ docker_service_envs }}\"\n\n- name: Force daemon reload of systemd\n  systemd:\n    daemon_reload: yes\n  become: yes\n  notify: restart docker\n  when: _systemd_docker_dropin|changed"}, {"commit_sha": "2f1ed84fec270723a1031cdc2b07b7a76a5a3bda", "sha": "213fd17474dd1b0fd967eed89d6894fd9ba06f98", "filename": "tasks/main-Fedora.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n# tasks file for ansible-role-docker-ce\n\n- name: Add Docker CE repository\n  shell: dnf config-manager --add-repo https://download.docker.com/linux/fedora/docker-ce.repo\n  args:\n    creates: /etc/yum.repos.d/docker-ce.repo\n  become: true\n  register: dnf_repo\n\n- name: Update dnf cache\n  shell: dnf makecache fast\n  become: true\n  when: dnf_repo.changed\n\n- name: Install python and deps for ansible modules\n  raw: dnf install -y python2 python2-dnf libselinux-python\n  become: true\n  changed_when: false\n\n- include: main-Generic.yml"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a70126f6d17c04272844c448b0f8ea97eac7bcbd", "filename": "roles/dns/manage-dns-records/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- include_tasks: nsupdate/main.yml\n- include_tasks: route53/main.yml\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "2589dd416d683a99794a2c21ba93a2239dacb5ca", "filename": "roles/ovirt-engine-cleanup/tasks/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\n# copy answer file\n- name: copy answerfile\n  template:\n    # TODO generate this varialbe from ovirt_engine_version and ovirt_engine_dwh\n    src: answerfile_{{ ovirt_engine_version|int }}.x.txt.j2\n    dest: /tmp/answerfile.txt\n    mode: 0644\n    owner: root\n    group: root\n\n- name: run engine-cleanup with answerfile\n  shell: 'engine-cleanup --config-append=/tmp/answerfile.txt'\n  tags:\n    - skip_ansible_lint\n\n- name: clean tmp files\n  file:\n    path: '/tmp/answerfile.txt'\n    state: 'absent'\n"}, {"commit_sha": "d25113e8fab871b2ead95ca976c5a43e4759ea26", "sha": "619b33592ce3b6737bf76cf92768bb97a5f4dbaf", "filename": "tasks/replication.yml", "repository": "UnderGreen/ansible-role-mongodb", "decoded_content": "---\n\n- name: Replication configuration\n  mongodb_replication:\n    login_host: \"{{ mongodb_login_host|default('localhost') }}\"\n    login_port: \"{{ mongodb_login_port|default(27017) }}\"\n    login_user: \"{{ mongodb_root_admin_name }}\"\n    login_password: \"{{ mongodb_root_admin_password }}\"\n    replica_set: \"{{ mongodb_conf_replSet }}\"\n    host_name: \"{{ item.host_name }}\"\n    host_port: \"{{ item.host_port|default(27017) }}\"\n    host_type: \"{{ item.host_type|default('replica') }}\"\n  when: mongodb_conf_auth and mongodb_replication_params is defined\n  with_items:\n    - \"{{ mongodb_replication_params }}\"\n\n- name: Replication configuration without auth\n  mongodb_replication:\n    login_host: \"{{ mongodb_login_host|default('localhost') }}\"\n    login_port: \"{{ mongodb_login_port|default(27017) }}\"\n    replica_set: \"{{ mongodb_conf_replSet }}\"\n    host_name: \"{{ item.host_name }}\"\n    host_port: \"{{ item.host_port|default(27017) }}\"\n    host_type: \"{{ item.host_type|default('replica') }}\"\n  when: not mongodb_conf_auth and mongodb_replication_params is defined\n  with_items:\n    - \"{{ mongodb_replication_params }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "ad2d0744f63ae0d1b616aebfd50e4675c84e58bd", "filename": "roles/pathagar/templates/pathagar.conf", "repository": "iiab/iiab", "decoded_content": "\nAlias {{ pathagar_subpath }}/static/ {{ pathagar_collectstatic }}/\nAlias {{ pathagar_subpath }}/static_media/ {{ pathagar_media }}/\n\n<Directory {{ pathagar_collectstatic }}>\n  Order deny,allow\n  Allow from all\n  Require all granted\n</Directory>\n\n<Directory {{ pathagar_media }}>\n  Order deny,allow\n  Allow from all\n  Require all granted\n</Directory>\n\nWSGIPythonPath {{ pathagar_dir }}:{{ pathagar_venv }}/lib/python2.7/site-packages\nWSGIScriptAlias {{ pathagar_subpath }} {{ pathagar_dir }}/wsgi.py\n\n<Directory {{ pathagar_dir }}>\n  <Files wsgi.py>\n    Order allow,deny\n    Allow from all\n    Require all granted\n  </Files>\n</Directory>\n\n\nCustomLog /var/log/{{ apache_service }}/pathagar-access.log combined\nServerSignature On\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "61283a1c3a865b5124e97a4773f86862fa888c42", "filename": "tasks/checks/compatibility-checks.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n# https://github.com/moby/moby/issues/35873\n# https://access.redhat.com/solutions/2991041\n- name: Compatibility check - Fail if both MountFlags=slave and live-restore are set\n  fail:\n    msg: >\n      Setting both `MountFlags=slave` (docker_enable_mount_flag_fix: true)\n      and `live-restore=true` (docker_daemon_config['live-restore']: true)\n      triggers a bug (https://github.com/moby/moby/issues/35873). For now,\n      don't use both.\n  when:\n    - docker_enable_mount_flag_fix\n    - docker_daemon_config['live-restore'] is defined\n    - docker_daemon_config['live-restore']\n\n\n# Issues related to specified URL http://pypi.python.org/simple/ which now must be https.\n- name: Compatibility check - Fail if PiP is required due to issues getting it to work smooth in Debian Wheezy\n  fail:\n    msg: >\n      Make sure Docker SDK, docker-compose etc is already in place before using\n      this role on a host running Debian Wheezy.\n  when:\n    - _docker_os_dist == \"Debian\"\n    - _docker_os_dist_major_version == '7'\n    - docker_stack|bool or\n      docker_sdk|bool or\n      docker_pip_upgrade|bool or\n      (docker_compose|bool and not docker_compose_no_pip|bool) or\n      docker_additional_packages_pip|length > 0"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "becd77e081a6968dd96e6a9047f42f2d368fe768", "filename": "roles/nfs-server/tests/inventory/group_vars/all.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nnfs_shares:\n- name: registry\n- name: metrics\n  nfs_owner: \"root\" \n  nfs_group: \"root\"\n  nfs_mode: \"0755\"     \n  nfs_share_options: \"ro\"\n- name: logging\n- name: data\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "6c56cc8e4dd2492e5ad72cc50d70cce508ee2989", "filename": "roles/nfs-server/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: prep.yml\n- import_tasks: lvm.yml\n- import_tasks: shares.yml\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "c772f6a5e7d8a00a6b57f7acdc1138fe0b91022e", "filename": "roles/load-balancers/manage-haproxy/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'enable and start service(s)'\n  service:\n    name: '{{ item }}'\n    enabled: yes\n    state: started\n  with_items:\n  - haproxy\n  become: True\n\n- name: 'restart rsyslog'\n  service:\n    name: rsyslog\n    state: restarted\n  become: True\n\n- name: 'reload haproxy'\n  service:\n    name: haproxy\n    state: reloaded\n  become: True\n\n- name: 'remove tmp new file'\n  file:\n    path: '{{ temp_new_file }}'\n    state: absent\n  become: True\n\n- name: 'cleanup temp dir'\n  file:\n    path: '{{ haproxy_temp_dir }}'\n    state: absent\n  delegate_to: localhost\n  run_once: True\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "48a75b3c3df5d0a6428b2cfd2ffe3de4d12533c1", "filename": "roles/sugarizer/templates/sugarizer.conf", "repository": "iiab/iiab", "decoded_content": "RewriteRule       ^/sugarizer(.*)$  http://localhost:8089/sugarizer$1 [P,L]\nProxyPassReverse  /sugarizer        http://localhost:8010/sugarizer\nProxyRequests     Off\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "6b6ebfa7b120b6b2e545e62fc33ed8edef09df7f", "filename": "playbooks/rhsm.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# If you want to use username/password for subscription, please ensure\n# to run the \"prep.yml\" playbook before running this playbook\n# - alternatively use the \"subscribe-host.yml\" playbook instead\n\n- hosts: rhsm_hosts\n  vars:\n    rhsm_username: \"{{ hostvars['localhost'].rhsm_username|default(omit) }}\"\n    rhsm_password: \"{{ hostvars['localhost'].rhsm_password|default(omit) }}\"\n  roles:\n  - role: rhsm\n    when:\n    - rhsm_register|default(False)\n  tags:\n  - configure_rhsm\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "6202bd1ce4d3fb45fdf9ab72d4db19084aac5407", "filename": "roles/ansible/tower/manage-inventories/tasks/process-inventory.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Get the org id based on the org name\"\n  set_fact:\n    org_id: \"{{ item.id }}\"\n  when:\n  - item.name|trim == inventory.organization|trim\n  with_items:\n  - \"{{ existing_organizations_output.rest_output }}\"\n\n- name: \"Load up the inventory\"\n  uri:\n    url: https://localhost/api/v2/inventories/\n    method: POST\n    body: \"{{ lookup('template', 'inventory.j2') }}\"\n    body_format: 'json'\n    headers:\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n    user: admin\n    password: \"{{ tower_admin_password }}\"\n    validate_certs: no\n    status_code: 200,201,400\n  register: inventory_output\n\n# Utilize the `rest_get` library routine to ensure REST pagination is handled\n- name: \"Get the updated list of existing inventories\"\n  rest_get:\n    host_url: \"{{ tower_url }}\"\n    api_uri: \"/api/v2/inventories/\"\n    rest_user: \"{{ tower_admin_username }}\"\n    rest_password: \"{{ tower_admin_password }}\"\n  register: existing_inventories_output\n\n- name: \"Get the inventory id based on the inventory name\"\n  set_fact:\n    inv_id: \"{{ item.id }}\"\n  when:\n  - item.name|trim == inventory.name|trim\n  with_items:\n  - \"{{ existing_inventories_output.rest_output }}\"\n\n- name: \"Process the inventory host entries\"\n  include_tasks: process-host.yml\n  with_items:\n  - \"{{ inventory.hosts }}\"\n  loop_control:\n    loop_var: host\n\n- name: \"Process the inventory group entries\"\n  include_tasks: process-group.yml\n  with_items:\n  - \"{{ inventory.groups }}\"\n  loop_control:\n    loop_var: group\n\n- name: \"Clear/Update facts\"\n  set_fact:\n    org_id: ''\n    inv_id: ''\n    processed_inventories: \"{{ processed_inventories + [ { 'name': inventory.name } ] }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "6764aacbf5a5bd64f0d2bfea74f535c652dde973", "filename": "roles/config-clair/tasks/firewall.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Check if firewalld is installed\n  command: systemctl status firewalld\n  register: firewalld_status\n  failed_when: false\n  changed_when: false\n\n- name: Check if iptables is installed\n  command: systemctl status iptables\n  register: iptables_status\n  failed_when: false\n  changed_when: false\n\n- name: Open port in firewalld\n  firewalld:\n    port: \"{{ item }}/tcp\"\n    permanent: true\n    state: enabled\n  when: firewalld_status.rc == 0\n  with_items:\n    - \"{{ clair_host_proxy_port }}\"\n    - \"{{ clair_host_api_port }}\"\n  notify:\n  - restart firewalld\n\n- name: Open iptables Clair firewall port for future sessions\n  lineinfile:\n    insertbefore: \"-A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT\"\n    state: present\n    dest: /etc/sysconfig/iptables\n    regexp: \"^-A INPUT .* --dport {{ item }} .* ACCEPT\"\n    line: \"-A INPUT -p tcp -m state --state NEW -m tcp --dport {{ item }} -j ACCEPT\"\n  with_items:\n    - \"{{ clair_host_proxy_port }}\"\n    - \"{{ clair_host_api_port }}\"\n  when: iptables_status.rc == 0 and firewalld_status.rc != 0\n  # notify:\n  # - restart iptables\n\n- name: Open iptables Clair firewall port for current session\n  iptables:\n    action: insert\n    protocol: tcp\n    destination_port: \"{{ item }}\"\n    state: present\n    chain: INPUT\n    jump: ACCEPT\n  with_items:\n    - \"{{ clair_host_proxy_port }}\"\n    - \"{{ clair_host_api_port }}\"\n  when: iptables_status.rc == 0 and firewalld_status.rc != 0\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "99a131aa2110c8c459f42b1810390f4427e45e27", "filename": "roles/network/templates/named/school.internal.zone.db", "repository": "iiab/iiab", "decoded_content": "@ in soa localhost. root 1 3H 15M 1W 1D\n  ns localhost.\n\n{{ iiab_hostname }}\tIN\tA\t172.18.96.1\nschoolserver\tIN\tA\t172.18.96.1\nschool\t\tIN\tA\t172.18.96.1\nwww\t\tIN\tA\t172.18.96.1\nntp\t\tIN\tA\t172.18.96.1\ntime\t\tIN\tA\t172.18.96.1\npresence\tIN\tA\t172.18.96.1\nxs\t\tIN\tA\t172.18.96.1\nlibrary\t\tIN\tA\t172.18.96.1\nbox\t\tIN\tA\t172.18.96.1\n\n\nconference.schoolserver\tIN\tA\t172.18.96.1\n\n\n; translations of school - in plain latin script\n; or un punycode of the utf-8 representation\n\n; es - escuela\nescuela         IN      CNAME       school\n\n; de - schule\nschule          IN      CNAME       school\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "38f4469db509d3b637c5c00ed0aa44e3ec83b787", "filename": "roles/xovis/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Install Couchdb and other necessary packages\n  package: name={{ item }}\n           state=present\n  with_items:\n    - couchdb\n    - curl\n    - python-pip\n    - nodejs\n    - npm\n  when: internet_available\n\n- name: Determine if xovis is already downloaded\n  stat: path={{ downloadds_dir }}/xovis/xxx\n  register: xovis\n\n- name: download the latest xovis repo\n  git: repo={{ xovis_repo_url }}\n       dest={{ downloads_dir }}/xovis\n       depth=1\n  when: internet_available  and xovis.stat.exists is defined and not xovis.stat.exists\n\n- name: Install node.js package kanso to maintain couchdb\n  npm: name=kanso\n       global=yes\n       path={{ downloads_dir }}\n  when: internet_available\n\n- name: move the xovis repo into place\n  shell: \"cp -rp {{ downloads_dir }}/xovis {{ xovis_root }}\"\n\n- name: Make sure the XO users directory exists\n  file: state=directory\n        dest=/library/users\n        owner=root\n        group=root\n        mode=0755\n\n- name: Install the xovis python dependencies\n  pip: requirements={{ xovis_root }}/process_stats/requirements.txt\n  when: internet_available\n\n- name: Update xovis repo with Chart Heading\n  lineinfile: dest=\"{{ xovis_root }}/index.html\" regexp='(.+)<h1>(.*)</h1>' line='\\1<h1>{{ xovis_chart_heading }}</h1>' backrefs=yes\n\n- name: Allow access to Couchdb from other hosts\n  command: sed -i 's/^\\(bind_address\\s*=\\s*\\).*$/\\10\\.0\\.0\\.0/' /etc/couchdb/default.ini\n\n- name: Enable Couchdb service\n  service: name=couchdb\n           enabled=yes\n           state=started\n  when: xovis_enabled\n\n- name: Wait for couchdb to become ready\n  wait_for: port=5984\n            delay=1\n            timeout=5\n  when: xovis_enabled\n\n- name: Add admin user\n  command: curl -X PUT {{ xovis_target_host }}/_config/admins/{{ xovis_db_user }} -d \"\\\"{{ xovis_db_password }}\\\"\"\n  when: xovis_enabled\n\n- name: Check if db exists\n  shell: \"kanso listdb | grep {{ xovis_db_name }}\"\n  register: found_db\n  ignore_errors: yes\n\n- name: Create Couchdb database if does not already exist\n  command: kanso createdb {{ xovis_db_url }}\n  when: xovis_enabled and found_db.stdout != xovis_db_name\n\n- name: Load initial xovis database\n  command: kanso push {{ xovis_root }} {{ xovis_db_url }}\n  when: xovis_enabled and found_db.stdout != xovis_db_name\n\n- name: Insert Sugar Journal metadata into Couchdb\n  command: \"{{ xovis_root }}/process_stats/process_journal_stats.py dbinsert {{ xovis_db_name }}\n  -d {{ xovis_backup_dir }}\n  --deployment {{ xovis_deployment_name }}\n  --server http://{{ xovis_db_login }}@{{ xovis_target_host }}\"\n  when: xovis_enabled\n\n- name: Add xovis to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=xovis\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: xovis\n    - option: description\n      value: '\"XOVis - Analytics and Visualization for Sugar and OLPC\"'\n    - option: installed\n      value: \"{{ xovis_install }}\"\n    - option: enabled\n      value: \"{{ xovis_enabled }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "fd0d10f3b548865757397e5638ee3529973a968c", "filename": "roles/1-prep/templates/iiab-network-reset", "repository": "iiab/iiab", "decoded_content": "#!/bin/bash\n# if called w/ parameter, skip the reset, create diagnostic package w/ param as file name\nSCRIPTDIR=$(cd `dirname $0` pwd)\ndiagnose_name=\nif [ $# -ne 0 ]; then\n   basket=$1\n   diagnose_name=$1\nelse\n   basket=netlog.$$\nfi\n\n# collect all the network info in one place\nmkdir -p /tmp/$basket\ncat << EOF > /tmp/script2overview\n#!/bin/bash\n# generate the body overview part diagnostic package about network\necho \"==========================================================\"\nfor f in \\$(ls  /etc/sysconfig/network-scripts/ifcfg-*|gawk '{printf(\" %s\",\\$1)}'); do\n   echo\n   echo \\$f\n   cat \\$f\ndone\necho \necho \"==========================================================\"\necho ifconfig\nifconfig\necho\necho \"==========================================================\"\necho ip addr\nip addr\necho\necho \"==========================================================\"\necho \"brctl show\"\nbrctl show\necho\necho \"==========================================================\"\necho \"/etc/resolv.conf\"\ncat /etc/resolv.conf\necho\necho \"==========================================================\"\necho \"cat /etc/iiab/iiab.ini\"\ncat /etc/iiab/iiab.ini\necho\necho \"==========================================================\"\necho \"routing table\"\nnetstat -rn\necho\necho \"==========================================================\"\necho \"install log -- last 50 lines\"\ntail -50 /opt/schoolserver/iiab/iiab-install.log\necho\necho \"==========================================================\"\necho \"iiab-network log -- last 50 lines\"\nif [ -f /opt/schoolserver/iiab/iiab-network.log ]; then\ntail -50 /opt/schoolserver/iiab/iiab-network.log\nelse \n  echo no iiab-network.log\nfi\necho\necho \"==========================================================\"\ncat /etc/fedora-release | grep 18\nif [ \\$? -eq 0 ]; then\n  echo \"nmcli conn list\"\n  nmcli conn list 3>&2\nelse\n  echo \"nmcli conn show\"\n  nmcli conn show 3>&2\nfi\necho\necho \"==========================================================\"\necho nmcli dev wifi list\nnmcli dev wifi list\nEOF\nchmod 755 /tmp/script2overview\n/tmp/script2overview > /tmp/$basket/overview\n\nif [ -f /opt/schoolserver/iiab/iiab-network.log ]; then\n   cp /opt/schoolserver/iiab/iiab-network.log /tmp/$basket\nelse\n  touch /tmp/$basket/no_iiab-network.log\nfi\n\nif [ -f /etc/sysconfig/iiab_domain_name ];then\n  cp -p /etc/sysconfig/iiab_domain_name /tmp/$basket\nelse \n  touch /tmp/$basket/iiab_domain_name_not_set\nfi\n\nif [ -f /etc/sysconfig/iiab_lan_device ];then\n  cp -p /etc/sysconfig/iiab_lan_device  /tmp/$basket\nelse \n  touch /tmp/$basket/iiab_lan_device_not_set\nfi\nif [ -f /etc/sysconfig/iiab_wan_device ];then\n  cp -p /etc/sysconfig/iiab_wan_device  /tmp/$basket\nelse \n  touch /tmp/$basket/iiab_wan_device_not_set\nfi\nls /etc/NetworkManager/system-connections > /dev/null\nif [ $? -eq 0  ]; then\n  cp -rp /etc/NetworkManager/system-connections /tmp/$basket\nfi\ncp /etc/sysconfig/network-scripts/ifcfg-* /tmp/$basket\nif [ -f /opt/schoolserver/iiab/iiab-network.log ]; then\n  cp -p /opt/schoolserver/iiab/iiab-network.log /tmp/$basket\nfi\n\nmkdir -p /etc/iiab/diagnose/\nif [ ! -z $diagnose_name ];then\n  pushd /tmp > /dev/null\n  tar czf /etc/iiab/diagnose/$basket.tgz $basket/*\n  popd > /dev/null\n  rm -rf /tmp/$basket\n  exit 0\nelse\n  pushd /tmp > /dev/null\n  tar czf  /etc/iiab/diagnose/$basket.tgz $basket/*\n  popd > /dev/null\n  rm -rf /tmp/$basket\nfi\n\n# clear out all the memory variables and let auto-configure start from scratch\nrm -rf /etc/sysconfig/iiab_domain_name\nrm -rf /etc/sysconfig/iiab_lan_device\nrm -rf /etc/sysconfig/iiab_wan_device\nrm -rf /etc/NetworkManager/system-connestions/*\nif [ -f /etc/sysconfig/network-scripts/ifcfg-WAN ];then\n  mv /etc/sysconfig/network-scripts/ifcfg-WAN /root\n  echo -e \"\\n\\nWAN setup file moved to /root for safekeeping.\\n\\n\"\nfi\n\nls -1 /etc/sysconfig/network-scripts/ifcfg-*|grep -v -e ifcfg-lo\nif [ $? -eq 0 ]; then\n  ls -1 /etc/sysconfig/network-scripts/ifcfg-*|grep -v -e ifcfg-lo|xargs rm\nfi\n\necho -e \"\\n\\nAll Network variables erased. Now run 'iiab-network' to set up the new network configuration.\\n\\nPlease see /opt/schoolserver/iiab/docs/GETTING_HELP.rst for ways to get help or \\nprovide the feedback which will improve XSCE\\n\\n\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "e060cb91ad0c91b21a1d53566a2cdc8dfce0daa3", "filename": "playbooks/provision-idm-server/setup-idm-dns.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: idm-server\n  tasks:\n  - name: Set required ip address for forward dns\n    set_fact:\n      dns_records: \"{{ dns_records|combine({\n        'view': inventory_hostname.split('.')[1:-1],\n        'forward': { 'ip': openstack.private_v4,\n                      'hostname': inventory_hostname.split('.')[0]  },\n        'reverse': { 'hostname': openstack.private_v4.split('.')[-1],\n                      'target': inventory_hostname + '.'  }\n      }, recursive=True) }}\"\n    when:\n    - hosting_infrastructure == 'openstack'\n\n- name: 'Copying dns_records from idm-server hosts'\n  hosts: dns-server\n  tasks:\n   - set_fact:\n       dns_records: \"{{ hostvars[groups['idm-server'][0]]['dns_records'] }}\"\n\n- name: Add DNS records for IdM'\n  import_playbook: ../update-dns-records.yml\n  vars:\n    dns_records_add:\n    - view: \"{{ dns_records.view }}\"\n      zone: \"{{ dns_records.reverse.zone }}\"\n      server: \"{{ dns_records.server }}\"\n      key_name: \"{{ dns_records.reverse.key_name }}\"\n      key_secret: \"{{ dns_records.reverse.key_secret }}\"\n      key_algorithm: \"{{ dns_records.reverse.key_algorithm }}\"\n      entries:\n      - type: ptr\n        hostname: \"{{ dns_records.reverse.hostname }}\"\n        ip: \"{{ dns_records.reverse.target }}\"\n    - view: \"{{ dns_records.view }}\"\n      zone: \"{{ dns_records.forward.zone }}\"\n      server: \"{{ dns_records.server }}\"\n      key_name: \"{{ dns_records.forward.key_name }}\"\n      key_secret: \"{{ dns_records.forward.key_secret }}\"\n      key_algorithm: \"{{ dns_records.forward.key_algorithm }}\"\n      entries:\n      - type: A\n        hostname: \"{{ dns_records.forward.hostname }}\"\n        ip: \"{{ dns_records.forward.ip }}\"\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "01177eb87af23951286b19a0661e9b61c4076da7", "filename": "archive/roles/openstack-create/defaults/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\ndefault_security_groups:\n  - name: default\n    rules: []\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "d3d505f435591c7536f5d556a6453a869ebe0112", "filename": "roles/keepalived/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'reload sysctl'\n  command: sysctl -p\n\n\n- name: 'start and enable keepalived services'\n  service:\n    name: '{{ item }}'\n    enabled: yes\n    state: started\n  with_items:\n  - keepalived\n\n\n- name: 'restart keepalived'\n  service:\n    name: keepalived \n    state: restarted\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "4c6fd9823d4bae389d666e42faf19e2cd9ce7ed4", "filename": "roles/config-nagios-target/tasks/nrpe_dns.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Copy in additional Nagios service plugin\n  copy: \n    src: plugins/check_service.sh\n    dest: /usr/lib64/nagios/plugins/check_service.sh\n    owner: root\n    group: root\n    mode: 0755\n\n- name: Copy nrpe.d DNS configuration files\n  copy: \n    src: nrpe.d/check_dns.cfg\n    dest: /etc/nrpe.d/check_dns.cfg\n    owner: root\n    group: root\n    mode: 0644\n\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "eefb0252fa3ec9126fc00e8643fcd17b12de0395", "filename": "tasks/create_repo_raw_proxy_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_raw_proxy\n    args: \"{{ _nexus_repos_raw_defaults|combine(item) }}\""}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "95c14449a0b084e8cdc4f8469901171b8b244d74", "filename": "roles/prometheus/defaults/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# defaults file for prometheus\nprometheus_consul_host: \"{{ ansible_ssh_host }}\"\nprometheus_config_dir: /etc/prometheus\nprometheus_node_exporter_image: \"prom/node-exporter:latest\"\nprometheus_node_exporter_port: 9100\nprometheus_node_exporter_hostname: \"{{ ansible_ssh_host }}\"\nprometheus_node_exporter_consul_service_id: \"{{ ansible_hostname }}:node-exporter:9100\"\nprometheus_consul_dir: /etc/consul.d\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "0b70c48b3627400d00a304f86ddec6fa82686d6e", "filename": "playbooks/roles/check_subscription/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "\n\n- set_fact:\n    newline: \"\\n\"\n- copy:\n    content: \"{{ repos | sort | join('\\n') }}\\n\"\n    dest: /tmp/stc-repos-should-enabled\n\n- shell: \"subscription-manager repos --list-enabled | grep 'Repo ID'  | cut -f2 -d':' | tr -d ' ' | sort > /tmp/stc-repos-enabled\"\n  args:\n    creates: /tmp/stc-repos-enabled\n\n- shell: \"diff -Nuar /tmp/stc-repos-should-enabled /tmp/stc-repos-enabled\"\n  ignore_errors: true\n  register: ret\n\n\n- assert:\n    that:\n      - \"ret.rc == 0\"\n    msg: \n      - \"Please check enabled repositories\"\n      - \"{{ ret.stdout_lines }}\"\n\n- name: Cleanup tmp files\n  file:\n    state: absent\n    path: \"{{ item }}\"\n  with_items: \n  - /tmp/stc-repos-should-enabled\n  - /tmp/stc-repos-enabled\n  tags:\n  - cleanup\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "898a212d5cd409fa8ae32f5dc4686433489ad442", "filename": "roles/rachel/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Create various directories for rachel\n  file: path={{ item }}\n        owner=root\n        group=root\n        mode=0755\n        state=directory\n  with_items:\n    - /library/rachel\n\n- name: See if rachel content is installed\n  stat: path=\"{{ rachel_content_path }}/index.php\"\n  register: rachel_content\n\n- name: Set rachel_content_found to False\n  set_fact:\n     rachel_content_found: False\n\n- name: Set rachel_content_found True if found\n  set_fact:\n     rachel_content_found: True\n  when: rachel_content.stat.exists  == true\n\n- include: rachel_enabled.yml\n  when: rachel_enabled and rachel_content_found\n\n- name: Add rachel to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=rachel\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: rachel\n    - option: description\n      value: '\"Educational resources, packaged together for download and distribution in places without internet.\"'\n    - option: rachel_content_path\n      value: \"{{ rachel_content_path }}\"\n    - option: rachel_version\n      value: \"{{ rachel_version }}\"\n    - option: rachel_mysqldb_path\n      value: \"{{ rachel_mysqldb_path }}\"\n    - option: rachel_src_url\n      value: \"{{ rachel_src_url }}\"\n    - option: content_found\n      value: \"{{ rachel_content_found }}\"\n    - option: enabled\n      value: \"{{ rachel_enabled }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "dd474444a5e86cb448db1083c0e4cbf3443d29e8", "filename": "roles/config-packages/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Test installing additional packages\"\n  hosts: all\n  roles:\n    - role: config-packages \n"}, {"commit_sha": "d25113e8fab871b2ead95ca976c5a43e4759ea26", "sha": "66a7653efc2716d16f7ffadf146f4307e96707ea", "filename": "tasks/main.yml", "repository": "UnderGreen/ansible-role-mongodb", "decoded_content": "---\n\n- include: install.deb.yml\n  when: ansible_os_family == 'Debian'\n\n- include: configure.yml\n\n- include: replication.yml\n  when: mongodb_conf_replSet != \"\"\n\n- include: mms-agent.yml\n  when: mongodb_mms_api_key != \"\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "50f50dd1028ae2963d937181d035889b81f34889", "filename": "roles/owncloud/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "owncloud_install: True\nowncloud_enabled: False\n\nowncloud_url: /owncloud\nowncloud_prefix: /opt\nowncloud_data_dir: /library/owncloud/data\nowncloud_dl_url: https://download.owncloud.org/community/\nowncloud_src_file: owncloud-9.0.2.tar.bz2\n\n# we install on mysql with these setting or those from default_vars, etc.\nowncloud_dbname: owncloud\nowncloud_dbhost: localhost\nowncloud_dbuser: owncloud\nowncloud_dbpassword: owncloudmysql\n\nowncloud_admin_user: 'Admin'\nowncloud_admin_password: 'changeme'\n\nowncloud_required_ip: 10.0.0.0/8 192.168.0.0/16\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "5ec38c87169ed86a33739bfb54c1c3375e0843c5", "filename": "roles/nfs-server/tasks/shares.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Set share basedir\"\n  set_fact:\n    nfs_share_basedir: \"{{ nfs_share_basedir | default(default_nfs_share_basedir) }}\"\n\n- name: \"Create directories\"\n  file:\n    path: \"{{ nfs_share_basedir }}/{{ item.name }}\"\n    state: directory \n    owner: \"{{ item.nfs_owner | default(default_nfs_owner) }}\" \n    group: \"{{ item.nfs_group | default(default_nfs_group) }}\"\n    mode: \"{{ item.nfs_mode | default(default_nfs_mode) }}\"\n  with_items: \n  - \"{{ nfs_shares }}\"\n\n- name: \"Update export file to share out the directory\"\n  lineinfile: \n    path: /etc/exports\n    state: present\n    regexp: \"^{{ nfs_share_basedir }}/{{ item.name }}\"\n    line: \"{{ nfs_share_basedir }}/{{ item.name }} *({{ item.nfs_share_options | default(default_nfs_share_options) }})\" \n  with_items: \n  - \"{{ nfs_shares }}\"\n  notify: Reload NFS\n\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "2a4250a497171ff4a679b56974ca9540ed5a7fdb", "filename": "roles/config-pxe/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ntftpserver_root_dir: \"/var/lib/tftpboot\"\n\ndefault_pxe_menu_title: \"PXE Boot Menu\"\ndefault_pxe_timeout: 300\n"}, {"commit_sha": "af1b4f6c5adde980e027a8b8f38684b11ffbfa19", "sha": "22a1981111164ae677efd9044aa8b4323a160625", "filename": "tasks/main.yml", "repository": "cytopia/ansible-role-cloudformation", "decoded_content": "---\n\n###\n### assert default variables\n###\n- include_tasks: asserts.yml\n\n\n###\n### Prepare jinja2 template render environment\n###\n- name: ensure previous build directory is removed\n  file:\n    state: absent\n    path: \"{{ cloudformation_build_dir_path }}\"\n  changed_when: False\n  check_mode: False\n  when: cloudformation_clean_build_env\n\n- name: ensure build directory is present\n  file:\n    state: directory\n    path: \"{{ cloudformation_build_dir_path }}\"\n    mode: \"{{ cloudformation_build_dir_mode }}\"\n  changed_when: False\n  check_mode: False\n\n\n###\n### Call in a loop for easier usage\n###\n- include_tasks: run.yml\n  vars:\n    cloudformation: \"{{ item }}\"\n  with_items:\n    - \"{{ cloudformation_stacks }}\"\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "4a7334a8a8ca21a84006ec856cf39729b6a7164e", "filename": "roles/dns/manage-dns-zones/tasks/prereq.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Fail when required items are not defined\"\n  fail:\n    msg: \"view name and zones must be defined for each dictionary record\"\n  when:\n    - (item.name is not defined) or (item.zones is not defined)\n  with_items:\n    - \"{{ dns_data.views | default({}) }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "00171b95063e622f201eddb340d6c58f57791ac1", "filename": "roles/config-software-src/tasks/prep.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Install required packages'\n  package:\n    name: '{{ item }}'\n    state: installed\n  with_items:\n  - nfs-utils\n\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "a781dc00c4a86e72c8da531b979ae9a3ccbd0bf0", "filename": "roles/ovirt-common/meta/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\ngalaxy_info:\n  author: \"Petr Kubica\"\n  description: \"oVirt common stuff\"\n  company: \"Red Hat\"\n  license: \"GPLv3\"\n  min_ansible_version: 1.9\n  platforms:\n  - name: EL\n    versions:\n    - all\n  galaxy_tags:\n    - installer\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "e8bec03f75f0487404fbfea02a0dcffb4355050e", "filename": "archive/roles/cicd/tasks/nexus.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n  \n- name: Download Nexus Artifact\n  get_url:\n    url: \"{{ nexus_url }}\"\n    dest: \"{{ nexus_local_archive }}\"\n  tags: nexus\n \n- name: Create Nexus User\n  user:\n    name: \"{{ nexus_user }}\"\n    shell: \"/bin/bash\"\n    home: \"{{ nexus_home_dir }}\"\n    createhome: no\n    state: present\n  tags: nexus\n \n- name: Extract Nexus Artifact\n  unarchive: \n    src: \"{{ nexus_local_archive }}\"\n    dest: \"{{ nexus_base_dir }}\"\n    copy: no\n    creates: \"{{ nexus_install_dir }}\"\n    group: \"{{ nexus_group }}\"\n    owner: \"{{ nexus_user }}\"\n  tags: nexus\n\n- name: Create Nexus Symbolic Link\n  file:\n    src: \"{{ nexus_install_dir }}\"\n    dest: \"{{ nexus_home_dir }}\"\n    state: link \n    group: \"{{ nexus_group }}\"\n    owner: \"{{ nexus_user }}\"\n  tags: nexus\n\n- name: Add NEXUS_HOME Variable\n  lineinfile: \n    dest: /etc/profile\n    regexp: \"^export NEXUS_HOME=/usr/local/nexus-{{nexus_version}}\"\n    line: \"export NEXUS_HOME=/usr/local/nexus-{{nexus_version}}\"\n  tags: nexus\n  \n- name: Create Nexus PID Directory\n  file: \n    path: \"{{nexus_pid_dir}}\"\n    state: directory\n    group: \"{{ nexus_group }}\"\n    owner: \"{{ nexus_user }}\"\n  tags: nexus\n  \n- name: Create Nexus Work Configuration Directory\n  file: \n    path: \"{{nexus_sonatype_work_dir}}/nexus/conf\"\n    state: directory\n    group: \"{{ nexus_group }}\"\n    owner: \"{{ nexus_user }}\"\n  tags: nexus\n  \n- name: Copy Work Nexus Configuration File\n  copy: \n    src: nexus/nexus.xml\n    dest: \"{{nexus_sonatype_work_dir}}/nexus/conf/\"\n    group: \"{{ nexus_group }}\"\n    owner: \"{{ nexus_user }}\"\n  notify:\n  - restart nexus\n  tags: nexus\n  \n- name: Custom Nexus Configuration File Settings\n  lineinfile:\n    dest: \"{{ nexus_home_dir }}/bin/nexus\"\n    regexp: \"{{ item.regex }}\"\n    line: \"{{ item.replace }}\"\n    backup: yes\n    state: present\n  with_items:\n  - { regex: \"^NEXUS_HOME=\\\"..\\\"\", replace: \"NEXUS_HOME=\\\"{{ nexus_home_dir }}\\\"\" }\n  - { regex: \"^#PIDDIR=\\\".\\\"\", replace: \"PIDDIR=\\\"{{ nexus_home_dir }}/bin/jsw/linux-x86-64\\\"\" }\n  - { regex: \"^#RUN_AS_USER=\", replace: \"RUN_AS_USER=\\\"{{ nexus_user }}\\\"\" }\n  notify:\n  - restart nexus\n  tags: nexus\n  \n- name: Copy Nexus Service File\n  copy: \n    src: nexus/nexus.service\n    dest: /etc/systemd/system/\n    mode: 0664\n  notify:\n  - reload systemd\n  - restart nexus\n  tags: nexus\n  \n- name: Open Firewall for Nexus\n  firewalld:\n    port: 8081/tcp\n    zone: public\n    permanent: yes\n    immediate: yes\n    state: enabled\n  tags: nexus\n  \n- name: Enable Nexus Service\n  service: \n    name: nexus\n    enabled: true\n  tags: nexus\n  \n  \n# TODO: Need to handle custom configurations"}, {"commit_sha": "b7c6bfe0369646ca69beeb3dfe07e8218d61c940", "sha": "b047873760b561295f304ec80c45e415a1aa92ee", "filename": "tasks/limits.yml", "repository": "dev-sec/ansible-os-hardening", "decoded_content": "---\n\n- block:\n  - name: create limits.d-directory if it does not exist | sysctl-31a, sysctl-31b\n    file:\n      path: '/etc/security/limits.d'\n      owner: 'root'\n      group: 'root'\n      mode: '0755'\n      state: 'directory'\n      \n  - name: create aditional limits config file -> 10.hardcore.conf | sysctl-31a, sysctl-31b\n    pam_limits:\n      dest: '/etc/security/limits.d/10.hardcore.conf'\n      domain: '*'\n      limit_type: hard\n      limit_item: core\n      value: 0\n      comment: Prevent core dumps for all users. These are usually only needed by developers and may contain sensitive information\n      \n  - name: set 10.hardcore.conf perms to 0400 and root ownership\n    file:\n      path: /etc/security/limits.d/10.hardcore.conf\n      owner: 'root'\n      group: 'root'\n      mode: '0440'\n  \n  when: 'not os_security_kernel_enable_core_dump'\n\n- name: remove 10.hardcore.conf config file\n  file:\n    path: /etc/security/limits.d/10.hardcore.conf\n    state: absent\n\n  when: 'os_security_kernel_enable_core_dump'\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "5324bc6f77a4658001ccfa2836fb18464eb28b78", "filename": "roles/haproxy/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'enable and start service(s)'\n  service:\n    name: '{{ item }}'\n    enabled: yes\n    state: started\n  with_items:\n  - haproxy\n\n- name: 'restart rsyslog'\n  service:\n    name: rsyslog\n    state: restarted\n\n- name: 'reload haproxy'\n  service: \n    name: haproxy\n    state: reloaded \n\n- name: 'remove tmp new file'\n  file:\n    path: '{{ temp_new_file }}'\n    state: absent\n\n    \n\n"}, {"commit_sha": "0af3e85a918252d0349ba15721cbedc1e3d80ff1", "sha": "a0cc39437b316cc81478a2a75bd57f7cebc40bdc", "filename": "tasks/nvm.yml", "repository": "fubarhouse/ansible-role-nodejs", "decoded_content": "---\n# Tasks file for NVM\n\n- name: \"NVM | Clean-up\"\n  become: yes\n  become_user: \"root\"\n  file:\n    path: \"{{ fubarhouse_npm.nvm_install_dir }}\"\n    state: absent\n  when: fubarhouse_npm.clean_install\n\n- name: NVM | Clean-up default version from shell profiles\n  become: yes\n  become_user: \"root\"\n  lineinfile:\n    dest: \"{{ fubarhouse_npm.user_dir }}/{{ item.filename }}\"\n    regexp: '.nvm/v{{ node_version }}/bin'\n    line:  'export PATH=$PATH:{{ fubarhouse_npm.user_dir }}/.nvm/v{{ node_version }}/bin;'\n    state: absent\n  with_items:\n    - \"{{ fubarhouse_npm.shell_profiles }}\"\n  ignore_errors: yes\n  when: fubarhouse_npm.clean_install\n\n- name: NVM | Clean-up other versions from shell profiles\n  become: yes\n  become_user: \"root\"\n  lineinfile:\n    dest: \"{{ fubarhouse_npm.user_dir }}/{{ item[0].filename }}\"\n    regexp: '.nvm/v{{ item[1] }}/bin'\n    line:  'export PATH=$PATH:{{ fubarhouse_npm.user_dir }}/.nvm/v{{ item[1] }}/bin;'\n    state: absent\n  with_nested:\n    - \"{{ fubarhouse_npm.shell_profiles }}\"\n    - \"{{ node_versions }}\"\n  ignore_errors: yes\n  when: fubarhouse_npm.clean_install\n\n- name: \"NodeJS | Remove imported exports not associated to specific versions\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  lineinfile:\n    dest: \"{{ fubarhouse_npm.user_dir }}/{{ item.filename }}\"\n    line: \"export PATH=$PATH:$(npm config --global get prefix)/bin\"\n    state: absent\n  with_items: \"{{ fubarhouse_npm.shell_profiles }}\"\n  when: fubarhouse_npm.clean_install\n\n- name: \"NVM | Check\"\n  stat:\n    path: \"{{ fubarhouse_npm.nvm_install_dir }}\"\n  register: fubarhouse_npm_nvm_installed\n\n- name: \"NVM | Ensure permissions are set\"\n  become: yes\n  become_user: \"root\"\n  file:\n    path: \"{{ item.path }}\"\n    state: directory\n    mode: 0777\n    owner: \"{{ fubarhouse_user }}\"\n    recurse: yes\n  with_items: \"{{ fubarhouse_npm.folder_paths }}\"\n  changed_when: false\n\n- name: \"NVM | Clone/Update\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  git:\n    repo: \"{{ fubarhouse_npm.nvm_repo }}\"\n    dest: \"{{ fubarhouse_npm.nvm_install_dir }}\"\n    clone: yes\n    update: yes\n    force: yes\n    version: master\n    recursive: false\n  changed_when: false\n\n- name: \"NVM | Install\"\n  shell: \"{{ fubarhouse_npm.nvm_install_dir }}/install.sh\"\n  when: fubarhouse_npm_nvm_installed.stat.exists == false\n\n- name: \"NVM | Create an executable\"\n  template:\n    src: \"nvm.sh\"\n    dest: \"{{ fubarhouse_npm.nvm_symlink_exec }}\"\n    owner: \"{{ fubarhouse_user }}\"\n    mode: 0755\n  when: fubarhouse_npm_nvm_installed.stat.exists == false\n\n- name: \"NVM | Get versions\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  shell: \"{{ fubarhouse_npm.nvm_symlink_exec }} ls-remote\"\n  register: nodejs_available_versions\n  changed_when: false\n\n- name: NVM | Ensure shell profiles are available\n  become: yes\n  become_user: \"root\"\n  file:\n    path: \"{{ fubarhouse_npm.user_dir }}/{{ item.filename }}\"\n    state: touch\n  with_items: \"{{ fubarhouse_npm.shell_profiles }}\"\n  ignore_errors: yes\n  changed_when: false\n\n- name: NVM | Ensure shell profiles are configured for default version\n  become: yes\n  become_user: \"root\"\n  lineinfile:\n    dest: \"{{ fubarhouse_npm.user_dir }}/{{ item.filename }}\"\n    regexp: '.nvm/v{{ node_version }}/bin'\n    line:  'export PATH=$PATH:{{ fubarhouse_npm.user_dir }}/.nvm/v{{ node_version }}/bin;'\n    state: present\n  with_items:\n    - \"{{ fubarhouse_npm.shell_profiles }}\"\n  when: '\"{{ node_version }}\" in nodejs_available_versions.stdout'\n  ignore_errors: yes\n\n- name: NVM | Ensure shell profiles are configured for other versions\n  become: yes\n  become_user: \"root\"\n  lineinfile:\n    dest: \"{{ fubarhouse_npm.user_dir }}/{{ item[0].filename }}\"\n    regexp: '.nvm/v{{ item[1] }}/bin'\n    line:  'export PATH=$PATH:{{ fubarhouse_npm.user_dir }}/.nvm/v{{ item[1] }}/bin;'\n    state: present\n  when: '\"{{ item[1] }}\" in nodejs_available_versions.stdout'\n  with_nested:\n    - \"{{ fubarhouse_npm.shell_profiles }}\"\n    - \"{{ node_versions }}\"\n  ignore_errors: yes"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "0a2a50d5817af9d50549627d500588c3c0edd5b0", "filename": "roles/config-idm-server/vars/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n# vars file for idm"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "8029ab5e9866df11da0273c7ec25a434be659096", "filename": "tasks/unit/setup-debian.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: Debian/Ubuntu) Add NGINX Unit Repository\"\n  apt_repository:\n    repo: \"{{ item }}\"\n  with_items:\n    - deb https://packages.nginx.org/unit/{{ ansible_distribution|lower }}/ {{ ansible_distribution_release }} unit\n    - deb-src https://packages.nginx.org/unit/{{ ansible_distribution|lower }}/ {{ ansible_distribution_release }} unit\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "61cb9e578478b8283a214846577e5410078334c6", "filename": "roles/marathon/defaults/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# defaults file for marathon\nmarathon_consul_dir: /etc/consul.d\nmarathon_enabled: true\nmarathon_version: '0.11.1'\nmarathon_restart_policy: 'always'\nmarathon_net: 'host'\nmarathon_hostname: \"{{ ansible_ssh_host }}\"\nmarathon_port: '8080'\nmarathon_container_memory_limit: '512MB'\nmarathon_java_settings: '-Xmx512m -Xms512m -XX:+HeapDumpOnOutOfMemoryError'\nmarathon_artifact_store: 'file:///store'\nmarathon_artifact_store_dir: '/etc/marathon/store'\nmarathon_server_zk_group: marathon_servers\nmarathon_rebuild_container: False\nmarathon_image: \"mesosphere/marathon:v{{ marathon_version }}\"\nmarathon_master_peers: \"zk://{{ zookeeper_peers_nodes }}/mesos\"\nmarathon_zk_peers: \"zk://{{ zookeeper_peers_nodes }}/marathon\"\nmarathon_command: \"--artifact_store {{ marathon_artifact_store }} --hostname {{ marathon_hostname }} --master {{ marathon_master_peers }} --zk {{ marathon_zk_peers }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "56cea8a4e705e4dc7171672c1282bd1edeca7453", "filename": "roles/config-chrony/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- hosts: ntp_servers\n  roles:\n  - config-chrony\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "853c0c7c401eeefbaa6ead895d4bda21af863bcd", "filename": "roles/config-routes/tasks/prereq.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Include prereqs per the type of OS\"\n  include_tasks: \"{{ distro_file }}\"\n  with_first_found:\n  - files:\n    - prereq-{{ ansible_distribution }}.yml\n    skip: true\n  loop_control:\n    loop_var: distro_file\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "ce546dfe9a1c210cc89af97be328b3e07e29c1f8", "filename": "roles/9-local-addons/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Addon services installed\n  command: echo Addon services installed\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "82910c7c8e19761ae01ad9eb0a30c3d709b83862", "filename": "roles/kalite/tasks/install-f18.yml", "repository": "iiab/iiab", "decoded_content": "# This is for Fedora 18, assumed to be an XO\n\n- name: Install dependent packages F18\n  package: name={{ item }}\n           state=present\n  with_items:\n    - python-psutil\n    - expect\n  when: is_F18\n\n- name: Install dependent pip packages F18\n  pip: name=selenium\n  when: internet_available  and is_F18\n\n- name: Determine if kalite is already downloaded\n  stat: path={{ downloads_dir }}/ka-lite\n  register: kalite\n\n- name: Download the latest kalite repo\n  git: repo={{ kalite_repo_url }}\n       dest={{ downloads_dir }}/ka-lite\n       depth=1\n       version=\"0.13.x\"\n  ignore_errors: yes\n  when: internet_available  and kalite.stat.exists is defined and not kalite.stat.exists\n\n- name: Create iiab-kalite user and password F18\n  user: name={{ kalite_user }}\n        password={{ kalite_password_hash }}\n        update_password=on_create\n\n- name: Create kalite_root directory F18\n  file: path={{ kalite_root }}\n        owner=root\n        group=root\n        mode=0755\n        state=directory\n\n- name: Copy the kalite repo into place F18\n  command: \"rsync -at {{ downloads_dir }}/ka-lite/ {{ kalite_root }}\"\n\n- name: Make kalite_user owner\n  file: path={{ kalite_root }}\n        owner={{ kalite_user }}\n        group={{ kalite_user }}\n        recurse=yes\n        state=directory\n\n# local_settings is deprecated\n- name: Copy local_settings file\n  template: src=f18/local_settings.py.j2\n            dest=\"{{ kalite_root }}/kalite/local_settings.py\"\n            owner={{ kalite_user }}\n            group={{ kalite_user }}\n            mode=0644\n\n- name: Create kalite service(s) and support scripts\n  template: backup=no\n            src={{ item.src }}\n            dest={{ item.dest }}\n            owner=root\n            group=root\n            mode={{ item.mode }}\n  with_items:\n    - { src: 'f18/kalite-serve.service.j2', dest: '/etc/systemd/system/kalite-serve.service', mode: '0644'}\n    - { src: 'f18/kalite-cron.service.j2', dest: '/etc/systemd/system/kalite-cron.service', mode: '0644'}\n    - { src: 'f18/iiab_cronservectl.sh.j2', dest: '{{ kalite_root }}/scripts/iiab_cronservectl.sh', mode: '0755'}\n"}, {"commit_sha": "2a05a5032ce341d6a1d918453164c59ea2922f58", "sha": "c9d81d1fab981d9c49877720c53700b29d5c727e", "filename": "roles/network_interface/meta/main.yml", "repository": "CSCfi/fgci-ansible", "decoded_content": "---\ngalaxy_info:\n  author: \"Benno Joy\"\n  company: AnsibleWorks\n  license: BSD\n  min_ansible_version: 1.4 \n  platforms:\n   - name: EL\n     versions:\n      - 5\n      - 6\n   - name: Fedora\n     versions:\n      - 16\n      - 17\n      - 18\n   - name: Ubuntu\n     versions:\n      - precise\n      - quantal\n      - raring\n      - saucy\n  categories:\n    - networking\n    - system\ndependencies: []\n  \n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "6e9cf96cc9e99c25feb99533f5b13f1cb07adfe5", "filename": "roles/docker/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Install docker\n  package:  name={{ item }} \n            state=present\n  with_items:\n    - docker\n    - python-docker-py\n  when: docker_install\n  tags: download\n\n- name: put the systemd startup file in place\n  template: src=docker.service\n            dest=/etc/systemd/system/\n            owner=root\n            group=root\n            mode=0644\n\n- name: create the socket for docker\n  template: src=docker.socket\n            dest=/etc/systemd/system/\n            owner=root\n            group=root\n            mode=0644\n\n- name: Create a folder for systemd unit files that are docker containers\n  file: path=/etc/systemd/system/docker.service.d\n        owner=root\n        group=root\n        mode=0644\n        state=directory\n\n- name: Enable docker\n  service: name=docker\n           state=started\n           enabled=true\n  when: docker_enabled\n\n- name: Disable docker\n  service: name=docker\n           state=stopped\n           enabled=false\n  when: not docker_enabled\n\n- name: add docker to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=docker\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: Docker Container\n    - option: description\n      value: '\"Docker allows a person to package an application with all of its dependencies into a standardized unit for software development.\"'\n    - option: enabled\n      value: \"{{ docker_enabled }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "6536e7da54db81eff12c527d1c67cddc4ea19fd5", "filename": "roles/nextcloud/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "# we need to install the rpm in order to get the dependencies\n# but we only need to do this the first time\n\n- name: See if the nextcloud startup page exists\n  stat: path={{ nextcloud_prefix }}/nextcloud/index.php\n  register: nextcloud_page\n\n\n# but we use the tar file to get the latest version\n\n- name: Get the nextcloud software\n  get_url: url={{ nextcloud_dl_url }}/{{ nextcloud_src_file }}  dest={{ downloads_dir }}/{{ nextcloud_src_file }}\n  when: internet_available\n  async: 900\n  poll: 15\n  tags:\n    - download\n\n- name: ubuntu and debian treat names differently\n  package: name={{ item }} state=present\n  with_items:\n    - libapache2-mod-php{{ php_version }}\n    - php{{ php_version }}-mbstring\n    - php{{ php_version }}-zip\n  when: is_debian\n\n- name: ubuntu and debian treat names differently\n  package: name={{ item }} state=present\n  with_items:\n    - libapache2-mod-php\n    - php-imagick\n    - php-zip\n    - php-mbstring\n  when: is_ubuntu\n\n- name: Install list of packages for debuntu\n  package: name={{ item }} state=present\n  with_items:\n    - php{{ php_version }}-gd\n    - php{{ php_version }}-json\n    - php{{ php_version }}-mysql\n    - php{{ php_version }}-curl\n    - php{{ php_version }}-intl\n    - php{{ php_version }}-mcrypt\n  when: is_debuntu\n\n- name: Install list of packages\n  package: name={{ item }} state=present\n  with_items:\n    - php\n    - php-gd\n    - php-json\n    - php-mysql\n    - php-curl\n    - php-intl\n    - php-mcrypt\n# centos does not have a package for php-imagick\n#    - php-imagick\n  when: is_redhat\n\n- name: Copy it to permanent location /opt\n  unarchive: src={{ downloads_dir }}/{{ nextcloud_src_file }}\n             dest={{ nextcloud_prefix }}\n             creates={{ nextcloud_prefix }}/nextcloud/version.php\n  when: not is_F18\n\n# ansible 1.4.1 does not have \"creates\"\n- name: Copy it to permanent location /opt\n  unarchive: src={{ downloads_dir }}/{{ nextcloud_src_file }}\n             dest={{ nextcloud_prefix }}\n  when: is_F18\n\n- name: in Centos, the following config dir is symlink to /etc/nextcloud\n  file: path=/etc/nextcloud\n        state=directory\n  when: is_centos\n\n- name: Add autoconfig file\n  template: src=autoconfig.php.j2\n            dest={{ nextcloud_prefix }}/nextcloud/config/autoconfig.php\n            owner={{ apache_user }}\n            group={{ apache_user }}\n            mode=0640\n  when: is_centos\n\n- name: Make apache owner\n  file: path={{ nextcloud_prefix }}/nextcloud\n        owner={{ apache_user }}\n        group={{ apache_user }}\n        recurse=yes\n        state=directory\n\n- name: Create data directory library\n  file: path={{ item }}\n        mode=0750\n        owner={{ apache_user }}\n        group={{ apache_user }}\n        state=directory\n  with_items:\n    - \"{{ nextcloud_data_dir }}\"\n\n- name: Create a mysql database for nextcloud\n  mysql_db: name={{ nextcloud_dbname }}\n  when: mysql_enabled and nextcloud_enabled\n\n- name: Create a user to access the nextcloud database\n  mysql_user: name={{ nextcloud_dbuser }} host={{ item }} password={{ nextcloud_dbpassword }} priv={{ nextcloud_dbname }}.*:ALL,GRANT\n  with_items:\n        - \"{{ nextcloud_dbhost }}\"\n        - 127.0.0.1\n        - ::1\n        - localhost\n  when: mysql_enabled and nextcloud_enabled\n\n\n- name: Restart apache, so it picks up the new aliases\n  service: name={{ apache_service }} state=restarted\n  when: not nextcloud_enabled\n\n# Enable nextcloud by copying template to httpd config\n\n# following enables and disables\n- include: nextcloud_enabled.yml\n\n- name: Add nextcloud to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=nextcloud\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: nextcloud\n    - option: description\n      value: '\"NextCloud is a local server-based facility for sharing files, photos, contacts, calendars, etc.\"'\n    - option: path\n      value: \"{{ nextcloud_prefix }}/nextcloud\"\n    - option: source\n      value: \"{{ nextcloud_src_file }}\"\n    - option: enabled\n      value: \"{{ nextcloud_enabled }}\"\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "ea0104c73321d4143b0f8ba4aa66e873c2ed5a61", "filename": "playbooks/templates/elasticsearch.yml.j2", "repository": "rocknsm/rock", "decoded_content": "# ======================== Elasticsearch Configuration =========================\n#\n# NOTE: Elasticsearch comes with reasonable defaults for most settings.\n#       Before you set out to tweak and tune the configuration, make sure you\n#       understand what are you trying to accomplish and the consequences.\n#\n# The primary way of configuring a node is via this file. This template lists\n# the most important settings you may want to configure for a production cluster.\n#\n# Please see the documentation for further information on configuration options:\n# <http://www.elastic.co/guide/en/elasticsearch/reference/current/setup-configuration.html>\n#\n# ---------------------------------- Cluster -----------------------------------\n#\n# Use a descriptive name for your cluster:\n#\ncluster.name: {{ es_cluster_name }}\n#\n# ------------------------------------ Node ------------------------------------\n#\n# Use a descriptive name for the node:\n#\nnode.name: {{ es_node_name }}\n#\n# Add custom attributes to the node:\n#\n# node.rack: r1\n#\n# ----------------------------------- Paths ------------------------------------\n#\n# Path to directory where to store the data (separate multiple locations by comma):\n#\n# path.data: /path/to/data\n#\n# Path to log files:\n#\n# path.logs: /path/to/logs\n#\n# ----------------------------------- Memory -----------------------------------\n#\n# Lock the memory on startup:\n#\nbootstrap.memory_lock: true\n#\n# Make sure that the heap size is set to about half the memory available\n# on the system and that the owner of the process is allowed to use this\n# limit.\n#\n# Elasticsearch performs poorly when the system is swapping the memory.\n#\n# ---------------------------------- Network -----------------------------------\n#\n# Set the bind address to a specific IP (IPv4 or IPv6):\n#\nnetwork.host: _local:ipv4_\n#\n# Set a custom port for HTTP:\n#\n# http.port: 9200\n#\n# For more information, see the documentation at:\n# <http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-network.html>\n#\n# --------------------------------- Discovery ----------------------------------\n#\n# Pass an initial list of hosts to perform discovery when new node is started:\n# The default list of hosts is [\"127.0.0.1\", \"[::1]\"]\n#\n# discovery.zen.ping.unicast.hosts: [\"host1\", \"host2\"]\n#\n# Prevent the \"split brain\" by configuring the majority of nodes (total number of nodes / 2 + 1):\n#\n#\n# For more information, see the documentation at:\n# <http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-discovery.html>\n#\n# ---------------------------------- Gateway -----------------------------------\n#\n# Block initial recovery after a full cluster restart until N nodes are started:\n#\n# gateway.recover_after_nodes: 3\n#\n# For more information, see the documentation at:\n# <http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-gateway.html>\n#\n# ---------------------------------- Various -----------------------------------\n#\n# Disable starting multiple nodes on a single system:\n#\nnode.max_local_storage_nodes: 1\n#\n# Require explicit names when deleting indices:\n#\n# action.destructive_requires_name: true\n"}, {"commit_sha": "f92ebbef856e59bd4563d4b5b69ee75a95ec89d5", "sha": "2cc5ee007c93e8e58c0fde01696f65ee3e7712c0", "filename": "roles/openshift-management/tasks/prune-builds.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- name: Prune Builds\n  shell: oc adm prune builds --keep-complete={{ openshift_prune_builds_complete }}  --keep-failed={{ openshift_prune_builds_failed }} --keep-younger-than={{ openshift_prune_builds_keep_younger }} --orphans --confirm\n  environment:\n    KUBECONFIG: \"{{ kubeconfig }}\""}, {"commit_sha": "9662c15ce2e4260fac5cc2bfdf5aaaaf0a2191dd", "sha": "a8b8d7eed0cbf561621b66cba9f7989b21b2e6ef", "filename": "tasks/section_03_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n#sections 3.3 and 3.4 have to happen before as the latter overwrite 3.1 and 3.2\n\n  - name: 3 Check for /boot/grub/grub.cfg file\n    stat: path=/boot/grub/grub.cfg\n    register: grub_cfg_file\n    tags:\n      - section3\n\n  - name: 3.3.1.1 Set Boot Loader Superuser (check) (Scored)\n    command: grep \"^set superusers\" /boot/grub/grub.cfg\n    register: boot_superusers \n    when: grub_cfg_file.stat.exists == True\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section3\n      - section3.3\n      - section3.3.1\n      - section3.3.1.1\n\n  - name: 3.3.1.2 Set Boot Loader Superuser (Scored)\n    lineinfile: >\n        dest='/etc/grub.d/40_custom'\n        regexp='^set superusers'\n        line='set superusers=\"root\"'\n        state=present\n    when: grub_cfg_file.stat.exists == True and boot_superusers.rc == 1\n    tags:\n      - section3\n      - section3.3\n      - section3.3.1\n      - section3.3.1.2\n    \n  - name: 3.3.2.1 Set Boot Loader Password (check) (Scored)\n    command: grep \"^password\" /boot/grub/grub.cfg\n    register: boot_password\n    when: grub_cfg_file.stat.exists == True\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section3\n      - section3.3\n      - section3.3.2\n      - section3.3.2.1\n\n  - name: 3.3.2.2 Set Boot Loader Password (Scored)\n    lineinfile: >\n        dest='/etc/grub.d/40_custom' \n        regexp='^password'\n        line='password_pbkdf2 root grub.pbkdf2.sha512.10000.529DB4AF052F170948C1DB2A754CEA8A286804DA2D9A4EB5A7CCE4B8636775C83EAF8A1093CBDBC256954BCE789A58EFB3B75D23DFC76583C703922D5DADB69E.4D5BD1EC6736057095CA2EBF55C2DA02DFB0B0784F2105A396F1CEF11FEB1483D5C420F412E2E817E2570DDFC22ABCC329C5FF44091A0ACDE67171FF72E96CFD'\n        state=present\n    when: grub_cfg_file.stat.exists == True and boot_password.rc == 1\n    tags:\n      - section3\n      - section3.3\n      - section3.3.2\n      - section3.3.2.2\n\n  - name: 3.3.3 Disable password protection booting\n    lineinfile: >\n        dest='/etc/grub.d/10_linux'\n        create=yes\n        regexp='^CLASS='\n        line='CLASS=\"--class gnu-linux --class gnu --class os --unrestricted\"'\n        state=present\n    tags:\n      - section3\n      - section3.3\n      - section3.3.3\n\n\n  - name: 3.3.4 Update Grub configuration (Scored)\n    command: update-grub\n    when: grub_cfg_file.stat.exists == True and (boot_superusers.rc == 1 or boot_password.rc == 1)\n    tags:\n      - section3\n      - section3.3\n      - section3.3.4\n\n\n  - name: 3.4.1 Require Authentication for Single-User Mode (check) (Scored)\n    shell: 'grep \"^root:[*\\!]:\" /etc/shadow'\n    register: root_password_set\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section3\n      - section3.4\n      - section3.4.1\n\n  - name: 3.4.2 Require Authentication for Single-User Mode (Scored)\n    user: name=root state=present password={{ root_password }}\n    when: root_password_set.rc == 1\n    tags:\n      - section3\n      - section3.4\n      - section3.4.2\n\n  - name: 3.1 Set User/Group Owner on bootloader config (Scored)\n    file: path=/boot/grub/grub.cfg owner=root group=root\n    when: grub_cfg_file.stat.exists == True\n    tags:\n      - section3\n      - section3.1\n\n  - name: 3.2 Set Permissions on bootloader config (Scored)\n    file: path=/boot/grub/grub.cfg mode=\"o-rwx,g-rwx\"\n    when: grub_cfg_file.stat.exists == True\n    sudo: yes\n    tags:\n      - section3\n      - section3.2\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a5e19beb55bc56f3dfb3b5e75f4805690e2500e1", "filename": "roles/config-nagios-target/tasks/install-nagios.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Installing the Nagios Software Packages\n  package:\n    name=\"{{item}}\"\n    state=present\n  with_items:\n  - nrpe\n  - nagios-plugins*\n  tags: epel\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "e7b870e0a493cbe0c44fc9814afc7459fbda3776", "filename": "roles/virt-install/tasks/virt-install.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Populate values for virt install run\"\n  set_fact:\n    virtinstall_connect: \"{{ hostvars[vm]['libvirt_connect'] | default(default_connect) }}\"\n    virtinstall_virt_type: \"{{ hostvars[vm]['libvirt_virt_type'] | default(default_virt_type) }}\"\n    virtinstall_name: \"{{ hostvars[vm]['libvirt_name'] | default(default_name) }}\"\n    virtinstall_title: \"{{ hostvars[vm]['libvirt_title'] | default(default_title) }}\"\n    virtinstall_description: \"{{ hostvars[vm]['libvirt_description'] | default(default_description) }}\"\n    virtinstall_memory: \"{{ hostvars[vm]['libvirt_memory'] | default(default_memory) }}\"\n    virtinstall_vcpus: \"{{ hostvars[vm]['libvirt_vcpus'] | default(default_vcpus) }}\"\n    virtinstall_disk_size: \"{{ hostvars[vm]['libvirt_disk_size'] | default(default_disk_size) }}\"\n    virtinstall_disk_pool: \"{{ hostvars[vm]['libvirt_disk_pool'] | default(default_disk_pool) }}\"\n    virtinstall_os_variant: \"{{ hostvars[vm]['libvirt_os_variant'] | default(default_os_variant) }}\"\n    virtinstall_iso: \"{{ hostvars[vm]['libvirt_iso'] | default(default_iso) }}\"\n    virtinstall_ksfile: \"{{ hostvars[vm]['libvirt_ksfile'] | default(default_ksfile) }}\"\n    virtinstall_authorized_keys: \"{{ hostvars[vm]['libvirt_authorized_keys'] | default(default_authorized_keys) }}\"\n    virtinstall_http_host: \"{{ hostvars[vm]['libvirt_http_host'] | default(default_http_host) }}\"\n    virtinstall_network_hostif: \"{{ hostvars[vm]['libvirt_network_hostif'] | default(default_network_hostif) }}\"\n    virtinstall_network_model: \"{{ hostvars[vm]['libvirt_network_model'] | default(default_network_model) }}\"\n\n- name: \"Make KS file available on the target host\"\n  copy: \n    src: \"{{ virtinstall_ksfile }}\"\n    dest: \"/tmp/{{ virtinstall_ksfile | basename }}\"\n\n- name: \"Make the authorized_keys file available on the target host\"\n  copy: \n    src: \"{{ virtinstall_authorized_keys }}\"\n    dest: \"{{ default_http_dir }}/{{ virtinstall_authorized_keys | basename }}\"\n  notify: 'Remove authorized_keys'\n\n- name: \"Make a mount point for install purpose\"\n  tempfile:\n    state: directory\n    prefix: install\n    path: \"{{ default_http_dir }}\"\n  register: http_mount\n  when: \n  - mounted_iso[virtinstall_iso] is not defined\n\n- name: \"Mount ISO to serv it up with http\"\n  mount:\n    src: \"{{ virtinstall_iso }}\"\n    path: \"{{ http_mount.path }}\"\n    opts: loop\n    fstype: iso9660\n    state: mounted\n  notify: 'Unmount install ISO'\n  when:\n  - mounted_iso[virtinstall_iso] is not defined\n\n- name: 'Track mounted iso'\n  set_fact: \n    mounted_iso: \"{{ mounted_iso | combine({ virtinstall_iso : http_mount.path }) }}\"\n  when:\n  - mounted_iso[virtinstall_iso] is not defined\n\n- name: \"Set Fact for VM command\"\n  set_fact:\n    virt_install_commands: \"{{ virt_install_commands | default([]) + [ ('virt-install' + ' --connect ' + virtinstall_connect + ' --virt-type ' + virtinstall_virt_type + ' --name ' + virtinstall_name + ' --metadata \\\"title=' + virtinstall_title + ',description=' + virtinstall_description + ',name=' + virtinstall_name + '\\\"' + ' --network \\\"type=direct,source=' + virtinstall_network_hostif + ',source_mode=bridge,model=' + virtinstall_network_model + '\\\"' + ' --memory ' + virtinstall_memory + ' --vcpus ' + virtinstall_vcpus + ' --disk pool=' + virtinstall_disk_pool + ',size=' + virtinstall_disk_size + ',bus=virtio' + ' --os-variant ' + virtinstall_os_variant + ' --location http://' + virtinstall_http_host + '/' + mounted_iso[virtinstall_iso] | basename + ' --initrd-inject=/tmp/' + virtinstall_ksfile | basename + ' --extra-args \\\"inst.repo=http://' + virtinstall_http_host + '/' + mounted_iso[virtinstall_iso] | basename + ' inst.ks=file:/' + virtinstall_ksfile | basename + '\\\"' + ' --graphics spice ' + ' --video qxl ' + ' --channel spicevmc ' + ' --autostart ') ] }}\"\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "557fa489e07aba0d612092823e976b42fe97bfef", "filename": "tasks/Win32NT/fetch/chocolatey.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Set java_binary_type = chocolatey\n  set_fact:\n    java_binary_type: chocolatey\n\n- name: Chocolatey will download artifact itself\n  debug:\n    msg: 'Chocolatey will download artifact itself'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "316cf9e6bc350c96f8f99165b8c62b70016668b4", "filename": "roles/dns/config-dns-server-bind/tests/inventory/group_vars/dns-server.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nnamed_config:\n  recursion: 'no'\n  dnssec_enable: 'yes'\n  dnssec_validation: 'yes'\n  dnssec_lookaside: 'no'\n  allow_transfer:\n    - 192.168.48.21\n    - 192.168.48.22\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "60dc795aff9d81e29736a54bece71bb8cf297366", "filename": "roles/network/tasks/enable_services.yml", "repository": "iiab/iiab", "decoded_content": "- name: Disable dhcpd service\n  service: name=dhcpd\n           enabled=no\n  when: not dhcpd_enabled\n\n# service is restarted with NM dispatcher.d script\n- name: Enable dhcpd service\n  service: name=dhcpd\n           enabled=yes\n  when: dhcpd_enabled\n\n- name: Copy /etc/sysconfig/dhcpd file\n  template: src={{ item.src }}\n            dest={{ item.dest }}\n            owner=root\n            group=root\n            mode={{ item.mode }}\n  with_items:\n   - { src: 'dhcp/dhcpd-env.j2' , dest: '/etc/sysconfig/dhcpd' , mode: '0644' }\n  when: dhcpd_enabled\n\n- name: Copy named  file\n  template: src={{ item.src }}\n            dest={{ item.dest }}\n            owner=root\n            group=root\n            mode={{ item.mode }}\n  with_items:\n   - { src: 'named/school.local.zone.db' , dest: '/var/named-iiab/' , mode: '0644' }\n   - { src: 'named/school.internal.zone.db' , dest: '/var/named-iiab/' , mode: '0644' }\n\n- name: Enable named service\n  service: name={{ dns_service }}\n           enabled=yes\n  when: named_enabled\n\n- name: Disable named service\n  service: name={{ dns_service }}\n           enabled=no\n  when: not named_enabled\n\n- name: Enable dansguardian\n  service: name=dansguardian\n           enabled=yes\n  when: dansguardian_enabled and dansguardian_install\n\n- name: Disable dansguardian\n  service: name=dansguardian\n           enabled=no\n  when: not dansguardian_enabled and dansguardian_install\n\n- name: Create xs_httpcache flag\n  shell: echo 1 > /etc/sysconfig/xs_httpcache_on\n         creates=/etc/sysconfig/xs_httpcache_on\n  when: squid_enabled\n\n- name: Enable squid service\n  service: name={{ proxy }}\n           enabled=yes\n  when: squid_enabled and squid_install\n\n- name: Copy init script and config file\n  template: src={{ item.src }}\n            dest={{ item.dest }}\n            owner={{ item.owner }}\n            group={{ item.group }}\n            mode={{ item.mode }}\n  with_items:\n    - src: 'squid/squid-iiab.conf.j2'\n      dest: '/etc/{{ proxy }}/squid-iiab.conf'\n      owner: '{{ proxy_user }}'\n      group: '{{ proxy_user }}'\n      mode: '0644'\n  when: squid_enabled and squid_install\n\n- name: point to Squid config file from startup file\n  lineinfile: regexp='^CONFIG'\n              line='CONFIG=/etc/{{ proxy }}/squid-iiab.conf'\n              dest=/etc/init.d/{{ proxy }}\n  when: squid_enabled and squid_install and is_debuntu\n\n- name: Disable squid service\n  service: name={{ proxy }}\n           enabled=no\n  when: not squid_enabled and squid_install\n\n- name: Remove xs_httpcache flag\n  file: path=/etc/sysconfig/xs_httpcache_on\n        state=absent\n  when: not squid_enabled\n\n- name: Enable wondershaper service\n  service: name=wondershaper\n           enabled=yes\n  when: wondershaper_enabled and wondershaper_install\n\n- name: Disable wondershaper service\n  service: name=wondershaper\n           enabled=no\n  when: not wondershaper_enabled and wondershaper_install\n\n# check-LAN should be iptables.yml remove later\n- name: Grab clean copy of iiab-gen-iptables\n  template: src={{ item.0 }}\n            dest={{ item.1 }}\n            owner='root'\n            group='root'\n            mode='0755'\n  with_items:\n   - { 0: 'gateway/iiab-gen-iptables', 1: '/usr/bin/iiab-gen-iptables' }\n   - { 0: 'gateway/check-LAN', 1: '/usr/bin/check-LAN' }\n\n- name: Execute the script that sets up userspace firewall\n  shell: iiab-gen-iptables\n\n- name: Add squid to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=squid\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: enabled\n      value: \"{{ squid_enabled }}\"\n\n- name: Add dansguardian to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=dansguardian\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: enabled\n      value: \"{{ dansguardian_enabled }}\"\n\n- name: Add wondershaper to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=wondershaper\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: enabled\n      value: \"{{ wondershaper_enabled }}\"\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "e4584024eae780a4eca1e34c98b5a2cdcb18646f", "filename": "roles/config-selinux/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Configure SELinux\"\n  selinux:\n    state: \"{{ target_state | default('enforcing') }}\"\n    policy: \"{{ (target_state == 'disabled') | ternary(omit, target_policy) }}\"\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "ba0fc09eb9ee8103644b736e909c16e697531662", "filename": "roles/config-quay-enterprise/tasks/complete_setup.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Configure Setup Process on 1st Quay Host\n  block:\n    - name: Set Setup Output File Location\n      set_fact:\n        tmp_setup_file_location: /tmp/quay\n\n    - name: Restart Quay\n      systemd:\n        name: \"{{ quay_service }}\"\n        enabled: yes\n        state: restarted\n        daemon_reload: yes\n\n    - name: Hit Quay Setup Endpoint\n      uri:\n        url: \"{{ quay_http_protocol }}://{{ quay_hostname }}/setup/\"\n        validate_certs: no\n        method: GET\n        return_content: yes\n      register: uri_setup\n      until: uri_setup.status == 200\n      retries: 30\n      delay: 10\n    - name: Write file\n      copy:\n        content: \"{{ uri_setup.content }}\"\n        dest: \"{{ tmp_setup_file_location }}\"\n    - name: Extract csrf token\n      shell: cat /tmp/quay | grep \"__token\" | awk -F\\' '{print $(NF-1)}'\n      register: token\n    - name: Create Superuser\n      uri:\n        url:  \"{{ quay_http_protocol }}://{{ quay_server_hostname }}/api/v1/superuser/config/createsuperuser?_csrf_token={{ token.stdout | urlencode }}\"\n        validate_certs: no\n        method: POST\n        body_format: json\n        body:\n          username: \"{{ quay_superuser_username }}\"\n          email: \"{{ quay_superuser_email }}\"\n          password: \"{{ quay_superuser_password }}\"\n        headers:\n          Cookie: \"{{ uri_setup.set_cookie }}\"\n\n    - name: Delete Temporary Setup File\n      file:\n        state: absent\n        path: \"{{ tmp_setup_file_location }}\"\n  when: inventory_hostname == groups['quay_enterprise'][0]\n\n- name: Set setup_complete Fact\n  set_fact:\n    quay_setup_complete: True\n\n- name: Setup initial quay configuration file\n  template:\n    src: config.yaml.j2\n    dest: \"{{ quay_config_dir }}/config.yaml\"\n    owner: root\n    group: root\n    mode: g+rw\n  notify: Restart quay service\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "55749253c9839ad56bcbea891cd788b0e3820e1f", "filename": "playbooks/openshift/stop-cluster.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n- import_playbook: aws/stop.yml\n  when:\n  - hosting_infrastructure == 'aws'\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "ce9db3170bff44226c607a8cbb16119754c38867", "filename": "roles/sshd/LICENSE", "repository": "roots/trellis", "decoded_content": "The MIT License (MIT)\n\nCopyright (c) 2014 Nick Janetakis nick.janetakis@gmail.com\n\nPermission is hereby granted, free of charge, to any person obtaining\na copy of this software and associated documentation files (the\n'Software'), to deal in the Software without restriction, including\nwithout limitation the rights to use, copy, modify, merge, publish,\ndistribute, sublicense, and/or sell copies of the Software, and to\npermit persons to whom the Software is furnished to do so, subject to\nthe following conditions:\n\nThe above copyright notice and this permission notice shall be\nincluded in all copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND,\nEXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\nMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\nIN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY\nCLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,\nTORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE\nSOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "39746338da29e03d964671bf1e92d88892c67615", "filename": "roles/config-iscsi-client/tasks/iscsi.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: prereq.yml\n- import_tasks: iscsi-config.yml\n- import_tasks: multipath-config.yml\n- import_tasks: lvm-config.yml\n- import_tasks: lock-lvm.yml\n"}, {"commit_sha": "7c574f3b148b4df43177a5c0fc398ce4bea6ae3e", "sha": "81b451e4dcf552678fc355383f71da9be8d77755", "filename": "tasks/apt_build_depends.yml", "repository": "zzet/ansible-rbenv-role", "decoded_content": "- name: update apt cache\n  apt: update_cache=yes\n  become: true\n  tags:\n    - rbenv\n\n- name: install build depends\n  apt: pkg={{ item }} state=present install_recommends=no\n  with_items:\n    - build-essential\n    - git\n    - libcurl4-openssl-dev\n    - libffi-dev\n    - libreadline-dev\n    - libssl-dev\n    - libxml2-dev\n    - libxslt1-dev\n    - zlib1g-dev\n  become: true\n  tags:\n    - rbenv\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "c831a79cdb48c78b98e499c86a2616fc9ed2f1db", "filename": "roles/openvpn/templates/iiab-vpn.conf.in", "repository": "iiab/iiab", "decoded_content": "# this file allows changing the world accessable vpn server and its ip address\n#\n# copy this template file to /etc/openvpn/iiab-vpn.conf, and set properly\n\n#  VPNCONFIG=< put the name of the config file in /etc/openvpn you want to use>\n#  VPNIP=<put the ip address of server, pinged to test for existence of vpn tunnel>\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "0ea32f381be058633f8abb0360a4e279d79276b0", "filename": "tasks/create_repo_rubygems_hosted_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_rubygems_hosted\n    args: \"{{ _nexus_repos_rubygems_defaults|combine(item) }}\""}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "e3ae506cbfb0f8dbc236baca894305417a619d06", "filename": "roles/usb-lib/README.rst", "repository": "iiab/iiab", "decoded_content": "==============\nUSB Lib README\n==============\n\nThis role implements Library Box type functionality to mount and link content on a USB drive.\n\nAutomount is handled by usbmount and scripts in this role look in the root of the mounted drive for\n\n* /share\n* /Share\n* /PirateShare\n\nand if found create a symlink of the form /library/content/USBn points to /media/usbn.\n\nThere is also a patch for problems with automount on Fedora 21+\n\nPlease Note that as of the 4.1.8-200.fc22.x86_64 not all USB drives will mount even with this patch.\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "8d2a00cdd0d36add7125041b4ba982e5e4a2b30c", "filename": "roles/scm/add-webhooks-github/tests/inventory/group_vars/all.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\napi_token: 1234567890abcdefghijklmnopqrstuvwxyz9876\n\nowner: aGithubUser\n\nrepo: aRepo\n\n# To see all possible events https://developer.github.com/v3/activity/events/types/\nwebhooks:\n  - url: \"https://website1.com/\"\n    events: \n      - push\n    is_active: true\n  - url: \"https://website2.com/\"\n    events:\n      - push\n      - delete\n    is_active: true\n\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "ca520c591d2662f96693e7ccf4b23048c0e1d324", "filename": "tasks/create_repo_bower_group_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_bower_group\n    args: \"{{ _nexus_repos_bower_defaults|combine(item) }}\""}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "322b2a5c7b0dbc7c526d9300948819f07945ad32", "filename": "roles/ansible/tower/manage-credential-types/tests/inventory/group_vars/tower.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ntower_url: 'https://mytower.local'\ntower_admin_username: 'admin'\ntower_admin_password: \"mypassword\"\n\nansible_tower_credential_types:\n- name: \"CredType1\"\n  description: \"My Credential Type 1\"\n  fields:\n  - type: \"string\"\n    id: \"CUSTOM_ID1\"\n    label: \"My Custom ID 1\"\n    secret: \"false\"\n  - type: \"string\"\n    id: \"CUSTOM_ID2\"\n    label: \"My Custom ID 2\"\n    secret: \"true\"\n  required:\n  - id: \"CUSTOM_ID1\"\n  - id: \"CUSTOM_ID2\"\n  injectors_extra_vars:\n    - name: \"MY_EXTRA_VAR1\"\n      id: \"CUSTOM_ID1\"\n    - name: \"MY_EXTRA_VAR2\"\n      id: \"CUSTOM_ID2\" \n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a2ab48d811d7291be0477c3fdf59f8ec2c6b43d2", "filename": "playbooks/provision-nfs-server/README.md", "repository": "redhat-cop/infra-ansible", "decoded_content": "# NFS Server playbook\n\nThis playbook is for provisioning a server to host NFS shares.\n\n## Example run\n\n```\n> ansible-playbook -i inventory/provision-nfs-server/ playbooks/provision-nfs-server/main.yml --tags='install'\n```\n\n## Inventory Options\n\n| variable | info |\n|:--------:|:----:|\n|nfs-shares|List of nfs shares to create, more details at [nfs-server role](https://github.com/redhat-cop/infra-ansible/tree/master/roles/nfs-server)|\n|nfs_storage_device|The storage device where the nfs shares will be running.|\n|rhsm_username|Subscription manager username|\n|rhsm_password|Subscription manager password|\n|rhsm_pool|The pool id to register the server with|\n\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "29ec89f7423782f8611efd90f2be73d18af9e4ae", "filename": "roles/kiwix/files/test_zim/Notes.txt", "repository": "iiab/iiab", "decoded_content": "Make zim with\r\n\r\n./zimwriterfs --welcome=index.html --favicon=favicon.png --language=eng --title=test --description=test --creator=XSCE --publisher=XSCE  /root/devel/test_zim test.zim\r\n\r\nCreate library.xml with\r\n\r\n/opt/schoolserver/kiwix/bin/kiwix-manage /library/zims/library.xml add /library/zims/content/test.zim\r\n\r\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "299d01fe51a3c16f16b0272b1e2c7b4debb8e57e", "filename": "roles/2-common/templates/li.nux.ro.repo", "repository": "iiab/iiab", "decoded_content": "[li-nux-ro]\nname=RPMs missing in EPEL\nbaseurl=http://li.nux.ro/download/nux/dextop/el7/x86_64/\nenabled=0\ngpgcheck=1\ngpgkey=http://li.nux.ro/download/nux/RPM-GPG-KEY-nux.ro\n\n\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "4ce9344afdb8322f9a1ef04dc350cdf4e465ab1d", "filename": "tasks/create_repo_maven_proxy_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_maven_proxy\n    args: \"{{ _nexus_repos_maven_defaults|combine(item) }}\"\n"}, {"commit_sha": "f92ebbef856e59bd4563d4b5b69ee75a95ec89d5", "sha": "d91c095c895ea3df1754538011443d844046aa59", "filename": "roles/openshift-management/tasks/prune-projects.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- name: Setup variables used in this task\n  set_fact:\n    projects_to_process: []\n\n- name: Set username fact (if this is run by an Ansible Tower job)\n  set_fact:\n    run_as: \"--as='{{ tower_user_name }}'\"\n  when: \n  - tower_user_name is defined\n  - tower_user_name|trim != ''\n\n- name: Get list of projects\n  shell: oc {{ run_as | default('') }} get project --no-headers | awk '{print $1}'\n  environment:\n    KUBECONFIG: \"{{ kubeconfig }}\"\n  register: projects \n\n- name: Remove excluded projects from the list to process\n  set_fact:\n    projects_to_process: \"{{ projects_to_process }} + [ '{{ item }}' ]\"\n  with_items: \"{{ projects.stdout_lines }}\"\n  when:\n  - item not in openshift_prune_projects_system_excludes\n  - item not in openshift_prune_projects_user_excludes\n\n- name: Get OpenShift project details (timestamps)\n  shell: oc {{ run_as | default('') }} get project {{ item }} -o json\n  environment:\n    KUBECONFIG: \"{{ kubeconfig }}\"\n  register: project_details\n  with_items: \"{{ projects_to_process }}\"\n\n- name: Convert timestamps (already in UTC) to seconds\n  shell: date -d '{{ (item.stdout | from_json).metadata.creationTimestamp }}' +%s\n  register: project_timestamp_seconds\n  with_items: \"{{ project_details.results }}\"\n\n- name: Get timestamp for X hrs ago (default 24 hrs) in seconds (UTC) \n  shell: date -u -d '{{ openshift_prune_projects_keep_younger | default(24) }} hour ago' +%s\n  register: cutoff_timestamp_seconds\n\n- name: Prune projects\n  shell: oc {{ run_as | default('') }} delete project {{ item.item.item }}\n  environment:\n    KUBECONFIG: \"{{ kubeconfig }}\"\n  when:\n  - \"{{ item.stdout }} < {{ cutoff_timestamp_seconds.stdout }}\"\n  with_items: \"{{ project_timestamp_seconds.results }}\"\n"}, {"commit_sha": "6fada6f2a7515ab18178ae350168c3de147c4dd0", "sha": "005dd424b6075ffbf39573f2c1ac0c1e0d4bb76a", "filename": "tasks/main.yml", "repository": "inkatze/wildfly", "decoded_content": "---\n# task file for wildfly\n\n- include: install.yml\n- include: configure.yml\n- include: users.yml\n\n- include: ssl.yml\n  when: wildfly_enable_ssl\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "8b137891791fe96927ad78e64b0aad7bded08bdc", "filename": "roles/registrator/handlers/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "e7f6365faccef098d4f56baf10381a433126c803", "filename": "roles/config-selinux/tests/inventory/group_vars/all.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ntarget_state: 'enforcing'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "96ca66c4804a16c1443a92d7de05d6c904e8dc9e", "filename": "roles/virt-install/tasks/prereq.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Install required packages'\n  package:\n    name: '{{ item }}'\n    state: installed\n  with_items:\n  - virt-install\n  - httpd\n  - libselinux-python\n\n- name: 'Enable and start libvirtd'\n  service:\n    name: libvirtd\n    enabled: yes\n    state: started\n\n- name: 'Enable and start httpd'\n  service:\n    name: httpd\n    enabled: no\n    state: started\n\n- name: 'Enable and start firewalld'\n  service:\n    name: firewalld\n    enabled: yes\n    state: started\n\n- name: 'Ensure firewalld is open for httpd traffic'\n  firewalld:\n    service: http\n    state: enabled\n    permanent: no\n    immediate: yes\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "09f9b4e28816a3c82eb9d58ceff9bd44f38253bb", "filename": "roles/rachel/meta/main.yml", "repository": "iiab/iiab", "decoded_content": "---\nallow_duplicates: yes\ndependencies:\n    - { role: mysql, mysql_enabled: True }\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "0628457236267bf1a6418f4bac98eb2cc4406c01", "filename": "roles/sugarizer/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "sugarizer_install: True\nsugarizer_enabled: False\nsugarizer_location: '{{ doc_root }}'\nsugarizer_version: 'sugarizer-0.9'\nnpm_exists: False\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "99717d1539fc7050012e1fdac6b27ba5ac8193bb", "filename": "cookbooks/packagecloud/metadata.rb", "repository": "rocknsm/rock", "decoded_content": "name 'packagecloud'\nmaintainer 'Joe Damato'\nmaintainer_email 'joe@packagecloud.io'\nlicense 'Apache 2.0'\ndescription 'Installs/Configures packagecloud.io repositories.'\nlong_description 'Installs/Configures packagecloud.io repositories.'\nversion '0.2.5'\nsource_url 'https://github.com/computology/packagecloud-cookbook' if respond_to?(:source_url)\nissues_url 'https://github.com/computology/packagecloud-cookbook/issues' if respond_to?(:issues_url)\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "ad8d65d4c9516beeda348bdaa3e85e251f4cb169", "filename": "roles/notifications/send-email/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n# This test covers the full feature set provided by the role\n\n- name: Test email/send role\n  hosts: localhost\n  roles:\n  - notifications/send-email\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "7919dbd80686384230be2d7db22ee1b02e4815ca", "filename": "handlers/main.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Handler: All OSs) Run NGINX\"\n  block:\n\n    - name: \"(Handler: All OSs) Start NGINX\"\n      service:\n        name: nginx\n        state: started\n        enabled: yes\n\n    - name: \"(Handler: All OSs) Reload NGINX\"\n      service:\n        name: nginx\n        state: reloaded\n\n  when:\n    - nginx_start | bool\n    - not ansible_check_mode\n\n- name: \"(Handler: All OSs) Start NGINX Amplify Agent\"\n  service:\n    name: amplify-agent\n    state: started\n\n- name: \"(Handler: All OSs) Start NGINX Controller Agent\"\n  service:\n    name: controller-agent\n    state: started\n\n- name: \"(Handler: Debian/Ubuntu/CentOS/RedHat) Start NGINX Unit\"\n  service:\n    name: unit\n    state: started\n    enabled: yes\n\n- name: \"(Handler: FreeBSD) Start NGINX Unit\"\n  service:\n    name: unitd\n    state: started\n    enabled: yes\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "d91adc69aad7be659dd009ea87d6b3ce090cf708", "filename": "playbooks/templates/bro-broctl.cfg.j2", "repository": "rocknsm/rock", "decoded_content": "## Global BroControl configuration file.\n\n###############################################\n# Mail Options\n\n# Recipient address for all emails sent out by Bro and BroControl.\nMailTo = root@localhost\n\n# Mail connection summary reports each log rotation interval.  A value of 1\n# means mail connection summaries, and a value of 0 means do not mail\n# connection summaries.  This option has no effect if the trace-summary\n# script is not available.\nMailConnectionSummary = 1\n\n# Lower threshold (in percentage of disk space) for space available on the\n# disk that holds SpoolDir. If less space is available, \"broctl cron\" starts\n# sending out warning emails.  A value of 0 disables this feature.\nMinDiskSpace = 5\n\n# Send mail when \"broctl cron\" notices the availability of a host in the\n# cluster to have changed.  A value of 1 means send mail when a host status\n# changes, and a value of 0 means do not send mail.\nMailHostUpDown = 1\n\n###############################################\n# Logging Options\n\n# Rotation interval in seconds for log files on manager (or standalone) node.\n# A value of 0 disables log rotation.\nLogRotationInterval = 3600\n\n# Expiration interval for archived log files in LogDir.  Files older than this\n# will be deleted by \"broctl cron\".  The interval is an integer followed by\n# one of these time units:  day, hr, min.  A value of 0 means that logs\n# never expire.\nLogExpireInterval = {{ bro_log_retention }}\n\n# Enable BroControl to write statistics to the stats.log file.  A value of 1\n# means write to stats.log, and a value of 0 means do not write to stats.log.\nStatsLogEnable = 1\n\n# Number of days that entries in the stats.log file are kept.  Entries older\n# than this many days will be removed upon running \"broctl cron\".  A value of 0\n# means that entries never expire.\nStatsLogExpireInterval = {{ bro_stats_retention }}\n\n###############################################\n# Other Options\n\n# Show all output of the broctl status command.  If set to 1, then all output\n# is shown.  If set to 0, then broctl status will not collect or show the peer\n# information (and the command will run faster).\nStatusCmdShowAll = 0\n\n# Site-specific policy script to load. Bro will look for this in\n# $PREFIX/share/bro/site. A default local.bro comes preinstalled\n# and can be customized as desired.\nSitePolicyScripts = local.bro\n\n# Location of the log directory where log files will be archived each rotation\n# interval.\nLogDir = {{ bro_data_dir }}/logs\n\n# Location of the spool directory where files and data that are currently being\n# written are stored.\nSpoolDir = {{ bro_data_dir }}/spool\n\n# Location of other configuration files that can be used to customize\n# BroControl operation (e.g. local networks, nodes).\nCfgDir = /opt/bro/etc\n"}, {"commit_sha": "045ff4bb9f4720739632aac2951fbf2798a99c8c", "sha": "20b8886d33ea7fa6018f237f0ee9059d067ccb98", "filename": "playbooks/local_ssh.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- name: Ensure the local ssh directory is exist\n  local_action:\n    module: file\n    path: \"~/.ssh/\"\n    state: directory\n\n- name: Copy the algo ssh key to the local ssh directory\n  local_action:\n    module: copy\n    src: configs/algo.pem\n    dest: ~/.ssh/algo.pem\n    mode: '0600'\n\n- name: Configure the local ssh config\n  blockinfile:\n    dest: \"~/.ssh/config\"\n    marker: \"# {mark} ALGO MANAGED BLOCK {{ cloud_instance_ip|default(server_ip) }}\"\n    insertbefore: BOF\n    create: yes\n    block: |\n      Host {{ cloud_instance_ip|default(server_ip) }}\n      \tIdentityFile ~/.ssh/algo.pem\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "175c0b423556d0779a23889ae490e1968badcfc3", "filename": "playbooks/prep.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Configure RHSM usernames/passwords'\n  hosts: localhost\n  tasks: \n  - pause:\n      prompt: 'Please enter your Red Hat Subscription username'\n    register: username\n  - set_fact:\n      rhsm_username: \"{{ username.user_input }}\"\n  - pause:\n      prompt: 'Please enter your Red Hat Subscription password'\n    no_log: True\n    register: password\n  - set_fact:\n      rhsm_password: \"{{ password.user_input }}\"\n    no_log: True\n  tags:\n  - configure_rhsm\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "4368862663608976cb5d5ed4963e76d25e1ceeb0", "filename": "roles/config-nagios-target/tasks/nrpe_mem.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Copy in additional Nagios Memory plugins\n  copy: \n    src: plugins/check_mem\n    dest: /usr/lib64/nagios/plugins/check_mem\n    owner: root\n    group: root\n    mode: 0755\n\n- name: Copy nrpe.d Memory configuration files\n  copy: \n    src: nrpe.d/check_mem.cfg\n    dest: /etc/nrpe.d/check_mem.cfg\n    owner: root\n    group: root\n    mode: 0644\n\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "52da16500f1d5f215426cf82db7e1b4529eda6d5", "filename": "playbooks/roles/bb0-openstack/README.md", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "Provisioning on OpenStack\n=========\n\nProvisionning of STC stack on top of OpenStack, inspired by https://github.com/ktenzer/openshift-on-openstack-123\n\nExample Playbook\n----------------\n\n\n```\ndocker run -ti $(pwd):/work:z quay.io/redhat/stc-openstack-provisioner\n\nexport OS_USERNAME=admin\nexport OS_PASSWORD=xxxx\nexport OS_AUTH_URL=xxxx\nexport OS_PROJECT_NAME=admin\nexport OS_USER_DOMAIN_NAME=Default\nexport OS_PROJECT_DOMAIN_NAME=Default\nexport OS_IDENTITY_API_VERSION=3\n\nexport STC_RHN_PASSWORD=xxxx\nexport STC_RHN_USERNAME=xxx\nexport STC_SUBSCRIPTION_POOL_ID=xx\nexport STC_REGISTRY_TOKEN_USER=xxx\nexport STC_REGISTRY_TOKEN=xxxx\nexport STC_FLAVOR=mini  # Only supported flavor at the moment is mini\n\ncd /work\n./playbooks/bb00-openstack_provisioning.yml\n```\n\n\nLicense\n-------\n\nApache 2.0\n\nAuthor Information\n------------------\n\nRobert Bohne \nrobert.bohne@redhat.com"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "4c7c1237e1fcf7ae5f706e912a7c53493ed88a52", "filename": "roles/2-common/tasks/xo.yml", "repository": "iiab/iiab", "decoded_content": "- name: XO Server specific tasks\n  command: echo Starting XO.yml\n\n- name: Disable sleep\n  command: touch /etc/powerd/flags/inhibit-suspend\n           creates=/etc/powerd/flags/inhibit-suspend\n\n- name: Disable sleep on lid closing\n  lineinfile: dest=/etc/powerd/powerd.conf\n              regexp='^config_SLEEP_WHEN_LID_CLOSED'\n              line='config_SLEEP_WHEN_LID_CLOSED=\"no\"'\n              state=present\n              backup=yes\n\n- name: Keep yum cache\n  ini_file: dest=/etc/yum.conf\n            section=main\n            option=keepcache\n            value=1\n  when: not installing\n\n- name: Keep docs when installing packages\n  lineinfile: backup=yes\n              dest=/etc/rpm/macros.imgcreate\n              regexp='^%_excludedocs'\n              state=absent\n\n- name: pre-Install packages\n  package: name={{ item }}\n           state=latest\n  with_items:\n   - usbmount\n   - man\n   - man-db\n   - man-pages\n\n- name: re-Install packages\n  shell: yum -y reinstall sed libidn grep which util-linux wget gnupg2 groff gnash yum\n  when: not osbuilder is defined\n\n- name: Configure networkmanager plugin\n  ini_file: dest=/etc/NetworkManager/NetworkManager.conf\n            section=main\n            option=plugins\n            value=ifcfg-rh,keyfile\n\n- name: check for modem config file\n  stat: path=/etc/NetworkManager/system-connections/\"Sugar Modem Connection\"\n  register: config\n\n- name: Change failure and interval settings for modem connection\n  ini_file: dest=/etc/NetworkManager/system-connections/\"Sugar Modem Connection\"\n            section=ppp\n            option={{ item.option }}\n            value={{ item.value }}\n            backup=yes\n            mode=0600\n  with_items:\n     - { option: 'lcp-echo-failure', value: '5' }\n     - { option: 'lcp-echo-interval', value: '30' }\n  when: config.stat.exists\n\n- name: Create bigger rwtab\n  lineinfile: backup=yes\n              dest=/etc/sysconfig/readonly-root\n              regexp='^RW_OPTIONS'\n              line='RW_OPTIONS=\"-o size=4M -o nr_inodes=2048\"'\n              state=present\n\n- name: Remove dhcpd entry from /etc/rwtab\n  lineinfile: backup=yes\n              dest=/etc/rwtab\n              regexp='^empty.*/var/lib/dhcpd'\n              state=absent\n\n- name: Remove php entry from /etc/rwtab\n  lineinfile: backup=yes\n              dest=/etc/rwtab\n              regexp='^empty.*/var/lib/php'\n              state=absent\n\n- name: Persist /etc/hosts between reboots\n  lineinfile: backup=yes\n              dest=/etc/statetab.d/olpc\n              regexp='^/etc/hosts'\n              state=absent\n\n\n- name: Disable /var/log tmpfs\n  lineinfile: backup=yes\n              dest=/etc/fstab\n              regexp='^varlog.*'\n              state=absent\n\n- name: Enlarge the /tmp directory so that url_get does not error out\n  lineinfile: backup=yes\n              dest=/etc/fstab\n              regexp='^/tmp*'\n              line='/tmp            /tmp            tmpfs         rw,size=600m 0 0'\n\n- name: Disable graphical login\n  file: path=/etc/systemd/system/default.target\n        src=/lib/systemd/system/multi-user.target\n        state=link\n  register: disabled_login\n\n- name: Remove custom profile settings\n  file: path=/etc/profile.d/zzz_olpc.sh\n        state=absent\n\n- name: Download substitute software for i386 on FC18 XO1.5\n  get_url: url=\"{{ iiab_download_url }}/{{ item }}\"  dest={{ downloads_dir }}/{{ item }}\n  with_items:\n     - hostapd_8188_i386\n  when: wifi_id  ==  \"tplink_WM725M\" and xo_model == \"XO-1.5\"  and internet_available\n  tags:\n    - xo\n\n- name: Put the substitute in place\n  copy: src={{ downloads_dir }}/hostapd_8188_i386\n        dest=/usr/sbin/hostapd\n        backup=yes\n        mode=0775\n        owner=root\n        group=root\n  when: wifi_id  ==  \"tplink_WM725M\" and xo_model == \"XO-1.5\"\n\n- name: Reboot system\n  command: /sbin/reboot\n  when: disabled_login.changed and not installing\n  ignore_errors: yes\n  async: 300\n  poll: 120\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "9e7c034178179e4505c4b1b82ce9b5c5c9010e9e", "filename": "roles/manage-aws-infra/tasks/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n- import_tasks: pre-reqs.yml\n\n- import_tasks: create-vpc.yml\n  when:\n    - aws_create_vpc\n    - operation == \"deploy\"\n\n- import_tasks: create-subnet.yml\n  when:\n    - operation == \"deploy\"\n\n- import_tasks: deploy-cluster.yml\n  when:\n    - operation == \"deploy\"\n\n- import_tasks: update_dns.yml\n  when:\n    - operation == \"deploy\"\n\n- import_tasks: start_stop_instances.yml\n  when: (operation == \"running\") or\n        (operation == \"stopped\")\n\n- import_tasks: remove_infra.yml\n  when:\n    - operation == \"absent\"\n\n- import_tasks: remove_vpc.yml\n  when:\n    - operation == \"absent\"\n    - delete_vpc\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "e567232a3d4aa0277a2d04b57e480f1384f7c2ba", "filename": "playbooks/services.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Configure DHCP'\n  hosts: dhcp_servers\n  roles:\n  - role: dhcp\n  tags:\n  - configure_dhcp\n\n- name: 'Configure DNS (internal)'\n  hosts: dns_servers_internal\n  roles:\n  - role: dns/config-dns-server\n  - role: dns/manage-dns-zones\n  tags:\n  - configure_dns_internal\n\n- name: 'Configure DNS (external)'\n  hosts: dns_servers_external\n  roles:\n  - role: dns/config-dns-server\n  - role: dns/manage-dns-zones\n  tags:\n  - configure_dns_external\n\n- name: 'Configure NTP / Chrony'\n  hosts: ntp_servers\n  roles:\n  - role: config-chrony\n  tags:\n  - configure_chrony\n\n- name: 'Configure IdM'\n  hosts: idm_servers\n  roles:\n  - role: idm\n  tags:\n  - configure_idm\n\n- name: 'Configure Satellite'\n  hosts: satellite_servers\n  roles:\n  - role: config-satellite\n  tags:\n  - configure_satellite\n\n- name: 'Configure www hosts'\n  hosts: www_servers\n  roles:\n  - role: config-httpd\n  tags:\n  - configure_www_hosts\n\n- name: 'Configure REPO hosts'\n  hosts: repo_servers\n  roles:\n  - role: config-software-src\n  - role: config-repo-server\n  tags:\n  - configure_repo_hosts\n\n- name: 'Configure PXE hosts'\n  hosts: pxe_servers\n  roles:\n  - role: config-pxe\n  tags:\n  - configure_pxe_hosts\n\n- name: 'Configure OpenVPN'\n  hosts: openvpn_servers\n  roles:\n  - role: config-openvpn\n  tags:\n  - configure_openvpn\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "4a101becf2f526dcd23fde074a7265636450066c", "filename": "playbooks/openshift/post-install.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- hosts: cluster_hosts\n  roles:\n    - role: sync-keys\n      key_url: \"{{ openshift_authorized_key_url | default('') }}\"\n\n- hosts: masters\n  roles:\n  - { role: create_users }\n\n- import_playbook: ../openshift-cluster-seed.yml\n  when:\n  - openshift_cluster_content is defined\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "10bd7d42063873e8c8d694f48fdde73171c48802", "filename": "playbooks/roles/bb0-openstack/templates/secrets.yml.j2", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "sudo_password: \"{{ lookup('env','STC_SUDO_PASSWORD') }}\"\nrhn_password: \"{{ lookup('env','STC_RHN_PASSWORD') | default('PLEASE SET',true) }}\""}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "3024c24ab96a623bc68468214ac4b085f51ca38f", "filename": "playbooks/container-registry/quay-enterprise.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Preflight Checks\n  hosts: localhost\n  tasks:\n    - name: Validate Required Group Configuration\n      fail:\n        msg: \"'database', 'redis' and 'quay_enterprise' groups must be specified\"\n      when:\n        - \"'redis' not in groups or groups['redis']| length == 0 or 'database' not in groups or groups['database']| length == 0 or 'quay_enterprise' not in groups or groups['quay_enterprise']| length == 0\"\n\n- name: Install Docker\n  hosts: docker_hosts\n  tasks:\n    - name: Configure Docker\n      include_role:\n        name: config-container-storage-setup\n      when: (docker_install|default(false))|bool\n\n    - name: Install Docker\n      include_role:\n        name: config-docker\n      when: (docker_install|default(false))|bool\n\n- name: Install HAProxy\n  hosts: lb\n  pre_tasks:\n    - name: Setup\n      setup:\n      delegate_to: \"{{ item }}\"\n      delegate_facts: true\n      with_items:\n        - \"{{ groups['quay_enterprise'] }}\"\n  roles:\n    - role: load-balancers/manage-haproxy\n      lb_config:\n        stats_page:\n          enabled: True\n          host_vip: \"{{ haproxy_host_vip | default('*') }}\"\n          host_port: 8080\n          username: \"{{ haproxy_stats_username | default('admin') }}\"\n          password: \"{{ haproxy_stats_password | default('admin') }}\"\n        frontends:\n        - lb_name: quay_http\n          lb_host_vip: \"{{ haproxy_host_vip | default('*') }}\"\n          lb_host_port: 80\n        - lb_name: quay_https\n          lb_host_vip: \"{{ haproxy_host_vip | default('*') }}\"\n          lb_host_port: 443\n        - lb_name: redis\n          lb_host_vip: \"{{ haproxy_host_vip | default('*') }}\"\n          lb_host_port: 6379\n          lb_ssl_enabled: True\n      lb_backend_template: \"{{ playbook_dir }}/templates/haproxy_backend.cfg.j2\"\n\n- name: Install and Configure Database for Quay\n  hosts: database\n  become: True\n  tasks:\n    - name: Install MySQL\n      include_role:\n        name: config-mysql\n      vars:\n        mode: containerized\n        mysql_name: \"{{ quay_database_service_name | default('mysql-quay') }}\"\n        mysql_username: \"{{ quay_database_username }}\"\n        mysql_password: \"{{ quay_database_password }}\"\n        mysql_root_username: \"{{ quay_database_admin_username }}\"\n        mysql_root_password: \"{{ quay_database_admin_password }}\"\n        mysql_database: \"{{ quay_database_name }}\"\n      when: quay_database_type == \"mysql\"\n\n    - name: Install and Configure PostgreSQL for Quay\n      block:\n        - name: Install PostgreSQL for Quay\n          include_role:\n            name: config-postgresql\n          vars:\n            mode: containerized\n            postgresql_name: \"{{ quay_database_service_name | default('postgresql-quay') }}\"\n            postgresql_username: \"{{ quay_database_username }}\"\n            postgresql_password: \"{{ quay_database_password }}\"\n            postgresql_admin_user: \"{{ quay_database_admin_username }}\"\n            postgresql_admin_password: \"{{ quay_database_admin_password }}\"\n            postgresql_port: \"{{ quay_database_port | default('5432') }}\"\n            postgresql_database: \"{{ quay_database_name }}\"\n\n        - name: Flush Handlers\n          meta: flush_handlers\n\n        - name: Sleep to give PostgreSQL a chance to finish starting up\n          pause:\n            seconds: 10\n\n        - name: Locate PostgreSQL Container\n          command: docker ps --filter=name=\"{{ quay_database_service_name | default('postgresql-quay') }}\" -q\n          register: postgresql_container\n\n        - name: Configure PostgreSQL\n          shell: docker exec -i {{ postgresql_container.stdout }} /bin/bash -c 'PGPASSWORD={{ quay_database_admin_password }} psql {{ quay_database_name }} -c \"CREATE EXTENSION pg_trgm;\"'\n          register: shell_result\n          failed_when:\n            - shell_result.rc != 0\n            - \"'already exists' not in shell_result.stderr\"\n      when: quay_database_type == \"postgresql\"\n\n- name: Install Redis\n  hosts: redis\n  become: True\n  tasks:\n    - name: Install Redis\n      include_role:\n        name: config-redis\n      vars:\n        mode: containerized\n\n- name: Install Quay Enterprise\n  hosts: quay_enterprise\n  become: True\n  tasks:\n    - name: Set Quay Hostname When LB Defined\n      set_fact:\n        quay_hostname: \"{{ hostvars[groups['lb'][0]]['inventory_hostname'] }}\"\n      when: quay_hostname is undefined and groups['lb'] | length > 0\n    - name: Set Quay Hostname When LB Not Defined\n      set_fact:\n        quay_hostname: \"{{ hostvars[groups['quay_enterprise'][0]]['inventory_hostname'] }}\"\n      when: quay_hostname is undefined and groups['lb'] | length == 0\n    - name: Install Quay\n      include_role:\n        name: config-quay-enterprise\n      vars:\n        quay_database_username: \"{{ hostvars[groups['database'][0]]['quay_database_username'] }}\"\n        quay_database_password: \"{{ hostvars[groups['database'][0]]['quay_database_password'] }}\"\n        quay_database_name: \"{{ hostvars[groups['database'][0]]['quay_database_name'] }}\"\n        quay_database_port: \"{{ hostvars[groups['database'][0]]['quay_database_port'] }}\"\n        quay_database_host: \"{{ hostvars[groups['database'][0]]['ansible_eth0']['ipv4']['address'] }}\"\n        redis_host: \"{{ quay_hostname | default(hostvars[groups['lb'][0]]['inventory_hostname']) if groups['lb'] | length > 0 else hostvars[groups['redis'][0]]['ansible_eth0']['ipv4']['address'] }}\"\n        quay_server_hostname: \"{{ quay_hostname | default(inventory_hostname) }}\"\n        quay_clair_enable: \"{{ (groups['clair']| length > 0) | ternary('True','False') }}\"\n        quay_clair_endpoint: \"http://{{ hostvars[groups['clair'][0]]['ansible_eth0']['ipv4']['address'] if (groups['clair']| length > 0) else '' }}:{{ clair_endpoint_port | default('6060') }}\"\n        quay_builder_enable: \"{{ (groups['quay_builder']| length > 0) | ternary('True','False') }}\"\n        quay_superuser_username: \"{{ hostvars[groups['quay_enterprise'][0]]['quay_superuser_username'] }}\"\n        quay_superuser_password: \"{{ hostvars[groups['quay_enterprise'][0]]['quay_superuser_password'] }}\"\n        quay_superuser_email: \"{{ hostvars[groups['quay_enterprise'][0]]['quay_superuser_email'] }}\"\n\n- name: Install Clair Database\n  hosts: database\n  become: True\n  tasks:\n    - name: Install and Configure PostgreSQL for Clair\n      include_role:\n        name: config-postgresql\n      vars:\n        mode: containerized\n        postgresql_name: \"{{ clair_database_service_name | default('postgresql-clair') }}\"\n        postgresql_username: \"{{ clair_database_username }}\"\n        postgresql_password: \"{{ clair_database_password }}\"\n        postgresql_admin_user: \"{{ clair_database_admin_username }}\"\n        postgresql_admin_password: \"{{ clair_database_admin_password }}\"\n        postgresql_host_port: \"{{ clair_database_port | default('5433') }}\"\n        postgresql_database: \"{{ clair_database_name }}\"\n      when: groups['clair']| length > 0\n\n- name: Install Clair\n  hosts: clair\n  become: True\n  tasks:\n    - name: Gather facts from machine\n      setup:\n      with_items:\n        - \"{{ groups['quay_enterprise'] }}\"\n    - name: Set Quay Hostname When LB Defined\n      set_fact:\n        quay_hostname: \"{{ hostvars[groups['lb'][0]]['inventory_hostname'] }}\"\n      when: quay_hostname is undefined and groups['lb'] | length > 0\n    - name: Set Quay Hostname When LB Defined\n      set_fact:\n        quay_hostname: \"{{ hostvars[groups['quay_enterprise'][0]]['inventory_hostname'] }}\"\n      when: quay_hostname is undefined and groups['lb'] | length == 0\n\n    - name: Install Clair\n      include_role:\n        name: config-clair\n      vars:\n        database_host: \"{{ hostvars[groups['database'][0]]['ansible_eth0']['ipv4']['address'] }}\"\n        quay_enterprise_address: \"{{ hostvars[groups['quay_enterprise'][0]]['quay_http_protocol'] }}://{{ quay_hostname }}\"\n        clair_ssl_trust_configure: \"{{ hostvars[groups['quay_enterprise'][0]]['quay_ssl_enable']|bool }}\"\n        clair_ssl_trust_src_file: \"{{ hostvars[groups['quay_enterprise'][0]]['quay_ssl_cert_file_to_use'] if hostvars[groups['quay_enterprise'][0]]['quay_ssl_enable'] is defined and hostvars[groups['quay_enterprise'][0]]['quay_ssl_enable']|bool else '' }}\"\n        postgresql_port: \"{{ clair_database_port | default('5433') }}\"\n        clair_host_proxy_port: \"{{ clair_endpoint_port | default('6060') }}\"\n\n- name: Install Quay Builder\n  hosts: quay_builder\n  tasks:\n    - name: Gather facts from machine\n      setup:\n      with_items:\n        - \"{{ groups['quay_enterprise'] }}\"\n    - name: Install Quay Enterprise\n      include_role:\n        name: config-quay-builder\n      vars:\n        quay_enterprise_hostname: \"{{ quay_hostname }}\"\n        quay_builder_ssl_trust_configure: \"{{ hostvars[groups['quay_enterprise'][0]]['quay_ssl_enable']|bool }}\"\n        quay_builder_ssl_trust_src_file: \"{{ hostvars[groups['quay_enterprise'][0]]['quay_ssl_cert_file_to_use'] if hostvars[groups['quay_enterprise'][0]]['quay_ssl_enable'] is defined and hostvars[groups['quay_enterprise'][0]]['quay_ssl_enable']|bool else '' }}\"\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "30cb3a698bf679e0fe4f429efa90e4ea8ebc0272", "filename": "roles/marathon/handlers/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# handlers file for marathon\n- name: wait for marathon to listen\n  command: /usr/local/bin/marathon-wait-for-listen.sh"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "776d654e5312f23352cde34b59b9b4e31b312599", "filename": "tasks/delete_repo_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: delete_repo\n    args:\n      name: \"{{ item }}\""}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "d4a417898382efd20c1d6187a503c3c6930eb6b0", "filename": "roles/config-satellite/tasks/activation_keys.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Get current subscriptions\"\n  shell: hammer -u \"{{ satellite_username }}\" -p \"{{ satellite_password }}\" --csv subscription list --organization \"{{ satellite_organization }}\" | grep \"{{ item.value.subscription }}\" | awk -F, '{print $1}'\n  register: subids\n  with_dict: \"{{ satellite_activation_keys }}\"\n\n- name: \"Create activation key(s)\"\n  command: > \n    hammer\n      -u \"{{ satellite_username }}\"\n      -p \"{{ satellite_password }}\"\n      activation-key create\n      --name {{ item.key }}\n      --lifecycle-environment Library\n      --organization \"{{ satellite_organization }}\"\n  with_dict: \"{{ satellite_activation_keys }}\"\n  register: chk_ak\n  failed_when:\n  - chk_ak.rc != 65\n  - chk_ak.rc != 0\n\n- name: \"Add subs to activation key\"\n  command: >\n     hammer\n       -u \"{{ satellite_username }}\"\n       -p \"{{ satellite_password }}\"\n       activation-key add-subscription\n       --name \"{{ item.item.key }}\"\n       --subscription-id \"{{ item.stdout }}\"\n       --organization \"{{ satellite_organization }}\"\n  with_items:\n  - \"{{ subids.results }}\"\n  register: ak_chk\n  failed_when:\n  - ak_chk.rc != 128\n  - ak_chk.rc != 0\n\n- name: \"Turn off autoattach on activation key(s)\"\n  command: >\n    hammer\n      -u \"{{ satellite_username }}\"\n      -p \"{{ satellite_password }}\"\n      activation-key update\n      --auto-attach false\n      --name \"{{ item.key }}\"\n      --organization \"{{ satellite_organization }}\"\n  with_dict: \"{{ satellite_activation_keys }}\"\n\n"}, {"commit_sha": "ccab58ae5d697bb64abd86558f79c34161d2fb00", "sha": "2074ad2c9ff30b0ece0d221c970bdd8abdf8f95a", "filename": "tasks/process_repos_list.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n\n# Process a single _nexus_repos_global_list for configured formats and apply default values for type.\n\n# @todo: refactor with easier syntax once the 'flip' filter is released (possibly in ansible 2.8)\n# See the following related PRs/issues.\n# - https://github.com/ansible/ansible/pull/46340\n# - https://github.com/ansible/ansible/pull/46255\n# - https://github.com/ansible/ansible/issues/46215\n# - https://github.com/pallets/jinja/pull/906\n\n- name: apply defaults to maven proxy repos\n  set_fact:\n    nexus_repos_maven_proxy: >-\n      {%- set result=[] -%}\n      {%- for repo in nexus_repos_maven_proxy -%}\n        {{ result.append(_nexus_repos_maven_defaults | combine(repo)) }}\n      {%- endfor -%}\n      {{ result | to_json | from_json }}\n\n- name: apply defaults to maven hosted repos\n  set_fact:\n    nexus_repos_maven_hosted: >-\n      {%- set result=[] -%}\n      {%- for repo in nexus_repos_maven_hosted -%}\n        {{ result.append(_nexus_repos_maven_defaults | combine(repo)) }}\n      {%- endfor -%}\n      {{ result | to_json | from_json }}\n\n- name: apply defaults to maven group repos\n  set_fact:\n    nexus_repos_maven_group: >-\n      {%- set result=[] -%}\n      {%- for repo in nexus_repos_maven_group -%}\n        {{ result.append(_nexus_repos_maven_defaults | combine(repo)) }}\n      {%- endfor -%}\n      {{ result | to_json | from_json }}\n\n- name: Add maven repositories to global repos list\n  set_fact:\n    _nexus_repos_global_list: >-\n      {{\n        _nexus_repos_global_list | default([])\n        +\n        (nexus_repos_maven_proxy | map('combine', {\"format\": \"maven2\", \"type\": \"proxy\"}) | list)\n        +\n        (nexus_repos_maven_hosted | map('combine', {\"format\": \"maven2\", \"type\": \"hosted\"}) | list)\n        +\n        (nexus_repos_maven_group | map('combine', {\"format\": \"maven2\", \"type\": \"group\"}) | list)\n      }}\n\n- name: Process definitions for docker\n  when: nexus_config_docker | bool\n  block:\n\n    - name: apply defaults to docker proxy repos\n      set_fact:\n        nexus_repos_docker_proxy: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_docker_proxy -%}\n            {{ result.append(_nexus_repos_docker_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: apply defaults to docker hosted repos\n      set_fact:\n        nexus_repos_docker_hosted: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_docker_hosted -%}\n            {{ result.append(_nexus_repos_docker_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: apply defaults to docker group repos\n      set_fact:\n        nexus_repos_docker_group: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_docker_group -%}\n            {{ result.append(_nexus_repos_docker_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: Add docker repositories to global repos list\n      set_fact:\n        _nexus_repos_global_list: >-\n          {{\n            _nexus_repos_global_list | default([])\n            +\n            (nexus_repos_docker_proxy | map('combine', {\"format\": \"docker\", \"type\": \"proxy\"}) | list)\n            +\n            (nexus_repos_docker_hosted | map('combine', {\"format\": \"docker\", \"type\": \"hosted\"}) | list)\n            +\n            (nexus_repos_docker_group | map('combine', {\"format\": \"docker\", \"type\": \"group\"}) | list)\n          }}\n\n- name: Process definitions for pypi\n  when: nexus_config_pypi | bool\n  block:\n\n    - name: apply defaults to pypi proxy repos\n      set_fact:\n        nexus_repos_pypi_proxy: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_pypi_proxy -%}\n            {{ result.append(_nexus_repos_pypi_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: apply defaults to pypi hosted repos\n      set_fact:\n        nexus_repos_pypi_hosted: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_pypi_hosted -%}\n            {{ result.append(_nexus_repos_pypi_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: apply defaults to pypi group repos\n      set_fact:\n        nexus_repos_pypi_group: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_pypi_group -%}\n            {{ result.append(_nexus_repos_pypi_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: Add pypi repositories to global repos list\n      set_fact:\n        _nexus_repos_global_list: >-\n          {{\n            _nexus_repos_global_list | default([])\n            +\n            (nexus_repos_pypi_proxy | map('combine', {\"format\": \"pypi\", \"type\": \"proxy\"}) | list)\n            +\n            (nexus_repos_pypi_hosted | map('combine', {\"format\": \"pypi\", \"type\": \"hosted\"}) | list)\n            +\n            (nexus_repos_pypi_group | map('combine', {\"format\": \"pypi\", \"type\": \"group\"}) | list)\n          }}\n\n- name: Process definitions for raw repositories\n  when: nexus_config_raw | bool\n  block:\n\n    - name: apply defaults to raw proxy repos\n      set_fact:\n        nexus_repos_raw_proxy: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_raw_proxy -%}\n            {{ result.append(_nexus_repos_raw_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: apply defaults to raw hosted repos\n      set_fact:\n        nexus_repos_raw_hosted: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_raw_hosted -%}\n            {{ result.append(_nexus_repos_raw_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: apply defaults to raw group repos\n      set_fact:\n        nexus_repos_raw_group: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_raw_group -%}\n            {{ result.append(_nexus_repos_raw_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: Add raw repositories to global repos list\n      set_fact:\n        _nexus_repos_global_list: >-\n          {{\n            _nexus_repos_global_list | default([])\n            +\n            (nexus_repos_raw_proxy | map('combine', {\"format\": \"raw\", \"type\": \"proxy\"}) | list)\n            +\n            (nexus_repos_raw_hosted | map('combine', {\"format\": \"raw\", \"type\": \"hosted\"}) | list)\n            +\n            (nexus_repos_raw_group | map('combine', {\"format\": \"raw\", \"type\": \"group\"}) | list)\n          }}\n\n- name: Process definitions for rubygems repositories\n  when: nexus_config_rubygems | bool\n  block:\n\n    - name: apply defaults to rubygems proxy repos\n      set_fact:\n        nexus_repos_rubygems_proxy: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_rubygems_proxy -%}\n            {{ result.append(_nexus_repos_rubygems_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: apply defaults to rubygems hosted repos\n      set_fact:\n        nexus_repos_rubygems_hosted: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_rubygems_hosted -%}\n            {{ result.append(_nexus_repos_rubygems_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: apply defaults to rubygems group repos\n      set_fact:\n        nexus_repos_rubygems_group: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_rubygems_group -%}\n            {{ result.append(_nexus_repos_rubygems_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: Add rubygems repositories to global repos list\n      set_fact:\n        _nexus_repos_global_list: >-\n          {{\n            _nexus_repos_global_list | default([])\n            +\n            (nexus_repos_rubygems_proxy | map('combine', {\"format\": \"rubygems\", \"type\": \"proxy\"}) | list)\n            +\n            (nexus_repos_rubygems_hosted | map('combine', {\"format\": \"rubygems\", \"type\": \"hosted\"}) | list)\n            +\n            (nexus_repos_rubygems_group | map('combine', {\"format\": \"rubygems\", \"type\": \"group\"}) | list)\n          }}\n\n- name: Process definitions for bower repositories\n  when: nexus_config_bower | bool\n  block:\n\n    - name: apply defaults to bower proxy repos\n      set_fact:\n        nexus_repos_bower_proxy: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_bower_proxy -%}\n            {{ result.append(_nexus_repos_bower_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: apply defaults to bower hosted repos\n      set_fact:\n        nexus_repos_bower_hosted: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_bower_hosted -%}\n            {{ result.append(_nexus_repos_bower_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: apply defaults to bower group repos\n      set_fact:\n        nexus_repos_bower_group: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_bower_group -%}\n            {{ result.append(_nexus_repos_bower_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: Add bower repositories to global repos list\n      set_fact:\n        _nexus_repos_global_list: >-\n          {{\n            _nexus_repos_global_list | default([])\n            +\n            (nexus_repos_bower_proxy | map('combine', {\"format\": \"bower\", \"type\": \"proxy\"}) | list)\n            +\n            (nexus_repos_bower_hosted | map('combine', {\"format\": \"bower\", \"type\": \"hosted\"}) | list)\n            +\n            (nexus_repos_bower_group | map('combine', {\"format\": \"bower\", \"type\": \"group\"}) | list)\n          }}\n\n- name: Process definitions for npm repositories\n  when: nexus_config_npm | bool\n  block:\n\n    - name: apply defaults to npm proxy repos\n      set_fact:\n        nexus_repos_npm_proxy: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_npm_proxy -%}\n            {{ result.append(_nexus_repos_npm_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: apply defaults to npm hosted repos\n      set_fact:\n        nexus_repos_npm_hosted: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_npm_hosted -%}\n            {{ result.append(_nexus_repos_npm_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: apply defaults to npm group repos\n      set_fact:\n        nexus_repos_npm_group: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_npm_group -%}\n            {{ result.append(_nexus_repos_npm_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: Add npm repositories to global repos list\n      set_fact:\n        _nexus_repos_global_list: >-\n          {{\n            _nexus_repos_global_list | default([])\n            +\n            (nexus_repos_npm_proxy | map('combine', {\"format\": \"npm\", \"type\": \"proxy\"}) | list)\n            +\n            (nexus_repos_npm_hosted | map('combine', {\"format\": \"npm\", \"type\": \"hosted\"}) | list)\n            +\n            (nexus_repos_npm_group | map('combine', {\"format\": \"npm\", \"type\": \"group\"}) | list)\n          }}\n\n- name: Process definitions for nuget repositories\n  when: nexus_config_nuget | bool\n  block:\n\n    - name: apply defaults to nuget proxy repos\n      set_fact:\n        nexus_repos_nuget_proxy: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_nuget_proxy -%}\n            {{ result.append(_nexus_repos_nuget_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: apply defaults to nuget hosted repos\n      set_fact:\n        nexus_repos_nuget_hosted: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_nuget_hosted -%}\n            {{ result.append(_nexus_repos_nuget_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: apply defaults to nuget group repos\n      set_fact:\n        nexus_repos_nuget_group: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_nuget_group -%}\n            {{ result.append(_nexus_repos_nuget_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: Add nuget repositories to global repos list\n      set_fact:\n        _nexus_repos_global_list: >-\n          {{\n            _nexus_repos_global_list | default([])\n            +\n            (nexus_repos_nuget_proxy | map('combine', {\"format\": \"nuget\", \"type\": \"proxy\"}) | list)\n            +\n            (nexus_repos_nuget_hosted | map('combine', {\"format\": \"nuget\", \"type\": \"hosted\"}) | list)\n            +\n            (nexus_repos_nuget_group | map('combine', {\"format\": \"nuget\", \"type\": \"group\"}) | list)\n          }}\n\n- name: Process definitions for gitlfs repositories\n  when: nexus_config_gitlfs | bool\n  block:\n\n    - name: apply defaults to gitlfs hosted repos\n      set_fact:\n        nexus_repos_gitlfs_hosted: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_gitlfs_hosted -%}\n            {{ result.append(_nexus_repos_gitlfs_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: Add gitlfs repositories to global repos list\n      set_fact:\n        _nexus_repos_global_list: >-\n          {{\n            _nexus_repos_global_list | default([])\n            +\n            (nexus_repos_gitlfs_hosted | map('combine', {\"format\": \"gitlfs\", \"type\": \"hosted\"}) | list)\n          }}\n\n- name: Process definitions for yum repositories\n  when: nexus_config_yum | bool\n  block:\n\n    - name: apply defaults to yum proxy repos\n      set_fact:\n        nexus_repos_yum_proxy: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_yum_proxy -%}\n            {{ result.append(_nexus_repos_yum_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: apply defaults to yum hosted repos\n      set_fact:\n        nexus_repos_yum_hosted: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_yum_hosted -%}\n            {{ result.append(_nexus_repos_yum_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: apply defaults to yum group repos\n      set_fact:\n        nexus_repos_yum_group: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_yum_group -%}\n            {{ result.append(_nexus_repos_yum_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: Add yum repositories to global repos list\n      set_fact:\n        _nexus_repos_global_list: >-\n          {{\n            _nexus_repos_global_list | default([])\n            +\n            (nexus_repos_yum_proxy | map('combine', {\"format\": \"yum\", \"type\": \"proxy\"}) | list)\n            +\n            (nexus_repos_yum_hosted | map('combine', {\"format\": \"yum\", \"type\": \"hosted\"}) | list)\n            +\n            (nexus_repos_yum_group | map('combine', {\"format\": \"yum\", \"type\": \"group\"}) | list)\n          }}\n\n- name: Process definitions for apt repositories\n  when: nexus_config_apt | bool\n  block:\n\n    - name: apply defaults to apt proxy repos\n      set_fact:\n        nexus_repos_apt_proxy: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_apt_proxy -%}\n            {{ result.append(_nexus_repos_apt_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: apply defaults to apt hosted repos\n      set_fact:\n        nexus_repos_apt_hosted: >-\n          {%- set result=[] -%}\n          {%- for repo in nexus_repos_apt_hosted -%}\n            {{ result.append(_nexus_repos_apt_defaults | combine(repo)) }}\n          {%- endfor -%}\n          {{ result | to_json | from_json }}\n\n    - name: Add apt repositories to global repos list\n      set_fact:\n        _nexus_repos_global_list: >-\n          {{\n            _nexus_repos_global_list | default([])\n            +\n            (nexus_repos_apt_proxy | map('combine', {\"format\": \"apt\", \"type\": \"proxy\"}) | list)\n            +\n            (nexus_repos_apt_hosted | map('combine', {\"format\": \"apt\", \"type\": \"hosted\"}) | list)\n          }}\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "b4d65a74cf2c9ebe690a833e33c5e20de2a79cf5", "filename": "roles/ansible/tower/manage-credential-types/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- block: # when ansible_tower.credential_types is defined\n\n  - name: \"Set default values\"\n    set_fact:\n      processed_credential_types: []\n      existing_credential_types_output: []\n\n  # Utilize the `rest_get` library routine to ensure REST pagination is handled\n  - name: \"Get the existing credential types\"\n    rest_get:\n      host_url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}\"\n      rest_user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      rest_password: \"{{ ansible_tower.admin_password }}\"\n      api_uri: \"/api/v2/credential_types/\"\n    register: existing_credential_types_output\n\n  - name: \"Process the inventory credential types\"\n    include_tasks: process-credential-type.yml\n    with_items:\n    - \"{{ ansible_tower.credential_types }}\"\n    loop_control:\n      loop_var: credential_type\n\n  when:\n  - ansible_tower.credential_types is defined\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "84fd756c07b274e11c2a74094c74f483866faa99", "filename": "roles/network/templates/avahi/schoolserver.service", "repository": "iiab/iiab", "decoded_content": "<?xml version=\"1.0\" standalone='no'?><!--*-nxml-*-->\n<!DOCTYPE service-group SYSTEM \"avahi-service.dtd\">\n<service-group>\n<name replace-wildcards=\"yes\">MGMT console at %h </name>\n<service>\n<type>_https._tcp</type>\n<port>{{ gui_port }}</port>\n</service>\n</service-group>\n"}, {"commit_sha": "473bab1042b717eb6a6641b7240516af4dbae4d8", "sha": "3f8ba834fc9ba14c5771a2f877b359e1457fd2e8", "filename": "tasks/install.yml", "repository": "fubarhouse/ansible-role-golang", "decoded_content": "---\n- name: \"Go-Lang | Define shell exports\"\n  set_fact:\n    shell_exports:\n    - regex: \"export GOROOT={{ GOROOT }}\"\n      lineinfile: \"export GOROOT={{ GOROOT }}\"\n    - regex: \"export GOPATH={{ GOPATH }}/bin\"\n      lineinfile: \"export GOPATH={{ GOPATH }}/bin\"\n    - regex: \"export PATH=$PATH:{{ GOPATH }}/bin\"\n      lineinfile: \"export PATH=$PATH:{{ GOPATH }}/bin\"\n  when: shell_exports is not defined\n\n- name: \"Go-Lang | Ensure bootstrap directory is writable\"\n  become: yes\n  become_user: root\n  file:\n    path: \"{{ GOROOT_BOOTSTRAP }}\"\n    state: directory\n    owner: \"{{ fubarhouse_user }}\"\n    mode: 0755\n  when:\n   - GOROOT_BOOTSTRAP is defined\n   - install_go_bootstrap == true\n\n- name: \"Go-Lang | Get bootstrap distribution\"\n  git:\n    repo: \"https://github.com/golang/go.git\"\n    dest: \"{{ GOROOT_BOOTSTRAP }}\"\n    version: \"release-branch.go1.4\"\n    clone: yes\n    update: no\n  when:\n   - GOROOT_BOOTSTRAP is defined\n   - install_go_bootstrap == true\n\n- name: \"Go-Lang | Building Bootstrapper\"\n  shell: \"cd {{ GOROOT_BOOTSTRAP }}/src && ./{{ go_build_script }}\"\n  environment:\n    GOROOT_BOOTSTRAP: \"{{ GOROOT_BOOTSTRAP }}\"\n  when:\n   - GOROOT_BOOTSTRAP is defined\n   - install_go_bootstrap == true\n   - go_binary_bootstrap.stat.exists|bool == false\n\n- name: \"Go-Lang | Get distribution\"\n  become: yes\n  become_user: root\n  get_url:\n    url: \"{{ go_custom_mirror }}/{{ go_distribution_filename }}.tar.gz\"\n    dest: \"{{ go_temporary_dir }}/{{ go_distribution_filename }}.tar.gz\"\n    validate_certs: no\n\n- name: \"Go-Lang | Empty destination directory\"\n  become: yes\n  become_user: root\n  file:\n    path: \"{{ GOROOT }}\"\n    state: absent\n\n- name: \"Go-Lang | Ensure directory is writable\"\n  become: yes\n  become_user: root\n  file:\n    path: \"{{ GOROOT }}\"\n    state: directory\n    owner: \"{{ fubarhouse_user }}\"\n    mode: 0755\n    recurse: true\n\n- name: \"Go-Lang | Unpack distribution\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  unarchive:\n    src: \"{{ go_temporary_dir }}/{{ go_distribution_filename }}.tar.gz\"\n    dest: \"{{ go_temporary_dir }}\"\n    copy: \"no\"\n\n- name: \"Go-Lang | Moving to installation directory\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  synchronize:\n    src: \"{{ go_temporary_dir }}/go/\"\n    dest: \"{{ GOROOT }}\"\n    delete: yes\n    recursive: yes\n  delegate_to: \"{{ inventory_hostname }}\"\n  when: ansible_ssh_user is undefined\n\n- name: \"Go-Lang | Moving to installation directory\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  shell: \"cp -rf {{ go_temporary_dir }}/go/* {{ GOROOT }}/\"\n  when: ansible_ssh_user is defined\n\n- name: \"Go-Lang | Remove temporary data\"\n  become: yes\n  become_user: root\n  file:\n    path: \"{{ go_temporary_dir }}/go/\"\n    state: absent\n\n- name: \"Go-Lang | Build from source\"\n  shell: \"cd {{ GOROOT }}/src && ./{{ go_build_script }}\"\n  environment:\n    GOROOT: \"{{ GOROOT }}\"\n    GOPATH: \"{{ GOPATH }}\"\n    GOROOT_BOOTSTRAP: \"{{ GOROOT_BOOTSTRAP }}\"\n  when:\n   - GOROOT_BOOTSTRAP is defined\n   - build_go_from_source|bool == true\n\n- name: \"Go-Lang | Ensure shell profiles are available\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  file:\n    path: \"{{ fubarhouse_user_dir }}/{{ item }}\"\n    state: touch\n  with_items: \"{{ shell_profiles }}\"\n  failed_when: false\n  when: shell_exports is defined\n\n- name: \"Go-Lang | Ensure shell profiles are configured\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  lineinfile:\n    dest: \"{{ fubarhouse_user_dir }}/{{ item[0] }}\"\n    regexp: \"{{ item[1].regex }}\"\n    line: \"{{ item[1].lineinfile }}\"\n    state: present\n  with_nested:\n  - \"{{ shell_profiles }}\"\n  - \"{{ shell_exports }}\"\n  ignore_errors: yes\n  when: shell_exports is defined\n\n- name: \"Go-Lang | Verify version\"\n  shell: \"{{ GOPATH }}/go version\"\n  environment:\n    GOROOT: \"{{ GOROOT }}\"\n    GOPATH: \"{{ GOPATH }}\"\n  register: go_version_output\n  failed_when: '\"{{ go_version }}\" not in \"{{ go_version_output.stdout }}\"'\n  changed_when: false\n\n- name: \"Go-Lang | Restart shell\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  shell: \"{{ fubarhouse_user_dir }}/{{ item }}\"\n  with_items: \"{{ shell_profiles }}\"\n  failed_when: false\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "1b618c76b812dd2aebbf33f23444788216d62d02", "filename": "playbooks/files/bro-scripts-readme.txt", "repository": "rocknsm/rock", "decoded_content": "\nIt is recommened to put bro scripts in individual directories and use __load__.bro files.\n\nExample:\ndirectory = scripts/something\nscript = scripts/something/something.bro\nloader = scripts/something/__load__.bro\n\nThen in your custom.local.bro you can @load scripts/something\n"}, {"commit_sha": "49010188a985bfe713552eb8980cfa0d7a888daf", "sha": "dbe88f24aa3b9341e15b1d4d6a5b99319fd2affe", "filename": "roles/openshift-pv-cleanup/test/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n- hosts: seed-hosts\n  roles:\n  - openshift-pv-cleanup\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "0a8a46fb271f0befea18d2b99777b2f01e12eb45", "filename": "roles/osp/packstack-install/tasks/packstack-install.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Run packstack with the proper answer file\"\n  command: \"packstack --answer-file=''{{ answer_file }}''\"\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "2f8e1010d56f7bb4875ce9befc0ac6769fca0482", "filename": "playbooks/roles/check_docker_setup/templates/docker-storage-setup.j2", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "WIPE_SIGNATURES=true\nSTORAGE_DRIVER=overlay2\n{%if container_disk is defined%}\nDEVS=/dev/{{container_disk}}\n{%endif%}\nCONTAINER_ROOT_LV_NAME=dockerlv\nCONTAINER_ROOT_LV_SIZE=100%FREE\nCONTAINER_ROOT_LV_MOUNT_PATH=/var/lib/docker\nVG={{docker_vg}}\n"}, {"commit_sha": "64cbc6946b7ebc0d9a36f40d77ac86f8e3564499", "sha": "c20096c1cd48e2f990af9711283a68ddd8f22a5e", "filename": "tasks/service.yml", "repository": "CSCfi/ansible-role-slurm", "decoded_content": "---\n  - name: install slurm service specific packages\n    package: \"name={{ item }} state=present\"\n    with_items: \"{{ slurm_service_packages }}\"\n\n  - name: does the munge.key exist?\n    stat: path=/etc/munge/munge.key\n    register: mungekeystat\n    check_mode: no\n    ignore_errors: True\n\n  - name: create munge key\n    command: /usr/sbin/create-munge-key creates=/etc/munge/munge.key\n    register: mungekeygen\n    when: mungekeystat is defined and mungekeystat.stat.exists == False\n\n  - name: Fetch munge key from Service node for distribution to nodes\n    fetch: src=/etc/munge/munge.key\n           dest=files/munge.key\n           fail_on_missing=yes\n           flat=yes\n\n  - name: create slurm_munge_key_nfs_dir\n    file: path={{ slurm_munge_key_nfs_dir }} state=directory owner=root group={{ admingroup }} mode=0750\n    when: slurm_munge_key_to_nfs\n\n  - name: copy munge.key to slurm_munge_key_nfs_dir too\n    copy: src=files/munge.key dest={{ slurm_munge_key_nfs }} mode=0400 owner=munge group=munge\n    when: slurm_munge_key_to_nfs\n\n  - name: add slurm unix group\n    group: name=slurm system=no state=present\n    register: reg_slurm_unixgroup\n\n  - name: add slurm unix user\n    user: name=slurm shell=/sbin/nologin createhome=no system=no append=yes group=slurm state=present\n    register: reg_slurm_unixuser\n\n  - name: add slurm log dir\n    file: \"path={{ slurm_log_dir }} state=directory owner=slurm group=slurm mode=0750\"\n\n  - name: add slurm tmp dir\n    file: \"path={{ slurmd_tmp_dir }} state=directory owner=slurm group=slurm mode=0750\"\n\n  - name: add slurm state dir\n    file: \"path={{ slurm_state_dir }} state=directory owner=slurm group=slurm mode=0750\"\n\n  - name: add slurm etc dir\n    file: path=\"/etc/slurm\" state=directory owner=root group=root mode=0755\n\n  - name: Update NIS DB\n    command: /usr/bin/make -C /var/yp\n    when: nis_server and (reg_slurm_unixgroup.changed or reg_slurm_unixuser.changed)\n\n  - name: restart munge\n    service: name=munge state=restarted\n    when: mungekeygen.changed and mungekeygen is defined\n\n  - name: start and enable munge\n    service: name=munge state=started enabled=yes\n\n  - name: copy in munge key to slurm_accounting_storage_host too if it is different than the service node\n    copy: src=files/munge.key\n          dest=/etc/munge/munge.key\n          owner=munge\n          group=munge\n          mode=0400\n    delegate_to: \"{{ slurm_accounting_storage_host }}\"\n    when: slurm_accounting_storage_host != ansible_hostname\n    notify:\n     - restart munge\n\n  - name: start and enable munge on the slurm_accounting_storage_host too if it is different than the service node\n    service: name=munge state=started enabled=yes\n    delegate_to: \"{{ slurm_accounting_storage_host }}\"\n    when: slurm_accounting_storage_host != ansible_hostname\n\n  - name: Increase net.core.somaxconn for slurmctld\n    sysctl: name=net.core.somaxconn\n            value={{ slurm_sysctl_core_somaxconn }}\n            sysctl_file=/etc/sysctl.d/50-slurm.conf\n    when: slurm_manage_sysctl\n\n  - name: Increase net.ipv4.tcp_max_syn_backlog for slurmctld\n    sysctl: name=net.ipv4.tcp_max_syn_backlog\n            value={{ slurm_sysctl_tcp_max_syn_backlog }}\n            sysctl_file=/etc/sysctl.d/50-slurm.conf\n    when: slurm_manage_sysctl\n\n  - name: install Slurm ( state=present - not updating )\n    package: name={{ item }} state=present\n    with_items: \"{{ slurm_packages }}\"\n\n    # slurmdbd needs to be started after the slurm unix user is created\n  - name: start and enable slurmdbd on slurm_accounting_storage_host\n    service: name=slurmdbd state=started enabled=yes\n    delegate_to: \"{{ slurm_accounting_storage_host }}\"\n    when: slurm_accounting_storage_host != ansible_hostname\n\n  - name: start and enable slurmdbd\n    service: name=slurmdbd state=started enabled=yes\n    when: slurm_accounting_storage_host == ansible_hostname\n\n  - name: sacctmgr show cluster siteName and store in slurm_clusterlist variable\n    command: \"sacctmgr -n show cluster {{ siteName }}\"\n    register: slurm_clusterlist\n    check_mode: no\n    changed_when: False\n\n  - name: add cluster to accounting\n    command: \"sacctmgr -i add cluster {{ siteName }}\"\n    when: slurm_clusterlist.stdout.find(\"{{siteName}}\") == -1\n\n  - name: disable the slurm init script slurm on el7\n    service: name=slurm enabled=no\n    when: ansible_os_family == \"RedHat\" and ansible_distribution_major_version == \"7\"\n\n  - name: start and enable slurmctld\n    service: name={{ slurmctld_service }} state=started enabled=yes\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "b94ff11d4af8efe8c77fced0639bcd81831a038b", "filename": "roles/config-packages/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Install additional Software packages/tools'\n  package:\n    name: '{{ item }}'\n    state: installed\n  with_items:\n  - \"{{ list_of_packages_to_install }}\"\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "853ef5b5f583d0449e6b5b64e4e959a7908dce4d", "filename": "roles/config-vnc-server/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nvnc_home_dir: '/home'\n"}, {"commit_sha": "49010188a985bfe713552eb8980cfa0d7a888daf", "sha": "74b4609d46b85fbfe4640115ec58474aa12e24d2", "filename": "roles/openshift-pv-cleanup/README.md", "repository": "redhat-cop/casl-ansible", "decoded_content": "# openshift-pv-cleanup\n\nThe purpose of this role is to clean up persistent volumes in a cluster before decommisioning a cluster.\n\n## Usage\n\n```\nansible-playbook -i inventory roles/openshift-pv-cleanup/test/main.yml\n```\n"}, {"commit_sha": "a5a5c4d74b7b0fd14f534dda1f41f903d1a58abf", "sha": "d41bdc3c772d2fb6fa64821d717614bc361422b9", "filename": "tasks/nodejs.yml", "repository": "fubarhouse/ansible-role-nodejs", "decoded_content": "---\n# Tasks file for NodeJS\n\n- name: \"NodeJS | Check\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  shell:  \"{{ fubarhouse_npm.nvm_symlink_exec }} ls | cat\"\n  register: installed_nodejs_versions\n  changed_when: false\n\n- name: \"NodeJS | Install all requested versions\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  shell:  \"{{ fubarhouse_npm.nvm_symlink_exec }} install {{ item }}\"\n  when: '\"{{ item }}\" in nodejs_available_versions.stdout and item not in installed_nodejs_versions.stdout'\n  with_items:\n  - \"{{ node_version }}\"\n  - \"{{ node_versions }}\"\n\n- name: \"NodeJS | Switching\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  shell:  \"{{ fubarhouse_npm.nvm_symlink_exec }} use {{ node_version }}\"\n  register: fubarhouse_npm_switch\n  changed_when: false\n  when: '\"{{ node_version }}\" in nodejs_available_versions.stdout'\n\n- name: \"NodeJS | Linking\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  shell: \"{{ fubarhouse_npm.nvm_symlink_exec }} alias default {{ node_version }}\"\n  changed_when: false\n  when: '\"{{ node_version }}\" in nodejs_available_versions.stdout'\n\n- name: \"NodeJS | Linking binaries\"\n  file:\n    src: \"{{ fubarhouse_npm.user_dir }}/.nvm/v{{ node_version }}/bin/{{ item }}\"\n    dest: \"/usr/local/bin/{{ item }}\"\n    state: link\n    force: yes\n  with_items:\n    - node\n    - npm\n  when: '\"{{ node_version }}\" in nodejs_available_versions.stdout'\n\n- name: \"NodeJS | Import exports\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  lineinfile:\n    dest: \"{{ fubarhouse_npm.user_dir }}/{{ item.filename }}\"\n    line: \"export PATH=$PATH:$(npm config --global get prefix)/bin\"\n    state: present\n  with_items: \"{{ fubarhouse_npm.shell_profiles }}\"\n  when: '\"{{ node_version }}\" in nodejs_available_versions.stdout'\n\n- name: \"NodeJS | Verify version in use\"\n  shell: \"{{ fubarhouse_npm.nvm_symlink_exec }} ls | grep current | cat\"\n  register: node_current_version\n  changed_when: false\n  failed_when: 'node_current_version.stdout.find(\"{{ node_version }}\") == -1'\n  when: '\"{{ node_version }}\" in nodejs_available_versions.stdout'"}, {"commit_sha": "b7c6bfe0369646ca69beeb3dfe07e8218d61c940", "sha": "0017e3f68e83f6aff528a3d0fffe59f39ea9f02e", "filename": "tasks/modprobe.yml", "repository": "dev-sec/ansible-os-hardening", "decoded_content": "---\n- name: install modprobe to disable filesystems | os-10\n  package:\n    name: '{{modprobe_package}}'\n    state: 'present'\n\n- name: disable unused filesystems | os-10\n  template:\n    src: 'modprobe.j2'\n    dest: '/etc/modprobe.d/dev-sec.conf'\n    owner: 'root'\n    group: 'root'\n    mode: '0640'\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "b1696228bfcaded0173ec7b39b08f8863dd9e6bf", "filename": "roles/user-management/manage-idm-users/tests/create_idm.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n# This test covers the full feature set provided by the role\n\n- name: Create Test Identities\n  hosts: ipa\n\n  vars_files:\n    - vars/idm.json\n\n  vars:\n    ipa_admin_user: admin\n    ipa_admin_password: test123\n    ipa_host: idm.example.com \n\n  roles:\n    - manage-idm-users\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "81c7efe8beb50387bb83e2c678ebc935b4fc7784", "filename": "roles/activity-server/files/lang_templates/ht/activity", "repository": "iiab/iiab", "decoded_content": "<div class=\"olpc-activity-info\">\n<h2>%(name)s</h2>\n%(description)s\n<ul>\n <li>Pou idantifye: <span class=\"olpc-activity-id\">%(bundle_id)s</span></li>\n <li>Vesyon: <span class=\"olpc-activity-version\">%(activity_version)s</span></li>\n <li>URL: <span class=\"olpc-activity-url\"><a href=\"%(bundle_url)s\">%(bundle_url)s</a></span></li>\n <li style=\"display: %(show_older_versions)s\">Vesyon ansyen: %(older_versions)s</li>\n</ul>\n</div>\n"}, {"commit_sha": "49010188a985bfe713552eb8980cfa0d7a888daf", "sha": "5b0072226fb63623b0125fb7e476cfa23bf5f075", "filename": "roles/openshift-route-status/tasks/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n- name: \"Lookup route url for {{ route }}\"\n  shell: \"oc get route {{ route }} -o jsonpath='{ .spec.host }'\"\n  register: url\n  when:\n  - route is defined\n  - route|trim != ''\n\n- name: \"Set default delay time\"\n  set_fact:\n    delay: \"{{ delay | default(5) }}\"\n\n- name: \"Set default number of retries\"\n  set_fact:\n    retries: \"{{ retries | default(3) }}\"\n\n- name: \"Wait for {{ protocol }}://{{ url.stdout }} to respond with status: {{ status }}\"\n  uri:\n    url: \"{{ protocol }}://{{ url.stdout }}\"\n  register: rc\n  until: rc.status|trim|int == status|trim|int\n  retries: \"{{ retries|int }}\"\n  delay: \"{{ delay|int }}\"\n  when:\n  - url.stdout is defined\n  - url.stdout|trim != ''\n  - protocol is defined\n  - protocol|trim != ''\n  - status is defined\n  - status|trim != ''\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "ff1a1c7f845b541d0b66e212a2cacc9043616c05", "filename": "roles/manage-confluence-space/tasks/prepare_confluence_vars.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Verify source and destination dictionaries exist\n  fail:\n    msg: \"This role requires that the following dictionaries exist: atlassian.confluence.source, atlassian.confluence.destination\"\n  when:\n    - (atlassian.confluence.source|trim == \"\") or (atlassian.confluence.destination|trim == \"\")\n\n- name: Set Confluence Credentials\n  set_fact:\n    confluence_source_username: \"{{ atlassian.confluence.source.username | default(atlassian.username) }}\"\n    confluence_source_password: \"{{ atlassian.confluence.source.password | default(atlassian.password) }}\"\n    confluence_destination_username: \"{{ atlassian.confluence.destination.username | default(atlassian.username) }}\"\n    confluence_destination_password: \"{{ atlassian.confluence.destination.password | default(atlassian.password) }}\"\n\n- name: Set Confluence URL\n  set_fact:\n    confluence_source_url: \"{{ atlassian.confluence.source.url | default(atlassian.url) }}\"\n    confluence_destination_url: \"{{ atlassian.confluence.destination.url | default(atlassian.url) }}\"\n\n- name: Fail when Confluence credentials are not set\n  fail:\n    msg: \"This role requires the following variables to be set: confluence_source_username, confluence_source_password, confluence_destination_username, confluence_destination_password.\"\n  when:\n    - (confluence_source_username|trim == \"\") or (confluence_source_password|trim == \"\") or\n      (confluence_destination_username|trim == \"\") or (confluence_destination_password|trim == \"\")\n\n- name: Fail when Confluence url is not set\n  fail:\n    msg: \"This role requires the following variables to be set: confluence_source_url, confluence_destination_url.\"\n  when:\n    - (confluence_source_url|trim == \"\") or (confluence_destination_url|trim == \"\")\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "e69de29bb2d1d6434b8b29ae775ad8c2e48c5391", "filename": "roles/prometheus/handlers/main.yml", "repository": "Capgemini/Apollo", "decoded_content": ""}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "5ab515000589019525353bf0c00198a43706e2ba", "filename": "roles/sugarizer/templates/sugarizer.ini", "repository": "iiab/iiab", "decoded_content": "; Sugarizer configuration file\n\n[web]\nport = 8089\n\n[database]\nserver = localhost\nport = 27018\nname = sugarizer\n\n[presence]\nport = 8039\n\n[collections]\nusers = users\njournal = journal\n\n[activities]\nactivities_directory_name = activities\nactivities_path = ../activities\ntemplate_directory_name = ActivityTemplate\nactivity_info_path = activity/activity.info\nfavorites = org.sugarlabs.GearsActivity,org.sugarlabs.MazeWebActivity,org.olpcfrance.PaintActivity,org.olpcfrance.TamTamMicro,org.olpcfrance.MemorizeActivity,org.olpg-france.physicsjs,org.sugarlabs.CalculateActivity,org.sugarlabs.TurtleBlocksJS,org.sugarlabs.Clock,,org.olpcfrance.RecordActivity,org.olpcfrance.Abecedarium,org.olpcfrance.KAView,org.olpcfrance.FoodChain,org.olpc-france.labyrinthjs,org.olpcfrance.TankOp,org.sugarlabs.ChatPrototype,org.olpcfrance.Gridpaint,org.olpc-france.LOLActivity,org.sugarlabs.StopwatchActivity,org.sugarlabs.GTDActivity,org.sugarlabs.Markdown,org.laptop.WelcomeWebActivity\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "cb32c7943ef502b439b2a66df73c82def92b81bd", "filename": "roles/config-iscsi-client/tasks/lvm-config.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- include_tasks: configure_lvm.yml\n  loop_control:\n    loop_var: disk\n  with_items:\n  - \"{{ disk_mapping }}\"\n\n- name: \"Updated PV metadata\"\n  command: 'pvscan --cache'\n  when:\n  - disk_mapping|length > 0\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "49cd8619ba2fa0d377375b1d5b4be463b31a2513", "filename": "roles/config-quay-enterprise/tasks/firewall.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Check if firewalld is installed\n  command: systemctl status firewalld\n  register: firewalld_status\n  failed_when: false\n  changed_when: false\n\n- name: Check if iptables is installed\n  command: systemctl status iptables\n  register: iptables_status\n  failed_when: false\n  changed_when: false\n\n- name: Open port in firewalld\n  firewalld:\n    port: \"{{ item }}/tcp\"\n    permanent: true\n    state: enabled\n  when: firewalld_status.rc == 0\n  with_items:\n    - \"{{ quay_host_http_port }}\"\n    - \"{{ quay_host_https_port }}\"\n  notify:\n  - restart firewalld\n\n- name: Open iptables Quay firewall ports for future sessions\n  lineinfile:\n    insertbefore: \"-A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT\"\n    state: present\n    dest: /etc/sysconfig/iptables\n    regexp: \"^-A INPUT .* --dport {{ item }} .* ACCEPT\"\n    line: \"-A INPUT -p tcp -m state --state NEW -m tcp --dport {{ item }} -j ACCEPT\"\n  with_items:\n    - \"{{ quay_host_http_port }}\"\n    - \"{{ quay_host_https_port }}\"\n  when: iptables_status.rc == 0 and firewalld_status.rc != 0\n  # notify:\n  # - restart iptables\n\n- name: Open iptables Quay firewall ports for current session\n  iptables:\n    action: insert\n    protocol: tcp\n    destination_port: \"{{ item }}\"\n    state: present\n    chain: INPUT\n    jump: ACCEPT\n  with_items:\n    - \"{{ quay_host_http_port }}\"\n    - \"{{ quay_host_https_port }}\"\n  when: iptables_status.rc == 0 and firewalld_status.rc != 0\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "19431853679443b7c7fdec8427a483da0a2b073d", "filename": "playbooks/files/broctl.sh", "repository": "rocknsm/rock", "decoded_content": "#!/usr/bin/bash\n\n# broctl should ALWAYS run as the bro user!\nsudo -u bro /opt/bro/bin/broctl $@\n\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "3208285bbef12ebf0a66d4cd669a882d35ac5fda", "filename": "tasks/Linux/fetch/sapjvm-fallback.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: 'Fetch root page {{ sapjvm_root_page }}'\n  uri:\n    url: '{{ sapjvm_root_page }}'\n    return_content: true\n  register: root_page\n\n- name: Find release url\n  set_fact:\n    release_url: >-\n      {{ root_page['content']\n        | regex_findall('(additional/sapjvm-'\n          + java_major_version|string\n          + '[\\d.]+-linux-x64.zip)')\n      }}\n\n- name: 'Download artifact from {{ release_url[0] }}'\n  get_url:\n    url: '{{ sapjvm_root_page }}/{{ release_url[0] }}'\n    dest: '{{ java_download_path }}'\n    headers:\n      Cookie: eula_3_1_agreed=tools.hana.ondemand.com/developer-license-3_1.txt\n  register: file_downloaded\n  retries: 20\n  delay: 5\n  until: file_downloaded is succeeded\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "4b79ca68c652f44d2e665eff5be7cf547ee7e074", "filename": "roles/manage-confluence-space/tasks/create_confluence_space.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Create Confluence Space\n  uri:\n    url: '{{ confluence_destination_url }}/wiki/rest/api/space'\n    method: POST\n    user: '{{ confluence_destination_username }}'\n    password: '{{ confluence_destination_password }}'\n    force_basic_auth: yes\n    status_code: 200\n    body_format: json\n    body: \"{{ lookup('template', 'space.j2') }}\"\n  register: space_content\n\n- name: set fact\n  set_fact:\n    destination_homepage_id: \"{{ space_content.json['homepage']['id']}}\"\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "21c708a88654a181a61ab5acdfb0ff613f37bb0d", "filename": "roles/update-host/tasks/reboot-host.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Reboot the host\"\n  shell: sleep 5 && shutdown -r now \"Ansible Reboot of host\"\n  async: 1\n  poll: 0\n  ignore_errors: true\n  when:\n    - host_updated.changed or force_host_reboot\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "4221a456423eafeade8450a9bff17c522c43d81f", "filename": "playbooks/osp/README.md", "repository": "redhat-cop/infra-ansible", "decoded_content": "# OpenStack Platform (OSP) related playbooks\n\nThese playbooks are mean to assist with creating OpenStack Platform objects in an automated way. Please checkout the `osp/admin-*` roles for management of individual features of the platform, while playbooks with various combinations of these roles are managed in this director.\n\n\n## Prerequisites\n\n1. A valid OpenStack RC file, with the proper access rights to an OpenStack tenant, needs to be sourced before using this role.\n1. The `openstack` python shade packages to allow for interactions with the platform.\n\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "0348d9dc8ed13195ac7c462b7e09517253645122", "filename": "tasks/section_05_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 5.1.1 Ensure NIS is not installed (Scored)\n    apt: name=nis state=absent purge=yes\n    tags:\n    - section5\n    - section5.1\n    - section5.1.1\n\n  - name: 5.1.2 Ensure rsh, rlogin, rexec, talk, telnet, chargen, daytime, echo, discard, time is not enabled (stat inetd) (Scored)\n    stat: path=/etc/inetd.conf\n    register: inetd_path\n    tags:\n    - section5\n    - section5.1\n    - section5.1.2\n\n  - name: 5.1.2-.6 Ensure rsh, rlogin, rexec, talk, telnet, chargen, daytime, echo, discard, time is not enabled (Scored)\n    lineinfile: >\n        dest=/etc/inetd.conf\n        regexp='^({{ item }}.*)'\n        line='#\\1'\n        state=present\n        backrefs=yes\n        backup=yes\n    with_items:\n        - shell\n        - login\n        - exec\n        - talk\n        - ntalk\n        - telnet\n        - chargen\n        - daytime\n        - echo\n        - discard\n        - time\n    when: inetd_path.stat.exists == True\n    tags:\n    - section5\n    - section5.1\n    - section5.1.2\n\n  - name: 5.1.3.1 Ensure rsh client is not installed (Scored)\n    apt: name=rsh-client state=absent purge=yes\n    tags:\n    - section5\n    - section5.1\n    - section5.1.3\n    - section5.1.3.1\n\n  - name: 5.1.3.2 Ensure rsh client is not installed (Scored)\n    apt: name=rsh-redone-client state=absent purge=yes\n    tags:\n    - section5\n    - section5.1\n    - section5.1.3\n    - section5.1.3.2\n\n  - name: 5.1.5 Ensure talk client is not installed (Scored)\n    apt: name=talk state=absent purge=yes\n    tags:\n    - section5\n    - section5.1\n    - section5.1.5\n\n  - name: 5.1.8 Ensure xinetd is not enabled (stat xinetd) (Scored)\n    stat: path=/etc/init/xinetd.conf\n    register: xinetd_path\n    tags:\n    - section5\n    - section5.1\n    - section5.1.8\n\n  - name: 5.1.8 Ensure xinetd is not enabled (Scored)\n    lineinfile: >\n        dest=/etc/init/xinetd.conf\n        regexp='start on runlevel'\n        state=present\n        line='#start on runlevel [2345]'\n    when: xinetd_path.stat.exists == True\n    tags:\n    - section5\n    - section5.1\n    - section5.1.8\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "ec017fbd958ddbe48c01b4a6e1e6e0fbcbabe7bc", "filename": "tasks/Linux/fetch/repositories.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: 'Install {{ java_distribution }} from repositories'\n  debug:\n    msg: 'Install {{ java_distribution }} from repositories'\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "9d0ac05e9365231217812d8fbe813b8035729125", "filename": "roles/monit/templates/idmgr", "repository": "iiab/iiab", "decoded_content": "check process idmgr with pidfile /var/run/idmgr.pid\n   start program = \"/sbin/service idmgr start\" \n   stop program = \"/sbin/service idmgr stop\" \n   if cpu > 60% for 3 cycles then restart\n   if totalmem > 200.0 MB for 3 cycles then restart \n   if failed host localhost port 8080 type tcp then restart\n   if 3  restarts within 5 cycles then timeout\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "a0536b777cf4de49cf17aabe595c5f8a79b9d1ec", "filename": "tasks/create_repo_rubygems_hosted_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_rubygems_hosted\n    args: \"{{ _nexus_repos_rubygems_defaults|combine(item) }}\"\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "28dd21fbc364a3e144178c7b2996562b425b9bc4", "filename": "archive/roles/cicd/tasks/java.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n  \n- name: Install Java\n  yum:\n    enablerepo: rhel-7-server-thirdparty-oracle-java-rpms\n    name: java-1.8.0-oracle-devel\n    state: present\n  tags: java\n  \n- name: Determine Java Home Location\n  shell: alternatives --list | grep jre_oracle | awk '{ print $3 }'\n  register: java_root\n  failed_when: java_root == \"\"\n  tags: java\n\n\n# TODO: Configure Custom Certificates \n "}, {"commit_sha": "d25113e8fab871b2ead95ca976c5a43e4759ea26", "sha": "03c6b8217beb504b787aed8744f319374605454b", "filename": "tasks/mms-agent.yml", "repository": "UnderGreen/ansible-role-mongodb", "decoded_content": "---\n\n- name: Install MMS agent pt. 1\n  get_url: url={{mongodb_mms_agent_pkg}} dest={{mongodb_conf_dbpath}}/mms-agent.deb\n  register: mongodb_mms_agent_loaded\n\n- name: Install MMS agent pt. 2\n  apt: deb={{mongodb_conf_dbpath}}/mms-agent.deb\n  when: mongodb_mms_agent_loaded.changed\n\n- name: Configure the MMS agent pt. 1\n  file: state=directory path=/etc/mongodb-mms owner={{mongodb_user}} group={{mongodb_user}} mode=0755\n\n- name: Configure the MMS agent pt. 2\n  template: src=automation-agent.config.j2 dest=/etc/mongodb-mms/automation-agent.config\n  notify: mongodb-mms-automation-agent restart\n\n- name: Ensure that the MMS agent is started\n  service: name=mongodb-mms-automation-agent state=started enabled=yes\n"}, {"commit_sha": "abafe1581c6c78d784cf215b214947675d49eff8", "sha": "ff7871612ae93207ac5990d3af8e27f23513fac4", "filename": "roles/ssh_tunneling/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- name: Ensure that the sshd_config file has desired options\n  blockinfile:\n    dest: /etc/ssh/sshd_config\n    marker: '# ANSIBLE_MANAGED_ssh_tunneling_role'\n    block: |\n      Match Group algo\n          AllowTcpForwarding local\n          AllowAgentForwarding no\n          AllowStreamLocalForwarding no\n          PermitTunnel no\n          X11Forwarding no\n  notify:\n    - restart ssh\n\n- name: Ensure that the algo group exist\n  group: name=algo state=present\n\n- name: Ensure that the jail directory exist\n  file: path=/var/jail/ state=directory mode=0755  owner=root group=root\n\n- name: Ensure that the SSH users exist\n  user:\n    name: \"{{ item }}\"\n    groups: algo\n    home: '/var/jail/{{ item }}'\n    createhome: yes\n    generate_ssh_key: yes\n    shell: /bin/false\n    ssh_key_type: rsa\n    ssh_key_bits: 2048\n    ssh_key_comment: '{{ item }}@{{ IP_subject_alt_name }}'\n    ssh_key_passphrase: \"{{ easyrsa_p12_export_password }}\"\n    state: present\n    append: yes\n  with_items: \"{{ users }}\"\n\n- name: The authorized keys file created\n  file:\n    src: '/var/jail/{{ item }}/.ssh/id_rsa.pub'\n    dest: '/var/jail/{{ item }}/.ssh/authorized_keys'\n    owner: \"{{ item }}\"\n    group: \"{{ item }}\"\n    state: link\n  with_items: \"{{ users }}\"\n\n- name: Generate SSH fingerprints\n  shell: >\n    ssh-keyscan {{ IP_subject_alt_name }} 2>/dev/null\n  register: ssh_fingerprints\n\n- name: The known_hosts file created\n  template: src=known_hosts.j2 dest=/root/.ssh/{{ IP_subject_alt_name }}_known_hosts\n\n- name: Fetch users SSH private keys\n  fetch: src='/var/jail/{{ item }}/.ssh/id_rsa' dest=configs/{{ IP_subject_alt_name }}_{{ item }}.ssh.pem flat=yes\n  with_items: \"{{ users }}\"\n\n- name: Change mode for SSH private keys\n  local_action: file path=configs/{{ IP_subject_alt_name }}_{{ item }}.ssh.pem mode=0600\n  with_items: \"{{ users }}\"\n  become: false\n\n- name: Fetch the known_hosts file\n  fetch: src='/root/.ssh/{{ IP_subject_alt_name }}_known_hosts' dest=configs/{{ IP_subject_alt_name }}_known_hosts flat=yes\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "f9f1dd048c26fa0f1c20a9fbf24fd82c6595f274", "filename": "roles/user-management/list-users-by-group/tests/inventory/group_vars/manage-users-host.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nusers:\n- user_name: user1\n  first_name: user\n  last_name: one\n  email: user1@example.com\n- user_name: user2\n  first_name: user\n  last_name: two\n  email: user2@example.com\n- user_name: user3\n  first_name: user\n  last_name: three\n  email: user3@example.com\n- user_name: user4\n  first_name: user\n  last_name: four\n  email: user4@example.com\n- user_name: user5\n  first_name: user\n  last_name: five\n  email: user5@example.com\n\nuser_groups:\n- name: group1\n  members:\n  - user1\n  - user2\n  - user3\n- name: group2\n  members:\n  - user2\n  - user4\n  - user5\n\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "811ac7a54742e360e6eb383d430c99eadcca00b0", "filename": "roles/deploy/tasks/prepare.yml", "repository": "roots/trellis", "decoded_content": "---\n- include: \"{{ deploy_prepare_before | default('../hooks/example.yml') }}\"\n  tags: deploy-prepare-before\n\n- name: write unfinished file\n  file:\n    path: \"{{ project_source_path }}/{{ deploy_helper.unfinished_filename }}\"\n    state: touch\n\n- name: Check for project repo subtree\n  stat:\n    path: \"{{ project_source_path }}/{{ project.repo_subtree_path }}\"\n  register: project_subtree_full_path\n  when: project.repo_subtree_path is defined\n\n- name: Fail if repo_subtree_path is set incorrectly\n  fail:\n    msg: \"repo subtree is set to '{{ project.repo_subtree_path }}' but that path does not exist in the repo. Edit `repo_subtree_path` for '{{ site }}' in `wordpress_sites.yml`.\"\n  when: project_subtree_full_path is defined and not project_subtree_full_path.stat.exists\n\n- name: Create new release dir\n  file:\n    path: \"{{ deploy_helper.new_release_path }}\"\n    state: directory\n\n- name: Run git archive to populate new build dir\n  shell: git archive {{ project_version }} | tar xf - -C {{ deploy_helper.new_release_path }}\n  args:\n    chdir: \"{{ project_source_path }}\"\n  when: project.repo_subtree_path is not defined\n\n- name: Run git archive with subdirectory to populate new build dir\n  shell: git archive {{ project_version }} {{ project.repo_subtree_path }} | tar -x --strip-components {{ project.repo_subtree_path.split('/') | count }} -f - -C {{ deploy_helper.new_release_path }}\n  args:\n    chdir: \"{{ project_source_path }}\"\n  when: project.repo_subtree_path is defined\n\n- include: \"{{ deploy_prepare_after | default('../hooks/example.yml') }}\"\n  tags: deploy-prepare-after\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "4eec57a1bbc67f56887025e00196babb6b0d73c3", "filename": "roles/config-iscsi-client/tests/group_vars/iscsi.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\niscsi_target: \"192.168.1.21\"\niscsi_brand: \"NETAPP\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "21997784b76d92b3c2c57887cf4d5361b1cd1a95", "filename": "roles/wordpress/tasks/install.yml", "repository": "iiab/iiab", "decoded_content": "- name: Get the WordPress software\n  get_url: url=\"{{ wordpress_download_base_url }}/{{ wordpress_src }}\"  dest={{ downloads_dir }}/\n  register: wp_download_output\n  when: internet_available\n\n- name: Copy it to permanent location /library\n  unarchive: src={{ wp_download_output.dest }}  dest=/library\n  when: internet_available\n\n- name: Rename /library/wordpress* to /library/wordpress\n  shell: if [ ! -d {{ wp_abs_path }} ]; then mv {{ wp_abs_path }}* {{ wp_abs_path }}; fi\n\n# First pass at permissions and ownership\n- name: Make apache owner and group\n  file: path={{ wp_abs_path }}\n        recurse=yes\n        owner=root\n        group={{ apache_user }}\n        mode=0664\n        state=directory\n\n- name: Make directories 775 so apache can traverse and write\n  command: \"/usr/bin/find {{ wp_abs_path }} -type d -exec chmod 775 {} +\"\n\n- name: Copy wp salt values\n  copy: src=wp-keys.php.BAK\n        dest={{ wp_abs_path }}/wp-keys.php.BAK\n        owner=root\n        group={{ apache_user }}\n        mode=0640\n\n# Fetch random salts for WordPress config into wp-keys.php file by generating script and running\n\n- name: Create wp salt script\n  template: src=get-iiab-wp-salts.j2\n            dest=/tmp/get-iiab-wp-salts\n            owner=root\n            group=root\n            mode=0700\n\n- name: Run wp salt script to create /library/wordpress/wp-keys.php\n  command: /tmp/get-iiab-wp-salts\n\n- name: Cleanup - remove wp salt script\n  file: path=/tmp/get-iiab-wp-salts\n        state=absent\n\n- name: mysql database needs to be running if we are trying to create a new db\n  service: state=started\n           name='{{ mysql_service }}'\n\n- name: Create mysql wordpress database\n  mysql_db: name={{ wp_db_name }}\n            state=present\n\n- name: Create mysql wordpress database user\n  mysql_user: name={{ wp_db_user }}\n              password={{ wp_db_user_password }}\n              priv={{ wp_db_name }}.*:ALL,GRANT\n              state=present\n\n- name: Copy WordPress config file\n  template: src=wp-config.php.j2\n            dest={{ wp_abs_path }}/wp-config.php\n            owner=root\n            group={{ apache_user }}\n            mode=0660\n\n- name: Copy WordPress httpd conf file\n  template: src=wordpress.conf.j2\n            dest=/etc/{{ apache_config_dir }}/wordpress.conf\n\n- name: Enable httpd conf file if we are disabled\n  file: path=/etc/apache2/sites-enabled/wordpress.conf\n        src=/etc/apache2/sites-available/wordpress.conf\n        state=link\n  when: wordpress_enabled and is_debuntu\n\n\n- name: Remove httpd conf file if we are disabled\n  file: path=/etc/apache2/sites-enabled/wordpress.conf\n        state=absent\n  when: not wordpress_enabled and is_debuntu\n\n- name: Restart apache, so it picks up the new aliases\n  service: name={{ apache_service }} state=restarted\n\n- name: Add wordpress to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=wordpress\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: wordpress\n    - option: description\n      value: '\"WordPress is a blog and web site management application.\"'\n    - option: wordpress_src\n      value: \"{{ wordpress_src }}\"\n    - option: wp_abs_path\n      value: \"{{ wp_abs_path }}\"\n    - option: wp_db_name\n      value: \"{{ wp_db_name }}\"\n    - option: wp_db_user\n      value: \"{{ wp_db_user }}\"\n    - option: wp_url\n      value: \"{{ wp_url }}\"\n    - option: wp_full_url\n      value: \"{{ wp_full_url }}\"\n    - option: wordpress_enabled\n      value: \"{{ wordpress_enabled }}\"\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "85da1ebd57d4185afd213539ef3c629652e78a94", "filename": "roles/client/tasks/systems/main.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- include: Debian.yml\n  when: ansible_distribution == 'Debian'\n\n- include: Ubuntu.yml\n  when: ansible_distribution == 'Ubuntu'\n\n- include: CentOS.yml\n  when: ansible_distribution == 'CentOS'\n\n- include: Fedora.yml\n  when: ansible_distribution == 'Fedora'\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "50c684bcfaa2f73e9e96f5aeacef07f5496144ec", "filename": "roles/create_users/tasks/create_users.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n - name: \"Create {{ users.num_users }} htpasswd users\"\n   htpasswd:\n     path: \"{{ users.passwd_file }}\"\n     name: \"{{ item }}\"\n     password: \"{{ users.password }}\"\n     owner: root\n     group: root\n     mode: 0600\n   with_sequence: start=0 end=\"{{ users.num_users }}\" format=\"{{ users.prefix }}%02d\"\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "7f87ca8a2d9dba6ac66d37b0338d67927156b581", "filename": "roles/osp/packstack-post/tasks/cinder.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# This is a workaround for iptables config \"bug\" whereas the IPs are wrong for\n# iSCSI traffic (i.e.: using the wrong interface)\n- name: \"Update iptables config to use correct interfaces\"\n  replace:\n    path: \"/etc/sysconfig/iptables\"\n    regexp: '-A INPUT -s {{ hostvars[item].mgmt_net_ip }}/32 -p tcp -m multiport --dports 3260 -m comment --comment \"001 cinder incoming cinder_{{ hostvars[item].mgmt_net_ip }}\" -j ACCEPT'\n    replace: '-A INPUT -s {{ hostvars[item].storage_net_ip }}/32 -p tcp -m multiport --dports 3260 -m comment --comment \"001 cinder incoming cinder_{{ hostvars[item].storage_net_ip }}\" -j ACCEPT'\n  with_items:\n  - \"{{ ansible_play_hosts }}\"\n  notify:\n  - 'restart iptables'\n\n- name: \"Configure Cinder\"\n  ini_file:\n    path: \"/etc/cinder/cinder.conf\"\n    section: \"{{ item.0.section }}\"\n    option: \"{{ item.1.option }}\"\n    value: \"{{ item.1.value }}\"\n  with_subelements:\n  - \"{{ cinder_config }}\"\n  - params\n  notify:\n  - 'restart openstack-cinder-api'\n  - 'restart openstack-cinder-backup'\n  - 'restart openstack-cinder-scheduler'\n  - 'restart openstack-cinder-volume'\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "6ae8dd6bcea3a10ecb3b9f055b9156b318aefd45", "filename": "roles/openvpn/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "vpn_presence: xscenet.net\nopenvpn_server_virtual_ip: 10.8.0.1\nopenvpn_server_port: 1194\nopenvpn_install: True\nopenvpn_enable: False\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "6db7a4f64b467e2b1e76d53807b64626c46d01d3", "filename": "roles/manage-sshd-config/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'reload sshd'\n  service:\n    name: '{{ item }}'\n    state: restarted\n  with_items:\n  - sshd\n\n"}, {"commit_sha": "abafe1581c6c78d784cf215b214947675d49eff8", "sha": "e6d614b7bb5e15d73e12ad3e3a6258d40ed79a79", "filename": "roles/security/handlers/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: restart ssh\n  service: name=ssh state=restarted\n\n- name: flush routing cache\n  shell: echo 1 > /proc/sys/net/ipv4/route/flush\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "0fb92113ab159222d56eff850c644573e7542df0", "filename": "roles/awstats/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "awstats_install: True\nawstats_enabled: False\nawstats_data_dir: /library/awstats/\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "4a50e79b66968be37ee409de15ecab8c520d0c10", "filename": "roles/config-pxe/tasks/kickstart.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Install kickstart files\"\n  copy:\n    src: \"{{ ks_files }}\"\n    dest: \"{{ ks_files_destination }}\" \n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "5defd41bf6fff8828274f721743ed4c93b4a2c42", "filename": "roles/activity-server/files/xs_activities/__init__.py", "repository": "iiab/iiab", "decoded_content": "# Copyright (C) 2008 One Laptop Per Child Association, Inc.\n# Licensed under the terms of the GNU GPL v2 or later; see COPYING for details.\n#\n# written by Douglas Bagnall <douglas@paradise.net.nz>\n\n\"\"\"Functions for processing XO activities, either for indexing and\npresentaton to the laptops, or for diagnostics.\n\"\"\"\n\nimport os, sys, shutil\nimport zipfile\nimport re\nfrom cStringIO import StringIO\n#import traceback\nimport syslog\nfrom ConfigParser import SafeConfigParser\n\n# we no longer really have a default in that it is set in the conf file\n# we assume that we have a lang_template for the default language\nTEMPLATE_DIR = '/library/xs-activity-server/lang_templates'\nDEFAULT_LANG = 'en'\n\n# how many versions before the latest are worth having around.\nKEEP_OLD_VERSIONS = 3\n\n#print to stderr, rathe than syslog?\nUSE_STDERR=False\n\nREQUIRED_TAGS = ('bundle_id', 'activity_version', 'host_version', 'name', 'license')\nOPTIONAL_TAGS = ('show_launcher', 'exec', 'mime_types', 'icon')\n#XXX need either icon or show_launcher=no\n\ndef log(msg, level=syslog.LOG_NOTICE):\n    if USE_STDERR:\n        print >> sys.stderr, msg\n    else:\n        syslog.openlog( 'xs-activity-server', 0, syslog.LOG_USER )\n        syslog.syslog(level, msg)\n        syslog.closelog()\n\nclass BundleError(Exception):\n    pass\n\nclass Bundle(object):\n    def __init__(self, bundle):\n        self.linfo = {}\n        self.zf = zipfile.ZipFile(bundle)\n        # The activity path will be 'Something.activity/activity/activity.info'\n        for p in self.zf.namelist():\n            if p.endswith(self.INFO_PATH):\n                self.raw_data = read_info_file(self.zf, p, self.INFO_SECTION)\n\n        # the file name itself is needed for the URL\n        self.url = os.path.basename(bundle)\n        self.mtime = os.stat(bundle).st_mtime\n\n        self.name = self.raw_data.get('name')\n        self.license = self.raw_data.get('license', None)\n\n        # child ctor should now call\n        # _set_bundle_id\n        # _set_version\n        # _set_description\n    def _set_bundle_id(self, id):\n        if id is None:\n            raise BundleError(\"bad bundle: No bundle ID\")\n        self.bundle_id = id\n        if self.name is None:\n            self.name = id\n\n    def _set_version(self, version):\n        self.version = version\n\n    def _set_description(self, description):\n        self.description = description\n\n    def __cmp__(self, other):\n        \"\"\"Alphabetical sort (locale dependant of course)\"\"\"\n        if self.bundle_id == other.bundle_id:\n            return cmp(self.version, other.version)\n        return cmp(self.name, other.name)\n\n    def set_older_versions(self, versions):\n        \"\"\"Versions should be a list of (version number, version tuples)\"\"\"\n        self.older_versions = ', '.join('<a href=\"%s\">%s</a>' % (v.url, v.version) for v in versions)\n\n    def to_html(self, locale, template=None):\n        \"\"\"Fill in the template with data approriate for the locale.\"\"\"\n        if template is None:\n            template = read_template('activity', locale)\n\n        d = {'older_versions':      self.older_versions,\n             'bundle_id':           self.bundle_id,\n             'activity_version':    self.version,\n             'bundle_url':          self.url,\n             'name':                self.name,\n             'description':         self.description,\n             }\n\n        d.update(self.linfo.get(locale, {}))\n\n        if d['older_versions']:\n            d['show_older_versions'] = 'inline'\n        else:\n            d['show_older_versions'] = 'none'\n\n        return template % d\n\n    def get_name(self, locale=None):\n        return self.name\n\nclass Content(Bundle):\n    INFO_PATH = \"library/library.info\"\n    INFO_SECTION = \"Library\"\n\n    def __init__(self, bundle):\n        super(Content, self).__init__(bundle)\n\n        d = self.raw_data\n        # bundle_id is often missing; service name is used instead.\n        self._set_bundle_id(d.get('global_name', None))\n        self._set_version(d.get('library_version', 1))\n        self._set_description(d.get('long_name', ''))\n\n    def debug(self, force_recheck=False):\n        # FIXME: implement debug checking for content bundles\n        return {}\n\nclass Activity(Bundle):\n    INFO_PATH = \"activity/activity.info\"\n    INFO_SECTION = \"Activity\"\n\n    #Activities appear to be looser than RFC3066, using e.g. _ in place of -.\n    linfo_re = re.compile(r'/locale/([A-Za-z]+[\\w-]*)/activity.linfo$')\n\n    def __init__(self, bundle):\n        \"\"\"Takes a zipped .xo bundle name, returns a dictionary of its\n        activity info.  Can raise a variety of exceptions, all of\n        which should indicate the bundle is invalid.\"\"\"\n        super(Activity, self).__init__(bundle)\n\n        # The locale info will be Something.activity/locale/xx_XX/activity.linfo\n        for p in self.zf.namelist():\n            linfo = self.linfo_re.search(p)\n            if linfo:\n                lang = canonicalise(linfo.group(1))\n                self.linfo[lang] = read_info_file(self.zf, p, self.INFO_SECTION)\n\n        # Unfortunately the dictionary lacks some information, and\n        # stores other bits in inconsistent ways.\n\n        d = self.raw_data\n        # bundle_id is often missing; service name is used instead.\n        self._set_bundle_id(d.get('bundle_id', d.get('service_name')))\n        self._set_version(d.get('activity_version', 1))\n        self._set_description(d.get('description', ''))\n\n    def debug(self, force_recheck=False):\n        \"\"\"Make a copy of the raw data with added bits so we can work\n        out what is going on.  This is useful for diagnosing problems\n        with odd activities and composing tut-tut-ing emails to their\n        authors.\n\n        Not used in production.\"\"\"\n        if hasattr(self, '_debug_data') and not force_recheck:\n            return self._debug_data\n\n        d = self.raw_data.copy()\n\n        correct_forms = {\n            'name': str.upper,\n            'activity_version': str.isdigit,\n            'host_version': str.isdigit,\n            'bundle_id': re.compile(r'^[\\w.]+$').match,\n            'service_name': re.compile(r'^[\\w.]+$').match,\n            'icon': re.compile(r'^[\\S]+$').match,\n            'exec': str.upper,\n            'mime_types': re.compile(r'^([\\w.+-]+/[\\w.+-]+;?)*$').match,\n            'update_url': re.compile(r'^http://([\\w-]+\\.?)+(:\\d+)?(/[\\w~%.-]+)*$').match,\n            #'update_url': re.compile(r'^$').match,\n            'show_launcher': re.compile(r'^(yes)|(no)$').match,\n            'class': re.compile(r'^(\\w+.?)+$').match,\n            'license': str.upper,\n            #'license': re.compile(r'^GPLv[23]\\+?$').match,\n            }\n\n        for k, v in d.items():\n            if k in correct_forms:\n                f = correct_forms.get(k, len)\n                if not f(v):\n                    d['BAD ' + k] = v\n\n        rcount = 0\n        for k in REQUIRED_TAGS:\n            if k not in d:\n                d['LACKS %s' % k] = True\n                rcount += 1\n        d['MISSING KEYS'] = rcount\n\n        for t in OPTIONAL_TAGS:\n            if t not in d:\n                d['NO ' + t] = True\n\n        if  not 'icon' in d and d.get('show_launcher') != 'no':\n            d['NO icon AND show_launcher'] = True\n\n        self._debug_data = d\n        return d\n\n    def get_name(self, locale):\n        \"\"\"Return the best guess at a name for the locale.\"\"\"\n        for loc in locale_search_path(locale):\n            if loc in self.linfo and 'name' in self.linfo[loc]:\n                return self.linfo[loc]['name']\n        return super(Activity, self).get_name()\n\n\n\ndef check_all_bundles(directory, show_all_bundles=False):\n    \"\"\"A verbose debug function.\"\"\"\n    all_bundles = []\n    unique_bundles = {}\n    counts = {}\n    # watch for these tags and print out the lists\n    bad_contents = {}\n    all_linfo = {}\n    unique_linfo = {}\n    linfo_keys = {}\n    log('Checking all activities in %s\\n' % directory)\n    for f in os.listdir(directory):\n        if not f.endswith('.xo') and not f.endswith('.xol'):\n            continue\n        #log(f)\n        try:\n            if f.endswith('.xo'):\n                bundle = Activity(os.path.join(directory, f))\n            else:\n                bundle = Content(os.path.join(directory, f))\n        except Exception, e:\n            log(\"IRREDEEMABLE bundle %-25s (Error: %s)\" % (f, e), syslog.LOG_WARNING)\n\n        #Clump together bundles of the same ID\n        x = unique_bundles.setdefault(bundle.bundle_id, [])\n        x.append(bundle)\n        all_bundles.append(bundle)\n\n    if not show_all_bundles:\n        #only show the newest one of each set.\n        bundles = []\n        for versions in unique_bundles.values():\n            versions.sort()\n            bundles.append(versions[-1])\n\n    else:\n        bundles = all_bundles\n\n    licenses = {}\n    for bundle in bundles:\n        bid = bundle.bundle_id\n        for k, v in bundle.debug().iteritems():\n            counts[k] = counts.get(k, 0) + 1\n            if k.startswith('BAD '):\n                bc = bad_contents.setdefault(k, {})\n                bc[bid] = v\n        for k, v in bundle.linfo.iteritems():\n            linfo_l = all_linfo.setdefault(k, [])\n            linfo_l.append(bundle)\n            for x in v:\n                linfo_keys[x] = linfo_keys.get(x, 0) + 1\n            if v['name'] != bundle.name:\n                linfo_l = unique_linfo.setdefault(k, [])\n                linfo_l.append(bundle)\n\n        if bundle.license:\n            lic = licenses.setdefault(bundle.license, [])\n            lic.append(bundle.bundle_id)\n\n    citems = counts.items()\n    rare_keys = [k for k, v in citems if v < 10]\n    lack_counts = dict((k, v) for k, v in citems if k.startswith('LACKS '))\n    bad_counts = dict((k, v) for k, v in citems if k.startswith('BAD '))\n    no_counts = dict((k, v) for k, v in citems if k.startswith('NO '))\n    tag_counts = dict((k, v) for k, v in citems if k not in lack_counts and\n                      k not in bad_counts and k not in no_counts and k != 'MISSING KEYS')\n\n    # flag whether the tag is needed, ok, or not\n    tag_quality = dict((k, '*') for k in REQUIRED_TAGS)\n    tag_quality.update((k, '+') for k in OPTIONAL_TAGS)\n    linfo_counts = dict((k, len(v)) for k, v in all_linfo.iteritems())\n    linfo_uniq_counts = dict((k, len(v)) for k, v in unique_linfo.iteritems())\n\n    log('\\nFound: %s bundles\\n       %s unique bundles' % (len(all_bundles), len(unique_bundles)))\n    for d, name, d2 in [(tag_counts, '\\nattribute counts:', tag_quality),\n                        (lack_counts, '\\nmissing required keys:', {}),\n                        (no_counts, '\\nunused optional keys:', {}),\n                        (bad_counts, '\\nill-formed values:', {}),\n                        (linfo_counts, '\\nlinfo counts:             total  localised', linfo_uniq_counts),\n                        (linfo_keys, '\\nlinfo keys:', {})]:\n        log(name)\n        counts_reversed = [(v, k) for (k, v) in d.iteritems()]\n        counts_reversed.sort()\n        counts_reversed.reverse()\n        for (k, v) in counts_reversed:\n            log(\"%-25s %4s   %4s\" % (v, k, d2.get(v, '')))\n\n    log(\"\\nRare keys:\")\n    for k in rare_keys:\n        if k.startswith('BAD '):\n            continue\n        log(k)\n        for b in bundles:\n            v = b.debug().get(k)\n            if v:\n                log('      %-25s %s' % (b.bundle_id, v))\n\n\n    log(\"\\nInteresting contents:\")\n    for k, v in bad_contents.iteritems():\n        log(k)\n        for x in v.iteritems():\n            log('      %s: %s' % x)\n\n    log(\"\\nInteresting linfo:\")\n    for k in ('pseudo',):\n        log(k)\n        for a in all_linfo[k]:\n            if a in unique_linfo.get(k, []):\n                log('   *  %s  (%s vs. %s)' % (a.bundle_id, a.name, a.linfo[k]['name']))\n            else:\n                log('      %s (%s)' % (a.bundle_id, a.name))\n\n    log(\"\\nLicenses:\")\n    for lic, v in licenses.iteritems():\n        log(\"%-20s  %s\" %(repr(lic), len(v)))\n\n    log(\"\\nRare licenses:\")\n    for lic, v in licenses.iteritems():\n        if len(v) < 3:\n            log('   %s' % lic)\n            for x in v:\n                log(\"      %s\" %(x))\n\n\n\n    log(\"\\nAlmost valid activities:\")\n    for b in bundles:\n        d = b.debug()\n        if d['MISSING KEYS'] == 1:\n            missing = ', '.join(x for x in d if x.startswith('LACKS'))\n            bad_values = ', '. join(x for x in d if x.startswith('BAD'))\n            log(\"%-20s %s %s\" %(b.name, missing, bad_values))\n\n    log(\"\\nValid activities (maybe):\")\n    for b in bundles:\n        d = b.debug()\n        bid = b.bundle_id\n        if (d['MISSING KEYS'] == 0 and\n            bid not in bad_contents['BAD mime_types']):\n            log(\"%-20s - %s\" %(b.name, bid))\n            #log(a.raw_data)\n\n\n\n\ndef read_info_file(zipfile, path, section):\n    \"\"\"Return a dictionary matching the contents of the config file at\n    path in zipfile\"\"\"\n    cp = SafeConfigParser()\n    info = StringIO(zipfile.read(path))\n    cp.readfp(info)\n    return dict(cp.items(section))\n\ndef canonicalise(lang):\n    \"\"\"Make all equivalent language strings the same.\n    >>> canonicalise('Zh-cN')\n    zh-CN\n    >>> canonicalise('zh_CN')\n    zh-CN\n    \"\"\"\n    lang = lang.replace('_', '-').upper()\n    bits = lang.split('-', 1)\n    bits[0] = bits[0].lower()\n    return '-'.join(bits)\n\ndef locale_search_path(locale):\n    \"\"\"Find a series of sensible locales to try, including\n    DEFAULT_LANG. For example 'zh-CN' would become ('zh-CN', 'zh',\n    'DEFAULT_LANG').\"\"\"\n    #XXX might be better to be storing locale as tuple\n    if '-' in locale:\n        return (locale, locale.split('-')[0], DEFAULT_LANG)\n    return (locale, DEFAULT_LANG)\n\n\n\ndef read_metadata(bundle_dir):\n    \"\"\"Attempt to read data in a metadata file. Raises expected\n    exceptions if the metadata file isn't readable. The file should\n    look something like this:\n\n    [org.laptop.Pippy]\n    description = Succinct description of this activity.\n\n    [org.laptop.Develop]\n    description = Succinct description of this activity.\n    web_icon = develop.png\n    \"\"\"\n    md_files = [os.path.join(bundle_dir, x)\n               for x in os.listdir(bundle_dir) if x.endswith('.info')]\n    cp = SafeConfigParser()\n    cp.read(md_files)\n    metadata = {}\n    for section in cp.sections():\n        metadata[section] = dict(x for x in cp.items(section))\n    return metadata\n\n\ndef htmlise_bundles(bundle_dir, dest_html):\n    \"\"\"Makes a nice html manifest for the bundles in a directory.  The\n    manifest only shows the newest version of each bundle.\n    \"\"\"\n    #so, we collect up a dictionary of lists, then sort each list on\n    #the version number to find the newest.\n\n    bundles = [os.path.join(bundle_dir, x)\n               for x in os.listdir(bundle_dir) if x.endswith('.xo') or x.endswith('.xol')]\n\n    try:\n        metadata = read_metadata(bundle_dir)\n    except Exception, e:\n        log(\"had trouble reading metadata: %s\" % e)\n        metadata = {}\n\n    all_bundles = {}\n    for filename in bundles:\n        try:\n            if filename.endswith('.xo'):\n                bundle = Activity(filename)\n            else:\n                bundle = Content(filename)\n            x = all_bundles.setdefault(bundle.bundle_id, [])\n            x.append((bundle.mtime, bundle))\n        except Exception, e:\n            log(\"Couldn't find good activity/library info in %s (Error: %s)\" % (filename, e))\n\n    newest = []\n    # create an index for each language that has a template\n    # but track any locales in bundles in case we do not have templates for them\n    locales = [os.path.join(o) for o in os.listdir(TEMPLATE_DIR) if os.path.isdir(os.path.join(TEMPLATE_DIR,o))]\n    locales_found = set ()\n    for versions in all_bundles.values():\n        versions = [x[1] for x in sorted(versions)]\n        # end of list is the newest; beginning of list might need deleting\n        latest = versions.pop()\n        locales_found.update(latest.linfo)\n        newest.append(latest)\n        goners = versions[:-KEEP_OLD_VERSIONS]\n        keepers = versions[-KEEP_OLD_VERSIONS:]\n        for v in goners:\n            fn = os.path.join(bundle_dir, v.url)\n            os.remove(fn)\n        latest.set_older_versions(keepers)\n\n        if latest.bundle_id in metadata:\n            # we have extra metadata with which to fill out details\n            # presumably this is mainly human-oriented description.\n            d = metadata[latest.bundle_id]\n            for k in ('description', 'name'):\n                if k in d:\n                    setattr(latest, k, d[k])\n\n    log('found locales: %s' % locales)\n   \n    # assume locales is not empty as we have at least the default language\n    for locale in locales:\n        try:\n            make_html(newest, locale, '%s.%s' % (dest_html, locale))\n        except Exception, e:\n            log(\"Couldn't make page for %s (Error: %s)\" % (locale, e), syslog.LOG_WARNING)    \n        \n    # make_varfile(locales, dest_html)- have switched to multiviews, so var not needed\n\n\ndef make_varfile(locales, dest_html):\n    f = open(dest_html + '.var', 'w')\n    index = os.path.basename(dest_html)\n    f.write('URI: %s\\n\\n' % index)\n    for locale in locales:\n        f.write('URI: %s.%s\\n' % (index, locale))\n        f.write('Content-type: text/html; charset=utf-8\\n')\n        f.write('Content-language: %s\\n\\n' % locale)\n    # now the default, slightly higher qs\n    f.write('URI: %s.DEFAULT\\n' % index)\n    f.write('Content-type: text/html; charset=utf-8\\n')\n    f.write('Content-language: en\\n\\n')\n\n    f.close()\n\ndef read_template(name, locale):\n    \"\"\"Try to read the locale's template, falling back to the\n    default.\"\"\"\n    #also try containing locales, eg 'zh' for 'zh-CN'\n    for x in locale_search_path(locale):\n        try:\n            f = open(os.path.join(TEMPLATE_DIR, x, name))\n            break\n        except (OSError, IOError), e:\n            #log(str(e))\n            continue\n    s = f.read()\n    f.close()\n    return s\n\n\ndef make_html(bundles, locale, filename):\n    \"\"\"Write a microformated index for the activities in the appropriate language,\n    and save it to filename.\"\"\"\n    page_tmpl = read_template('page', locale)\n    act_tmpl = read_template('activity', locale)\n\n    #bundles.sort() won't cut it.\n    schwartzian = [ (x.get_name(locale), x.to_html(locale, act_tmpl)) for x in bundles ]\n    schwartzian.sort()\n    s = page_tmpl % {'activities': '\\n'.join(x[1] for x in schwartzian)}\n\n    if os.path.exists(filename):\n        shutil.move(filename, filename + '~')\n    f = open(filename, 'w')\n    f.write(s)\n    f.close()\n\n\n\n\n\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "5c5bfcc97d72a92b10b4776033ab1de8c03492c2", "filename": "roles/dns/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: \"Remove any deleted DNS A records\"\n  nsupdate:\n    key_name: \"{{ item.0.key_name }}\"\n    key_secret: \"{{ item.0.key_secret }}\"\n    key_algorithm: \"{{ item.0.key_algorithm }}\"\n    server: \"{{ item.0.server }}\"\n    zone: \"{{ item.0.zone }}\"\n    record: \"{{ item.1.hostname }}\"\n    type: \"{{ item.1.type }}\"\n    state: absent\n  with_subelements:\n  - \"{{ dns_records_rm | default({}) }}\"\n  - entries\n  register: nsupdate_remove_result\n  until: nsupdate_remove_result|succeeded\n  retries: 10\n  delay: 1\n\n- name: \"Add DNS A records\"\n  nsupdate:\n    key_name: \"{{ item.0.key_name }}\"\n    key_secret: \"{{ item.0.key_secret }}\"\n    key_algorithm: \"{{ item.0.key_algorithm }}\"\n    server: \"{{ item.0.server }}\"\n    zone: \"{{ item.0.zone }}\"\n    record: \"{{ item.1.hostname }}\"\n    value: \"{{ item.1.ip }}\"\n    type: \"{{ item.1.type }}\"\n    state: present\n  with_subelements:\n  - \"{{ dns_records_add | default({}) }}\"\n  - entries\n  register: nsupdate_add_result\n  until: nsupdate_add_result|succeeded\n  retries: 10\n  delay: 1\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "7c982dbd2e5d3134f4f17a3d69f1ab99c0eba697", "filename": "roles/network/tasks/create_ifcfg.yml", "repository": "iiab/iiab", "decoded_content": "- name: Stop 'Wired WAN connection'\n  shell: nmcli dev disconnect {{ discovered_wan_iface }}\n  ignore_errors: True\n  changed_when: False\n  when: discovered_wan_iface != \"none\" and not has_WAN and has_ifcfg_gw == \"none\"\n\n# set user_wan_iface: <device> for static\n# use wan_* for static info\n- name: Supply ifcfg-WAN file\n  template: src=network/ifcfg-WAN.j2\n            dest=/etc/sysconfig/network-scripts/ifcfg-WAN\n  when: iiab_wan_iface != \"none\" and not has_WAN  and has_ifcfg_gw == \"none\"\n\n- name: Now setting ifcfg-WAN True after creating file\n  set_fact:\n    has_WAN: True\n  when: iiab_wan_iface != \"none\" and has_ifcfg_gw == \"none\"\n"}, {"commit_sha": "51dcdf691a7801895b569a5a927e30030d8feb70", "sha": "ca88ce2542fe98f8a0e9e5b82f0310540dde1d67", "filename": "tasks/apt_install.yml", "repository": "nusenu/ansible-relayor", "decoded_content": "---\n\n- name: Setup Debian specific variables (set_fact)\n  set_fact:\n    tor_user: debian-tor\n    tor_DataDir: /var/lib/tor-instances\n    tor_ConfDir: /etc/tor/instances\n    tor_RunAsDaemon: 0\n  tags:\n   - reconfigure\n   - renewkey\n   - createdir\n\n- name: Ensure torproject gpg key is installed (A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89)\n  become: yes\n  apt_key: data=\"{{ lookup('file', 'deb.torproject.org_A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89.pub') }}\"\n    id=A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89\n    state=present\n\n- name: Ensure torproject.org repository is present (APT)\n  become: yes\n  apt_repository: repo='deb http://deb.torproject.org/torproject.org {{ tor_distribution_release }} main'\n    state=present \n    update_cache=yes\n\n# we specifically opt for present over latest to improve performance\n# \"latest\" is covered by auto updates\n- name: Ensure Tor is installed (APT)\n  become: yes\n  apt: pkg=\"{{ item }}\" state=present\n  with_items: \n    - deb.torproject.org-keyring\n    - tor\n  # apt starts a tor client instance by default after installing the package\n  # we do not need that\n  notify:\n    - stop-and-disable default tor\n\n\n- name: Ensure AppArmor allows access to necessary files (Ubuntu)\n  become: yes\n  lineinfile: dest=/etc/apparmor.d/local/system_tor line={{ item }}\n  with_items:\n    - '/etc/tor/enabled/*\\ r,'\n    - '/{,var/}run/tor/*.pid\\ w,'\n    - '/var/lib/tor/**\\ w,'\n  when: ansible_distribution == 'Ubuntu'\n  notify: restart apparmor\n\n- meta: flush_handlers\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "940368af1e31a6fb5daa87064c486ec415e59fef", "filename": "roles/registrator/vars/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# vars file for registrator\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "64d8c88d05e60c1d0b5e63d91dfc27fb346ad3cd", "filename": "tasks/main.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n\n- name: Include OS specific variables.\n  include_vars: \"configure-{{ ansible_os_family }}.yml\"\n\n- name: Include OS specific selinux libs and utils if needed\n  include: \"selinux-{{ ansible_os_family }}.yml\"\n  when: ansible_selinux.status is defined and ansible_selinux.status == \"enabled\"\n\n- name: Check if SystemD service is installed\n  stat:\n    path: /etc/systemd/system/nexus.service\n  register: nexus_systemd_service_file\n\n- include: nexus_purge.yml\n  when: ((purge is defined) and (purge | bool))\n\n- include: nexus_install.yml\n\n- include: httpd_reverse_proxy_config.yml\n  when: httpd_setup_enable\n\n- include: admin_password_setup.yml\n\n- name: Deleting default repositories\n  include: delete_repo_each.yml\n  with_items:\n    - maven-central\n    - maven-public\n    - maven-releases\n    - maven-snapshots\n    - nuget-group\n    - nuget-hosted\n    - nuget.org-proxy\n  when: nexus_data_dir_contents.stdout == \"\" and nexus_delete_default_repos\n\n- name: Deleting default blobstore\n  include: delete_blobstore_each.yml\n  with_items:\n    - name: default\n    - name: \"{{ nexus_blob_names.raw.blob }}\"\n    - name: \"{{ nexus_blob_names.pypi.blob }}\"\n    - name: \"{{ nexus_blob_names.docker.blob }}\"\n    - name: \"{{ nexus_blob_names.ruby.blob }}\"\n    - name: \"{{ nexus_blob_names.bower.blob }}\"\n    - name: \"{{ nexus_blob_names.npm.blob }}\"\n    - name: \"{{ nexus_blob_names.nuget.blob }}\"\n    - name: \"{{ nexus_blob_names.mvn.blob }}\"\n    - name: \"{{ nexus_blob_names.gitlfs.blob }}\"\n    - name: \"{{ nexus_blob_names.yum.blob }}\"\n  when: nexus_data_dir_contents.stdout == \"\" and nexus_delete_default_blobstore\n\n- include: setup_ldap_each.yml\n  with_items: \"{{ ldap_connections }}\"\n\n- include: setup_privilege_each.yml\n  with_items: \"{{ nexus_privileges }}\"\n\n- include: setup_role_each.yml\n  with_items: \"{{ nexus_roles }}\"\n\n- include: setup_user_each.yml\n  with_items: \"{{ nexus_local_users }}\"\n\n- name: \"Digest splited blob list var\"\n  include_vars: blob_vars.yml\n  when: nexus_blob_split\n\n- include: create_blobstore_each.yml\n  with_items: \"{{ nexus_blobstores }}\"\n  when: nexus_restore_point is undefined\n\n- name: \"Restore nexus backup\"\n  include: nexus-restore.yml\n  when: nexus_restore_point is defined\n\n- include: create_repo_maven_proxy_each.yml\n  with_items: \"{{ nexus_repos_maven_proxy }}\"\n\n- include: create_repo_maven_hosted_each.yml\n  with_items: \"{{ nexus_repos_maven_hosted }}\"\n\n- include: create_repo_maven_group_each.yml\n  with_items: \"{{ nexus_repos_maven_group }}\"\n\n- block:\n    - include: create_repo_docker_hosted_each.yml\n      with_items: \"{{ nexus_repos_docker_hosted }}\"\n\n    - include: create_repo_docker_proxy_each.yml\n      with_items: \"{{ nexus_repos_docker_proxy }}\"\n\n    - include: create_repo_docker_group_each.yml\n      with_items: \"{{ nexus_repos_docker_group }}\"\n  when: nexus_config_docker\n\n- block:\n    - include: create_repo_pypi_proxy_each.yml\n      with_items: \"{{ nexus_repos_pypi_proxy }}\"\n\n    - include: create_repo_pypi_hosted_each.yml\n      with_items: \"{{ nexus_repos_pypi_hosted }}\"\n\n    - include: create_repo_pypi_group_each.yml\n      with_items: \"{{ nexus_repos_pypi_group }}\"\n  when: nexus_config_pypi\n\n- block:\n    - include: create_repo_raw_proxy_each.yml\n      with_items: \"{{ nexus_repos_raw_proxy }}\"\n\n    - include: create_repo_raw_hosted_each.yml\n      with_items: \"{{ nexus_repos_raw_hosted }}\"\n\n    - include: create_repo_raw_group_each.yml\n      with_items: \"{{ nexus_repos_raw_group }}\"\n  when: nexus_config_raw\n\n- block:\n    - include: create_repo_rubygems_proxy_each.yml\n      with_items: \"{{ nexus_repos_rubygems_proxy }}\"\n\n    - include: create_repo_rubygems_hosted_each.yml\n      with_items: \"{{ nexus_repos_rubygems_hosted }}\"\n\n    - include: create_repo_rubygems_group_each.yml\n      with_items: \"{{ nexus_repos_rubygems_group }}\"\n  when: nexus_config_rubygems\n\n- block:\n    - include: create_repo_bower_proxy_each.yml\n      with_items: \"{{ nexus_repos_bower_proxy }}\"\n\n    - include: create_repo_bower_hosted_each.yml\n      with_items: \"{{ nexus_repos_bower_hosted }}\"\n\n    - include: create_repo_bower_group_each.yml\n      with_items: \"{{ nexus_repos_bower_group }}\"\n  when: nexus_config_bower\n\n- block:\n    - include: create_repo_npm_proxy_each.yml\n      with_items: \"{{ nexus_repos_npm_proxy }}\"\n\n    - include: create_repo_npm_hosted_each.yml\n      with_items: \"{{ nexus_repos_npm_hosted }}\"\n\n    - include: create_repo_npm_group_each.yml\n      with_items: \"{{ nexus_repos_npm_group }}\"\n  when: nexus_config_npm\n\n- block:\n    - include: create_repo_nuget_proxy_each.yml\n      with_items: \"{{ nexus_repos_nuget_proxy }}\"\n    - include: create_repo_nuget_hosted_each.yml\n      with_items: \"{{ nexus_repos_nuget_hosted }}\"\n    - include: create_repo_nuget_group_each.yml\n      with_items: \"{{ nexus_repos_nuget_group }}\"\n  when: nexus_config_nuget\n\n\n- include: create_repo_gitlfs_hosted_each.yml\n  with_items: \"{{ nexus_repos_gitlfs_hosted }}\"\n  when: nexus_config_gitlfs\n\n- block:\n    - include: create_repo_yum_hosted_each.yml\n      with_items: \"{{ nexus_repos_yum_hosted }}\"\n    - include: create_repo_yum_proxy_each.yml\n      with_items: \"{{ nexus_repos_yum_proxy }}\"\n  when: nexus_config_yum\n\n- include: call_script.yml\n  vars:\n    script_name: setup_anonymous_access\n    args:\n      anonymous_access: \"{{ nexus_anonymous_access }}\"\n\n- include: call_script.yml\n  vars:\n    script_name: setup_base_url\n    args:\n      base_url: \"https://{{ public_hostname }}/\"\n\n- include: call_script.yml\n  vars:\n    script_name: setup_http_proxy\n    args:\n      with_http_proxy: \"{{ nexus_with_http_proxy }}\"\n      http_proxy_host: \"{{ nexus_http_proxy_host }}\"\n      http_proxy_port: \"{{ nexus_http_proxy_port }}\"\n      http_proxy_username: \"{{ nexus_http_proxy_username }}\"\n      http_proxy_password: \"{{ nexus_http_proxy_password }}\"\n      with_https_proxy: \"{{ nexus_with_https_proxy }}\"\n      https_proxy_host: \"{{ nexus_https_proxy_host }}\"\n      https_proxy_port: \"{{ nexus_https_proxy_port }}\"\n      https_proxy_username: \"{{ nexus_https_proxy_username }}\"\n      https_proxy_password: \"{{ nexus_https_proxy_password }}\"\n      proxy_exclude_hosts: \"{{ nexus_proxy_exclude_hosts }}\"\n\n- include: call_script.yml\n  vars:\n    script_name: setup_realms\n    args:\n      nuget_api_key_realm: \"{{ nexus_nuget_api_key_realm }}\"\n      npm_bearer_token_realm: \"{{ nexus_npm_bearer_token_realm }}\"\n      rut_auth_realm: \"{{ nexus_rut_auth_realm }}\"\n      ldap_realm: \"{{ nexus_ldap_realm }}\"\n      docker_bearer_token_realm: \"{{ nexus_docker_bearer_token_realm }}\"\n\n- name: Configure RUT Auth header\n  include: call_script.yml\n  vars:\n    script_name: setup_capability\n    args:\n      capability_typeId: \"rutauth\"\n      capability_properties:\n        httpHeader: \"{{ nexus_rut_auth_header }}\"\n  when: nexus_rut_auth_header is defined\n\n- include: call_script.yml\n  vars:\n    script_name: setup_email\n    args:\n      email_server_enabled: \"{{ nexus_email_server_enabled }}\"\n      email_server_host: \"{{ nexus_email_server_host }}\"\n      email_server_port: \"{{ nexus_email_server_port }}\"\n      email_server_username: \"{{ nexus_email_server_username }}\"\n      email_server_password: \"{{ nexus_email_server_password }}\"\n      email_from_address: \"{{ nexus_email_from_address }}\"\n      email_subject_prefix: \"{{ nexus_email_subject_prefix }}\"\n      email_tls_enabled: \"{{ nexus_email_tls_enabled }}\"\n      email_tls_required: \"{{ nexus_email_tls_required }}\"\n      email_ssl_on_connect_enabled: \"{{ nexus_email_ssl_on_connect_enabled }}\"\n      email_ssl_check_server_identity_enabled: \"{{ nexus_email_ssl_check_server_identity_enabled }}\"\n      email_trust_store_enabled: \"{{ nexus_email_trust_store_enabled }}\"\n\n- name: Configure branding capability\n  include: call_script.yml\n  vars:\n    script_name: setup_capability\n    args:\n      capability_typeId: \"rapture.branding\"\n      capability_properties:\n        footerHtml: \"{{ nexus_branding_footer }}\"\n        headerHtml: \"{{ nexus_branding_header }}\"\n        footerEnabled: \"{{ nexus_branding_footer != '' }}\"\n        headerEnabled: \"{{ nexus_branding_header != '' }}\"\n\n- include: create_task_each.yml\n  with_items: \"{{ nexus_scheduled_tasks }}\"\n\n- name: Configure nexus backup task\n  include: call_script.yml\n  vars:\n    script_name: create_task\n    args:\n      name: db and blobstores backup\n      typeId: script\n      cron: \"{{ nexus_backup_cron }}\"\n      taskProperties:\n        language: groovy\n        source: \"{{ lookup('template', './templates/backup.groovy.j2') }}\"\n  when: nexus_backup_configure | bool\n"}, {"commit_sha": "f26e6a5f816bc8f8672d0b80aa761ae8c459d30a", "sha": "55b33a1306a92d3e1647363795743c0ceba8ff64", "filename": "tasks/main.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Set distribution facts\n  set_fact:\n    _docker_os_dist: \"{{ ansible_distribution }}\"\n    _docker_os_dist_release: \"{{ ansible_distribution_release }}\"\n    _docker_os_dist_major_version: \"{{ ansible_distribution_major_version }}\"\n    _docker_os_dist_check: yes\n  tags: [\"install\", \"configure\"]\n\n- name: Reinterpret distribution facts for Linux Mint 18\n  set_fact:\n    _docker_os_dist: \"Ubuntu\"\n    _docker_os_dist_release: \"xenial\"\n    _docker_os_dist_major_version: \"16\"\n  when:\n    _docker_os_dist == \"Linux Mint\" and\n    _docker_os_dist_major_version == \"18\"\n  tags: [\"install\", \"configure\"]\n\n- include: checks.yml\n  tags: [\"install\", \"configure\"]\n\n- include: setup-repository.yml\n  tags: [\"install\"]\n\n- include: remove-pre-docker-ce.yml\n  when: docker_remove_pre_ce | bool\n  tags: [\"install\"]\n\n- include: install-docker.yml\n  tags: [\"install\"]\n\n- include: setup-audit.yml\n  tags: [\"configure\"]\n\n- include: kernel-3-mount-fixes.yml\n  when: ansible_kernel | version_compare('4', '<')\n  tags: [\"configure\"]\n\n- include: configure-docker.yml\n  tags: [\"configure\"]\n"}, {"commit_sha": "f3dd45a61b08de1b3351140cc442a705cb2fad82", "sha": "adf847b65fab7b5a65f8624d67bf64495b3f25ba", "filename": "meta/main.yml", "repository": "geerlingguy/ansible-role-security", "decoded_content": "---\ndependencies: []\n\ngalaxy_info:\n  author: geerlingguy\n  description: Security software installation and configuration.\n  company: \"Midwestern Mac, LLC\"\n  license: \"license (BSD, MIT)\"\n  min_ansible_version: 2.4\n  platforms:\n    - name: EL\n      versions:\n        - all\n    - name: Fedora\n      versions:\n        - all\n    - name: Debian\n      versions:\n        - all\n    - name: Ubuntu\n      versions:\n        - all\n  galaxy_tags:\n    - system\n    - security\n    - fail2ban\n    - automatic\n    - updates\n    - yum\n    - apt\n    - dnf\n    - hardening\n"}, {"commit_sha": "54430da1067241aa5fcd13a3e02c676a762a7db3", "sha": "ad2a5765f2199bae7e7e88a91d854a3ec707eac5", "filename": "tasks/main.yml", "repository": "geerlingguy/ansible-role-php-xdebug", "decoded_content": "---\n- name: Include OS-specific variables.\n  include_vars: \"{{ ansible_os_family }}.yml\"\n\n- name: Download Xdebug.\n  get_url:\n    url: \"http://xdebug.org/files/xdebug-{{ php_xdebug_version }}.tgz\"\n    dest: \"{{ workspace }}\"\n\n- name: Untar Xdebug.\n  command: >\n    tar -C {{ workspace }} -xvzf {{ workspace }}/xdebug-{{ php_xdebug_version }}.tgz\n    creates={{ workspace }}/xdebug-{{ php_xdebug_version }}/README\n\n- name: Build Xdebug.\n  shell: >\n    {{ item }}\n    chdir={{ workspace }}/xdebug-{{ php_xdebug_version }}\n    creates={{ workspace }}/xdebug-{{ php_xdebug_version }}/modules/xdebug.so\n  with_items:\n    - phpize\n    - ./configure\n    - make\n  notify: restart webserver\n\n- name: Ensure Xdebug module path exists.\n  file:\n    path: \"{{ php_xdebug_module_path }}\"\n    state: directory\n    owner: root\n    group: root\n    mode: 0755\n\n- name: Move Xdebug module into place.\n  shell: >\n    cp {{ workspace }}/xdebug-{{ php_xdebug_version }}/modules/xdebug.so {{ php_xdebug_module_path }}/xdebug.so\n    creates={{ php_xdebug_module_path }}/xdebug.so\n  notify: restart webserver\n\n- name: Copy xdebug INI into php.d folder.\n  template:\n    src: xdebug.ini.j2\n    dest: \"{{ php_extension_conf_path }}/xdebug.ini\"\n    owner: root\n    group: root\n    mode: 0644\n  notify: restart webserver\n\n- name: Check for separate cli php conf.d directory.\n  stat: path=/etc/php5/cli/conf.d\n  register: php_cli_path\n  when: php_xdebug_cli_enable\n\n- name: Symlink xdebug.ini into separate cli directory if it exists.\n  file:\n    src: \"{{ php_extension_conf_path }}/xdebug.ini\"\n    dest: /etc/php5/cli/conf.d/xdebug.ini\n    state: link\n  when: php_xdebug_cli_enable and php_cli_path.stat.isdir is defined and php_cli_path.stat.isdir\n"}, {"commit_sha": "e91a55152358e890a05cf849abc7d58b8badecc2", "sha": "c58d571489b4a59e5ac680e2c5d190c5d8a0c7a3", "filename": "tasks/tasks-FreeBSD.yml", "repository": "fubarhouse/ansible-role-golang", "decoded_content": "---\n\n- name: \"Go-Lang | Define GOARCH\"\n  set_fact:\n    GOARCH: \"amd64\"\n  when: GOARCH is not defined\n\n- name: \"Go-Lang | Define GOOS\"\n  set_fact:\n    GOOS: \"freebsd\"\n  when: GOOS is not defined"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "27602bf466d6a7219580e1e6f8ce0cb8101d5e5d", "filename": "tasks/create_repo_nuget_hosted_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_nuget_hosted\n    args: \"{{ _nexus_repos_nuget_defaults|combine(item) }}\"\n"}, {"commit_sha": "c33f3410e002f9d8506f0725f56b7d7afa1c5f74", "sha": "2fbb50c4a8dc7dae6bd07d08c3f7d02ccb2818b0", "filename": "meta/tests/inventory", "repository": "jloh/nagios-nrpe-server", "decoded_content": "localhost\n"}, {"commit_sha": "a94f9ce4fa32273fd0fad7492d36db4101423cc3", "sha": "d75ce020d582a604333f699f7fed552b42a0504c", "filename": "meta/main.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "galaxy_info:\n  author: Bjorn Oscarsson\n  description: \"Installs and configures Docker Community Edition (CE)\"\n  min_ansible_version: 2.4\n  license: MIT\n  platforms:\n  - name: Fedora\n    versions:\n      - 24\n      - 25\n      - 26\n      - 27\n      - 28\n\n  - name: EL\n    versions:\n      - 7\n\n  - name: Debian\n    versions:\n      - jessie\n      - stretch\n\n  - name: Ubuntu\n    versions:\n      - trusty\n      - xenial\n      - bionic\n\n  galaxy_tags:\n    - docker\n    - containers\n    - system\n\ndependencies: []\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "b99e071d3191e7190ca8dc8ebd0adc4ee1089c58", "filename": "tasks/section_09_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 9.1.1.1 Check that cron conf file exists (check) (Scored)\n    stat: path=/etc/init/cron.conf\n    register: cron_conf_stat\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.1\n\n  - name: 9.1.1.2 Enable cron Daemon (Scored)\n    service: >\n        name=cron\n        state=started\n        enabled=yes\n    when: not cron_conf_stat.stat.exists\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.2\n\n  - name: 9.1.2 Set User/Group Owner and Permission on /etc/crontab (Scored)\n    file: path='/etc/crontab' owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.2\n\n  - name: 9.1.3 Set User/Group Owner and Permission on /etc/cron.hourly (Scored)\n    file: path=/etc/cron.hourly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.3\n\n  - name: 9.1.4 Set User/Group Owner and Permission on /etc/cron.daily (Scored)\n    file: path=/etc/cron.daily owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.4\n\n  - name: 9.1.5 Set User/Group Owner and Permission on /etc/cron.weekly (Scored)\n    file: path=/etc/cron.weekly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.5\n\n  - name: 9.1.6 Set User/Group Owner and Permission on /etc/cron.monthly (Scored)\n    file: path=/etc/cron.monthly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.6\n\n  - name: 9.1.7 Set User/Group Owner and Permission on /etc/cron.d (Scored)\n    file: path=/etc/cron.d owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.7\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (remove deny) (Scored)\n    file: path={{ item }} state=absent\n    with_items:\n        - /etc/cron.deny\n        - /etc/at.deny\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (create cron allow) (Scored)\n    copy:\n        dest: /etc/cron.allow\n        owner: root\n        group: root\n        mode: \"og-rwx\"\n        content: \"\"\n        force: no\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (create at allow) (Scored)\n    copy:\n        dest: /etc/at.allow\n        owner: root\n        group: root\n        mode: \"og-rwx\"\n        content: \"\"\n        force: no\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.2.1 Set Password Creation Requirement Parameters Using pam_cracklib (install) (Scored)\n    apt: name=libpam-cracklib state=present\n    when: use_pam_cracklib == True\n    tags:\n      - section9\n      - section9.2\n      - section9.2.1\n\n  - name: 9.2.1 Set Password Creation Requirement Parameters Using pam_cracklib (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password'\n        regexp=\"pam_cracklib.so\"\n        line=\"password required pam_cracklib.so retry=3 minlen=14 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1\"\n        state=present\n    when: use_pam_cracklib == True\n    tags:\n      - section9\n      - section9.2\n      - section9.2.1\n\n#Note for section 9.2.2:\n#If a user has been locked out because they have reached the maximum consecutive failure count\n#defined by denied= in the pam_tally2.so module, the user can be unlocked by issuing the command\n#/sbin/pam_tally2 -u username --reset\n#This command sets the failed count to 0, effectively unlocking the user\n  - name: 9.2.2 Set Lockout for Failed Password Attempts (Not Scored)\n    lineinfile: >\n        dest='/etc/pam.d/login'\n        regexp='pam_tally2'\n        line=\"auth required pam_tally2.so onerr=fail audit silent deny=5 unlock_time=900\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.2\n\n  - name: 9.2.3 Limit Password Reuse (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password'\n        regexp='remember=5'\n        line=\"password sufficient pam_unix.so remember=5\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.3\n\n  - name: 9.3 Check if ssh is installed (check) (Not Scored)\n    stat: path='/etc/ssh/sshd_config'\n    register: ssh_config_file\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n  - include: section_09_level1_03.yml\n    when: ssh_config_file.stat.exists == True\n\n  - name: 9.4 Restrict root Login to System Console (stat securetty) (Not Scored)\n    stat: path=/etc/securetty\n    register: securetty_file\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.4 Restrict root Login to System Console (Not Scored)\n    debug: msg='*** Check /etc/securetty for console allowed for root access ***'\n    when: securetty_file.stat.exists == True\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.5.1 Restrict Access to the su Command (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/su'\n        line='auth            required        pam_wheel.so use_uid'\n        state=present\n    tags:\n      - section9\n      - section9.5\n      - section9.5.1\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "b3a2b6f2add91e9a2b3e89725703555ecb24dfaa", "filename": "roles/fail2ban/defaults/main.yml", "repository": "roots/trellis", "decoded_content": "---\nfail2ban_loglevel: 3\nfail2ban_logtarget: /var/log/fail2ban.log\nfail2ban_socket: /var/run/fail2ban/fail2ban.sock\n\nfail2ban_ignoreip: 127.0.0.1/8 {{ ip_whitelist | join(' ') }}\nfail2ban_bantime: 600\nfail2ban_maxretry: 6\n\nfail2ban_backend: polling\n\nfail2ban_destemail: root@localhost\nfail2ban_banaction: iptables-multiport\nfail2ban_mta: sendmail\nfail2ban_protocol: tcp\nfail2ban_chain: INPUT\n\nfail2ban_action: action_\n\nfail2ban_services:\n  - name: ssh\n    port: ssh\n    filter: sshd\n    logpath: /var/log/auth.log\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "a8ef6ce9c434d2752646dca7dbc96cb2cc68f670", "filename": "roles/network/tasks/debian.yml", "repository": "iiab/iiab", "decoded_content": "# debian.yml\n# Start out making simplifying assumptions\n#   1. we are dealing with a rpi3\n#   2. Gui inputs define the config -- auto config is more difficult\n#      a. gui_desired_network_role\n#      b. hostapd_enabled\n#      c. gui_static_wan_ip\n#   3. In appliance mode: wan (and wlan0) is either static or dhcp under br0, and hostapd off\n#   4. In lan_controller: wan is off, eth0 and wlan0 under br0\n#   5. In gateway: eth0 is wan, and wlan0 is under br0 (only one adapter under br0)\n#   6. As a slight concess to auto config, if eth1 exists, make it wan, and force gateway\n\n- name: in upgrade from earlier 6.2, delete the resolvconf\n  package: name=resolvconf\n           state=absent\n           enabled=False\n  ignore_errors: True\n\n- name: Get the dhcp client daemon used in recent raspbian\n  package: name=dhcpcd5\n           state=present\n\n- name: for upgrades from earlier 6.2, remove br0 file\n  file: path=/etc/network/interfaces.d/br0\n        state=absent\n\n- name: default to lan controller\n  set_fact:\n      gui_desired_network_role: \"lan_controller\"\n  when: not gui_desired_network_role is defined\n\n- name: Recover from putting config in /etc/network/interfaces\n  template: dest=/etc/network/interfaces\n            src=network/interfaces.j2\n\n- name: Copy the bridge script\n  template: dest=/etc/network/interfaces.d/iiab\n            src=network/iiab.j2\n  register: interface\n\n- name: start up the dhcpcd service\n  service: name=dhcpcd\n           enabled=True\n           state=started\n\n- name: If this was a change, things need to shift\n  service: name=hostapd state=stopped\n  when: interface.changed\n\n- name: dhcpd may be affected\n  service: name=bind9 state=stopped\n  when: interface.changed\n\n- name: restart the networking service\n  service: name=networking state=restarted\n  when: interface.changed\n\n- name: start up hostapd again\n  service: name=hostapd state=started\n  when: interface.changed\n\n- name: dhcpd may be affected\n  service: name=bind9 state=started\n  when: interface.changed\n\n#create lan br0 if lan_controller or gateway\n#create wan br0 if appliance\n#allocate wlan0 under br0 in all cases\n#allocate eth0 under br0 if appliance, alone if gateway\n\n- name: Add location section to config file\n  ini_file: dest='{{ iiab_config_file }}'\n            section=network\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n  - option: 'gateway_active'\n    value:  '{{ gw_active }}'\n  - option: 'internet_available'\n    value:  '{{ internet_available }}'\n  - option: 'gateway_ifcfg'\n    value: '{{ has_ifcfg_gw }}'\n  - option: 'detected_gateway'\n    value: '{{ discovered_wan_iface }}'\n  - option: 'prior_gateway'\n    value: '{{ device_gw2 }}'\n  - option: 'wireless_list_1'\n    value: '{{ wifi1 }}'\n  - option: 'wireless_list_2'\n    value: '{{ wifi2 }}'\n  - option: 'num_wifi_interfaces'\n    value: '{{ num_wifi_interfaces }}'\n  - option: 'discovered_wireless_iface'\n    value: '{{ discovered_wireless_iface }}'\n  - option: 'iiab_wireless_lan_iface'\n    value: '{{ iiab_wireless_lan_iface }}'\n  - option: 'num_lan_interfaces'\n    value: '{{ num_lan_interfaces }}'\n  - option: 'detected_lan'\n    value: '{{ discovered_lan_iface }}'\n  - option: 'static_wan'\n    value: '{{ gui_static_wan }}'\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "1f68c2e3821f63803ee1b6a0d5f13c4cf1ff8747", "filename": "roles/ansible/tower/config-ansibletower/tests/inventory/group_vars/tower.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ntower_admin_password: \"admin01\"\npg_password: \"pg_password01\"\nrabbitmq_password: \"rabbitmq_password01\"\n\n# Update this to a valid tower license file\n#tower_license_file: \"{{ inventory_dir }}/../files/tower-license.json\"\n\n# Overall flag to indicate if LDAP should be configured or not\nldap_config: False\n\n# NOTE: example on how these files can be specified - please replace with valid files\n#ldap_ca_cert: \"{{ inventory_dir }}/../files/ca.crt\" \n\nldap_uri: \"ldaps://idm.test.example.com:636\"\nldap_bind_dn: \"uid=bind-user,cn=users,cn=accounts,dc=test,dc=example,dc=com\"\nldap_bind_password: \"my-bind-secret\"\n\nldap_user_search_dn: \"cn=users,cn=accounts,dc=test,dc=example,dc=com\"\nldap_user_dn_template: \"uid=%(user)s,cn=users,cn=accounts,dc=test,dc=example,dc=com\"\n\nldap_group_search_dn: \"cn=groups,cn=accounts,dc=test,dc=example,dc=com\"\n\nldap_require_group: \"cn=tower-users,cn=groups,cn=accounts,dc=test,dc=example,dc=com\"\nldap_admin_group: \"cn=tower-admins,cn=groups,cn=accounts,dc=test,dc=example,dc=com\"\n\nldap_organization_map:\n- name: \"My Admin Org\"\n  ldap_admin_group: \"cn=tower-admins,cn=groups,cn=accounts,dc=test,dc=example,dc=com\"\n  ldap_user_groups:\n  - \"cn=tower-users,cn=groups,cn=accounts,dc=test,dc=example,dc=com\"\n- name: \"My Support Org\"\n  ldap_admin_group: \"cn=tower-admins,cn=groups,cn=accounts,dc=test,dc=example,dc=com\"\n  ldap_user_groups:\n  - \"cn=tower-users,cn=groups,cn=accounts,dc=test,dc=example,dc=com\"\n  - \"cn=tower-support,cn=groups,cn=accounts,dc=test,dc=example,dc=com\"\n\nldap_team_map:\n- name: \"My First Team\"\n  organization: \"First Org\"\n  ldap_user_groups:\n  - \"cn=users1,cn=groups,cn=accounts,dc=test,dc=example,dc=com\"\n  - \"cn=users2,cn=groups,cn=accounts,dc=test,dc=example,dc=com\"\n- name: \"My Second Team\"\n  organization: \"Second Org\"\n  ldap_user_groups:\n  - \"cn=users1,cn=groups,cn=accounts,dc=test,dc=example,dc=com\"\n\n\n"}, {"commit_sha": "abafe1581c6c78d784cf215b214947675d49eff8", "sha": "d894b2e5e8827a24cc2b923272bd1ff895b3d898", "filename": "roles/cloud-azure/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- set_fact:\n    resource_group: \"Algo_{{ region }}\"\n\n- name: Create a resource group\n  azure_rm_resourcegroup:\n    secret: \"{{ azure_secret | default(lookup('env','AZURE_CLIENT_ID')) }}\"\n    tenant: \"{{ azure_tenant | default(lookup('env','AZURE_SECRET')) }}\"\n    client_id: \"{{ azure_client_id | default(lookup('env','AZURE_SUBSCRIPTION_ID')) }}\"\n    subscription_id: \"{{ azure_subscription_id | default(lookup('env','AZURE_TENANT')) }}\"\n    name: \"{{ resource_group }}\"\n    location: \"{{ region }}\"\n    tags:\n        service: algo\n\n- name: Create a virtual network\n  azure_rm_virtualnetwork:\n    resource_group: \"{{ resource_group }}\"\n    name: algo_net\n    address_prefixes: \"10.10.0.0/16\"\n    tags:\n        service: algo\n\n- name: Create a subnet\n  azure_rm_subnet:\n    resource_group: \"{{ resource_group }}\"\n    name: algo_subnet\n    address_prefix: \"10.10.0.0/24\"\n    virtual_network: algo_net\n    tags:\n        service: algo\n\n- name: Create an instance\n  azure_rm_virtualmachine:\n    secret: \"{{ azure_secret | default(lookup('env','AZURE_CLIENT_ID')) }}\"\n    tenant: \"{{ azure_tenant | default(lookup('env','AZURE_SECRET')) }}\"\n    client_id: \"{{ azure_client_id | default(lookup('env','AZURE_SUBSCRIPTION_ID')) }}\"\n    subscription_id: \"{{ azure_subscription_id | default(lookup('env','AZURE_TENANT')) }}\"\n    resource_group: \"{{ resource_group }}\"\n    admin_username: ubuntu\n    virtual_network: algo_net\n    name: \"{{ azure_server_name }}\"\n    ssh_password_enabled: false\n    vm_size: Standard_D1\n    tags:\n      service: algo\n    ssh_public_keys:\n      - { path: \"/home/ubuntu/.ssh/authorized_keys\", key_data: \"{{ lookup('file', '{{ ssh_public_key }}') }}\" }\n    image:\n      offer: UbuntuServer\n      publisher: Canonical\n      sku: '16.04-LTS'\n      version: latest\n  register: azure_rm_virtualmachine\n\n- set_fact:\n    ip_address: \"{{ azure_rm_virtualmachine.ansible_facts.azure_vm.properties.networkProfile.networkInterfaces[0].properties.ipConfigurations[0].properties.publicIPAddress.properties.ipAddress }}\"\n\n- name: Add the instance to an inventory group\n  add_host:\n    name: \"{{ ip_address }}\"\n    groups: vpn-host\n    ansible_ssh_user: ubuntu\n    ansible_python_interpreter: \"/usr/bin/python2.7\"\n    easyrsa_p12_export_password: \"{{ easyrsa_p12_export_password }}\"\n    cloud_provider: azure\n    ipv6_support: no\n\n- name: Wait for SSH to become available\n  local_action: \"wait_for port=22 host={{ ip_address }} timeout=320\"\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "c3a5ece29b637416ffc765058f0518948a02366f", "filename": "roles/config-clair/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Restart Clair Service\n  systemd:\n    name: \"{{ clair_name }}\"\n    enabled: yes\n    state: restarted\n    daemon_reload: yes\n\n- name: restart firewalld\n  service:\n    name: firewalld\n    state: restarted\n\n- name: restart iptables\n  service:\n    name: iptables\n    state: restarted"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "414895820e4a8ebb7bd8de7c93051ecdf816cd8d", "filename": "roles/config-docker/tasks/docker.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: \"Install additional packages for Docker\"\n  package:\n    name: \"{{ item }}\"\n    state: latest\n  with_items:\n  - docker\n  notify: \n  - restart docker\n\n- name: \"Enable docker\"\n  service:\n    name: docker\n    enabled: yes\n    state: started\n\n# This task will error out if the user doesn't exist\n- name: \"Check to see if the targeted docker user exists\"\n  command: id \"{{ docker_username }}\"\n  changed_when: false\n\n- name: \"Add docker group\"\n  group:\n    name: docker\n    state: present\n  notify: restart docker\n\n- name: \"Add username to the docker group\" \n  user:\n    name: \"{{ docker_username }}\"\n    groups: docker\n    append: yes\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "df42b4279f4d4d6aa1942817f78ede162c56a675", "filename": "meta/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\ngalaxy_info:\n  author: \"Petr Kubica\"\n  description: \"oVirt Deployment\"\n  company: \"Red Hat\"\n  license: \"GPLv3\"\n  min_ansible_version: 1.9\n  platforms:\n  - name: EL\n    versions:\n    - all\n  galaxy_tags:\n    - installer\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "45570d910498e56bcf16fcd8cd5c3d5dd07b9e51", "filename": "roles/ansible/tower/manage-job-templates/tasks/set-permissions.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Obtain team id based on the team name\"\n  set_fact:\n    object_id: \"{{ item.id }}\"\n  when:\n  - permissions_object == \"teams\"\n  - item.name|trim == permissions_value.name|trim\n  with_items:\n  - \"{{ existing_teams_output.rest_output }}\"\n\n- name: \"Obtain user id based on the username\"\n  set_fact:\n    object_id: \"{{ item.id }}\"\n  when:\n  - permissions_object == \"users\"\n  - item.username|trim == permissions_value.name|trim\n  with_items:\n  - \"{{ existing_users_output.rest_output }}\"\n\n- name: \"Obtain role id based on the job_template name + role name\"\n  set_fact:\n    role_id: \"{{ item.id }}\"\n  when:\n  - item.summary_fields is defined\n  - item.summary_fields.resource_name is defined\n  - item.summary_fields.resource_name|trim == job_template.name|trim\n  - item.name|trim == permissions_value.role|trim\n  with_items:\n  - \"{{ existing_roles_output.rest_output }}\"\n\n- name: \"Set Permission\"\n  uri:\n    url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}/api/v2/{{ permissions_object }}/{{ object_id }}/roles/\"\n    user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n    password: \"{{ ansible_tower.admin_password }}\"\n    force_basic_auth: yes\n    method: POST\n    body: \"{{ { 'id': role_id|int } }}\"\n    body_format: 'json'\n    headers:\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n    validate_certs: no\n    status_code: 200,204\n  when:\n  - object_id is defined\n  - object_id|trim != ''\n  - role_id is defined\n  - role_id|trim != ''\n"}, {"commit_sha": "96adc61e360141bb718b75d48c387b3680a8471b", "sha": "6609113c885252f6b997eba96336e806f639ad57", "filename": "tasks/remove-pre-docker-ce.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Determine Docker version\n  command: bash -c \"docker version | grep Version | awk '{print $2}'\"\n  ignore_errors: yes\n  changed_when: false\n  register: cmd_docker_version\n\n- name: Set fact if old Docker installation shall be removed\n  set_fact:\n    remove_old_docker: \"{{ docker_remove_pre_ce | bool }} == true and {{ cmd_docker_version.stdout_lines[0] | search('-ce') }} == false\"\n  when: cmd_docker_version.stdout_lines is defined and cmd_docker_version.stdout_lines[0] is defined\n\n- name: Check if Docker is running\n  command: systemctl status docker\n  ignore_errors: yes\n  changed_when: false\n  register: service_docker_status\n  when: remove_old_docker | default(false) | bool == true\n  become: true\n\n- name: Stop Docker service\n  service:\n    name: docker\n    state: stopped\n  when: \"service_docker_status.rc | default(1) == 0\"\n\n- name: Remove old Docker installation before Docker CE\n  package:\n    name: \"{{ item }}\"\n    state: absent\n  become: true\n  when: remove_old_docker|default(false) | bool == true\n  with_items:\n    - \"{{ docker_old_packages[_docker_os_dist] }}\"\n"}, {"commit_sha": "7c574f3b148b4df43177a5c0fc398ce4bea6ae3e", "sha": "6378ca60a715903c6fa7fb8cf667dee18ed94cd4", "filename": "handlers/main.yml", "repository": "zzet/ansible-rbenv-role", "decoded_content": "---\n# handlers file for rbenv\n- name: rehash rbenv\n  shell: RBENV_ROOT={{ rbenv_root }} rbenv rehash\n\n"}, {"commit_sha": "836dc4dd0dacc490044a14c0e39469d162b9449b", "sha": "acd6e50847fa46e8f5aeae2b1d49ce8c4c87d0bd", "filename": "handlers/main.yml", "repository": "florianutz/Ubuntu1604-CIS", "decoded_content": "---\n# handlers file for Ubuntu1604-CIS\n\n- name: sysctl flush ipv4 route table\n  become: true\n  sysctl:\n      name: net.ipv4.route.flush\n      value: 1\n      sysctl_set: true\n  when: ansible_virtualization_type != \"docker\"\n\n- name: sysctl flush ipv6 route table\n  become: true\n  sysctl:\n      name: net.ipv6.route.flush\n      value: 1\n      sysctl_set: true\n  when: ansible_virtualization_type != \"docker\"\n\n- name: systemd restart tmp.mount\n  become: true\n  systemd:\n      name: tmp.mount\n      daemon_reload: true\n      enabled: true\n      masked: false\n      state: reloaded\n  when: ansible_virtualization_type != \"docker\"\n\n- name: systemd restart var-tmp.mount\n  become: true\n  systemd:\n      name: var-tmp.mount\n      daemon_reload: true\n      enabled: true\n      masked: false\n      state: reloaded\n\n- name: generate new grub config\n  become: true\n  command: grub-mkconfig -o \"{{ grub_cfg.stat.path }}\"\n\n- name: restart firewalld\n  become: true\n  service:\n      name: firewalld\n      state: restarted\n\n- name: restart xinetd\n  become: true\n  service:\n      name: xinetd\n      state: restarted\n\n- name: restart sshd\n  become: true\n  service:\n      name: sshd\n      state: restarted\n\n- name: reload dconf\n  become: true\n  command: dconf update\n\n- name: restart auditd\n  become: true\n  service:\n      name: auditd\n      state: restarted\n  when:\n      - ubuntu1604cis_skip_for_travis == false\n  tags:\n      - skip_ansible_lint\n\n- name: load audit rules\n  become: true\n  command: /sbin/augenrules --load\n  when:\n      - ubuntu1604cis_skip_for_travis == false\n  tags:\n      - skip_ansible_lint\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "eb7428b3fd1e8cb7f35a235666831f488b73dee0", "filename": "tasks/create_repo_pypi_group_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_pypi_group\n    args: \"{{ _nexus_repos_pypi_defaults|combine(item) }}\""}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "b9e3048f41d452439fb032e7281d5c4eb0bf4367", "filename": "roles/letsencrypt/tasks/setup.yml", "repository": "roots/trellis", "decoded_content": "- name: Create directories and set permissions\n  file:\n    mode: \"{{ item.mode | default(omit) }}\"\n    path: \"{{ item.path }}\"\n    state: directory\n  with_items:\n    - path: \"{{ acme_tiny_data_directory }}\"\n      mode: '0700'\n    - path: \"{{ acme_tiny_data_directory }}/csrs\"\n    - path: \"{{ acme_tiny_software_directory }}\"\n    - path: \"{{ acme_tiny_challenges_directory }}\"\n    - path: \"{{ letsencrypt_certs_dir }}\"\n      mode: '0700'\n\n- name: Clone acme-tiny repository\n  git:\n    dest: \"{{ acme_tiny_software_directory }}\"\n    repo: \"{{ acme_tiny_repo }}\"\n    version: \"{{ acme_tiny_commit }}\"\n    accept_hostkey: yes\n\n- name: Copy Lets Encrypt account key source file\n  copy:\n    src: \"{{ letsencrypt_account_key_source_file }}\"\n    dest: \"{{ letsencrypt_account_key }}\"\n  when: letsencrypt_account_key_source_file is defined\n\n- name: Copy Lets Encrypt account key source contents\n  copy:\n    content: \"{{ letsencrypt_account_key_source_content | trim }}\"\n    dest: \"{{ letsencrypt_account_key }}\"\n  when: letsencrypt_account_key_source_content is defined\n\n- name: Generate a new account key\n  shell: openssl genrsa 4096 > {{ letsencrypt_account_key }}\n  args:\n    creates: \"{{ letsencrypt_account_key }}\"\n  register: generate_account_key\n  when: letsencrypt_account_key_source_content is not defined and letsencrypt_account_key_source_file is not defined\n\n- name: Generate certificate renewal script\n  template:\n    src: renew-certs.py\n    dest: \"{{ acme_tiny_data_directory }}/renew-certs.py\"\n    mode: 0700\n\n- name: Download intermediate certificate\n  get_url:\n    url: \"{{ letsencrypt_intermediate_cert_url }}\"\n    dest: \"{{ letsencrypt_intermediate_cert_path }}\"\n    sha256sum: \"{{ letsencrypt_intermediate_cert_sha256sum }}\"\n\n- name: Create Nginx conf for challenges location\n  template:\n    src: acme-challenge-location.conf.j2\n    dest: \"{{ nginx_path }}/acme-challenge-location.conf\"\n"}, {"commit_sha": "beb41b82405655aa385bb8297bf49ada1a4eb14c", "sha": "bbbfafd0812e17e58e7fbe3faa77144f1c5852e5", "filename": "tasks/Win32NT/fetch/zulu-fallback.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: 'Fetch download page'\n  win_uri:\n    url: \"{{ zulu_api_page }}\\\n      /bundles/latest/\\\n      ?version={{ java_major_version }}\\\n      &ext=zip&os=win&\\\n      arch={{ (java_arch == 'x64') | ternary('x64', 'x86') }}\"\n    return_content: true\n    follow_redirects: all\n  register: root_page\n\n- name: Find release url and checksum\n  set_fact:\n    release_url: >-\n      {{ [(root_page.content | from_json).url] + [(root_page.content | from_json).md5_hash] }}\n\n- name: 'Get artifact checksum {{ release_url[1] }}'\n  set_fact:\n    artifact_checksum:\n      content: >-\n        {{ release_url[1] }}\n\n- name: Exit if Zulu version is not found\n  fail:\n    msg: 'Zulu version {{ java_major_version }} not found'\n  when: release_url is not defined\n\n- name: 'Download artifact from {{ release_url[0] }}'\n  win_get_url:\n    url: '{{ release_url }}'\n    dest: '{{ java_download_path }}'\n    force: true\n    checksum: '{{ artifact_checksum.content }}'\n    checksum_algorithm: '{{ checksum_alg }}'\n  register: file_downloaded\n  retries: 20\n  delay: 5\n  until: file_downloaded is succeeded\n  when: ansible_version.full is version('2.8.0', '>=')\n\n- name: Old fetch (Ansible < 2.8)\n  include_tasks: fetch_fallback_old.yml\n  when: ansible_version.full is version('2.8.0', '<')\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "c8d505fc118a2eb239f4df748ca97d4a7430bc00", "filename": "roles/users/tasks/connection-warnings.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Fail if root login will be disabled but admin_user cannot connect\n  fail:\n    msg: 'The admin_user `{{ admin_user }}` is unable to connect to the server. To prevent you from losing access to your server, the playbook has halted before disabling root login (`sshd_permit_root_login: false`). Ensure that the admin_user appears in your `users` hash with a valid entry for `keys`.'\n  when: not cli_ask_pass | default(false) and ansible_user == 'root'\n\n- block:\n  - name: Confirm that a non-root user can connect\n    pause:\n      prompt: |\n\n        The play will disable SSH login for `root` (because `sshd_permit_root_login: false`)\n        but the admin_user named `{{ admin_user }}` appears unable to connect via SSH key.\n\n        Be careful to avoid losing SSH access to your server.\n        Continue only if `{{ admin_user }}` will be able to connect via password or if\n        a different user will be able to connect and invoke sudo.\n\n        (press RETURN to continue or CTRL+C to abort)\n    when: not sshd_permit_root_login and ansible_user == 'root'\n\n  - name: Confirm disabling of SSH password authentication\n    pause:\n      prompt: |\n\n        The play will disable password login (because `sshd_password_authentication: false`)\n        but the admin_user named `{{ admin_user }}` appears unable to connect via SSH key.\n\n        Be careful to avoid losing SSH access to your server.\n        Continue only if you are certain you will have another means of connecting,\n        such as via SSH keys.\n\n        If you prefer to continue to allow SSH password authentication (less secure),\n        abort now and make the following edit in `group_vars/all/security.yml`:\n        `sshd_password_authentication: true`\n\n        (press RETURN to continue or CTRL+C to abort)\n    when: not sshd_password_authentication\n\n  when: cli_ask_pass | default(false)\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "09e9b63c942a008e1867ad482d49b72b53213997", "filename": "tasks/section_08.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - include: section_08_level1.yml\n    tags:\n      - section08\n      - level1\n       \n\n  - include: section_08_level2.yml\n    tags:\n      - section08\n      - level2\n\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "0002ab7869871aabdb1e5d8120e997ba6e556e04", "filename": "tasks/Linux/fetch/zulu-fallback.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: 'Fetch download page'\n  uri:\n    url: \"{{ zulu_api_page }}\\\n      /bundles/latest/\\\n      ?version={{ java_major_version }}\\\n      &ext=tar.gz&os=linux&\\\n      arch={{ (java_arch == 'x64') | ternary('x64', 'x86') }}\"\n    return_content: true\n    follow_redirects: all\n  register: root_page\n\n- name: Find release url\n  set_fact:\n    release_url: >-\n      {{ (root_page.content | from_json).url }}\n\n- name: Find checksum\n  set_fact:\n    checksum: >-\n      {{ (root_page.content | from_json).md5_hash }}\n\n- name: Exit if Zulu version is not found\n  fail:\n    msg: 'Zulu version {{ java_major_version }} not found'\n  when: release_url is not defined\n\n- name: 'Download artifact from {{ release_url }}'\n  get_url:\n    url: '{{ release_url }}'\n    dest: '{{ java_download_path }}'\n    checksum: 'md5:{{ checksum }}'\n  register: file_downloaded\n  retries: 20\n  delay: 5\n  until: file_downloaded is succeeded\n"}, {"commit_sha": "9662c15ce2e4260fac5cc2bfdf5aaaaf0a2191dd", "sha": "0c3b34937b2ab2fb66d85d062b5ac1f2b8b8867f", "filename": "tasks/section_04_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 4.5 Activate AppArmor (install) (Scored)\n    apt: >\n        name=apparmor\n        state=present\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (start) (Scored)\n    service: >\n        name=apparmor\n        state=started\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (Scored)\n    command: apparmor_status\n    register: aa_status_lines\n    failed_when: '\"0 profiles are loaded\" in aa_status_lines.stdout_lines or \"0 processes are in complain mode.\" not in aa_status_lines.stdout_lines or \"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n        # - '\"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n    changed_when: False\n    when: travis_env == False\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (enforce install) (Scored)\n    apt: >\n        name=apparmor-utils\n        state=present\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (enforce) (Scored)\n    shell: 'aa-enforce /etc/apparmor.d/*'\n    register: aaenforce_rc\n    failed_when: aaenforce_rc.rc == 1\n    changed_when: False\n    tags:\n      - section4\n      - section4.5\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "409ba93c55c894921e4814d0cb7492dd28d2b97b", "filename": "roles/activity-server/files/lang_templates/ht/page", "repository": "iiab/iiab", "decoded_content": "<!DOCTYPE html>\n<META http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n<body>\n<h1 id=\"olpc-activity-group-name\">Aktivite ki disponib nan Bwat la</h1>\n<p id=\"olpc-activity-group-desc\">Aktivite sa yo disponib sou sit lek\u00f2l la.</p>\n%(activities)s\n</body>\n</html>\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "fe6e6f536d5962d9cdd40b7cbac4fca7edc0f8ee", "filename": "roles/dns/manage-dns-zones-bind/tasks/print_keys.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Print configured keys - if requested\"\n  debug:\n    var: nsupdate_keys\n  run_once: true\n  when:\n  - print_dns_keys|default(False)\n  delegate_to: \"{{ ansible_play_hosts | first }}\"\n"}, {"commit_sha": "d7fbb1f61d1191166152acc249d0e910859619ca", "sha": "ff55df29f92a3a92ed2e6868ec189f108bb5cd01", "filename": "tasks/bug-tweaks.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "# Configuration to avoid 'Device or resource busy'\n- block:\n  - name: Stat /proc/sys/fs/may_detach_mounts (CentOS/RedHat)\n    stat:\n      path: /proc/sys/fs/may_detach_mounts\n    register: may_detach_mounts\n\n  - name: Ensure fs.may_detach_mounts is set to avoid 'Device or resource busy' (CentOS/RedHat)\n    become: true\n    sysctl:\n      name: fs.may_detach_mounts\n      value: 1\n      sysctl_file: /etc/sysctl.d/99-docker.conf\n      reload: yes\n    when: may_detach_mounts.stat.exists\n\n  # Keep for compatibility reasons of this role. Now everything is in the same file.\n  - name: Remove systemd drop-in for Docker Mount Flags slave configuration (CentOS/RedHat)\n    become: true\n    file:\n      path: /etc/systemd/system/docker.service.d/mountflags-slave.conf\n      state: absent\n    notify: restart docker\n\n  - name: Set systemd service MountFlags option to \"slave\" to prevent \"device busy\" errors on CentOS/RedHat 7.3 kernels (CentOS/RedHat)\n    set_fact:\n      docker_systemd_service_config_tweaks: \"{{ docker_systemd_service_config_tweaks + _systemd_service_config_tweaks }}\"\n    vars:\n      _systemd_service_config_tweaks:\n        - 'MountFlags=slave'\n  when:\n    - _docker_os_dist == \"CentOS\" or _docker_os_dist == \"RedHat\"\n    - docker_enable_mount_flag_fix | bool\n    - ansible_kernel | version_compare('4', '<')\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "3c57ec6bf7f85203e1f3b1facdf1557cb98affe8", "filename": "tasks/plus/setup-debian.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: Debian/Ubuntu) Add NGINX Plus Repository\"\n  apt_repository:\n    repo: deb https://plus-pkgs.nginx.com/{{ ansible_distribution | lower }} {{ ansible_distribution_release }} nginx-plus\n    filename: nginx-plus\n    update_cache: no\n\n- name: \"(Install: Debian/Ubuntu) Verify NGINX Plus License\"\n  blockinfile:\n    path: /etc/apt/apt.conf.d/90nginx\n    create: yes\n    block: |\n      Acquire::https::plus-pkgs.nginx.com::Verify-Peer \"true\";\n      Acquire::https::plus-pkgs.nginx.com::Verify-Host \"true\";\n      Acquire::https::plus-pkgs.nginx.com::SslCert     \"/etc/ssl/nginx/nginx-repo.crt\";\n      Acquire::https::plus-pkgs.nginx.com::SslKey      \"/etc/ssl/nginx/nginx-repo.key\";\n\n- name: \"(Install: Debian/Ubuntu) Update APT Cache\"\n  apt:\n    update_cache: yes\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "a45c61c36891a979c61949e5873fa794cdd9054b", "filename": "roles/ejabberd_xs/templates/10-ejabberdmoodle", "repository": "iiab/iiab", "decoded_content": "##\n## 10-ejabberdmoodle\n## for ejabberd-moodle interaction\n##\n\n# allow the apache user to invoke ejabberdctl and start/stop/condrestart \nDefaults:apache !requiretty\nCmnd_Alias EJABBERDCTL = /usr/sbin/ejabberdctl \nCmnd_Alias EJABBERDINIT = /etc/init.d/ejabberd start , /etc/init.d/ejabberd stop , /etc/init.d/ejabberd condrestart\n\napache ALL = (ejabberd) NOPASSWD: EJABBERDCTL\napache ALL = (root) NOPASSWD: EJABBERDINIT\n"}, {"commit_sha": "d7fbb1f61d1191166152acc249d0e910859619ca", "sha": "083a06ada7e59272066385e4463b79a6d4db144c", "filename": "tasks/setup-repository.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Ensure python and deps for Ansible modules\n  become: true\n  raw: dnf install -y python2 python2-dnf libselinux-python\n  changed_when: false\n  when: _docker_os_dist == \"Fedora\"\n\n- name: Update APT cache\n  become: true\n  apt:\n    update_cache: yes\n  changed_when: false\n  when: _docker_os_dist == \"Ubuntu\" or\n        _docker_os_dist == \"Debian\"\n\n- name: Ensure packages are installed for repository setup\n  become: true\n  package:\n    name: \"{{ item }}\"\n    state: present\n  with_items:\n    - \"{{ docker_repository_related_packages[_docker_os_dist] }}\"\n  when: _docker_os_dist == \"Ubuntu\" or\n        _docker_os_dist == \"Debian\" or\n        _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Add Docker official GPG key\n  become: true\n  apt_key:\n    url: https://download.docker.com/linux/{{ _docker_os_dist|lower }}/gpg\n    state: present\n  when: (_docker_os_dist == \"Ubuntu\" and _docker_os_dist_major_version > '14')\n        or _docker_os_dist == \"Debian\"\n\n- name: Add Docker APT key (alternative for older Ubuntu systems without SNI).\n  become: true\n  shell: \"curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\"\n  args:\n    warn: false\n  changed_when: false\n  when: _docker_os_dist == \"Ubuntu\" and\n        _docker_os_dist_major_version == '14'\n\n- name: Add Docker CE repository (Ubuntu/Debian)\n  become: true\n  apt_repository:\n    repo: deb [arch=amd64] https://download.docker.com/linux/{{ _docker_os_dist|lower }} {{ _docker_os_dist_release }} stable {{ (docker_enable_ce_edge == true) | ternary('edge','') }}\n    state: present\n    filename: 'docker-ce'\n  when: _docker_os_dist == \"Ubuntu\" or\n        _docker_os_dist == \"Debian\"\n\n- name: Add Docker CE repository (Fedora/CentOS/RedHat)\n  become: true\n  get_url:\n    url: \"{{ docker_repository_url[_docker_os_dist] }}\"\n    dest: /etc/yum.repos.d/docker-ce.repo\n    mode: 0644\n  register: docker_repo\n  when: _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"Fedora\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Determine Docker CE Edge repo status (Fedora/CentOS/RedHat)\n  shell: \"{{ docker_cmd_check_edge_repo_status[_docker_os_dist] }}\"\n  args:\n    warn: false\n  ignore_errors: yes\n  changed_when: false\n  register: cmd_docker_ce_edge_enabled\n  when: _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"Fedora\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Set current Docker CE Edge repo status fact (Fedora/CentOS/RedHat)\n  set_fact:\n    _fact_docker_ce_edge_enabled: \"{{ cmd_docker_ce_edge_enabled.stdout == 'enabled = True' }}\"\n  when: _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"Fedora\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Enable/Disable Docker CE Edge Repository (Fedora/CentOS/RedHat)\n  become: true\n  shell: \"{{ docker_cmd_enable_disable_edge_repo[_docker_os_dist] }}\"\n  when: (_docker_os_dist == \"CentOS\" or _docker_os_dist == \"Fedora\" or _docker_os_dist == \"RedHat\") and\n        _fact_docker_ce_edge_enabled != docker_enable_ce_edge\n\n# disable rt-beta so we don't get a 403 error retrieving repomd.xml\n- name: Check if rhel-7-server-rt-beta-rpms Repository is enabled (RedHat)\n  become: true\n  shell: \"subscription-manager repos --list-enabled | grep rhel-7-server-rt-beta-rpms\"\n  register: cmd_rhel_rt_beta_repo_enabled\n  when: _docker_os_dist == \"RedHat\"\n  changed_when: false\n  failed_when: cmd_rhel_rt_beta_repo_enabled.rc not in [ 0, 1 ]\n\n- name: Disable rhel-7-server-rt-beta-rpms Repository (RedHat)\n  become: true\n  shell: \"subscription-manager repos --disable=rhel-7-server-rt-beta-rpms\"\n  when: _docker_os_dist == \"RedHat\" and cmd_rhel_rt_beta_repo_enabled.rc == 0\n\n# container-selinux package wants this\n- name: Check if rhel-7-server-extras-rpms Repository is enabled (RedHat)\n  become: true\n  shell: \"subscription-manager repos --list-enabled | grep rhel-7-server-extras-rpms\"\n  register: cmd_rhel_extras_repo_enabled\n  when: _docker_os_dist == \"RedHat\"\n  changed_when: false\n  failed_when: cmd_rhel_extras_repo_enabled.rc not in [ 0, 1 ]\n\n- name: Enable rhel-7-server-extras-rpms Repository (RedHat)\n  become: true\n  shell: \"subscription-manager repos --enable=rhel-7-server-extras-rpms\"\n  when: _docker_os_dist == \"RedHat\" and cmd_rhel_extras_repo_enabled.rc == 1\n\n- name: Update repository cache\n  become: true\n  shell: \"{{ docker_cmd_update_repo_cache[_docker_os_dist] }}\"\n  args:\n    warn: false\n  when: docker_repo.changed"}, {"commit_sha": "49010188a985bfe713552eb8980cfa0d7a888daf", "sha": "eded206ee8d35f0245656b85fbc8b479541885f1", "filename": "roles/requirements.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "# This is the Ansible Galaxy requirements file to pull in the correct roles\n# to support the operation of CASL provisioning/runs.\n# and also support any role dependency while using the repository in Ansible Tower\n\n# From 'infra-ansible'\n- src: https://github.com/redhat-cop/infra-ansible\n  version: v1.0.8\n\n# From 'openshift-applier'\n- src: https://github.com/redhat-cop/openshift-applier\n  version: v2.0.8\n\n# From 'openshift-ansible'\n- src: https://github.com/openshift/openshift-ansible\n  version: release-3.11\n\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "cdfd8add7a0d167a30907a0d0c913c8a41ff4354", "filename": "tasks/main.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Load a system variables file based on distribution or OS family\n  include_vars: '{{ distribution }}'\n  with_first_found:\n    - '{{ ansible_os_family }}.yml'\n    - default.yml\n  loop_control:\n    loop_var: distribution\n\n- name: Set base variables based on java distribution\n  include_vars: 'java_distro_configs/{{ java_distribution }}_vars.yml'\n\n- name: 'Fetch oracle artifact with {{ transport }} transport'\n  include_tasks: '{{ transport_driver }}'\n  with_first_found:\n    - '{{ ansible_system }}/fetch/{{ transport }}.yml'\n    - unknown-transport.yml\n  loop_control:\n    loop_var: transport_driver\n\n- name: Choose platform based task\n  include_tasks: '{{ platform }}'\n  with_first_found:\n    - '{{ ansible_system }}/system_{{ transport }}.yml'\n    - '{{ ansible_system }}/system_{{ java_binary_type }}.yml'\n    - '{{ ansible_system }}/system.yml'\n    - not-supported.yml\n  loop_control:\n    loop_var: platform\n\n- name: Apply security policy patch\n  include_tasks: '{{ platform }}'\n  with_first_found:\n    - '{{ ansible_system }}/security_policy.yml'\n    - not-supported.yml\n  loop_control:\n    loop_var: platform\n  when:\n    - java_unlimited_policy_enabled\n    - java_distribution == 'oracle_java'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "d1c4ac0ef3bde0b5a73e1ec7223ab2f9cb126f4e", "filename": "roles/config-redis/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Install Containerized Redis\n  include_tasks: install_containerized.yml\n  when: mode == \"containerized\"\n\n- name: Flush Handlers (Redis)\n  meta: flush_handlers\n"}, {"commit_sha": "1d7d3a653c598355333e7c34a54a550ed3d79cc5", "sha": "3fdf8af6580e20b846f51eac45ad976a59eab1e3", "filename": "tasks/nginx.yml", "repository": "RocketChat/Rocket.Chat.Ansible", "decoded_content": "---\n# tasks/nginx.yml: Nginx management tasks for RocketChat.Ansible\n\n  - name: Grant Nginx permissions to proxy requests to an upstream [SELinux]\n    shell: setsebool httpd_can_network_connect on -P\n    changed_when: false\n    when: (ansible_selinux is defined) and\n          (ansible_selinux.status != \"disabled\")\n\n  - name: Ensure Nginx is present\n    package:\n      name: nginx\n      state: present\n\n  - name: Deploy Nginx configuration\n    template:\n      src: \"{{ item.src }}\"\n      dest: \"{{ item.dest }}\"\n    with_items:\n      - { src: nginx.conf.j2, dest: /etc/nginx/nginx.conf }\n      - { src: rocket_chat.conf.j2, dest: /etc/nginx/conf.d/rocket_chat.conf }\n    notify: Reload the Nginx service\n\n  - name: Ensure provided SSL certs have been deployed\n    copy:\n      src: \"{{ item.src }}\"\n      dest: \"{{ item.dest }}\"\n    when: not rocket_chat_ssl_generate_certs|bool and\n          rocket_chat_ssl_deploy_data|bool\n    with_items:\n      - src: \"{{ rocket_chat_ssl_key_file }}\"\n        dest: \"{{ rocket_chat_ssl_key_path }}\"\n      - src: \"{{ rocket_chat_ssl_cert_file }}\"\n        dest: \"{{ rocket_chat_ssl_cert_path }}\"\n    notify: Reload the Nginx service\n\n  - name: Ensure SSL certs have been generated\n    shell: >-\n      openssl req -x509 -newkey rsa:2048 -nodes\n      -subj \"/CN={{ rocket_chat_service_host }}/\n      /C=NA/ST=NA/L=NA/O=NA/OU=NA\"\n      -keyout {{ rocket_chat_ssl_key_path }}\n      -out {{ rocket_chat_ssl_cert_path }}\n      -days 3650\n    when: rocket_chat_ssl_generate_certs|bool\n    args:\n      creates: \"{{ rocket_chat_ssl_key_path }}\"\n    notify: Reload the Nginx service\n\n  - name: Ensure provided PFS key has been deployed\n    copy:\n      src: \"{{ rocket_chat_nginx_pfs_file }}\"\n      dest: \"{{ rocket_chat_nginx_pfs_key_path }}\"\n    when: not rocket_chat_nginx_generate_pfs_key\n    notify: Reload the Nginx service\n\n  - name: Ensure the PFS key has been generated (this can take a while!)\n    shell: >-\n      openssl dhparam -out {{ rocket_chat_nginx_pfs_key_path }}\n      {{ rocket_chat_nginx_pfs_key_numbits }}\n    when: rocket_chat_nginx_generate_pfs_key|bool\n    args:\n      creates: \"{{ rocket_chat_nginx_pfs_key_path }}\"\n    notify: Reload the Nginx service\n\n  - name: Ensure the Nginx service is running/enabled\n    service:\n      name: nginx\n      state: started\n      enabled: true\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "b9d6adaabd75d8746ea137666b670adf514859c8", "filename": "roles/network/tasks/restart.yml", "repository": "iiab/iiab", "decoded_content": "# dhcpd service is restarted with NM dispatcher.d script\n- name: Stop dhcpd\n  service: name=dhcpd\n           state=stopped\n  when: not dhcpd_enabled\n\n- name: Stop named service\n  service: name={{ dns_service }}\n           state=stopped\n  when: not named_enabled\n\n- name: Start named service\n  service: name={{ dns_service }}\n           state=started\n  ignore_errors: True\n  when: named_enabled\n  register: dns_started\n\n- name: Stop dansguardian\n  service: name=dansguardian\n           state=stopped\n  when: not dansguardian_enabled and dansguardian_install\n\n- name: Restart dansguardian\n  service: name=dansguardian\n           state=restarted\n  when: dansguardian_enabled and dansguardian_install\n\n- name: Stop squid service\n  service: name={{ proxy }}\n           state=stopped\n  when: not squid_enabled and squid_install\n\n# Squid get re-loaded with dispatcher.d\n- name: Restart squid service\n  service: name={{ proxy }}\n           state=started\n  when: squid_enabled and squid_install\n\n- name: Restart wondershaper service\n  service: name=wondershaper\n            state=restarted\n  when: wondershaper_enabled\n\n- name: Restart avahi service\n  service: name=avahi-daemon\n           state=restarted\n\n- name: Create gateway flag\n  shell: echo 1 > /etc/sysconfig/olpc-scripts/setup.d/installed/gateway\n         creates=/etc/sysconfig/olpc-scripts/setup.d/installed/gateway\n  when: iiab_network_mode == \"Gateway\"\n\n- name: Run iptables\n  command: /usr/bin/iiab-gen-iptables\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "bf25230c6c8279c150360b50ed487f06a3391abc", "filename": "tasks/section_02_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 2.18 Disable Mounting of cramfs Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install cramfs /bin/true'\n        state=present\n        create=yes\n    tags:\n      - section2\n      - section2.18\n\n  - name: 2.19 Disable Mounting of freevxfs Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install freevxfs /bin/true'\n        state=present\n        create=yes\n    tags:\n      - section2\n      - section2.19\n\n  - name: 2.20 Disable Mounting of jffs2 Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install jffs2 /bin/true'\n        state=present\n        create=yes\n    tags:\n      - section2\n      - section2.20\n\n  - name: 2.21 Disable Mounting of hfs Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install hfs /bin/true'\n        state=present\n        create=yes\n    tags:\n      - section2\n      - section2.21\n\n  - name: 2.22 Disable Mounting of hfsplus Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install hfsplus /bin/true'\n        state=present\n        create=yes\n    tags:\n      - section2\n      - section2.22\n\n  - name: 2.23 Disable Mounting of squashfs Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install squashfs /bin/true'\n        state=present\n        create=yes\n    tags:\n      - section2\n      - section2.23\n\n  - name: 2.24 Disable Mounting of udf Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install udf /bin/true'\n        state=present\n        create=yes\n    tags:\n      - section2\n      - section2.24\n"}, {"commit_sha": "c33f3410e002f9d8506f0725f56b7d7afa1c5f74", "sha": "d71be3a0a4b27efae301419b3733097f34120302", "filename": "meta/main.yml", "repository": "jloh/nagios-nrpe-server", "decoded_content": "---\ngalaxy_info:\n  author: Mooash\n  description: Nagios NRPE Server configuration Ansible Role\n  license: license (MIT)\n  min_ansible_version: 1.2\n  platforms:\n  - name: Ubuntu\n    versions:\n    - raring\n    - saucy\n    - trusty\n  - name: Debian\n    versions:\n    - squeeze\n    - wheezy\n  - name: ArchLinux\n    versions:\n    - all\n  - name: Solaris\n    versions:\n    - 11.1\n  categories:\n    - monitoring\n    - system\ndependencies: []\n"}, {"commit_sha": "51dcdf691a7801895b569a5a927e30030d8feb70", "sha": "5bc3923f0fd6ab8f87b87ea68653c6b489ffaad6", "filename": "tasks/configure.yml", "repository": "nusenu/ansible-relayor", "decoded_content": "---\n\n- name: Ensure local key folders exist (LOCAL)\n  file: path={{ offline_masterkey_dir }}/{{ item[0] }}_{{ item.1.orport }}/keys\n    state=directory mode=700\n  delegate_to: 127.0.0.1\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - createdir\n\n- name: Ensure all relay keys exist (LOCAL)\n  local_action: command tor --PublishServerDescriptor 0 --orport 1234 --list-fingerprint --datadirectory \"{{ offline_masterkey_dir }}/{{ item[0] }}_{{ item.1.orport }}\" --Log \"err stdout\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Generate new Ed25519 signing keys\n  local_action: command tor --keygen --SigningKeyLifetime {{ tor_signingkeylifetime_days}}\\ days --datadirectory \"{{ offline_masterkey_dir }}/{{ item[0] }}_{{ item.1.orport }}\" --Log \"err stdout\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - renewkey\n\n- name: Detect duplicate relay keys across relays (LOCAL)\n  shell: sha1sum {{ offline_masterkey_dir }}/*/keys/secret_id_key {{ offline_masterkey_dir }}/*/keys/ed25519_master_id_secret_key|cut -d/ -f1|sort|uniq -d|wc -l\n  delegate_to: 127.0.0.1\n  register: dupcount\n\n- name: Abort on duplicate relay keys\n  fail: msg=\"Duplicate relay key detected! Aborting.\"\n  when: dupcount.stdout != \"0\"\n\n- name: Detect if Ed25519 master keys are on the relay\n  stat: path={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}/keys/ed25519_master_id_secret_key\n  become: yes\n  register: masterkeycheck\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Abort if Ed25519 master keys are on the relay\n  fail: msg=\"\n\n            Ed25519 MASTER KEY detected on the relay - it is NOT supposed to be there! Aborting.\"\n  when: item.stat.exists == True\n  with_items: masterkeycheck.results\n\n- name: Collect fingerprints for MyFamily (LOCAL)\n  shell: cut {{ offline_masterkey_dir }}/*/fingerprint -d\" \" -f2|xargs|sed -e 's/ /,/g'\n  delegate_to: 127.0.0.1\n  register: family\n  tags:\n   - reconfigure\n\n- name: Ensure per-instance tor users exist\n  become: yes\n  user: name=_tor-{{ item[0] }}_{{ item.1.orport }} system=yes shell=/bin/false createhome=no home={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - createdir\n\n- name: Ensure per-instance config folders exist (Debian only)\n  become: yes\n  file: path={{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }} state=directory mode=755\n  with_nested:\n   - tor_ips\n   - tor_ports\n  when: ansible_pkg_mgr == 'apt'\n  tags:\n   - createdir\n\n- name: Ensure DataDir exists\n  become: yes\n  file: path={{ tor_DataDir }}\n    state=directory\n    owner=root\n    mode=0755\n  tags:\n   - createdir\n\n- name: Ensure per-instance DataDir exists\n  become: yes\n  file: path={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}\n    state=directory\n    owner=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n    group=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n    mode=0700\n    recurse=yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - createdir\n\n- name: Ensure \"keys\" subfolder exists\n  become: yes\n  file: path={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}/keys\n    state=directory\n    owner=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n    group=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n    mode=0700\n    recurse=yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure RSA key is in place (without overriding existing keys)\n  become: yes\n  copy: src={{ offline_masterkey_dir }}/{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}\n   dest={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}\n   owner=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n   mode=700 force=no\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'secret_id_key' ]\n\n- name: Fetch RSA key for comparision\n  become: yes\n  fetch: src={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}\n    dest={{ offline_masterkey_dir }}/{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}.untrustedremotekey\n    flat=yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'secret_id_key' ]\n\n- name: Compare local vs. remote RSA key (secret_id_key)\n  local_action: shell sha1sum {{ offline_masterkey_dir }}/\"{{ item[0] }}_{{ item.1.orport }}\"/keys/secret_id_key*|cut -d/ -f1|uniq -d|wc -l\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  register: rsakey\n\n- name: Abort if local and remote RSA keys do not match\n  fail: 'msg=\"\n\n\n   Key MISMATCH detected: Remote RSA key does not match local key - manual intervention required.\n\n   We deteted that the remote host uses an RSA key that was not generated by us.\n   We will not override it with our locally generated key.\n\n   If you want to make use of the remote RSA key you have to override the local key manually:\n\n\n   cd ~/.tor/offlinemasterkeys/<IP_port>/keys\n\n   mv secret_id_key.untrustedremotekey secret_id_key\"'\n  when: item.stdout != \"1\"\n  with_items: rsakey.results\n\n# this task is separated from the task named \"Ensure RSA key is in place\" because it is not run with 'force=no'\n- name: Renew Ed25519 signing keys\n  become: yes\n  copy: src={{ offline_masterkey_dir }}/{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}\n   dest={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}\n   owner=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n   mode=700\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'ed25519_master_id_public_key', 'ed25519_signing_cert', 'ed25519_signing_secret_key' ]\n  tags:\n   - renewkey\n\n- name: Ensure Tor config directory exists\n  become: yes\n  file: path={{ tor_ConfDir }}\n    state=directory\n    owner=root\n    group={{ tor_user }}\n    mode=755\n\n- name: Ensure LogDir exists\n  become: yes\n  file: path={{ tor_LogDir }}\n    state=directory\n    owner=root\n    mode=755\n  when: ansible_pkg_mgr != 'apt'\n\n# we only use distinct logfiles on systems that have no SyslogIdentityTag support yet (all non-Debian plaforms)\n# otherwise we log to syslog with SyslogIdentityTag to avoid the filesystem permissions troubles with logrotate.\n# We aim to log to syslog+SyslogIdentityTag for all platforms eventually.\n# This is a medium-term workaround until all platform get SyslogIdentityTag support\n# without this workaround tor will fail to start after logrotate created new logfiles because\n# logrotate is not not aware that every tor instance runs under a distinct user.\n# This effectively disables logrotate.\n- name: Ensure per-instance LogDir exists\n  become: yes\n  file: path={{ tor_LogDir }}/{{ item[0] }}_{{ item.1.orport }}\n    state=directory\n    owner=_tor-{{ item[0] }}_{{ item.1.orport }}\n    group=_tor-{{ item[0] }}_{{ item.1.orport }}\n    mode=700\n  with_nested:\n   - tor_ips\n   - tor_ports\n  when: ansible_pkg_mgr != 'apt'\n\n- name: Generating torrc file(s)\n  become: yes\n  template: >\n    src=torrc\n    dest=\"{{ (ansible_pkg_mgr != 'apt')| ternary(tor_ConfDir ~ '/' ~ item[0] ~ '_' ~ item.1.orport ~ '.torrc', tor_ConfDir ~ '/' ~ item[0] ~ '_' ~ item.1.orport ~ '/torrc') }}\"\n    owner=root\n    mode=0644\n    backup=yes\n    validate=\"tor --verify-config -f %s\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n  register: instances\n  tags:\n   - reconfigure\n"}, {"commit_sha": "3c4d272a77f8aaeb300c8b841bb7e6d8dbd76c1f", "sha": "8b2fb1acb8bc5c5d2f5732ed5670bcff30f192fa", "filename": "handlers/main.yml", "repository": "ansiblebit/oracle-java", "decoded_content": "---\n# file: oracle-java/handlers/main.yml\n#\n# Handlers file.\n#\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "e65599b3efeccd561753f923c9ede9186e2050e7", "filename": "roles/user-management/manage-local-user-ssh-authkeys/tasks/authorizedkeys.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: \"Update authorized keys for user: {{ user_name|default(ansible_user) }}\"\n  authorized_key: \n    user: \"{{ user_name|default(ansible_user) }}\"\n    exclusive: \"{{ reset_keyfile|default('no') }}\"\n    key: \"{{ key_url }}\"\n\n"}, {"commit_sha": "7c574f3b148b4df43177a5c0fc398ce4bea6ae3e", "sha": "fe142afe5011c15a1f8a2797b3303feef4c2e0c6", "filename": "tasks/main.yml", "repository": "zzet/ansible-rbenv-role", "decoded_content": "---\n- name: include env vars\n  include_vars: \"{{ rbenv.env }}.yml\"\n\n- include: apt_build_depends.yml\n  when: ansible_pkg_mgr == 'apt'\n- include: yum_build_depends.yml\n  when: ansible_pkg_mgr == 'yum'\n# - include: pacman_build_depends.yml # Arch Linux\n#   when: ansible_pkg_mgr == 'pacman'\n- include: homebrew_build_depends.yml\n  when: ansible_os_family == 'Darwin'\n\n\n- name: checkout rbenv_repo for system\n  git: >\n    repo={{ rbenv_repo }}\n    dest={{ rbenv_root }}\n    version={{ rbenv.version }}\n    accept_hostkey=true\n    force=yes\n  when: rbenv.env == \"system\"\n  tags:\n    - rbenv\n\n- name: create plugins directory for system\n  file: state=directory path={{ rbenv_root }}/plugins\n  when: rbenv.env == \"system\"\n  tags:\n    - rbenv\n\n- name: install plugins for system\n  git: >\n    repo={{ item.repo }}\n    dest={{ rbenv_root }}/plugins/{{ item.name }}\n    version={{ item.version }}\n    accept_hostkey=true\n    force=yes\n  with_items: \"{{ rbenv_plugins }}\"\n  when: rbenv.env == \"system\"\n  tags:\n    - rbenv\n\n- name: checkout rbenv_repo for selected users\n  git: >\n    repo={{ rbenv_repo }}\n    dest={{ rbenv_root }}\n    version={{ rbenv.version }}\n    accept_hostkey=true\n    force=yes\n  with_items: \"{{ rbenv_users }}\"\n  become: true\n  become_user: \"{{ item }}\"\n  when: rbenv.env != \"system\"\n  ignore_errors: true\n  tags:\n    - rbenv\n\n- name: create plugins directory for selected users\n  file: state=directory path={{ rbenv_root }}/plugins\n  with_items: \"{{ rbenv_users }}\"\n  become: true\n  become_user: \"{{ item }}\"\n  when: rbenv.env != \"system\"\n  ignore_errors: true\n  tags:\n    - rbenv\n\n- name: install plugins for selected users\n  git: >\n    repo={{ item[1].repo }}\n    dest={{ rbenv_root }}/plugins/{{ item[1].name }}\n    version={{ item[1].version }}\n    accept_hostkey=true\n    force=yes\n  with_nested:\n    - \"{{ rbenv_users }}\"\n    - \"{{ rbenv_plugins }}\"\n  become: true\n  become_user: \"{{ item[0] }}\"\n  when: rbenv.env != \"system\"\n  ignore_errors: true\n  tags:\n    - rbenv\n\n- name: add rbenv initialization to profile system-wide\n  template: src=rbenv.sh.j2 dest=/etc/profile.d/rbenv.sh owner=root group=root mode=0755\n  become: true\n  when:\n    - ansible_os_family != 'OpenBSD'\n  tags:\n    - rbenv\n\n- name: set default-gems for select users\n  copy: src=default-gems dest={{ rbenv_root }}/default-gems\n  with_items: \"{{ rbenv_users }}\"\n  become: true\n  become_user: \"{{ item }}\"\n  when:\n    - not \"system\" == \"{{ rbenv.env }}\"\n    - default_gems_file is not defined\n  ignore_errors: true\n  tags:\n    - rbenv\n\n- name: set custom default-gems for select users\n  copy: src={{ default_gems_file }} dest={{ rbenv_root }}/default-gems\n  with_items: \"{{ rbenv_users }}\"\n  become: true\n  become_user: \"{{ item }}\"\n  when:\n    - not \"system\" == \"{{ rbenv.env }}\"\n    - default_gems_file is defined\n  ignore_errors: true\n  tags:\n    - rbenv\n\n- name: set gemrc for select users\n  copy: src=gemrc dest=~/.gemrc\n  with_items: \"{{ rbenv_users }}\"\n  become: true\n  become_user: \"{{ item }}\"\n  when: rbenv.env != \"system\"\n  ignore_errors: true\n  tags:\n    - rbenv\n\n- name: set vars for select users\n  copy: src=vars dest={{ rbenv_root }}/vars\n  with_items: \"{{ rbenv_users }}\"\n  become: true\n  become_user: \"{{ item }}\"\n  when: rbenv.env != \"system\"\n  ignore_errors: true\n  tags:\n    - rbenv\n\n- name: check ruby {{ rbenv.ruby_version }} installed for system\n  shell: $SHELL -lc \"rbenv versions | grep {{ rbenv.ruby_version }}\"\n  register: ruby_installed\n  changed_when: false\n  ignore_errors: yes\n  always_run: yes\n  when: rbenv.env == \"system\"\n  tags:\n    - rbenv\n\n- name: install ruby {{ rbenv.ruby_version }} for system\n  shell: bash -lc \"rbenv install {{ rbenv.ruby_version }}\"\n  when:\n    - rbenv.env == \"system\"\n    - ruby_installed.rc != 0\n  tags:\n    - rbenv\n\n- name: check if current system ruby version is {{ rbenv.ruby_version }}\n  shell: $SHELL -lc \"rbenv version | cut -d ' ' -f 1 | grep -Fx '{{ rbenv.ruby_version }}'\"\n  register: ruby_selected\n  changed_when: false\n  ignore_errors: yes\n  always_run: yes\n  when: rbenv.env == \"system\"\n  tags:\n    - rbenv\n\n- name: set ruby {{ rbenv.ruby_version }} for system\n  shell: bash -lc \"rbenv global {{ rbenv.ruby_version }} && rbenv rehash\"\n  when:\n    - rbenv.env == \"system\"\n    - ruby_selected.rc != 0\n  tags:\n    - rbenv\n\n- name: check ruby {{ rbenv.ruby_version }} installed for select users\n  shell: $SHELL -lc \"rbenv versions | grep {{ rbenv.ruby_version }}\"\n  become: true\n  become_user: \"{{ item }}\"\n  with_items: \"{{ rbenv_users }}\"\n  when: rbenv.env != \"system\"\n  register: ruby_installed\n  changed_when: false\n  ignore_errors: yes\n  always_run: yes\n  tags:\n    - rbenv\n\n- name: install ruby {{ rbenv.ruby_version }} for select users\n  shell: $SHELL -lc \"rbenv install {{ rbenv.ruby_version }}\"\n  become: true\n  become_user: \"{{ item[1] }}\"\n  with_together:\n    - \"{{ ruby_installed.results }}\"\n    - \"{{ rbenv_users }}\"\n  when:\n    - rbenv.env != \"system\"\n    - item[0].rc != 0\n  ignore_errors: true\n  tags:\n    - rbenv\n\n- name: check if user ruby version is {{ rbenv.ruby_version }}\n  shell: $SHELL -lc \"rbenv version | cut -d ' ' -f 1 | grep -Fx '{{ rbenv.ruby_version }}'\"\n  become: true\n  become_user: \"{{ item }}\"\n  with_items: \"{{ rbenv_users }}\"\n  when: rbenv.env != \"system\"\n  register: ruby_selected\n  changed_when: false\n  ignore_errors: yes\n  always_run: yes\n  tags:\n    - rbenv\n\n- name: set ruby {{ rbenv.ruby_version }} for select users\n  shell: $SHELL -lc \"rbenv global {{ rbenv.ruby_version }} && rbenv rehash\"\n  become: true\n  become_user: \"{{ item[1] }}\"\n  with_together:\n    - \"{{ ruby_selected.results }}\"\n    - \"{{ rbenv_users }}\"\n  when:\n    - rbenv.env != \"system\"\n    - item[0].rc != 0\n  ignore_errors: true\n  tags:\n    - rbenv\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "bf9b35bbeef0539fb4ca851f1253cf995aa59265", "filename": "playbooks/provision-dns-server/configure-dns-server-bind.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: dns-server\n  roles:\n    - role: dns/config-dns-server-bind\n  tags:\n    - 'never'\n    - 'install'\n\n- hosts: dns-server\n  roles:\n    - role: dns/manage-dns-zones-bind\n  tags:\n    - 'always'\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "1d33313c0b01a0d7b9b69416c8b92c9035bee468", "filename": "roles/manage-aws-infra/tasks/create-vpc.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "# Create VPC if requested\n---\n- name: \"Create VPC if required\"\n  ec2_vpc_net:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    name: \"{{ env_id }}-vpc\"\n    cidr_block: \"{{ vpc_cidr_block | default('172.31.0.0/16') }}\"\n    region: \"{{ aws_region }}\"\n    state: \"present\"\n    tags:\n      env_id: \"{{ env_id }}\"\n  register: new_vpc\n\n- name: \"Store away the new VPC id for use later\"\n  set_fact:\n    aws_vpc_id: \"{{ new_vpc.vpc.id }}\"\n\n- name: \"Create an Internet Gateway for the new VPC\"\n  ec2_vpc_igw:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    vpc_id: \"{{ aws_vpc_id }}\"\n    region: \"{{ aws_region }}\"\n    state: present\n    tags:\n      env_id: \"{{ env_id }}\"\n  register: new_gw\n\n- name: \"Store away the new Internet Gateway id for use later\"\n  set_fact:\n    aws_vpc_ig: \"{{ new_gw.gateway_id }}\"\n"}, {"commit_sha": "c33f3410e002f9d8506f0725f56b7d7afa1c5f74", "sha": "5a002a25189c08035d117f3bfa61e2d31d61ab09", "filename": "tasks/packages-Solaris.yml", "repository": "jloh/nagios-nrpe-server", "decoded_content": "---\n- name: Ensure CSWpkgutil is installed\n  svr4pkg: src=http://get.opencsw.org/now name=CSWpkgutil state=present\n\n# pkgutil module does not actually provide full path to pkgutil --\n# until that changes, it's necessary to make sure that /opt/csw/bin\n# is included in path:\n# Nagios NRPE Server for Solaris\n- name: Install Nagios NRPE Server [Solaris]\n  pkgutil: name=CSWnrpe state=present \n  environment: \n    PATH: \"{{ ansible_env.PATH }}:/opt/csw/bin\"\n\n# Nagios Plugins\n- name: Install Nagios NRPE Plugins [Solaris]\n  pkgutil: name=\"CSWnrpe-plugin\" state=present \n  environment: \n    PATH: \"{{ ansible_env.PATH }}:/opt/csw/bin\"\n  notify: restart nagios-nrpe-server\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "62f6276908bf83af447af3f8ccb4b8d224e3c94a", "filename": "roles/network/tasks/rpi_debian.yml", "repository": "iiab/iiab", "decoded_content": "# rpi_debian.yml\n# Start out making simplifying assumptions\n#   1. we are dealing with a rpi3\n#   2. Gui inputs define the config -- auto config is more difficult\n#      a. gui_desired_network_role\n#      b. hostapd_enabled\n#      c. gui_static_wan_ip\n#   3. In appliance mode: wan (and wlan0) is either static or dhcp under br0, and hostapd off\n#   4. In lan_controller: wan is off, eth0 and wlan0 under br0\n#   5. In gateway: eth0 is wan, and wlan0 is under br0 (only one adapter under br0)\n#   6. As a slight concess to auto config, if eth1 exists, make it wan, and force gateway\n\n- name: Raspbian stock has openresolv which is not available in debian, off it\n  package: name=openresolv\n           state=absent\n\n- name: Get the stock resolv.conf manager\n  package: name=resolvconf\n           state=absent\n\n- name: on upgrade from earlier iiab versions, remove /etc/network/interfaces.d/br0\n  file: path=/etc/network/interfaces.d/br0\n        state=absent\n\n- name: default to lan controller\n  set_fact:\n      gui_desired_network_role: \"LanController\"\n  when: not gui_desired_network_role is defined\n\n- name: Rewrite the /etc/network/interfaces file which we corrupted\n  template: dest=/etc/network/interfaces\n            src=network/interfaces.j2\n\n- name: Supply our own dhcpcd.conf\n  template: dest=/etc/dhcpcd.conf\n            src=network/dhcpcd.conf\n\n- name: Copy the network config script\n  template: dest=/etc/network/interfaces.d/iiab\n            src=network/iiab.j2\n  register: interface\n\n- name: If this was a change, things need to shift\n  service: name=hostapd state=stopped\n  when: interface.changed\n\n- name: dhcpd may be affected\n  service: name=bind9 state=stopped\n  when: interface.changed\n\n- name: Tear down any bridge and start fresh\n  command: ip link set br0 down\n  ignore_errors: True\n  when: interface.changed\n\n- name: and remove the device\n  command: brctl delbr br0\n  ignore_errors: True\n  when: interface.changed\n\n- name: reset the eth0 interface\n  command: ifdown eth0\n  ignore_errors: True\n  when: interface.changed\n\n- name: restart the networking service\n  service: name=networking state=restarted\n  when: interface.changed\n\n- name: start up hostapd again\n  service: name=hostapd state=started\n  when: interface.changed\n\n- name: dhcpd may be affected\n  service: name=bind9 state=started\n  when: interface.changed\n\n#create lan br0 if lan_controller or gateway\n#create wan br0 if appliance\n#allocate wlan0 under br0 in all cases\n#allocate eth0 under br0 if appliance, alone if gateway\n\n- name: Add location section to config file\n  ini_file: dest='{{ iiab_config_file }}'\n            section=network\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n  - option: 'gateway_active'\n    value:  '{{ gw_active }}'\n  - option: 'internet_available'\n    value:  '{{ internet_available }}'\n  - option: 'gateway_ifcfg'\n    value: '{{ has_ifcfg_gw }}'\n  - option: 'detected_gateway'\n    value: '{{ discovered_wan_iface }}'\n  - option: 'prior_gateway'\n    value: '{{ device_gw2 }}'\n  - option: 'wireless_list_1'\n    value: '{{ wifi1 }}'\n  - option: 'wireless_list_2'\n    value: '{{ wifi2 }}'\n  - option: 'num_wifi_interfaces'\n    value: '{{ num_wifi_interfaces }}'\n  - option: 'discovered_wireless_iface'\n    value: '{{ discovered_wireless_iface }}'\n  - option: 'iiab_wireless_lan_iface'\n    value: '{{ iiab_wireless_lan_iface }}'\n  - option: 'num_lan_interfaces'\n    value: '{{ num_lan_interfaces }}'\n  - option: 'detected_lan'\n    value: '{{ discovered_lan_iface }}'\n  - option: 'static_wan'\n    value: '{{ gui_static_wan }}'\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "8d1779e5979e71a112a9362eab1649dc8ba84b36", "filename": "roles/config-redis/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Install Containerized Redis\n  include_tasks: install_containerized.yml\n  when: mode == \"containerized\"\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "02c815f9772f228e8fd35f4570e4c7c8efe41507", "filename": "roles/ansible/tower/manage-inventories/tasks/process-group-member.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Associate the host(s) with the group\"\n  uri:\n    url: https://localhost/api/v2/groups/{{ group_id }}/hosts/\n    method: POST\n    body: \"{{ lookup('template', 'group-member.j2') }}\"\n    body_format: 'json'\n    headers:\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n    user: admin\n    password: \"{{ tower_admin_password }}\"\n    validate_certs: no\n    status_code: 200,201,204,400\n"}, {"commit_sha": "a9f9815335a6b9c73bed7e3dcd75e14cd973fbb5", "sha": "7a2612e42bb9dd4de450ce43d98b4c99192bce83", "filename": "meta/main.yml", "repository": "CSCfi/ansible-role-cuda", "decoded_content": "---\ngalaxy_info:\n  author: Johan Guldmyr\n  description: Installs CUDA\n  company: CSC - IT Center for Science\n  # If the issue tracker for your role is not on github, uncomment the\n  # next line and provide a value\n  # issue_tracker_url: http://example.com/issue/tracker\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: MIT\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your \n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  - name: EL\n    versions:\n  #  - all\n  #  - 5\n    - 6\n    - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #  - 21\n  #  - 22\n  #- name: Windows\n  #  versions:\n  #  - all\n  #  - 2012R2\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  #- name: Ubuntu\n  #  versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n  #  - trusty\n  #  - utopic\n  #  - vivid\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - jessie\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  #- cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies: []\n  # List your role dependencies here, one per line.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n  \n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "b1910cc263d9748e76805d2fb73c5b7a0c611891", "filename": "roles/httpd/templates/iiab-home-page.conf", "repository": "iiab/iiab", "decoded_content": "# XSCE Home Page\n\n# Redirect to home page on School Server\n# Default is xs-portal\n\n# RedirectMatch of root to home page\n# See the note in default_vars.yml\n\nRedirectMatch ^/$ {{ iiab_home_url }}\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "e387139a55a752a4f1e041d36003a95b3b2aa6d6", "filename": "roles/cadvisor/meta/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\ngalaxy_info:\n  author: Alberto Lamela\n  description:\n  company: Capgemini\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (MIT)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: Ubuntu\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n     - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies:\n  - role: handlers\n  # - role: registrator\n  # - role: zookeeper\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "7c574f3b148b4df43177a5c0fc398ce4bea6ae3e", "sha": "bb8c51c9c3046f06ca38fbe8d534af192ca2b837", "filename": "tasks/yum_build_depends.yml", "repository": "zzet/ansible-rbenv-role", "decoded_content": "---\n- name: install build depends\n  yum: name={{ item }} state=present\n  with_items:\n    - gcc\n    - openssl-devel\n    - libyaml-devel\n    - readline-devel\n    - zlib-devel\n    - libffi-devel\n    - git\n  become: true\n  tags:\n    - rbenv\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "02c8cbe15134f101381adf689a073baee625273a", "filename": "roles/1-prep/templates/iiab-rpi-max-rootfs.sh", "repository": "iiab/iiab", "decoded_content": "#!/bin/bash -x\n# Resize rootfs and its partition on the rpi SD card to maximum size\n# To be used by systemd service on boot\n# Only resizes if /.resize-rootfs exists\n# Assumes root is last partition\n# Only works on F22 + where resizepart command exists\n# Assumes sd card style partition name like <device>p<partition number>\n\nif [  -f /.resize-rootfs ];then\n  echo \"$0: maximizing rootfs partion\"\n  # Calculate root partition\n  root_part=`lsblk -aP -o NAME,MOUNTPOINT|grep  'MOUNTPOINT=\"/\"' |awk -F\\\" '{ print $2 }'`\n  root_dev=${root_part:0:-2}\n  root_part_no=${root_part: (-1)}\n\n  # Resize partition\n  parted -s /dev/$root_dev resizepart $root_part_no 100%\n  resize2fs /dev/$root_part\n  rm /.resize-rootfs\nfi\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "38b008750a7ed3d9528c9211e7f6861c38706063", "filename": "roles/config-lvm/tasks/lvm.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Setup and create PV & VG\"\n  lvg:\n    vg: \"{{ item.vg_name }}\"\n    pvs: \"{{ item.storage_device }}\"\n\n- name: \"Setup LV\"\n  lvol: \n    vg: \"{{ item.vg_name }}\"\n    lv: \"{{ item.lv_name }}\"\n    size: \"100%VG\"\n\n- name: \"Create file system on share\"\n  filesystem:\n    fstype: \"{{ lvm_fstype }}\"\n    dev: \"/dev/mapper/{{ item.vg_name }}-{{ item.lv_name }}\"\n\n- name: \"Ensure the mount dir exists\" \n  file:\n    path: \"{{ item.mount_path }}\"\n    state: directory\n\n- name: \"Mount LVM to directory\"\n  mount:\n    src: \"/dev/mapper/{{ item.vg_name }}-{{ item.lv_name }}\" \n    path: \"{{ item.mount_path }}\"\n    fstype: \"{{ lvm_fstype }}\" \n    state: mounted\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "40baa0f34cf49b804c3f4cfa229b8474016db67b", "filename": "playbooks/vars/bb6.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "dev_project: dev-project\ntest_project: test-project\nprod_project: prod-project\ntag_prod: toprod\ntag_test: totest\nbuilder_image: redhat-openjdk18-openshift:1.1\nservice_name: hello-ocp\nsource: https://github.com/tahonen/hello-springboot.git\nsource_branch: master\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "f61c19a32793acc2837c5ab776fb378de3c67c8b", "filename": "archive/roles/registry/tasks/openssl.yaml", "repository": "redhat-cop/casl-ansible", "decoded_content": "- name: Creates directory\n  file: path={{ certificate_path }} state=directory\n\n- name: create self-signed SSL cert\n  command: openssl req -new -nodes -x509 -subj \"{{ certificate_subject }}\" -days 3650 -keyout {{ certificate_path }}/server.key -out {{ certificate_path }}/server.crt -extensions v3_ca creates={{ certificate_path }}/server.crt\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "f360a85b39d34bf05e324e8bbcb0e41aaff5ee73", "filename": "roles/openvpn/templates/client1.key", "repository": "iiab/iiab", "decoded_content": "-----BEGIN PRIVATE KEY-----\nMIIEvgIBADANBgkqhkiG9w0BAQEFAASCBKgwggSkAgEAAoIBAQCsXgeDFKouxttl\nmyjyUGeVLm8lhchShwN+Wl0x856Vi0G8cgFnalY0q8ngzOUU8a00Vom3XcNcLzFG\n4Q/92l6LDG6bKECdqv3ZBdYqYtvTA6h2rNl4A8hxqX4e/Yubgc3N6jwwGaF2ur0e\nCA+Vc3u6MCivN/CZ8OWO6cHdEE1W+Vw4El+QY14ZoMFNtk6GDZNq/0AbTvpR8rBx\nwMftsfvruYUBF2fFu50s85wSmfZ0WlfGo0rfD89dCQyErIYeglDzbSjwtw/WU0F6\nyJSCwaNWT+sIdu7KkVIFndMe1g3sP2beqwujA8JgFLCDQuwI3ZR6rBP5rIhXvmY9\nW7b3JFJ5AgMBAAECggEAQNF3V7a8rKyBMrtfcYgE+9ejWmPtygMVsD1BEJjBiRD+\nHmRs3LvjQRlc6FmEyBR+AtGMJlVvMspYaIQYJGkq5nU9XsGLUv9LSIJmYDge3EJi\n5oXnnbcmeH+5euPzzP3KK+YqzhfFXUWp+pIjchskawbTNdj+dJVfbhe/nGcV/l9X\nDZ/HupnOMzHbHdrYRlykjS49GQuyY7xNRwQUjSYqZXDCpz/7NGks6W+Wly5SEi9e\nE2PT5ww2GuH7EjWrJXkMdTkad24uhHozQduaAWPfjk51WF/NEAHQiRz0L/I9CGM7\noNOvqrLdKUwGMq52JwS/oQ+kyhuEglltR13JUu74xQKBgQDhGwceYKEzWxra4JMQ\noAgRBGh0e41jCmzaC1s2lrmAje/d0GA/QXfQ7LcbOvNOveiUacgdlGgFHxb7snIv\n+yp4knpFWKyKZ6Eb4M1Z6zt7V38dwl1dwcJTILuM7usVkprHZmaIFkekv55eIQf0\n0U49caSWCc7axQzbAsSjG15Y5wKBgQDEBhGLuStPs/VYKX6hM24XdpaFvo6quGWI\nQGKZ9X9LrnHt/cy6d6aEb45918F7wgWbEnY9D6c6PTJgDhqpSd5NQY1Kxx70N/o6\ngCODVe2gb8TpalHPccvdCBUA7KIyC9aA6L2AmyhVjSuxXr5hNMRHQjWqey4PfKw1\nY4F+3PGtnwKBgQDNsvQDV0uW8UaOAi+BPquAWWXWI1zkxw8HBN+Z94uVpJ4vNI3u\n37VMTjNYh7r0FmfkzvEVzpprK6jF4Z+kpsB9o2Rl4AzzAJVhM0CTTXhyUlcPa6AD\n393iNoQL2fsqIGidk75X1vwq2QsvesGZfnYfgaxjipzinrQLofDsF0NUuwKBgFkB\nHGRhzl2hK2w9YwbUsE8tBElz7ZlsooVMHrkjNApsCcTy8UtVWqFVedB/75U+0obH\nyjINcnPKJ55fqRFmve48LmheoxpmdFKtrfJLSNsJBNKq+LyFQfh5W/gQedDZeSsN\nAkZrrNOzhrxBdZXzfI+Sa4Wd6psTk6mmJb0xmvanAoGBAM85Vrohbtr5tbpXSY7O\nSM24Ue76E1x8loYKPKfCROJZyDaHPeIKwLznNeEhwQUGOZnw8dWUHfMWK+JG41ju\n4Hx8Af7RemWqMxunRlhHNONj94aDKCT9I4ZKTLk/PiS9JxBTDNNkGvHZzTBOvkLm\nk1yt5jfvk9Fa5Qtsp2Vbo5vb\n-----END PRIVATE KEY-----\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "a8f75c4b8fdb87ce6a5e65a28358f9a8579d12ee", "filename": "roles/moodle/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "---\n- name: Install moodle required packages\n  package: name={{ item }}\n           state=present\n  with_items:\n    - python-psycopg2\n    - php-pgsql\n  when: not is_debuntu\n\n- name: Install moodle required packages\n  package: name={{ item }}\n           state=present\n  with_items:\n    - python-psycopg2\n    - php{{ php_version }}-pgsql\n    - php{{ php_version }}-curl\n#    - php{{ php_version }}-zip\n    - php{{ php_version }}-gd\n#    - php{{ php_version }}-mbstring\n# mbstring is now included in php-cli\n    - php{{ php_version }}-cli\n  when: is_debuntu\n\n- name: php-zip debian 8-9 changed name\n  package: name=php{{ php_version }}-zip\n  when: is_debian_9 or is_ubuntu\n\n- name: php-zip debian 8-9 changed name\n  package: name=php-pclzip\n  when: is_debian_8\n\n- name: Determine if moodle is already downloaded\n  stat: path={{ moodle_base }}/config-dist.php\n  register: moodle\n\n- name: Download the latest moodle repo\n  git: repo={{ moodle_repo_url }}\n       dest={{ moodle_base }}\n       depth=1\n       force=yes\n       version=\"MOODLE_{{ moodle_version }}_STABLE\"\n#  ignore_errors: yes\n  when: internet_available  and moodle.stat.exists is defined and not moodle.stat.exists\n\n- name: Prepare the downloaded directory so apache can install config file\n  file: path={{ moodle_base }}\n        owner={{ apache_user }}\n        recurse=yes\n        state=directory\n\n- name: Give apache permission to write moodle data directory\n  file: path={{ content_base }}/dbdata/moodle\n        owner={{ apache_user }}\n        mode=0755\n        state=directory\n\n- name: Create a moodle data dir with apache permission to write\n  file: path={{ moodle_data }}\n        owner={{ apache_user }}\n        group={{ apache_user }}\n        mode=0770\n        state=directory\n\n- name: Remove stock moodle conf\n  file: path='/etc/{{ apache_config_dir }}/moodle.conf'\n        state=absent\n\n- name: Put moodle config file in place\n  template: src=022-moodle.j2\n            dest=/etc/{{ apache_config_dir }}/022-moodle.conf\n            owner=root\n            group=root\n            mode=0644\n  when: moodle_enabled\n\n- name: Enable moodle\n  file: path=/etc/apache2/sites-enabled/022-moodle.conf\n        src=/etc/apache2/sites-available/022-moodle.conf\n        state=link\n  when: moodle_enabled and is_debuntu\n\n- name: Disable moodle\n  file: path=/etc/apache2/sites-enabled/022-moodle.conf\n        state=absent\n  when: not moodle_enabled and is_debuntu\n\n- name: Start postgresql-iiab\n  service: name=postgresql-iiab\n           state=restarted\n\n- name: Create db user\n  postgresql_user: name=Admin\n                   password=changeme\n                   role_attr_flags=NOSUPERUSER,NOCREATEROLE,NOCREATEDB\n                   state=present\n  become: yes\n  become_user: postgres\n\n- name: Create database\n  postgresql_db: name=moodle\n                 encoding=utf8\n                 owner=Admin\n                 template=template1\n                 state=present\n  become: yes\n  become_user: postgres\n\n- name: Put a startup install script in place\n  template: dest={{ moodle_base }}\n            src=moodle_installer\n            mode=0755\n\n- name: Restart postgresql-iiab\n  service: name=postgresql-iiab\n           state=restarted\n           enabled=yes\n  when: moodle_enabled\n\n- name: Restart apache\n  service: name={{ apache_service }}\n           state=restarted\n\n- name: see if the config.php file exists\n  stat: path='{{ moodle_base }}/config.php'\n  register: config\n\n- name: Execute moodle startup script\n  shell: '{{ moodle_base }}/moodle_installer'\n  when: config.stat.exists is defined and not config.stat.exists\n\n- name: Give apache permission to read config file\n#  command: chown -R {{ apache_user }} {{ moodle_base }}\n  file: path={{ moodle_base }}/config.php\n        mode=0644\n\n- name: add moodle to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=moodle\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: Moodle\n    - option: description\n      value: '\"Access the Moodle learning management system.\"'\n    - option: 'directory path'\n      value: '{{ moodle_base }}'\n    - option: moodle_enabled\n      value: \"{{ moodle_enabled }}\"\n"}, {"commit_sha": "6fada6f2a7515ab18178ae350168c3de147c4dd0", "sha": "e2600d152f37828024619516380853a9c70bc8fd", "filename": "tasks/ssl.yml", "repository": "inkatze/wildfly", "decoded_content": "---\n# task file for wildfly\n\n# See the README file on how to generate this file.\n- name: Copy keystore file to the configuration folder\n  copy:\n    src: '{{ wildfly_keystore_name }}'\n    dest: '{{ wildfly_keystore_path }}'\n    owner: '{{ wildfly_user }}'\n    group: '{{ wildfly_group }}'\n    mode: '0750'\n  notify:\n    - restart wildfly\n    - change standalone data mode\n\n- name: Add SSL identity to the management realm\n  lineinfile:\n    dest: '{{ wildfly_standalone_config_path }}'\n    insertafter: <security-realm name=\"ManagementRealm\">\n    line: '{{ wildfly_application_ssl_identity }}'\n    owner: '{{ wildfly_user }}'\n    group: '{{ wildfly_group }}'\n    mode: '0750'\n  notify:\n    - restart wildfly\n    - change standalone data mode\n\n- name: Add https listener for applications\n  lineinfile:\n    dest: '{{ wildfly_standalone_config_path }}'\n    insertafter: <http-listener name=*\n    line: '{{ wildfly_https_listener }}'\n    owner: '{{ wildfly_user }}'\n    group: '{{ wildfly_group }}'\n    mode: '0750'\n  notify:\n    - restart wildfly\n    - change standalone data mode\n\n- name: Add https socket binding to management interfaces\n  lineinfile:\n    dest: '{{ wildfly_standalone_config_path }}'\n    insertafter: <http-interface security-realm=\"ManagementRealm\"*\n    line: <socket-binding https=\"management-https\"/>\n    owner: '{{ wildfly_user }}'\n    group: '{{ wildfly_group }}'\n    mode: '0750'\n  notify:\n    - restart wildfly\n    - change standalone data mode\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "cb69805e5117c459ca94b65cf935ed03c70acda9", "filename": "tasks/create_repo_raw_hosted_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_raw_hosted\n    args: \"{{ _nexus_repos_raw_defaults|combine(item) }}\"\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "e1dfac1c8f38a8c2a4f44901d58cf3a46a246134", "filename": "playbooks/openshift/openstack/delete.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n- hosts: localhost\n  pre_tasks:\n  - import_tasks: ../prep-inventory.yml\n  roles:\n  - role: openshift-ansible-contrib/roles/openstack-stack\n    stack_name: \"{{ full_dns_domain }}\"\n    stack_state: 'absent'\n  post_tasks:\n  - name: Delete auto provisioned registry\n    os_volume: \n      display_name: \"{{ full_dns_domain }}-registry\"\n      state: 'absent'\n"}, {"commit_sha": "e91a55152358e890a05cf849abc7d58b8badecc2", "sha": "8709ec2eefcb6469dc5648d840372ea7b787c16d", "filename": "tasks/go-get.yml", "repository": "fubarhouse/ansible-role-golang", "decoded_content": "---\n\n- name: \"Go-Lang | Define list of package directories\"\n  set_fact:\n    go_package_locations:\n    - \"{{ GOPATH }}/bin\"\n    - \"{{ GOPATH }}/pkg\"\n    - \"{{ GOPATH }}/src\"\n  when: go_reget|bool == true\n\n- name: \"Go-Lang | Remove installed workspace packages\"\n  file:\n    path: \"{{ item }}\"\n    state: absent\n  with_items: \"{{ go_package_locations }}\"\n  ignore_errors: yes\n  when:\n    - go_reget|bool == true\n    - go_package_locations is defined\n\n- name: \"Go-Lang | Run get commands\"\n  shell: \"{{ GOROOT }}/bin/go get -u {{ item.url }}\"\n  environment:\n    GOPATH: \"{{ GOPATH }}\"\n    GOROOT: \"{{ GOROOT }}\"\n  with_items: \"{{ go_get }}\"\n  changed_when: false"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "7dcd74cb2f000c700f9c4ed11bf8c982cc93ff9a", "filename": "roles/config-httpd/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\ndefault_document_root: \"/var/www/html\"\n"}, {"commit_sha": "f3dd45a61b08de1b3351140cc442a705cb2fad82", "sha": "f725c8437ee5e8b55df838c109705fa387410ae3", "filename": "tasks/fail2ban-RedHat.yml", "repository": "geerlingguy/ansible-role-security", "decoded_content": "---\n- name: Install fail2ban.\n  package: name=fail2ban state=present enablerepo=epel\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "6efa54b2a40a07a90a8c723c99ae01ca3b0b04a6", "filename": "playbooks/notifications/email-notify-single-user.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- include_vars:\n    file: \"{{ email_content_file }}\"\n- set_fact:\n    markdown_content: \"{{ body }}\"\n- include_role:\n    name: notifications/md-to-html\n- set_fact: \n    mail: \"{{ mail | combine( {'subject': title, 'body': md_to_html.html_body_message, 'to': email_to} ) }}\"\n- include_role:\n    name: notifications/send-email\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "895e796618d5eb5d7c7363674305f93f61aa5fcd", "filename": "roles/notifications/send-email/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Create the 'To:' list of addresses\"\n  set_fact:\n    mail: \"{{ mail | combine({ 'to': list_of_mail_to }) }}\"\n  when:\n  - list_of_mail_to is defined\n\n- name: \"Create the 'CC:' list of addresses\"\n  set_fact:\n    mail: \"{{ mail | combine({ 'cc': list_of_mail_cc }) }}\"\n  when:\n  - list_of_mail_cc is defined\n\n- name: \"Create the 'BCC:' list of addresses\"\n  set_fact:\n    mail: \"{{ mail | combine({ 'bcc': list_of_mail_bcc }) }}\"\n  when:\n  - list_of_mail_bcc is defined\n\n- name: \"Send out e-mail content to users\"\n  mail:\n    subject: \"{{ mail.subject }}\"\n    body: \"{{ mail.body | default(omit) }}\"\n    host: \"{{ mail.host | default(omit) }}\"\n    port: \"{{ mail.port | default (omit) }}\"\n    username: \"{{ mail.username | default(omit) }}\"\n    password: \"{{ mail.password | default(omit) }}\"\n    to: \"{{ mail.to | default(omit) }}\"\n    cc: \"{{ mail.cc | default(omit) }}\"\n    bcc: \"{{ mail.bcc | default(omit) }}\"\n    from: \"{{ mail.from | default(omit)}}\"\n    headers: \"{{ mail.headers | default(omit)}}\"\n    secure: \"{{ mail.secure | default(omit) }}\"\n    subtype: \"{{ mail.subtype | default(omit) }}\"\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "5a6c88324e8f2023600359b78cca88a5a114f477", "filename": "roles/ovirt-engine-cleanup/meta/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "galaxy_info:\n  author: Lukas Bednar\n  description: generates answer file for engine-cleanup and execute it.\n  company: Red Hat\n\n  # If the issue tracker for your role is not on github, uncomment the\n  # next line and provide a value\n  issue_tracker_url: https://github.com/rhevm-qe-automation/ovirt-ansible/issues\n\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: GPLv3\n\n  min_ansible_version: 1.2\n\n  # Optionally specify the branch Galaxy will use when accessing the GitHub\n  # repo for this role. During role install, if no tags are available,\n  # Galaxy will use this branch. During import Galaxy will access files on\n  # this branch. If travis integration is cofigured, only notification for this\n  # branch will be accepted. Otherwise, in all cases, the repo's default branch\n  # (usually master) will be used.\n  #github_branch:\n\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n    - name: EL\n      versions:\n        - all\n\n  galaxy_tags:\n    # List tags for your role here, one per line. A tag is\n    # a keyword that describes and categorizes the role.\n    # Users find roles by searching for tags. Be sure to\n    # remove the '[]' above if you add tags to this list.\n    #\n    # NOTE: A tag is limited to a single word comprised of\n    # alphanumeric characters. Maximum 20 tags per role.\n    - installer\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a146d9ccd3a24ffd588e70b93d343299a47e5aba", "filename": "roles/osp/admin-user/tasks/roles.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Grant access for account {{ role.name }}\"\n  shell: >\n    source {{ admin_keystonerc_file }};\n    openstack role add \\\n      --user \"{{ role.name }}\" \\\n      --user-domain \"{{ role.domain }}\" \\\n      --project \"{{ item.0.name }}\" \\\n      --project-domain \"{{ item.0.domain }}\" \\\n      \"{{ item.1 }}\"\n  with_subelements:\n  - \"{{ role.projects }}\"\n  - roles\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "aa855834ebfbfc266e8e79aa4b7e94ac610b8ed9", "filename": "roles/deploy/tasks/share.yml", "repository": "roots/trellis", "decoded_content": "---\n- include: \"{{ deploy_share_before | default('../hooks/example.yml') }}\"\n  tags: deploy-share-before\n\n- name: Ensure shared sources are present\n  file:\n    path: \"{{ deploy_helper.shared_path }}/{{ item.src }}\"\n    state: \"{{ item.type | default('directory') }}\"\n    mode: \"{{ item.mode | default('0755') }}\"\n  with_items: \"{{ project_shared_children }}\"\n\n- name: Ensure shared paths are absent\n  file:\n    path: \"{{ deploy_helper.new_release_path }}/{{ item.path }}\"\n    state: absent\n  with_items: \"{{ project_shared_children }}\"\n\n- name: Create shared symlinks\n  file:\n    path: \"{{ deploy_helper.new_release_path }}/{{ item.path }}\"\n    src: \"{{ deploy_helper.shared_path }}/{{ item.src }}\"\n    state: link\n  with_items: \"{{ project_shared_children }}\"\n\n- include: \"{{ deploy_share_after | default('../hooks/example.yml') }}\"\n  tags: deploy-share-after\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "cc5ce94093a824f740f0551d6c8619cfc7d7ab66", "filename": "tasks/unit/install-modules.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: Debian/Ubuntu/CentOS/RedHat) Install NGINX Unit Modules\"\n  package:\n    name: \"{{ item }}\"\n    state: present\n  with_items: \"{{ nginx_unit_modules }}\"\n  when: ansible_os_family != \"FreeBSD\"\n  notify: \"(Handler: Debian/Ubuntu/CentOS/RedHat) Start NGINX Unit\"\n\n- name: \"(Install: FreeBSD) Install NGINX Unit Modules\"\n  portinstall:\n    name: \"{{ item }}\"\n    state: present\n  with_items: \"{{ nginx_unit_modules }}\"\n  when: ansible_os_family == \"FreeBSD\"\n  notify: \"(Handler: FreeBSD) Start NGINX Unit\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "61969e2158d8c71461fe697b541a372d40777ec7", "filename": "roles/notifications/md-to-html/tasks/prereq.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n\n- name: \"Install additional packages\"\n  package:\n    name: \"{{ item }}\"\n    state: \"{{ prereq_state | default('installed') }}\"\n  with_items:\n  - pandoc\n  \n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "db4eb2c531f1e43a568e28ae47fa107695f5b489", "filename": "roles/wordpress/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Include the install playbook\n  include: install.yml\n  when: wordpress_install"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "1ef7378b568974e4c0b21b662a1def3916769b6e", "filename": "roles/wordpress-setup/tasks/nginx.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Copy SSL cert\n  copy:\n    src: \"{{ item.value.ssl.cert }}\"\n    dest: \"{{ nginx_ssl_path }}/{{ item.value.ssl.cert | basename }}\"\n    mode: 0640\n  with_dict: \"{{ wordpress_sites }}\"\n  when: item.value.ssl.enabled and item.value.ssl.cert is defined\n\n- name: Copy SSL key\n  copy:\n    src: \"{{ item.value.ssl.key }}\"\n    dest: \"{{ nginx_ssl_path }}/{{ item.value.ssl.key | basename }}\"\n    mode: 0600\n  with_dict: \"{{ wordpress_sites }}\"\n  when: item.value.ssl.enabled and item.value.ssl.key is defined\n\n- name: Create includes.d directories\n  file:\n    path: \"{{ nginx_path }}/includes.d/{{ item }}\"\n    state: directory\n    mode: 0755\n  with_items: \"{{ wordpress_sites.keys() }}\"\n  register: nginx_includes_paths\n\n- name: Template files out to includes.d\n  template:\n    src: \"includes.d/{{ item }}\"\n    dest: \"{{ nginx_path }}/includes.d/{{ item[:-3] }}\"\n  with_lines: \"cd {{ role_path }}/templates/includes.d && find {{ wordpress_sites.keys() | join(' ') }} -type f -name \\\\*.conf.j2 2>/dev/null || :\"\n  register: nginx_includes_managed\n  notify: reload nginx\n\n- name: Retrieve list of existing files in includes.d\n  shell: \"find {{ nginx_includes_paths.results | map(attribute='path') | join(' ') }} -type f -name \\\\*.conf 2>/dev/null || :\"\n  register: nginx_includes_existing\n  changed_when: false\n\n- name: Remove unmanaged files from includes.d\n  file:\n    path: \"{{ item }}\"\n    state: absent\n  with_items: \"{{ nginx_includes_existing.stdout_lines |\n                  difference(nginx_includes_managed.results | default([]) | map(attribute='item') |\n                    map('regex_replace', '(.*)\\\\.j2', '/etc/nginx/includes.d/\\\\1') | list\n                  )\n               }}\"\n  notify: reload nginx\n\n- name: Create Nginx conf for challenges location\n  template:\n    src: \"{{ playbook_dir }}/roles/letsencrypt/templates/acme-challenge-location.conf.j2\"\n    dest: \"{{ nginx_path }}/acme-challenge-location.conf\"\n  notify: reload nginx\n\n- name: Create WordPress configuration for Nginx\n  template:\n    src: \"wordpress-site.conf.j2\"\n    dest: \"{{ nginx_path }}/sites-available/{{ item.key }}.conf\"\n  with_dict: \"{{ wordpress_sites }}\"\n  notify: reload nginx\n\n- name: Enable WordPress site\n  file:\n    src: \"{{ nginx_path }}/sites-available/{{ item.key }}.conf\"\n    dest: \"{{ nginx_path }}/sites-enabled/{{ item.key }}.conf\"\n    owner: root\n    group: root\n    state: link\n  with_dict: \"{{ wordpress_sites }}\"\n  notify: reload nginx\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "bd2a28737b690919be5d814c6998e6f2ebec9177", "filename": "handlers/main.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- name: systemd-reload\n  systemd:\n    daemon-reload: yes\n    name: nexus.service\n\n- name: nexus-service-restart\n  systemd:\n    name: nexus.service\n    state: restarted\n    no_block: yes\n\n- name: nexus-service-stop\n  systemd:\n    name: nexus.service\n    state: stopped\n  when: nexus_systemd_service_file.stat.exists\n\n- name: wait-for-nexus\n  wait_for:\n    path: \"{{ nexus_data_dir }}/log/nexus.log\"\n    search_regex: \"Started Sonatype Nexus OSS .*\"\n    timeout: 1800\n\n- name: wait-for-nexus-port\n  wait_for:\n    port: \"{{ nexus_default_port }}\"\n    delay: 5\n\n- name: httpd-service-reload\n  systemd:\n    name: \"{{ httpd_package_name }}.service\"\n    state: reloaded\n    enabled: yes\n    no_block: yes\n\n- name: wait-for-httpd\n  wait_for:\n    port: 443\n    delay: 5\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "aab6bff520a0f35872e8e4f2dc66c1b00d0ed49f", "filename": "roles/ansible/tower/config-ansibletower/tasks/ldap.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Upload Cert CA to Ansible Tower (if applicable)\"\n  copy: \n    src: \"{{ ldap_ca_cert }}\"\n    dest: \"/etc/pki/ca-trust/source/anchors/{{ ldap_ca_cert | basename }}\"\n  when:\n  - ldap_ca_cert is defined\n  - ldap_ca_cert|trim != ''\n  notify:\n  - restart-tower\n  register: ca_uploaded\n\n- name: \"Update CA trust if a new CA was added\"\n  command: update-ca-trust\n  when:\n  - ca_uploaded is defined\n  - ca_uploaded.changed\n\n- name: \"Update Ansible Tower LDAP config\"\n  uri: \n    url: https://localhost/api/v1/settings/ldap/\n    method: PUT\n    body: \"{{ lookup('template', 'ldap.j2') }}\"\n    body_format: 'json'\n    headers:\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n    user: admin\n    password: \"{{ tower_admin_password }}\" \n    validate_certs: no\n  notify:\n  - restart-tower\n  \n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "63cb001ebf448b67e9c9e9f67e5c683526add7fc", "filename": "roles/user-management/manage-local-user-ssh-authkeys/test/inventory/group_vars/all.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nuser_name: user1\nclear_text_password: test123\n\nauthorized_keyfile: \"{{ inventory_dir }}/../authorized_keys\"\nreset_keyfile: yes\n\n\nkey_url: \"{{ lookup('file', authorized_keyfile) }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "380398fa88c7f46b66a5d1ba1555772c01b16121", "filename": "roles/dns/config-dns-server-bind/tasks/prereq.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Ensure required packages are installed\n  package:\n    name: \"{{ item }}\"\n    state: \"{{ package_state }}\"\n  with_items:\n    - bind\n    - bind-utils\n    - firewalld\n    - python-firewall\n    - libsemanage-python\n    - python-dns\n    - libselinux-python\n\n- name: Enable named\n  service:\n    name: named\n    enabled: yes\n\n- name: Enable firewalld\n  service:\n    name: firewalld\n    enabled: yes\n    state: started\n\n- name: Open Firewall for DNS\n  firewalld:\n    port: \"{{item}}\"\n    permanent: yes\n    state: enabled\n    immediate: yes\n  with_items:\n    - 53/tcp\n    - 53/udp\n\n- name: Configure named\n  copy:\n    src: named.conf\n    dest: /etc/named.conf\n    owner: named\n    group: named\n    mode: 0660\n\n- name: Setup Zone Directory\n  file:\n    path: /var/named/static\n    state: directory\n    owner: named\n    group: named\n    mode: 0770\n\n- name: Setup key for service named status to communicate with BIND\n  command: /sbin/rndc-confgen -a -r /dev/urandom\n\n- name: Ensure various files/directories exists with the proper permissions\n  file:\n    path: \"{{ item }}\"\n    owner: root\n    group: named\n    mode: 0640\n  with_items:\n    - \"/etc/rndc.key\"\n\n- name: Configure SELinux\n  seboolean:\n    name: named_write_master_zones\n    state: yes\n    persistent: yes\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "189dc449d37bce2a30b386a6edcb800def3a79b3", "filename": "roles/dns/manage-dns-zones/tasks/route53/process-one-zone.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Remove Zone entries prior to remove the Zone\n  include_tasks: loop-zones.yml\n  when:\n    - zone.state == \"absent\"\n\n- name: Ensure the private zone is on the desired state\n  route53_zone:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    zone: \"{{ zone.dns_domain }}\"\n    vpc_id: \"{{ zone.route53.vpc_id }}\"\n    vpc_region: \"{{ zone.route53.vpc_region }}\"\n    state: \"{{ zone.state | default('present') }}\"\n  when:\n    - view.name == \"private\"\n\n- name: Ensure the public zone is on the desired state\n  route53_zone:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    zone: \"{{ zone.dns_domain }}\"\n    state: \"{{ zone.state | default('present') }}\"\n  when:\n    - view.name == \"public\"\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "c59679ce103577080ab576a1feb785cbd184d67b", "filename": "roles/notifications/send-email/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n# This test covers the full feature set provided by the role\n\n- name: Test email/send role\n  hosts: localhost\n\n  roles:\n    - email/send\n"}, {"commit_sha": "473bab1042b717eb6a6641b7240516af4dbae4d8", "sha": "08caf1dee52ef9a6332089dde29b946c3beb8524", "filename": "tasks/main.yml", "repository": "fubarhouse/ansible-role-golang", "decoded_content": "---\n# main tasks file for fubarhouse-golang\n\n- name: \"Include tasks gathering system information\"\n  include: setup.yml\n\n- name: \"Include tasks to clean installation\"\n  include: cleanup.yml\n  when: go_install_clean|bool == true\n\n- name: \"Include tasks for installation\"\n  include: install.yml\n  when: (current_go_version is not defined) or\n        (expected_go_version_output|string not in current_go_version.stdout|default(''))\n\n- name: \"Include tasks for Go Get\"\n  include: go-get.yml\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "239911063d68a50b3475746e08c4216c8f007090", "filename": "roles/config-linux-desktop/config-lxde/tasks/lxde-Fedora.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: \"Install additional packages for LXDE\"\n  dnf:\n    name: \"{{ item }}\"\n    state: present\n  with_items:\n  - '@lxde-desktop'\n\n"}, {"commit_sha": "4e46e9eb277bc88f285dbc9dd980193e57f7bf48", "sha": "6610a68efe253e94a5af8d5b3449b73039591ba3", "filename": "handlers/main.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n# handlers file for ansible-role-docker-ce\n\n- name: restart docker\n  service:\n    name: docker\n    state: restarted\n  become: yes\n  tags: [\"install\", \"configure\"]\n\n# Workaround because systemd cannot be used: https://github.com/ansible/ansible/issues/22171\n- name: restart auditd\n  shell: service auditd restart\n  args:\n    warn: no\n  become: yes\n  tags: [\"install\", \"configure\"]\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "cfdeb9ca03b77c9c695ed0b432ea28b810e950f8", "filename": "roles/ansible/tower/manage-credentials/tasks/process-credential.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Get the org id based on the org name\"\n  set_fact:\n    org_id: \"{{ item.id }}\"\n  when:\n  - item.name|trim == credential.organization|trim\n  with_items:\n  - \"{{ existing_organizations_output.rest_output }}\"\n\n- name: \"Get the credential_type id based on the name\"\n  set_fact:\n    credential_type_id: \"{{ item.id }}\"\n  when:\n  - item.name|trim == credential.credential_type|trim\n  with_items:\n  - \"{{ existing_credential_types_output.rest_output }}\"\n\n- name: \"Load up the credential\"\n  uri:\n    url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}/api/v2/credentials/\"\n    user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n    password: \"{{ ansible_tower.admin_password }}\"\n    force_basic_auth: yes\n    method: POST\n    body: \"{{ lookup('template', 'credential.j2') }}\"\n    body_format: 'json'\n    headers:\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n    validate_certs: no\n    status_code: 200,201,400\n\n- name: \"Clear/Update facts\"\n  set_fact:\n    org_id: ''\n    credential_type_id: ''\n    processed_credentials: \"{{ processed_credentials + [ { 'name': credential.name } ] }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "eaf02e06b21bdf1d7f34c8de82a9b2381a238869", "filename": "playbooks/notifications/email-notify-group-of-users.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Obtain list of users to e-mail\"\n  hosts: mail-host\n  gather_facts: no\n  tasks:\n  - include_role:\n      name: roles/user-management/list-users-by-group\n\n- import_playbook: email-notify-list-of-users.yml\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "609df85d8dde0b7d0369ec22a0f1686b7d359517", "filename": "tasks/create_task_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_task\n    args: \"{{ item }}\"\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "ebee218af6a129fcb1101b4989e4047e78810099", "filename": "roles/notifications/send-email/tests/inventory/group_vars/all.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nmail:\n  host: \"smtp.example.com\"\n  port: \"465\"\n  username: \"user1@example.com\"\n  password: \"pa55word\"\n  secure: \"always\"\n  header: 'Reply-To=user2@example.com'\n  to: \"person1@example.com, person2@example.com\"\n  subject: \"Test Message 1\"\n  body: \"<html><body><h1>This is a H1 header</h1></body></html>\"\n  subtype: \"html\"\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "56ef3f1ff5ed9e52e39a988f4be0dba4a14ad3dc", "filename": "roles/config-libvirt/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: libvirt.yml\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "9144aedd27e719f05e68628143f700efa67b3a39", "filename": "playbooks/files/stenographer.service", "repository": "rocknsm/rock", "decoded_content": "[Unit]\nDescription=packet capture to disk\nAfter=syslog.target network.target\n\n[Service]\nType=oneshot\nRemainAfterExit=yes\nExecStart=/bin/true\nExecReload=/bin/true\nWorkingDirectory=/etc/stenographer\n\n[Install]\nWantedBy=multi-user.target\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "5f1c0dbe7b633b44097550cd5b1cf45475fb259d", "filename": "roles/ansible/tower/manage-credentials/tests/inventory/group_vars/tower.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ntower_admin_password: \"admin01\"\n\nansible_tower_credentials:\n- name: \"Cred1\"\n  description: \"My Credential 1\"\n  organization: \"Default\"\n  credential_type: \"Machine\"\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "f3816a6f8a74d0136d38c0eaf9a58de16596071c", "filename": "archive/roles/openstack-create/pre_tasks/pre_tasks.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- name: \"Validate OpenStack SSH key is defined\"\n  fail: msg=\"Required 'openstack_key_name' is not defined!\"\n  when: openstack_key_name is undefined or openstack_key_name is none or openstack_key_name|trim == ''\n\n- name: \"Verify connectivity to OpenStack\"\n  command: \"nova credentials\"\n  register: nova_result\n  failed_when: nova_result.rc != 0\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "ae9970c7b84062eeff904c8b318bc530b96a8614", "filename": "tasks/check_requirements.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: Check if OS is Debian-based (we do not support others)\n    debug: msg=\"Check OS family\"\n    failed_when: ansible_os_family != \"Debian\"\n\n  - name: Check if Ansible version is supported\n    debug: msg=\"Check Ansible version\"\n    failed_when: ansible_version.full | version_compare('1.8', '<')\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "ba69dfbb30b4f4e9448c76ce51a8afdf8cba2d28", "filename": "archive/roles/registry/defaults/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\ndefault_auth_layer: false\ndefault_certificate_path: \"/etc/nginx/ssl\"\ndefault_certificate_subject: \"/C=US/ST=NC/L=Raleigh/O=Example, Inc/OU=Web/CN=example.com\"\ndefault_domain_name: registry.example.com\ndefault_nginx_repo_url: \"http://nginx.org/packages/rhel/7/noarch/RPMS/nginx-release-rhel-7-0.el7.ngx.noarch.rpm\"\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "c8dce8ad6e5eafde6c0a26f8727e22fa5e467235", "filename": "roles/mesos/tasks/slave.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# Tasks for Slave nodes\n\n- name: create mesos-slave work directory\n  when: mesos_install_mode == \"slave\"\n  file:\n    path: \"{{ mesos_slave_work_dir }}\"\n    state: directory\n    mode: 0755\n  sudo: yes\n  tags:\n    - mesos-slave\n\n- name: run mesos-slave container\n  when: mesos_install_mode == \"slave\"\n  docker:\n    name: mesos-slave\n    image: \"{{ mesos_slave_image }}\"\n    state: started\n    privileged: true\n    volumes:\n    - \"{{ mesos_slave_work_dir }}:{{ mesos_slave_work_dir }}\"\n    - \"/proc:/host/proc:ro\"\n    - \"/cgroup:/cgroup\"\n    - \"/sys:/sys\"\n    - \"/lib/libpthread.so.0:/lib/libpthread.so.0:ro\"\n    - \"/usr/bin/docker:/usr/bin/docker:ro\"\n    - \"/usr/lib/x86_64-linux-gnu/libapparmor.so.1.1.0:/usr/lib/x86_64-linux-gnu/libapparmor.so.1\"\n    - \"{{ mesos_docker_socket }}:/var/run/docker.sock\"\n    ports:\n    - \"{{ mesos_slave_port }}:{{ mesos_slave_port }}\"\n    net: \"host\"\n    env:\n      MESOS_MASTER: \"zk://{{ zookeeper_peers_nodes }}/mesos\"\n      MESOS_EXECUTOR_REGISTRATION_TIMEOUT: \"{{ mesos_executor_registration_timeout }}\"\n      MESOS_CONTAINERIZERS: \"{{ mesos_containerizers }}\"\n      MESOS_RESOURCES: \"{{ mesos_resources }}\"\n      MESOS_IP: \"{{ mesos_ip }}\"\n      MESOS_WORK_DIR: \"{{ mesos_slave_work_dir }}\"\n      MESOS_HOSTNAME: \"{{ mesos_hostname }}\"\n  tags:\n    - mesos-slave\n\n- name: upload mesos-slave template service\n  when: mesos_install_mode == \"slave\"\n  template:\n    src: mesos-slave.conf.j2\n    dest: /etc/init/mesos-slave.conf\n    mode: 0755\n  sudo: yes\n  tags:\n    - mesos-slave\n\n- name: ensure mesos-slave is running (and enable it at boot)\n  when: mesos_install_mode == \"slave\"\n  sudo: yes\n  service:\n    name: mesos-slave\n    state: started\n    enabled: yes\n  tags:\n    - mesos-slave\n\n- name: run prometheus mesos slave exporter container\n  when: mesos_install_mode == \"slave\" and prometheus_enabled|bool\n  docker:\n    name: mesos-exporter\n    image: \"{{ prometheus_mesos_exporter_image }}\"\n    command: \"-exporter.scrape-mode=slave -exporter.url=http://{{ mesos_hostname }}:{{ mesos_slave_port }}\"\n    state: started\n    restart_policy: always\n    ports:\n    - \"{{ prometheus_mesos_exporter_port }}:{{ prometheus_mesos_exporter_port }}\"\n  environment: proxy_env\n  tags:\n    - prometheus\n    - mesos_slave\n\n- name: Set mesos-exporter consul service definition\n  when: mesos_install_mode == \"slave\" and prometheus_enabled|bool\n  sudo: yes\n  template:\n    src: mesos-exporter-consul.j2\n    dest: \"{{ consul_dir }}/mesos-exporter.json\"\n  notify:\n    - restart consul\n  tags:\n    - prometheus\n    - mesos_slave\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "3e980ff60cd8ff4b42fe215d160aab2bf344d3e1", "filename": "roles/ansible/tower/manage-inventories/tasks/process-inventory.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Get the org id based on the org name\"\n  set_fact:\n    org_id: \"{{ item.id }}\"\n  when:\n  - item.name|trim == inventory.organization|trim\n  with_items:\n  - \"{{ existing_organizations_output.rest_output }}\"\n\n- name: \"Load up the inventory\"\n  uri:\n    url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}/api/v2/inventories/\"\n    user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n    password: \"{{ ansible_tower.admin_password }}\"\n    force_basic_auth: yes\n    method: POST\n    body: \"{{ lookup('template', 'inventory.j2') }}\"\n    body_format: 'json'\n    headers:\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n    validate_certs: no\n    status_code: 200,201,400\n  register: inventory_output\n\n# Utilize the `rest_get` library routine to ensure REST pagination is handled\n- name: \"Get the updated list of existing inventories\"\n  rest_get:\n    host_url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}\"\n    rest_user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n    rest_password: \"{{ ansible_tower.admin_password }}\"\n    api_uri: \"/api/v2/inventories/\"\n  register: existing_inventories_output\n\n- name: \"Get the inventory id based on the inventory name\"\n  set_fact:\n    inv_id: \"{{ item.id }}\"\n  when:\n  - item.name|trim == inventory.name|trim\n  with_items:\n  - \"{{ existing_inventories_output.rest_output }}\"\n\n- name: \"Process the inventory host entries\"\n  include_tasks: process-host.yml\n  with_items:\n  - \"{{ inventory.hosts }}\"\n  loop_control:\n    loop_var: host\n\n- name: \"Process the inventory group entries\"\n  include_tasks: process-group.yml\n  with_items:\n  - \"{{ inventory.groups }}\"\n  loop_control:\n    loop_var: group\n\n- name: \"Clear/Update facts\"\n  set_fact:\n    org_id: ''\n    inv_id: ''\n    processed_inventories: \"{{ processed_inventories + [ { 'name': inventory.name } ] }}\"\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "ebdae5262483aa9e7e49b191a9f0ffa9bcc63318", "filename": "tasks/Win32NT/fetch/fetch_fallback_old.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Set artifact basename\n  set_fact:\n    artifact_url: '{{ release_url[0] }}'\n    artifact_basename: \"{{ (release_url[0] | urlsplit('path')).split('/')[-1] }}\"\n\n- name: 'Get {{ checksum_alg }} checksum of file'\n  win_stat:\n    path: '{{ java_download_path }}\\{{ artifact_basename }}'\n    get_checksum: true\n    checksum_algorithm: '{{ checksum_alg }}'\n  register: artifact\n\n- name: Download with checksum validation\n  include_tasks: fetch_checksum.yml\n  when: |\n    not artifact.stat.exists | bool\n    or artifact.stat.checksum != artifact_checksum.content\n  retries: 15\n  delay: 2\n  until: artifact.stat.checksum == artifact_checksum.content\n\n- name: Set downloaded artifact vars\n  set_fact:\n    file_downloaded:\n      dest: '{{ artifact.stat.path }}'\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "06eb979579c508ad4b2a64c0d3be548ce6a9029e", "filename": "tasks/create_repo_pypi_hosted_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_pypi_hosted\n    args: \"{{ _nexus_repos_pypi_defaults|combine(item) }}\""}, {"commit_sha": "abafe1581c6c78d784cf215b214947675d49eff8", "sha": "a5730ac1363187720cef0a218aad8b2cd051a8ea", "filename": "roles/common/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- name: Gather Facts\n  setup:\n  tags:\n    - always\n\n- name: Install software updates\n  apt: update_cache=yes upgrade=dist\n  tags:\n    - cloud\n\n- name: Check if reboot is required\n  shell: >\n    if [[ -e /var/run/reboot-required ]]; then echo \"required\"; else echo \"no\"; fi\n  args:\n    executable: /bin/bash\n  register: reboot_required\n  tags:\n    - cloud\n\n- name: Reboot\n  shell: sleep 2 && shutdown -r now \"Ansible updates triggered\"\n  async: 1\n  poll: 0\n  when: reboot_required is defined and reboot_required.stdout == 'required'\n  ignore_errors: true\n  tags:\n    - cloud\n\n- name: Wait for shutdown\n  local_action: wait_for host={{ inventory_hostname }} port=22 state=stopped timeout=120\n  when: reboot_required is defined and reboot_required.stdout == 'required'\n  become: false\n  tags:\n    - cloud\n\n- name: Wait until SSH becomes ready...\n  local_action: wait_for host={{ inventory_hostname }} port=22 state=started timeout=120\n  when: reboot_required is defined and reboot_required.stdout == 'required'\n  become: false\n  tags:\n    - cloud\n\n- name: Disable MOTD on login and SSHD\n  replace: dest=\"{{ item.file }}\" regexp=\"{{ item.regexp }}\" replace=\"{{ item.line }}\"\n  with_items:\n    - { regexp: '^session.*optional.*pam_motd.so.*', line: '# MOTD DISABLED', file: '/etc/pam.d/login' }\n    - { regexp: '^session.*optional.*pam_motd.so.*', line: '# MOTD DISABLED', file: '/etc/pam.d/sshd' }\n  tags:\n    - cloud\n\n- name: Install tools\n  apt: name=\"{{ item }}\" state=latest\n  with_items:\n    - git\n    - screen\n    - apparmor-utils\n    - uuid-runtime\n    - coreutils\n    - sendmail\n    - iptables-persistent\n    - cgroup-tools\n  tags:\n    - always\n\n- name: Loopback for services configured\n  template: src=10-loopback-services.cfg.j2 dest=/etc/network/interfaces.d/10-loopback-services.cfg\n  notify:\n    - restart loopback\n  tags:\n    - always\n\n- name: Loopback included into the network config\n  lineinfile: dest=/etc/network/interfaces line='source /etc/network/interfaces.d/10-loopback-services.cfg' state=present\n  notify:\n    - restart loopback\n  tags:\n    - always\n\n- meta: flush_handlers\n  tags:\n    - always\n\n- name: Enable packet forwarding for IPv4\n  sysctl: name=\"{{ item }}\" value=1\n  with_items:\n    - net.ipv4.ip_forward\n    - net.ipv4.conf.all.forwarding\n  tags:\n    - always\n\n- name: Enable packet forwarding for IPv6\n  sysctl: name=net.ipv6.conf.all.forwarding value=1\n  tags:\n    - always\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "644aa5a1fdbe39e2758e7d9291751048c3fbdae8", "filename": "roles/awstats/templates/logrotate.d.apache2", "repository": "iiab/iiab", "decoded_content": "/var/log/apache2/*.log {\n\tdaily\n\tmissingok\n\trotate 14\n\tcompress\n\tdelaycompress\n\tnotifempty\n\tcreate 640 root www-data\n\tsharedscripts\n\tpostrotate\n                if /etc/init.d/apache2 status > /dev/null ; then \\\n                    /etc/init.d/apache2 reload > /dev/null; \\\n                fi;\n\tendscript\n\tprerotate\n\t\tif [ -d /etc/logrotate.d/httpd-prerotate ]; then \\\n\t\t\trun-parts /etc/logrotate.d/httpd-prerotate; \\\n\t\tfi; \\\n\tendscript\n}\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "96946ba6d14882dceabe1aeb27e6fd81d03eba9a", "filename": "roles/ovirt-engine-install-packages/tasks/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\n# tasks file for ovirt-engine-install-packages\n- name: yum install engine\n  yum:\n    name: \"{{ovirt_engine_type}}\"\n    state: installed\n    update_cache: yes\n\n- name: yum install dwh\n  yum:\n    name: \"{{ovirt_engine_type}}-dwh\"\n    state: present\n  when: (ovirt_engine_dwh|bool == True) and (ovirt_engine_version|int < 4)\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "ae140d18323b3fe634a6438e5d44da538824e5b2", "filename": "roles/cadvisor/tasks/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "# tasks for running cadvisor\n- name: run cadvisor container\n  when: cadvisor_enabled\n  docker:\n    name: cadvisor\n    image: \"{{ cadvisor_image }}\"\n    state: started\n    restart_policy: \"{{ cadvisor_restart_policy }}\"\n    net: \"{{ cadvisor_net }}\"\n    hostname: \"{{ cadvisor_hostname }}\"\n    volumes:\n    - \"/var/lib/docker/:/var/lib/docker:ro\"\n    - \"/:/rootfs:ro\"\n    - \"/var/run:/var/run:rw\"\n    - \"/sys:/sys:ro\"\n  tags:\n    - cadvisor\n\n- name: upload cadvisor template service\n  when: cadvisor_enabled\n  template:\n    src: cadvisor.conf.j2\n    dest: /etc/init/cadvisor.conf\n    mode: 0755\n  sudo: yes\n  tags:\n    - cadvisor\n\n# Attach to the running container, or start it if needed\n# and forward all signals so that the process manager can detect\n# when a container stops and correctly restart it.\n- name: ensure cadvisor is running (and enable it at boot)\n  when: cadvisor_enabled\n  sudo: yes\n  service:\n    name: cadvisor\n    state: started\n    enabled: yes\n  tags:\n    - cadvisor\n\n- name: get cadvisor container ip\n  sudo: yes\n  command: >\n    docker inspect -f \\{\\{' '.NetworkSettings.IPAddress' '\\}\\} cadvisor\n  register: cadvisor_container_ip\n  when: cadvisor_enabled\n  tags:\n    - cadvisor\n\n- name: Set cadvisor consul service definition\n  sudo: yes\n  template:\n    src: cadvisor-consul.j2\n    dest: \"{{ cadvisor_consul_dir }}/cadvisor.json\"\n  notify:\n    - restart consul\n  when: cadvisor_enabled\n  tags:\n    - cadvisor\n\n- name: stop cadvisor container\n  when: not cadvisor_enabled\n  sudo: yes\n  service:\n    name: cadvisor\n    state: stopped\n    enabled: yes\n  tags:\n    - cadvisor\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "3af663a73e434f6c8cf4771891996e2d43d93c89", "filename": "roles/fail2ban/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: ensure fail2ban is installed\n  apt:\n    pkg: fail2ban\n    state: latest\n    update_cache: true\n    cache_valid_time: \"{{ apt_cache_valid_time }}\"\n  notify:\n    - restart fail2ban\n\n- name: ensure fail2ban is configured\n  template:\n    src: \"{{ item }}.j2\"\n    dest: /etc/fail2ban/{{ item }}\n  with_items:\n    - jail.local\n    - fail2ban.local\n  notify:\n    - restart fail2ban\n\n- name: ensure fail2ban starts on a fresh reboot\n  service:\n    name: fail2ban\n    state: started\n    enabled: yes\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "ef06fea2727eb222b2873b0b3a233a6371d11998", "filename": "tasks/setup_privilege_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: setup_privilege\n    args: \"{{ _nexus_privilege_defaults|combine(item) }}\""}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "34b1d093f2218d1f1abebdf02fe9820b6741906c", "filename": "roles/1-prep/templates/92-rtc-i2c.rules", "repository": "iiab/iiab", "decoded_content": "# /etc/udev/rules.d/92-rtc-i2c.rules\n#\nACTION==\"add\", SUBSYSTEM==\"rtc\", ATTRS{hctosys}==\"0\", RUN+=\"/usr/sbin/hwclock -s --utc\"\n"}, {"commit_sha": "9662c15ce2e4260fac5cc2bfdf5aaaaf0a2191dd", "sha": "255086c2a9f619f83ebf6af5697930379979c8e2", "filename": "handlers/main.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: restart auditd\n    service: name=auditd state=restarted\n    changed_when: False\n    ignore_errors: True\n\n  - name: restart rsyslog\n    service: name=rsyslog state=restarted\n    changed_when: False\n    ignore_errors: True\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "73b763fb2249eaf8c1ac0977c61c1ba90dc1be7d", "filename": "roles/config-iscsi-client/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- include_tasks: iscsi.yml\n  when: \n  - iscsi_target is defined\n  - iscsi_target|trim != ''\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "92a395cb8c94d2fefe55248f64ac16ac01fef831", "filename": "roles/cups/templates/cupsd.conf", "repository": "iiab/iiab", "decoded_content": "ServerAlias *\nLogLevel warn\nMaxLogSize 1m\nListen {{ lan_ip }}:631\nListen localhost:631\nListen /var/run/cups/cups.sock\nBrowsing On\nBrowseLocalProtocols dnssd\nDefaultAuthType Basic\nWebInterface Yes\n<Location />\n  Order allow,deny\n</Location>\n<Location /admin>\n  Order allow,deny\n</Location>\n<Location /admin/conf>\n  AuthType Default\n  Require user @SYSTEM\n  Order allow,deny\n</Location>\n<Policy default>\n  JobPrivateAccess default\n  JobPrivateValues default\n  SubscriptionPrivateAccess default\n  SubscriptionPrivateValues default\n  <Limit Create-Job Print-Job Print-URI Validate-Job>\n    Order deny,allow\n  </Limit>\n  <Limit Send-Document Send-URI Hold-Job Release-Job Restart-Job Purge-Jobs Set-Job-Attributes Create-Job-Subscription Renew-Subscription Cancel-Subscription Get-Notifications Reprocess-Job Cancel-Current-Job Suspend-Current-Job Resume-Job Cancel-My-Jobs Close-Job CUPS-Move-Job CUPS-Get-Document>\n    Require user @OWNER @SYSTEM\n    Order deny,allow\n  </Limit>\n  <Limit CUPS-Add-Modify-Printer CUPS-Delete-Printer CUPS-Add-Modify-Class CUPS-Delete-Class CUPS-Set-Default CUPS-Get-Devices>\n    AuthType Default\n    Require user @SYSTEM\n    Order deny,allow\n  </Limit>\n  <Limit Pause-Printer Resume-Printer Enable-Printer Disable-Printer Pause-Printer-After-Current-Job Hold-New-Jobs Release-Held-New-Jobs Deactivate-Printer Activate-Printer Restart-Printer Shutdown-Printer Startup-Printer Promote-Job Schedule-Job-After Cancel-Jobs CUPS-Accept-Jobs CUPS-Reject-Jobs>\n    AuthType Default\n    Require user @SYSTEM\n    Order deny,allow\n  </Limit>\n  <Limit Cancel-Job CUPS-Authenticate-Job>\n    Require user @OWNER @SYSTEM\n    Order deny,allow\n  </Limit>\n  <Limit All>\n    Order deny,allow\n  </Limit>\n</Policy>\n<Policy authenticated>\n  JobPrivateAccess default\n  JobPrivateValues default\n  SubscriptionPrivateAccess default\n  SubscriptionPrivateValues default\n  <Limit Create-Job Print-Job Print-URI Validate-Job>\n    AuthType Default\n    Order deny,allow\n  </Limit>\n  <Limit Send-Document Send-URI Hold-Job Release-Job Restart-Job Purge-Jobs Set-Job-Attributes Create-Job-Subscription Renew-Subscription Cancel-Subscription Get-Notifications Reprocess-Job Cancel-Current-Job Suspend-Current-Job Resume-Job Cancel-My-Jobs Close-Job CUPS-Move-Job CUPS-Get-Document>\n    AuthType Default\n    Require user @OWNER @SYSTEM\n    Order deny,allow\n  </Limit>\n  <Limit CUPS-Add-Modify-Printer CUPS-Delete-Printer CUPS-Add-Modify-Class CUPS-Delete-Class CUPS-Set-Default>\n    AuthType Default\n    Require user @SYSTEM\n    Order deny,allow\n  </Limit>\n  <Limit Pause-Printer Resume-Printer Enable-Printer Disable-Printer Pause-Printer-After-Current-Job Hold-New-Jobs Release-Held-New-Jobs Deactivate-Printer Activate-Printer Restart-Printer Shutdown-Printer Startup-Printer Promote-Job Schedule-Job-After Cancel-Jobs CUPS-Accept-Jobs CUPS-Reject-Jobs>\n    AuthType Default\n    Require user @SYSTEM\n    Order deny,allow\n  </Limit>\n  <Limit Cancel-Job CUPS-Authenticate-Job>\n    AuthType Default\n    Require user @OWNER @SYSTEM\n    Order deny,allow\n  </Limit>\n  <Limit All>\n    Order deny,allow\n  </Limit>\n</Policy>\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "a554d6c130a3d556ba99b9136c49f7349625f7c7", "filename": "tasks/opensource/install-oss-linux.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: Linux) Configure NGINX repo\"\n  block:\n\n    - import_tasks: setup-debian.yml\n      when: ansible_os_family == \"Debian\"\n\n    - import_tasks: setup-redhat.yml\n      when: ansible_os_family == \"RedHat\"\n\n    - import_tasks: setup-suse.yml\n      when: ansible_os_family == \"Suse\"\n\n  when: nginx_install_from == \"nginx_repository\"\n\n- name: \"(Install: Linux) Install NGINX package\"\n  package:\n    name: \"nginx{{ nginx_version | default('') }}\"\n    state: present\n  when: ansible_os_family in nginx_linux_families\n  notify: \"(Handler: All OSs) Start NGINX\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "7c5971d74c425617a5c732542b09272027af99b7", "filename": "roles/network/templates/named/named.root.hints", "repository": "iiab/iiab", "decoded_content": "//\n//   The 'named.root' root cache hints zone for the bind DNS 'named' nameserver.\n//\n//   named's cache must be primed with the addresses of the root zone '.' nameservers. \n//   The root zone file can be obtained by querying the root 'A' nameserver:\n//     $ dig . ns @198.41.0.4 > named.root\n//   Or by download via FTP / HTTP:\n//     $ wget ftp://ftp.rs.internic.net/domain/named.root \n//   \n//   Every view that is to provide recursive service must include this zone.\n//\nzone \".\" IN {\n\ttype hint;\n\tfile \"named.root\";\n};"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "02ff61f50350bd40a8fd0857375ad32a7a49d58f", "filename": "tasks/Linux/fetch/dragonwell8-fallback.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Check requested major version for Alibaba Dragonwell\n  fail:\n    msg: \"Alibaba Dragonwell corresponds to OpenJDK 8 only\"\n  when: java_major_version != 8\n\n- name: Check requested architecture for Alibaba Dragonwell\n  fail:\n    msg: \"Alibaba Dragonwell JDK currently supports Linux/x86_64 platform only\"\n  when: java_arch != \"x64\"\n\n- name: Prepare GitHub API release tag\n  set_fact:\n    sub_uri: >-\n      {{ ((java_minor_version != '*')\n        | ternary('tags/v{{ java_major_version }}.{{ java_minor_version }}-GA', 'latest')) }}\n\n- name: Fetch Dragonwell version by tag\n  uri:\n    url: \"{{ github_api_page }}/repos/alibaba/dragonwell8/releases/{{ sub_uri }}\"\n    return_content: true\n    body_format: json\n    status_code: [200, 404] # Not found case we are handling below\n  register: response\n\n- name: Exit if Dragonwell version is not found\n  fail:\n    msg: 'Dragonwell version {{ java_major_version }}.{{ java_minor_version }} not found'\n  when: response.status == 404\n\n# Transform Release name to Asset name\n# Release name sample: Alibaba Dragonwell 8.1.1-GA\n# Asset name sample: Alibaba_Dragonwell_8.1.1-GA_Linux_x64.tar.gz\n- name: Prepare release asset name\n  set_fact:\n    asset_name: \"{{ (response.json.name | regex_replace(' ', '_')) + '_Linux_x64.tar.gz' }}\"\n\n- name: Get release URL\n  set_fact:\n    release_url: \"{{ response.json | json_query(\\\"assets[?name=='\\\" + asset_name + \\\"'].browser_download_url\\\") }}\"\n\n- name: Download artifact from {{ release_url[0] }}\n  get_url:\n    url: '{{ release_url[0] }}'\n    dest: '{{ java_download_path }}'\n  register: file_downloaded\n  retries: 20\n  delay: 5\n  until: file_downloaded is succeeded\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "33c37a143e917faa842660b7c2353c43e9e2ef00", "filename": "roles/config-vnc-server/tasks/vnc-server.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Install additional packages for VNC server\"\n  package:\n    name: \"{{ item }}\"\n    state: latest\n  with_items:\n  - tigervnc-server\n  - policycoreutils-python-utils\n  - checkpolicy \n\n- name: \"Ensure .vnc dir exists\"\n  file:\n    path: \"{{ vnc_home_dir }}/{{ main_user }}/.vnc\"\n    state: directory\n    owner: \"{{ main_user }}\"\n\n- name: \"Check to see if a VNC password already exists\"\n  stat: \n    path: \"{{ vnc_home_dir }}/{{ main_user }}/.vnc/passwd\"\n  register: passwd_info \n\n- name: \"Set a default vnc password (use 'vncpasswd' to change)\"\n  shell: \"echo vncpasswd01 | vncpasswd -f > {{ vnc_home_dir }}/{{ main_user }}/.vnc/passwd\"\n  when: passwd_info.stat.exists == False\n\n- name: \"Ensure correct ownership of the vnc password file\"\n  file:\n    path: \"{{ vnc_home_dir }}/{{ main_user }}/.vnc/passwd\"\n    owner: \"{{ main_user }}\"\n    mode: 0600\n\n- name: \"Add the xstartup (gnome) configuration to the main user\"\n  copy :\n    src: xstartup-gnome\n    dest: \"{{ vnc_home_dir }}/{{ main_user }}/.vnc/xstartup\"\n    force: no\n    owner: \"{{ main_user }}\"\n    mode: 0755\n  when:\n  - gnome_install|default(False)\n\n- name: \"Add the xstartup (XFCE) configuration to the main user\"\n  copy :\n    src: xstartup-xfce\n    dest: \"{{ vnc_home_dir }}/{{ main_user }}/.vnc/xstartup\"\n    force: no\n    owner: \"{{ main_user }}\"\n    mode: 0755\n  when:\n  - xfce_install|default(False)\n\n- name: \"Add the xstartup (LXDE) configuration to the main user\"\n  copy :\n    src: xstartup-lxde\n    dest: \"{{ vnc_home_dir }}/{{ main_user }}/.vnc/xstartup\"\n    force: no\n    owner: \"{{ main_user }}\"\n    mode: 0755\n  when:\n  - lxde_install|default(False)\n\n- name: \"Add the xstartup (MATE) configuration to the main user\"\n  copy :\n    src: xstartup-mate\n    dest: \"{{ vnc_home_dir }}/{{ main_user }}/.vnc/xstartup\"\n    force: no\n    owner: \"{{ main_user }}\"\n    mode: 0755\n  when:\n  - mate_install|default(False)\n\n- name: \"Copy VNC service file into place\" \n  copy:\n    src: /usr/lib/systemd/system/vncserver@.service\n    dest: \"/etc/systemd/system/vncserver-{{ main_user }}@.service\"\n    remote_src: True\n\n- name: \"Ensure the user config is set for the vnc service\"\n  replace: \n    path: \"/etc/systemd/system/vncserver-{{ main_user }}@.service\"\n    regexp: \"{{ item.0 }}\"\n    replace: \"{{ item.1 }}\"\n  with_together:\n  - ['<USER>', '/home/' ]\n  - [ \"{{ main_user }}\", \"{{ vnc_home_dir }}/\" ]\n\n- name: \"Reload systemctl daemon\"\n  command: systemctl daemon-reload\n\n- name: \"Copy SELinux .te file to the host - used to build the module\"\n  copy:\n    src: SELinuxVNC.te\n    dest: /tmp/SELinuxVNC.te\n  \n- name: \"Build SELinux module (.mod) to allow VNC\"\n  command: checkmodule -M -m -o SELinuxVNC.mod /tmp/SELinuxVNC.te  \n    \n- name: \"Build SELinux module (.pp) to allow VNC\"\n  command: semodule_package -m SELinuxVNC.mod -o SELinuxVNC.pp\n\n- name: \"Load SELinux module to allow VNC\"\n  command: semodule -i SELinuxVNC.pp\n\n- name: \"Enable and start VNC server for user\"\n  service:\n    name: \"vncserver-{{ main_user }}@:1\"\n    enabled: yes\n    state: started\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "ffb8e14c96bd59cf607693735bf79f275d09908a", "filename": "roles/config-redis/tasks/install_containerized.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Configure Storage Directory\n  file:\n    state: directory\n    owner: root\n    group: root\n    mode: g+rw\n    path: \"{{ redis_storage_dir }}\"\n  notify: \"Restart Redis Service\"\n\n- name: Configure systemd environment files\n  template:\n    src: \"{{ redis_name }}.j2\"\n    dest: \"{{ systemd_environmentfile_dir}}/{{ redis_name }}\"\n  notify: \"Restart Redis Service\"\n\n- name: Configure systemd unit files\n  template:\n    src: \"{{ redis_service }}.j2\"\n    dest: \"{{ systemd_service_dir}}/{{ redis_service }}\"\n  notify: \"Restart Redis Service\"\n\n- name: Include firewall tasks\n  include_tasks: firewall.yml"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "c0f2fcfe6bac86aeb66d8ce27c06a2373a94259c", "filename": "roles/config-versionlock/tasks/prereq-Fedora.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Install required packages\"\n  package:\n    name: \"{{ item }}\"\n    state: installed\n  with_items:\n  - python2-dnf-plugins-extras-versionlock\n  - python3-dnf-plugins-extras-versionlock\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "cb8d9aa13aa69a374f0437ba485c0c9d8cc39a00", "filename": "roles/dns/manage-dns-zones-route53/tests/inventory/host_vars/localhost.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nansible_connection: local\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "08d80dd66d1905ba83ef1c2517db835beda3a622", "filename": "examples/playbooks/remote_db.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\n- hosts: database\n  remote_user: root\n  become: yes\n  roles:\n    - {role: ovirt-common}\n    - {role: ovirt-engine-remote-db}\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "f5eff8d4cf880e13bb74b04f3210d54fe8c3147e", "filename": "roles/user-management/manage-local-user-password/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nuser_name: \"\"\nclear_text_password: \"\"\n\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "5b62ab8ea8989949f6e06057045a254fe8fcde90", "filename": "roles/haproxy-config/tasks/haproxy-config.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Populate the common config portion for HAproxy'\n  template:\n    src: lb_common.j2\n    dest: '{{ haproxy_temp_dir }}/0001_lb.cfg'\n\n- name: 'Set Facts for HTTP/SSL frontend (ocp_masters)' \n  set_fact: \n    lb_frontend_name: 'ocp_masters' \n    lb_host_port: '{{ lb_https_port_ocp_master }}'\n    lb_entries: '{{ lb_https_entries }}'\n\n- name: 'Populate the HTTP/SSL frontend for HAproxy (ocp_masters)'\n  template:\n    src: lb_https_frontend.j2\n    dest: '{{ haproxy_temp_dir }}/0002_lb.cfg'\n  \n- name: 'Set Facts for HTTP/SSL frontend (ocp_routers_https)' \n  set_fact: \n    lb_frontend_name: 'ocp_routers_https' \n    lb_host_port: '{{ lb_https_port_ocp_router }}'\n    lb_entries: '{{ lb_https_entries }}'\n\n- name: 'Populate the HTTP/SSL frontend for HAproxy (ocp_routers_https)'\n  template:\n    src: lb_https_frontend.j2\n    dest: '{{ haproxy_temp_dir }}/0003_lb.cfg'\n\n- name: 'Populate the HTTP/SSL backend for HAproxy'\n  template:\n    src: lb_https_backend.j2\n    dest: '{{ haproxy_temp_dir }}/0004_lb_{{ item.fqdn }}.cfg'\n  with_items: '{{ lb_https_entries }}'\n\n- name: 'Set Facts for HTTP frontend (ocp_routers_http)' \n  set_fact: \n    lb_frontend_name: 'ocp_routers_http' \n    lb_host_port: '{{ lb_http_port_ocp_router }}'\n    lb_entries: '{{ lb_http_entries }}'\n\n- name: 'Populate the HTTP frontend for HAproxy (ocp_routers_http)'\n  template:\n    src: lb_http_frontend.j2\n    dest: '{{ haproxy_temp_dir }}/0005_lb.cfg'\n\n- name: 'Populate the HTTP backends for HAproxy'\n  template:\n    src: lb_http_backend.j2\n    dest: '{{ haproxy_temp_dir }}/0006_lb_{{ item.fqdn }}.cfg'\n  with_items: '{{ lb_http_entries }}'\n\n- name: 'Populate the default config portion for HAproxy (stats)'\n  template:\n    src: lb_http_default.j2\n    dest: '{{ haproxy_temp_dir }}/0007_lb.cfg'\n\n- name: 'Assemble the final HAproxy config file'\n  assemble: \n    src: '{{ haproxy_temp_dir }}'\n    dest: '{{ haproxy_temp_file }}'\n\n"}, {"commit_sha": "0af3e85a918252d0349ba15721cbedc1e3d80ff1", "sha": "e0c7d86485971bfcd5e30cb3ae955790a9302205", "filename": "tasks/ivm.yml", "repository": "fubarhouse/ansible-role-nodejs", "decoded_content": "---\n\n- name: \"IVM | Ensure folder requirements are met\"\n  become: yes\n  become_user: root\n  file:\n    path: /usr/local/ivm\n    state: directory\n    mode: 0777\n    owner: root\n\n- name: \"IVM | Clone/Update\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  git:\n    repo: \"https://github.com/demohi/ivm.git\"\n    dest: \"{{ fubarhouse_npm.user_dir }}/.ivm\"\n    clone: yes\n    update: yes\n    force: yes\n    version: master\n    recursive: false\n  changed_when: false\n\n- name: \"IVM | Linking\"\n  become: yes\n  become_user: root\n  file:\n    src: \"{{ fubarhouse_npm.user_dir }}/.ivm/bin/ivm\"\n    dest: \"/usr/local/bin/ivm\"\n    state: link\n    force: yes\n  changed_when: false\n\n- name: \"IVM | Ensure shell profiles are configured\"\n  become: yes\n  become_user: \"root\"\n  lineinfile:\n    dest: \"{{ fubarhouse_npm.user_dir }}/{{ item.filename }}\"\n    regexp: 'export NVM_IOJS_ORG_MIRROR=https://iojs.org/dist'\n    line:  'export NVM_IOJS_ORG_MIRROR=https://iojs.org/dist;'\n    state: present\n  with_items:\n    - \"{{ fubarhouse_npm.shell_profiles }}\"\n  ignore_errors: yes"}, {"commit_sha": "1d7d3a653c598355333e7c34a54a550ed3d79cc5", "sha": "8a36671baa0c8a098169f00b32003409b2a165d5", "filename": "tasks/main.yml", "repository": "RocketChat/Rocket.Chat.Ansible", "decoded_content": "---\n# tasks/main.yml: Main tasks for RocketChat.Ansible\n\n  - include_vars: \"{{ item }}\"\n    with_first_found:\n      - \"{{ ansible_distribution }}.yml\"\n      - \"{{ ansible_os_family }}.yml\"\n    tags: vars\n\n  - include: repo_RedHat.yml\n    when: ansible_os_family == \"RedHat\"\n    tags: repo\n\n  - name: Ensure APT cache has been updated recently\n    apt:\n      update_cache: yes\n      #cache_valid_time: 3600\n    when: ansible_pkg_mgr == \"apt\"\n\n  - include: mongodb.yml\n    when: rocket_chat_include_mongodb|bool\n    tags: mongodb\n\n  - name: Ensure the Rocket.Chat service group is present\n    group:\n      name: \"{{ rocket_chat_service_group }}\"\n      state: present\n      system: true\n\n  - name: Ensure the Rocket.Chat service user is present\n    user:\n      comment: Rocket.Chat Service User\n      name: \"{{ rocket_chat_service_user }}\"\n      group: \"{{ rocket_chat_service_group }}\"\n      home: \"{{ rocket_chat_application_path }}\"\n      createhome: true\n      shell: /bin/false\n      state: present\n      system: true\n\n  - name: Ensure Rocket.Chat dependencies are installed\n    package:\n      name: \"{{ rocket_chat_dep_packages }}\"\n      state: present\n    retries: 2\n\n  - name: Ensure link /bin/node -> /bin/nodejs exists\n    file:\n      src: /bin/node\n      dest: /bin/nodejs\n      state: link\n    when: ansible_os_family == \"RedHat\"\n\n  - name: Ensure n (NodeJS) is installed\n    npm:\n      name: n\n      global: true\n      executable: \"{{ rocket_chat_original_npm }}\"\n\n  - name: Check to see if n has installed the required 'node' binary\n    stat:\n      path: \"{{ rocket_chat_node_10_40_path }}/node\"\n    register: n_10_40_node_bin\n\n  - name: Install the 0.10.40 NodeJS environment via n\n    shell: n 0.10.40\n    when: not n_10_40_node_bin.stat.exists|bool\n\n  - name: \"Configure /etc/hosts\"\n    lineinfile:\n      dest: /etc/hosts\n      line:  \"127.0.0.1    {{ ansible_fqdn }}    {{ ansible_hostname }}\"\n      regexp: '^127.0.0.1'\n    when: ansible_virtualization_type != \"docker\"\n\n  - name: Check to see if this is the initial Rocket.Chat deployment\n    stat:\n      path: \"{{ rocket_chat_application_path }}/bundle\"\n    register: rocket_chat_deploy_state\n\n  - name: Set the initial Rocket.Chat upgrade status\n    set_fact:\n      rocket_chat_upgraded: false\n\n  - name: Ensure acl-tools are present [Ubuntu 16]\n    package:\n      name: acl\n      state: present\n    when:\n      - ansible_distribution == \"Ubuntu\"\n      - ansible_distribution_major_version == \"16\"\n\n  - name: Fetch the Rocket.Chat binary tarball\n    get_url:\n      url: \"{{ rocket_chat_tarball_remote }}\"\n      checksum: \"{{ (rocket_chat_tarball_check_checksum == false) | ternary(omit, 'sha256: ' + rocket_chat_tarball_sha256sum) }}\"\n      force: \"{{ (rocket_chat_tarball_check_checksum == false) | ternary('yes', omit) }}\"\n      dest: \"{{ rocket_chat_application_path }}/rocket.chat-{{ rocket_chat_version }}.tgz\"\n      timeout: \"{{ rocket_chat_tarball_fetch_timeout }}\"\n      validate_certs: \"{{ rocket_chat_tarball_validate_remote_cert }}\"\n    # Temp fix for ansible/ansible#15915 ( Broken include in handlers )\n    # https://github.com/ansible/ansible/issues/15915\n    #notify: Upgrade Rocket.Chat\n    become: true\n    become_user: \"{{ rocket_chat_service_user }}\"\n    register: result\n    retries: 3\n    changed_when: (result|changed)\n                  or (not rocket_chat_tarball_check_checksum)\n\n  - name: Upgrade Rocket.Chat\n    include: upgrade.yml\n    when:\n      - result|changed\n      - rocket_chat_deploy_state.stat.exists\n    tags:\n      - upgrade\n\n  - meta: flush_handlers\n\n  - name: Unpack the Rocket.Chat binary tarball\n    unarchive:\n      copy: false\n      src: \"{{ rocket_chat_application_path }}/rocket.chat-{{ rocket_chat_version }}.tgz\"\n      dest: \"{{ rocket_chat_application_path }}\"\n      creates: \"{{ rocket_chat_application_path }}/bundle\"\n    become: true\n    become_user: \"{{ rocket_chat_service_user }}\"\n    tags: build\n\n  - name: Install Rocket.Chat via NPM\n    npm:\n      state: present\n      path: \"{{ rocket_chat_application_path }}/bundle/programs/server\"\n      executable: \"{{ rocket_chat_original_npm }}\"\n    become: true\n    become_user: \"{{ rocket_chat_service_user }}\"\n    tags: build\n\n  - name: Ensure the Rocket.Chat log file symlink is present [Ubuntu 14]\n    file:\n      path: /var/log/rocketchat.log\n      src: /var/log/upstart/rocketchat.log\n      state: link\n      force: yes\n\n    when:\n      - ansible_distribution == \"Ubuntu\"\n      - ansible_distribution_major_version == \"14\"\n\n  - name: Ensure the Rocket.Chat application data permissions are correct\n    file:\n      path: \"{{ rocket_chat_application_path }}\"\n      state: directory\n      owner: \"{{ rocket_chat_service_user }}\"\n      group: \"{{ rocket_chat_service_user }}\"\n      recurse: true\n    tags: build\n\n  - include_vars: \"{{ item }}\"\n    with_first_found:\n      - \"{{ ansible_distribution }}_{{ ansible_distribution_major_version }}.yml\"\n      - \"{{ ansible_os_family }}_{{ ansible_distribution_major_version }}.yml\"\n      - \"{{ ansible_distribution }}.yml\"\n      - \"{{ ansible_os_family }}.yml\"\n    tags: service\n\n  - name: Deploy the Rocket.Chat service file\n    template:\n      src: \"{{ rocket_chat_service_template.src }}\"\n      dest: \"{{ rocket_chat_service_template.dest }}\"\n    notify:\n      - Update the Rocket.Chat service configuration\n      - Restart the Rocket.Chat service\n    tags: service\n\n  - meta: flush_handlers\n\n  - name: Ensure the MongoDB replSets have been initiated\n    shell: >-\n      mongo --eval 'rs.initiate()' &&\n      touch .mongo_rs_initialised\n    become: yes\n    become_user: mongodb\n    args:\n      chdir: /var/lib/mongodb\n      creates: /var/lib/mongodb/.mongo_rs_initialised\n    when: rocket_chat_include_mongodb|bool\n\n  - name: Restart the Rocket.Chat service [UPGRADE]\n    service:\n      name: rocketchat\n      state: restarted\n    when: rocket_chat_upgraded|bool\n\n  - name: Ensure the Rocket.Chat service is running/enabled\n    service:\n      name: rocketchat\n      state: started\n      enabled: true\n    tags: service\n\n  - include: nginx.yml\n    when: rocket_chat_include_nginx|bool\n    tags: nginx\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "28e7005bb55cd34f470e3080ca49fea25902424c", "filename": "roles/config-routes/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: 'prereq.yml'\n- import_tasks: 'route.yml'\n\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "e34e63133d3078c777b1f55b6456092981bbe6f1", "filename": "roles/openvpn/templates/15-openvpn", "repository": "iiab/iiab", "decoded_content": "#!/bin/bash\n\nexport LC_ALL=C\n\n#INTERFACE=$1 # The interface which is brought up or down\n#STATUS=$2 # The new state of the interface\n\n# whenever interface is brought up by NM (rhbz #565921)\nif [ \"$2\" = \"up\" ]; then\n    # wait a few seconds to allow interface startup to complete\n    # (important at boot time without this the service still fails\n    # time-out for dispatcher script is 3s (rhbz#1003695#8)\n    sleep 2\n    /sbin/ip route list dev \"$1\" | grep -q '^default' &&\n    # restart the services\n    systemctl -q is-enabled openvpn@xscenet.service && /usr/lib/iiab/up-wan\nfi\n\n# we added this to prevent logs from filling with openvpn errors\n#  but we do not expect openvpn to be on in that case\n#if [ \"$2\" = \"down\" ]; then\n#    sleep 2\n#    /sbin/ip route list dev \"$1\" | grep -q '^default' ||\n    # stop the services\n#    systemctl -q is-enabled openvpn@xscenet.service && systemctl stop openvpn@xscenet.service\n#fi\n\nexit 0\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "942b93e3b07013ebe2e275eadabaabe15198edaf", "filename": "tasks/Linux/system.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Set parse variables based on java distribution\n  include_vars: java_parts.yml\n\n- name: Perform install from artifacts\n  block:\n    - name: Install requirements\n      package:\n        name: '{{ java_package_requirements }}'\n        state: present\n      register: installed_packages\n      until: installed_packages is succeeded\n      when: transport != 'repositories'\n\n    - name: 'Perform {{ java_binary_type }} install'\n      include_tasks: '{{ install_task }}'\n      with_first_found:\n        - 'install/{{ java_distribution }}_{{ java_binary_type }}.yml'\n        - 'install/{{ java_binary_type }}.yml'\n        - 'install/{{ ansible_os_family }}.yml'\n      loop_control:\n        loop_var: install_task\n\n    - name: Finalize binary paths\n      include_tasks: finalize_paths.yml\n  become: true\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "288ca2e6d5e5e91b05c6642fc580d3933b8a09e7", "filename": "tasks/checks.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- include_tasks: checks/distribution-checks.yml\n  when:\n    _docker_os_dist_check | bool\n\n- include_tasks: checks/compatibility-checks.yml\n"}, {"commit_sha": "79e29502fb4e0ff1c30c0b5396bfa1b48fb84a8e", "sha": "6f18349e26ae5ac124f876032ff8579d0f50325e", "filename": "tasks/main.yml", "repository": "Oefenweb/ansible-wordpress", "decoded_content": "# tasks file for wordpress\n---\n- include: wp-cli.yml\n- include: core.yml\n- include: themes.yml\n- include: plugins.yml\n- include: users.yml\n- include: options.yml\n- include: chown.yml\n"}, {"commit_sha": "1224adf2811c827a09ff0bf133fbb476901a547d", "sha": "cab894aa41c6d342b6ab716ea92a3d28c354a047", "filename": "tasks/freebsd_prepare.yml", "repository": "nusenu/ansible-relayor", "decoded_content": "---\n\n- name: Ensure sequential IP IDs are avoided (FreeBSD)\n  become: yes\n  sysctl:\n    name: net.inet.ip.random_id\n    value: 1\n    reload: no\n    sysctl_set: yes\n\n- name: Gather current kern.ipc.somaxconn setting (FreeBSD)\n  shell: \"sysctl kern.ipc.somaxconn|cut -d' '  -f2\"\n  register: currentsomaxconn\n\n- name: Ensure somaxconn setting is reasonable (FreeBSD)\n  become: yes\n  sysctl:\n    name: kern.ipc.somaxconn\n    value: \"{{ freebsd_somaxconn }}\"\n    reload: no\n    sysctl_set: yes\n  when: currentsomaxconn.stdout|int < {{ freebsd_somaxconn }}\n\n- name: Gather current kern.ipc.nmbclusters setting (FreeBSD)\n  shell: \"sysctl kern.ipc.nmbclusters|cut -d' '  -f2\"\n  register: currentnmbc\n\n- name: Ensure nmbclusters setting is reasonable (FreeBSD)\n  become: yes\n  sysctl:\n    name: kern.ipc.nmbclusters\n    value: \"{{ freebsd_nmbclusters }}\"\n    reload: no\n    sysctl_set: yes\n  when: currentnmbc.stdout|int < {{ freebsd_nmbclusters }}\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "d73cb036daf2fe107132f0b51857c9ce365c65ae", "filename": "roles/dns/manage-dns-zones-bind/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: dns-servers\n  roles:\n    - dns/manage-dns-zones\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "fea2e79ecf63bb83f0808886f9082706695997ce", "filename": "tasks/modules/install-waf.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: All OSs) Install NGINX Plus WAF Module\"\n  package:\n    name: nginx-plus-module-modsecurity\n    state: present\n\n- name: \"(Setup: NGINX Plus) Load NGINX Plus WAF Module\"\n  lineinfile:\n    path: /etc/nginx/nginx.conf\n    insertbefore: BOF\n    line: load_module modules/ngx_http_modsecurity_module.so;\n  when: not nginx_main_template_enable\n  notify: \"(Handler: All OSs) Reload NGINX\"\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "62d99571dcc016b3d90c13e5814daef649bfbdaa", "filename": "tasks/section_13_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 13.1 Ensure Password Fields are Not Empty (Scored)\n    command: awk -F':' '($2 == \"\" ) { print $1 }' /etc/shadow\n    register: awk_empty_shadow\n    changed_when: False\n    failed_when: awk_empty_shadow.stdout != '' and not lock_shadow_accounts\n    tags:\n      - section13\n      - section13.1\n\n  - name: 13.1 Ensure Password Fields are Not Empty (locking accounts) (Scored)\n    command: passwd -l '{{ item }}'\n    with_items:\n        awk_empty_shadow.stdout_lines\n    when: lock_shadow_accounts\n    tags:\n      - section13\n      - section13.1\n\n  - name: 13.2 Verify No Legacy \"+\" Entries Exist in /etc/passwd File (Scored)\n    command: grep '^+:' /etc/passwd\n    register: plus_pass\n    failed_when: plus_pass.rc == 0\n    changed_when: plus_pass.rc == 0\n    tags:\n      - section13\n      - section13.2\n\n  - name: 13.3 Verify No Legacy \"+\" Entries Exist in /etc/shadow File (Scored)\n    command: grep '^+:' /etc/shadow\n    register: plus_shadow\n    failed_when: plus_shadow.rc == 0\n    changed_when: plus_shadow.rc == 0\n    tags:\n      - section13\n      - section13.3\n\n  - name: 13.4 Verify No Legacy \"+\" Entries Exist in /etc/group File (Scored)\n    command: grep '^+:' /etc/group\n    register: plus_group\n    failed_when: plus_group.rc == 0\n    changed_when: plus_group.rc == 0\n    tags:\n      - section13\n      - section13.4\n\n  - name: 13.5 Verify No UID 0 Accounts Exist Other Than root (Scored)\n    command: awk -F':' '($3 == 0) { print $1 }' /etc/passwd\n    register: uid_zero_root\n    changed_when: False\n    failed_when: uid_zero_root.stdout != 'root'\n    tags:\n      - section13\n      - section13.5\n\n  - name: 13.6.1 Ensure root PATH Integrity (empty value) (Scored)\n    shell: 'echo $PATH | grep ::'\n    register: path_colon\n    changed_when: False\n    failed_when: path_colon.rc == 0\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.2 Ensure root PATH Integrity (colon end) (Scored)\n    shell: 'echo $PATH | grep :$'\n    register: path_colon_end\n    changed_when: False\n    failed_when: path_colon_end.rc == 0\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.3 Ensure root PATH Integrity (dot in path) (Scored)\n    shell: \"echo $PATH | sed -e 's/::/:/' -e 's/:$//' -e 's/:/\\\\n/g'\"\n    register: dot_in_path\n    changed_when: False\n    failed_when: '\".\" in dot_in_path.stdout_lines'\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.4 Ensure root PATH Integrity (Scored)\n    file: >\n        path='{{ item }}'\n        state=directory\n        owner=root\n        mode='o-w,g-w'\n    with_items:\n        dot_in_path.stdout_lines\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.7.1 Check Permissions on User Home Directories (gather users) (Scored)\n    shell: /bin/egrep -v '(root|halt|sync|shutdown|false)' /etc/passwd | /usr/bin/awk -F':' '($7 != \"/usr/sbin/nologin\") { print $6 }'\n    register: home_users\n    changed_when: False\n    failed_when: False\n    tags:\n      - section13\n      - section13.7\n\n  - name: 13.7.2 Check Permissions on User Home Directories (Scored)\n    file: >\n        path='{{ item }}'\n        mode='g-w,o-rwx'\n        state=directory\n    with_items:\n        home_users.stdout_lines\n    when: modify_user_homes == True\n    tags:\n      - section13\n      - section13.7\n\n  - name: 13.8.1 Check User Dot File Permissions (gather dotfiles) (Scored)\n    shell: for pth in `/bin/egrep -v '(root|halt|sync|shutdown)' /etc/passwd | /usr/bin/awk -F':' '($7 != \"/usr/sbin/nologin\") { print $6 }'`; do ls -d -A -1 $pth/.* | egrep -v '[..]$'; done\n    changed_when: False\n    failed_when: False\n    always_run: True\n    register: home_dot_files\n    tags:\n      - section13\n      - section13.8\n\n  - name: 13.8.2 Check User Dot File Permissions (Scored)\n    file: >\n        path='{{ item }}'\n        mode='o-w,g-w'\n    with_items:\n        home_dot_files.stdout_lines\n    tags:\n      - section13\n      - section13.8\n\n  - name: 13.9 Check Permissions on User .netrc Files (Scored)\n    file: >\n        path='{{ item }}/.netrc'\n        mode='g-rwx,o-rwx'\n        recurse=yes\n        state=directory\n    with_items:\n        home_users.stdout_lines\n    tags:\n      - section13\n      - section13.9\n\n  - name: 13.10 Check for Presence of User .rhosts Files (Scored)\n    file: >\n        state=absent\n        path='{{ item }}/.rhosts'\n    with_items:\n        home_users.stdout_lines\n    tags:\n      - section13\n      - section13.10\n\n  - name: 13.11 Check Groups in /etc/passwd (preparation) (Scored)\n    command: cut -s -d':' -f4 /etc/passwd\n    register: groups_id_cut\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.11\n\n  - name: 13.11 Check Groups in /etc/passwd (Scored)\n    command: grep -q -P \"^.*?:[^:]*:{{ item }}:\" /etc/group\n    with_items:\n        groups_id_cut.stdout_lines\n    register: groups_present\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.11\n\n  - name: 13.12 Check That Users Are Assigned Valid Home Directories (Scored)\n    stat: path='{{ item }}'\n    with_items:\n        home_users.stdout_lines\n    register: rstat\n    failed_when: rstat is defined and rstat.stat.isdir == False\n    always_run: True\n    tags:\n      - section13\n      - section13.12\n\n  - name: 13.13 Check User Home Directory Ownership (Scored)\n    debug: msg=\"*** Hardcore ***\"\n    tags:\n      - section13\n      - section13.13\n\n  - name: 13.14 Check for Duplicate UIDs (Scored)\n    shell: cut -f3 -d':' /etc/passwd | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.14\n\n  - name: 13.15 Check for Duplicate GIDs (Scored)\n    shell: cut -f3 -d':' /etc/group | sort | uniq -d\n    register: gids_list\n    failed_when: gids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.15\n\n  - name: 13.16 Check for Duplicate User Names (Scored)\n    shell: cut -f1 -d':' /etc/passwd | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.16\n\n  - name: 13.17 Check for Duplicate Group Names (Scored)\n    shell: cut -f1 -d':' /etc/group | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.17\n\n  - name: 13.18 Check for Presence of User .netrc Files (stat) (Scored)\n    stat: path='{{ item }}/.netrc'\n    with_items: home_users.stdout_lines\n    register: netrc_files\n    tags:\n      - section13\n      - section13.18\n\n  - name: 13.18 Check for Presence of User .netrc Files (Scored)\n    file: >\n        path='{{ item.stat.path }}'\n        state=absent\n    when: item is defined and item.stat.exists == True\n    with_items: netrc_files.results\n    tags:\n      - section13\n      - section13.18\n\n  - name: 13.19 Check for Presence of User .forward Files (Scored)\n    file: >\n        path='{{ item }}/.forward'\n        state=absent\n    with_items:\n        home_users.stdout_lines\n    tags:\n      - section13\n      - section13.19\n\n  - name: 13.20.1 Ensure shadow group is empty (Scored)\n    shell: grep '^shadow' /etc/group | cut -f4 -d':'\n    register: shadow_group_empty\n    failed_when: shadow_group_empty.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.1\n\n  - name: 13.20.2 Ensure shadow group is empty (preparation) (Scored)\n    shell: grep '^shadow' /etc/group | cut -f1 -d':'\n    register: shadow_group_id\n    failed_when: False\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.1\n\n  - name: 13.20.2 Ensure shadow group is empty (Scored)\n    shell: awk -F':' '($4 == \"{{ item }}\") { print }' /etc/passwd\n    register: awk_passwd_shadow\n    with_items:\n        shadow_group_id.stdout_lines\n    changed_when: False\n    failed_when: awk_passwd_shadow.stdout != ''\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.2\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "20d20890ae046888494a3f3c3e5a79aec797b1a9", "filename": "roles/dcos_cli/vars/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# vars file for dcos_cli\n"}, {"commit_sha": "2a05a5032ce341d6a1d918453164c59ea2922f58", "sha": "73e63039e8cb3d9ec772a2bc201de53aab0476cc", "filename": "roles/network_interface/vars/RedHat.yml", "repository": "CSCfi/fgci-ansible", "decoded_content": "---\nnetwork_pkgs:\n  - libselinux-python\n  - bridge-utils\n  - iputils\n\nnet_path: \"/etc/sysconfig/network-scripts\"\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "19bf1d7194ad5c1da3022ea104becc5cd06d97d2", "filename": "tasks/prerequisites/setup-debian.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: Debian/Ubuntu) Install Required Debian and Ubuntu Dependencies\"\n  apt:\n    name:\n      - apt-transport-https\n      - dirmngr\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "4fca5d1c34df0c8826de4e0cdc4d150b0c09f4e5", "filename": "roles/dns/manage-dns-records/tasks/nsupdate/process-records.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Manage DNS records for view: {{ dns.0.name }}, zone: {{ dns.1.dns_domain }}, server: {{ nsupdate.server }}\"\n  nsupdate:\n    server: \"{{ nsupdate.server }}\"\n    key_name: \"{{ nsupdate.key_name }}\"\n    key_secret: \"{{ nsupdate.key_secret }}\"\n    key_algorithm: \"{{ nsupdate.key_algorithm }}\"\n    zone: \"{{ dns.1.dns_domain }}\"\n    record: \"{{ item.record }}\"\n    value: \"{{ item.value | default(omit) }}\"\n    type: \"{{ item.type }}\"\n    ttl: \"{{ item.ttl | default(omit) }}\"\n    state: \"{{ item.state | default(present) }}\"\n  with_items:\n    - \"{{ dns.1.entries }}\"\n  when:\n    - dns.1.entries is defined\n  register: nsupdate_result\n  until: nsupdate_result | succeeded\n  retries: 10\n  delay: 1\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "788b322b823a2f1bc195d3a527a6f0b989fb6273", "filename": "roles/dcos_cli/tasks/frameworks.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# tasks file for frameworks\n- include_vars: \"{{ item }}.yml\"\n  with_items:\n    - \"{{ dcos_cli_frameworks_list }}\"\n\n- name: create config directory\n  when: \"dcos_cli_framework_{{ item }}_enabled | bool\"\n  run_once: true\n  template:\n    src: \"{{ item }}-config.j2\"\n    dest: \"/tmp/{{ item }}-config\"\n    mode: 0755\n  sudo: yes\n  tags:\n    - \"{{ item }}\"\n  with_items:\n    - \"{{ dcos_cli_frameworks_list }}\"\n\n- name: install dcos-cli package\n  when: \"dcos_cli_framework_{{ item }}_enabled | bool\"\n  run_once: true\n  docker:\n    name: \"{{ item }}\"\n    image: \"{{ dcos_cli_image }}\"\n    state: started\n    command: \"package install --options=/config --yes {{ item }}\"\n    volumes:\n    - \"/tmp/{{ item }}-config:/config\"\n    env:\n      MESOS_MASTER_URL: \"{{ dcos_cli_mesos_master_url }}\"\n      MARATHON_URL: \"{{ dcos_cli_marathon_url }}\"\n      SOURCES: \"{{ dcos_cli_sources }}\"\n  tags:\n    - \"{{ item }}\"\n  with_items:\n    - \"{{ dcos_cli_frameworks_list }}\"\n\n- name: uninstall dcos-cli package\n  when: \"not dcos_cli_framework_{{ item }}_enabled | bool\"\n  run_once: true\n  docker:\n    name: \"{{ item }}\"\n    image: \"{{ dcos_cli_image }}\"\n    state: started\n    command: \"package uninstall {{ item }}\"\n    env:\n      MESOS_MASTER_URL: \"{{ dcos_cli_mesos_master_url }}\"\n      MARATHON_URL: \"{{ dcos_cli_marathon_url }}\"\n  tags:\n    - \"{{ item }}\"\n  with_items:\n    - \"{{ dcos_cli_frameworks_list }}\"\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "d26e514722c4985253339a25f43f6fcb2ecc40f0", "filename": "tasks/remove-pre-docker-ce.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Determine Docker version\n  command: bash -c \"docker version | grep Version | awk '{print $2}'\"\n  ignore_errors: yes\n  changed_when: false\n  register: _cmd_docker_version\n  check_mode: no\n\n- name: Set fact if old Docker installation shall be removed\n  set_fact:\n    _remove_old_docker: \"{{ docker_remove_pre_ce | bool }} and not \\\n      {{ _cmd_docker_version.stdout_lines[0] is search('-ce') }}\"\n  when: _cmd_docker_version.stdout_lines is defined and _cmd_docker_version.stdout_lines[0] is defined\n\n- name: Check if Docker is running\n  become: true\n  systemd:\n    name: docker\n  ignore_errors: yes\n  register: _service_docker_status\n  check_mode: no\n  when: _remove_old_docker | default(False) | bool\n\n- name: Stop Docker service\n  service:\n    name: docker\n    state: stopped\n  when: \"_service_docker_status.rc | default(1) == 0\"\n\n- name: Remove old Docker installation before Docker CE\n  become: true\n  package:\n    name: \"{{ item }}\"\n    state: absent\n  register: _pkg_result\n  until: _pkg_result is succeeded\n  when: _remove_old_docker | default(False) | bool\n  with_items:\n    - \"{{ docker_old_packages[_docker_os_dist] }}\"\n"}, {"commit_sha": "0183b10864f53eb0cf3405fb2a3a92a07d573349", "sha": "f8199b974f1deb7c4dfed91539a18bcd0ad01594", "filename": "handlers/main.yml", "repository": "angstwad/docker.ubuntu", "decoded_content": "---\n# handlers file for docker.ubuntu\n- name: Start Docker\n  service: name=docker state=started\n  \n- name: Reload docker\n  service: name=docker state=reloaded\n\n- name: Restart docker io\n  service: name=docker.io state=restarted\n  \n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "978de3138f5d73ece826803688860b5efaacb3c9", "filename": "roles/config-versionlock/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Include prereqs per the type of OS\"\n  include_tasks: \"{{ distro_file }}\"\n  with_first_found:\n  - files:\n    - prereq-{{ ansible_distribution }}.yml\n    skip: true\n  loop_control:\n    loop_var: distro_file\n\n- import_tasks: versionlock.yml\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "9362d1528df466fd5c958a2c2e304504aa02abbc", "filename": "archive/roles/cicd/tasks/jenkins.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n    \n- name: Install Jenkins Repository\n  get_url:\n    url: \"{{ jenkins_repo_url }}\"\n    dest: /etc/yum.repos.d/jenkins.repo\n  tags: jenkins\n\n- name: Add Jenkins GPG Key.\n  rpm_key:\n    state: present\n    key: \"{{ jenkins_repo_key_url }}\"\n  tags: jenkins\n\n- name: Install Jenkins.\n  yum:\n    pkg: jenkins\n    state: installed\n  tags: jenkins\n  \n- name: Copy Jenkins Configuration Files\n  copy:\n    src: jenkins/\n    dest: \"{{ jenkins_home_dir }}\"\n    group: \"{{ jenkins_group }}\"\n    owner: \"{{ jenkins_user }}\"\n  notify:\n  - restart jenkins\n  tags: jenkins\n  \n- name: Jenkins XML File\n  template:\n    src: jenkins-config.j2\n    dest: \"{{ jenkins_home_dir }}/config.xml\"\n    group: \"{{ jenkins_group }}\"\n    owner: \"{{ jenkins_user }}\"\n  notify:\n  - restart jenkins\n  tags: jenkins\n  \n  \n- name: Update Jenkins Service Configuration\n  lineinfile: \n    dest: /etc/sysconfig/jenkins\n    regexp: \"JENKINS_ARGS=\"\n    line: \"JENKINS_ARGS=\\\"--prefix=/jenkins\\\"\"\n  notify:\n  - restart jenkins\n  tags: jenkins\n  \n  \n- name: Install Jenkins Plugin\n  include: jenkins_install_plugins.yml \n  vars:\n    plugins:\n        - { name: \"github\", version: \"1.14.2\" }\n        - { name: \"github-api\", version: \"1.71\" }\n        - { name: \"git\", version: \"2.4.1\" }\n        - { name: \"git-client\", version: \"1.19.1\" }\n        - { name: \"git-server\", version: \"1.5\" }\n        - { name: \"credentials\", version: \"1.24\" }\n        - { name: \"scm-api\", version: \"1.0\" }\n        - { name: \"credentials-binding\", version: \"1.6\" }\n        - { name: \"plain-credentials\", version: \"1.1\" }\n        - { name: \"ace-editor\", version: \"1.0.1\" }\n        - { name: \"jquery-detached\", version: \"1.1.1\" }\n        - { name: \"workflow-basic-steps\", version: \"1.12\" }\n        - { name: \"workflow-scm-step\", version: \"1.12\" }\n        - { name: \"workflow-cps-global-lib\", version: \"1.12\" }\n        - { name: \"workflow-support\", version: \"1.12\" }\n        - { name: \"workflow-job\", version: \"1.12\" }\n        - { name: \"workflow-durable-task-step\", version: \"1.12\" }\n        - { name: \"workflow-cps\", version: \"1.12\" }\n        - { name: \"workflow-api\", version: \"1.12\" }\n        - { name: \"workflow-step-api\", version: \"1.12\" }\n        - { name: \"workflow-aggregator\", version: \"1.12\" }\n        - { name: \"parameterized-trigger\", version: \"2.30\" }\n        - { name: \"matrix-project\", version: \"1.6\" }\n        - { name: \"promoted-builds\", version: \"2.24.1\" }\n        - { name: \"ssh-credentials\", version: \"1.11\" }\n        - { name: \"mapdb-api\", version: \"1.0.6.0\" }\n        - { name: \"build-pipeline-plugin\", version: \"1.4.9\" }\n        - { name: \"jquery\", version: \"1.11.2-0\" }\n        - { name: \"delivery-pipeline-plugin\", version: \"0.9.8\" }\n        - { name: \"token-macro\", version: \"1.12.1\" }\n        - { name: \"ws-cleanup\", version: \"0.28\" }\n        - { name: \"job-dsl\", version: \"1.41\" }\n        - { name: \"cloudbees-folder\", version: \"5.1\" }\n        - { name: \"groovy\", version: \"1.27\" }\n        - { name: \"groovy-postbuild\", version: \"2.2.2\" }\n        - { name: \"script-security\", version: \"1.15\" }\n        - { name: \"durable-task\", version: \"1.7\" }\n        - { name: \"docker-plugin\", version: \"0.16.0\" }\n        - { name: \"openshift-pipeline\", version: \"1.0.4\" }\n        - { name: \"credentials\", version: \"1.24\", pinned: true }\n        - { name: \"cvs\", version: \"2.12\", pinned: true }\n        - { name: \"javadoc\", version: \"1.3\", pinned: true }\n        - { name: \"junit\", version: \"1.10\", pinned: true }\n        - { name: \"mailer\", version: \"1.16\", pinned: true }\n        - { name: \"matrix-auth\", version: \"1.2\", pinned: true }\n        - { name: \"matrix-project\", version: \"1.6\", pinned: true }\n        - { name: \"maven-plugin\", version: \"2.12.1\", pinned: true }\n        - { name: \"antisamy-markup-formatter\", version: \"1.3\", pinned: true }\n        - { name: \"script-security\", version: \"1.15\", pinned: true }\n        - { name: \"ssh-credentials\", version: \"1.11\", pinned: true }\n        - { name: \"ssh-slaves\", version: \"1.10\", pinned: true }\n        - { name: \"translation\", version: \"1.12\", pinned: true }\n        - { name: \"subversion\", version: \"2.5.5\", pinned: true }\n        - { name: \"windows-slaves\", version: \"1.1\", pinned: true }\n  notify:\n  - restart jenkins\n  tags: jenkins\n  \n- name: Create Docker Group\n  group:\n    name: docker\n    state: present\n  tags: jenkins\n    \n- name: Add Docker Group to Jenkins User\n  user:\n    name: \"{{ jenkins_user }}\"\n    groups: docker\n    append: yes\n  tags: jenkins\n  \n- name: Open Firewall for Jenkins\n  firewalld:\n    port: \"{{ item }}\"\n    zone: public\n    permanent: yes\n    immediate: yes\n    state: enabled\n  with_items:\n  - \"8080/tcp\"\n  - \"50000/tcp\"\n  tags: jenkins\n  \n- name: Enable Jenkins Service\n  service: \n    name: jenkins\n    enabled: true\n  tags: jenkins"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "2942bd04c8021fc868c67e7793624c4c721cd53f", "filename": "tasks/opensource/setup-alpine.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: Alpine Linux) Add NGINX Plus Repository\"\n  lineinfile:\n    path: /etc/apk/repositories\n    insertafter: EOF\n    line: \"{{ nginx_repository.alpine }}\"\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "9204abf49f6de0696e2b9f51a78662db11fc2b87", "filename": "tasks/amplify/install-amplify.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- import_tasks: setup-debian.yml\n  when: ansible_os_family == \"Debian\"\n\n- import_tasks: setup-redhat.yml\n  when: ansible_os_family == \"RedHat\"\n\n- name: \"(Install: All OSs) Install NGINX Amplify Agent\"\n  package:\n    name: nginx-amplify-agent\n    state: present\n\n- name: \"(Setup: All OSs) Copy NGINX Configurator Agent Configuration Template\"\n  copy:\n    remote_src: yes\n    src: /etc/amplify-agent/agent.conf.default\n    dest: /etc/amplify-agent/agent.conf\n\n- name: \"(Setup: All OSs) Configure NGINX Amplify Agent API Key\"\n  lineinfile:\n    dest: /etc/amplify-agent/agent.conf\n    regexp: api_key =.*\n    line: \"api_key = {{ nginx_amplify_api_key }}\"\n  notify: \"(Handler: All OSs) Start NGINX Amplify Agent\"\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "75ce0637bf611b0d9c41eb2cc4dd9ff7bd0dbe61", "filename": "roles/cfme-ocp-provider/tasks/query_provider.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n- name: Query Provider\n  uri:\n    url: \"{{ provider_url.href }}\"\n    method: GET\n    user: \"{{ cfme_username }}\"\n    password: \"{{ cfme_password }}\"\n    force_basic_auth: true\n    validate_certs: false\n    status_code: 200\n  register: provider_result\n\n- name: Set Provider Facts When Match Found\n  set_fact:\n    ocp_provider_found: True\n    ocp_provider_id: \"{{ provider_result.json.id }}\"\n  when: \"provider_result.json.name == ocp_container_provier_name\""}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "52903391b739d33c7f9d5f0aad3f6fdbedf3fd23", "filename": "roles/dns/manage-dns-zones-route53/tasks/prereq.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Fail when required items are not defined\"\n  fail:\n    msg: \"view name and zones must be defined for each dictionary record\"\n  when:\n    - (item.name is not defined) or\n      (item.zones is not defined)\n  with_items:\n    - \"{{ dns_data.views | default({}) }}\"\n\n- name: Fail when AWS KEY environment variables are not defined\n  debug:\n    msg: \"Both 'AWS_ACCESS_KEY_ID' and 'AWS_SECRET_ACCESS_KEY' environment variables must be defined\"\n  failed_when: (lookup('env','AWS_ACCESS_KEY_ID')|trim == \"\") or\n               (lookup('env','AWS_SECRET_ACCESS_KEY')|trim == \"\")\n"}, {"commit_sha": "d34de7b476a164b23bda483f9bf6853264ca89ec", "sha": "8ae4ec2b98d2f70b521ccba39d33dff755e00f0b", "filename": "roles/virt-install/tests/infrahosts.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: 'Create VMs on infra hosts'\n  hosts: infra_hosts\n  roles:\n  - role: virt-install\n  tags:\n  - provision_infra_vms\n  \n- name: 'Check that the VMs are alive'\n  hosts: infra_vms\n  gather_facts: no\n  tasks:\n  - name: 'Wait for VMs to come alive'\n    local_action: wait_for\n    args: \n      host: \"{{ ansible_host }}\"\n      port: 22\n      delay: 30\n      timeout: 300\n  tags:\n  - vm_health_check\n"}, {"commit_sha": "473bab1042b717eb6a6641b7240516af4dbae4d8", "sha": "9c0e842c73c0a32d206f4b57f7d89476d710caf5", "filename": "meta/main.yml", "repository": "fubarhouse/ansible-role-golang", "decoded_content": "galaxy_info:\n  author: Karl Hepworth\n  description: Installs the Go programming language from distribution, or build from source, and install desired packages to your Golang workspace!\n  license: MIT\n  min_ansible_version: 2.0\n  platforms:\n  - name: MacOSX\n    versions:\n    - all\n  - name: Ubuntu\n    versions:\n    - trusty\n    - xenial\n    - precise\n  - name: EL\n    versions:\n    - 6\n    - 7\n  - name: Debian\n    versions:\n    - jessie\n  galaxy_tags:\n  - go\n  - development\n  - programming\n  - language\n  - compiler\n  - package\n  - manager\ndependencies: []"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "89ef04747b14eab88c3aab5fb8a4645575c50bc0", "filename": "playbooks/templates/ifup-local.j2", "repository": "rocknsm/rock", "decoded_content": "#!/bin/bash\n# File: /sbin/ifup-local\n#\n#\n# This script is run after normal sysconfig network-script configuration\n# is performed on RHEL/CentOS-based systems.\n#\n# Parameters:\n# $1: network interface name\n#\n# Post ifup configuration for tuning capture interfaces\n# This is compatible with the ixgbe driver, YMMV\n\n# Change this to something like /tmp/ifup-local.log for troubleshooting\nLOG=/dev/null\n#LOG=/tmp/ifup-local.log\n\ncase $1 in\n{{ rock_monifs | list | join('|') }})\n\n  for i in rx tx sg tso ufo gso gro lro rxvlan txvlan\n  do\n    ethtool -K $1 $i off &>$LOG\n  done\n\n  ethtool -N $1 rx-flow-hash udp4 sdfn  &>$LOG\n  ethtool -N $1 rx-flow-hash udp6 sdfn &>$LOG\n  ethtool -n $1 rx-flow-hash udp6 &>$LOG\n  ethtool -n $1 rx-flow-hash udp4 &>$LOG\n  ethtool -C $1 rx-usecs 10 &>$LOG\n  ethtool -C $1 adaptive-rx off &>$LOG\n  ethtool -G $1 rx 4096 &>$LOG\n\n  # Disable ipv6\n  echo 1 > /proc/sys/net/ipv6/conf/$1/disable_ipv6 &>$LOG\n  echo 0 > /proc/sys/net/ipv6/conf/$1/autoconf &>$LOG\n\n  # Set promiscuous mode\n  ip link set $1 promisc on &>$LOG\n\n  # Just in case ipv6 is already on this interfaces, let's kill it\n  ip addr show dev $1 | grep --silent inet6\n\n  if [ $? -eq 0 ]\n  then\n    ADDR=$(ip addr show dev $1 | grep inet6 | awk '{ print $2 }')\n    ip addr del $ADDR dev $1 &>$LOG\n  fi\n\n;;\n\n*)\n# No post commands needed for this interface\n;;\n\nesac\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "b4754c02e8c3c6dc7d807849957e49214e77bbea", "filename": "tasks/create_blobstore_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- name: Create directory for blob store.\n  file:\n    path: \"{{ item['path'] }}\"\n    owner: \"{{ nexus_os_user }}\"\n    group: \"{{ nexus_os_group }}\"\n    state: directory\n    recurse: true\n  when: item.path is defined\n\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_blobstore\n    args: \"{{ item }}\"\n"}, {"commit_sha": "836dc4dd0dacc490044a14c0e39469d162b9449b", "sha": "470ecad6f5520650307c7577c7453b9e3f23fd7b", "filename": "tasks/main.yml", "repository": "florianutz/Ubuntu1604-CIS", "decoded_content": "---\n# tasks file for Ubuntu1604-CIS\n- name: Check OS version and family\n  fail:\n      msg: \"This role can only be run agaist Ubuntu 16.04. {{ ansible_distribution }} {{ ansible_distribution_major_version }} is not supported.\"\n  when:\n      - not ansible_distribution == \"Ubuntu\"\n      - not ansible_distribution_release == \"xenial\"\n  tags:\n      - always\n\n- name: Check ansible version\n  fail:\n      msg: You must use ansible 2.3 or greater!\n  when: not ansible_version.full is version_compare('2.3', '>=')\n  tags:\n      - always\n\n- include: prelim.yml\n  become: true\n  tags:\n      - prelim_tasks\n      - always\n\n- include: section1.yml\n  become: true\n  when: ubuntu1604cis_section1\n  tags: section1\n\n- include: section2.yml\n  become: true\n  when: ubuntu1604cis_section2\n  tags: section2\n\n- include: section3.yml\n  become: true\n  when: ubuntu1604cis_section3\n  tags: section3\n\n- include: section4.yml\n  become: true\n  when: ubuntu1604cis_section4\n  tags: section4\n\n- include: section5.yml\n  become: true\n  when: ubuntu1604cis_section5\n  tags: section5\n\n- include: section6.yml\n  become: true\n  when: ubuntu1604cis_section6\n  tags: section6\n\n- include: post.yml\n  become: true\n  tags:\n      - post_tasks\n      - always\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "13322adc6167f59548f718a83d99ab15a41cad36", "filename": "playbooks/files/es-bro-mappings.json", "repository": "rocknsm/rock", "decoded_content": "{\"order\":0,\"template\":\"bro-*\",\"mappings\":{\"_default_\":{\"dynamic_templates\":[{\"ip_addresses\":{\"match_mapping_type\":\"string\",\"match\":\"id_*_h\",\"mapping\":{\"type\":\"ip\"}}},{\"record_uids\":{\"match_mapping_type\":\"string\",\"match\":\"uid\",\"mapping\":{\"type\":\"keyword\"}}},{\"strings_as_keywords\":{\"match_mapping_type\":\"string\",\"match\":\"*\",\"mapping\":{\"type\":\"keyword\"}}}],\"properties\":{\"@version\":{\"type\":\"text\",\"fields\":{\"keyword\":{\"type\":\"keyword\",\"ignore_above\":256}}}}},\"detection\":{\"properties\":{\"notice\":{\"properties\":{\"dst\":{\"type\":\"ip\"},\"id_orig_h\":{\"type\":\"ip\"},\"id_orig_p\":{\"type\":\"long\"},\"id_resp_h\":{\"type\":\"ip\"},\"id_resp_p\":{\"type\":\"long\"},\"src\":{\"type\":\"ip\"},\"msg\":{\"type\":\"text\",\"fields\":{\"keyword\":{\"type\":\"keyword\",\"ignore_above\":256}}}}}}},\"file\":{\"properties\":{\"files\":{\"properties\":{\"rx_hosts\":{\"type\":\"ip\"},\"tx_hosts\":{\"type\":\"ip\"}}}}},\"network\":{\"properties\":{\"@meta\":{\"properties\":{\"geoip_orig\":{\"properties\":{\"ip\":{\"type\":\"ip\"},\"location\":{\"type\":\"geo_point\"}}},\"geoip_resp\":{\"properties\":{\"ip\":{\"type\":\"ip\"},\"location\":{\"type\":\"geo_point\"}}},\"orig_host\":{\"type\":\"ip\"},\"resp_host\":{\"type\":\"ip\"}}},\"dhcp\":{\"properties\":{\"assigned_ip\":{\"type\":\"ip\"}}},\"http\":{\"properties\":{\"user_agent\":{\"type\":\"text\",\"fields\":{\"keyword\":{\"type\":\"keyword\",\"ignore_above\":256}}}}},\"smtp\":{\"properties\":{\"user_agent\":{\"type\":\"text\",\"fields\":{\"keyword\":{\"type\":\"keyword\",\"ignore_above\":256}}}}},\"syslog\":{\"properties\":{\"message\":{\"type\":\"text\",\"fields\":{\"keyword\":{\"type\":\"keyword\",\"ignore_above\":256}}}}},\"sip\":{\"properties\":{\"user_agent\":{\"type\":\"text\",\"fields\":{\"keyword\":{\"type\":\"keyword\",\"ignore_above\":256}}}}}}},\"observations\":{\"properties\":{\"software\":{\"properties\":{\"unparsed_version\":{\"type\":\"text\",\"fields\":{\"keyword\":{\"type\":\"keyword\",\"ignore_above\":256}}}}}}}}}\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "6ad7ba179ad2f904955e668f02203fe21aa746b8", "filename": "tasks/conf/debug-output.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Setup: All OSs) Register NGINX configuration\"\n  command: nginx -T\n  changed_when: false\n  register: nginx_configuration\n\n- name: \"(Setup: All OSs) Print NGINX configuration\"\n  debug:\n    var: nginx_configuration.stdout_lines\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "090f34bbe5425b115079beb9f1740284f2851c9b", "filename": "roles/cfme-ocp-provider/tests/test.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- hosts: localhost\n  roles:\n    - cfme-ocp-provider\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "3ee7ee20017cc592d55bfa824de58c4967a8ce30", "filename": "tasks/create_repo_docker_proxy_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_docker_proxy\n    args: \"{{ _nexus_repos_docker_defaults|combine(item) }}\"\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "60df753fe3f51feb2c3083cd0d2cf25e67a2e454", "filename": "roles/client/tasks/systems/CentOS.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- set_fact:\n    prerequisites:\n      - epel-release\n    configs_prefix: /etc/strongswan/\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "99e7a9504ba8bad047191325d8ae9cec38f73822", "filename": "roles/weave/defaults/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n\n# defaults file for weave\nweave_server_group: weave_servers\nweave_launch_peers: \"\n  {%- set weave_peers = [] -%}\n  {%- for host in groups[weave_server_group] -%}\n    {%- if host != inventory_hostname and host not in weave_peers -%}\n      {% do weave_peers.append(hostvars[host]['ansible_eth0']['ipv4']['address']) %}\n    {%- endif -%}\n  {%- endfor -%}\n  {{ weave_peers|join(' ') }}\n\"\n\nweave_scope_url: https://github.com/weaveworks/scope/releases/download/latest_release/scope\nweave_scope_dest: /usr/local/bin/scope\nweave_scope_enabled: false\n"}, {"commit_sha": "af1b4f6c5adde980e027a8b8f38684b11ffbfa19", "sha": "f280e624760d14fe37e94c36a83dfb4212ddee53", "filename": "meta/main.yml", "repository": "cytopia/ansible-role-cloudformation", "decoded_content": "---\n\ngalaxy_info:\n  author: cytopia\n  company: cytopia\n  license: MIT\n  description: Ansible role to render an arbitrary number of Jinja2 templates into cloudformation files and create any number of stacks.\n  min_ansible_version: 2.4\n  platforms:\n    - name: Amazon\n      versions:\n        - all\n    - name: EL\n      versions:\n        - 5\n        - 6\n    - name: Fedora\n      versions:\n        - 16\n        - 17\n        - 18\n    - name: Ubuntu\n      versions:\n        - precise\n        - quantal\n        - raring\n        - saucy\n  galaxy_tags:\n    - amazon\n    - aws\n    - cfn\n    - cloud\n    - cloudformation\n    - deployment\n    - diff\n    - jinja2\n    - template\ndependencies: []\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "3dd6dfda905cb42569e8ba99aed447c772f4bc4c", "filename": "roles/dokuwiki/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "dokuwiki_url: /wiki\ndokuwiki_install: True\ndokuwiki_enabled: False\ndokuwiki_version: \"dokuwiki-170219b\"\n"}, {"commit_sha": "c0bf4b7577771e6d9cd9f162e7588a1a8f8e302e", "sha": "e2f1c9e1c44e49944dbac9a08952a1504029db57", "filename": "handlers/main.yml", "repository": "geerlingguy/ansible-role-solr", "decoded_content": "---\n- name: restart solr\n  service:\n    name: \"{{ solr_service_name }}\"\n    state: restarted\n    sleep: 5\n  when: solr_restart_handler_enabled\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "a7cc2d7e9704af11b736380cbd5626e4c5db7e53", "filename": "playbooks/local.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- name: Generate the SSH private key\n  local_action: shell echo -e  'n' | ssh-keygen -b 2048 -C {{ SSH_keys.comment }} -t rsa -f {{ SSH_keys.private }} -q -N \"\"\n  args:\n    creates: \"{{ SSH_keys.private }}\"\n\n- name: Generate the SSH public key\n  local_action: shell echo `ssh-keygen -y -f {{ SSH_keys.private }}` {{ SSH_keys.comment }} > {{ SSH_keys.public }}\n  changed_when: false\n\n- name: Change mode for the SSH private key\n  local_action: file path={{ SSH_keys.private }} mode=0600\n\n- name: Ensure the dynamic inventory exists\n  blockinfile:\n    dest: configs/inventory.dynamic\n    marker: \"# {mark} ALGO MANAGED BLOCK\"\n    create: yes\n    block: |\n      [algo:children]\n      {% for group in cloud_providers.keys() %}\n      {{ group }}\n      {% endfor %}\n"}, {"commit_sha": "c33f3410e002f9d8506f0725f56b7d7afa1c5f74", "sha": "79e32d3f2118a064b735b475d52c089ec1b9bd4c", "filename": "meta/tests/local_host.yml", "repository": "jloh/nagios-nrpe-server", "decoded_content": "---\n- hosts: localhost\n  remote_user: root\n  roles:\n    - nagios-nrpe-server\n  vars:\n     nagios_nrpe_command:\n       oracle_tnsping:\n         script: check_oracle_health\n         option: --mode tnsping\n       oracle_connection-time:\n         script: check_oracle_health\n         option: --mode connection-time"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "ede22f89043695a344f0f41547989b4568ff3528", "filename": "roles/calibre/templates/calibre.conf", "repository": "iiab/iiab", "decoded_content": "ProxyPass /calibre  http://localhost:8010\nProxyPassReverse /calibre http://localhost:8010\n"}, {"commit_sha": "f26e6a5f816bc8f8672d0b80aa761ae8c459d30a", "sha": "83ed0a7a7d95ebeb9046e12d311f06d163d98e80", "filename": "meta/main.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "galaxy_info:\n  author: Bjorn Oscarsson\n  description: \"Installs and configures Docker Community Edition (CE)\"\n  min_ansible_version: 2.3\n  license: MIT\n  platforms:\n  - name: Fedora\n    versions:\n      - 24\n      - 25\n      - 26\n\n  - name: EL\n    versions:\n      - 7\n\n  - name: Debian\n    versions:\n      - jessie\n      - stretch\n\n  - name: Ubuntu\n    versions:\n      - trusty\n      - xenial\n\n  galaxy_tags:\n    - docker\n\ndependencies: []\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "c54cc3058d71627fed413816d69303b6398c0f81", "filename": "roles/config-quay-enterprise/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Restart quay service\n  systemd:\n    name: \"{{ quay_service }}\"\n    enabled: yes\n    state: restarted\n    daemon_reload: yes\n\n- name: restart firewalld\n  service:\n    name: firewalld\n    state: restarted\n\n- name: restart iptables\n  service:\n    name: iptables\n    state: restarted\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "9ac901387f0388aecbfed9be8eb230eb56fd4e84", "filename": "roles/1-prep/templates/rpmfusion-free-updates.repo", "repository": "iiab/iiab", "decoded_content": "[iiab-rpmfusion-free-updates]\nname=iiab-RPM Fusion for Fedora $releasever - Free - Updates\n#baseurl=http://download1.rpmfusion.org/free/fedora/updates/$releasever/$basearch/\nmirrorlist=http://mirrors.rpmfusion.org/mirrorlist?repo=free-fedora-updates-released-$releasever&arch=$basearch\nenabled=0\ngpgcheck=0\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-rpmfusion-free-fedora-$releasever\n\n[iiab-rpmfusion-free-updates-debuginfo]\nname=iiab-RPM Fusion for Fedora $releasever - Free - Updates Debug\n#baseurl=http://download1.rpmfusion.org/free/fedora/updates/$releasever/$basearch/debug/\nmirrorlist=http://mirrors.rpmfusion.org/mirrorlist?repo=free-fedora-updates-released-debug-$releasever&arch=$basearch\nenabled=0\ngpgcheck=1\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-rpmfusion-free-fedora-$releasever\n\n[iiab-rpmfusion-free-updates-source]\nname=iiab-RPM Fusion for Fedora $releasever - Free - Updates Source\n#baseurl=http://download1.rpmfusion.org/free/fedora/updates/$releasever/SRPMS/\nmirrorlist=http://mirrors.rpmfusion.org/mirrorlist?repo=free-fedora-updates-released-source-$releasever&arch=$basearch\nenabled=0\ngpgcheck=1\ngpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-rpmfusion-free-fedora-$releasever\n\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "5472ec2172089f836ed958da0006c9065ee99c28", "filename": "tasks/Linux/install/Debian_adoptopenjdk.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Add apt-key for AdoptOpenJDK\n  apt_key:\n    url: https://adoptopenjdk.jfrog.io/adoptopenjdk/api/gpg/key/public\n    state: present\n  register: package_install\n  until: package_install is succeeded\n\n- name: Add repository for AdoptOpenJDK\n  apt_repository:\n    repo: 'deb https://adoptopenjdk.jfrog.io/adoptopenjdk/deb/ bionic main'\n    filename: adoptopenjdk\n    state: present\n    codename: trusty\n    update_cache: true\n\n- name: Install java packages\n  apt:\n    deb: '{{ java_artifact | default(omit) }}'\n    name: '{{ (jdk_package if transport == \"repositories\") | default(omit) }}'\n    state: present\n    update_cache: true\n    cache_valid_time: 3600\n  register: package_install\n  until: package_install is succeeded\n"}, {"commit_sha": "9662c15ce2e4260fac5cc2bfdf5aaaaf0a2191dd", "sha": "8efbf4d1f555516a2fe2ecbcf7287f7a49b2bfb8", "filename": "tasks/section_08_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n#  - name: 8.2 Configure rsyslog\n#  The rsyslog software is recommended as a replacement for the default syslogd daemon and\n#  provides improvements over syslogd, such as connection-oriented (i.e. TCP) transmission\n#  of logs, the option to log to database formats, and the encryption of log data en route to a\n#  central logging server.\n#  tags:\n#    - section8\n#    - section8.2\n\n\n  - name: 8.2.1 Install the rsyslog package (Scored)\n    apt: name=rsyslog state=present\n    tags:\n      - section8\n      - section8.2\n      - section8.2.1\n\n  - name: 8.2.2 Ensure the rsyslog Service is activated (Scored)\n    command: grep 'start on filesystem' /etc/rsyslog.conf\n    register: startonfilesystem\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.5.2 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line='start on filesystem'\n       insertafter=EOF\n       state=present\n    when: startonfilesystem.rc == 1\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.3 Configure /etc/rsyslog.conf (Not Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line=\"{{ item }}\"\n       insertafter=EOF\n    with_items:\n      - '*.emerg :omusrmsg:*'\n      - 'mail.* -/var/log/mail'\n      - 'mail.info -/var/log/mail.info'\n      - 'mail.warning -/var/log/mail.warn'\n      - 'mail.err /var/log/mail.err'\n      - 'news.crit -/var/log/news/news.crit'\n      - 'news.err -/var/log/news/news.err'\n      - 'news.notice -/var/log/news/news.notice'\n      - '*.=warning;*.=err -/var/log/warn'\n      - '*.crit /var/log/warn'\n      - '*.*;mail.none;news.none -/var/log/messages'\n      - 'local0,local1.* -/var/log/localmessages'\n      - 'local2,local3.* -/var/log/localmessages'\n      - 'local4,local5.* -/var/log/localmessages'\n      - 'local6,local7.* -/var/log/localmessages'\n    changed_when: False\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.3\n  \n  - name: 8.2.4.1 Create and Set Permissions on rsyslog Log Files (Scored)\n    shell: awk '{ print $NF }' /etc/rsyslog.d/* /etc/rsyslog.conf | grep /var/log | sed 's/^-//' | sed 's/)$//' \n    register: result\n    changed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.4.2 Create and Set Permissions on rsyslog Log Files (Scored)\n    shell: 'mkdir -p -- \"$(dirname -- {{ item }})\"; touch -- {{ item }}' \n    with_items: result.stdout_lines          \n    changed_when: False\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.4.3 Create and Set Permissions on rsyslog Log Files (Scored)\n    file: >\n        path={{item}}  \n        owner=root \n        group=root \n        mode=\"og-rwx\" \n    with_items: result.stdout_lines\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.5.1 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    command: grep \"^*.*[^I][^I]*@\" /etc/rsyslog.conf\n    register: remoteloghost \n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.5.2 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line=\"*.* @@{{Remote_Logs_Host_Address}}\"\n       insertafter=EOF\n       state=present\n    when: remoteloghost.rc == 1\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.6.1 Accept Remote rsyslog Messages Only on Designated Log Hosts (Not Scored)\n    command: grep '^$ModLoad imtcp' /etc/rsyslog.conf\n    register: moadloadpresent\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.6\n\n  - name: 8.2.6.2 Accept Remote rsyslog Messages Only on Designated Log Hosts (Not Scored)\n    lineinfile: >\n        dest=/etc/rsyslog.conf\n        regexp='^#({{ item }})'\n        line='{{ item }}'\n        state=present\n    with_items:\n        - '$ModLoad imtcp'\n        - '$InputTCPServerRun 514'\n    when: moadloadpresent.rc == 1\n    changed_when: False\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.6\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "c3cc8a3eed319d5429c96a1619f0cb1cb5bf6fd5", "filename": "playbooks/osp/manage-user-network.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# See the roles README for detailed info on inventory requirements.\n# https://github.com/redhat-cop/infra-ansible/blob/master/roles/osp/admin-network/README.md\n\n- hosts: localhost\n  roles:\n  - osp/admin-network\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "e9597beb9024e155956329dc52f4c3977e9a4853", "filename": "roles/dns/manage-dns-zones-bind/tasks/process-views.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Ensure the final view directory exists\n  file:\n    path: \"{{ dns_zone_temp_config_dir }}/view\"\n    state: directory\n\n- name: Generate a consistent serial number to be used across all zones\n  set_fact:\n    zone_serial_number: \"{{ ansible_date_time.epoch }}\"\n    common_recursion: dns_data.named_global_config.recursion | default(default_recursion) \n  run_once: true\n  delegate_to: \"{{ ansible_play_hosts | first }}\"\n\n- include_tasks: process-zones.yml\n  with_items:\n    - \"{{ dns_data.views }}\"\n  loop_control:\n    loop_var: \"view\"\n\n- name: Assemble the final view configuration\n  assemble:\n    src: \"{{ dns_zone_temp_config_dir }}/view\"\n    dest: \"/etc/named/named.conf.view\"\n    owner: \"{{ bind_user }}\"\n    group: \"{{ bind_group }}\"\n    mode: 0660\n  notify: restart named\n\n- name: Setup ACLs\n  vars:\n    named_views: \"{{ dns_data.views }}\"\n  template:\n    src: acl.j2\n    dest: /etc/named/named.conf.acl\n    owner: \"{{ bind_user }}\"\n    group: \"{{ bind_group }}\"\n    mode: 0660\n  notify: restart named\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "26c01c2e65b7ccbfde25a2004c811bc732b27bc8", "filename": "tasks/bug-tweaks/lvm-thinpool.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "- name: Ensure lvm2 is installed\n  become: true\n  package:\n    name: lvm2\n    state: present\n  register: _pkg_result\n  until: _pkg_result is succeeded\n\n- name: Create LVM volume group\n  become: true\n  lvg:\n    pvs: '{{ pool.physical_volumes }}'\n    state: present\n    vg: '{{ pool.volume_group }}'\n  when: pool.physical_volumes|default(None)\n\n- name: Check if data volume exists\n  become: true\n  stat:\n    path: '/dev/mapper/{{ pool.volume_group }}-{{ pool.name }}'\n  ignore_errors: true\n  register: _volume\n\n- name: Create data volume\n  become: true\n  lvol:\n    lv: '{{ pool.name }}'\n    size: '{{ pool.data_size }}'\n    vg: '{{ pool.volume_group }}'\n  register: _datavolume_created\n  when: not _volume.stat.exists\n\n- name: Create meta data volume\n  become: true\n  lvol:\n    lv: '{{ pool.name }}meta'\n    size: '{{ pool.metadata_size }}'\n    vg: '{{ pool.volume_group }}'\n  when: _datavolume_created is changed\n\n- name: Convert data volume to thinpool\n  become: true\n  shell:\n    lvconvert\n        -y\n        --zero n\n        -c 512K\n        --thinpool \"{{ pool.volume_group }}/{{ pool.name }}\"\n        --poolmetadata \"{{ pool.volume_group }}/{{ pool.name }}meta\"\n  when: _datavolume_created is changed\n  tags:\n    - skip_ansible_lint"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "50414c7dd0d3bbfa728b595422bc8a82d564c1d9", "filename": "roles/dockerbench/tasks/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# tasks file for docker bench\n- name: checkout docker bench git repo\n  git:\n    repo: \"{{ dockerbench_repo }}\"\n    dest: \"{{ dockerbench_dest }}\"\n    accept_hostkey: true\n    version: \"{{ dockerbench_version }}\"\n  when: dockerbench_run_test\n\n- name: install docker bench threshold script\n  sudo: yes\n  template:\n    src: docker-bench-warn.sh.j2\n    dest: /usr/local/bin/docker-bench-warn.sh\n    mode: 0755\n  when: dockerbench_run_test\n\n- name: run docker bench script\n  command: /usr/local/bin/docker-bench-warn.sh\n  sudo: yes\n  args:\n    chdir: \"{{ dockerbench_dest }}\"\n  when: dockerbench_run_test\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "c5afe59d247c47d94004154d2278637b237cbf92", "filename": "tasks/postinstall.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Reset internal variables for additional packages to be installed\n  set_fact:\n    _docker_additional_packages_os: []\n    _docker_additional_packages_pip: []\n    _docker_python_system: false\n\n- name: Do best effort detection and set fact to indicate system Python environment is used\n  set_fact:\n    _docker_python_system: true\n  when: ansible_python.executable | regex_search('^/bin') or ansible_python.executable | regex_search('^/usr/bin')\n\n- name: Set facts to install Docker SDK for Python\n  set_fact:\n    _docker_additional_packages_pip: \"{{ _docker_additional_packages_pip + \\\n      docker_predefined_packages_pip[_docker_os_dist]['sdk'] }}\"\n  when:\n    - docker_sdk\n\n- name: Set facts to install Docker Compose\n  set_fact:\n    _docker_additional_packages_pip: \"{{ _docker_additional_packages_pip + \\\n      docker_predefined_packages_pip[_docker_os_dist]['compose'] }}\"\n  when:\n    - docker_compose and not docker_compose_no_pip\n\n- name: Set facts to install Docker Stack dependencies ('docker_stack')\n  set_fact:\n    _docker_additional_packages_pip: \"{{ _docker_additional_packages_pip + \\\n      docker_predefined_packages_pip[_docker_os_dist]['stack'] }}\"\n  when:\n    - docker_stack\n\n- name: Set facts with additional package to be installed\n  set_fact:\n    _docker_additional_packages_pip: \"{{ _docker_additional_packages_pip + docker_additional_packages_pip }}\"\n    _docker_additional_packages_os: \"{{ _docker_additional_packages_os + docker_additional_packages_os }}\"\n\n- name: Determine if pip exists in path\n  become: true\n  shell: type pip\n  register: _docker_pip_cmd\n  changed_when: false\n  failed_when: false\n  check_mode: no\n  tags:\n    - skip_ansible_lint\n  when:\n    - _docker_additional_packages_pip | length > 0\n\n- name: Set fact to install Python PiP\n  set_fact:\n    _docker_additional_packages_os: \"{{ _docker_additional_packages_os + [docker_pip_package] }}\"\n  when:\n    - _docker_additional_packages_pip | length > 0\n    - _docker_pip_cmd.rc != 0\n\n- name: Ensure python-pip-whl is present (Debian 8)\n  set_fact:\n    _docker_additional_packages_os: \"{{ _docker_additional_packages_os + ['python-pip-whl'] }}\"\n  when:\n    - _docker_additional_packages_pip | length > 0\n    - _docker_pip_cmd.rc != 0\n    - _docker_os_dist == \"Debian\"\n    - _docker_os_dist_major_version == '8'\n\n- name: Ensure EPEL release repository is installed\n  become: true\n  package:\n    name: \"epel-release\"\n    state: present\n  register: _pkg_result\n  until: _pkg_result is succeeded\n  when:\n    - _docker_os_dist == \"CentOS\"\n    - _docker_additional_packages_os | length > 0\n\n- name: Install additional packages (OS package manager)\n  become: true\n  package:\n    name: \"{{ item }}\"\n    state: present\n  with_items:\n    - \"{{ _docker_additional_packages_os }}\"\n  register: _pkg_result\n  until: _pkg_result is succeeded\n  when: _docker_additional_packages_os | length > 0\n\n- name: Upgrade PiP\n  become: \"{{ docker_pip_sudo | bool }}\"\n  pip:\n    name: pip\n    state: forcereinstall\n  register: _pkg_result\n  until: _pkg_result is succeeded\n  when: docker_pip_upgrade\n\n- name: Install additional packages (PiP)\n  become: \"{{ docker_pip_sudo | bool }}\"\n  pip:\n    name: \"{{ item }}\"\n    state: present\n    extra_args: \"{{ docker_pip_extra_args }}\"\n  with_items:\n    - \"{{ _docker_additional_packages_pip }}\"\n  register: _pkg_result\n  until: _pkg_result is succeeded\n  when: _docker_additional_packages_pip | length > 0\n  environment:\n    PYTHONWARNINGS: ignore\n\n# Not using github_release:  https://github.com/ansible/ansible/issues/45391\n- name: Get latest release of docker-compose\n  uri:\n    url: https://api.github.com/repos/docker/compose/releases/latest\n    body_format: json\n  register: _github_docker_compose\n  until: _github_docker_compose.status == 200\n  retries: 10\n  check_mode: no\n  when:\n    - docker_compose\n\n- name: Set common facts related to docker-compose\n  set_fact:\n    _docker_compose_shasum_url: \"https://github.com/docker/compose/releases/download/\\\n      {{ _github_docker_compose.json.tag_name }}/docker-compose-{{ ansible_system }}-{{ ansible_architecture }}.sha256\"\n    _docker_compose_url: \"https://github.com/docker/compose/releases/download/\\\n      {{ _github_docker_compose.json.tag_name }}/docker-compose-{{ ansible_system }}-{{ ansible_architecture }}\"\n  when:\n    - docker_compose\n\n- name: Fetch docker-compose SHA265 sum file\n  get_url:\n    url: \"{{ _docker_compose_shasum_url }}\"\n    dest: \"/tmp/ansible.docker-compose-sha256\"\n  register: _github_docker_compose_shasum_file\n  changed_when: false\n  until: _github_docker_compose_shasum_file.status_code == 200\n  retries: 10\n  check_mode: no\n  when:\n    - docker_compose\n\n- name: Dump SHA256 file contents to variable\n  command: cat /tmp/ansible.docker-compose-sha256\n  register: _github_docker_compose_shasum\n  changed_when: false\n  check_mode: no\n  when:\n    - docker_compose\n\n- name: Remove temporary file for SHA256 sum\n  file:\n    path: \"/tmp/ansible.docker-compose-sha256\"\n    state: absent\n  changed_when: false\n  check_mode: no\n  when:\n    - docker_compose\n\n- name: Set SHA256 facts related to docker-compose\n  set_fact:\n    _docker_compose_checksum: \"sha256:{{ _github_docker_compose_shasum.stdout | \\\n      regex_replace('^([0-9a-zA-Z]*)[\\\\s\\\\t]+.+', '\\\\1') }}\"\n  when:\n    - docker_compose\n\n# Use when moving to Ansible 2.7 as minimum version\n# - name: Set SHA256 facts related to docker-compose (Ansible >= 2.7)\n#   set_fact:\n#     _docker_compose_checksum: \"sha256:https://github.com/docker/compose/releases/download/\\\n#       {{ _github_docker_compose.json.tag_name }}/\\\n#       docker-compose-{{ ansible_system }}-{{ ansible_architecture }}.sha256\"\n#   when: ansible_version.full is version_compare('2.7', '>=')\n\n- name: Stat /usr/bin/docker-compose\n  stat:\n    path: /usr/bin/docker-compose\n  register: _docker_compose_file\n  check_mode: no\n\n# Official installation of docker-compose (Linux): https://docs.docker.com/compose/install/#install-compose\n- name: Install docker-compose\n  block:\n    - name: Install docker-compose (Linux)\n      become: true\n      get_url:\n        url: \"{{ _docker_compose_url }}\"\n        checksum: \"{{ _docker_compose_checksum }}\"\n        dest: /usr/local/bin/docker-compose\n        mode: 0755\n\n    - name: Create symlink for docker-compose to work with sudo in some distributions\n      become: true\n      file:\n        src: /usr/local/bin/docker-compose\n        dest: /usr/bin/docker-compose\n        state: link\n  when:\n    - docker_compose\n    - not _docker_compose_file.stat.exists\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "4104060bd8683bb09bab354be131ac92334938f1", "filename": "playbooks/provision-dns-server/subscribe-rhel.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Subscribe RHEL based instances\" \n  vars:\n    rhsm_username: \"{{ hostvars['localhost'].rhsm_username|default(omit) }}\"\n    rhsm_password: \"{{ hostvars['localhost'].rhsm_password|default(omit) }}\"\n  include_role: \n    name: rhsm\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "692e329819de9126b0e08574bf5121a9fdc12b14", "filename": "roles/config-timezone/test/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: node\n  roles:\n  - role: config-timezone\n\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "095dbd71016c17a2cf14f191a754b267e244b0a9", "filename": "playbooks/provision-dns-server/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# Please see `inventory/dns-server` for an example inventory to be used with \n# this playbook to provision a dns-server  \n\n- import_playbook: ../prep.yml\n  when:\n  - rhsm_register|default(False)\n\n- import_playbook: ../osp/manage-user-network.yml\n  when:\n  - hosting_infrastructure == 'openstack'\n\n- import_playbook: ../osp/provision-osp-instance.yml\n  when:\n  - hosting_infrastructure == 'openstack'\n\n- hosts: dns-server\n  tasks:\n  - import_tasks: subscribe-rhel.yml\n    when:\n    - rhsm_register|default(False)\n\n- hosts: dns-server\n  roles: \n  - role: update-host\n\n- import_playbook: configure-dns-server.yml\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "71aaa7661e477d920ab6df79e0d4883dd572d1dc", "filename": "roles/mariadb/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Add MariaDB MySQL apt-key\n  apt_key:\n    url: \"http://keyserver.ubuntu.com/pks/lookup?op=get&fingerprint=on&search={{ keyserver_fingerprint }}\"\n    state: present\n\n- name: Add MariaDB MySQL deb and deb-src\n  apt_repository:\n    repo: \"{{ item }}\"\n    state: present\n  with_items:\n  - \"deb http://{{ mirror }}/mariadb/repo/{{ version }}/ubuntu {{ mariadb_dist | default(ansible_distribution_release) }} main\"\n  - \"deb-src http://{{ mirror }}/mariadb/repo/{{ version }}/ubuntu {{ mariadb_dist | default(ansible_distribution_release) }} main\"\n\n- name: Install MariaDB MySQL server\n  apt:\n    name: mariadb-server\n    state: present\n\n- name: Disable MariaDB binary logging\n  template:\n    src: disable-binary-logging.cnf\n    dest: /etc/mysql/conf.d\n    owner: root\n    group: root\n  when: binary_logging_disabled\n\n- name: Restart MariaDB MySQL Server\n  service:\n    name: mysql\n    state: restarted\n    enabled: true\n\n- name: Set root user password\n  mysql_user:\n    name: root\n    host: \"{{ item }}\"\n    password: \"{{ mysql_root_password }}\"\n    check_implicit_admin: yes\n    state: present\n  with_items:\n    - \"{{ inventory_hostname }}\"\n    - 127.0.0.1\n    - ::1\n    - localhost\n\n- name: Copy .my.cnf file with root password credentials.\n  template:\n    src: my.cnf.j2\n    dest: ~/.my.cnf\n    owner: root\n    group: root\n    mode: 0600\n\n- name: Delete anonymous MySQL server users\n  mysql_user:\n    user: \"\"\n    host: \"{{ item }}\"\n    state: absent\n  with_items:\n    - localhost\n    - \"{{ inventory_hostname }}\"\n    - \"{{ ansible_hostname }}\"\n\n- name: Remove the test database\n  mysql_db:\n    name: test\n    state: absent\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "55a5384ce2a71df8faa8d659b6d0d4894ab97577", "filename": "tasks/bug-tweaks.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "- name: Configuration to avoid 'Device or resource busy' (CentOS/RedHat)\n  include_tasks: bug-tweaks/bug-centos7-resource-busy.yml\n  when:\n    - _docker_os_dist == \"CentOS\" or _docker_os_dist == \"RedHat\"\n    - ansible_kernel is version_compare('4', '<')\n\n- name: Best effort handling to directlvm for Debian 8 to get uniform behavior across distributions\n  include_tasks: bug-tweaks/tweak-debian8-directlvm.yml\n  when:\n    - _docker_os_dist == \"Debian\"\n    - _docker_os_dist_major_version == '8'\n    - docker_daemon_config['storage-opts'] is defined\n    - docker_daemon_config['storage-opts'] | select('match', '^dm.directlvm_device.+')\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "68874fd6bb8e1792cd2f40d94bc86a48c01810d2", "filename": "tasks/nexus_purge.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- name: Make sure nexus is stopped\n  debug:\n    msg: \"trigger nexus stop\"\n  changed_when: true\n  notify:\n    - nexus-service-stop\n\n- meta: flush_handlers\n\n- name: get target path of current installed nexus version\n  command: 'readlink {{ nexus_installation_dir }}/nexus-latest'\n  register: nexus_readlink_latest_call\n  failed_when: false\n  changed_when: false\n  check_mode: no\n\n- name: \"Purge Nexus\"\n  file:\n    path: \"{{ item }}\"\n    state: absent\n  with_items:\n    - \"{{ nexus_data_dir }}\"\n    - \"{{ nexus_readlink_latest_call.stdout | default(omit) }}\"\n    - \"{{ nexus_restore_log }}\"\n    - \"{{ nexus_installation_dir }}/nexus-latest\"\n    # - \"{{ nexus_backup_dir }}\" # Optional\n\n- name: \"remove nexus package if present\"\n  package:\n    name: nexus\n    state: absent\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "1dae13dd4d0ae418f499a80349cc3fdee1742dd6", "filename": "roles/ansible/tower/manage-projects/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Set default values\"\n  set_fact:\n    processed_projects: []\n    existing_projects_output: []\n\n# Utilize the `rest_get` library routine to ensure REST pagination is handled\n- name: \"Get the existing organizations\"\n  rest_get:\n    host_url: \"{{ tower_url }}\"\n    api_uri: \"/api/v2/organizations/\"\n    rest_user: \"{{ tower_admin_username }}\"\n    rest_password: \"{{ tower_admin_password }}\"\n  register: existing_organizations_output\n\n# Utilize the `rest_get` library routine to ensure REST pagination is handled\n- name: \"Get the existing projects\"\n  rest_get:\n    host_url: \"{{ tower_url }}\"\n    api_uri: \"/api/v2/projects/\"\n    rest_user: \"{{ tower_admin_username }}\"\n    rest_password: \"{{ tower_admin_password }}\"\n  register: existing_projects_output\n\n- name: \"Process the inventory projects\"\n  include_tasks: process-project.yml\n  with_items:\n  - \"{{ ansible_tower_projects }}\"\n  loop_control:\n    loop_var: project\n\n- name: \"Elminate the projects that should not be present\"\n  uri:\n    url: https://localhost/api/v2/projects/{{ item.id }}/\n    method: DELETE\n    user: admin\n    password: \"{{ tower_admin_password }}\"\n    validate_certs: no\n    status_code: 200,204\n  with_items:\n  - \"{{ existing_projects_output.rest_output | get_remaining_items(processed_projects, 'name', 'name')}}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a1062cfd476d200ae5d8396572e7e736273c81af", "filename": "roles/scm/github.com/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n# defaults file for github\ngithub_api_base: https://api.github.com/orgs/{{ github_org_name }}\ngithub_api_proj: \"{{ github_api_base }}/projects\"\ngithub_api_teams: \"{{ github_api_base }}/teams\"\ngithub_api_repos: \"{{ github_api_base }}/repos\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "fa70295db7f5bc41de43153228296009d8d9cd9a", "filename": "roles/osm/templates/osm.repo", "repository": "iiab/iiab", "decoded_content": "[osm]\nname=Internet-in-a-Box\nbaseurl=http://downloads.internet-in-a-box.org/fedora/18\nenabled=1\ngpgcheck=0\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "9586be5e7f55b929dd6ddb96dfd4b859042afb11", "filename": "playbooks/container-registry/README.md", "repository": "redhat-cop/infra-ansible", "decoded_content": "# Quay Enterprise\n\nThis playbook provides support for deploying [Quay Enterprise](https://coreos.com/quay-enterprise/) and its required dependencies.\n\n## Components\n\nThe following sets of resources are provisioned by this playbook:\n\n* [Redis](https://redis.io/)\n* Database Persistence ([PostgreSQL](https://www.postgresql.org/) or [MySQL](https://www.mysql.com/))\n* Load Balancer ([HAProxy](http://www.haproxy.org/))\n* [Quay Enterprise](https://coreos.com/quay-enterprise/)\n* [Clair](https://coreos.com/clair)\n\n## Inventory Options\n\nThe deployment of Quay Enterprise is driven by the inventory found in the [quay-enterprise](../../inventory/quay-enterprise) folder.\n\nSeveral host groups are available and listed below:\n\n```\n[quay_enterprise]\n\n[db]\n\n[redis]\n\n[clair]\n\n[lb]\n\n[quay_builder]\n```\n\nThe following is a list of the most commonly utilized inventory variables used to drive the execution (not comprehensive):\n\n| variable | info |\n|---|---|\n|quay_registry_auth|Base64 encoded value to access a secured registry for Quay|\n|database_type|Database type (`postgresql` or `mysql`)|\n|quay_database_username|Quay database username|\n|quay_database_password|Quay database poassword|\n|quay_database_name|Quay database name|\n|docker_install|Boolean whether to install and configure docker|\n|quay_hostname|Hostname to configure the optionally generated SSL certificate|\n|quay_superuser_username|Quay superuser username|\n|quay_superuser_password|Quay superuser password|\n|quay_superuser_email|Quay superuser email|\n|quay_hostname|Custom hostname for Load Balancing and SSL Certificates| \n|quay_superuser_username|Superuser username|\n|quay_superuser_password|Superuser password|\n|quay_superuser_username|Superuser email|\n\nAdditional variables can be utilized by inspecting the variables provided by each role.\n\n## Playbook Execution\n\nExecute the following command to provision the Quay ecosystem:\n\n```\n$ ansible-playbook -i ../../inventory/quay-enterprise  quay-enterprise.yml\n```\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "6a932559747bf4e3ff049cd3fc755521d8817aa3", "filename": "tasks/create_task_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_task\n    args: \"{{ item }}\""}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "380888cd3dfcf724e6c20995620883a8be3fc759", "filename": "roles/scm/github.com/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: 'github.com cleanup temp'\n  delegate_to: localhost\n  file:\n    path: '{{ tmp_dir.path }}'\n    state: absent"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "45efc809883d92ff7d7666d1bd37afd68688aedf", "filename": "roles/wordpress/files/wp-keys.php.BAK", "repository": "iiab/iiab", "decoded_content": "<?php\ndefine('AUTH_KEY',         'L0f`R#=aNZqApmM9PB. N}|5Ndk6!@Y2|iH+<#6-<nf0ZwI@UN1-4?Ui|>KjZ?z?');\ndefine('SECURE_AUTH_KEY',  'a*m|a.6+mJItP_-A{hIvuE<zoGK*0F;$5 q(Z%C< ^k%-BbM|E/Y,zf;X++?W;Hs');\ndefine('LOGGED_IN_KEY',    'P%<)zvsAy-`I 5k+6|Ixa%xN#$-mS-P#k+b2`8eQh&B65e>L0QX:j32-T2qM<b/I');\ndefine('NONCE_KEY',        'b)$6#DH j~iD+X~jLC!~7H>$Y5-42j^,O]0Iw2}BMI{%n+v?9J|QguMZqBktspP;');\ndefine('AUTH_SALT',        'U+](-b-),e9S0=-/d:xNO{3Dp47ZE6G|dg[)AjlxQn]!)H~ni|<$:y>}Od@,i&7E');\ndefine('SECURE_AUTH_SALT', '}I%X$L-Pr89=2=)KQ~05#7V%gg;g!;&.O[PIx4QBKq,uF.I35ymf|~iAX|qX+/rm');\ndefine('LOGGED_IN_SALT',   'Qwr|f4|^e+~&0e 31?(dO$P96BqAAw{8RdJ<R7QcOy18NY`-Tt5gnl*s<A8p;u.v');\ndefine('NONCE_SALT',       'f638d_sIUyp9{h<Eq[,q 9nP>0*pd_ 3+7r[LO$.feEa>z^*M+cs$uF@1J6CWkk.');\n?>\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "5065d0245e493cf33536019e1d22412f92bcad95", "filename": "playbooks/roles/bb0-openstack/tasks/provisioning-prepare-bastion.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "---\n- name: \"Wait for bastion {{ ansible_host }}:22 (SSH)\"\n  connection: local\n  wait_for:\n    port: 22\n    host: \"{{ ansible_host }}\"\n    search_regex: OpenSSH\n    delay: 10\n\n- name: Copy ssh key to bastion\n  connection: ssh\n  copy:\n    src: \"{{ playbook_dir }}/id_rsa\"\n    dest: ~/.ssh/id_rsa\n    mode: 0600\n\n- name: Copy ssh pub to bastion\n  connection: ssh\n  copy:\n    src: \"{{ playbook_dir }}/id_rsa.pub\"\n    dest: ~/.ssh/id_rsa.pub\n    mode: 0600\n\n- name: Create ~/stc bastion\n  connection: ssh\n  file:\n    path: ~/stc/\n    state: directory\n    mode: 0755\n\n- name: Checkout STC on bastion\n  connection: ssh\n  unarchive:\n    src: https://github.com/RedHat-EMEA-SSA-Team/stc/archive/master.tar.gz\n    dest: ~/stc/\n    extra_opts: [--strip-components=1]\n    remote_src: yes\n\n# - debug: var=hostvars\n\n- name: Create STC env.yml\n  connection: ssh\n  template:\n    src: env.yml.j2\n    dest: ~/stc/env.yml\n    mode: 0660\n\n- name: Create STC secrets.yml\n  connection: ssh\n  template:\n    src: secrets.yml.j2\n    dest: ~/stc/secrets.yml\n    mode: 0660\n\n- name: Register and subscribe.\n  connection: ssh\n  become: true\n  redhat_subscription:\n    state: present\n    username: \"{{ lookup('env','STC_RHN_USERNAME') }}\"\n    password: \"{{ lookup('env','STC_RHN_PASSWORD') }}\"\n    pool_ids:\n      - \"{{ lookup('env','STC_SUBSCRIPTION_POOL_ID') }}\"\n\n- name: Disable all RHSM repositories\n  connection: ssh\n  become: true\n  rhsm_repository:\n    name: '*'\n    state: disabled\n\n- name: Disable all repositories except rhel-7-server-rpms\n  connection: ssh\n  become: true\n  rhsm_repository:\n    name: \"{{ item }}\"\n    state: enabled\n  with_items:\n    - \"rhel-7-server-rpms\"\n    - \"rhel-7-server-extras-rpms\"\n    - \"rhel-7-server-ose-3.11-rpms\"\n    - \"rhel-7-server-ansible-2.6-rpms\"\n\n- name: Install necessary packages\n  connection: ssh\n  become: true\n  yum:\n    name:\n      - git\n      - ansible\n      - tmux\n      - nc\n      - screen\n    state: present"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "1a20ef5ee5b6db65fb2f935fe650f8e24a6a86d8", "filename": "roles/manage-confluence-space/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- import_tasks: prepare_confluence_vars.yml\n\n- import_tasks: prepare_confluence_source.yml\n\n- import_tasks: create_confluence_space.yml\n\n- include_tasks: copy_confluence_content.yml\n  with_items: '{{ processed_contents.stdout }}'\n  loop_control:\n    loop_var: confluence_space_content\n\n- include_tasks: copy_confluence_attachments.yml\n  with_dict: '{{ id_mapping }}'\n  loop_control:\n    loop_var: confluence_content_ids\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "ab98db635ab10eceb7c0cda79dccd550ed90392e", "filename": "roles/security/handlers/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: restart ssh\n  service: name=\"{{ ssh_service_name|default('ssh') }}\" state=restarted\n\n- name: flush routing cache\n  shell: echo 1 > /proc/sys/net/ipv4/route/flush\n"}, {"commit_sha": "b7c6bfe0369646ca69beeb3dfe07e8218d61c940", "sha": "90fd1ea28ce733d1a7907dc2b9d264543805bc93", "filename": "meta/main.yml", "repository": "dev-sec/ansible-os-hardening", "decoded_content": "---\ngalaxy_info:\n  author: \"Sebastian Gumprich\"\n  description: 'This Ansible role provides numerous security-related configurations, providing all-round base protection.'\n  company: Hardening Framework Team\n  license: Apache License 2.0\n  min_ansible_version: '2.4.2'\n  platforms:\n    - name: EL\n      versions:\n        - 6\n        - 7\n    - name: Ubuntu\n      versions:\n        - precise\n        - trusty\n        - xenial\n    - name: Debian\n      versions:\n        - wheezy\n        - jessie\n    - name: Amazon\n  galaxy_tags:\n    - system\n    - security\n    - hardening\ndependencies: []\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "9b3caa7dae2f6e4cb8277337bfee39a12337aebb", "filename": "roles/osp/admin-volume/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Manage Volumes\n  os_volume:\n    cloud: \"{{ item.cloud | default(osp_default_cloud) | default(omit) }}\"\n    state: \"{{ item.state | default(osp_resource_state) | default('present') }}\"\n    name: \"{{ item.name }}\"\n    size: \"{{ item.size | default(omit) }}\"\n    display_name: \"{{ item.display_name | default(omit) }}\"\n    display_description: \"{{ item.display_description | default(omit) }}\"\n  register: os_volumes\n  with_items:\n  - \"{{ osp_volumes | default([]) }}\"\n"}, {"commit_sha": "045ff4bb9f4720739632aac2951fbf2798a99c8c", "sha": "1262d3fcdc28c5e10690dcb12de0dfb0b4ea97be", "filename": "roles/common/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- name: Gather Facts\n  setup:\n  tags:\n    - always\n\n- name: Install software updates\n  apt: update_cache=yes upgrade=dist\n  tags:\n    - cloud\n\n- name: Check if reboot is required\n  shell: >\n    if [[ -e /var/run/reboot-required ]]; then echo \"required\"; else echo \"no\"; fi\n  args:\n    executable: /bin/bash\n  register: reboot_required\n  tags:\n    - cloud\n\n- name: Reboot\n  shell: sleep 2 && shutdown -r now \"Ansible updates triggered\"\n  async: 1\n  poll: 0\n  when: reboot_required is defined and reboot_required.stdout == 'required'\n  ignore_errors: true\n  tags:\n    - cloud\n\n- name: Wait until SSH becomes ready...\n  local_action:\n    module: wait_for\n    port: 22\n    host: \"{{ inventory_hostname }}\"\n    search_regex: OpenSSH\n    delay: 10\n    timeout: 320\n  when: reboot_required is defined and reboot_required.stdout == 'required'\n  become: false\n  tags:\n    - cloud\n\n- name: Disable MOTD on login and SSHD\n  replace: dest=\"{{ item.file }}\" regexp=\"{{ item.regexp }}\" replace=\"{{ item.line }}\"\n  with_items:\n    - { regexp: '^session.*optional.*pam_motd.so.*', line: '# MOTD DISABLED', file: '/etc/pam.d/login' }\n    - { regexp: '^session.*optional.*pam_motd.so.*', line: '# MOTD DISABLED', file: '/etc/pam.d/sshd' }\n  tags:\n    - cloud\n\n- name: Install tools\n  apt: name=\"{{ item }}\" state=latest\n  with_items:\n    - git\n    - screen\n    - apparmor-utils\n    - uuid-runtime\n    - coreutils\n    - sendmail\n    - iptables-persistent\n    - cgroup-tools\n    - openssl\n  tags:\n    - always\n\n- name: Loopback for services configured\n  template: src=10-loopback-services.cfg.j2 dest=/etc/network/interfaces.d/10-loopback-services.cfg\n  notify:\n    - restart loopback\n  tags:\n    - always\n\n- name: Loopback included into the network config\n  lineinfile: dest=/etc/network/interfaces line='source /etc/network/interfaces.d/10-loopback-services.cfg' state=present\n  notify:\n    - restart loopback\n  tags:\n    - always\n\n- meta: flush_handlers\n  tags:\n    - always\n\n- name: Enable packet forwarding for IPv4\n  sysctl: name=\"{{ item }}\" value=1\n  with_items:\n    - net.ipv4.ip_forward\n    - net.ipv4.conf.all.forwarding\n  tags:\n    - always\n\n- name: Enable packet forwarding for IPv6\n  sysctl: name=net.ipv6.conf.all.forwarding value=1\n  tags:\n    - always\n\n- name: Check apparmor support\n  shell: apparmor_status\n  ignore_errors: yes\n  register: apparmor_status\n\n- set_fact:\n    apparmor_enabled: true\n  when: '\"profiles are in enforce mode\" in apparmor_status.stdout'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "b7150d2d80f92f5e313ff33b95eb626197188b05", "filename": "roles/config-clair/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Validate Quay Address Provided\n  fail:\n    msg: \"Quay Address Must Be Provided!\"\n  when: quay_enterprise_address is undefined or quay_enterprise_address|trim == \"\"\n\n- name: Set Clair Address\n  set_fact:\n    clair_address: \"http://{{ hostvars[inventory_hostname]['ansible_eth0']['ipv4']['address'] }}\"\n  when: clair_address is undefined or clair_address|trim == \"\"\n\n- name: Configure Configuration Directory\n  file:\n    state: directory\n    owner: root\n    group: root\n    mode: g+rw\n    path: \"{{ clair_config_dir }}\"\n  \n- name: Configure Trusted SSL\n  block:\n    - name: Check if Trusted SSL file exists\n      become: false\n      stat:\n        path: \"{{ clair_ssl_trust_src_file  }}\"\n      register: trusted_ssl_exists\n      changed_when: False\n      delegate_to: localhost\n    \n    - name: Fail if SSL source file does not exist\n      fail:\n        msg: \"Could not locate SSL trust certificate\"\n      when: trusted_ssl_exists.stat.exists == false\n  \n    - name: Copy SSL Certificate\n      copy:\n        src: \"{{ clair_ssl_trust_src_file }}\"\n        dest: \"{{ clair_ssl_trust_host_file }}\"\n        owner: root\n        group: root\n        mode: g+rw\n      notify: Restart Clair Service\n  when: clair_ssl_trust_configure|bool\n\n- name: Setup Clair configuration file\n  template:\n    src: config.yaml.j2\n    dest: \"{{ clair_config_dir }}/config.yaml\"\n    owner: root\n    group: root\n    mode: g+rw\n  notify: Restart Clair Service\n\n- name: Configure systemd environment files\n  template:\n    src: \"{{ clair_name }}.j2\"\n    dest: \"{{ systemd_environmentfile_dir}}/{{ clair_name }}\"\n  notify: \"Restart Clair Service\"\n\n- name: Configure systemd unit files\n  template:\n    src: \"{{ clair_service }}.j2\"\n    dest: \"{{ systemd_service_dir}}/{{ clair_service }}\"\n  notify: \"Restart Clair Service\"\n\n- name: Include firewall tasks\n  include_tasks: firewall.yml\n\n- name: Flush Handlers (Clair)\n  meta: flush_handlers\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "20dee97d27de374b1dff4510b099795b5f7d4726", "filename": "roles/mysql/tasks/fedora.yml", "repository": "iiab/iiab", "decoded_content": "    - name: Install MySQL\n      package: name={{ item }}\n               state=present\n      with_items:\n        - mysql-server\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "e30a866b0420f33ec71a3dda2bbbe32ebd6c94d1", "filename": "playbooks/files/profile.d-bro.sh", "repository": "rocknsm/rock", "decoded_content": "# Helpers\nalias bro-column=\"sed \\\"s/fields.//;s/types.//\\\" | column -s $'\\t' -t\"\nalias bro-awk='awk -F\" \"'\nbro-grep() { grep -E \"(^#)|$1\" $2; }\nbro-zgrep() { zgrep -E \"(^#)|$1\" $2; }\ntopcount() { sort | uniq -c | sort -rn | head -n ${1:-10}; }\ncolorize() { sed 's/#fields\\t\\|#types\\t/#/g' | awk 'BEGIN {FS=\"\\t\"};{for(i=1;i<=NF;i++) printf(\"\\x1b[%sm %s \\x1b[0m\",(i%7)+31,$i);print \"\"}'; }\ncm() { cat $1 | sed 's/#fields\\t\\|#types\\t/#/g' | awk 'BEGIN {FS=\"\\t\"};{for(i=1;i<=NF;i++) printf(\"\\x1b[%sm %s \\x1b[0m\",(i%7)+31,$i);print \"\"}'; }\nlesscolor() { cat $1 | sed 's/#fields\\t\\|#types\\t/#/g' | awk 'BEGIN {FS=\"\\t\"};{for(i=1;i<=NF;i++) printf(\"\\x1b[%sm %s \\x1b[0m\",(i%7)+31,$i);print \"\"}' | less -RS; }\ntopconn() { if [ $# -lt 2 ]; then echo \"Usage: topconn {resp|orig} {proto|service} {tcp|udp|icmp|http|dns|ssl|smtp|\\\"-\\\"}\"; else cat conn.log | bro-cut id.$1_h $2 | grep $3 | topcount; fi; }\nfields() { grep -m 1 -E \"^#fields\" $1 | awk -vRS='\\t' '/^[^#]/ { print $1 }' | cat -n ; }\ntoptalk() { for i in *.log; do echo -e \"$i\\n=================\"; cat $i | bro-cut id.orig_h id.resp_h | topcount 20; done; }\ntalkers() { for j in tcp udp icmp; do echo -e \"\\t=============\\n\\t     $j\\n\\t=============\"; for i in resp orig; do echo -e \"====\\n$i\\n====\"; topconn $i proto $j | column -t; done; done; }\n\ntoptotal() { if [ $# -lt 3 ]; then echo \"Usage: toptotal {resp|orig} {orig_bytes|resp_bytes|duration} conn.log\"; else\n      zcat $3 | bro-cut id.$1_h $2                  \\\n    | sort                                          \\\n    | awk '{ if (host != $1) {                      \\\n                 if (size != 0)                     \\\n                     print $1, size;                \\\n                  host=$1;                          \\\n                  size=0                            \\\n              } else                                \\\n                  size += $2                        \\\n            }                                       \\\n            END {                                   \\\n                if (size != 0)                      \\\n                     print $1, size                 \\\n                }'                                  \\\n    | sort -rnk 2                                   \\\n    | head -n 20; fi; }\n\ntopconvo() { if [ $# -lt 1 ]; then echo \"Usage: topconvo conn.log\"; else\n      zcat $1 | bro-cut  id.orig_h id.resp_h orig_bytes resp_bytes  \\\n    | sort                                                          \\\n    | awk '{ if (host != $1 || host2 != $2) {                       \\\n                 if (size != 0)                                     \\\n                     print $1, $2, size;                            \\\n                  host=$1;                                          \\\n                  host2=$2;                                         \\\n                  size=0                                            \\\n              } else                                                \\\n                  size += $3;                                       \\\n                  size += $4                                        \\\n            }                                                       \\\n            END {                                                   \\\n                if (size != 0)                                      \\\n                     print $1, $2, size                             \\\n                }'                                                  \\\n    | sort -rnk 3                                                   \\\n    | head -n 20; fi; }\n"}, {"commit_sha": "2a05a5032ce341d6a1d918453164c59ea2922f58", "sha": "345df2a909aa127a17a2ae365967398f01f79306", "filename": "roles/network_interface/vars/main.yml", "repository": "CSCfi/fgci-ansible", "decoded_content": "---\nenv:\n RUNLEVEL: 1\n\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "6aecba1fdf92a536f853fa3c93b07a6401c4f7b6", "filename": "tasks/section_01_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 1.1.1 Install Updates, Patches and Additional Security Software (Not Scored)\n    apt: update_cache=yes\n    tags:\n      - section1\n      - section1.1\n      - section1.1.1\n\n  - name: 1.1.2 Install Updates, Patches and Additional Security Software (Not Scored)\n    apt: upgrade=yes\n    when: apt_upgrade == True\n    tags:\n      - section1\n      - section1.1\n      - section1.1.2\n"}, {"commit_sha": "481f7ad18dc225973e1d676d33e58c49cbbfe986", "sha": "96e26dd4b76ef9242df95e34442acaac8b18e2e5", "filename": "tasks/main.yml", "repository": "openwisp/ansible-openwisp2", "decoded_content": "---\n\n### openwisp2\n## tasks\n- import_tasks: variables.yml\n  tags: [openwisp2, apt, yum, pip, django, supervisor, nginx, variables]\n\n- import_tasks: variables-spatialite.yml\n  tags: [openwisp2, apt, yum, pip, django, supervisor, nginx, variables]\n  when: >\n    openwisp2_database.engine == \"django.contrib.gis.db.backends.spatialite\"\n    and openwisp2_spatialite_path is none\n\n- import_tasks: apt.yml\n  tags: [openwisp2, apt]\n  when: ansible_os_family == 'Debian'\n\n- import_tasks: yum.yml\n  tags: [openwisp2, yum]\n  when: ansible_os_family == 'RedHat'\n\n- import_tasks: pip.yml\n  tags: [openwisp2, pip]\n\n# comprises django_secret_key.yml\n- import_tasks: django.yml\n  tags: [openwisp2, django]\n\n- import_tasks: firewalld.yml\n  tags: [openwisp2, firewalld]\n  when:\n    - ansible_os_family == 'RedHat'\n    - ansible_distribution_major_version|int >= 7\n\n- import_tasks: selinux.yml\n  tags: [openwisp2, selinux]\n  when: ansible_os_family == 'RedHat' and ansible_virtualization_type != 'docker'\n\n- import_tasks: supervisor.yml\n  tags: [openwisp2, supervisor]\n\n- import_tasks: nginx.yml\n  tags: [openwisp2, nginx]\n\n- import_tasks: cron.yml\n  tags: [openwisp2, cron]\n\n- import_tasks: complete.yml\n  tags: [openwisp2]\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "f0c33e80f081a15f10938a175b6a96c20c2b56fa", "filename": "roles/6-generic-apps/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Generic Apps Installed\n  command: echo Generic Apps Installed\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "0731fc96c9c19f98d6dc3e8f05afe96a2ef2b112", "filename": "roles/osp/packstack-install/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: infra_osp_hosts\n  roles:\n    - packstack-install\n"}, {"commit_sha": "2a05a5032ce341d6a1d918453164c59ea2922f58", "sha": "f7186e10946e44e61f63d383b9f893bbc348615c", "filename": "roles/network_interface/tasks/main.yml", "repository": "CSCfi/fgci-ansible", "decoded_content": "---\n\n- name: Add the OS specific varibles\n  include_vars: \"{{ ansible_os_family }}.yml\"\n\n- name: Install the required  packages in Redhat derivatives\n  yum: name={{ item }} state=installed\n  with_items: network_pkgs\n  when: ansible_os_family == 'RedHat'\n\n- name: Install the required packages in Debian derivatives\n  apt: name={{ item }} state=installed update_cache=yes\n  with_items: network_pkgs\n  environment: env\n  when: ansible_os_family == 'Debian'\n\n- name: Make sure the include line is there in interfaces file\n  lineinfile: >\n     regexp=\"^source\\ \\/etc\\/network\\/interfaces.d\\/\\*\"\n     line=\"source /etc/network/interfaces.d/*\"\n     dest=/etc/network/interfaces\n     state=present\n     insertafter=EOF\n  when: ansible_os_family == \"Debian\"\n\n- name: Create the directory for interface cfg files\n  file: path=/etc/network/interfaces.d  state=directory\n  when: ansible_os_family == \"Debian\"\n\n- name: Create the network configuration file for ethernet devices\n  template: src=ethernet_{{ ansible_os_family }}.j2 dest={{ net_path }}/ifcfg-{{ item.device }}\n  with_items: network_ether_interfaces\n  when: network_ether_interfaces is defined\n  register: ether_result\n  notify:\n     - restart network\n\n- name: Write configuration files for rhel route configuration\n  template: src=route_{{ ansible_os_family }}.j2 dest={{ net_path }}/route-{{ item.device }} \n  with_items: network_ether_interfaces\n  when: network_ether_interfaces is defined and item.route is defined and ansible_os_family == 'RedHat'\n  notify:\n     - restart network\n\n#- shell: ifdown {{ item.item.device }}; ifup {{ item.item.device }}\n#  with_items: ether_result.results\n#  when: ether_result is defined and item.changed\n\n- name: Create the network configuration file for bond devices\n  template: src=bond_{{ ansible_os_family }}.j2 dest={{ net_path }}/ifcfg-{{ item.device }}\n  with_items: network_bond_interfaces\n  when: network_bond_interfaces is defined\n  register: bond_result\n  notify:\n     - restart network\n\n- name: Make sure the bonding module is loaded\n  modprobe: name=bonding state=present\n  when: bond_result|changed\n\n- name: Write configuration files for route configuration\n  template: src=route_{{ ansible_os_family }}.j2 dest={{ net_path }}/route-{{ item.device }} \n  with_items: network_bond_interfaces\n  when: network_bond_interfaces is defined and item.route is defined and ansible_os_family == 'RedHat'\n  notify:\n     - restart network\n\n#- shell: ifdown {{ item.item.device }}; ifup {{ item.item.device }}\n#  with_items: bond_result.results\n#  when: bond_result is defined and item.changed\n\n- name: Create the network configuration file for slave in the bond devices\n  template: src=bond_slave_{{ ansible_os_family }}.j2 dest={{ net_path }}/ifcfg-{{ item.1 }}\n  with_subelements:\n   - network_bond_interfaces\n   - bond_slaves\n  when: network_bond_interfaces is defined\n  register: bond_port_result\n  notify:\n     - restart network\n\n#- shell: ifdown {{ item.item.1 }}; ifup {{ item.item.1 }}\n#  with_items: bond_port_result.results\n#  when: bond_port_result is defined and item.changed\n\n#- shell: ifdown {{ item.item.device }}; ifup {{ item.item.device }}\n#  with_items: bond_result.results\n#  when: bond_result is defined and item.changed and ansible_os_family == 'RedHat'\n\n- name: Create the network configuration file for vlan devices\n  template: src=ethernet_{{ ansible_os_family }}.j2 dest={{ net_path }}/ifcfg-{{ item.device }}\n  with_items: network_vlan_interfaces\n  when: network_vlan_interfaces is defined\n  register: vlan_result\n  notify:\n     - restart network\n\n- name: Write configuration files for rhel route configuration with vlan\n  template: src=route_{{ ansible_os_family }}.j2 dest={{ net_path }}/route-{{ item.device }} \n  with_items: network_vlan_interfaces\n  when: network_vlan_interfaces is defined and item.route is defined and ansible_os_family == 'RedHat'\n  notify:\n     - restart network\n\n#- shell: ifdown {{ item.item.device }}; ifup {{ item.item.device }}\n#  with_items: vlan_result.results\n#  when: vlan_result is defined and item.changed\n\n- name: Create the network configuration file for bridge devices\n  template: src=bridge_{{ ansible_os_family }}.j2 dest={{ net_path }}/ifcfg-{{ item.device }}\n  with_items: network_bridge_interfaces\n  when: network_bridge_interfaces is defined\n  register: bridge_result\n  notify:\n     - restart network\n\n- name: Write configuration files for rhel route configuration\n  template: src=route_{{ ansible_os_family }}.j2 dest={{ net_path }}/route-{{ item.device }}\n  with_items: network_bridge_interfaces\n  when: network_bridge_interfaces is defined and item.route is defined and ansible_os_family == 'RedHat'\n  notify:\n     - restart network\n\n#- shell: ifdown {{ item.item.device }}; ifup {{ item.item.device }}\n#  with_items: bridge_result.results\n#  when: bridge_result is defined and item.changed\n\n- name: Create the network configuration file for port on the bridge devices\n  lineinfile: dest={{ net_path }}/ifcfg-{{ item.1 }} regexp='^BRIDGE=' line=BRIDGE={{ item.0.device }}\n  with_subelements:\n    - network_bridge_interfaces\n    - ports\n  when: network_bridge_interfaces is defined\n  register: bridge_port_result\n  notify:\n     - restart network\n\nhandlers:\n  - name: restart network\n    service: \n      name: network\n      state: restarted\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "e8b7b9a5bf4bb50119ccc34b25c64b55224ce5b6", "filename": "roles/ejabberd_xs/templates/ejabberd.tmpfiles", "repository": "iiab/iiab", "decoded_content": "d /run/lock/ejabberdctl 0750 ejabberd ejabberd\nd /var/run/ejabberd 0750 ejabberd ejabberd\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "4a5628a2b9e228be64d4e2ed38b474c42b2f6c47", "filename": "roles/config-quay-enterprise/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Verify Storage Type\n  fail:\n    msg: \"Invalid Database Type. 'quay_database_type' must be 'postgres' or 'mysql'\"\n  when: quay_database_type not in [\"postgresql\",\"mysql\"]\n\n- name: Verify Clair Endpoint\n  fail:\n    msg: Clar Endpoint Must Be Specified\n  when: quay_clair_enable is defined and quay_clair_enable|bool and (quay_clair_endpoint is not defined or quay_clair_endpoint|trim == \"\")\n\n- name: Set PostgreSQL Facts\n  set_fact:\n    quay_db_uri: \"{{ postgresql_db_uri }}\"\n  when: quay_database_type == \"postgresql\"\n\n- name: Set MySQL Facts\n  set_fact:\n    quay_db_uri: \"{{ mysql_db_uri }}\"\n  when: quay_database_type == \"mysql\"\n\n- name: Set HTTP Protocol\n  set_fact:\n    quay_http_protocol: \"{{ (quay_ssl_enable|bool)| ternary('https','http') }}\"\n\n- name: Include Container Credentials\n  include_tasks: container_credentials.yml\n  when: (quay_registry_server | trim != \"\") and ((quay_registry_auth | trim != \"\") or (quay_registry_email | trim != \"\"))\n\n- name: Configure Storage Directories\n  file:\n    state: directory\n    owner: root\n    group: root\n    mode: g+rw\n    path: \"{{ item }}\"\n  with_items:\n    - \"{{ quay_config_dir }}\"\n    - \"{{ quay_storage_dir }}\"\n\n- name: Include systemd configurations\n  include_tasks: configure_systemd.yml\n\n- name: Set Fact for Custom SSL Certificates\n  set_fact:\n    quay_ssl_cert_file_to_use: \"{{ quay_ssl_cert_file }}\"\n    quay_ssl_key_file_to_use: \"{{ quay_ssl_key_file }}\"\n  when: quay_ssl_enable|bool and (quay_ssl_key_file is defined and quay_ssl_key_file|trim != \"\" and quay_ssl_cert_file is defined and quay_ssl_cert_file|trim != \"\")\n\n- name: Create Self Signed SSL Certificates\n  block:\n  - name: Create Temporary SSL Directory\n    command: mktemp -d /tmp/quay-ssl-XXXXXXX\n    register: quay_ssl_remote_tmp_dir_mktemp\n    delegate_to: \"{{ groups['quay_enterprise'][0] }}\"\n    when: quay_ssl_remote_tmp_dir is undefined and quay_ssl_remote_tmp_dir|trim == \"\"\n\n  - name: Set Fact for Remote Self Signed SSL Directory\n    set_fact:\n      quay_ssl_remote_tmp_dir: \"{{ quay_ssl_remote_tmp_dir if quay_ssl_remote_tmp_dir is defined and quay_ssl_remote_tmp_dir|trim == '' else quay_ssl_remote_tmp_dir_mktemp.stdout }}\"\n    when: quay_ssl_remote_tmp_dir is undefined and quay_ssl_remote_tmp_dir|trim == \"\"\n\n  - name: Create SSL Certificate\n    command: openssl req -nodes -x509 -newkey rsa:4096 -keyout {{ quay_ssl_remote_tmp_dir }}/ssl.key -out {{ quay_ssl_remote_tmp_dir }}/ssl.cert -subj \"/C={{ quay_ssl_generate_country }}/ST={{ quay_ssl_generate_state }}/L={{ quay_ssl_generate_city }}/O={{ quay_ssl_generate_organization }}/OU={{ quay_ssl_generate_organizational_unit }}/CN={{ quay_server_hostname }}\" -days {{ quay_ssl_generate_days_validity }}\n    delegate_to: \"{{ groups['quay_enterprise'][0] }}\"\n\n  - name: Fetch Self Signed SSL Certifictes\n    fetch:\n      src:  \"{{ item.src }}\"\n      dest: \"{{ item.dest }}\"\n      flat: true\n      fail_on_missing: yes\n    delegate_to: \"{{ groups['quay_enterprise'][0] }}\"\n    run_once: true\n    with_items:\n      - { src: \"{{ quay_ssl_remote_tmp_dir }}/ssl.key\", dest: \"{{ quay_ssl_local_tmp_dir }}/ssl.key\" }\n      - { src: \"{{ quay_ssl_remote_tmp_dir }}/ssl.cert\", dest: \"{{ quay_ssl_local_tmp_dir }}/ssl.cert\" }\n\n  - name: Delete Remote Self Signed SSL Certificates\n    file:\n      state: absent\n      path: \"{{ quay_ssl_remote_tmp_dir }}\"\n    when: quay_ssl_delete_generated_cert|bool\n    delegate_to: \"{{ groups['quay_enterprise'][0] }}\"\n\n  - name: Set Fact for Self Signed SSL Certificates\n    set_fact:\n      quay_ssl_cert_file_to_use: \"{{ quay_ssl_local_tmp_dir }}/ssl.cert\"\n      quay_ssl_key_file_to_use: \"{{ quay_ssl_local_tmp_dir }}/ssl.key\"\n  when: quay_ssl_enable|bool and (quay_ssl_key_file is not defined or quay_ssl_key_file|trim == \"\" or quay_ssl_cert_file is not defined or quay_ssl_cert_file|trim == \"\")\n\n- name: Copy SSL Certificates\n  copy:\n    src: \"{{ item.src }}\"\n    dest: \"{{ item.dest }}\"\n    owner: root\n    group: root\n    mode: g+rw\n  notify: Restart quay service\n  with_items:\n    - { src: \"{{ quay_ssl_cert_file_to_use }}\", dest: \"{{ quay_config_dir }}/ssl.cert\" }\n    - { src: \"{{ quay_ssl_key_file_to_use }}\", dest: \"{{ quay_config_dir }}/ssl.key\" }\n  when: quay_ssl_enable|bool\n\n- name: Check if Quay configuration exists\n  stat:\n    path: \"{{ quay_config_dir }}/config.yaml\"\n  register: quay_config_stat_result\n\n- name: Configure BitTorrent Pepper Value\n  set_fact:\n    bittorrent_filename_pepper: \"{{ 'hostname' | to_uuid | upper }}\"\n\n- name: Setup initial quay configuration file\n  template:\n    src: config.yaml.j2\n    dest: \"{{ quay_config_dir }}/config.yaml\"\n    owner: root\n    group: root\n    mode: g+rw\n  notify: Restart quay service\n  when: not quay_config_stat_result.stat.exists\n\n- name: Include firewall tasks\n  include_tasks: firewall.yml\n\n- name: Setup Initial User and Configuration\n  include_tasks: complete_setup.yml\n  when: not quay_config_stat_result.stat.exists and quay_superuser_username is defined and quay_superuser_username|trim != \"\" and quay_superuser_password is defined and quay_superuser_password|trim != \"\" and quay_superuser_email is defined and quay_superuser_email|trim != \"\"\n\n- name: Flush Handlers (Quay)\n  meta: flush_handlers\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "5dc5416da8d484121983d5388da3f4704f658b4d", "filename": "roles/nfs-server/tasks/prep.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Ensure everything is up-to-date' \n  package: \n    name: '*'\n    state: latest\n\n- name: 'Install required packages'\n  package:\n    name: '{{ item }}'\n    state: installed\n  with_items:\n  - nfs-utils\n  - lvm2\n  - firewalld\n  - python-firewall\n\n- name: 'Ensure firewalld is running'\n  service:\n    name: firewalld\n    state: started \n    enabled: yes\n\n- name: 'Ensure nfs-server is running'\n  service:\n    name: nfs-server\n    state: started \n    enabled: yes\n\n- name: 'Open Firewall for NFS use'\n  firewalld: \n    port: \"{{ item }}\"\n    permanent: yes\n    state: enabled\n    immediate: yes\n  with_items:\n  - 111/tcp\n  - 111/udp\n  - 2049/tcp\n  - 2049/udp\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "dc8a66595e83057900f1dccc0d1801a6dd39c972", "filename": "roles/awstats/templates/cron.d.awstats", "repository": "iiab/iiab", "decoded_content": "MAILTO=root\n\n*/10 * * * * www-data [ -x /usr/share/awstats/tools/update.sh ] && /usr/share/awstats/tools/update.sh\n\n# Generate static reports:\n10 03 * * * www-data [ -x /usr/share/awstats/tools/buildstatic.sh ] && /usr/share/awstats/tools/buildstatic.sh\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "90403e98f4c7e5141a4ab3b2784ad4f8aff3f368", "filename": "roles/mesos/defaults/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# Common\nconsul_dir: /etc/consul.d\nmesos_executor_registration_timeout: 10mins\nmesos_cluster_name: \"Cluster01\"\nmesos_ip: \"{{ ansible_default_ipv4.address }}\"\nmesos_hostname: \"{{ ansible_ssh_host }}\"\nmesos_docker_socket: \"/var/run/weave/weave.sock\"\nmesos_version: \"0.25.0-0.2.70.ubuntu1404\"\n\n# Defaults file for mesos-salve\nmesos_slave_port: 5051\nmesos_containerizers: \"docker,mesos\"\nmesos_resources: \"ports(*):[31000-32000]\"\nmesos_slave_work_dir: \"/tmp/mesos\"\nmesos_slave_image: \"mesosphere/mesos-slave:{{ mesos_version }}\"\n\n# Defaults file for mesos-master\nmesos_zookeeper_group: zookeeper_servers\nmesos_master_port: 5050\nmesos_master_work_dir: \"/var/lib/mesos\"\nmesos_master_image: \"mesosphere/mesos-master:{{ mesos_version }}\"\n\nprometheus_mesos_exporter_image: \"prom/mesos-exporter:latest\"\nprometheus_mesos_exporter_port: 9105\nprometheus_mesos_exporter_consul_service_id: \"{{ ansible_hostname }}:mesos-exporter:{{ prometheus_mesos_exporter_port }}\"\n\n# The Mesos quorum value is based on the number of Mesos Masters. Take the\n# number of masters, divide by 2, and round-up to nearest integer. For example,\n# if there are 1 or 2 masters the quorum count is 1. If there are 3 or 4\n# masters then the quorum count is 2. For 5 or 6 masters it's 3 and so on.\nmesos_quorum: \"\n{% if mesos_master_quorum is defined %}\n{{ mesos_master_quorum }}\n{% else %}\n{{ ( groups.mesos_masters|count / 2) | round(0, 'ceil') | int }}\n{%- endif -%}\n\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "5d6e1de48e49353c25e636eea67ae26046c5827b", "filename": "roles/notifications/md-to-html/tasks/convert_md_to_html.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Convert markdown(md) to HTML\"\n  shell: >\n    echo \"{{ markdown_content }}\" | pandoc -f markdown -t html\n  register: result\n\n- name: \"Store away converted Markdown(md) in a dict\"\n  set_fact:\n    md_to_html: \n      html_body_message: \"<html><body>{{ result.stdout }}</body></html>\"\n      html_message: \"{{ result.stdout }}\"\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "1e8a4f6b352a3864adce28327ea324a30d121473", "filename": "tasks/create_repo_nuget_proxy_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_nuget_proxy\n    args: \"{{ _nexus_repos_nuget_defaults|combine(item) }}\""}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "34fac5fd46539a66614950e69eba39dcb42f57ea", "filename": "tasks/setup-audit.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Ensure auditd is installed\n  become: true\n  package:\n    name: auditd\n    state: present\n  register: _pkg_result\n  until: _pkg_result is succeeded\n  when: \n    - docker_enable_audit\n    - docker_network_access\n    - _docker_os_dist == \"Ubuntu\" or _docker_os_dist == \"Debian\"\n\n- name: Copy Docker audit rules\n  become: yes\n  copy:\n    src: files/etc/audit/rules.d/docker.rules\n    dest: /etc/audit/rules.d/docker.rules\n  notify: restart auditd\n  when: docker_enable_audit\n\n- name: Ensure Docker audit rules are removed\n  become: yes\n  file:\n    path: /etc/audit/rules.d/docker.rules\n    state: absent\n  notify: restart auditd\n  when: not docker_enable_audit\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "afb3138d5f857e1099566a2380b8afae4ed52859", "filename": "roles/network/tasks/redetect.yml", "repository": "iiab/iiab", "decoded_content": "# The preferred method of disabling the LAN would be to set iiab_lan_enabled:\n# False before getting here but we are here...\n# Well if we got here something changed with the gateway and ifcfg-WAN maybe\n# no longer accurate. Note if DEVICE= is any ifcfg files the listed DEVICE\n# becomes bound to the NAME in the ifcfg file. With the LAN files out of the\n# way we can try the interfaces one by one starting with device_gw.\n\n# Setting up three way conditions with the results\n# skipped|changed|failed\n# failure results in blowing away the ifcfg-WAN so lets make sure...\n\n# We only got here by way of no detected gateway, lets see if we can pick-up\n# transient change like cable issues.\n\n- name: BAD DHCP defaults\n  set_fact:\n    dhcp_good: False\n\n# don't shoot ourselves in the foot....\n- name: Disable dhcp server just because\n  service: name=dhcpd state=stopped\n\n### clear all connections first\n# We should have the LAN torndown at this point.\n\n- name: No ifcfg-WAN known\n  debug: msg=\"NO WAN known\"\n  when: not has_WAN\n\n- name: Finding connection name for wifi AP gateway first\n  shell: egrep -rn NAME /etc/sysconfig/network-scripts/{{ has_wifi_gw }} |  gawk -F '=' '{print $2}'\n  register: ap_name\n  when: has_wifi_gw != \"none\" and has_ifcfg_gw != \"none\"\n\n- name: Trying wifi first\n  shell: nmcli conn up id {{ ap_name.stdout }}\n  register: try_wifi\n  ignore_errors: yes\n  when: ap_name is defined and ap_named.changed\n\n- name: Checking for WiFi gateway\n  shell: sleep 5 | ip route | grep default | awk '{print $5}'\n  register: dhcp_wifi_results\n  when: try_wifi is defined and try_wifi.changed\n\n# We have the DEVICE?\n- name: Now setting iiab_wan_iface based on wifi\n  set_fact:\n     iiab_wan_iface: \"{{ dhcp_wifi_results.stdout }}\"\n     dhcp_good: True\n  when: dhcp_wifi_results.stdout is defined and dhcp_wifi_results.stdout != \"\"\n\n- name: Trying ifcfg-WAN second\n  shell: nmcli conn up id iiab-WAN\n  register: dhcp_WAN\n  ignore_errors: yes\n  when: has_WAN\n\n- name: BAD ifcfg-WAN\n  debug: msg=\"BAD WAN\"\n  when: dhcp_WAN is defined and dhcp_WAN|failed\n\n- name: Delete ifcfg-WAN\n  shell: rm -f /etc/sysconfig/network-scripts/ifcfg-WAN\n  when: dhcp_WAN is defined and dhcp_WAN|failed and wan_ip == \"dhcp\"\n\n- name: Setting no ifcfg-WAN\n  set_fact:\n      has_WAN: False\n  when: dhcp_WAN is defined and dhcp_WAN|failed and wan_ip == \"dhcp\"\n\n- name: interface list\n  shell: ls /sys/class/net | grep -v -e lo -e br -e tun\n  register: adapter_list\n\n# wired devices with no wire plugged in fail here\n- name: Not risking an active device dropping all devices\n  shell: nmcli d delete {{ item|trim }}\n  ignore_errors: True\n  when: item|trim != iiab_wireless_lan_iface and not dhcp_good and wan_ip == \"dhcp\"\n  with_items:\n      - \"{{ adapter_list.stdout_lines }}\"\n\n# monitor-connection-files defaults to no with F21, F18-F20 defaults to yes\n- name: Reloading nmcli for deleted files\n  shell: nmcli con reload\n  when: not installing and not no_NM_reload\n\n# wired devices with no wire plugged in fail here\n# discovered_wireless_iface might need work\n- name: Try dhcp on all wired devices\n  shell: nmcli d connect {{ item|trim }}\n  ignore_errors: True\n  when: item|trim != discovered_wireless_iface and item|trim != iiab_wireless_lan_iface and not dhcp_good and wan_ip == \"dhcp\"\n  with_items:\n      - \"{{ adapter_list.stdout_lines }}\"\n\n# This should be neat on a VM with 2 bridged interfaces.\n- name: Checking for gateway\n  shell: sleep 5 | ip route | grep default | awk '{print $5}'\n  register: dhcp_1BY1_results\n  when: not has_WAN and not dhcp_good\n\n# We have the DEVICE?\n- name: Now setting iiab_wan_iface via nmcli\n  set_fact:\n     iiab_wan_iface: \"{{ dhcp_1BY1_results.stdout }}\"\n     dhcp_good: True\n  when: dhcp_1BY1_results.stdout is defined and dhcp_1BY1_results.stdout != \"\" and not has_WAN\n\n- name: Find gateway config based on device\n  shell: egrep -rn \"{{ iiab_wan_iface }}\" /etc/sysconfig/network-scripts/ifcfg* | gawk -F ':' '{print $1}'\n  register: ifcfg_dhcp_device\n  ignore_errors: True\n  changed_when: False\n  when: dhcp_good\n\n- name: Setting has ifcfg gw based on device if found\n  set_fact:\n    has_ifcfg_gw: \"{{ item|trim }}\"\n  when: dhcp_good and ifcfg_dhcp_device is defined and item|trim != \"\"\n  with_items:\n      - \"{{ ifcfg_dhcp_device.stdout_lines }}\"\n  ignore_errors: True\n\n# wired devices with no wire plugged in fail here\n- name: Disconnect wired devices\n  shell: nmcli c down id \"System{{ item|trim }}\"\n  ignore_errors: True\n  when: item|trim != iiab_wireless_lan_iface and item|trim != iiab_wan_iface and wan_ip == \"dhcp\"\n  with_items:\n      - \"{{ adapter_list.stdout_lines }}\"\n\n### keep at end.\n### If dhcp fails the single interface will become LAN again because we didn't prevent the creation\n# Now disable LAN if single interface\n- name: DHCP found on Single interface forcing LAN disabled.\n  set_fact:\n     iiab_lan_iface: \"none\"\n  when: dhcp_good  and adapter_count.stdout|int == \"1\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "79d25baf54b1b8bef1311dadaab78cd3407a483e", "filename": "roles/network/templates/squid/dstaddress.rules", "repository": "iiab/iiab", "decoded_content": "# put ip addresses here that are permitted squid access\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "da6ca7309704689134952c321db1345ee0f42343", "filename": "roles/ovirt-iso-uploader-conf/defaults/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\novirt_iso_uploader_conf: '/etc/ovirt-engine/isouploader.conf'\novirt_iso_uploader_user: 'admin@internal'\novirt_iso_uploader_password: '123456'\novirt_iso_uploader_engine: \"\"\novirt_iso_uploader_cert_file: \"\"\novirt_iso_uploader_iso_domain: \"\"\novirt_iso_uploader_nfs_server: \"\"\novirt_iso_uploader_ssh_user: \"\"\novirt_iso_uploader_ssh_port: \"\"\novirt_iso_uploader_key_file: \"\"\n"}, {"commit_sha": "b7c6bfe0369646ca69beeb3dfe07e8218d61c940", "sha": "91605350ce8d7ea8c745bf1cb18bde1350e3a84e", "filename": "tasks/user_accounts.yml", "repository": "dev-sec/ansible-os-hardening", "decoded_content": "---\n- name: get UID_MIN from login.defs\n  shell: awk '/^\\s*UID_MIN\\s*([0-9]*).*?$/ {print $2}' /etc/login.defs\n  args:\n    removes: /etc/login.defs\n  register: uid_min\n  check_mode: False\n  changed_when: False\n\n- name: calculate UID_MAX from UID_MIN by substracting 1\n  set_fact:\n    uid_max: '{{ uid_min.stdout | int - 1 }}'\n  when: uid_min is defined\n\n- name: set UID_MAX on Debian-systems if no login.defs exist\n  set_fact:\n    uid_max: '999'\n  when: ansible_os_family == 'Debian' and not uid_min\n\n- name: set UID_MAX on other systems if no login.defs exist\n  set_fact:\n    uid_max: '499'\n  when: not uid_min\n\n- name: get all system accounts\n  command: awk -F'':'' '{ if ( $3 <= {{ uid_max|quote }} ) print $1}' /etc/passwd\n  args:\n    removes: /etc/passwd\n  changed_when: False\n  check_mode: False\n  register: sys_accs\n\n- name: remove always ignored system accounts from list\n  set_fact:\n    sys_accs_cond: '{{ sys_accs.stdout_lines | difference(os_always_ignore_users) }}'\n  check_mode: False\n\n- name: change system accounts not on the user provided ignore-list\n  user:\n    name: '{{ item }}'\n    shell: '{{ os_nologin_shell_path }}'\n    password: '*'\n    createhome: False\n  with_flattened:\n    - '{{ sys_accs_cond | default([]) | difference(os_ignore_users) | list }}'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "12a759f0fa09f72130a16b631f6b757dbfb54191", "filename": "roles/dns/manage-dns-zones-route53/tests/inventory/group_vars/all.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ndns_data:\n  views:\n    - name: \"private\"\n      zones:\n        - dns_domain: \"roletest1.com\"\n          state: present\n          route53:\n            aws_access_key: \"{{ aws_access_key }}\"\n            aws_secret_key: \"{{ aws_secret_key }}\"\n            vpc_id: vpc-9dcde6f8\n            vpc_region: eu-west-1\n        - dns_domain: \"roletest2.com\"\n          state: present\n          route53:\n            aws_access_key: \"{{ aws_access_key }}\"\n            aws_secret_key: \"{{ aws_secret_key }}\"\n            vpc_id: vpc-9dcde6f8\n            vpc_region: eu-west-1\n    - name: \"public\"\n      zones:\n        - dns_domain: \"roletest3.com\"\n          state: absent\n          route53:\n            aws_access_key: \"{{ aws_access_key }}\"\n            aws_secret_key: \"{{ aws_secret_key }}\"\n        - dns_domain: \"roletest4.com\"\n          state: absent\n          route53:\n            aws_access_key: \"{{ aws_access_key }}\"\n            aws_secret_key: \"{{ aws_secret_key }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "44c489521654ea39d68b08e2b06628e5ad69cec4", "filename": "roles/config-nagios-target/tasks/nrpe_openshift_node.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Copy in additional Nagios service plugin\n  copy: \n    src: plugins/check_service.sh\n    dest: /usr/lib64/nagios/plugins/check_service.sh\n    owner: root\n    group: root\n    mode: 0755\n\n- name: Copy nrpe.d OpenShift node configuration files\n  copy: \n    src: nrpe.d/check_openshift_node.cfg\n    dest: /etc/nrpe.d/check_openshift_node.cfg\n    owner: root\n    group: root\n    mode: 0644\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "7bacb6b117a246d57ab731d3f5b2de01bcb6a673", "filename": "roles/osp/packstack-post/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: infra_osp_hosts\n  roles:\n    - packstack-post\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "c99b4258be3d7599cf8c7f2748367fada7ac7e35", "filename": "roles/network/templates/squid/denyregex.rules", "repository": "iiab/iiab", "decoded_content": "# put regular expressions for portions of urls that are to be denied access\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "864e35ef3709cdf5754fb6fdfed84ddde41b2ad4", "filename": "roles/dns_adblocking/templates/adblock.sh", "repository": "trailofbits/algo", "decoded_content": "#!/bin/sh\n# Block ads, malware, etc..\n\n# Redirect endpoint\nENDPOINT_IP4=\"0.0.0.0\"\nENDPOINT_IP6=\"::\"\nIPV6=\"Y\"\nTEMP=`mktemp`\nTEMP_SORTED=`mktemp`\n\n#Delete the old block.hosts to make room for the updates\nrm -f /var/lib/dnsmasq/block.hosts\n\necho 'Downloading hosts lists...'\n#Download and process the files needed to make the lists (enable/add more, if you want)\nwget -qO- http://winhelp2002.mvps.org/hosts.txt| awk -v r=\"$ENDPOINT_IP4\" '{sub(/^0.0.0.0/, r)} $0 ~ \"^\"r' > \"$TEMP\"\nwget -qO- \"https://adaway.org/hosts.txt\"|awk -v r=\"$ENDPOINT_IP4\" '{sub(/^127.0.0.1/, r)} $0 ~ \"^\"r' >> \"$TEMP\"\nwget -qO- https://www.malwaredomainlist.com/hostslist/hosts.txt|awk -v r=\"$ENDPOINT_IP4\" '{sub(/^127.0.0.1/, r)} $0 ~ \"^\"r' >> \"$TEMP\"\nwget -qO- \"https://hosts-file.net/.\\ad_servers.txt\"|awk -v r=\"$ENDPOINT_IP4\" '{sub(/^127.0.0.1/, r)} $0 ~ \"^\"r' >> \"$TEMP\"\n\n#Add black list, if non-empty\nif [ -s \"/var/lib/dnsmasq/black.list\" ]\nthen\n    echo 'Adding blacklist...'\n    awk -v r=\"$ENDPOINT_IP4\" '/^[^#]/ { print r,$1 }' /var/lib/dnsmasq/black.list >> \"$TEMP\"\nfi\n\n#Sort the download/black lists\nawk '{sub(/\\r$/,\"\");print $1,$2}' \"$TEMP\"|sort -u > \"$TEMP_SORTED\"\n\n#Filter (if applicable)\nif [ -s \"/var/lib/dnsmasq/white.list\" ]\nthen\n    #Filter the blacklist, suppressing whitelist matches\n    #  This is relatively slow =-(\n    echo 'Filtering white list...'\n    egrep -v \"^[[:space:]]*$\" /var/lib/dnsmasq/white.list | awk '/^[^#]/ {sub(/\\r$/,\"\");print $1}' | grep -vf - \"$TEMP_SORTED\" > /var/lib/dnsmasq/block.hosts\nelse\n    cat \"$TEMP_SORTED\" > /var/lib/dnsmasq/block.hosts\nfi\n\nif [ \"$IPV6\" = \"Y\" ]\nthen\n    safe_pattern=$(printf '%s\\n' \"$ENDPOINT_IP4\" | sed 's/[[\\.*^$(){}?+|/]/\\\\&/g')\n    safe_addition=$(printf '%s\\n' \"$ENDPOINT_IP6\" | sed 's/[\\&/]/\\\\&/g')\n    echo 'Adding ipv6 support...'\n    sed -i -re \"s/^(${safe_pattern}) (.*)$/\\1 \\2\\n${safe_addition} \\2/g\" /var/lib/dnsmasq/block.hosts\nfi\n\nservice dnsmasq restart\n\nexit 0\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "a29aea7231e9e147c0e041989b200769aac01dce", "filename": "roles/nextcloud/tasks/F18.yml", "repository": "iiab/iiab", "decoded_content": "- name: Remove /etc/nextcloud to avoid confusion as we use the config in {{ nextcloud_prefix }}/nextcloud/config/\n  file: path=/etc/nextcloud\n        state=absent\n\n# but we use the tar file to get the latest version; really only benefits the xo4 on fedora 18\n- name: Get the nextcloud software\n  get_url: url=\"{{ nextcloud_dl_url }}\"/{{ nextcloud_src_file }}  dest={{ downloads_dir }}/{{ nextcloud_src_file }}\n  when: internet_available\n\n- name: Copy it to permanent location /opt\n  unarchive: src={{ downloads_dir }}/{{ nextcloud_src_file }}  dest=/opt/\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "f4b01db517cd9a0cf7cbcb02412be52910ac6ce2", "filename": "roles/dns/manage-dns-records/tasks/route53/process-records.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Print WARNING for views other than 'public' and 'private'\"\n  fail:\n    msg: \"WARNING: only 'public' and 'private' views are processed for Route53\"\n  ignore_errors: True\n  when:\n    - dns.0.name != 'private'\n    - dns.0.name != 'public'\n\n- name: \"Manage Route53 DNS records for view: {{ dns.0.name }}, zone: {{ dns.1.dns_domain }}\"\n  route53:\n    zone: \"{{ dns.1.dns_domain }}\"\n    record: \"{{ item.record }}\"\n    value: \"{{ item.value | default(omit) }}\"\n    type: \"{{ item.type }}\"\n    ttl: \"{{ item.ttl | default(omit) }}\"\n    state: \"{{ item.state | default(present) }}\"\n  with_items:\n    - \"{{ dns.1.entries }}\"\n  when:\n    - dns.0.name == 'private' or dns.0.name == 'public'\n    - dns.1.entries is defined\n    - dns.1.route53 is defined\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "f18d673c876502f502cace1431a0d501309353c7", "filename": "playbooks/files/suricata.service", "repository": "rocknsm/rock", "decoded_content": "[Unit]\nDescription=Suricata Intrusion Detection Service\nAfter=syslog.target network.target\n\n[Service]\nEnvironmentFile=-/etc/sysconfig/suricata\nExecStart=/sbin/suricata -c /etc/suricata/suricata.yaml --af-packet\nExecReload=/bin/kill -HUP $MAINPID\nUser=suricata\nGroup=suricata\n\n[Install]\nWantedBy=multi-user.target\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "d7fb9ca0729c3ed084fec7ea7c061144305a19ef", "filename": "roles/debian_schooltool/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: get the required build packages \n  package: name={{ item }}\n           state=present\n  with_items:\n    - build-essential \n    - gettext\n    - python-dev\n    - libicu-dev \n    - libxslt1-dev \n    - libfreetype6-dev \n    - libjpeg-dev \n    - enscript\n    - python-virtualenv \n    - ttf-liberation\n    - redis-server\n    - libjpeg-dev\n    - xvfb\n  when: debian_schooltool_install and is_debuntu\n\n- name: Create the font directory\n  file: path=/usr/share/fonts/truetype/ttf-ubuntu\n        state=directory\n  \n- name: get the ttf-ubuntu-font-family\n  get_url: url={{ iiab_download_url }}/ubuntu-font-family-0.83.zip\n           dest={{ downloads_dir }}\n\n- name: expand the ttf fonts to the right place\n  unarchive: src={{ downloads_dir }}/ubuntu-font-family-0.83.zip\n             dest=/usr/share/fonts/truetype/ttf-ubuntu/\n\n- name: get the schooltool source\n  get_url: url={{ iiab_download_url }}/{{ schooltool_src }}\n           dest={{ downloads_dir }}\n\n- name: expand source to dest\n  unarchive: src={{ downloads_dir }}/{{ schooltool_src }}\n             dest={{ iiab_base }}\n\n- name: create a link for schooltool\n  file: src={{ iiab_base }}/{{ schooltool_version }}\n        dest={{ iiab_base }}/schooltool\n        state=link\n\n- name: build the schooltool from source\n  shell: command='$( cd {{ iiab_base }}/schooltool; /usr/bin/make ) '\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a1fc85fefd43a8142ea5d563721294393c8382f5", "filename": "roles/config-libvirt/tasks/libvirt.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Install the Virtualization Host group\"\n  yum:\n    name: \"@^virtualization-host-environment\"\n    state: present\n\n- name: \"Ensure libvirt is running\"\n  service:\n    name: libvirtd \n    state: started\n    enabled: yes \n\n"}, {"commit_sha": "7032aee7df1c2c6e96795067285efa3b2a6de32e", "sha": "61780e0f27c4889a5677a1b8bf37188bcf111f77", "filename": "playbooks/dns_dual_view.yaml", "repository": "openshift/openshift-ansible-contrib", "decoded_content": "---\n  - name: \"Setting up views\"\n    template:\n      dest: /tmp/named_views.yaml\n      src: ./playbooks/templates/named_views.template\n      force: true\n    delegate_to: localhost\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "20f901193b66852a8e39fadb1a0840277e2202d5", "filename": "roles/config-dns-server/tasks/named_zones.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Setup Views and Zones configuration\n  template:\n    src: named.conf.view.j2\n    dest: /etc/named/named.conf.view\n    owner: named\n    group: named\n    mode: 0660\n  notify: restart named \n\n- name: Get existing zone files\n  shell: 'ls -1 {{ item }}.db | sed -ne \"s/\\({{ item }}\\).db/\\1/p\"'\n  args:\n    chdir: /var/named/static\n  register: zone_files\n  ignore_errors: yes\n  with_items:\n  - \"{{ dns_views }}\"\n\n- name: Build list of existing zone files\n  set_fact:\n    existing_zone_files: \"{{ existing_zone_files | default([]) + [ item.stdout ] }}\"\n  with_items:\n  - \"{{ zone_files.results }}\"\n\n- name: Build zone/view items to iterate\n  set_fact:\n    zones: \"{{ zones | default([]) + [ { 'name': item.0.name, 'dns_domain': item.1.dns_domain, 'combined': item.0.name + '-' + item.1.dns_domain } ] }}\"\n  with_subelements:\n  - \"{{ named_config_views }}\"\n  - zone\n\n- name: Prepare Zone Files\n  template: \n    src: zone.db.j2\n    dest: \"/var/named/static/{{ item.combined }}.db\"\n    owner: named\n    group: named\n    mode: 0660\n  with_items:\n  - \"{{ zones }}\"\n  when:\n  - item.combined not in existing_zone_files\n  notify: restart named \n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "d4a297bbb7f16b3c5ac7e0ccff3110d89846cdb1", "filename": "roles/usb-lib/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "usb_lib_install: True\nusb_lib_enabled: True\n"}, {"commit_sha": "35c4af9fd84d7a7e6bc093adc944b352e68d6ff1", "sha": "d8e42a7b6123f8b4f98df13ed0207bd0c30c3420", "filename": "tasks/main-Generic.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n# tasks file for ansible-role-docker-ce\n\n- name: Copy Docker audit rules\n  copy:\n    src: files/etc/audit/rules.d/docker.rules\n    dest: /etc/audit/rules.d/docker.rules\n  become: yes\n  notify: restart auditd\n  when: docker_enable_audit == true\n\n- name: Ensure Docker audit rules are removed\n  file:\n    path: /etc/audit/rules.d/docker.rules\n    state: absent\n  become: yes\n  notify: restart auditd\n  when: docker_enable_audit == false\n\n- name: Determine Docker version\n  command: bash -c \"docker version | grep Version | awk '{print $2}'\"\n  ignore_errors: yes\n  changed_when: false\n  register: cmd_docker_version\n\n- name: Set fact if old Docker installation shall be removed\n  set_fact:\n    remove_old_docker: \"{{docker_remove_pre_ce | bool }} == true and {{ cmd_docker_version.stdout_lines[0] | search('-ce') }} == false\"\n  when: cmd_docker_version.stdout_lines is defined and cmd_docker_version.stdout_lines[0] is defined\n\n- name: Check if Docker is running\n  command: systemctl status docker\n  ignore_errors: yes\n  changed_when: false\n  register: service_docker_status\n  when: remove_old_docker | default(false) | bool == true\n  become: true\n\n- name: Stop Docker service\n  service:\n    name: docker\n    state: stopped\n  when: \"service_docker_status.rc | default(1) == 0\"\n\n- name: Remove old Docker installation before Docker CE\n  package:\n    name: \"{{ item }}\"\n    state: absent\n  become: true\n  when: remove_old_docker|default(false) | bool == true\n  with_items:\n    - docker\n    - docker-common\n    - container-selinux\n    - docker-selinux\n    - docker-engine\n\n- name: Set docker-ce package state to latest\n  set_fact:\n    docker_pkg_state: 'latest'\n  when: docker_latest_version|bool\n\n- name: Ensure docker-ce is installed\n  package:\n    name: docker-ce\n    state: \"{{ docker_pkg_state|default('present') }}\"\n  become: true\n  notify: restart docker\n\n- name: Ensure /etc/docker directory exists\n  file:\n    path: /etc/docker\n    state: directory\n    mode: 0755\n  become: true\n\n- name: Configure Docker daemon (file)\n  copy:\n    src: \"{{ docker_daemon_config_file }}\"\n    dest: /etc/docker/daemon.json\n  become: true\n  notify: restart docker\n  when: docker_daemon_config_file is defined\n\n- name: Configure Docker daemon (variables)\n  copy:\n    content: \"{{ docker_daemon_config | to_nice_json }}\"\n    dest: /etc/docker/daemon.json\n  become: true\n  notify: restart docker\n  when: docker_daemon_config_file is not defined and \n        docker_daemon_config is defined\n\n- name: Ensure Docker default user namespace is defined in subuid and subgid\n  lineinfile:\n    path: \"{{ item }}\"\n    regexp: '^dockremap'\n    line: 'dockremap:500000:65536'\n  become: yes\n  with_items:\n    - /etc/subuid\n    - /etc/subgid\n  when: (docker_daemon_config is defined and\n        docker_daemon_config['userns-remap'] is defined and\n        docker_daemon_config['userns-remap'] == 'default') or\n        docker_bug_usermod|bool == true\n\n- name: Enable and start Docker service\n  service:\n    name: docker\n    state: started\n    enabled: true\n  become: true\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "2b8aada65b7e7cbd7cda78e37fff2b53d824052f", "filename": "playbooks/provision-nfs-server/nfs-server.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Create NFS server'\n  hosts: nfs-server\n  roles:\n  - role: nfs-server\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "42d5f46b28e9129fadcccbb558e264d6ca84b736", "filename": "archive/roles/expose-registry/tasks/main.yaml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- name: \"Check that Openshift Docker Registry exists\"\n  command: >\n    {{ openshift.common.client_binary }} get deploymentConfig {{ registry_dc }}\n     -n {{ openshift_registry_project }}\n  register: registry_exists\n\n- fail:\n    msg: \"No docker registry found\"\n  when: registry_exists.rc != 0\n\n- name: \"Check that Openshift router exists\"\n  command: >\n    {{ openshift.common.client_binary }} get deploymentConfig {{ router_dc }}\n     -n {{ openshift_router_project }}\n  register: router_exists\n\n- fail:\n    msg: \"No router found\"\n  when: router_exists.rc != 0\n\n- name: \"Collect registry service info\"\n  command: >\n    {{ openshift.common.client_binary}} get service {{ registry_dc }}\n     -n {{ openshift_registry_project }} -o yaml\n  register: registry_svc_info\n\n- set_fact:\n    registry_svc_ip: \"{{ (registry_svc_info.stdout | from_yaml).spec.clusterIP }}\"\n\n\n- name: \"Check if registry is already secured\"\n  uri:\n    url: \"https://{{ registry_svc_ip }}:5000\"\n    method: \"GET\"\n    status_code: '200'\n    validate_certs: no\n  register: secured\n  failed_when: false\n\n- fail:\n    msg: \"The registry has not been secured.\"\n  when: secured.status != 200\n\n- name: \"Check if registry is already exposed\"\n  command: >\n    {{openshift.common.client_binary}} get routes {{registry_dc}} -n {{openshift_registry_project}}\n  register: already_exposed\n  failed_when: false\n\n- fail:\n    msg: \"Docker registry is already exposed\"\n  when: already_exposed.rc == 0\n\n- fail:\n    msg: \"Variable 'registry_hostname' has not been defined.\"\n  when: registry_hostname == '' or registry_hostname is not defined\n\n- name: \"Create route\"\n  command: >\n   {{ openshift.common.client_binary }} create route passthrough\n   --service={{registry_dc}}\n   --hostname={{registry_hostname}}\n   -n {{ openshift_registry_project }}\n  when: \"{{openshift.common.version_gte_3_2_or_1_2 | bool}}\"\n\n- name: \"Create route\"\n  command: >\n   {{ openshift.common.client_binary }} expose service/{{registry_dc}}\n   --hostname={{registry_hostname}}\n   -n {{ openshift_registry_project }}\n  when: \"{{not openshift.common.version_gte_3_2_or_1_2 | bool}}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "ec2605490688aa4a95fa8e25be3aac3a55ebb7b9", "filename": "playbooks/notifications/email-notify-users.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Send HTML e-mail message to a user\"\n  hosts: mail-host\n  gather_facts: no\n  tasks:\n  - include_tasks: email-notify-single-user.yml\n    vars:\n      first_name: \"{{ item.first_name }}\"\n      user_name: \"{{ item.user_name }}\"\n      password: \"{{ item.password }}\"\n      email_to: \"{{ item.email }}\"\n    when:\n    - item.notify_user == True\n    with_items:\n    - \"{{ users }}\"\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "02ee87d276e3e0faa8a0600b6c386af2bc217d53", "filename": "roles/openvpn/templates/silence", "repository": "iiab/iiab", "decoded_content": "#!/bin/bash\n# if pid file for announce exists kill the process\n\nkill `pgrep ncat`\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "2a59096dcf8a3c5054f20d3781d90b244e9eb994", "filename": "roles/config-vlans/tests/infrahosts.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Configure VLANs on the infrastructure hosts'\n  hosts: infra_hosts\n  roles:\n  - role: config_vlans\n  tags: \n  - configure_infra_hosts\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "784755e471f37e62cdec644058d15eba17d4268d", "filename": "meta/main.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\nallow_duplicates: no\n\n\ngalaxy_info:\n  author: Aur\u00e9lien Wailly\n  description: Ansible role to meet CIS (Center for Internet Security) requirements on ubuntu\n  license: GPLv2\n  min_ansible_version: 1.9.0.1\n  platforms:\n    - name: Ubuntu\n      versions:\n        14.04\n  categories:\n    #- cloud\n    #- cloud:ec2\n    #- cloud:gce\n    #- cloud:rax\n    #- clustering\n    #- database\n    #- database:nosql\n    #- database:sql\n    #- development\n    - monitoring\n    #- networking\n    #- packaging\n    - system\n    #- web\n\n\n\ndependencies: []\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "dc17f028a73a5a27853a93406bc31a96c0af62e0", "filename": "playbooks/roles/check_firewall_initialize/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- name: Ensure nc is installed\n  yum:\n    name: nc\n    state: present\n- name: Open correct ports from iptables\n  iptables:\n    chain: INPUT\n    protocol: tcp\n    destination_port: \"{{item}}\"\n    jump: ACCEPT\n    comment: \"Accept trafic to {{item}}\"\n  with_items:\n  - \"{{firewall_ports}}\"\n- name: Start nc -l to all valid ports\n  shell: \"nc -l {{item}} >/dev/null 2>&1 &\"\n  async: -1\n  poll: -1\n  with_items:\n  - \"{{firewall_ports}}\"\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "c4dedb6a3fa010b8c6386bfb4d7b56bce1f60bfe", "filename": "playbooks/roles/check_docker_setup/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- name: Ensure docker installed\n  yum:\n    name: docker\n    state: latest\n- name: Ensure docker proxy settings\n  lineinfile:\n    dest: /etc/sysconfig/docker\n    state: present\n    line: \"{{item[0]}}={{ item[1] }}\"\n  with_together:\n  - ['HTTP_PROXY', 'HTTPS_PROXY', 'NO_PROXY']\n  - [\"{{proxy_http}}\", \"{{proxy_https}}\", \"{{proxy_no}}\"]\n  when: proxy_username is not defined and proxy_http is defined\n- name: Ensure docker proxy settings with username and password\n  lineinfile:\n    dest: /etc/sysconfig/docker\n    state: present\n    line: \"{{item[0]}}=http://{{ proxy_username }}:{{ proxy_password }}@{{ item[1] }}\"\n  with_together:\n  - ['HTTP_PROXY', 'HTTPS_PROXY', 'NO_PROXY']\n  - [\"{{proxy_http}}\", \"{{proxy_https}}\", \"{{proxy_no}}\"]\n  when: proxy_username is defined and proxy_http is defined\n- name: Detect Docker storage configuration status\n  command: grep -q overlay2 /etc/sysconfig/docker-storage\n  register: docker_storage_test\n  changed_when: false\n  failed_when: false\n- name: Create docker storage configuration\n  template:\n    src: templates/docker-storage-setup.j2\n    dest: /etc/sysconfig/docker-storage-setup\n  when: docker_storage_test.rc != 0\n\n- name: Apply Docker storage configuration changes\n  command: docker-storage-setup\n  when: docker_storage_test.rc != 0\n\n- name: Fail if Docker version is < {{docker_version}}\n  fail:\n    msg: 'docker_version must be >= 1.12, yours is set to {{ docker_version }}.'\n  when: docker_version | version_compare('1.12', '<')\n\n- name: Enable docker\n  command: systemctl enable docker\n\n- name: Start docker\n  command: systemctl start docker\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "058c8bd6d41f8f48d180a9cd1c232d171a1a3fc5", "filename": "tasks/nexus_install.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n\n- name: No version given =>> calculate latest available nexus version\n  block:\n\n    - name: Call latest nexus uri to get redirection\n      uri:\n        url: \"{{ nexus_download_url }}/latest-unix.tar.gz\"\n        method: CONNECT\n        status_code: 302\n      register: nexus_latest_uri_call\n      # No changes made, we only need the target uri. Safe for check mode and needed for next operations\n      check_mode: no\n\n    - name: Register latest nexus version from redirection\n      set_fact:\n        nexus_version: \"{{ nexus_latest_uri_call.location | regex_replace('^https://.*nexus-(\\\\d*\\\\.\\\\d*\\\\.\\\\d*-\\\\d*)-unix.tar.gz', '\\\\1') }}\"\n\n  when: nexus_version == ''\n\n- name: Broken compatibility => nexus_package is now dynamically calculated\n  fail:\n    msg: >-\n      You have set the variable nexus_package in your playbook.\n      Starting from version 2.2.0 of this role, this is not compatible\n      with the new nexus latest version detection feature and is not\n      supported anymore. Please use the nexus_version variable only.\n  when: nexus_package is defined\n\n- name: Register nexus package name\n  set_fact:\n    nexus_package: \"nexus-{{ nexus_version }}-unix.tar.gz\"\n\n- name: Download nexus_package\n  get_url:\n    url: \"{{ nexus_download_url }}/{{ nexus_package }}\"\n    dest: \"{{ nexus_download_dir }}/{{ nexus_package }}\"\n    force: no\n  notify:\n    - nexus-service-stop\n\n- name: Ensure Nexus o/s group exists\n  group:\n    name: \"{{ nexus_os_group }}\"\n    state: present\n\n- name: Ensure Nexus o/s user exists\n  user:\n    name: \"{{ nexus_os_user }}\"\n    group: \"{{ nexus_os_group }}\"\n    shell: \"/bin/bash\"\n    state: present\n\n- name: Ensure Nexus installation directory exists\n  file:\n    path: \"{{ nexus_installation_dir }}\"\n    state: \"directory\"\n\n- name: Unpack Nexus download\n  unarchive:\n    src: \"{{ nexus_download_dir }}/{{ nexus_package }}\"\n    dest: \"{{ nexus_installation_dir }}\"\n    creates: \"{{ nexus_installation_dir }}/nexus-{{ nexus_version }}\"\n    force: no\n    copy: false\n  notify:\n    - nexus-service-stop\n\n- meta: flush_handlers\n\n- name: Update symlink nexus-latest\n  file:\n    path: \"{{ nexus_installation_dir }}/nexus-latest\"\n    src: \"{{ nexus_installation_dir }}/nexus-{{ nexus_version }}\"\n    owner: \"{{ nexus_os_user }}\"\n    group: \"{{ nexus_os_group }}\"\n    state: link\n    follow: false\n  register: nexus_latest_version\n\n- name: Delete unpacked data directory\n  file:\n    path: \"{{ nexus_installation_dir }}/nexus-latest/data\"\n    state: absent\n\n- name: Get path to default settings\n  set_fact:\n    nexus_default_settings_file: \"{{ nexus_installation_dir }}/nexus-latest/etc/org.sonatype.nexus.cfg\"\n  when: nexus_version is version_compare('3.1.0', '<')\n\n- name: Get path to default settings\n  set_fact:\n    nexus_default_settings_file: \"{{ nexus_installation_dir }}/nexus-latest/etc/nexus-default.properties\"\n  when: nexus_version is version_compare('3.1.0', '>=')\n\n- name: Get application settings directories\n  set_fact:\n    nexus_app_dir_settings_dirs:\n      - \"{{ nexus_installation_dir }}/nexus-latest/etc\"\n  when: nexus_version is version_compare('3.1.0', '<')\n\n- name: Get application settings directories\n  set_fact:\n    nexus_app_dir_settings_dirs:\n      - \"{{ nexus_installation_dir }}/nexus-latest/etc\"\n      - \"{{ nexus_installation_dir }}/nexus-latest/etc/karaf\"\n      - \"{{ nexus_installation_dir }}/nexus-latest/etc/jetty\"\n      - \"{{ nexus_installation_dir }}/nexus-latest/etc/fabric\"\n      - \"{{ nexus_installation_dir }}/nexus-latest/etc/logback\"\n      - \"{{ nexus_installation_dir }}/nexus-latest/etc/scripts\"\n  when: nexus_version is version_compare('3.1.0', '>=')\n\n- name: Get rest API endpoint (v < 3.8.0)\n  set_fact:\n    nexus_rest_api_endpoint: \"service/siesta/rest/v1/script\"\n  when: nexus_version is version_compare('3.8.0', '<')\n\n- name: Get rest API endpoint (v >= 3.8.0)\n  set_fact:\n    nexus_rest_api_endpoint: \"service/rest/v1/script\"\n  when: nexus_version is version_compare('3.8.0', '>=')\n\n- name: Get path to database restore dir (v < 3.11.0)\n  set_fact:\n    nexus_db_restore_dir: \"{{ nexus_data_dir }}/backup\"\n  when: nexus_version is version_compare('3.11.0', '<')\n\n- name: Get path to database restore dir (v >= 3.11.0)\n  set_fact:\n    nexus_db_restore_dir: \"{{ nexus_data_dir }}/restore-from-backup\"\n  when: nexus_version is version_compare('3.11.0', '>=')\n\n- name: Allow nexus to create first-time install configuration files in  {{ nexus_installation_dir }}/nexus-latest/etc\n  file:\n    path: \"{{ item }}\"\n    state: \"directory\"\n    owner: \"{{ nexus_os_user }}\"\n    group: \"{{ nexus_os_group }}\"\n    mode: \"0755\"\n    recurse: false\n  with_items: \"{{ nexus_app_dir_settings_dirs }}\"\n  when: nexus_latest_version.changed\n  register: chown_config_first_time\n  tags:\n    # hard to run as a handler for time being\n    - skip_ansible_lint\n\n- name: Create Nexus data directory\n  file:\n    path: \"{{ nexus_data_dir }}\"\n    state: \"directory\"\n    owner: \"{{ nexus_os_user }}\"\n    group: \"{{ nexus_os_group }}\"\n\n- name: Setup Nexus data directory\n  lineinfile:\n    dest: \"{{ nexus_installation_dir }}/nexus-latest/bin/nexus.vmoptions\"\n    regexp: \"^-Dkaraf.data=.*\"\n    line: \"-Dkaraf.data={{ nexus_data_dir }}\"\n\n- name: Setup JVM logfile directory\n  lineinfile:\n    dest: \"{{ nexus_installation_dir }}/nexus-latest/bin/nexus.vmoptions\"\n    regexp: \"^-XX:LogFile=.*\"\n    line: \"-XX:LogFile={{ nexus_data_dir }}/log/jvm.log\"\n\n- name: Setup Nexus default timezone\n  lineinfile:\n    dest: \"{{ nexus_installation_dir }}/nexus-latest/bin/nexus.vmoptions\"\n    regexp: \"^-Duser.timezone=.*\"\n    line: \"-Duser.timezone={{ nexus_timezone }}\"\n\n- name: Setup Nexus JVM min heap size\n  lineinfile:\n    dest: \"{{ nexus_installation_dir }}/nexus-latest/bin/nexus.vmoptions\"\n    regexp: \"^-Xms.*\"\n    line: \"-Xms{{ nexus_min_heap_size }}\"\n  notify: nexus-service-stop\n\n- name: Setup Nexus JVM max heap size\n  lineinfile:\n    dest: \"{{ nexus_installation_dir }}/nexus-latest/bin/nexus.vmoptions\"\n    regexp: \"^-Xmx.*\"\n    line: \"-Xmx{{ nexus_max_heap_size }}\"\n  notify: nexus-service-stop\n\n- name: Setup Nexus JVM max direct memory\n  lineinfile:\n    dest: \"{{ nexus_installation_dir }}/nexus-latest/bin/nexus.vmoptions\"\n    regexp: \"^-XX:MaxDirectMemorySize=.*\"\n    line: \"-XX:MaxDirectMemorySize={{ nexus_max_direct_memory }}\"\n  notify: nexus-service-stop\n\n- name: Create Nexus tmp/backup directory\n  file:\n    path: \"{{ item }}\"\n    state: \"directory\"\n    owner: \"{{ nexus_os_user }}\"\n    group: \"{{ nexus_os_group }}\"\n  with_items:\n    - \"{{ nexus_tmp_dir }}\"\n    - \"{{ nexus_backup_dir }}\"\n\n- name: Setup Nexus tmp directory\n  lineinfile:\n    dest: \"{{ nexus_installation_dir }}/nexus-latest/bin/nexus.vmoptions\"\n    regexp: \"^-Djava.io.tmpdir=.*\"\n    line: \"-Djava.io.tmpdir={{ nexus_tmp_dir }}\"\n\n- name: Set NEXUS_HOME for the service user\n  lineinfile:\n    dest: \"/home/{{ nexus_os_user }}/.bashrc\"\n    regexp: \"^export NEXUS_HOME=.*\"\n    line: \"export NEXUS_HOME={{ nexus_installation_dir }}/nexus-latest\"\n\n- name: Set nexus user\n  lineinfile:\n    dest: \"{{ nexus_installation_dir }}/nexus-latest/bin/nexus.rc\"\n    regexp: \".*run_as_user=.*\"\n    line: \"run_as_user=\\\"{{ nexus_os_user }}\\\"\"\n\n- name: Set nexus port\n  lineinfile:\n    dest: \"{{ nexus_default_settings_file }}\"\n    regexp: \"^application-port=.*\"\n    line: \"application-port={{ nexus_default_port }}\"\n\n- name: Set nexus context path\n  lineinfile:\n    dest: \"{{ nexus_default_settings_file }}\"\n    regexp: \"^nexus-context-path=.*\"\n    line: \"nexus-context-path={{ nexus_default_context_path }}\"\n\n- name: Bind nexus service to 127.0.0.1 only\n  lineinfile:\n    dest: \"{{ nexus_default_settings_file }}\"\n    regexp: \"^application-host=.*\"\n    line: \"application-host=127.0.0.1\"\n  when: httpd_setup_enable\n\n- name: Create systemd service configuration\n  template:\n    src: \"nexus.service\"\n    dest: \"/etc/systemd/system\"\n  notify:\n    - systemd-reload\n\n- block:\n    - name: \"Deploy backup restore script\"\n      template:\n        src: \"nexus-blob-restore.sh.j2\"\n        dest: \"{{ nexus_script_dir }}/nexus-blob-restore.sh\"\n        mode: 0755\n    - name: \"Symlink backup restore script to /sbin\"\n      file:\n        src: \"{{ nexus_script_dir }}/nexus-blob-restore.sh\"\n        dest: \"/sbin/nexus-blob-restore.sh\"\n        state: link\n  when: nexus_backup_configure | bool\n\n- name: 'Check if data directory is empty (first-time install)'\n  command: \"ls {{ nexus_data_dir }}\"\n  register: nexus_data_dir_contents\n  check_mode: no\n  changed_when: false\n\n- name: Clean cache for upgrade process\n  file:\n    path: \"{{ nexus_data_dir }}/clean_cache\"\n    state: touch\n  when: nexus_latest_version.changed and nexus_data_dir_contents.stdout != \"\"\n  tags:\n    # hard to run as a handler for time being\n    - skip_ansible_lint\n\n- meta: flush_handlers\n\n- name: Enable nexus service and make sure it is started\n  systemd:\n    name: nexus.service\n    enabled: yes\n    state: started\n    no_block: yes\n  notify:\n    - wait-for-nexus\n    - wait-for-nexus-port\n\n- meta: flush_handlers\n\n- name: Chown configuration files from {{ nexus_installation_dir }}/nexus-latest/etc back to root\n  file:\n    path: \"{{ nexus_installation_dir }}/nexus-latest/etc\"\n    owner: \"root\"\n    group: \"root\"\n    mode: a=rX,u+w\n    recurse: true\n  when: chown_config_first_time.changed\n  tags:\n    # hard to run as a handler for time being\n    - skip_ansible_lint\n\n- name: Prevent nexus to create any new configuration files in  {{ nexus_installation_dir }}/nexus-latest/etc\n  file:\n    path: \"{{ item }}\"\n    state: \"directory\"\n    owner: \"root\"\n    group: \"root\"\n    mode: \"0755\"\n    recurse: false\n  with_items: \"{{ nexus_app_dir_settings_dirs }}\"\n\n- name: First-time install admin password\n  set_fact:\n    current_nexus_admin_password: 'admin123'\n  when: nexus_data_dir_contents.stdout == \"\"\n\n- name: Subsequent re-provision admin password\n  set_fact:\n    current_nexus_admin_password: \"{{ nexus_admin_password }}\"\n  when: nexus_data_dir_contents.stdout != \"\"\n  no_log: true\n\n- name: Create directory to hold current groovy scripts for reference\n  file:\n    path: \"{{ nexus_data_dir }}/groovy-raw-scripts/current\"\n    state: directory\n    owner: root\n    group: root\n\n- name: Upload new scripts\n  synchronize:\n    archive: no\n    checksum: yes\n    recursive: yes\n    delete: yes\n    mode: push\n    use_ssh_args: yes\n    src: \"files/groovy/\"\n    dest: \"{{ nexus_data_dir }}/groovy-raw-scripts/new/\"\n\n- name: Sync new scripts to old and get differences\n  shell: 'rsync -ric {{ nexus_data_dir }}/groovy-raw-scripts/new/ {{ nexus_data_dir }}/groovy-raw-scripts/current/ | cut -d\" \" -f 2 | sed \"s/\\.groovy//g\"'\n  register: nexus_groovy_files_changed\n  check_mode: no\n  changed_when: false\n  # simple check on changed files kept on host\n  # skip ansible lint (we don't want to use synchronize module for this)\n  args:\n    warn: false\n\n- name: Declare new or changed groovy scripts in nexus\n  include_tasks: declare_script_each.yml\n  with_items: \"{{ nexus_groovy_files_changed.stdout_lines}}\"\n"}, {"commit_sha": "7032aee7df1c2c6e96795067285efa3b2a6de32e", "sha": "2e09e17f7b329815a0ad086f8881d811174e981b", "filename": "playbooks/dns_records.yaml", "repository": "openshift/openshift-ansible-contrib", "decoded_content": "---\n  - name: \"Creating DNS records\"\n    template:\n      dest: \"/tmp/records.yaml\"\n      src: \"./playbooks/templates/records.template.yaml\"\n      force: yes\n    delegate_to: localhost\n\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "810840529b4e2767eafd60666c3bba187ad36ee6", "filename": "tasks/create_repo_raw_group_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_raw_group\n    args: \"{{ _nexus_repos_raw_defaults|combine(item) }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "9b65895a55df26a980d24bb890df14743d817d4b", "filename": "roles/activity-server/files/lang_templates/es/page", "repository": "iiab/iiab", "decoded_content": "<!DOCTYPE html>\n<META http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n<body>\n<h1 id=\"olpc-activity-group-name\">Actividades disponibles localmente</h1>\n<p id=\"olpc-activity-group-desc\">Estas actividades est\u00e1n almacenads en el servidor de la escuela.</p>\n%(activities)s\n</body>\n</html>\n"}, {"commit_sha": "64cbc6946b7ebc0d9a36f40d77ac86f8e3564499", "sha": "55ed1dae697ed0262760ccbe8737a3dd894660a1", "filename": "tasks/common.yml", "repository": "CSCfi/ansible-role-slurm", "decoded_content": "---\n# This sh/could be put in a separate role..\n  - name: Add FGI slurm repo\n    template: src=fgislurm.repo dest=/etc/yum.repos.d/fgislurm.repo owner=root group=root mode=0644 backup=yes\n    when: fgci_install == True\n\n  - name: Import FGI slurm repo key\n    rpm_key: key=http://idris.fgi.csc.fi/fgirepo6/RPM-GPG-KEY-CSC-GRID-2 state=present\n    when: fgci_install == True\n\n  - name: Install FGCI repo\n    package: pkg=http://idris.fgi.csc.fi/fgci7/x86_64/fgci/rpms/fgci-release7-1-1.el7.noarch.rpm\n    when: ansible_distribution_major_version == \"7\" and fgci_install == True and ansible_os_family == \"RedHat\"\n\n##\n  - name: install common Slurm packages\n    package: name={{ item }} state=present\n    with_items: \"{{ slurm_packages }}\"\n    when: slurm_packages.0 != \"\"\n\n  - name: install fgci Slurm addons\n    package: name=slurm-fgi-addons state=present\n    when: fgci_install and ansible_distribution_major_version == \"7\"\n\n  - name: Copy pam.d/slurm\n    copy: src=pam_slurm dest=/etc/pam.d/slurm owner=root mode=0644\n\n  - name: Make from template cgroup.conf\n    template: src=cgroup.conf.j2 dest=/etc/slurm/cgroup.conf owner=root mode=0644 backup=yes\n    notify: restart slurm\n\n  - name: Make from template gres.conf\n    template: src=gres.conf.j2 dest=/etc/slurm/gres.conf owner=root mode=0644\n    notify: restart slurm\n\n  - name: Make from template topology.conf\n    template: src=topology.conf.j2 dest=/etc/slurm/topology.conf owner=root moder=0644\n    notify: restart slurm\n    when: slurm_topology_plugin is defined\n\n  - name: Make from template slurm.conf\n    template: src=slurm.conf.j2 dest=/etc/slurm/slurm.conf owner=root mode=0644 backup=yes\n    notify: restart slurm\n\n  - name: write all slurm logs handled by rsyslog to one file\n    template: src=slurm_rsyslog.conf dest=/etc/rsyslog.d/10_slurm_rsyslog.conf owner=root mode=0644 backup=yes\n    notify: Restart rsyslog\n    when: slurm_manage_rsyslog_conf\n\n  - name: configure logrotate to rotate slurm_logs in slurm_log_dir\n    template: src=slurm_logrotate.j2 dest=/etc/logrotate.d/slurm owner=root mode=0644 backup=no\n    when: slurm_log_dir is defined\n\n  - name: template in plugstack.conf\n    template: src=plugstack.conf.j2 dest=/etc/slurm/plugstack.conf owner=root mode=0644 backup=yes\n    when: slurm_plugstack\n\n  - name: create slurm/plugstack.conf.d\n    file: path=/etc/slurm/plugstack.conf.d state=directory owner=root group=root mode=0755\n    when: slurm_plugstack\n\n  - name: template in plugstack.conf.d/x11.conf\n    template: src=x11.conf.j2 dest=/etc/slurm/plugstack.conf.d/x11.conf owner=root mode=0644 backup=no\n    when: slurm_plugstack and slurm_x11_spank\n\n  - name: install slurm-spank-x11 and xauth\n    package: name={{ item }} state=present\n    with_items: \"{{\u00a0slurm_spank_x11_packages }}\"\n    when: slurm_plugstack and slurm_x11_spank\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "37e94bf6963098df4382a19c4006c7df262cf801", "filename": "roles/idm/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- hosts: idm\n  become: yes\n\n  roles:\n    - idm\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "ea7c2e0535b95fac5641fd7e8efd5f0a82747b8a", "filename": "roles/manage-sshd-config/tasks/sshd-update.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: \"Update sshd_config with provided values\" \n  lineinfile:\n    path: /etc/ssh/sshd_config\n    backup: yes\n    regexp: '^{{ item.key }}'\n    line: '{{ item.key }} {{ item.value }}'\n  notify: 'reload sshd'\n  with_dict: \"{{ update_sshd_config | default({}) }}\"\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "86b71450d6f7239414f86413b352d4fa33b6d87a", "filename": "roles/idm-host-cert/tasks/generate-csr.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Generate the private Key and a CSR\"\n  generate_csr:\n    country: \"{{ csr_country }}\"\n    state: \"{{ csr_state }}\"\n    location: \"{{ csr_location }}\"\n    org_name: \"{{ csr_org_name }}\"\n    org_unit: \"{{ csr_org_unit }}\"\n    common_name: \"{{ host_name }}\"\n    email: \"{{ csr_email }}\"\n  register: csr_content\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "84c893a11d70fb2beae588f9032d80c787cf6576", "filename": "roles/client/handlers/main.yml", "repository": "trailofbits/algo", "decoded_content": "---\n  \n- name: restart strongswan\n  service: name=strongswan state=restarted\n"}, {"commit_sha": "f92ebbef856e59bd4563d4b5b69ee75a95ec89d5", "sha": "9ac5bf2f38f9bef2e98559c7afd6325c21ab3d22", "filename": "roles/openshift-labels/tasks/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n- name: \"Set defaults\"\n  set_fact:\n    target_namespace: \"{{ target_namespace | default('') }}\"\n\n- name: \"Apply label {{ label }} to object {{ target_object }}\"\n  command: >\n    oc label --overwrite {{ target_object }} {{ target_name }} {{ label }} {{ target_namespace }}\n  when:\n  - target_object is defined\n  - target_object|trim != ''\n  - target_name is defined\n  - target_name|trim != ''\n  - label is defined\n  - label| trim != ''\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "d39ba3412bc5573a8a1be1cd214aef0a70cb3cc3", "filename": "roles/config-quay-enterprise/tasks/configure_systemd.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Configure systemd environment files\n  template:\n    src: \"{{ item.src }}\"\n    dest: \"{{ item.dest }}\"\n  notify: \"Restart quay service\"\n  with_items:\n    - { src: quay.j2, dest: \"{{ systemd_environmenfile_dir}}/{{ quay_name }}\" }\n    - { src: postgresql.j2, dest: \"{{ systemd_environmenfile_dir}}/{{ postgresql_name }}\" }\n    - { src: redis.j2, dest: \"{{ systemd_environmenfile_dir}}/{{ redis_name }}\" }\n\n- name: Configure systemd unit files\n  template:\n    src: \"{{ item.src }}\"\n    dest: \"{{ item.dest }}\"\n  notify: \"Restart quay service\"\n  with_items:\n    - { src: quay.service.j2, dest: \"{{ systemd_service_dir}}/{{ quay_service }}\" }\n    - { src: postgresql.service.j2, dest: \"{{ systemd_service_dir}}/{{ postgresql_service }}\" }\n    - { src: redis.service.j2, dest: \"{{ systemd_service_dir}}/{{ redis_service }}\" }\n"}, {"commit_sha": "abafe1581c6c78d784cf215b214947675d49eff8", "sha": "aeed994b568e5bf08b9cfd01ce8421ca57d51e36", "filename": "roles/vpn/tasks/iptables.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- name: Iptables configured\n  template: src=\"{{ item.src }}\" dest=\"{{ item.dest }}\" owner=root group=root mode=0640\n  with_items:\n    - { src: rules.v4.j2, dest: /etc/iptables/rules.v4 }\n    - { src: rules.v6.j2, dest: /etc/iptables/rules.v6 }\n  notify:\n    - restart iptables\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "6a5e8766baca1aa1fd59d8d98f21bad943e01e66", "filename": "roles/idm-host-cert/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: \"idm-login.yml\"\n\n- import_tasks: \"register-host.yml\"\n\n- import_tasks: \"generate-csr.yml\"\n\n- import_tasks: \"create-host-cert.yml\"\n\n- import_tasks: \"retrieve-ca-cert.yml\"\n\n- import_tasks: \"write-certs-to-file.yml\"\n\n- import_tasks: \"print-certs.yml\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "3c3bb2994df152130839e4801dbd751d65651ab0", "filename": "roles/sugar-stats/templates/statistics-consolidation/stats-consolidation.logrotate", "repository": "iiab/iiab", "decoded_content": "/var/log/statistics-consolidation/stats-consolidation.log {\n    daily\n    rotate 5\n    weekly\n    missingok\n    create 0600 sugar-stats sugar-stats\n    notifempty\n\t\tcompress\n}\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "55dedee1a57e31b2ae1c9069266efa98ac5c8f93", "filename": "roles/pathagar/meta/main.yml", "repository": "iiab/iiab", "decoded_content": "---\ndependencies:\n    - { role: postgresql }\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "62bb4afded559cbf75ec492463a6964b072d6a6f", "filename": "roles/idm-host-cert/tasks/idm-login.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Login and create a session with the IdM\"\n  uri:\n    url: \"https://{{ idm_fqdn }}/ipa/session/login_password\"\n    method: POST\n    body: \"user={{ idm_user }}&password={{ idm_password }}\"\n    validate_certs: no\n    headers:\n      Content-Type: \"application/x-www-form-urlencoded\"\n  register: idm_session\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "25c38471730781bb4a47a7b7171a4c05e9837756", "filename": "roles/iiab-admin/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- include: admin-user.yml\n  tags:\n    - base\n  when: not no_admin is defined\n\n- include: access.yml\n  tags:\n    - base\n\n- name: Add iiab-admin parameters to ini file\n  ini_file: dest='{{ service_filelist }}'\n            section=iiab-admin\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: iiab-admin\n    - option: description\n      value: '\"Admin User\"'\n    - option: iiab_admin_user\n      value: \"{{ iiab_admin_user }}\"\n\n- name: Set up to issue warning if iiab-admin password is still default\n  template: src=profile_ssh_warn.sh\n            dest=/etc/profile.d/\n\n- name: Is this LXDE?\n  stat: path=/home/pi/.config/lxsession\n  register: lx\n\n- name: Do the same if running on raspbian\n  template: src=lxde_ssh_warn.sh\n            dest=/home/pi/.config/lxsession/LXDE-pi/\n  when: lx.stat.isdir is defined and lx.stat.isdir and is_rpi and is_debuntu\n\n- name: put a autostart line to check for default password in LXDE\n  lineinfile: line=@/home/pi/.config/lxsession/LXDE-pi/lxde_ssh_warn.sh\n              dest=/home/pi/.config/lxsession/LXDE-pi/autostart\n  when: lx.stat.isdir is defined and lx.stat.isdir and is_rpi and is_debuntu\n"}, {"commit_sha": "481f7ad18dc225973e1d676d33e58c49cbbfe986", "sha": "7c27526590c12f96f3851875327e870dfb4aa810", "filename": "tasks/yum.yml", "repository": "openwisp/ansible-openwisp2", "decoded_content": "---\n\n- name: Install epel-release (if RedHat/Centos)\n  when: ansible_distribution in ['RedHat', 'CentOS']\n  yum: name=epel-release state=latest\n  notify: reload systemd\n\n- name: Install system packages\n  package: name={{ item }} state=latest\n  notify: \n    - reload systemd\n    - start redis\n  with_items:\n    - sudo\n    - gcc\n    - supervisor\n    - nginx\n    - openssl\n    - openssl-devel\n    - libffi-devel\n    - python-devel\n    - redis\n    - libsemanage-python\n    - policycoreutils-python\n    - redhat-rpm-config\n\n# On the newer versions of redis, by default redis\n# binds to localhost on ipv6 address which wouldn't\n# let the service start if the server doesn't have\n# ipv6 enabled. Hence, we set redis to listen on ipv4\n- name: set redis to listen on ipv4 (RedHat & CentOS)\n  notify: start redis\n  lineinfile:\n    path: /etc/redis.conf\n    regexp: '^bind 127\\.0\\.0\\.1 ::1'\n    line: 'bind 127.0.0.1'\n    backrefs: yes\n\n- name: Install firewall packages\n  package: name={{ item }} state=present\n  notify: reload systemd\n  with_items:\n    - python-firewall\n    - firewalld\n  when: ansible_distribution_major_version|int >= 7\n\n- name: Install spatialite\n  when: openwisp2_database.engine == \"django.contrib.gis.db.backends.spatialite\"\n  package: name={{ item }} state=latest\n  notify: reload systemd\n  with_items:\n    - sqlite\n    - gdal\n    - proj-devel\n    - geos-devel\n    - libspatialite-devel\n\n- name: ensure supervisor is started\n  service: name=supervisord state=started enabled=yes\n\n- name: ensure nginx is enabled\n  service: name=nginx enabled=yes\n\n- name: Install python2 packages\n  when: openwisp2_python in [\"python2.7\", \"python2\"]\n  package: name={{ item }} state=latest\n  with_items:\n    - python-pip\n    - python-virtualenv\n\n- name: Install python3 packages\n  when: openwisp2_python == \"python3\"\n  package: name={{ item }} state=latest\n  with_items:\n    - \"{{ python3_package_prefix }}\"\n    - \"{{ python3_package_prefix }}-pip\"\n    - \"{{ python3_package_prefix }}-devel\"\n\n- name: Install python wheel (optional, allowed to fail)\n  ignore_errors: yes\n  package: name={{ item }} state=latest\n  with_items:\n    - python-wheel\n    - \"{{ python3_package_prefix }}-wheel\"\n\n- name: Install python3 virtualenv\n  when: openwisp2_python == \"python3\" and ansible_distribution == 'Fedora'\n  package:\n    name: \"{{ python3_package_prefix }}-virtualenv\"\n    state: latest\n\n- name: (CentOS/RedHat) Always install pip\n  when: ansible_distribution in ['RedHat', 'CentOS']\n  package:\n    name: python-pip\n    state: latest\n\n- name: (CentOS/RedHat/Fedora) Install/upgrade virtualenv via pip\n  pip:\n    name: virtualenv\n    state: latest\n\n- name: Install ntp\n  when: openwisp2_install_ntp\n  package:\n    name: ntp\n    state: latest\n"}, {"commit_sha": "96adc61e360141bb718b75d48c387b3680a8471b", "sha": "1cd33a375e479ddd832bb7effbfdf000c29907d0", "filename": "tasks/bug-tweaks.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "# Configuration to avoid 'Device or resource busy'\n- block:\n  - name: Stat /proc/sys/fs/may_detach_mounts (CentOS/RedHat)\n    stat:\n      path: /proc/sys/fs/may_detach_mounts\n    register: may_detach_mounts\n\n  - name: Ensure fs.may_detach_mounts is set to avoid 'Device or resource busy' (CentOS/RedHat)\n    sysctl:\n      name: fs.may_detach_mounts\n      value: 1\n      sysctl_file: /etc/sysctl.d/99-docker.conf\n      reload: yes\n    become: yes\n    when: may_detach_mounts.stat.exists\n\n  # Keep for compatibility reasons of this role. Now everything is in the same file.\n  - name: Remove systemd drop-in for Docker Mount Flags slave configuration (CentOS/RedHat)\n    file:\n      path: /etc/systemd/system/docker.service.d/mountflags-slave.conf\n      state: absent\n    become: yes\n    notify: restart docker\n\n  - name: Set systemd service MountFlags option to \"slave\" to prevent \"device busy\" errors on CentOS/RedHat 7.3 kernels (CentOS/RedHat)\n    set_fact:\n      docker_systemd_service_config_tweaks: \"{{ docker_systemd_service_config_tweaks + _systemd_service_config_tweaks }}\"\n    vars:\n      _systemd_service_config_tweaks:\n        - 'MountFlags=slave'\n  when:\n    - _docker_os_dist == \"CentOS\" or _docker_os_dist == \"RedHat\"\n    - docker_enable_mount_flag_fix | bool\n    - ansible_kernel | version_compare('4', '<')\n"}, {"commit_sha": "4e46e9eb277bc88f285dbc9dd980193e57f7bf48", "sha": "f15b95e43a7f730317eb0f3eae7ee364e0a4a18e", "filename": "tasks/bug-tweaks.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "# Configuration to avoid 'Device or resource busy'\n- block:\n  - name: Stat /proc/sys/fs/may_detach_mounts (CentOS/RedHat)\n    stat:\n      path: /proc/sys/fs/may_detach_mounts\n    register: may_detach_mounts\n\n  - name: Ensure fs.may_detach_mounts is set to avoid 'Device or resource busy' (CentOS/RedHat)\n    sysctl:\n      name: fs.may_detach_mounts\n      value: 1\n      sysctl_file: /etc/sysctl.d/99-docker.conf\n      reload: yes\n    become: yes\n    when: may_detach_mounts.stat.exists\n  \n  # Keep for compatibility reasons of this role. Now everything is in the same file.\n  - name: Remove systemd drop-in for Docker Mount Flags slave configuration (CentOS/RedHat)\n    file:\n      path: /etc/systemd/system/docker.service.d/mountflags-slave.conf\n      state: absent\n    become: yes\n    notify: restart docker\n\n  - name: Set systemd service MountFlags option to \"slave\" to prevent \"device busy\" errors on CentOS/RedHat 7.3 kernels (CentOS/RedHat)\n    set_fact:\n      docker_systemd_service_config_tweaks: \"{{ docker_systemd_service_config_tweaks + _systemd_service_config_tweaks }}\"\n    vars:\n      _systemd_service_config_tweaks:\n        - 'MountFlags=slave'\n  when:\n    - _docker_os_dist == \"CentOS\" or _docker_os_dist == \"RedHat\"\n    - docker_enable_mount_flag_fix | bool\n    - ansible_kernel | version_compare('4', '<')\n\n\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "8733fdb3d07b1fb54cf3300742b2d149aaaf1568", "filename": "playbooks/files/stenoread", "repository": "rocknsm/rock", "decoded_content": "#!/bin/bash\n# Copyright 2014 Google Inc. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nif [ \"$#\" -lt 1 ]; then\n  cat >&2 <<EOF\n$0 provides a simple method for reading logs out of stenographer.\nIts first argument is the query to send to stenographer, all other arguments\nare passed to TCPDump.\n\nExamples:\n # Print all packets for source IP 1.1.1.1 without DNS resolution (-n).\n $0 'host 1.1.1.1' -n src host 1.1.1.1\n # Print all PSH packets between 1.1.1.1 and 2.2.2.2:\n $0 'host 1.1.1.1 and host 2.2.2.2' -n 'tcp[tcpflags] & tcp-push != 0'\n # Write all packets between 1.1.1.1 and 2.2.2.2 to disk.\n'host 1.1.1.1 and host 2.2.2.2' -w /tmp/out.pcap\n\nSee README.md for more details on the Stenographer query language.\n\nSet the STENOGRAPHER_CONFIG environmental variable to point to your stenographer\nconfig if it's in a nonstandard place (defaults to /etc/stenographer/config).\n\n$0 arguments are given before the filter.  These include:\n  --limit-bytes X    :  Stop output once we've exceeded X bytes\n  --limit-packets X  :  Stop output once we've exceeded X packets\n\nFor example:\n  # Print first 6 packets or 2K bytes, whichever comes first,\n  # from source IP 1.1.1.1\n  $0 --limit-packets 6 --limit-bytes 2048 'host 1.1.1.1'\nEOF\n  exit 1\nfi\n\nHEADERS=\"\"\nwhile true; do\n  case \"$1\" in\n    --limit-packets)\n      HEADERS=\"$HEADERS --header Steno-Limit-Packets:$2\"\n      shift 2\n      ;;\n    --limit-bytes)\n      HEADERS=\"$HEADERS --header Steno-Limit-Bytes:$2\"\n      shift 2\n      ;;\n    *)\n      STENOQUERY=\"$1\"\n      shift\n      break\n      ;;\n  esac\ndone\n\nTCPDUMP=$(PATH=$PATH:/usr/local/sbin:/usr/sbin:/sbin which tcpdump)\nSTENOCURL=$(PATH=$(dirname \"$0\"):$PATH which stenocurl)\n\nSTENOGRAPHER_CONFIG_BASE=/etc/stenographer/config.\nINTERFACES=$(ls ${STENOGRAPHER_CONFIG_BASE}* | awk -F. '{ print $2 }')\nOUT=$(mktemp -d /tmp/stenoread.XXXXXXXXXX) || { echo \"Failed to create temp file\"; exit 1; }\n\necho \"Running stenographer query '$STENOQUERY', piping to 'tcpdump $@'\" >&2\n\nfor IFACE in ${INTERFACES[@]}\ndo\n  STENOGRAPHER_CONFIG=\"${STENOGRAPHER_CONFIG_BASE}${IFACE}\"\n  \"$STENOCURL\" /query \\\n    -d \"$STENOQUERY\" \\\n    --silent \\\n    --max-time 890 \\\n    --show-error $HEADERS |\n    \"$TCPDUMP\" -r /dev/stdin -s 0 -w ${OUT}/${IFACE}.pcap  &>/dev/null\ndone\n\nmergecap -w - ${OUT}/*.pcap | tcpdump -r /dev/stdin -s 0 \"$@\"\nrm -rf ${OUT}\n\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "bfb6ca8afb5e58e832b1d9b5d012bfde716461f7", "filename": "tasks/create_repo_rubygems_proxy_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_rubygems_proxy\n    args: \"{{ _nexus_repos_rubygems_defaults|combine(item) }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "d66cc6877e74d345ed510e3e5ef1cbdc1a8d4e1b", "filename": "roles/2-common/templates/local.repo", "repository": "iiab/iiab", "decoded_content": "[iiab-local]\nname=iiab-local\nbaseurl=file://{{ yum_packages_dir }}\nenabled=1\ngpgcheck=0\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "0af30dfc4abfb993c73b4768c139b530b8e1ef1b", "filename": "roles/proxy/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: Gather Facts\n  setup:\n\n- name: Privoxy installed\n  apt: name=privoxy state=latest\n\n- name: Privoxy configured\n  template: src=\"{{ item.src }}\" dest=\"{{ item.dest }}\"\n  with_items:\n    - { src: privoxy_config.j2, dest: /etc/privoxy/config }\n    - { src: default.filter.j2, dest: /etc/privoxy/default.filter }\n  notify:\n    - restart privoxy\n\n- name: Privoxy profile for apparmor configured\n  template: src=usr.sbin.privoxy.j2 dest=/etc/apparmor.d/usr.sbin.privoxy owner=root group=root mode=0600\n  when: apparmor_enabled is defined and apparmor_enabled == true\n  notify:\n    - restart privoxy\n\n- name: Enforce the privoxy AppArmor policy\n  shell: aa-enforce usr.sbin.privoxy\n  when: apparmor_enabled is defined and apparmor_enabled == true\n  tags: ['apparmor']\n\n- name: Ensure that the privoxy service directory exist\n  file: path=/etc/systemd/system/privoxy.service.d/ state=directory mode=0755  owner=root group=root\n\n- name: Setup the cgroup limitations for the privoxy daemon\n  template: src=privoxy_100-CustomLimitations.conf.j2 dest=/etc/systemd/system/privoxy.service.d/100-CustomLimitations.conf\n  notify:\n    - daemon-reload\n    - restart privoxy\n\n- meta: flush_handlers\n\n- name: Privoxy enabled and started\n  service: name=privoxy state=started enabled=yes\n\n# PageSpeed\n\n- name: Apache installed\n  apt: name=apache2 state=latest\n\n- name: PageSpeed installed for x86_64\n  apt: deb=https://dl-ssl.google.com/dl/linux/direct/mod-pagespeed-stable_current_amd64.deb\n  when: ansible_architecture == \"x86_64\"\n\n- name: PageSpeed installed for i386\n  apt: deb=https://dl-ssl.google.com/dl/linux/direct/mod-pagespeed-stable_current_i386.deb\n  when: ansible_architecture != \"x86_64\"\n\n- name: PageSpeed configured\n  template: src=pagespeed.conf.j2 dest=/etc/apache2/mods-available/pagespeed.conf\n  notify:\n    - restart apache2\n\n- name: Modules enabled\n  apache2_module: state=present name=\"{{ item }}\"\n  with_items:\n    - proxy_http\n    - pagespeed\n    - cache\n    - proxy_connect\n    - proxy_html\n    - rewrite\n  notify:\n    - restart apache2\n\n- name: VirtualHost configured for the PageSpeed module\n  template: src=000-default.conf.j2 dest=/etc/apache2/sites-enabled/000-default.conf\n  notify:\n    - restart apache2\n\n- name: Apache ports configured\n  template: src=ports.conf.j2 dest=/etc/apache2/ports.conf\n  notify:\n    - restart apache2\n\n- name: Ensure that the apache2 service directory exist\n  file: path=/etc/systemd/system/apache2.service.d/ state=directory mode=0755  owner=root group=root\n\n- name: Setup the cgroup limitations for the apache2 daemon\n  template: src=apache2_100-CustomLimitations.conf.j2 dest=/etc/systemd/system/apache2.service.d/100-CustomLimitations.conf\n  notify:\n    - daemon-reload\n    - restart apache2\n\n- meta: flush_handlers\n\n- name: Set facts for mobileconfigs\n  set_fact:\n    proxy_enabled: true\n\n- name: Register p12 PayloadContent\n  shell: >\n    cat /{{ easyrsa_dir }}/easyrsa3//pki/private/{{ item }}.p12 | base64\n  register:  PayloadContent\n  with_items: \"{{ users }}\"\n\n- name: Register CA PayloadContent\n  shell: >\n    cat /{{ easyrsa_dir }}/easyrsa3/pki/ca.crt | base64\n  register:  PayloadContentCA\n\n- name: Build the mobileconfigs\n  template: src=roles/vpn/templates/mobileconfig.j2 dest=/{{ easyrsa_dir }}/easyrsa3//pki/private/{{ item.0 }}_proxy.mobileconfig mode=0600\n  with_together:\n    - \"{{ users }}\"\n    - \"{{ PayloadContent.results }}\"\n  no_log: True\n\n- name: Fetch users mobileconfig\n  fetch: src=/{{ easyrsa_dir }}/easyrsa3//pki/private/{{ item }}_proxy.mobileconfig dest=configs/{{ IP_subject_alt_name }}_{{ item }}_proxy.mobileconfig flat=yes\n  with_items: \"{{ users }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "7b879f8cd4ab0c6974a33e633a5d2df1bb2fa315", "filename": "playbooks/provision-idm-server/README.md", "repository": "redhat-cop/infra-ansible", "decoded_content": "# IdM Server playbook\n\nThis playbooks runs through the steps to provision a VM, set it up, configure DNS records, and install IdM.\nCurrently it is configured to provision OpenStack resources, but other providers can easily be added.\n\n\n## Prerequisites\n\nFor hosting infrastructure, you will need one of the two:\n- a set of running instance(s)\n- a IaaS that allow for provisioning through these playbooks\n\nYou must have a working DNS server which accepts \"nsupdate\" connections for the IdM VMs forward and reverse DNS records to be added/updated to the existing DNS zones. For this, you will need the DNS zone key names, key secrets, and key algorithms.\n\n## Example\n\n### Inventory\n\nPlease see the **sample** inventory in the inventory area:\n\n- [IdM-server](../../inventory/idm-server/README.md)\n\n\nYou will need to modify this sample inventory to fit your desired configuration, including information from your DNS server such as the key names, secrets, and more.\n\n\n### Playbook execution\n\nDepending on how this is being hosted, the initial may need the `tags='install'` set to ensure all necessary software is installed:\n\n```bash\n> ansible-playbook -i inventory main.yml --tags='install'\n```\n\nAny consecutive runs can be done without the 'install' tag to speed up execution:\n```bash\n> ansible-playbook -i inventory main.yml\n```\n\nLicense\n-------\n\nApache License 2.0\n\n\nAuthor Information\n------------------\n\nRed Hat Community of Practice & staff of the Red Hat Open Innovation Labs.\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "d61f391e2130113010f09c394e64ff1ba353f5e2", "filename": "playbooks/roles/check_dns/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- name: Check DNS resolution for OpenShift API endpoint. If fails if it's not resolved OK.\n  command: nslookup \"{{api_dns}}\"\n  ignore_errors: yes\n  register: api_ns\n  changed_when: false\n- name: Check DNS resolution for OpenShift apps subdomain. If fails if it's not resolved OK.\n  command: nslookup apps.\"{{apps_dns}}\"\n  ignore_errors: yes\n  register: apps_ns\n  changed_when: false\n- debug:\n    msg: \"{{api_dns}} resolved to {{api_ns.stdout}}\"\n  failed_when: \"'server can\\\\'t find' in api_ns.stdout\"\n- debug:\n    msg: \"apps.{{apps_dns}} resolved to {{apps_ns.stdout}}\"\n  failed_when: \"'server can\\\\'t find' in apps_ns.stdout\"\n- name: Figure out DNS server from NetworkManager\n  shell: \"for uuid in `nmcli -g UUID connection show --active`; do  dns=`nmcli -g ipv4.dns,IP4.DNS connection show $uuid`; if [ -n $dns ]; then echo $dns;  break; fi; done\"\n  register: nm_nameserver\n  changed_when: false\n  ignore_errors: true\n- debug:\n    msg: \"Your nameserver DNS is '{{nm_nameserver.stdout}}'\"\n  failed_when: nm_nameserver == ''\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "0a9b5156677b47deb5e1d06ddb35e01a7322439b", "filename": "roles/nfs-server/tasks/lvm.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Check if LV has been created and mounted\"\n  shell: \"lsblk {{ nfs_storage_device }} | egrep 'lvm.*/exports'\"\n  register: lvm_check\n  ignore_errors: yes\n\n- include_tasks: configure_lvm.yml\n  when: lvm_check.rc != 0\n"}, {"commit_sha": "b7c6bfe0369646ca69beeb3dfe07e8218d61c940", "sha": "dea4c96e2a5efed550d7a14f6dfb5fff5ebcdd56", "filename": "tasks/minimize_access.yml", "repository": "dev-sec/ansible-os-hardening", "decoded_content": "---\n# Using a two-pass approach for checking directories in order to support symlinks.\n- name: find directories for minimizing access\n  stat:\n    path: '{{ item }}'\n  register: minimize_access_directories\n  with_items:\n    - '/usr/local/sbin'\n    - '/usr/local/bin'\n    - '/usr/sbin'\n    - '/usr/bin'\n    - '/sbin'\n    - '/bin'\n    - '{{ os_env_extra_user_paths }}'\n\n- name: minimize access\n  file:\n    path: '{{ item.stat.path }}'\n    mode: 'go-w'\n    recurse: 'yes'\n  when: item.stat.isdir\n  with_items: '{{ minimize_access_directories.results }}'\n\n- name: change shadow ownership to root and mode to 0600 | os-02\n  file:\n    dest: '/etc/shadow'\n    owner: '{{ os_shadow_perms.owner }}'\n    group: '{{ os_shadow_perms.group }}'\n    mode: '{{ os_shadow_perms.mode }}'\n\n- name: change passwd ownership to root and mode to 0644 | os-03\n  file:\n    dest: '/etc/passwd'\n    owner: '{{ os_passwd_perms.owner }}'\n    group: '{{ os_passwd_perms.group }}'\n    mode: '{{ os_passwd_perms.mode }}'\n\n- name: change su-binary to only be accessible to user and group root\n  file:\n    dest: '/bin/su'\n    owner: 'root'\n    group: 'root'\n    mode: '0750'\n  when: os_security_users_allow != None\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "3a6fc6d26673482bba773ac8ea3b1d155f6d84de", "filename": "roles/network/templates/dhcp/dhcpd.service", "repository": "iiab/iiab", "decoded_content": "[Unit]\nDescription=DHCPv4 Server Daemon\nAfter=syslog.target network.target\n\n[Service]\nEnvironmentFile=/etc/sysconfig/dhcpd\nExecStart=/usr/sbin/dhcpd -f --no-pid $DHCPDARGS\n\n[Install]\nWantedBy=multi-user.target\n"}, {"commit_sha": "96adc61e360141bb718b75d48c387b3680a8471b", "sha": "3f09e68f137afe4fab5d79ea6166e3c17bce20c9", "filename": "tasks/install-docker.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Set docker-ce package state to latest\n  set_fact:\n    docker_pkg_state: 'latest'\n  when: docker_latest_version|bool\n\n- name: Ensure docker-ce is installed\n  package:\n    name: \"{{ docker_pkg_name }}\"\n    state: \"{{ docker_pkg_state|default('present') }}\"\n  become: true\n  notify: restart docker\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "6610d9dc2bb4327d108ddede2e5538afd6c5804b", "filename": "roles/awstats/tasks/install.yml", "repository": "iiab/iiab", "decoded_content": "- name: Install awstats package\n  package: name={{ item }}\n           state=present\n  with_items:\n    - awstats\n    - pwauth\n    - openssl\n  tags:\n    - download\n\n- name: Install awstats package\n  package: name={{ item }}\n           state=present\n  with_items:\n    - libapache2-mod-authnz-external\n    - apache2-utils\n  when: is_debuntu\n  tags:\n    - download\n\n- name: enable cgi execution\n  command: a2enmod cgi\n  when: is_debuntu\n\n- name: Create directory for awstat to use as intermediate summary storage\n  file: path={{ item }}\n        mode=0750\n        owner={{ apache_user }}\n        group={{ apache_user }}\n        state=directory\n        force=true\n  with_items:\n    - \"{{ awstats_data_dir }}\"\n    - \"{{ apache_log_dir }}\"\n\n- name: Install the Apache config for Advanced Web Statistics\n  template: src=apache.conf\n            dest=/etc/{{ apache_config_dir }}/awstats.conf\n            owner=root\n            group=root\n            mode=0644\n  when: awstats_enabled and is_debuntu\n\n- name: Install the Apache config for Advanced Web Statistics\n  template: src=apache-awstats.conf\n            dest=/etc/{{ apache_config_dir }}/awstats.conf\n            owner=root\n            group=root\n            mode=0644\n  when: awstats_enabled and not is_debuntu\n\n- name: make sure logrotate does not make logs unreadable\n  template: src=logrotate.d.apache2\n            dest=/etc/logrotate.d/apache2\n  when: is_debuntu\n\n- name: See if awstats package installed a config file\n  stat: path=/etc/awstats/awstats.conf\n  register: awstats\n\n\n- name: If there was a config file installed by package, move it aside\n  command: mv /etc/awstats/awstats.conf /etc/awstats/awstats.conf.dist\n  when: awstats.stat.islnk is defined and not awstats.stat.islnk\n\n- name: Enable Awstats\n  file: src=/etc/apache2/sites-available/awstats.conf\n        path=/etc/apache2/sites-enabled/awstats.conf\n        state=link\n  when: awstats_enabled and is_debuntu\n\n- name: Disable Awstats\n  file: path=/etc/apache2/sites-enabled/awstats.conf\n        state=absent\n  when: not awstats_enabled and is_debuntu\n\n- name: Install the awstats config for Advanced Web Statistics\n  template: src=awstats.schoolserver.conf.j2\n            dest=/etc/awstats/awstats.schoolserver.conf\n            owner=root\n            group=root\n            mode=0644\n  when: awstats_enabled\n\n- name: Create a symbolic link to use when access is by ip address\n  file: src=/etc/awstats/awstats.schoolserver.conf\n        dest=/etc/awstats/awstats.conf\n        state=link\n  when: awstats_enabled\n\n- name: On first enabling of awstats, summarize httpd logs up to now\n  shell: /bin/perl /usr/share/awstats/wwwroot/cgi-bin/awstats.pl -config=schoolserver -update\n  when: awstats_enabled and not is_debuntu\n\n- name: On first enabling of awstats, summarize httpd logs up to now\n  shell: /usr/bin/perl /usr/lib/cgi-bin/awstats.pl -config=schoolserver -update\n  when: awstats_enabled and is_debuntu\n"}, {"commit_sha": "2378736112ce798a1b1b6e66f372415b01cd5536", "sha": "f745b77d182b66c40331ad1d5d7393c63f88d31c", "filename": "handlers/main.yml", "repository": "CSCfi/ansible-role-cuda", "decoded_content": "---\n\n- name: ZZ CUDA Restart server\n  command: sleep 2 && /sbin/shutdown -r now \"Node software upgrade reboot\"\n  async: 1\n  poll: 0\n  ignore_errors: true\n  when: cuda_packages_installation.changed and cuda_restart_node_on_install == True\n\n- name: ZZ CUDA Wait for server to restart\n  local_action: wait_for host=\"{{ ansible_ssh_host | default(inventory_hostname) }}\" \n                state=started \n                delay=30 \n                timeout=300\n  become: false\n  when: cuda_restart_node_on_install == True\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "be822a231c6bd04d702370d98e72435a5bdcd92a", "filename": "tasks/section_06_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 6.1 Ensure the X Window system is not installed (Scored)\n    apt: name=xserver-xorg-core* purge=yes state=absent\n    when: remove_xserver == True\n    tags:\n      - section6\n      - section6.1\n\n  - name: 6.2 Ensure Avahi Server is not enabled (check) (Scored)\n    stat: path='/etc/init/avahi-daemon.conf'\n    register: avahi_stat\n    tags:\n      - section6\n      - section6.2\n\n  - name: 6.2 Ensure Avahi Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on (filesystem'\n        state=present\n        regexp='start on \\(filesystem'\n        dest=/etc/init/avahi-daemon.conf\n    when: avahi_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.2\n\n  - name: 6.3 Ensure print server is not enabled (check) (Not Scored)\n    stat: path='/etc/init/cups.conf'\n    register: cups_stat\n    tags:\n      - section6\n      - section6.3\n\n  - name: 6.3 Ensure print server is not enabled (Not Scored)\n    lineinfile: >\n        line='#start on (filesystem'\n        state=present\n        regexp='start on \\(filesystem'\n        dest=/etc/init/cups.conf\n    when: cups_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.3\n\n  - name: 6.4.1 Ensure DHCP Server is not enabled (check) (Scored)\n    stat: path='/etc/init/isc-dhcp-server.conf'\n    register: dhcp_stat\n    tags:\n      - section6\n      - section6.4\n      - section6.4.1\n\n  - name: 6.4.1 Ensure DHCP Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n        dest=/etc/init/isc-dhcp-server.conf\n    when: dhcp_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.4\n      - section6.4.1\n\n  - name: 6.4.2 Ensure DHCP Server is not enabled (check) (Scored)\n    stat: path='/etc/init/isc-dhcp-server6.conf'\n    register: dhcp6_stat\n    tags:\n      - section6\n      - section6.4\n      - section6.4.2\n\n  - name: 6.4.2 Ensure DHCP Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n        dest=/etc/init/isc-dhcp-server6.conf\n    when: dhcp6_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.4\n      - section6.4.2\n\n  - name: 6.5.1 Configure Network Time Protocol (install) (NTP) (Scored)\n    apt: name=ntp state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.1\n\n  - name: 6.5.1 Check if /etc/ntp.conf file exists (stat)\n    stat:\n        path: /etc/ntp.conf\n    register: ntp_conf_file\n    tags:\n      - section6\n      - section6.5\n      - section6.5.1\n\n  - include: section_06_level1_05.yml\n    when: ntp_conf_file.stat.exists == True\n\n  - name: 6.6 Ensure LDAP is not enabled (Not Scored)\n    apt: name=slapd purge=yes state=absent\n    tags:\n      - section6\n      - section6.6\n\n  - name: 6.7.1 Ensure NFS and RPC are not enabled (stat) (Not Scored)\n    stat: path=/etc/init/rpcbind-boot.conf\n    register: nfs_rpc_rc\n    tags:\n      - section6\n      - section6.7\n      - section6.7.1\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (Not Scored)\n    lineinfile: >\n        dest=/etc/init/rpcbind-boot.conf\n        line='#start on virtual-filesystems and net-device-up IFACE=lo'\n        state=present\n        regexp='start on virtual-filesystems and net'\n    when: nfs_rpc_rc.stat.exists == True\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (check) (Not Scored)\n    command: dpkg -S nfs-kernel-server\n    changed_when: False\n    failed_when: False\n    register: nfs_present\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (rc.d) (Not Scored)\n    service: >\n        name=nfs-kernel-server\n        enabled=no\n    when: nfs_present is defined and nfs_present.rc == 0\n    register: nfs_service_result\n    failed_when: \"nfs_service_result|failed and 'service not found' not in nfs_service_result.msg\"\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.8-14 Ensure DNS,FTP,HTTP,IMAP,POP,Samba,Proxy,SNMP Servers are not enabled (Not Scored)\n    service: >\n        name={{ item }}\n        enabled=no\n    with_items:\n      - bind9\n      - vsftpd\n      - apache2\n      - dovecot\n      - smbd\n      - squid3\n      - snmpd\n    failed_when: False\n    tags:\n      - section6\n      - section6.8\n      - section6.9\n      - section6.10\n      - section6.11\n      - section6.12\n      - section6.13\n      - section6.14\n\n  - name: 6.15 Configure Mail Transfer Agent for Local-Only Mode (stat) (Scored)\n    stat: path=/etc/postfix/main.cf\n    register: postfix_main_cf\n    tags:\n      - section6\n      - section6.15\n\n  - name: 6.15 Configure Mail Transfer Agent for Local-Only Mode (Scored)\n    lineinfile: >\n        dest=/etc/postfix/main.cf\n        regexp='^inet_interfaces ='\n        line='inet_interfaces = localhost'\n        state=present\n    when: postfix_main_cf.stat.exists == True\n    tags:\n      - section6\n      - section6.15\n\n  - name: 6.16 Ensure rsync service is not enabled (stat) (Scored)\n    stat: path=/etc/default/rsync\n    register: default_rsync\n    tags:\n      - section6\n      - section6.16\n\n  - name: 6.16 Ensure rsync service is not enabled (Scored)\n    lineinfile: >\n        dest='/etc/default/rsync'\n        regexp='^RSYNC_ENABLE'\n        line='RSYNC_ENABLE=false'\n    when: default_rsync.stat.exists == True\n    tags:\n      - section6\n      - section6.16\n\n  - name: 6.17 Ensure Biosdevname is not enabled (Scored)\n    apt: name=biosdevname purge=yes state=absent\n    tags:\n      - section6\n      - section6.17\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "79ba969c36bbc58d88af77732defeffce6eb06a8", "filename": "tasks/Win32NT/fetch/zulu-fallback.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Fetch download page\n  win_uri:\n    url: \"{{ zulu_api_page }}\\\n      /bundles/latest/\\\n      ?version={{ java_major_version }}\\\n      &ext=zip&os=win&\\\n      arch={{ (java_arch == 'x64') | ternary('x64', 'x86') }}\"\n    return_content: true\n    follow_redirects: all\n  register: root_page\n\n- name: Set artifact checksum and url\n  set_fact:\n    artifact_url: >-\n      {{ (root_page.content | from_json).url }}\n    artifact_checksum: >-\n      {{ (root_page.content | from_json).md5_hash }}\n\n- name: 'Download artifact from {{ artifact_url }}'\n  win_get_url:\n    url: '{{ artifact_url }}'\n    dest: '{{ java_download_path }}'\n    force: true\n    checksum: '{{ artifact_checksum }}'\n    checksum_algorithm: '{{ checksum_alg }}'\n  register: file_downloaded\n  retries: 20\n  delay: 5\n  until: file_downloaded is succeeded\n  when: ansible_version.full is version('2.8.0', '>=')\n\n- name: Old fetch (Ansible < 2.8)\n  include_tasks: fetch_fallback_old.yml\n  when: ansible_version.full is version('2.8.0', '<')\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "b4fc2c4a2b32f6d0188224ea7f8972dfea3eb361", "filename": "roles/manage-sshd-config/test/inventory/group_vars/all.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n# needed to setup for the test conditions\nuser_name: root\nauthorized_keyfile: \"{{ inventory_dir }}/../authorized_keys\"\nkey_url: \"{{ lookup('file', authorized_keyfile) }}\"\n\nreset_keyfile: yes\nclear_text_password: test1234\n\n#needed to test the role\nupdate_sshd_config:\n  PermitRootLogin: \"without-password\"\n\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "2f541b895c727d09931f3befb99af4e0e46e0e3a", "filename": "playbooks/vm.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Create VM on infra virtual hosts'\n  hosts: infra_virt_hosts\n  roles:\n  - role: virt-install\n  tags:\n  - provision_infra_vms\n  \n- name: 'Check that the VM(s) are alive'\n  hosts: infra_vms\n  gather_facts: no\n  tasks:\n  - name: 'Wait for VM(s) to come alive'\n    local_action: wait_for\n    args: \n      host: \"{{ ansible_host }}\"\n      port: 22\n      delay: 30\n      timeout: 300\n  tags:\n  - vm_health_check\n\n- name: 'Subscribe the VMs to RHSM'\n  hosts: infra_vms\n  vars:\n    rhsm_username: \"{{ hostvars['localhost'].rhsm_username }}\"\n    rhsm_password: \"{{ hostvars['localhost'].rhsm_password }}\"\n  roles:\n  - role: rhsm\n  tags:\n  - configure_rhsm\n\n- name: 'Make sure the VM is running the latest'\n  hosts: infra_vms\n  roles:\n  - role: update-host\n  tags:\n  - update_host\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "d16a407fabcb1b194d3da99f3a5a4803b0a9ab67", "filename": "playbooks/ansible.cfg", "repository": "rocknsm/rock", "decoded_content": "# config file for ansible -- https://ansible.com/\n# ===============================================\n\n# nearly all parameters can be overridden in ansible-playbook\n# or with command line flags. ansible will read ANSIBLE_CONFIG,\n# ansible.cfg in the current working directory, .ansible.cfg in\n# the home directory or /etc/ansible/ansible.cfg, whichever it\n# finds first\n\n[defaults]\n\n# some basic default values...\n\ninventory      = inventory/all-in-one.ini\n#library        = /usr/share/my_modules/\n#module_utils   = /usr/share/my_module_utils/\n#remote_tmp     = ~/.ansible/tmp\n#local_tmp      = ~/.ansible/tmp\n#forks          = 5\n#poll_interval  = 15\n#sudo_user      = root\n#ask_sudo_pass = True\n#ask_pass      = True\n#transport      = smart\n#remote_port    = 22\n#module_lang    = C\n#module_set_locale = False\n\n# plays will gather facts by default, which contain information about\n# the remote system.\n#\n# smart - gather by default, but don't regather if already gathered\n# implicit - gather by default, turn off with gather_facts: False\n# explicit - do not gather by default, must say gather_facts: True\n#gathering = implicit\n\n# This only affects the gathering done by a play's gather_facts directive,\n# by default gathering retrieves all facts subsets\n# all - gather all subsets\n# network - gather min and network facts\n# hardware - gather hardware facts (longest facts to retrieve)\n# virtual - gather min and virtual facts\n# facter - import facts from facter\n# ohai - import facts from ohai\n# You can combine them using comma (ex: network,virtual)\n# You can negate them using ! (ex: !hardware,!facter,!ohai)\n# A minimal set of facts is always gathered.\n#gather_subset = all\n\n# some hardware related facts are collected\n# with a maximum timeout of 10 seconds. This\n# option lets you increase or decrease that\n# timeout to something more suitable for the\n# environment.\n# gather_timeout = 10\n\n# additional paths to search for roles in, colon separated\nroles_path    = roles\n\n# uncomment this to disable SSH key host checking\n#host_key_checking = False\n\n# change the default callback\n#stdout_callback = skippy\n# enable additional callbacks\n#callback_whitelist = timer, mail\n\n# Determine whether includes in tasks and handlers are \"static\" by\n# default. As of 2.0, includes are dynamic by default. Setting these\n# values to True will make includes behave more like they did in the\n# 1.x versions.\n#task_includes_static = True\n#handler_includes_static = True\n\n# Controls if a missing handler for a notification event is an error or a warning\n#error_on_missing_handler = True\n\n# change this for alternative sudo implementations\n#sudo_exe = sudo\n\n# What flags to pass to sudo\n# WARNING: leaving out the defaults might create unexpected behaviours\n#sudo_flags = -H -S -n\n\n# SSH timeout\n#timeout = 10\n\n# default user to use for playbooks if user is not specified\n# (/usr/bin/ansible will use current user as default)\n#remote_user = root\n\n# logging is off by default unless this path is defined\n# if so defined, consider logrotate\n#log_path = /var/log/ansible.log\n\n# default module name for /usr/bin/ansible\n#module_name = command\n\n# use this shell for commands executed under sudo\n# you may need to change this to bin/bash in rare instances\n# if sudo is constrained\n#executable = /bin/sh\n\n# if inventory variables overlap, does the higher precedence one win\n# or are hash values merged together?  The default is 'replace' but\n# this can also be set to 'merge'.\n#hash_behaviour = replace\n\n# by default, variables from roles will be visible in the global variable\n# scope. To prevent this, the following option can be enabled, and only\n# tasks and handlers within the role will see the variables there\n#private_role_vars = yes\n\n# list any Jinja2 extensions to enable here:\n#jinja2_extensions = jinja2.ext.do,jinja2.ext.i18n\n\n# if set, always use this private key file for authentication, same as\n# if passing --private-key to ansible or ansible-playbook\n#private_key_file = /path/to/file\n\n# If set, configures the path to the Vault password file as an alternative to\n# specifying --vault-password-file on the command line.\n#vault_password_file = /path/to/vault_password_file\n\n# format of string {{ ansible_managed }} available within Jinja2\n# templates indicates to users editing templates files will be replaced.\n# replacing {file}, {host} and {uid} and strftime codes with proper values.\n#ansible_managed = Ansible managed: {file} modified on %Y-%m-%d %H:%M:%S by {uid} on {host}\n# {file}, {host}, {uid}, and the timestamp can all interfere with idempotence\n# in some situations so the default is a static string:\n#ansible_managed = Ansible managed\n\n# by default, ansible-playbook will display \"Skipping [host]\" if it determines a task\n# should not be run on a host.  Set this to \"False\" if you don't want to see these \"Skipping\"\n# messages. NOTE: the task header will still be shown regardless of whether or not the\n# task is skipped.\n#display_skipped_hosts = True\n\n# by default, if a task in a playbook does not include a name: field then\n# ansible-playbook will construct a header that includes the task's action but\n# not the task's args.  This is a security feature because ansible cannot know\n# if the *module* considers an argument to be no_log at the time that the\n# header is printed.  If your environment doesn't have a problem securing\n# stdout from ansible-playbook (or you have manually specified no_log in your\n# playbook on all of the tasks where you have secret information) then you can\n# safely set this to True to get more informative messages.\n#display_args_to_stdout = False\n\n# by default (as of 1.3), Ansible will raise errors when attempting to dereference\n# Jinja2 variables that are not set in templates or action lines. Uncomment this line\n# to revert the behavior to pre-1.3.\n#error_on_undefined_vars = False\n\n# by default (as of 1.6), Ansible may display warnings based on the configuration of the\n# system running ansible itself. This may include warnings about 3rd party packages or\n# other conditions that should be resolved if possible.\n# to disable these warnings, set the following value to False:\n#system_warnings = True\n\n# by default (as of 1.4), Ansible may display deprecation warnings for language\n# features that should no longer be used and will be removed in future versions.\n# to disable these warnings, set the following value to False:\n#deprecation_warnings = True\n\n# (as of 1.8), Ansible can optionally warn when usage of the shell and\n# command module appear to be simplified by using a default Ansible module\n# instead.  These warnings can be silenced by adjusting the following\n# setting or adding warn=yes or warn=no to the end of the command line\n# parameter string.  This will for example suggest using the git module\n# instead of shelling out to the git command.\n# command_warnings = False\n\n\n# set plugin path directories here, separate with colons\n#action_plugins     = /usr/share/ansible/plugins/action\n#cache_plugins      = /usr/share/ansible/plugins/cache\n#callback_plugins   = /usr/share/ansible/plugins/callback\n#connection_plugins = /usr/share/ansible/plugins/connection\n#lookup_plugins     = /usr/share/ansible/plugins/lookup\n#inventory_plugins  = /usr/share/ansible/plugins/inventory\n#vars_plugins       = /usr/share/ansible/plugins/vars\n#filter_plugins     = /usr/share/ansible/plugins/filter\n#test_plugins       = /usr/share/ansible/plugins/test\n#strategy_plugins   = /usr/share/ansible/plugins/strategy\n\n\n# by default, ansible will use the 'linear' strategy but you may want to try\n# another one\n#strategy = free\n\n# by default callbacks are not loaded for /bin/ansible, enable this if you\n# want, for example, a notification or logging callback to also apply to\n# /bin/ansible runs\n#bin_ansible_callbacks = False\n\n\n# don't like cows?  that's unfortunate.\n# set to 1 if you don't want cowsay support or export ANSIBLE_NOCOWS=1\n#nocows = 1\n\n# set which cowsay stencil you'd like to use by default. When set to 'random',\n# a random stencil will be selected for each task. The selection will be filtered\n# against the `cow_whitelist` option below.\n#cow_selection = default\n#cow_selection = random\n\n# when using the 'random' option for cowsay, stencils will be restricted to this list.\n# it should be formatted as a comma-separated list with no spaces between names.\n# NOTE: line continuations here are for formatting purposes only, as the INI parser\n#       in python does not support them.\n#cow_whitelist=bud-frogs,bunny,cheese,daemon,default,dragon,elephant-in-snake,elephant,eyes,\\\n#              hellokitty,kitty,luke-koala,meow,milk,moofasa,moose,ren,sheep,small,stegosaurus,\\\n#              stimpy,supermilker,three-eyes,turkey,turtle,tux,udder,vader-koala,vader,www\n\n# don't like colors either?\n# set to 1 if you don't want colors, or export ANSIBLE_NOCOLOR=1\n#nocolor = 1\n\n# if set to a persistent type (not 'memory', for example 'redis') fact values\n# from previous runs in Ansible will be stored.  This may be useful when\n# wanting to use, for example, IP information from one group of servers\n# without having to talk to them in the same playbook run to get their\n# current IP information.\n#fact_caching = memory\n\n\n# retry files\n# When a playbook fails by default a .retry file will be created in ~/\n# You can disable this feature by setting retry_files_enabled to False\n# and you can change the location of the files by setting retry_files_save_path\n\n#retry_files_enabled = False\n#retry_files_save_path = ~/.ansible-retry\n\n# squash actions\n# Ansible can optimise actions that call modules with list parameters\n# when looping. Instead of calling the module once per with_ item, the\n# module is called once with all items at once. Currently this only works\n# under limited circumstances, and only with parameters named 'name'.\n#squash_actions = apk,apt,dnf,homebrew,pacman,pkgng,yum,zypper\n\n# prevents logging of task data, off by default\n#no_log = False\n\n# prevents logging of tasks, but only on the targets, data is still logged on the master/controller\n#no_target_syslog = False\n\n# controls whether Ansible will raise an error or warning if a task has no\n# choice but to create world readable temporary files to execute a module on\n# the remote machine.  This option is False by default for security.  Users may\n# turn this on to have behaviour more like Ansible prior to 2.1.x.  See\n# https://docs.ansible.com/ansible/become.html#becoming-an-unprivileged-user\n# for more secure ways to fix this than enabling this option.\n#allow_world_readable_tmpfiles = False\n\n# controls the compression level of variables sent to\n# worker processes. At the default of 0, no compression\n# is used. This value must be an integer from 0 to 9.\n#var_compression_level = 9\n\n# controls what compression method is used for new-style ansible modules when\n# they are sent to the remote system.  The compression types depend on having\n# support compiled into both the controller's python and the client's python.\n# The names should match with the python Zipfile compression types:\n# * ZIP_STORED (no compression. available everywhere)\n# * ZIP_DEFLATED (uses zlib, the default)\n# These values may be set per host via the ansible_module_compression inventory\n# variable\n#module_compression = 'ZIP_DEFLATED'\n\n# This controls the cutoff point (in bytes) on --diff for files\n# set to 0 for unlimited (RAM may suffer!).\n#max_diff_size = 1048576\n\n# This controls how ansible handles multiple --tags and --skip-tags arguments\n# on the CLI.  If this is True then multiple arguments are merged together.  If\n# it is False, then the last specified argument is used and the others are ignored.\n#merge_multiple_cli_flags = False\n\n# Controls showing custom stats at the end, off by default\n#show_custom_stats = True\n\n# Controlls which files to ignore when using a directory as inventory with\n# possibly multiple sources (both static and dynamic)\n#inventory_ignore_extensions = ~, .orig, .bak, .ini, .cfg, .retry, .pyc, .pyo\n\n[privilege_escalation]\nbecome=True\nbecome_method=sudo\n#become_user=root\n#become_ask_pass=False\n\n[paramiko_connection]\n\n# uncomment this line to cause the paramiko connection plugin to not record new host\n# keys encountered.  Increases performance on new host additions.  Setting works independently of the\n# host key checking setting above.\n#record_host_keys=False\n\n# by default, Ansible requests a pseudo-terminal for commands executed under sudo. Uncomment this\n# line to disable this behaviour.\n#pty=False\n\n[ssh_connection]\n\n# ssh arguments to use\n# Leaving off ControlPersist will result in poor performance, so use\n# paramiko on older platforms rather than removing it, -C controls compression use\n#ssh_args = -C -o ControlMaster=auto -o ControlPersist=60s\n\n# The base directory for the ControlPath sockets.\n# This is the \"%(directory)s\" in the control_path option\n#\n# Example:\n# control_path_dir = /tmp/.ansible/cp\n#control_path_dir = ~/.ansible/cp\n\n# The path to use for the ControlPath sockets. This defaults to a hashed string of the hostname,\n# port and username (empty string in the config). The hash mitigates a common problem users\n# found with long hostames and the conventional %(directory)s/ansible-ssh-%%h-%%p-%%r format.\n# In those cases, a \"too long for Unix domain socket\" ssh error would occur.\n#\n# Example:\n# control_path = %(directory)s/%%h-%%r\n#control_path =\n\n# Enabling pipelining reduces the number of SSH operations required to\n# execute a module on the remote server. This can result in a significant\n# performance improvement when enabled, however when using \"sudo:\" you must\n# first disable 'requiretty' in /etc/sudoers\n#\n# By default, this option is disabled to preserve compatibility with\n# sudoers configurations that have requiretty (the default on many distros).\n#\n#pipelining = False\n\n# Control the mechanism for transferring files (old)\n#   * smart = try sftp and then try scp [default]\n#   * True = use scp only\n#   * False = use sftp only\n#scp_if_ssh = smart\n\n# Control the mechanism for transferring files (new)\n# If set, this will override the scp_if_ssh option\n#   * sftp  = use sftp to transfer files\n#   * scp   = use scp to transfer files\n#   * piped = use 'dd' over SSH to transfer files\n#   * smart = try sftp, scp, and piped, in that order [default]\n#transfer_method = smart\n\n# if False, sftp will not use batch mode to transfer files. This may cause some\n# types of file transfer failures impossible to catch however, and should\n# only be disabled if your sftp version has problems with batch mode\n#sftp_batch_mode = False\n\n[accelerate]\n#accelerate_port = 5099\n#accelerate_timeout = 30\n#accelerate_connect_timeout = 5.0\n\n# The daemon timeout is measured in minutes. This time is measured\n# from the last activity to the accelerate daemon.\n#accelerate_daemon_timeout = 30\n\n# If set to yes, accelerate_multi_key will allow multiple\n# private keys to be uploaded to it, though each user must\n# have access to the system via SSH to add a new key. The default\n# is \"no\".\n#accelerate_multi_key = yes\n\n[selinux]\n# file systems that require special treatment when dealing with security context\n# the default behaviour that copies the existing context or uses the user default\n# needs to be changed to use the file system dependent context.\n#special_context_filesystems=nfs,vboxsf,fuse,ramfs,9p\n\n# Set this to yes to allow libvirt_lxc connections to work without SELinux.\n#libvirt_lxc_noseclabel = yes\n\n[colors]\n#highlight = white\n#verbose = blue\n#warn = bright purple\n#error = red\n#debug = dark gray\n#deprecate = purple\n#skip = cyan\n#unreachable = red\n#ok = green\n#changed = yellow\n#diff_add = green\n#diff_remove = red\n#diff_lines = cyan\n\n\n[diff]\n# Always print diff when running ( same as always running with -D/--diff )\n# always = no\n\n# Set how many context lines to show in diff\n# context = 3\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "148d503cceb07040c255394df57ab3d67bc9bf2d", "filename": "roles/config-bonding/tasks/interfaces.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Check if bonding has been initiated\" \n  stat:\n    path: /proc/net/bonding\n  register: proc_bonding\n\n- name: \"Detect which bonds already exist\"\n  command: ls -1 /proc/net/bonding\n  register: existing_bonds\n  when:\n  - proc_bonding.stat.isdir is defined\n  - proc_bonding.stat.isdir\n\n- name: \"Set fact for existing_bonds\"\n  set_fact: \n    existing_bonds: \"{{ existing_bonds.stdout_lines | default([]) }}\"\n\n- name: \"Configure bonding master interfaces\"\n  template:\n    src: bonding_master.j2 \n    dest: /etc/sysconfig/network-scripts/ifcfg-{{ ifcfg.device }}\n  with_items:\n  - '{{ bonds }}'\n  loop_control:\n    loop_var: ifcfg\n  when:\n  - ifcfg.device not in existing_bonds\n\n- name: \"Configure bonding slave interfaces\"\n  template:\n    src: bonding_slave.j2 \n    dest: /etc/sysconfig/network-scripts/ifcfg-{{ ifcfg.1.device }}\n  with_subelements:\n  - '{{ bonds }}'\n  - slaves\n  loop_control:\n    loop_var: ifcfg\n  when:\n  - ifcfg.0.device not in existing_bonds\n\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "9eb405c0c041f16054049967f54aea97b6076bf3", "filename": "tasks/conf/cleanup-config.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Setup: All OSs) Remove NGINX configuration files\"\n  file:\n    path: \"{{ item }}\"\n    state: absent\n  with_items:\n    - \"{{ nginx_cleanup_config_path }}\"\n  notify: \"(Handler: All OSs) Reload NGINX\"\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "154da5e9a4b4fb3db3b622c9cd1d12bd31be94f4", "filename": "tasks/amplify/setup-redhat.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: CentOS/RedHat/Amazon Linux) Add NGINX Amplify Agent Repository\"\n  yum_repository:\n    name: nginx-amplify\n    baseurl: http://packages.amplify.nginx.com/{{ (ansible_distribution == \"Amazon\") | ternary('amzn/', 'centos/') }}/$releasever/$basearch/\n    description: NGINX Amplify Agent\n    enabled: yes\n    gpgcheck: yes\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "84fcfa1e756eb90bdf83315803deadf2642f9af1", "filename": "roles/common/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Validate Ansible version\n  assert:\n    that:\n     - \"{{ ansible_version is defined }}\"\n     - \"{{ ansible_version.full | version_compare(minimum_ansible_version, '>=') }}\"\n    msg: \"Your Ansible version is too old. Trellis require at least {{ minimum_ansible_version }}. Your version is {{ ansible_version.full | default('< 1.6') }}\"\n\n- name: Update Apt\n  apt:\n    update_cache: yes\n\n- name: Checking essentials\n  apt:\n    name: \"{{ item }}\"\n    state: present\n  with_items:\n  - python-software-properties\n  - python-pycurl\n  - build-essential\n  - python-mysqldb\n  - curl\n  - git-core\n\n- name: Validate timezone variable\n  stat:\n    path: /usr/share/zoneinfo/{{ default_timezone }}\n  register: timezone_path\n  changed_when: false\n\n- name: Explain timezone error\n  fail:\n    msg: \"{{ default_timezone }} is not a valid timezone. For a list of valid timezones, check https://php.net/manual/en/timezones.php\"\n  when: not timezone_path.stat.exists\n\n- name: Get current timezone\n  command: cat /etc/timezone\n  register: current_timezone\n  changed_when: false\n\n- name: Set timezone\n  command: timedatectl set-timezone {{ default_timezone }}\n  when: current_timezone.stdout != default_timezone\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "1edcb9ca0b167acc621d1188f0c5a26d9b102787", "filename": "tasks/call_script.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- name: Calling Groovy script {{ script_name }}\n  uri:\n    url: \"http://localhost:{{ nexus_default_port }}{{ nexus_default_context_path }}{{ nexus_rest_api_endpoint }}/{{ script_name }}/run\"\n    user: 'admin'\n    password: \"{{ current_nexus_admin_password }}\"\n    headers:\n      Content-Type: \"text/plain\"\n    method: POST\n    status_code: 200,204\n    force_basic_auth: yes\n    body: \"{{ args | to_json }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "3947be59c959b0fc7fbab7a008ca613617af7782", "filename": "roles/config-openvpn/tests/openvpn-server.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: openvpn_servers\n  roles: \n  - role: config-openvpn\n"}, {"commit_sha": "a5a5c4d74b7b0fd14f534dda1f41f903d1a58abf", "sha": "10b97401c5f5e5a65bd7b4bb5a46cf154b9ca23b", "filename": "handlers/main.yml", "repository": "fubarhouse/ansible-role-nodejs", "decoded_content": "---\n# handlers file for fubarhouse.nodejs\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "2f512199cc04ddea3325414ae4d4adea298d9377", "filename": "playbooks/manage-lb/README.md", "repository": "redhat-cop/infra-ansible", "decoded_content": "# Load Balancer Playbook\n\nThis playbook directory has the playbook(s) necessary to manage your load balancers.\n\n## Prerequisites\n\nCurrently, the playbook(s) in here don't manage the instances themselves, so you need to ensure you already have running instances (and subscribed if applicable) before running these playbook(s) with a valid inventory.\n\n## Example\n\n### Inventory\n\nPlease see the inventory in the respective role for more details:\n\n- [manage-haproxy](../../roles/load-balancers/manage-haproxy/README.md)\n\n\n### Playbook execution\n\nInitial run needs the `tags='install'` set to ensure all necessary software is installed:\n\n```bash\n> ansible-playbook -i inventory lb-vms.yml --tags='install'\n```\n\nAny consecutive runs can be done without the 'install' tag to speed up execution:\n```bash\n> ansible-playbook -i inventory lb-vms.yml\n```\n\nLicense\n-------\n\nApache License 2.0\n\n\nAuthor Information\n------------------\n\nRed Hat Community of Practice & staff of the Red Hat Open Innovation Labs.\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "37d90010025f36d268701f3f7519ef1e75fbb0ef", "filename": "roles/kalite/tasks/setup.yml", "repository": "iiab/iiab", "decoded_content": "# This is for an OS other than Fedora 18\n\n- name: Create kalite_root directory\n  file: path={{ kalite_root }}/httpsrv/static\n        owner=root\n        group=root\n        mode=0755\n        state=directory\n\n- name: Run the setup using kalite manage\n  command: \"{{ kalite_program }} manage setup --username={{ kalite_admin_user }} --password={{ kalite_admin_password }} --noinput\"\n  environment:\n     KALITE_HOME: \"{{ kalite_root }}\"\n  async: 900\n  poll: 10\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "c7aa5476b96a89733be6b069e4013ca679a828e6", "filename": "roles/ovirt-collect-logs/tasks/db.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\n- name: Dump engine database\n  shell: \"su - postgres -c 'pg_dump engine > {{ ovirt_collect_logs_tmp_dir }}/engine_db.sql'\"\n  ignore_errors: true\n"}, {"commit_sha": "beb41b82405655aa385bb8297bf49ada1a4eb14c", "sha": "b39df6f3f66ea09e223d45482aaf3f98a443b979", "filename": "tasks/Linux/install/RedHat.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Add repository for AdoptOpenJDK\n  yum_repository:\n    name: AdoptOpenJDK\n    description: AdoptOpenJDK\n    baseurl: http://adoptopenjdk.jfrog.io/adoptopenjdk/rpm/centos/7/x86_64\n    enabled: true\n    gpgcheck: true\n    gpgkey: https://adoptopenjdk.jfrog.io/adoptopenjdk/api/gpg/key/public\n  when:\n    - java_distribution == \"adoptopenjdk\"\n\n- name: Install java packages\n  yum:\n    name: '{{ (transport == \"repositories\") | ternary(jdk_package, java_artifact) }}'\n    state: present\n  register: package_install\n  until: package_install is succeeded\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "9bfe4b5d4899580a39c6c9e11957eddb256ae8ba", "filename": "roles/dns/config-dns-server/tasks/named/prereq.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Ensure required packages are installed\n  package:\n    name: \"{{ item }}\"\n    state: \"{{ package_state }}\"\n  with_items:\n    - bind\n    - bind-utils\n    - firewalld\n    - python-firewall\n    - libsemanage-python\n    - python-dns\n    - libselinux-python\n\n- name: Enable named\n  service:\n    name: named\n    enabled: yes\n\n- name: Enable firewalld\n  service:\n    name: firewalld\n    enabled: yes\n    state: started\n\n- name: Open Firewall for DNS\n  firewalld:\n    port: \"{{item}}\"\n    permanent: yes\n    state: enabled\n    immediate: yes\n  with_items:\n    - 53/tcp\n    - 53/udp\n\n- name: Configure named\n  copy:\n    src: named.conf\n    dest: /etc/named.conf\n    owner: named\n    group: named\n    mode: 0660\n\n- name: Setup Zone Directory\n  file:\n    path: /var/named/static\n    state: directory\n    owner: named\n    group: named\n    mode: 0770\n\n- name: Setup key for service named status to communicate with BIND\n  command: \"/sbin/rndc-confgen -a -r /dev/urandom\"\n\n- name: Ensure various files/directories exists with the proper permissions\n  file:\n    path: \"{{ item }}\"\n    owner: root\n    group: named\n    mode: 0640\n  with_items:\n    - \"/etc/rndc.key\"\n\n- name: Configure SELinux\n  seboolean:\n    name: named_write_master_zones\n    state: yes\n    persistent: yes\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "1f92254b9a8ea165f676e55b787dc696d0c2df06", "filename": "tasks/modules/install-njs.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: All OSs) Install NGINX Open Source JavaScript Module\"\n  package:\n    name: nginx-module-njs\n    state: present\n  when: nginx_type == \"opensource\"\n\n- name: \"(Install: All OSs) Install NGINX Plus JavaScript Module\"\n  package:\n    name: nginx-plus-module-njs\n    state: present\n  when: nginx_type == \"plus\"\n\n- name: \"(Setup: All NGINX) Load NGINX JavaScript Module\"\n  lineinfile:\n    path: /etc/nginx/nginx.conf\n    insertbefore: BOF\n    line: \"{{ item }}\"\n  with_items:\n    - load_module modules/ngx_http_js_module.so;\n    - load_module modules/ngx_stream_js_module.so;\n  when: not nginx_main_template_enable\n  notify: \"(Handler: All OSs) Reload NGINX\"\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "6e016e92967c146280cdcc9e9778c4274939908e", "filename": "playbooks/templates/suricata_overrides.yaml.j2", "repository": "rocknsm/rock", "decoded_content": "%YAML 1.1\n---\nrule-files:\n  - pulledpork.rules\n  - http-events.rules\n  - smtp-events.rules\n  - dns-events.rules\n  - tls-events.rules\n  - app-layer-events.rules\n  - files.rules\naf-packet:\n{% for iface in rock_monifs %}\n  - interface: {{ iface }}\n    #threads: auto\n    cluster-id: {{ 99 - loop.index0 }}\n    cluster-type: cluster_flow\n    defrag: yes\n    use-mmap: yes\n    mmap-locked: yes\n    #rollover: yes\n    tpacket-v3: yes\n    use-emergency-flush: yes\n{% endfor %}\ndefault-log-dir: {{ suricata_data_dir }}\noutputs:\n  - fast:\n      enabled: yes\n      filename: fast.log\n      append: yes\n  - eve-log:\n      enabled: yes\n      filetype: regular\n      filename: eve.json\n      types:\n        - alert:\n            http: yes\n            tls: yes\n            ssh: yes\n            smtp: yes\n            tagged-packets: yes\n            xff:\n              enabled: no\n        - files:\n            force-magic: no\n            force-md5: no\n        - stats:\n            totals: yes\n            threads: no\n            deltas: no\n        - flow\n  - unified2-alert:\n      enabled: yes\n      filename: unified2.alert\n      limit: 32mb\n      sensor-id: 0\n      payload: yes\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "8bb5985ed59b9d5d172bbf8bfab968f0390c2d15", "filename": "roles/sugarizer/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Download the latest stable version of sugarizer from location under our control\n  get_url: url={{ iiab_download_url }}/{{ sugarizer_version }}.tar.gz\n           dest={{ downloads_dir }}/{{ sugarizer_version }}.tar.gz\n\n#fixme\n- name: Untar it to target location\n  command: tar xzf {{ downloads_dir }}/{{ sugarizer_version }}.tar.gz -C {{ sugarizer_location }}\n           creates=\"{{ sugarizer_location }}/{{ sugarizer_version }}/index.html\"\n\n- name: Create a symbolic link from generic url to version specific location\n  file: dest={{ sugarizer_location }}/sugarizer\n        src={{ sugarizer_location }}/{{ sugarizer_version }}\n        state=link\n\n- name: Set up apt sources on is_debuntu\n  shell: curl -sL https://deb.nodesource.com/setup_6.x | bash -\n  when: internet_available and is_debuntu\n\n- name: Install nodejs=6.* which includes /usr/bin/npm - is_debuntu\n  package: name=nodejs=6.*\n           state=present\n  when: internet_available and is_debuntu\n\n- name: Install npm non is_debuntu\n  package: name={{ item }}\n           state=present\n  when: internet_available and not is_debuntu\n  with_items:\n    - nodejs\n    - npm\n\n# attempting to reinstall npm is broken on raspbian 9\n- name: check for sugarizer already installed\n  stat: path={{ sugarizer_location }}/sugarizer/server/node_modules\n  register: npm\n\n- name: set a flag to abort second attempt to install\n  set_fact:\n     npm_exists: True\n  when: npm.stat.exists is defined and npm.stat.exists\n\n- name: Create systemd files and copy our ini file\n  template: src={{ item.src }}\n            dest={{ item.dest }}\n            owner=root\n            group=root\n            mode=0644\n  with_items:\n     - { src: 'sugarizer.service.j2' , dest: '/etc/systemd/system/sugarizer.service'}\n     - { src: 'sugarizer.ini' , dest: '{{ sugarizer_location }}/sugarizer/server' }\n#     - { src: 'sugarizer.conf' , dest: '/etc/apache2/sites-available' }\n\n#- name: Create the symlink enabling the rewrite\n#  file: src=/etc/apache2/sites-available/sugarizer.conf\n#        dest=/etc/apache2/sites-enabled/sugarizer.conf\n#        state=link\n\n- name: Create the express framework for node.js - ALL less F18\n  shell:  npm install\n  args:\n     chdir: \"{{ sugarizer_location }}/sugarizer/server\"\n     creates: \"{{ sugarizer_location }}/sugarizer/server/node_modules\"\n  when: not is_F18 and not npm_exists\n\n- name: Create the express framework for node.js - F18\n  shell:  npm install\n  args:\n     chdir: \"{{ sugarizer_location }}/sugarizer/server\"\n  when: is_F18 and not npm_exists\n\n- name: enable services - All\n  service: name={{ item.name }}\n           enabled=yes\n           state=restarted\n  with_items:\n      - { name: sugarizer }\n  when: sugarizer_enabled\n\n- name: disable services - All\n  service: name={{ item.name }}\n           enabled=no\n           state=stopped\n  with_items:\n      - { name: sugarizer }\n  when: not sugarizer_enabled\n\n- name: add sugarizer to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=sugarizer\n            option='{{ item.option }}'\n            value='\"{{ item.value }}\"'\n  with_items:\n       - option: name\n         value: Sugarizer\n       - option: description\n         value: '\"The Sugar Learning Platform is a leading learning platform that began in the famous One Laptop Per Child project. Sugarizer is a web implementation of that platform\"'\n       - option: enabled\n         value: \"{{ sugarizer_enabled }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "5db9cbc68f88c294f6e882b2fb7076d49e56c2a3", "filename": "roles/2-common/tasks/centos.yml", "repository": "iiab/iiab", "decoded_content": "- name: Centos Server specific tasks\n  command: echo Starting centos.yml\n\n- name: Keep yum cache\n  ini_file: dest=/etc/yum.conf\n            section=main\n            option=keepcache\n            value=1\n\n- name: Install epel-release for CentOS\n  package: name={{ item }}\n           state=present\n  with_items:\n   - epel-release\n\n- name: Install IIAB repo for CentOS\n  template: src={{ item }} dest=/etc/yum.repos.d/ owner=root group=root mode=0644\n  with_items:\n   - iiab-centos.repo\n   - li.nux.ro.repo\n   - ansible.repo\n\n#- name: Disable updating ansible on CentOS\n#  shell: sed -i -e '/^enabled=/a exclude=ansible' {{ item }}\n#  with_items:\n#    - /etc/yum.repos.d/CentOS-Base.repo\n#    - /etc/yum.repos.d/CentOS-CR.repo\n#    - /etc/yum.repos.d/CentOS-fasttrack.repo\n#    - /etc/yum.repos.d/CentOS-Vault.repo\n#  when: ansible_distribution == \"CentOS\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "d25761965bf4e0077b067c3690ff96f157f4ab62", "filename": "roles/config-mysql/tasks/install_containerized.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Generate Random DB Username\n  set_fact:\n    mysql_username: \"{{ lookup('password', '/dev/null length=5 chars=ascii_letters') | lower }}\"\n  when: mysql_username is undefined or mysql_username|trim == \"\"\n  run_once: True\n\n- name: Generate Random DB Admin Username\n  set_fact:\n    mysql_root_username: \"root\"\n  when: mysql_root_username is undefined or mysql_root_username|trim == \"\"\n  run_once: True\n\n- name: Generate Random DB Password\n  set_fact:\n    mysql_password: \"{{ lookup('password', '/dev/null length=10 chars=ascii_letters,digits,hexdigits') }}\"\n  when: mysql_password is undefined or mysql_password|trim == \"\"\n  run_once: True\n\n- name: Generate Random Admin DB Password\n  set_fact:\n    mysql_root_password: \"{{ lookup('password', '/dev/null length=10 chars=ascii_letters,digits,hexdigits') }}\"\n  when: mysql_root_password is undefined or mysql_root_password|trim == \"\"\n  run_once: True\n\n- name: Configure Storage Directory\n  file:\n    state: directory\n    owner: root\n    group: root\n    mode: g+rw\n    path: \"{{ mysql_storage_dir }}\"\n\n- name: Configure systemd environment files\n  template:\n    src: \"{{ mysql_name }}.j2\"\n    dest: \"{{ systemd_environmentfile_dir}}/{{ mysql_name }}\"\n  notify: \"Restart MySQL Service\"\n\n- name: Configure systemd unit files\n  template:\n    src: \"{{ mysql_service }}.j2\"\n    dest: \"{{ systemd_service_dir}}/{{ mysql_service }}\"\n  notify: \"Restart MySQL Service\"\n\n- name: Include firewall tasks\n  include_tasks: firewall.yml"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "661b428ee96326fe20a1b8c3ba8602a7e687d031", "filename": "roles/moodle-1.9/moodle/templates/moodle-xs-init", "repository": "iiab/iiab", "decoded_content": "#!/bin/bash\n#\n# moodle        This shell script is modified from sysVinit init.d moodle \n#\t\t--checks for moodle upgrade flag and enables the cron \n#\t\tjob for Moodle\n#\n# Author:       Ignacio Vazquez-Abrams <ivazquez@ivazquez.net>\n# Adapted from the yum initscript by Seth Vidal\n# Adapted for systemd by George Hunt <georgejhunt@gmail.com>\n#\n# description:  Enable the Moodle cron job\n#\n# source function library\n. /etc/rc.d/init.d/functions\n\n# both moodle cron and config.php check\n# for this file -\nlockfile=/var/lock/subsys/moodle\n\nRETVAL=0\n\n\t\nstart() {\n        if [ -e /etc/moodle/needsupgrade ]; then\n\n                echo \"Moodle installation or upgrade required...\"\n\t\tpushd /var/www/moodle/web\n\n\t\techo \"[\"`date`\"]\" Start install / upgrade >> /var/log/moodle-instupg.log \n\n\t\t# Correct a bungled 'version' variable in mdl_config. If version matches local_version, and\n\t\t# is one of the known-to-be-bungled local_version/version pairs, fix it to the last-known-good\n\t\t# value.\n\t\techo \"Correcting version/local_version mangling - will error out on fresh DBs\" >> /var/log/moodle-instupg.log \n\t\t(su -c \"psql -c \\\"UPDATE mdl_config \n                                 SET value='2007101526'\n                                 WHERE id=(SELECT v.id \n                                           FROM mdl_config v \n                                            JOIN mdl_config lv \n                                                 ON (v.name='version' AND lv.name='local_version'\n                                                     AND v.value=lv.value)\n                                           WHERE lv.value IN ('2009030301', '2009042801',\n                                                              '2009051800', '2009052500'));\\\" moodle-xs \" postgres 2>&1 ) >> /var/log/moodle-instupg.log \n\n\n\t\t# Before install/upgrade, enable the admin user\n\t\t# (will DTRT for upgrades, fail silently in fresh installs)\n\t\t( runuser -s /bin/bash -c \"/usr/bin/php /var/www/moodle/web/local/scripts/adminuser-enable.php\" apache 2>&1 ) >> /var/log/moodle-instupg.log \n\n\t\t# Install/upgrade moodle DB schema\n\t\t( runuser -s /bin/bash -c \"/usr/bin/php /var/www/moodle/web/admin/cliupgrade.php \\\n\t\t    --agreelicense=yes --confirmrelease=yes \\\n\t\t    --sitefullname='School Server' \\\n\t\t    --siteshortname='XS' \\\n\t\t    --sitesummary='Put the name of your school here' \\\n\t\t    --adminfirstname=Admin --adminlastname=OLPC \\\n\t\t    --adminusername=admin --adminpassword=changeme \\\n\t\t    --adminemail=admin@localhost \\\n\t\t    --verbose=0 --interactivelevel=0\" apache 2>&1 ) #&& \\\n        #  runuser -s /bin/bash -c \"/usr/bin/php /var/www/moodle/web/local/scripts/adminuser-disable.php\" apache 2>&1 ) \\\n        # >> /var/log/moodle-instupg.log \n\t\tif [ $? = 0 ]; then\n\t\t    # success\n\t\t    echo \"[\"`date`\"]\" Finished install / upgrade - Success >> /var/log/moodle-instupg.log \n\t\t    rm -f /etc/moodle/needsupgrade\n\t\telse\n\t\t    # failure\n\t\t    echo \"[\"`date`\"]\" Finished install / upgrade - Failure >> /var/log/moodle-instupg.log \n\t\t    exit 1\n\t\tfi\n\t\tpopd\n\tfi\n\techo -n $\"Enabling Moodle access and cron job: \"\n\ttouch \"$lockfile\" && success || failure\n\tRETVAL=$?\n\techo\n}\n\nstop() {\n\techo -n $\"Disabling Moodle access and cron job: \"\n\trm -f \"$lockfile\" && success || failure\n\tRETVAL=$?\n\techo\n}\n\ncase \"$1\" in\n  start)\n\tstart\n\t;;\n  stop) \n\tstop\n\t;;\n  *)\n\texit 1\nesac\n\nexit $RETVAL\n"}, {"commit_sha": "481f7ad18dc225973e1d676d33e58c49cbbfe986", "sha": "bbf5d92cea4f27508054c0e96fb90f523c9a077c", "filename": "tasks/django_secret_key.yml", "repository": "openwisp/ansible-openwisp2", "decoded_content": "- name: upload generate_django_secret_key.py script\n  copy:\n    src: generate_django_secret_key.py\n    dest: \"{{ openwisp2_path }}/generate_django_secret_key.py\"\n    mode: 0754\n\n- name: generate new django SECRET_KEY\n  shell: \"./generate_django_secret_key.py > .django-secret-key\"\n  args:\n    chdir: \"{{ openwisp2_path }}\"\n    creates: \"{{ openwisp2_path }}/.django-secret-key\"\n\n- name: get django SECRET_KEY\n  command: \"cat .django-secret-key\"\n  register: secret_key\n  changed_when: false\n  args:\n    chdir: \"{{ openwisp2_path }}\"\n\n- name: set permission to secret key file\n  file:\n    dest: \"{{ openwisp2_path }}/.django-secret-key\"\n    mode: 0600\n\n- name: set secret_key fact\n  set_fact: openwisp2_secret_key=\"{{ secret_key.stdout }}\"\n"}, {"commit_sha": "3848dbe33432b38a7e7ebad0da63826355cf1b4c", "sha": "463bdb377c2f4ebd67c15b1b77a831b8831993da", "filename": "tasks/cores.yml", "repository": "geerlingguy/ansible-role-solr", "decoded_content": "---\n- name: Check current list of Solr cores.\n  uri:\n    url: http://localhost:{{ solr_port }}/solr/admin/cores\n    return_content: yes\n  register: solr_cores_current\n\n- name: Ensure Solr conf directories exist.\n  file:\n    path: \"{{ solr_home }}/data/{{ item }}/conf\"\n    state: directory\n    owner: \"{{ solr_user }}\"\n    group: \"{{ solr_user }}\"\n    recurse: yes\n  when: \"'{{ item }}' not in '{{ solr_cores_current.content }}'\"\n  with_items: \"{{ solr_cores }}\"\n\n- name: Ensure core configuration directories exist.\n  shell: \"cp -r {{ solr_install_path }}/example/files/conf/ {{ solr_home }}/data/{{ item }}/\"\n  when: \"'{{ item }}' not in '{{ solr_cores_current.content }}'\"\n  with_items: \"{{ solr_cores }}\"\n\n- name: Create configured cores.\n  shell: \"{{ solr_install_path }}/bin/solr create -c {{ item }}\"\n  when: \"'{{ item }}' not in '{{ solr_cores_current.content }}'\"\n  with_items: \"{{ solr_cores }}\"\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "8a7ae0c2194590212e22ced8aa8e9d05c5686c64", "filename": "playbooks/openshift/aws/start.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n- hosts: localhost\n  roles:\n  - role: manage-aws-infra\n    operation: running\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "fb1d6a5e4e8e5a544dfe6d29d0490f349b4eab36", "filename": "roles/config-mysql/tasks/firewall.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Check if firewalld is installed\n  command: systemctl status firewalld\n  register: firewalld_status\n  failed_when: false\n  changed_when: false\n\n- name: Check if iptables is installed\n  command: systemctl status iptables\n  register: iptables_status\n  failed_when: false\n  changed_when: false\n\n- name: Open port in firewalld\n  firewalld:\n    port: \"{{ mysql_host_port }}/TCP\"\n    permanent: true\n    state: enabled\n  when: firewalld_status.rc == 0\n  notify:\n  - restart firewalld\n\n- name: Ensure iptables is correctly configured \n  lineinfile:\n    insertafter: \"^-A INPUT .* --dport {{ mysql_host_port }} .* ACCEPT\"\n    state: present\n    dest: /etc/sysconfig/iptables\n    regexp: \"^-A INPUT .* --dport {{ mysql_host_port }} .* ACCEPT\"\n    line: \"-A INPUT -p TCP -m state --state NEW -m TCP --dport {{ mysql_host_port }} -j ACCEPT\"\n  when: iptables_status.rc == 0 and firewalld_status.rc != 0 \n  notify:\n  - restart iptables\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "2d91440b5f944c7e28e33e78197fe7c1928c883d", "filename": "roles/dnsmasq/handlers/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# handlers file for dnsmasq\n- name: restart dnsmasq\n  service:\n    name: dnsmasq\n    state: restarted\n  sudo: yes\n\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "f0aaf760821e1c40ce9b6e0b2f6137e24e81875b", "filename": "roles/marathon/meta/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\ngalaxy_info:\n  author: Alberto Lamela\n  description:\n  company: Capgemini\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (MIT)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: Ubuntu\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n     - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies:\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "6fada6f2a7515ab18178ae350168c3de147c4dd0", "sha": "8363324266afba40278443266d60bbd19f04d555", "filename": "tasks/install.yml", "repository": "inkatze/wildfly", "decoded_content": "---\n# task file for wildfly\n\n- name: Install OpenJDK\n  yum:\n    name: java-1.8.0-openjdk-headless\n    state: present\n\n- name: Check if wildfly version file exists\n  stat:\n    path: '{{ wildfly_version_file }}'\n  register: wildfly_version_file_st\n\n- name: Check wildfly installation\n  command: grep -q '{{ wildfly_version }}' '{{ wildfly_version_file }}'\n  register: wildfly_installed\n  when: wildfly_version_file_st.stat.exists and\n        not wildfly_version_file_st.stat.isdir\n  changed_when: no\n\n- block:\n\n  - name: Download wildfly tar file\n    get_url:\n      url: '{{ wildfly_download_url }}'\n      dest: '{{ wildfly_download_dir }}'\n\n  - name: Create wildfly group\n    group:\n      name: '{{ wildfly_group }}'\n      state: present\n\n  - name: Create wildfly user\n    user:\n      name: '{{ wildfly_user }}'\n      group: '{{ wildfly_group }}'\n      createhome: no\n      state: present\n\n  - name: Unarchive downloaded file\n    unarchive:\n      src: '{{ wildfly_download_dir }}/{{ wildfly_download_file }}'\n      dest: '{{ wildfly_install_dir }}'\n      owner: '{{ wildfly_user }}'\n      group: '{{ wildfly_group }}'\n      mode: '0750'\n      copy: no\n\n  when: wildfly_installed.stdout is not defined or not wildfly_installed.stdout\n"}, {"commit_sha": "e91a55152358e890a05cf849abc7d58b8badecc2", "sha": "6cd79cae190cd57bba30a5fe43db93bd36a38755", "filename": "tasks/tasks-CentOS.yml", "repository": "fubarhouse/ansible-role-golang", "decoded_content": "---\n\n- name: \"Go-Lang | Install dependencies\"\n  yum:\n    name: \"{{ item }}\"\n    state: installed\n  with_items:\n    - curl\n    - gcc\n    - git\n    - findutils\n    - make\n    - rsync\n    - tar\n\n- name: \"Go-Lang | Define GOARCH\"\n  set_fact:\n    GOARCH: \"amd64\"\n  when: GOARCH is not defined\n\n- name: \"Go-Lang | Define GOOS\"\n  set_fact:\n    GOOS: \"linux\"\n  when: GOOS is not defined"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "dfb3b1f96745e7cbddf32c9b6747b9a39eb70270", "filename": "roles/cloud-ec2/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "- set_fact:\n    access_key: \"{{ aws_access_key | default(lookup('env','AWS_ACCESS_KEY_ID'), true) }}\"\n    secret_key: \"{{ aws_secret_key | default(lookup('env','AWS_SECRET_ACCESS_KEY'), true) }}\"\n\n- name: Locate official Ubuntu 16.04 AMI for region\n  ec2_ami_find:\n    aws_access_key: \"{{ access_key }}\"\n    aws_secret_key: \"{{ secret_key }}\"\n    name: \"ubuntu/images/hvm-ssd/ubuntu-xenial-16.04-amd64-server-*\"\n    owner:  099720109477\n    sort: creationDate\n    sort_order: descending\n    sort_end: 1\n    region: \"{{ region }}\"\n  register: ami_search\n\n- set_fact:\n    ami_image: \"{{ ami_search.results[0].ami_id }}\"\n\n- include: encrypt_image.yml\n  tags: [encrypted]\n\n- name: Add ssh public key\n  ec2_key:\n    aws_access_key: \"{{ access_key }}\"\n    aws_secret_key: \"{{ secret_key }}\"\n    name: VPNKEY\n    region: \"{{ region }}\"\n    key_material: \"{{ item }}\"\n  with_file: \"{{ SSH_keys.public }}\"\n  register: keypair\n\n- name: Configure EC2 virtual private clouds\n  ec2_vpc:\n    aws_access_key: \"{{ access_key }}\"\n    aws_secret_key: \"{{ secret_key }}\"\n    state: present\n    resource_tags: { \"Environment\":\"Algo\" }\n    region: \"{{ region }}\"\n    cidr_block: \"{{ ec2_vpc_nets.cidr_block }}\"\n    internet_gateway: yes\n    subnets:\n      - cidr: \"{{ ec2_vpc_nets.subnet_cidr }}\"\n        resource_tags: { \"Environment\":\"Algo\" }\n  register: vpc\n\n- name: Set up Public Subnets Route Table\n  ec2_vpc_route_table:\n    aws_access_key: \"{{ access_key }}\"\n    aws_secret_key: \"{{ secret_key }}\"\n    vpc_id: \"{{ vpc.vpc_id }}\"\n    region: \"{{ region }}\"\n    state: present\n    tags:\n      Environment: Algo\n    subnets:\n      - \"{{ ec2_vpc_nets.subnet_cidr }}\"\n    routes:\n      - dest: 0.0.0.0/0\n        gateway_id: \"{{ vpc.igw_id }}\"\n  register: public_rt\n\n- name: Configure EC2 security group\n  ec2_group:\n    aws_access_key: \"{{ access_key }}\"\n    aws_secret_key: \"{{ secret_key }}\"\n    name: vpn-secgroup\n    description: Security group for VPN servers\n    region: \"{{ region }}\"\n    vpc_id: \"{{ vpc.vpc_id }}\"\n    rules:\n      - proto: udp\n        from_port: 4500\n        to_port: 4500\n        cidr_ip: 0.0.0.0/0\n      - proto: udp\n        from_port: 500\n        to_port: 500\n        cidr_ip: 0.0.0.0/0\n      - proto: tcp\n        from_port: 22\n        to_port: 22\n        cidr_ip: 0.0.0.0/0\n    rules_egress:\n      - proto: all\n        from_port: 0-65535\n        to_port: 0-65535\n        cidr_ip: 0.0.0.0/0\n\n- name: Launch instance\n  ec2:\n    aws_access_key: \"{{ access_key }}\"\n    aws_secret_key: \"{{ secret_key }}\"\n    keypair: \"VPNKEY\"\n    vpc_subnet_id: \"{{ vpc.subnets[0].id }}\"\n    group: vpn-secgroup\n    instance_type: \"{{ cloud_providers.ec2.size }}\"\n    image: \"{{ ami_image }}\"\n    wait: true\n    region: \"{{ region }}\"\n    instance_tags:\n      Name: \"{{ aws_server_name }}\"\n      Environment: Algo\n    exact_count: 1\n    count_tag:\n      Name: \"{{ aws_server_name }}\"\n    assign_public_ip: yes\n    instance_initiated_shutdown_behavior: terminate\n  register: ec2\n\n- name: Add new instance to host group\n  add_host:\n    hostname: \"{{ item.public_ip }}\"\n    groupname: vpn-host\n    ansible_ssh_user: ubuntu\n    ansible_python_interpreter: \"/usr/bin/python2.7\"\n    ansible_ssh_private_key_file: \"{{ SSH_keys.private }}\"\n    cloud_provider: ec2\n    ipv6_support: no\n  with_items: \"{{ ec2.tagged_instances }}\"\n\n- set_fact:\n    cloud_instance_ip: \"{{ ec2.tagged_instances[0].public_ip }}\"\n\n- name: Get EC2 instances\n  ec2_remote_facts:\n    aws_access_key: \"{{ access_key }}\"\n    aws_secret_key: \"{{ secret_key }}\"\n    region: \"{{ region }}\"\n    filters:\n      instance-state-name: running\n      \"tag:Environment\": Algo\n  register: algo_instances\n\n- name: Ensure the group ec2 exists in the dynamic inventory file\n  lineinfile:\n    state: present\n    dest: configs/inventory.dynamic\n    line: '[ec2]'\n\n- name: Populate the dynamic inventory\n  lineinfile:\n    state: present\n    dest: configs/inventory.dynamic\n    insertafter: '\\[ec2\\]'\n    regexp: \"^{{ item.public_ip_address }}.*\"\n    line: \"{{ item.public_ip_address }}\"\n  with_items:\n    - \"{{ algo_instances.instances }}\"\n"}, {"commit_sha": "836dc4dd0dacc490044a14c0e39469d162b9449b", "sha": "9034a147d7e636bb0e72ae974d598f3b0a3b5ac6", "filename": "tasks/post.yml", "repository": "florianutz/Ubuntu1604-CIS", "decoded_content": "---\n# Post tasks\n\n- name: \"POST | Find removed but configured apt packages\"\n  shell: \"dpkg --list | grep ^rc | tr -s ' ' | cut -d ' ' -f 2\"\n  register: apt_rc_packages\n  changed_when: false\n\n- name: \"POST | Perform apt package cleanup\"\n  apt:\n    name: \"{{ item }}\"\n    state: absent\n    purge: true\n  changed_when: false\n  ignore_errors: true\n  with_items: \"{{ apt_rc_packages.stdout_lines }}\"\n  tags:\n    - skip_ansible_lint\n"}, {"commit_sha": "9662c15ce2e4260fac5cc2bfdf5aaaaf0a2191dd", "sha": "9e1d764954b1764f0488be762559cced09980e9b", "filename": "tasks/section_08_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: Check if the file auditd.conf exists\n    stat: >\n        path=/etc/audit/auditd.conf\n    register: auditd_file\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n\n  - name: Create the audit directory if it does not exists\n    file: >\n        path=/etc/audit/\n        state=directory\n    when: not auditd_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n\n  - name: 8.1.1-3 Configure Data Retention\n    lineinfile: >\n        dest=/etc/audit/auditd.conf\n        regexp=\"{{ item.rxp }}\"\n        line=\"{{ item.line }}\"\n        state=present\n        create=yes\n    with_items:\n      - { rxp: '^max_log_file ', line: 'max_log_file = {{ Max_Log_File }}' }\n      - { rxp: '^space_left_action', line: 'space_left_action = email' }\n      - { rxp: '^action_mail_acct', line: 'action_mail_acct = root' }\n      - { rxp: '^admin_space_left_action', line: 'admin_space_left_action = halt' }\n      - { rxp: '^max_log_file_action', line: 'max_log_file_action = keep_logs' }\n    notify: restart auditd\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n      - section8.1.1.2\n      - section8.1.1.3\n\n  - name: 8.1.2 Install and Enable auditd Service (Scored)\n    apt: name=auditd state=present\n    tags:\n      - section8\n      - section8.1\n      - section8.1.2\n      - section8.1.2\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    stat: path=/etc/default/grub\n    register: grubcfg_file\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    file: >\n        path=/etc/default/grub\n        state=touch\n    when: not grubcfg_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    lineinfile: >\n        dest=/etc/default/grub\n        line='GRUB_CMDLINE_LINUX=\"audit=1\"'\n    when: not grubcfg_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.4 Record Events That Modify Date and Time Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a always,exit -F arch=b64 -S adjtimex -S settimeofday -k time-change'\n      - '-a always,exit -F arch=b32 -S adjtimex -S settimeofday -S stime -k time-change'\n      - '-a always,exit -F arch=b64 -S clock_settime -k time-change'\n      - '-a always,exit -F arch=b32 -S clock_settime -k time-change'\n      - '-w /etc/localtime -p wa -k time-change'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"64\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.4\n\n  - name: 8.1.4 Record Events That Modify Date and Time Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line={{ item }}\n      state=present\n      create=yes\n    with_items:\n      - '-a always,exit -F arch=b32 -S adjtimex -S settimeofday -S stime -k time-change'\n      - '-a always,exit -F arch=b32 -S clock_settime -k time-change'\n      - '-w /etc/localtime -p wa -k time-change'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"32\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.4\n\n  - name: 8.1.5,7,8,9,15,16,17 Record Events That Modify User/Group Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-w /etc/group -p wa -k identity'\n      - '-w /etc/passwd -p wa -k identity'\n      - '-w /etc/gshadow -p wa -k identity'\n      - '-w /etc/shadow -p wa -k identity'\n      - '-w /etc/security/opasswd -p wa -k identity'\n      - '-w /var/log/faillog -p wa -k logins'\n      - '-w /var/log/lastlog -p wa -k logins'\n      - '-w /var/log/tallylog -p wa -k logins'\n      - '-w /var/run/utmp -p wa -k session'\n      - '-w /var/log/wtmp -p wa -k session'\n      - '-w /var/log/btmp -p wa -k session'\n      - '-w /etc/selinux/ -p wa -k MAC-policy'\n      - '-w /etc/sudoers -p wa -k scope'\n      - '-w /var/log/sudo.log -p wa -k actions'\n      - '-w /sbin/insmod -p x -k modules'\n      - '-w /sbin/rmmod -px -k modules'\n      - '-w /sbin/modprobe -p x -k modules'\n    notify: restart auditd\n    tags:\n      - section8\n      - section8.1\n      - section8.1.5\n      - section8.1.7\n      - section8.1.8\n      - section8.1.9\n      - section8.1.15\n      - section8.1.16\n      - section8.1.17\n\n  - name: 8.1.6,10,11,13,14,17 Record Events That Modify the System's Network Environment (64b) (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a exit,always -F arch=b64 -S sethostname -S setdomainname -k system-locale'\n      - '-a exit,always -F arch=b32 -S sethostname -S setdomainname -k system-locale'\n      - '-w /etc/issue -p wa -k system-locale'\n      - '-w /etc/issue.net -p wa -k system-locale'\n      - '-w /etc/hosts -p wa -k system-locale'\n      - '-w /etc/network -p wa -k system-locale'\n      - '-a always,exit -F arch=b64 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b64 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b64 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b32 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b64 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b32 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b64 -S init_module -S delete_module -k modules'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"64\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.6\n      - section8.1.10\n      - section8.1.11\n      - section8.1.13\n      - section8.1.14\n      - section8.1.17\n\n  - name: 8.1.6,10,11,13,14,17 Record Events That Modify the System's Network Environment (32b) (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a exit,always -F arch=b32 -S sethostname -S setdomainname -k system-locale'\n      - '-w /etc/issue -p wa -k system-locale'\n      - '-w /etc/issue.net -p wa -k system-locale'\n      - '-w /etc/hosts -p wa -k system-locale'\n      - '-w /etc/network -p wa -k system-locale'\n      - '-a always,exit -F arch=b32 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b32 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b32 -S init_module -S delete_module -k modules'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"32\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.6\n      - section8.1.10\n      - section8.1.11\n      - section8.1.13\n      - section8.1.14\n      - section8.1.17\n\n  - name: 8.1.12 Collect Use of Privileged Commands (Scored)\n    shell: find / -xdev \\( -perm -4000 -o -perm -2000 \\) -type f | awk '{print \"-a always,exit -F path=\" $1 \" -F perm=x -F auid>=500 -F auid!=4294967295 -k privileged\" }'\n    register: audit_lines_for_find\n    changed_when: False\n    tags:\n      - section8\n      - section8.1\n      - section8.1.12\n\n  - name: 8.1.12 Collect Use of Privileged Commands (infos) (Scored)\n    debug: msg=\"Add a line in auditd for the privileged program\"\n    with_items: audit_lines_for_find.stdout_lines\n    tags:\n      - section8\n      - section8.1\n      - section8.1.12\n\n\n  - name: 8.1.18 Make the Audit Configuration Immutable (Scored)\n    lineinfile: >\n        dest='/etc/audit/audit.rules'\n        line='-e 2'\n        insertafter=EOF\n        state=present\n        create=yes\n    tags:\n      - section8\n      - section8.1\n      - section8.1.18\n\n  - name: 8.3.1 Install AIDE (Scored)\n    apt: name=aide state=present\n    register: aide_installed\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (init) (Scored)\n    command: aideinit\n    when: aide_installed.changed == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (Scored)\n    stat: path=/var/lib/aide/aide.db.new\n    register: aide_db_path\n    when:\n      - aide_installed.changed == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (copy db) (Scored)\n    command: mv /var/lib/aide/aide.db.new /var/lib/aide/aide.db\n    when:\n      - aide_installed.changed == True\n      - aide_db_path.stat.exists == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.2 Implement Periodic Execution of File Integrity (Scored)\n    cron: name=\"Check files integrity\" minute=\"0\" hour=\"5\" job=\"/usr/sbin/aide --check\"\n    tags:\n      - section8\n      - section8.3\n      - section8.3.2\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "f7df2f32c9542ac26755aee7e34bdc4608ed05a5", "filename": "roles/ansible/tower/manage-projects/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: tower\n  roles:\n  - role: ansible/tower/manage-projects\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "83aeb478c30509bda2ebfd0dae6c9711b0883e55", "filename": "tasks/Win32NT/install/tarball.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Mkdir for java installation\n  win_file:\n    path: '{{ java_path }}'\n    state: directory\n\n- name: 'Install java {{ java_full_version }}'\n  win_unzip:\n    src: '{{ java_artifact }}'\n    dest: '{{ java_path }}'\n    creates: '{{ java_path }}\\{{ java_folder }}'\n"}, {"commit_sha": "f92ebbef856e59bd4563d4b5b69ee75a95ec89d5", "sha": "b35b7e479d98497f8f8d1be294b2dd6deceba885", "filename": "roles/openshift-management/tasks/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- name: Validate OpenShift Token Provided\n  fail: msg=\"OpenShift Token Not Provided\"\n  failed_when: (openshift_token is undefined) or (openshift_token is none) or (openshift_token|trim == '')\n  tags: always\n\n- name: Set Facts\n  set_fact: kubeconfig=\"/tmp/openshift-management-{{ ansible_date_time.epoch }}/config\"\n  tags: always\n\n- name: Create Directory\n  file: path=\"{{ kubeconfig | dirname }}\" state=directory\n  notify: cleanup openshift login\n  tags: always\n\n- name: Login to OpenShift\n  shell: oc login --token={{ openshift_token }} {{ openshift_login_insecure_flag }} {{ openshift_master_url }} \n  environment:\n    KUBECONFIG: \"{{ kubeconfig }}\"\n  tags: always\n\n- import_tasks: prune-builds.yml\n  when: \"{{ openshift_prune_builds | default(False) }}\"\n  tags: openshift-management-builds\n\n- import_tasks: prune-deployments.yml\n  when: \"{{ openshift_prune_deployments | default(False) }}\"\n  tags: openshift-management-deployments\n\n- import_tasks: prune-images.yml\n  when: \"{{ openshift_prune_images | default(False) }}\"\n  tags: openshift-management-images\n\n- import_tasks: prune-projects.yml\n  when: \"{{ openshift_prune_projects | default(False) }}\"\n  tags: openshift-management-projects\n\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "6c2310b8469c135486d66bc470f3f629c2a0e770", "filename": "playbooks/roles/check_ntp/handlers/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "---\n- name: Restart chrony\n  service:\n    name: chronyd\n    state: restarted\n\n- name: Restart ntp\n  service:\n    name: ntpd\n    state: restarted\n\n\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "04170eed0bee26655c7b520eb9d591f66ec97246", "filename": "roles/dns/manage-dns-zones/tasks/route53/loop-zones.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: \"Loop over all zones\"\n  include_tasks: loop-records.yml\n  with_items:\n    - \"{{ zones_records.results }}\"\n  loop_control:\n    loop_var: r53_zone\n"}, {"commit_sha": "f26e6a5f816bc8f8672d0b80aa761ae8c459d30a", "sha": "755cf1983c97243016c5e43ac5c6c0917654530b", "filename": "tasks/kernel-3-mount-fixes.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "- name: Stat /proc/sys/fs/may_detach_mounts\n  stat:\n    path: /proc/sys/fs/may_detach_mounts\n  register: may_detach_mounts\n\n- name: Ensure fs.may_detach_mounts is set to avoid 'Device or resource busy'\n  sysctl:\n    name: fs.may_detach_mounts\n    value: 1\n    sysctl_file: /etc/sysctl.d/99-docker.conf\n    reload: yes\n  become: yes\n  when: may_detach_mounts.stat.exists\n\n- name: Ensure /etc/systemd/system/docker.service.d directory exists\n  file:\n    path: /etc/systemd/system/docker.service.d\n    state: directory\n    mode: 0755\n  become: yes\n\n- name: Copy systemd drop-in for Docker Mount Flags slave configuration to avoid 'Device or resource busy'\n  copy:\n    src: files/etc/systemd/system/docker.service.d/mountflags-slave.conf\n    dest: /etc/systemd/system/docker.service.d/mountflags-slave.conf\n  become: yes\n  notify: restart docker\n  when: docker_enable_mount_flag_fix\n  \n- name: Remove systemd drop-in for Docker Mount Flags slave configuration\n  file:\n    path: /etc/systemd/system/docker.service.d/mountflags-slave.conf\n    state: absent\n  become: yes\n  notify: restart docker\n  when: not docker_enable_mount_flag_fix\n"}, {"commit_sha": "2f1ed84fec270723a1031cdc2b07b7a76a5a3bda", "sha": "63164f4ce8b7f7d742a42efb9ecb6644ebc8ff78", "filename": "handlers/main.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n# handlers file for ansible-role-docker-ce\n\n- name: restart docker\n  service:\n    name: docker\n    state: restarted\n  become: true"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "c2185a7fc6233da7126b508f61abb11440beda99", "filename": "playbooks/roles/bb0-openstack/tasks/deprovisioning-post-once.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "---\n\n- name: Add ssh\n  os_keypair:\n    auth:\n      auth_url: \"{{ lookup('env','OS_AUTH_URL') }}\"\n      project_name: \"{{ lookup('env','OS_PROJECT_NAME') }}\"\n      username: \"{{ lookup('env','OS_USERNAME') }}\"\n      password: \"{{ lookup('env','OS_PASSWORD') }}\"\n    state: absent\n    name: openshift-stc-key\n\n# Delete security groups\n- name: \"Delete security groups\"\n  os_security_group:\n    state: absent\n    name: \"{{item.name}}\"\n    description: \"secgroup {{ item.name }} - managed by ansible\"\n  auth:\n      auth_url: \"{{ lookup('env','OS_AUTH_URL') }}\"\n      project_name: \"{{ lookup('env','OS_PROJECT_NAME') }}\"\n      username: \"{{ lookup('env','OS_USERNAME') }}\"\n      password: \"{{ lookup('env','OS_PASSWORD') }}\"\n  with_items:\n     - \"{{ os_sec_groups }}\"\n\n# Delete cloud flare dns \n- name: Optional cloud clare dns\n  block:\n    - name: Delete DNS record bastion\n      cloudflare_dns:\n        zone: \"{{ cloudflare_zone }}\"\n        record: \"bastion{{ cloudflare_name_postfix }}\"\n        type: A\n        account_email: \"{{ cloudflare_account_email }}\"\n        account_api_token: \"{{ cloudflare_account_api_token }}\"\n        state: absent\n\n    - name: Delete DNS record  *.apps\n      cloudflare_dns:\n        zone: \"{{ cloudflare_zone }}\"\n        record: \"*.apps{{ cloudflare_name_postfix }}\"\n        type: A\n        account_email: \"{{ cloudflare_account_email }}\"\n        account_api_token: \"{{ cloudflare_account_api_token }}\"\n        state: absent\n\n    - name: Delete DNS record api\n      cloudflare_dns:\n        zone: \"{{ cloudflare_zone }}\"\n        record: \"api{{ cloudflare_name_postfix }}\"\n        type: A\n        account_email: \"{{ cloudflare_account_email }}\"\n        account_api_token: \"{{ cloudflare_account_api_token }}\"\n        state: absent  \n  when: ( dns_provider | default('nip.io') == \"cloudflare\" )\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "166061904535dd54f2b34f056dc1b0564500d657", "filename": "roles/scm/github.com/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Concatenate the users\n  set_fact:\n    list_of_users: \"{{ users | join(',') }}\"\n\n- name: Create new Github Team in {{ github_org_name }}, and add users {{ users }}\n  uri:\n    url: '{{ github_api_teams }}'\n    headers:\n      Accept: application/vnd.github.hellcat-preview+json\n    method: POST\n    user: '{{ github_api_username }}'\n    password: '{{ github_api_password }}'\n    force_basic_auth: yes\n    status_code: 201\n    body_format: json\n    body: '{\n             \"name\": \"{{ team.name }}\",\n             \"description\": \"{{ team.description | default(team.name) }}\",\n             \"permission\": \"{{ team.permission | default(\"admin\") }}\",\n             \"privacy\": \"{{ team.privacy | default(\"closed\") }}\",\n             \"maintainers\": [ {{ list_of_users }} ]\n           }'\n  register: teams_json_response\n\n- name: Add Repo to existing Github Organization\n  uri:\n    url: '{{ github_api_repos }}'\n    headers:\n      Accept: application/json\n    method: POST\n    user: '{{ github_api_username }}'\n    password: '{{ github_api_password }}'\n    force_basic_auth: yes\n    status_code: 201\n    body_format: json\n    body: '{\n             \"name\": \"{{ item.repo_name }}\",\n             \"description\": \"{{ item.description }}\",\n             \"homepage\": \"https://github.com\",\n             \"private\": {{ item.private_repo_bool | default(\"false\") }},\n             \"has_issues\": {{ item.has_issues | default(\"true\") }},\n             \"has_projects\": {{ item.has_projects | default(\"false\") }},\n             \"has_wiki\": {{ item.has_wiki | default(\"true\") }},\n             \"team_id\": {{ teams_json_response.json.id }},\n             \"auto_init\": {{ item.auto_init | default(\"false\") }}\n           }'\n  with_items: \"{{ repos }}\"\n  register: repos_json_response\n\n- name: Add a new deploy key to the GitHub repositories using basic authentication\n  github_deploy_key:\n    organization: \"{{ github_org_name }}\"\n    repo: \"{{ item.repo_name }}\"\n    name: \"deploy-key-{{ item.repo_name }}\"\n    key: \"{{ item.deploy_key_location }}\"\n    read_only: \"{{ item.deploy_key_read_only | default('no') }}\"\n    username: \"{{ github_api_username }}\"\n    password: \"{{ github_api_password }}\"\n    otp: \"{{ github_api_otp | default('123456') }}\"\n  with_items: \"{{ repos }}\"\n  register: deploy_keys_json_response\n\n- name: \"Create a temporary directory to use\"\n  tempfile:\n    state: directory\n  register: tmp_dir\n  notify: github.com cleanup temp\n\n- name: Seed Repo with another repo\n  git:\n    repo: '{{ item.seed_repo_url }}'\n    dest: '{{ tmp_dir.path }}/{{ item.repo_name }}'\n    version: '{{ item.seed_repo_version | default(\"HEAD\") }}'\n  with_items: '{{ repos }}'\n\n- name: Set seed repo to new locations\n  command: >\n    git remote set-url origin https://{{ github_api_username }}:{{ github_api_password }}@github.com/{{ github_org_name }}/{{ item.repo_name }}.git\n  args:\n    chdir: \"{{ tmp_dir.path }}/{{ item.repo_name }}\"\n  with_items: \"{{ repos }}\"\n\n- name: Push repos up to new locations\n  command: >\n    git push origin master\n  args:\n    chdir: \"{{ tmp_dir.path }}/{{ item.repo_name }}\"\n  with_items: \"{{ repos }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a903180a20d57df6ea8bd93b38156da7d7cec407", "filename": "roles/rhsm/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Testing RHSM functional for Satellite 6 integration\n  hosts: test-sat6\n  roles:\n  - role: rhsm \n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "37c99a58da1133676b2e200f988020c16f5b454c", "filename": "roles/activity-server/files/lang_templates/es/activity", "repository": "iiab/iiab", "decoded_content": "<div class=\"olpc-activity-info\">\n<h2>%(name)s</h2>\n%(description)s\n<ul>\n <li>Identificador: <span class=\"olpc-activity-id\">%(bundle_id)s</span></li>\n <li>Versi\u00f3n: <span class=\"olpc-activity-version\">%(activity_version)s</span></li>\n <li>URL: <span class=\"olpc-activity-url\"><a href=\"%(bundle_url)s\">%(bundle_url)s</a></span></li>\n <li style=\"display: %(show_older_versions)s\">Versiones anteriores: %(older_versions)s</li>\n</ul>\n</div>\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "12abca623301819d612960f5949807ab4c998df9", "filename": "roles/keepalived/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: prereq.yml\n- import_tasks: keepalived-config.yml\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "b0f3bec0a6c391fa1928e75c0d5140d0f4f6cf5e", "filename": "roles/config-dns-server/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: prereq.yml\n- import_tasks: named.yml\n- import_tasks: named_keys.yml\n- import_tasks: named_zones.yml\n- import_tasks: print_keys.yml\n"}, {"commit_sha": "65a0d28b6ec721aa7a5396f559b1085d61ac3c90", "sha": "dbc41cfae5a13d69813f189085f9705636204791", "filename": "tasks/section_09_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 9.1.1.1 Check that cron conf file exists (check) (Scored)\n    stat: path=/etc/init/cron.conf\n    register: cron_conf_stat\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.1\n\n  - name: 9.1.1.2 Enable cron Daemon (Scored)\n    lineinfile: >\n        dest='/etc/init/cron.conf'\n        line='start on runlevel [2345]'\n        state=present\n    when: not cron_conf_stat.stat.exists\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.2\n\n  - name: 9.1.2 Set User/Group Owner and Permission on /etc/crontab (Scored)\n    file: path='/etc/crontab' owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.2\n\n  - name: 9.1.3 Set User/Group Owner and Permission on /etc/cron.hourly (Scored)\n    file: path=/etc/cron.hourly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.3\n\n  - name: 9.1.4 Set User/Group Owner and Permission on /etc/cron.daily (Scored)\n    file: path=/etc/cron.daily owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.4\n\n  - name: 9.1.5 Set User/Group Owner and Permission on /etc/cron.weekly(Scored)\n    file: path=/etc/cron.weekly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.5\n\n  - name: 9.1.6 Set User/Group Owner and Permission on /etc/cron.monthly(Scored)\n    file: path=/etc/cron.monthly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.6\n\n  - name: 9.1.7 Set User/Group Owner and Permission on /etc/cron.d (Scored)\n    file: path=/etc/cron.d owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.7\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (Scored)\n    file: path={{ item }} state=absent\n    with_items:\n        - /etc/cron.deny\n        - /etc/at.deny\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n  \n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    stat: path=/etc/cron.allow\n    register: cron_allow_path\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    shell: touch /etc/cron.allow\n    when: cron_allow_path.stat.exists == False\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (Scored)\n    file: path=/etc/cron.allow owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    stat: path=/etc/at.allow\n    register: at_allow_path\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    shell: touch /etc/at.allow\n    when: at_allow_path.stat.exists == False\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (Scored)\n    file: path=/etc/at.allow owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n \n  - name: 9.2.1 Set Password Creation Requirement Parameters Usingpam_cracklib (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password'\n        regexp=\"pam_cracklib.so\"\n        line=\"password required pam_cracklib.so retry=3 minlen=14 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.1\n\n#Note for section 9.2.2:\n#If a user has been locked out because they have reached the maximum consecutive failure count \n#defined by denied= in the pam_tally2.so module, the user can be unlocked by issuing the command\n#/sbin/pam_tally2 -u username --reset\n#This command sets the failed count to 0, effectively unlocking the user\n  - name: 9.2.2 Set Lockout for Failed Password Attempts (Not Scored)\n    lineinfile: >\n        dest='/etc/pam.d/login' \n        regexp='pam_tally2'\n        line=\"auth required pam_tally2.so onerr=fail audit silent deny=5 unlock_time=900\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.2\n\n  - name: 9.2.3 Limit Password Reuse (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password' \n        regexp='remember=5'\n        line=\"password sufficient pam_unix.so remember=5\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.3\n\n  - name: 9.3 Check if ssh is installed (check)\n    stat: path='/etc/ssh/sshd_config'\n    register: ssh_config_file\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n\n  - name: 9.3.1 Set SSH Protocol to 2 (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config' \n        regexp='^Protocol'\n        state=present\n        line='Protocol 2'\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n  - name: 9.3.2 Set LogLevel to INFO (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config' \n        regexp='^LogLevel'\n        state=present\n        line='LogLevel INFO'\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.2\n\n  - name: 9.3.3 Set Permissions on /etc/ssh/sshd_config (Scored)\n    file: path='/etc/ssh/sshd_config' owner=root group=root mode=600\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.3\n\n#Regroups sections 9.3.4 9.3.7 9.3.8 9.3.9 9.3.10\n  - name: 9.3.{4,7,8,9,10} Disable some SSH options (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^{{ item }}'\n        line='{{ item }} no'\n        state=present\n    with_items: \n      - X11Forwarding\n      - HostbasedAuthentication\n      - PermitRootLogin\n      - PermitEmptyPasswords\n      - PermitUserEnvironment\n    tags:\n      - section9\n      - section9.3\n      - section9.3.4\n      - section9.3.7\n      - section9.3.8\n      - section9.3.9\n      - section9.3.10\n\n  - name: 9.3.5 Set SSH MaxAuthTries to 4 or Less (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^MaxAuthTries'\n        line='MaxAuthTries 4'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.5\n\n  - name: 9.3.6 Set SSH IgnoreRhosts to Yes (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^IgnoreRhosts'\n        line='IgnoreRhosts yes'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.6\n\n  - name: 9.3.11 Use Only Approved Cipher in Counter Mode (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Ciphers'\n        line='Ciphers aes128-ctr,aes192-ctr,aes256-ctr'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.11\n\n  - name: 9.3.12.1 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveInterval'\n        line='ClientAliveInterval 300'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.1\n\n  - name: 9.3.12.2 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveCountMax'\n        line='ClientAliveCountMax 0'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.2\n\n  - name: 9.3.13.1 Limit Access via SSH (Scored)\n    shell: grep AllowUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.1\n\n  - name: 9.3.13.2 Limit Access via SSH (Scored)\n    shell: grep AllowGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.2\n\n  - name: 9.3.13.3 Limit Access via SSH (Scored)\n    shell: grep DenyUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.3\n\n  - name: 9.3.13.4 Limit Access via SSH (Scored)\n    shell: grep DenyGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.4\n\n  - name: 9.3.14 Set SSH Banner (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Banner'\n        line='Banner /etc/issue.net'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.14\n\n  - name: 9.4 Restrict root Login to System Console (Not Scored)\n    stat: path=/etc/securetty\n    register: securetty_file\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.4 Restrict root Login to System Console (Not Scored)\n    debug: msg='*** Check /etc/securetty for console allowed for root access ***'\n    when: securetty_file.stat.exists == True\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.5.1 Restrict Access to the su Command (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/su'\n        line='auth            required        pam_wheel.so use_uid'\n        state=present\n    tags:\n      - section9\n      - section9.5\n      - section9.5.1\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "71d7e5d76d18182ce291c61a20e3d3e5d61bf5ff", "filename": "archive/roles/cicd/handlers/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n- name: reload systemd\n  command: systemctl daemon-reload\n  \n- name: restart httpd\n  service: \n    name: httpd\n    state: restarted\n\n- name: restart nexus\n  service: \n    name: nexus\n    state: restarted\n    \n- name: restart jenkins\n  service: \n    name: jenkins\n    state: restarted\n  \n- name: restart docker\n  service:\n    name: docker\n    state: restarted"}, {"commit_sha": "2a05a5032ce341d6a1d918453164c59ea2922f58", "sha": "8f6c1fb9b8920229246445aed560d6d4083e7557", "filename": "meta/main.yml", "repository": "CSCfi/fgci-ansible", "decoded_content": "---\ngalaxy_info:\n  author: Lu\u00eds Alves & Johan Guldmyr\n  description: Configures an FGCI cluster\n  company: CSC\n  # If the issue tracker for your role is not on github, uncomment the\n  # next line and provide a value\n  # issue_tracker_url: http://example.com/issue/tracker\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: MIT\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your \n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  - name: EL\n    versions:\n  #  - all\n  #  - 5\n  #  - 6\n     - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #  - 21\n  #  - 22\n  #- name: Windows\n  #  versions:\n  #  - all\n  #  - 2012R2\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  #- name: Ubuntu\n  #  versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n  #  - trusty\n  #  - utopic\n  #  - vivid\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - jessie\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  #- cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  - clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies: []\n  # List your role dependencies here, one per line.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n  \n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "6414718aca3c888d141deb342c1f0263040f0eb6", "filename": "roles/ansible/tower/config-ansibletower/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: tower\n  roles:\n  - role: ansible/tower/config-ansibletower\n"}, {"commit_sha": "481f7ad18dc225973e1d676d33e58c49cbbfe986", "sha": "7a242d535262f5ea2214ebb75e3f61a0a6e9e434", "filename": "tasks/django.yml", "repository": "openwisp/ansible-openwisp2", "decoded_content": "- name: openwisp_users present in settings.py?\n  shell: >\n    test -f {{ openwisp2_path }}/openwisp2/settings.py &&\n    grep openwisp_users {{ openwisp2_path }}/openwisp2/settings.py | wc -l\n  failed_when: false\n  changed_when: false\n  register: openwisp_users_check\n\n# perform migration to multitenant version of OpenWISP 2\n- import_tasks: multitenancy_migration.yml\n  when: openwisp_users_check.rc == 0 and openwisp_users_check.stdout == \"0\"\n\n- name: create {{ openwisp2_path }}\n  file:\n    path: \"{{ openwisp2_path }}\"\n    state: directory\n    group: \"{{ www_group }}\"\n    mode: 0775\n\n- name: create \"{{ openwisp2_path }}/openwisp2\"\n  file:\n    path: \"{{ openwisp2_path }}/openwisp2\"\n    state: directory\n    group: \"{{ www_group }}\"\n    mode: 0775\n\n- name: create \"{{ openwisp2_path }}/log\"\n  file:\n    path: \"{{ openwisp2_path }}/log\"\n    state: directory\n    group: \"{{ www_group }}\"\n    mode: 0775\n\n- name: manage.py\n  notify: reload supervisor\n  template:\n    src: ../templates/manage.py\n    dest: \"{{ openwisp2_path }}/manage.py\"\n    group: \"{{ www_group }}\"\n    mode: 0754\n\n- name: __init__.py\n  notify: reload supervisor\n  template:\n    src: ../templates/openwisp2/__init__.py\n    dest: \"{{ openwisp2_path }}/openwisp2/__init__.py\"\n    group: \"{{ www_group }}\"\n\n- name: urls.py\n  notify: reload supervisor\n  template:\n    src: ../templates/openwisp2/urls.py\n    dest: \"{{ openwisp2_path }}/openwisp2/urls.py\"\n    group: \"{{ www_group }}\"\n\n- name: wsgi.py\n  notify: reload supervisor\n  template:\n    src: ../templates/openwisp2/wsgi.py\n    dest: \"{{ openwisp2_path }}/openwisp2/wsgi.py\"\n    group: \"{{ www_group }}\"\n\n- name: asgi.py\n  notify: reload supervisor\n  template:\n    src: ../templates/openwisp2/asgi.py\n    dest: \"{{ openwisp2_path }}/openwisp2/asgi.py\"\n    group: \"{{ www_group }}\"\n\n# set openwisp2_secret_key if not defined explicitly\n- import_tasks: django_secret_key.yml\n  when: openwisp2_secret_key is not defined\n\n- name: settings.py\n  notify: reload supervisor\n  template:\n    src: ../templates/openwisp2/settings.py\n    dest: \"{{ openwisp2_path }}/openwisp2/settings.py\"\n    group: \"{{ www_group }}\"\n\n- name: migrate\n  notify: reload supervisor\n  become: yes\n  become_user: \"{{ www_user }}\"\n  django_manage:\n    app_path: \"{{ openwisp2_path }}\"\n    command: migrate\n    virtualenv: \"{{ virtualenv_path }}\"\n\n- name: set permissions to sqlite db\n  when: openwisp2_database.engine == \"django.db.backends.sqlite3\"\n  file:\n    path: \"{{ openwisp2_database.name }}\"\n    state: file\n    group: \"{{ www_group }}\"\n    mode: 0775\n\n- name: collectstatic\n  notify: reload supervisor\n  become: yes\n  become_user: \"{{ www_user }}\"\n  django_manage:\n    app_path: \"{{ openwisp2_path }}\"\n    command: \"collectstatic --noinput\"\n    virtualenv: \"{{ virtualenv_path }}\"\n\n- name: create load_initial_data.py script\n  template:\n    src: ../templates/load_initial_data.py\n    dest: \"{{ openwisp2_path }}/load_initial_data.py\"\n    mode: 0754\n\n- name: load initial data\n  command: \"env/bin/python load_initial_data.py\"\n  register: load_initial_data_result\n  changed_when: '\"created\" in load_initial_data_result.stdout'\n  args:\n    chdir: \"{{ openwisp2_path }}\"\n"}, {"commit_sha": "2a05a5032ce341d6a1d918453164c59ea2922f58", "sha": "ef7890b05b6831ad0a63f92e9e24315489593163", "filename": "roles/network_interface/vars/Debian.yml", "repository": "CSCfi/fgci-ansible", "decoded_content": "---\n\nnetwork_pkgs:\n  - python-selinux\n  - bridge-utils\n  - ifenslave-2.6\n\nnet_path: \"/etc/network/interfaces.d\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "1b7889a88c3f31022d0b988d38c5438e5b9a0a60", "filename": "playbooks/osp/provision-osp-instance.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Provision Instance(s)\n  hosts: osp-provisioner\n  roles:\n  - role: osp/admin-volume\n  - role: osp/admin-sec-group\n  - role: osp/admin-instance\n\n- name: Refresh Server inventory\n  hosts: osp-provisioner\n  gather_facts: False\n  tasks:\n  - meta: refresh_inventory\n\n- name: Print Instance info + Wait for Instances to come alive\n  hosts: osp_instances\n  gather_facts: false\n  tasks:\n  - name: Debug hostvar\n    debug:\n      msg: \"{{ hostvars[inventory_hostname] }}\"\n      verbosity: 2\n  - name: waiting for server to come back\n    local_action:\n      module: wait_for\n      host: \"{{ hostvars[inventory_hostname]['ansible_ssh_host'] }}\"\n      port: 22\n      delay: 10\n      timeout: 300\n\n- name: \"Ensure the host is ready for Ansible\"\n  hosts: osp_instances\n  gather_facts: no\n  roles:\n  - role: ansible/prep-for-ansible\n\n- name: \"Workaround for .novalocal\"\n  hosts: osp_instances\n  tasks:\n  - name: \"Eliminate the .novalocal at the end of the FQDN\"\n    hostname:\n      name: \"{{ ansible_fqdn | regex_replace('(.*).novalocal$', '\\\\1') }}\"\n  - name: \"Ensure the local host can resolve by its own IP\"\n    lineinfile:\n      path: /etc/hosts\n      regexp: \"^{{ ansible_default_ipv4.address }}.*\"\n      line: \"{{ ansible_default_ipv4.address }} {{ ansible_fqdn | regex_replace('(.*).novalocal$', '\\\\1') }}\"\n  - name: \"Ensure the changes stick during reboot\"\n    stat: path=/etc/cloud/cloud.cfg\n    register: cloud_cfg\n  - lineinfile:\n      dest: /etc/cloud/cloud.cfg\n      state: present\n      regexp: \"{{ item.regexp }}\"\n      line: \"{{ item.line }}\"\n    with_items:\n    - { regexp: '^ - set_hostname', line: '# - set_hostname' }\n    - { regexp: '^ - update_hostname', line: '# - update_hostname' }\n    when: cloud_cfg.stat.exists == True\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "5fa8bf2e44b33b95983184cccc820e97ba270e16", "filename": "roles/dns/config-dns-server-bind/tests/inventory/group_vars/forward-server.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nnamed_config:\n  recursion: 'yes'\n  dnssec_enable: 'yes'\n  dnssec_validation: 'yes'\n  dnssec_lookaside: 'no'\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "43839eb7f3cde573bccae76f35b38890228dc715", "filename": "roles/kalite/tasks/assessment.yml", "repository": "iiab/iiab", "decoded_content": "# This is for an OS other than Fedora 18\n\n# The stock install puts a small /library/ka-lite/content/assessmentitems.sqlite file, so use size instead of exists\n- name: See if assessment is already installed\n  stat: path=\"{{ kalite_root }}/content/assessment/khan/assessmentitems.sqlite\"\n  register: khan_assessment_installed\n\n- name: Run the assessment setup using kalite manage\n  command: \"{{ kalite_program }} manage unpack_assessment_zip {{ downloads_dir }}/khan_assessment.zip\"\n  environment:\n     KALITE_HOME: \"{{ kalite_root }}\"\n  async: 900\n  poll: 10\n  when: not khan_assessment_installed.stat.exists or khan_assessment_installed.stat.size < 20000\n"}, {"commit_sha": "1224adf2811c827a09ff0bf133fbb476901a547d", "sha": "78583afe5f1453e6a8f7401926a0eba5bf729c13", "filename": "tasks/ip-list.yml", "repository": "nusenu/ansible-relayor", "decoded_content": "---\n\n# workaround for this ansible IPv6 filter bug\n# https://github.com/ansible/ansible/issues/14829\n# we simply convert False to empty lists\n- name: workaround for ansible bug 14829 (1/3)\n  set_fact:\n    v6tmp: []\n  when: v6tmp == False\n\n- name: workaround for ansible bug 14829 (2/3)\n  set_fact:\n    tor_v6ips: \"{{ v6tmp[0:ipv4_count|int]|ipv6('address') }}\"\n\n- name: workaround for ansible bug 14829 (3/3)\n  set_fact:\n    tor_v6ips: []\n  when: tor_v6ips == False\n\n- name: setup IP list (1/2)\n  set_fact:\n    ips:\n        ipv4: \"{{ item.0 }}\"\n        ipv6: \"{{ item.1 }}\"\n  with_together:\n        - \"{{ tor_v4ips }}\"\n        - \"{{ tor_v6ips }}\"\n  register: ipsinterm\n\n- name: setup IP list (2/2)\n  set_fact:\n    tor_ips: \"{{ ipsinterm.results | map(attribute='ansible_facts.ips')|list}}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "f565250f82cc75ddc01862cfda985aeab3bed028", "filename": "roles/kiwix/templates/iiab-make-apache-config.py", "repository": "iiab/iiab", "decoded_content": "#!/usr/bin/python\n# write out proxy definitions for zim currently loaded\n\nimport os, sys, syslog\n\niiab_zim_path = \"{{ iiab_zim_path }}\"\nkiwix_apache_config = \"/etc/{{ apache_config_dir }}/kiwix.conf\"\n\ndef main ():\n    content = iiab_zim_path + \"/content/\"\n    index = iiab_zim_path + \"/index/\"\n\n    # remove existing file\n    try:\n        os.remove(kiwix_apache_config)\n    except:\n        pass\n\n    with open(kiwix_apache_config, 'w') as fp:\n       fp.write(\"RewriteEngine on\\n\")\n       fp.write(\"ProxyPreserveHost on\\n\")\n       fp.write(\"ProxyPass /kiwix  http://127.0.0.1:3000\\n\")\n       fp.write(\"ProxyPassReverse /kiwix  http://127.0.0.1:3000\\n\")\n\n       for filename in os.listdir(content):\n          zimpos = filename.find(\".zim\")\n          if zimpos != -1:\n\t     filename = filename[:zimpos]\n          fp.write(\"RewriteRule %s(.*)  http://127.0.0.1:3000/%s$1 [P]\\n\"% (filename,filename))\n          fp.write(\"ProxyPassReverse %s$1 http://localhost:3000/%s$1\\n\" % (filename,filename))\n\n\n\n\nif __name__ == \"__main__\":\n\n    # Run the main routine\n    main()\n\n# vim: tabstop=3 shiftwidth=3 expandtab softtabstop=3\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "c0ae0d0322c25fc96c22f7369def58a8a84f5334", "filename": "tasks/create_repo_yum_proxy_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_yum_proxy\n    args: \"{{ _nexus_repos_yum_defaults|combine(item) }}\"\n"}, {"commit_sha": "a77a8900bb9032eb97498fbb9149d4504e73b0b5", "sha": "b9085fa38afbca75b81064763b78ab8fdd26c905", "filename": "tasks/main.yml", "repository": "geerlingguy/ansible-role-solr", "decoded_content": "---\n- include: user.yml\n  when: solr_create_user\n\n- name: Set solr_filename for Solr 4+.\n  set_fact:\n    solr_filename: \"solr-{{ solr_version }}\"\n  when: \"solr_version.split('.')[0] >= '4'\"\n\n- name: Set solr_filename for Solr 3.x.\n  set_fact:\n    solr_filename: \"apache-solr-{{ solr_version }}\"\n  when: \"solr_version.split('.')[0] == '3'\"\n\n- name: Download Solr.\n  get_url:\n    url: \"{{ solr_mirror }}/lucene/solr/{{ solr_version }}/{{ solr_filename }}.tgz\"\n    dest: \"{{ solr_workspace }}/{{ solr_filename }}.tgz\"\n    force: no\n\n- name: Expand Solr.\n  unarchive:\n    src: \"{{ solr_workspace }}/{{ solr_filename }}.tgz\"\n    dest: \"{{ solr_workspace }}\"\n    creates: \"{{ solr_workspace }}/{{ solr_filename }}/CHANGES.txt\"\n    copy: no\n\n# Install Solr < 5.\n- include: install-pre5.yml\n  when: \"solr_version.split('.')[0] < '5'\"\n\n# Install Solr 5+.\n- include: install.yml\n  when: \"solr_version.split('.')[0] >= '5'\"\n\n- name: Ensure solr is started and enabled on boot.\n  service:\n    name: \"{{ solr_service_name }}\"\n    state: started\n    enabled: yes\n\n# Create cores, if any are configured.\n- include: cores.yml\n  when: \"solr_cores and solr_version.split('.')[0] >= '5'\"\n\n# Configure solr.\n- include: configure.yml\n  when: \"solr_version.split('.')[0] >= '5'\"\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "878877b0776c44f55fc4e458f70840f31da5bb01", "filename": "playbooks/roles/bb0-openstack/tests/inventory", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "localhost\n\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "56167f9a1c01b2091b9da85c855d8178d1f8fe6d", "filename": "roles/common/defaults/main.yml", "repository": "roots/trellis", "decoded_content": "minimum_ansible_version: 1.9.2\ndefault_timezone: Etc/UTC\n"}, {"commit_sha": "f92ebbef856e59bd4563d4b5b69ee75a95ec89d5", "sha": "82622528447599461343ea65b407ede6a7b1ad27", "filename": "roles/openshift-applier/tests/README.md", "repository": "redhat-cop/casl-ansible", "decoded_content": "# Instructions\n\n1. Ensure the 'oc' client is part of your path \n2. Login as a cluster-admin on the OpenShift cluster\n3. Execute with ansible, i.e.:\n\n```\n  > ansible-playbook -i inventory test.yml\n```\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "9ffb1e87075542fd8aaeaade2f9f8ed80e251bcf", "filename": "roles/pathagar/templates/prod_settings.py", "repository": "iiab/iiab", "decoded_content": "from settings import *\n\nFORCE_SCRIPT_NAME = '{{ pathagar_subpath }}'\nLOGIN_REDIRECT_URL = FORCE_SCRIPT_NAME\n\nMEDIA_ROOT = '{{ pathagar_media }}'\nMEDIA_URL = '{{ pathagar_subpath }}/static_media/'\n\nSECRET_KEY = '7ks@b7+gi^c4adff)6ka228#rd4f62v*g_dtmo*@i62k)qn=cs'\nDATABASES = {\n    'default': {\n            'ENGINE':'django.db.backends.postgresql_psycopg2',\n            'NAME': '{{ pathagar_db_name }}',\n            'USER': '{{ pathagar_db_user }}',\n            'PASSWORD': '{{ pathagar_db_password }}',\n            'HOST': '127.0.0.1',\n            'PORT': '5432',\n        }\n}\n\nSTATIC_ROOT = '{{ pathagar_collectstatic }}'\nSTATIC_URL = '{{ pathagar_subpath }}/static/'\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "66a1015b9129d1ae6904d3313ab1c62d198364c8", "filename": "roles/ovirt-guest-agent/defaults/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\novirt_guest_agent_pkg_prefix: ovirt\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "90febf02a6931d3a86a0c549911772cc0ee890c7", "filename": "roles/ansible/tower/manage-inventories/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- block: # when ansible_tower.inventories is defined\n\n  - name: \"Set default values\"\n    set_fact:\n      processed_inventories: []\n      existing_organizations_output: []\n\n  # Utilize the `rest_get` library routine to ensure REST pagination is handled\n  - name: \"Get the existing organizations\"\n    rest_get:\n      host_url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}\"\n      rest_user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      rest_password: \"{{ ansible_tower.admin_password }}\"\n      api_uri: \"/api/v2/organizations/\"\n    register: existing_organizations_output\n\n  - name: \"Process the inventory entries\"\n    include_tasks: process-inventory.yml\n    with_items:\n    - \"{{ ansible_tower.inventories }}\"\n    loop_control:\n      loop_var: inventory\n\n  - name: \"Elminate the inventories that should not be present\"\n    uri:\n      url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}/api/v2/inventories/{{ item.id }}/\"\n      user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      password: \"{{ ansible_tower.admin_password }}\"\n      force_basic_auth: yes\n      method: DELETE\n      validate_certs: no\n      status_code: 200,202,204\n    with_items:\n    - \"{{ existing_inventories_output.rest_output | get_remaining_items(processed_inventories, 'name', 'name')}}\"\n\n  when:\n  - ansible_tower.inventories is defined\n"}, {"commit_sha": "35c4af9fd84d7a7e6bc093adc944b352e68d6ff1", "sha": "f9e383461e8e4b24b6e376f5f1220b148380792f", "filename": "tasks/main-Fedora.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n# tasks file for ansible-role-docker-ce\n\n- name: Add Docker CE repository\n  get_url:\n    url: https://download.docker.com/linux/fedora/docker-ce.repo\n    dest: /etc/yum.repos.d/docker-ce.repo\n    mode: 0644\n  become: true\n  register: dnf_repo\n\n- name: Determine Docker CE Edge repo status\n  shell: dnf config-manager --dump docker-ce-edge | grep enabled\n  args:\n    warn: false\n  ignore_errors: yes\n  changed_when: false\n  register: cmd_docker_ce_edge_enabled\n\n- name: Set current Docker CE Edge repo status fact\n  set_fact:\n    fact_docker_ce_edge_enabled: \"{{ cmd_docker_ce_edge_enabled.stdout == 'enabled = True' }}\"\n\n- name: Enable/Disable Docker CE Edge Repository\n  shell: dnf config-manager --set-{{ (docker_enable_ce_edge == true) | ternary('enabled','disabled') }} docker-ce-edge\n  become: true\n  when: fact_docker_ce_edge_enabled != docker_enable_ce_edge\n\n- name: Update dnf cache\n  shell: dnf makecache fast\n  become: true\n  when: dnf_repo.changed\n\n- name: Install python and deps for ansible modules\n  raw: dnf install -y python2 python2-dnf libselinux-python\n  become: true\n  changed_when: false\n\n- include: main-Generic.yml"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "b2e388c26bd738fce8dd44b5effce45c4a08cc41", "filename": "playbooks/openshift/end-to-end.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n# Provision Openstack Instances\n- import_playbook: provision-instances.yml\n\n# Pre-Install Steps\n- import_playbook: pre-install.yml\n\n# Install\n- import_playbook: install.yml\n\n# Post Install\n- import_playbook: post-install.yml\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "ff6220a8184be9f1239b05d0e005d68308a8e133", "filename": "tasks/Linux/finalize_paths.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Find java_folder\n  find:\n    paths: '{{ java_path }}'\n    recurse: false\n    file_type: directory\n    patterns: '{{ java_folder }}'\n    use_regex: true\n  register: java_dir\n\n- name: Set actual java directory\n  set_fact:\n    java_folder: \"{{ java_dir.files | map(attribute='path') | list | last | basename }}\"\n\n- name: Put java profile\n  template:\n    src: java.sh.j2\n    dest: /etc/profile.d/java.sh\n    owner: root\n    group: root\n    mode: 0555\n\n- name: Check for java binaries existence\n  stat:\n    path: '{{ java_path }}/{{ java_folder }}/bin/{{ binary }}'\n  register: java_binary_collection\n  loop:\n    - java\n    - javac\n    - jar\n    - keytool\n  loop_control:\n    loop_var: binary\n\n- name: Update alternatives\n  alternatives:\n    name: '{{ java_item.binary }}'\n    path: '{{ java_path }}/{{ java_folder }}/bin/{{ java_item.binary }}'\n    link: '/usr/bin/{{ java_item.binary }}'\n    priority: 100\n  when: java_item.stat.exists | bool\n  loop: '{{ java_binary_collection.results }}'\n  loop_control:\n    loop_var: java_item\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "d336e253039efc864e0ce9f5132acefe4c46ace1", "filename": "tasks/Win32NT/fetch/security-fetch/security-winfetch-local.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Copy security policy artifact to destination\n  win_copy:\n    src: '{{ java_unlimited_policy_transport_local }}'\n    dest: '{{ java_download_path }}'\n  register: policy_file_downloaded\n  retries: 5\n  delay: 2\n  until: policy_file_downloaded is succeeded\n\n- name: Downloaded artifact\n  set_fact:\n    security_policy_java_artifact: '{{ policy_file_downloaded.dest }}'\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "3e144d314d083a762d664048e08c19baf8676d14", "filename": "tasks/section_04_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 4.1.1 Restrict Core Dumps (Scored)\n    lineinfile: dest='/etc/security/limits.conf' line=\"* hard core 0\" state=present\n    tags:\n      - section4\n      - section4.1\n      - section4.1.1\n\n  - name: 4.1.2 Restrict Core Dumps (Scored)\n    sysctl: >\n        name=fs.suid_dumpable\n        value=0\n        state=present\n    when: restrict_core_dumps == True\n    tags:\n      - section4\n      - section4.1\n      - section4.1.2\n\n  - name: 4.1.4 Restrict Core Dumps (stat file) (Scored)\n    stat: path='/etc/init/apport.conf'\n    register: apport_present\n    tags:\n      - section4\n      - section4.1\n      - section4.1.4\n\n  - name: 4.1.5 Restrict Core Dumps (Scored)\n    lineinfile: >\n        dest='/etc/init/apport.conf'\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n    when: apport_present.stat.exists == True\n    tags:\n      - section4\n      - section4.1\n      - section4.1.3\n\n  - name: 4.1.6 Restrict Core Dumps (stat file) (Scored)\n    stat: path='/etc/init/whoopsie.conf'\n    register: whoopsie_present\n    tags:\n      - section4\n      - section4.1\n      - section4.1.4\n\n  - name: 4.1.7 Restrict Core Dumps (Scored)\n    lineinfile: >\n        dest='/etc/init/whoopsie.conf'\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n    when: whoopsie_present.stat.exists == True\n    tags:\n      - section4\n      - section4.1\n      - section4.1.4\n\n  - name: 4.2 Enable XD/NX Support on 32-bit x86 Systems (read dmesg) (Not Scored)\n    shell: 'dmesg | grep NX'\n    register: nx_result\n    failed_when: nx_result.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section4\n      - section4.2\n\n  - name: 4.3 Enable Randomized Virtual Memory Region Placement (Scored)\n    sysctl: >\n       name=kernel.randomize_va_space\n       value=2\n       state=present\n    when: enable_aslr\n    tags:\n      - section4\n      - section4.3\n\n  - name: 4.4 Disable Prelink (check) (Scored)\n    stat: path=/usr/sbin/prelink\n    register: prelink_rc\n    tags:\n      - section4\n      - section4.4\n\n  - name: 4.4 Disable Prelink (restore) (Scored)\n    command: '/usr/sbin/prelink -ua'\n    when: prelink_rc.stat.exists == True\n    tags:\n      - section4\n      - section4.4\n\n  - name: 4.4 Disable Prelink (remove) (Scored)\n    apt: purge=yes name='prelink' state=absent\n    when: prelink_rc.stat.exists == True\n    tags:\n      - section4\n      - section4.4\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "86337d4fc059952d18f1bd2ba56245b55e298011", "filename": "playbooks/osp/delete-osp-instance.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Delete Instance(s)\n  hosts: osp-provisioner\n  vars:\n    osp_resource_state: absent \n  roles:\n  - osp/admin-instance\n  - osp/admin-sec-group\n  - osp/admin-volume\n\n"}, {"commit_sha": "a94f9ce4fa32273fd0fad7492d36db4101423cc3", "sha": "39b1fa6f98aefd4f171488522fde744876162d50", "filename": "tasks/setup-repository.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Ensure python and deps for Ansible modules\n  become: true\n  raw: dnf install -y python2 python2-dnf libselinux-python\n  changed_when: false\n  when: _docker_os_dist == \"Fedora\"\n\n- name: Update APT cache\n  become: true\n  apt:\n    update_cache: yes\n  changed_when: false\n  when: _docker_os_dist == \"Ubuntu\" or\n        _docker_os_dist == \"Debian\"\n\n- name: Ensure packages are installed for repository setup\n  become: true\n  package:\n    name: \"{{ item }}\"\n    state: present\n  with_items:\n    - \"{{ docker_repository_related_packages[_docker_os_dist] }}\"\n  when: _docker_os_dist == \"Ubuntu\" or\n        _docker_os_dist == \"Debian\" or\n        _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Add Docker official GPG key\n  become: true\n  apt_key:\n    url: https://download.docker.com/linux/{{ _docker_os_dist|lower }}/gpg\n    state: present\n  when: (_docker_os_dist == \"Ubuntu\" and _docker_os_dist_major_version > '14') or\n        _docker_os_dist == \"Debian\"\n\n- name: Add Docker APT key (alternative for older Ubuntu systems without SNI).\n  become: true\n  shell: \"curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\"\n  args:\n    warn: false\n  changed_when: false\n  when: _docker_os_dist == \"Ubuntu\" and\n        _docker_os_dist_major_version == '14'\n\n- name: Determine channels to be enabled and/or disabled\n  set_fact:\n    _docker_disable_channels: \"{{ docker_channels | difference(_docker_merged_channels) }}\"\n    _docker_enable_channels: \"{{ docker_channels | intersect(_docker_merged_channels) }}\"\n  vars:\n    _docker_mandatory_channel: [ 'stable' ]\n    _docker_merged_channels: \"{{ _docker_mandatory_channel }} + [ '{{ docker_channel }}' ]\"\n\n- name: Add Docker CE repository with correct channels (Ubuntu/Debian)\n  become: true\n  apt_repository:\n    repo: deb [arch=amd64] https://download.docker.com/linux/{{ _docker_os_dist|lower }} {{ _docker_os_dist_release }} {{ _docker_enable_channels | join(\" \") }}\n    state: present\n    filename: 'docker-ce'\n  when: _docker_os_dist == \"Ubuntu\" or\n        _docker_os_dist == \"Debian\"\n\n- name: Add Docker CE repository (Fedora/CentOS/RedHat)\n  become: true\n  get_url:\n    url: \"{{ docker_repository_url[_docker_os_dist] }}\"\n    dest: /etc/yum.repos.d/docker-ce.repo\n    mode: 0644\n  register: _docker_repo\n  when: _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"Fedora\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Disable Docker CE repository channels (Fedora/CentOS/RedHat)\n  become: true\n  shell: \"{{ docker_cmd_enable_disable_edge_repo[_docker_os_dist] }}\"\n  with_items: \"{{ _docker_disable_channels }}\"\n  changed_when: false\n  vars:\n    _item_enabled: false\n  when: _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"Fedora\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Enable Docker CE repository channels (Fedora/CentOS/RedHat)\n  become: true\n  shell: \"{{ docker_cmd_enable_disable_edge_repo[_docker_os_dist] }}\"\n  with_items: \"{{ _docker_enable_channels }}\"\n  changed_when: false\n  vars:\n    _item_enabled: true\n  when: _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"Fedora\" or\n        _docker_os_dist == \"RedHat\"\n\n# disable rt-beta so we don't get a 403 error retrieving repomd.xml\n- name: Check if rhel-7-server-rt-beta-rpms Repository is enabled (RedHat)\n  become: true\n  shell: \"subscription-manager repos --list-enabled | grep rhel-7-server-rt-beta-rpms\"\n  register: cmd_rhel_rt_beta_repo_enabled\n  when: _docker_os_dist == \"RedHat\"\n  changed_when: false\n  failed_when: cmd_rhel_rt_beta_repo_enabled.rc not in [ 0, 1 ]\n\n- name: Disable rhel-7-server-rt-beta-rpms Repository (RedHat)\n  become: true\n  shell: \"subscription-manager repos --disable=rhel-7-server-rt-beta-rpms\"\n  when: _docker_os_dist == \"RedHat\" and cmd_rhel_rt_beta_repo_enabled.rc == 0\n\n# container-selinux package wants this\n- name: Check if rhel-7-server-extras-rpms Repository is enabled (RedHat)\n  become: true\n  shell: \"subscription-manager repos --list-enabled | grep rhel-7-server-extras-rpms\"\n  register: cmd_rhel_extras_repo_enabled\n  when: _docker_os_dist == \"RedHat\"\n  changed_when: false\n  failed_when: cmd_rhel_extras_repo_enabled.rc not in [ 0, 1 ]\n\n- name: Enable rhel-7-server-extras-rpms Repository (RedHat)\n  become: true\n  shell: \"subscription-manager repos --enable=rhel-7-server-extras-rpms\"\n  when: _docker_os_dist == \"RedHat\" and cmd_rhel_extras_repo_enabled.rc == 1\n\n- name: Update repository cache\n  become: true\n  shell: \"{{ docker_cmd_update_repo_cache[_docker_os_dist] }}\"\n  args:\n    warn: false\n  changed_when: false"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "e97eb7ca01a38bc593067f4146e7870a2d886733", "filename": "roles/letsencrypt/defaults/main.yml", "repository": "roots/trellis", "decoded_content": "sites_using_letsencrypt: \"[{% for name, site in wordpress_sites.iteritems() if site.ssl.enabled and site.ssl.provider | default('manual') == 'letsencrypt' %}'{{ name }}',{% endfor %}]\"\nletsencrypt_enabled: \"{{ sites_using_letsencrypt | count > 0 }}\"\nsite_uses_letsencrypt: \"{{ item.value.ssl is defined and item.value.ssl.enabled | default(false) and item.value.ssl.provider | default('manual') == 'letsencrypt' }}\"\nsites_need_confs: \"False in [{% for item in nginx_confs.results if 'stat' in item %}{{ item.stat.exists }},{% endfor %}]\"\n\nacme_tiny_repo: 'https://github.com/diafygi/acme-tiny.git'\nacme_tiny_commit: '5a7b4e79bc9bd5b51739c0d8aaf644f62cc440e6'\n\nacme_tiny_software_directory: /usr/local/letsencrypt\nacme_tiny_data_directory: /var/lib/letsencrypt\nacme_tiny_challenges_directory: \"{{ www_root }}/letsencrypt\"\n\n# Path to the local file containing the account key to copy to the server.\n# Secure this file using Git-crypt for example.\n# Leave this blank to generate a new account key that will need to be registered manually with Letsencrypt.org\n#letsencrypt_account_key_source_file: /my/account.key\n\n# Content of the account key to copy to the server.\n# Secure this key using Ansible Vault for example.\n# Leave this blank to generate a new account key that will need to be registered manually with Letsencrypt.org\n#letsencrypt_account_key_source_content: |\n#  -----BEGIN RSA PRIVATE KEY-----\n#  MIIJKAJBBBKCaGEA63J7t9dqyua5+Q+P6M3iHtLEKpF/AZcZNBHr1F2Oo8+Hfyvl\n#  KWXliiWjUORxDxI1c56Rw2VCIExnFjWJAdSLv6/XaQWo2T7U28bkKbAlCF9=\n#  -----END RSA PRIVATE KEY-----\n\nletsencrypt_ca: 'https://acme-v01.api.letsencrypt.org'\n\nletsencrypt_account_key: '{{ acme_tiny_data_directory }}/account.key'\n\nletsencrypt_intermediate_cert_path: /etc/ssl/certs/lets-encrypt-x3-cross-signed.pem\nletsencrypt_intermediate_cert_url: 'https://letsencrypt.org/certs/lets-encrypt-x3-cross-signed.pem'\nletsencrypt_intermediate_cert_sha256sum: 'e446c5e9dbef9d09ac9f7027c034602492437a05ff6c40011d7235fca639c79a'\n\nletsencrypt_keys_dir: \"{{ nginx_ssl_path }}/letsencrypt\"\nletsencrypt_certs_dir: \"{{ nginx_ssl_path }}/letsencrypt\"\n\n# the minimum age (in days) after which a certificate will be renewed\nletsencrypt_min_renewal_age: 60\n\n# the days of a month the cronjob should be run. Make sure to run it rather often, three times per month is a pretty\n# good value. It does not harm to run it often, as it will only regenerate certificates that have passed a certain age\n# (60 days by default).\nletsencrypt_cronjob_daysofmonth: 1,11,21\n"}, {"commit_sha": "f92ebbef856e59bd4563d4b5b69ee75a95ec89d5", "sha": "0d0696fdc4e6b800dd0b80b28679ff0775db1c9b", "filename": "roles/openshift-management/README.md", "repository": "redhat-cop/casl-ansible", "decoded_content": "OpenShift Cluster Administration Role\n=============================\n\nThis role performs methods to ensure the health and stability of the OpenShift Container Platform Environment\n\n## Management Features\n\n* Pruning Builds\n* Pruning Deployments\n* Pruning Images\n* Pruning Projects\n\n## Required Parameters\n\nThe following parameters are required for the execution of this role\n\n`openshift_token` - OAuth Token associated with a user/service account with *cluster-admin* permissions\n\n## Additional Parameters\n\nEach management action has a set of parameters to tailor its' execution. Management actions contained within this role are disabled by default unless explicitly enabled. The following parameters can be configured with a value of `True` ``to enable each management action:\n\n`openshift_prune_builds`  - Pruning builds\n`openshift_prune_deployments`  - Pruning deployments\n`openshift_prune_images`  - Pruning images in the Integrated Docker Registry\n`openshift_prune_projects`  - Pruning OpenShift projects\n\n## Running Playbooks with this Role\n\nPrune builds, deployments and images\n\n```\nansible-playbook -e \"openshift_token=<token> openshift_prune_builds=True openshift_prune_deployments=True openshift_prune_images=True openshift_prune_projects=True\"\n```\n\n## NOTES\n\n### Minimum Ansible Version\n\n* Requires Ansible **2.2.1.x** or greater\n\n### Hosting Environment\n\n* This role is meant for execution on Linux hosts / targets and may not work correctly on other hosting operating systems.\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "ff9b80777ddae1882e8485fc68abd8be698b6005", "filename": "roles/config-routes/tests/inventory/group_vars/infra_hosts.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nroutes:\n- device: eth0\n  entries:\n  - address: 192.168.10.0\n    netmask: 255.255.255.0\n    gateway: 192.168.1.1 \n  - address: 192.168.11.0\n    netmask: 255.255.255.0\n    gateway: 192.168.1.1\n\n"}, {"commit_sha": "a77a8900bb9032eb97498fbb9149d4504e73b0b5", "sha": "623133b50e124bde8dbee3f86ee01434faa2b171", "filename": "tasks/install-pre5.yml", "repository": "geerlingguy/ansible-role-solr", "decoded_content": "---\n# Install Solr.\n- name: Check if Solr is already installed.\n  stat: \"path={{ solr_install_path }}/dist/{{ solr_filename }}.war\"\n  register: solr_war_file\n\n- name: Copy Solr into place.\n  command: \"cp -r {{ solr_workspace }}/{{ solr_filename }} {{ solr_install_path }}\"\n  when: not solr_war_file.stat.exists\n\n- name: Ensure Solr install files are owned by the solr_user.\n  file:\n    path: \"{{ solr_install_path }}\"\n    owner: \"{{ solr_user }}\"\n    group: \"{{ solr_user }}\"\n    recurse: yes\n  when: not solr_war_file.stat.exists\n\n# Set up solr_home.\n- name: Check if solr_home is already set up.\n  stat: \"path={{ solr_home }}/solr.xml\"\n  register: solr_example\n\n- name: Ensure solr_home directory exists.\n  file:\n    path: \"{{ solr_home }}\"\n    state: directory\n    owner: \"{{ solr_user }}\"\n    group: \"{{ solr_user }}\"\n    mode: 0755\n  when: not solr_example.stat.exists\n\n- name: Copy Solr example into solr_home.\n  shell: \"cp -r {{ solr_install_path }}/example/solr/* {{ solr_home }}\"\n  when: not solr_example.stat.exists\n\n- name: Fix the example solrconfig.xml file.\n  replace:\n    dest: \"{{ solr_home }}/collection1/conf/solrconfig.xml\"\n    regexp: ^.+solr\\.install\\.dir.+$\n    replace: \"\"\n  when: \"not solr_example.stat.exists and solr_version.split('.')[0] == '4'\"\n\n- name: Ensure Solr home files are owned by the solr_user.\n  file:\n    path: \"{{ solr_home }}\"\n    owner: \"{{ solr_user }}\"\n    group: \"{{ solr_user }}\"\n    recurse: yes\n  when: not solr_example.stat.exists\n\n# Set up Solr init script.\n- name: Ensure log file is created and has proper permissions.\n  file:\n    path: \"/var/log/solr.log\"\n    state: touch\n    owner: \"{{ solr_user }}\"\n    group: root\n    mode: 0664\n  changed_when: false\n\n- name: Copy solr init script into place.\n  template:\n    src: \"solr-init-{{ ansible_os_family }}-pre5.j2\"\n    dest: \"/etc/init.d/{{ solr_service_name }}\"\n    mode: 0755\n\n- name: Ensure daemon is installed (Debian).\n  apt: name=daemon state=installed\n  when: ansible_os_family == \"Debian\"\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "119ba7ee656bd94ab77e6975a6d6bc8e113827d4", "filename": "roles/haproxy-config/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nlb_https_backends: {}\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "47afb2f1d82eaa890942e0ebddf7bed51f7609ca", "filename": "roles/notifications/md-to-html/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: \"prereq.yml\"\n  when:\n    - install_prereq|default(False)\n \n- import_tasks: \"convert_md_to_html.yml\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "619f137aec669be593bdde9188bab52f5b4fbb32", "filename": "roles/dns/config-dns-server-bind/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: dns-servers\n  roles:\n  - role: dns/config-dns-server\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "0c6f15c4095e5b2127554f0c1aa8155e2904aefc", "filename": "playbooks/provision-dns-server/configure-dns-server.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: dns-server\n  roles:\n  - role: dns/config-dns-server\n  - role: dns/manage-dns-zones\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "03379b692a43f7158c254217982a7d7f65d4f88f", "filename": "roles/dns/config-dns-server/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: named/main.yml\n\n# Add calls to additional providers here ...\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "36e2ee610eb612106b6c69a0efe28877c3e6c0fa", "filename": "tasks/setup_privilege_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: setup_privilege\n    args: \"{{ _nexus_privilege_defaults|combine(item) }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "6eb869997e1a6344a0ed9557deeec3341dec9478", "filename": "roles/openvpn/templates/client1.crt", "repository": "iiab/iiab", "decoded_content": "Certificate:\n    Data:\n        Version: 3 (0x2)\n        Serial Number: 2 (0x2)\n    Signature Algorithm: sha256WithRSAEncryption\n        Issuer: C=US, ST=NY, L=NewYorkCity, O=UnleashKids, OU=SchoolServer, CN=UnleashKids CA/name=EasyRSA/emailAddress=georgejhunt@gmail.com\n        Validity\n            Not Before: Jun 12 06:56:55 2014 GMT\n            Not After : Jun  9 06:56:55 2024 GMT\n        Subject: C=US, ST=NY, L=NewYorkCity, O=UnleashKids, OU=SchoolServer, CN=client1/name=EasyRSA/emailAddress=georgejhunt@gmail.com\n        Subject Public Key Info:\n            Public Key Algorithm: rsaEncryption\n                Public-Key: (2048 bit)\n                Modulus:\n                    00:ac:5e:07:83:14:aa:2e:c6:db:65:9b:28:f2:50:\n                    67:95:2e:6f:25:85:c8:52:87:03:7e:5a:5d:31:f3:\n                    9e:95:8b:41:bc:72:01:67:6a:56:34:ab:c9:e0:cc:\n                    e5:14:f1:ad:34:56:89:b7:5d:c3:5c:2f:31:46:e1:\n                    0f:fd:da:5e:8b:0c:6e:9b:28:40:9d:aa:fd:d9:05:\n                    d6:2a:62:db:d3:03:a8:76:ac:d9:78:03:c8:71:a9:\n                    7e:1e:fd:8b:9b:81:cd:cd:ea:3c:30:19:a1:76:ba:\n                    bd:1e:08:0f:95:73:7b:ba:30:28:af:37:f0:99:f0:\n                    e5:8e:e9:c1:dd:10:4d:56:f9:5c:38:12:5f:90:63:\n                    5e:19:a0:c1:4d:b6:4e:86:0d:93:6a:ff:40:1b:4e:\n                    fa:51:f2:b0:71:c0:c7:ed:b1:fb:eb:b9:85:01:17:\n                    67:c5:bb:9d:2c:f3:9c:12:99:f6:74:5a:57:c6:a3:\n                    4a:df:0f:cf:5d:09:0c:84:ac:86:1e:82:50:f3:6d:\n                    28:f0:b7:0f:d6:53:41:7a:c8:94:82:c1:a3:56:4f:\n                    eb:08:76:ee:ca:91:52:05:9d:d3:1e:d6:0d:ec:3f:\n                    66:de:ab:0b:a3:03:c2:60:14:b0:83:42:ec:08:dd:\n                    94:7a:ac:13:f9:ac:88:57:be:66:3d:5b:b6:f7:24:\n                    52:79\n                Exponent: 65537 (0x10001)\n        X509v3 extensions:\n            X509v3 Basic Constraints: \n                CA:FALSE\n            Netscape Comment: \n                Easy-RSA Generated Certificate\n            X509v3 Subject Key Identifier: \n                38:23:D3:DB:02:EE:7B:B4:C7:C3:87:AF:5C:C0:19:99:99:0D:BF:58\n            X509v3 Authority Key Identifier: \n                keyid:BD:0C:F9:75:F1:1C:A8:FE:16:72:FB:E4:A7:B3:2C:C1:91:8A:F4:4D\n                DirName:/C=US/ST=NY/L=NewYorkCity/O=UnleashKids/OU=SchoolServer/CN=UnleashKids CA/name=EasyRSA/emailAddress=georgejhunt@gmail.com\n                serial:D4:E9:76:B5:19:24:1C:97\n\n            X509v3 Extended Key Usage: \n                TLS Web Client Authentication\n            X509v3 Key Usage: \n                Digital Signature\n    Signature Algorithm: sha256WithRSAEncryption\n         23:00:c2:e2:a3:89:be:c4:34:ed:cf:33:0e:c4:42:de:49:be:\n         21:e1:4b:49:8f:ad:ed:e8:bd:e2:b9:94:79:9f:ec:0b:a1:f7:\n         66:2d:fe:c1:33:f0:be:ad:04:2a:cf:f4:e5:d1:ef:0b:e1:12:\n         e4:1b:e3:9f:6c:a3:5c:d3:76:8b:14:bf:b2:ff:c0:a1:26:df:\n         36:cf:44:54:51:8a:a5:bf:5e:12:5a:78:ab:2a:72:42:d1:3d:\n         d4:c4:e5:65:9f:b3:eb:47:90:55:9f:e4:00:28:46:69:f8:37:\n         5f:7c:35:b1:b0:2b:c0:d6:a7:98:3b:c7:4a:96:1d:22:a5:79:\n         c8:91:4e:2f:37:d5:58:52:07:4f:e1:e5:c2:7a:42:4f:f3:3b:\n         94:ee:08:84:4c:81:34:9a:c4:b5:27:59:12:48:92:5f:79:57:\n         b5:e3:35:f6:64:ee:9c:e6:3d:61:c4:06:5a:cf:4b:18:33:33:\n         78:d5:0b:15:e7:cd:cd:c4:07:f0:33:f1:78:54:c1:45:d3:4c:\n         fd:fb:a1:5b:f3:d1:ab:89:39:48:b7:aa:75:36:3c:89:1e:bc:\n         f1:40:84:4b:81:15:47:30:6d:ad:5a:b3:a2:4a:db:97:b0:d3:\n         59:99:8a:1b:79:49:e3:eb:32:90:65:9f:c3:ce:18:1b:7d:36:\n         8d:8b:0f:5b\n-----BEGIN CERTIFICATE-----\nMIIFOTCCBCGgAwIBAgIBAjANBgkqhkiG9w0BAQsFADCBrjELMAkGA1UEBhMCVVMx\nCzAJBgNVBAgTAk5ZMRQwEgYDVQQHEwtOZXdZb3JrQ2l0eTEUMBIGA1UEChMLVW5s\nZWFzaEtpZHMxFTATBgNVBAsTDFNjaG9vbFNlcnZlcjEXMBUGA1UEAxMOVW5sZWFz\naEtpZHMgQ0ExEDAOBgNVBCkTB0Vhc3lSU0ExJDAiBgkqhkiG9w0BCQEWFWdlb3Jn\nZWpodW50QGdtYWlsLmNvbTAeFw0xNDA2MTIwNjU2NTVaFw0yNDA2MDkwNjU2NTVa\nMIGnMQswCQYDVQQGEwJVUzELMAkGA1UECBMCTlkxFDASBgNVBAcTC05ld1lvcmtD\naXR5MRQwEgYDVQQKEwtVbmxlYXNoS2lkczEVMBMGA1UECxMMU2Nob29sU2VydmVy\nMRAwDgYDVQQDEwdjbGllbnQxMRAwDgYDVQQpEwdFYXN5UlNBMSQwIgYJKoZIhvcN\nAQkBFhVnZW9yZ2VqaHVudEBnbWFpbC5jb20wggEiMA0GCSqGSIb3DQEBAQUAA4IB\nDwAwggEKAoIBAQCsXgeDFKouxttlmyjyUGeVLm8lhchShwN+Wl0x856Vi0G8cgFn\nalY0q8ngzOUU8a00Vom3XcNcLzFG4Q/92l6LDG6bKECdqv3ZBdYqYtvTA6h2rNl4\nA8hxqX4e/Yubgc3N6jwwGaF2ur0eCA+Vc3u6MCivN/CZ8OWO6cHdEE1W+Vw4El+Q\nY14ZoMFNtk6GDZNq/0AbTvpR8rBxwMftsfvruYUBF2fFu50s85wSmfZ0WlfGo0rf\nD89dCQyErIYeglDzbSjwtw/WU0F6yJSCwaNWT+sIdu7KkVIFndMe1g3sP2beqwuj\nA8JgFLCDQuwI3ZR6rBP5rIhXvmY9W7b3JFJ5AgMBAAGjggFlMIIBYTAJBgNVHRME\nAjAAMC0GCWCGSAGG+EIBDQQgFh5FYXN5LVJTQSBHZW5lcmF0ZWQgQ2VydGlmaWNh\ndGUwHQYDVR0OBBYEFDgj09sC7nu0x8OHr1zAGZmZDb9YMIHjBgNVHSMEgdswgdiA\nFL0M+XXxHKj+FnL75KezLMGRivRNoYG0pIGxMIGuMQswCQYDVQQGEwJVUzELMAkG\nA1UECBMCTlkxFDASBgNVBAcTC05ld1lvcmtDaXR5MRQwEgYDVQQKEwtVbmxlYXNo\nS2lkczEVMBMGA1UECxMMU2Nob29sU2VydmVyMRcwFQYDVQQDEw5VbmxlYXNoS2lk\ncyBDQTEQMA4GA1UEKRMHRWFzeVJTQTEkMCIGCSqGSIb3DQEJARYVZ2Vvcmdlamh1\nbnRAZ21haWwuY29tggkA1Ol2tRkkHJcwEwYDVR0lBAwwCgYIKwYBBQUHAwIwCwYD\nVR0PBAQDAgeAMA0GCSqGSIb3DQEBCwUAA4IBAQAjAMLio4m+xDTtzzMOxELeSb4h\n4UtJj63t6L3iuZR5n+wLofdmLf7BM/C+rQQqz/Tl0e8L4RLkG+OfbKNc03aLFL+y\n/8ChJt82z0RUUYqlv14SWnirKnJC0T3UxOVln7PrR5BVn+QAKEZp+DdffDWxsCvA\n1qeYO8dKlh0ipXnIkU4vN9VYUgdP4eXCekJP8zuU7giETIE0msS1J1kSSJJfeVe1\n4zX2ZO6c5j1hxAZaz0sYMzN41QsV583NxAfwM/F4VMFF00z9+6Fb89GriTlIt6p1\nNjyJHrzxQIRLgRVHMG2tWrOiStuXsNNZmYobeUnj6zKQZZ/DzhgbfTaNiw9b\n-----END CERTIFICATE-----\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "148b132062f4e9683a3326ff31d9db08a3170edd", "filename": "playbooks/openshift/roles", "repository": "redhat-cop/casl-ansible", "decoded_content": "../../roles/"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "602898af1fc353e4cd9203532a8474edfd659766", "filename": "playbooks/files/etc-issue.in", "repository": "rocknsm/rock", "decoded_content": " +--------------------------------------------------+\n |                   \\\\                              |     Hostname: \\n                 \n |                  / \\\\                             |           OS: {{OS_RELEASE}}     \n |                 /   \\\\                            |        Kernel: \\s                \n |         \\\\      /     \\\\                           |        Build: \\v                 \n |        / \\\\    X   \\\\   \\\\                          |      IP Addr: {{IP_ADDR}}       \n |       /   \\\\  / \\\\ / \\\\ ^_v___   ____   _____ _  __ |      Release: ROCK 2.0          \n |      /     v/   /   /|  __ \\\\ / __ \\\\ / ____| |/ / |                                 \n |     /      /         | |__) | |  | | |    | ' /  |                                \n |    /      /          |  _  /| |  | | |    |  <   |         Date: \\d                \n |   /      /           | | \\\\ \\\\| |__| | |____| . \\\\  |         Time: \\t               \n |  /      /            |_|  \\\\_\\\\\\\\____/ \\\\_____|_|\\\\_\\\\ |        Users: \\U              \n +--------------------------------------------------+\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "2214f9ded9042e1940ab5ec622801debf46775e8", "filename": "playbooks/roles/check_nm/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- name: Ensure that NetworkManager is running\n  command: systemctl status NetworkManager\n  ignore_errors: yes\n  changed_when: false\n  register: service_NetworkManager_status\n- name: Report status of Network Manager\n  fail:\n    msg: |\n      Service NetworkManager is not running.\n      Output of `systemctl status NetworkManager`:\n      {{ service_NetworkManager_status.stdout }}\n      {{ service_NetworkManager_status.stderr }}\n  when: service_NetworkManager_status | failed\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "fd4d18a1fd3ae8561ae148921e42c5ab8874284b", "filename": "playbooks/openshift/prep-inventory.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- name: Generate Environment ID\n  set_fact:\n    env_random_id: \"{{ ansible_date_time.epoch }}\"\n  run_once: true\n  delegate_to: localhost\n\n- name: Set default Environment ID\n  set_fact:\n    default_env_id: \"casl-{{ lookup('env','OS_USERNAME') }}-{{ env_random_id }}\"\n  delegate_to: localhost\n\n- name: Setting Common Facts\n  set_fact:\n    env_id: \"{{ env_id | default(default_env_id) }}\"\n  delegate_to: localhost\n\n- name: Set Dynamic Inventory Filters\n  shell: >\n    export OS_INV_FILTER_KEY=clusterid && OS_INV_FILTER_VALUE={{ env_id }}\n  delegate_to: localhost\n\n- name: Updating DNS configurations\n  set_fact:\n    full_dns_domain: \"{{ (env_id|trim == '') | ternary(dns_domain, env_id + '.' + dns_domain) }}\"\n    openshift_app_domain: \"{{ openshift_app_domain | default('apps') }}\"\n    public_dns_domain: \"{{ dns_domain }}\"\n  delegate_to: localhost\n\n- name: Set the default app domain for routing purposes\n  set_fact:\n    openshift_master_default_subdomain: \"{{ openshift_app_domain }}.{{ full_dns_domain }}\"\n  delegate_to: localhost\n  when:\n  - openshift_master_default_subdomain is undefined\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "aa54811a7b551de57906414e49fcebb38aa25b7d", "filename": "playbooks/templates/pulledpork.conf.j2", "repository": "rocknsm/rock", "decoded_content": "# Config file for pulledpork\n# Be sure to read through the entire configuration file\n# If you specify any of these items on the command line, it WILL take \n# precedence over any value that you specify in this file!\n{# I'm making the assumption here that a user will only configure\n   pulledpork if they have snort or suricata installed. This will \n   currently break otherwise. We could address this usecase fairly\n   easily if there is a need \n#}\n{% if with_suricata %}\n{% set engine_basepath = \"/etc/suricata\" %}\n{% elif with_snort %}\n{% set engine_basepath = \"/etc/snort\" %}\n{% endif %}\n\n#######\n#######  The below section defines what your oinkcode is (required for \n#######  VRT rules), defines a temp path (must be writable) and also \n#######  defines what version of rules that you are getting (for your \n#######  snort version and subscription etc...)\n####### \n\n# You can specify one or as many rule_urls as you like, they \n# must appear as http://what.site.com/|rulesfile.tar.gz|1234567.  You can specify\n# each on an individual line, or you can specify them in a , separated list\n# i.e. rule_url=http://x.y.z/|a.tar.gz|123,http://z.y.z/|b.tar.gz|456\n# note that the url, rule file, and oinkcode itself are separated by a pipe |\n# i.e. url|tarball|123456789, \n#rule_url=https://www.snort.org/reg-rules/|snortrules-snapshot.tar.gz|<oinkcode>\n# NEW Community ruleset:\n#rule_url=https://snort.org/downloads/community/|community-rules.tar.gz|Community\n# NEW For IP Blacklisting! Note the format is urltofile|IPBLACKLIST|<oinkcode>\n# This format MUST be followed to let pulledpork know that this is a blacklist\n#rule_url=http://talosintelligence.com/feeds/ip-filter.blf|IPBLACKLIST|open\n# URL for rule documentation! (slow to process)\n#rule_url=https://www.snort.org/reg-rules/|opensource.gz|<oinkcode>\n# THE FOLLOWING URL is for emergingthreats downloads, note the tarball name change!\n# and open-nogpl, to avoid conflicts.\n#rule_url=https://rules.emergingthreats.net/|emerging.rules.tar.gz|open-nogpl\n# THE FOLLOWING URL is for etpro downloads, note the tarball name change!\n# and the et oinkcode requirement!\n#rule_url=https://rules.emergingthreatspro.com/|etpro.rules.tar.gz|<et oinkcode>\n# NOTE above that the VRT snortrules-snapshot does not contain the version\n# portion of the tarball name, this is because PP now automatically populates\n# this value for you, if, however you put the version information in, PP will\n# NOT populate this value but will use your value!\n{% for rule in pulledpork_rules if (rule.test is undefined or rule.test) %}\nrule_url={{ rule.url }}|{{ rule.file }}|{{ rule.apikey }}\n{% endfor %}\n# Specify rule categories to ignore from the tarball in a comma separated list\n# with no spaces.  There are four ways to do this:\n# 1) Specify the category name with no suffix at all to ignore the category\n#    regardless of what rule-type it is, ie: netbios\n# 2) Specify the category name with a '.rules' suffix to ignore only gid 1\n#    rulefiles located in the /rules directory of the tarball, ie: policy.rules\n# 3) Specify the category name with a '.preproc' suffix to ignore only\n#    preprocessor rules located in the /preproc_rules directory of the tarball,\n#    ie: sensitive-data.preproc\n# 4) Specify the category name with a '.so' suffix to ignore only shared-object\n#    rules located in the /so_rules directory of the tarball, ie: netbios.so\n# The example below ignores dos rules wherever they may appear, sensitive-\n# data preprocessor rules, p2p so-rules (while including gid 1 p2p rules),\n# and netbios gid-1 rules (while including netbios so-rules):\n# ignore = dos,sensitive-data.preproc,p2p.so,netbios.rules\n# These defaults are reasonable for the VRT ruleset with Snort 2.9.0.x.\nignore=deleted.rules,experimental.rules,local.rules\n# IMPORTANT, if you are NOT yet using 2.8.6 then you MUST comment out the\n# previous ignore line and uncomment the following!\n# ignore=deleted,experimental,local,decoder,preprocessor,sensitive-data\n\n# What is our temp path, be sure this path has a bit of space for rule \n# extraction and manipulation, no trailing slash\ntemp_path=/tmp\n\n#######\n#######  The below section is for rule processing.  This section is \n#######  required if you are not specifying the configuration using\n#######  runtime switches.  Note that runtime switches do SUPERSEED \n#######  any values that you have specified here!\n#######\n\n# What path you want the .rules file containing all of the processed \n# rules? (this value has changed as of 0.4.0, previously we copied \n# all of the rules, now we are creating a single large rules file\n# but still keeping a separate file for your so_rules!\nrule_path={{ engine_basepath }}/rules/pulledpork.rules\n# What path you want the .rules files to be written to, this is UNIQUE\n# from the rule_path and cannot be used in conjunction, this is to be used with the\n# -k runtime flag, this can be set at runtime using the -K flag or specified\n# here.  If specified here, the -k option must also be passed at runtime, however\n# specifying -K <path> at runtime forces the -k option to also be set\n# out_path=/usr/local/etc/snort/rules/\n\n# If you are running any rules in your local.rules file, we need to\n# know about them to properly build a sid-msg.map that will contain your\n# local.rules metadata (msg) information.  You can specify other rules\n# files that are local to your system here by adding a comma and more paths...\n# remember that the FULL path must be specified for EACH value.\n# local_rules=/path/to/these.rules,/path/to/those.rules\nlocal_rules={{ engine_basepath }}/rules/local.rules\n\n# Where should I put the sid-msg.map file?\nsid_msg={{ engine_basepath }}/sid-msg.map\n\n# New for by2 and more advanced msg mapping.  Valid options are 1 or 2\n# specify version 2 if you are running barnyard2.2+.  Otherwise use 1\nsid_msg_version=1\n\n# Where do you want me to put the sid changelog?  This is a changelog \n# that pulledpork maintains of all new sids that are imported\nsid_changelog=/var/log/sid_changes.log\n# this value is optional\n\n#######\n#######  The below section is for so_rule processing only.  If you don't\n#######  need to use them.. then comment this section out!\n#######  Alternately, if you are not using pulledpork to process \n#######  so_rules, you can specify -T at runtime to bypass this altogether\n#######\n\n# What path you want the .so files to actually go to *i.e. where is it\n# defined in your snort.conf, needs a trailing slash\n#sorule_path=''\n\n# Path to the snort binary, we need this to generate the stub files\nsnort_path={{ \"/sbin/suricata\" if with_suricata else \"/usr/sbin/snort\" }}\n\n# We need to know where your snort.conf file lives so that we can\n# generate the stub files\n#config_path={{ engine_basepath }}/{{ \"suricata.yaml\" if with_suricata else \"snort.conf\" }}\n\n##### Deprecated - The stubs are now  categorically written to the  single rule file!\n# sostub_path=/usr/local/etc/snort/rules/so_rules.rules\n\n# Define your distro, this is for the precompiled shared object libs!\n# Valid Distro Types:\n# Debian-6-0, Ubuntu-10-4\n# Ubuntu-12-04, Centos-5-4\n# FC-12, FC-14, RHEL-5-5, RHEL-6-0\n# FreeBSD-8-1, FreeBSD-9-0, FreeBSD-10-0\n# OpenBSD-5-2, OpenBSD-5-3\n# OpenSUSE-11-4, OpenSUSE-12-1\n# Slackware-13-1\n#distro=''\n\n#######  This next section is optional, but probably pretty useful to you.\n#######  Please read thoroughly!\n\n# If you are using IP Reputation and getting some public lists, you will probably\n# want to tell pulledpork where your blacklist file lives, PP automagically will\n# de-dupe any duplicate IPs from different sources.\nblack_list={{ engine_basepath }}/rules/iplists/default.blacklist\n\n# IP Reputation does NOT require a full snort HUP, it introduces a concept whereby\n# the IP list can be reloaded while snort is running through the use of a control\n# socket.  Please be sure that you built snort with the following optins:\n# -enable-shared-rep and --enable-control-socket.  Be sure to read about how to\n# configure these!  The following option tells pulledpork where to place the version\n# file for use with control socket ip list reloads!\n# This should be the same path where your black_list lives!\nIPRVersion={{ engine_basepath }}/rules/iplists\n\n# The following option tells snort where the snort_control tool is located.\nsnort_control={{ \"/usr/bin/snort_control\" if with_snort else \"\" }}\n\n# What do you want to backup and archive?  This is a comma separated list\n# of file or directory values.  If a directory is specified, PP will recurse\n# through said directory and all subdirectories to archive all files.\n# The following example backs up all snort config files, rules, pulledpork\n# config files, and snort shared object binary rules.\n# backup=/usr/local/etc/snort,/usr/local/etc/pulledpork,/usr/local/lib/snort_dynamicrules/\n\n# what path and filename should we use for the backup tarball?\n# note that an epoch time value and the .tgz extension is automatically added\n# to the backup_file name on completeion i.e. the written file is:\n# pp_backup.1295886020.tgz\n# backup_file=/tmp/pp_backup\n\n# Where do you want the signature docs to be copied, if this is commented \n# out then they will not be copied / extracted.  Note that extracting them \n# will add considerable runtime to pulledpork.\n# docs=/path/to/base/www\n\n# The following option, state_order, allows you to more finely control the order\n# that pulledpork performs the modify operations, specifically the enablesid\n# disablesid and dropsid functions.  An example use case here would be to\n# disable an entire category and later enable only a rule or two out of it.\n# the valid values are disable, drop, and enable.\n# state_order=disable,drop,enable\n\n\n# Define the path to the pid files of any running process that you want to\n# HUP after PP has completed its run.\n# pid_path=/var/run/snort.pid,/var/run/barnyard.pid,/var/run/barnyard2.pid\n# and so on...\n# pid_path=/var/run/snort_eth0.pid\n\n# This defines the version of snort that you are using, for use ONLY if the \n# proper snort binary is not on the system that you are fetching the rules with\n# This value MUST contain all 4 minor version\n# numbers. ET rules are now also dependant on this, verify supported ET versions\n# prior to simply throwing rubbish in this variable kthx!\n#\n# Suricata users - set this to 'suricata-3.x.x' to process rule files\n# for suricata, this mimics the -S flag on the command line.\n{% if with_suricata %}\nsnort_version=suricata\n{% else %}\nsnort_version=2.9.0.0\n{% endif %}\n\n\n# Here you can specify what rule modification files to run automatically.\n# simply uncomment and specify the apt path.\n# enablesid=/usr/local/etc/snort/enablesid.conf\n# dropsid=/usr/local/etc/snort/dropsid.conf\ndisablesid=/etc/pulledpork/disablesid.conf\n# modifysid=/usr/local/etc/snort/modifysid.conf\n\n# What is the base ruleset that you want to use, please uncomment to use\n# and see the README.RULESETS for a description of the options.  \n# Note that setting this value will disable all ET rulesets if you are \n# Running such rulesets\n# ips_policy=security\n\n####### Remember, a number of these values are optional.. if you don't \n####### need to process so_rules, simply comment out the so_rule section\n####### you can also specify -T at runtime to process only GID 1 rules.\n\nversion=0.7.2\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "1568045abb2c35552562235c46ca0dee8d4091bb", "filename": "tasks/not-supported.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Warn on unsupported platform\n  fail:\n    msg: |\n      This role does not support '{{ ansible_os_family }}' platform.\n        Please contact support@lean-delivery.com\n"}, {"commit_sha": "f3dd45a61b08de1b3351140cc442a705cb2fad82", "sha": "e418e053bade09c90c1ce87357379ecfe4148c32", "filename": "tasks/autoupdate-Debian.yml", "repository": "geerlingguy/ansible-role-security", "decoded_content": "---\n- name: Install unattended upgrades package.\n  package: name=unattended-upgrades state=present\n\n- name: Copy unattended-upgrades configuration files in place.\n  template:\n    src: \"{{ item }}.j2\"\n    dest: \"/etc/apt/apt.conf.d/{{ item }}\"\n    owner: root\n    group: root\n    mode: 0644\n  with_items:\n    - 10periodic\n    - 50unattended-upgrades\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "1f3dce4a0eb3a7d8ed1c30bb0fb275157f708939", "filename": "roles/config-ipa-client/tasks/prereq-CentOS.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Install additional packages for IPA/IdM\"\n  package:\n    name: \"{{ item }}\"\n    state: latest\n  with_items:\n  - ipa-client\n  - libsss_sudo\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "9a578830fa5032b239c55e0f6b690e2b8f9fe682", "filename": "playbooks/ansible/tower/configure-ansible-tower.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: ansible-tower\n  roles:\n  - role: ansible/tower/config-ansible-tower\n  - role: ansible/tower/config-ansible-tower-ldap\n  tags:\n  - 'never'\n  - 'install'\n\n- hosts: tower-management-host\n  roles:\n  - role: ansible/tower/manage-projects\n  - role: ansible/tower/manage-credential-types\n  - role: ansible/tower/manage-credentials\n  - role: ansible/tower/manage-inventories\n  - role: ansible/tower/manage-job-templates\n  - role: ansible/tower/manage-workflow-templates\n  tags:\n  - 'always'\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "a08e2342a6dc67efa22d8283ab24387cd304ce1f", "filename": "roles/dns_adblocking/tasks/freebsd.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- name: FreeBSD / HardenedBSD | Enable dnsmasq\n  lineinfile: dest=/etc/rc.conf regexp=^dnsmasq_enable= line='dnsmasq_enable=\"YES\"'\n"}, {"commit_sha": "d25113e8fab871b2ead95ca976c5a43e4759ea26", "sha": "5d9f5278cd5087e4a89f3353555e747d8691d1ef", "filename": "handlers/main.yml", "repository": "UnderGreen/ansible-role-mongodb", "decoded_content": "---\n\n- name: mongodb reload\n  service: name={{ mongodb_daemon_name }} state=reloaded\n\n- name: mongodb restart\n  service: name={{ mongodb_daemon_name }} state=restarted\n\n- name: mongodb-mms-automation-agent restart\n  service: name=mongodb-mms-automation-agent state=restarted\n\n- name: reload systemd\n  shell: systemctl daemon-reload\n  when: systemd.stat.exists == true\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "966d219d038b426233eac0f00222e088b71bfb75", "filename": "roles/setup-slack/tasks/invite_users.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Get channels info\n  import_tasks: get_channel_info.yml\n\n- name: Convert channel name to its mapped id\n  set_fact:\n    channels_ids: \"{{ user.channels | map('extract', channel_mapping) | list }}\"\n\n- name: Invite user\n  uri:\n    url: \"https://slack.com/api/users.admin.invite?token={{ slack_token }}&channels={{ channels_ids|join(',') }}&email={{ user.email }}&first_name={{ user.first_name | urlencode }}&last_name={{ user.last_name | urlencode }}&set_active=true\"\n    method: GET\n    status_code: [200]"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "fc065c37564a46711824f169567af9f2bc083f48", "filename": "roles/vpn/tasks/iptables.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- name: Iptables configured\n  template: src=\"{{ item.src }}\" dest=\"{{ item.dest }}\" owner=root group=root mode=0640\n  with_items:\n    - { src: rules.v4.j2, dest: /etc/iptables/rules.v4 }\n  notify:\n    - restart iptables\n\n- name: Iptables configured\n  template: src=\"{{ item.src }}\" dest=\"{{ item.dest }}\" owner=root group=root mode=0640\n  when: ipv6_support is defined and ipv6_support == true\n  with_items:\n    - { src: rules.v6.j2, dest: /etc/iptables/rules.v6 }\n  notify:\n    - restart iptables\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "0de2ac93da2468768b43187ae69c46af16b71fdd", "filename": "playbooks/bb00-openstack_provisioning.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "#!/usr/bin/env ansible-playbook\n---\n\n- hosts: localhost\n  gather_facts: False\n  become: False\n  connection: local\n  serial: 1 # Because my lab is not so fast\n  tasks:\n    - name: Parameter validation\n      import_role:\n        name: bb0-openstack\n        tasks_from: validate-parameters.yml\n\n    - name: Create mini inventory\n      import_role:\n        name: bb0-openstack\n        tasks_from: create-inventory-mini.yml\n\n    - name: Provisioning pre once\n      import_role:\n        name: bb0-openstack\n        tasks_from: provisioning-pre-once.yml\n\n\n# openstack_instances, created by create-inventory-mini.yml\n- hosts: openstack_instances\n  gather_facts: False\n  become: False\n  connection: local\n  serial: 1 # Because my lab is not so fast\n  tasks:\n    - name: Provisioning\n      import_role:\n        name: bb0-openstack\n        tasks_from: provisioning.yml\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "71aadf35c81ba24e0b4780cc8036b1724ecdc924", "filename": "roles/kalite/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "# Assessment logic removed 3/1/2017 TFM\n\n# Assume all XOs are F18 and nothing else is\n\n- name: Calc kalite db file name F18\n  set_fact:\n     kalite_db_name: \"{{ kalite_root }}/kalite/database/data.sqlite\"\n  when: is_F18\n\n- name: Calc kalite db file name\n  set_fact:\n     kalite_db_name: \"{{ kalite_root }}/database/data.sqlite\"\n  when: not is_F18\n\n- name: See if kalite is already configured\n  stat: path=\"{{ kalite_db_name }}\"\n  register: kalite_installed\n\n- include: install-f18.yml\n  when: not kalite_installed.stat.exists and is_F18\n\n- include: install.yml\n  when: kalite_installed is defined and not kalite_installed.stat.exists and not is_F18\n\n- name: ask systemd to reread the unit files\n  shell: systemctl daemon-reload\n  when: not kalite_installed.stat.exists\n\n- include: setup-f18.yml\n  when: not kalite_installed.stat.exists and is_F18\n\n- include: setup.yml\n  when: not kalite_installed.stat.exists and not is_F18\n\n- include: enable.yml\n\n- name: Add kalite to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=kalite\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: kalite\n    - option: description\n      value: '\"KA-Lite is a server to present Khan Academy videos offline and to download them.\"'\n    - option: path\n      value: \"{{ kalite_root }}\"\n    - option: server_name\n      value: \"{{ kalite_server_name }}\"\n    - option: port\n      value: \"{{ kalite_server_port }}\"\n    - option: enabled\n      value: \"{{ kalite_enabled }}\"\n    - option: cron_enabled\n      value: \"{{ kalite_cron_enabled }}\"\n    - option: khan_assessment_install\n      value: \"{{ khan_assessment_install }}\"\n"}, {"commit_sha": "1224adf2811c827a09ff0bf133fbb476901a547d", "sha": "ded6fe8a37e9e97c45c20659820960cf5f5b977e", "filename": "tasks/openbsd_service.yml", "repository": "nusenu/ansible-relayor", "decoded_content": "---\n\n\n# OpenBSD section (uses service module)\n# This is basically a copy from the Linux\n# section, but it requires different service\n# names and additional arguments.\n# =====================================\n\n# OpenBSD does not support multi-instance rc.d\n# # so we link as many pseudo rc scripts as we need.\n# # OpenBSD does not like dots in rc filenames so\n# # we replace them with underscores.\n- name: Create links to the service files (OpenBSD)\n  become: yes\n  file:\n    src: /etc/rc.d/tor\n    state: link\n    path: \"/etc/rc.d/tor{{ item.0.ipv4| replace('.','_') }}_{{ item.1.orport }}\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure Tor instances are enabled and started (OpenBSD)\n  become: yes\n  service:\n    name: \"tor{{ item.0.ipv4|replace('.','_') }}_{{ item.1.orport }}\"\n    arguments: \"-f {{ tor_ConfDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}.torrc\"\n    enabled: yes\n    state: started\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure Tor instances are reloaded if its torrc changed (OpenBSD)\n  become: yes\n  service:\n    name: \"tor{{ item.item.0.ipv4|replace('.','_') }}_{{ item.item.1.orport }}\"\n    state: reloaded\n  with_items: \"{{ instances.results }}\"\n  when: item.changed == True\n  tags:\n   - reconfigure\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "a7598e1defa852bc99d1b3f2566b85b412e246b8", "filename": "roles/haproxy/tasks/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# tasks file for haproxy\n- name: \"assures {{ consul_template_dir }} dirs exists\"\n  file:\n    path: \"{{ consul_template_dir }}/{{ item.path }}\"\n    state: directory\n  with_items:\n    - { path: 'config' }\n    - { path: 'templates' }\n  tags:\n    - haproxy\n\n- name: upload template config files\n  template:\n    src: consul.cfg.j2\n    dest: \"{{ consul_template_dir }}/config/consul.cfg\"\n    mode: 0644\n  sudo: yes\n  tags:\n    - haproxy\n\n- name: upload static config files\n  copy:\n    src: \"{{ item.src }}\"\n    dest: \"{{ consul_template_dir }}/{{ item.dst }}\"\n    mode: 0644\n  sudo: yes\n  with_items:\n    - { src: haproxy.cfg, dst: 'config/haproxy.cfg' }\n    - { src: haproxy.tmpl, dst: 'templates/haproxy.tmpl' }\n  tags:\n    - haproxy\n\n- name: destroy old haproxy container\n  when: haproxy_rebuild_container\n  docker:\n    name: haproxy\n    image: \"{{ haproxy_image }}\"\n    state: absent\n\n- name: run haproxy container\n  docker:\n    name: haproxy\n    image: \"{{ haproxy_image }}\"\n    state: started\n    net: host\n    restart_policy: always\n    ports:\n      - \"80:80\"\n      - \"34180:34180\"\n    env:\n      HAPROXY_DOMAIN: \"{{ haproxy_domain }}\"\n      CONSUL_TEMPLATE_VERSION: \"{{ consul_template_version }}\"\n      CONSUL_LOGLEVEL: \"{{ consul_template_loglevel }}\"\n      CONSUL_CONNECT: \"{{ consul_backend }}\"\n      CONSUL_CONFIG: \"/config\"\n      SERVICE_NAME: haproxy\n    volumes:\n    - \"{{ consul_template_dir }}/config:/config\"\n    - \"{{ consul_template_dir }}/templates:/templates\"\n  tags:\n    - haproxy\n"}, {"commit_sha": "a5a5c4d74b7b0fd14f534dda1f41f903d1a58abf", "sha": "1b3dd6d9a77679bc53cc3dbc5b9a285ac101bb89", "filename": "tasks/nvm.yml", "repository": "fubarhouse/ansible-role-nodejs", "decoded_content": "---\n# Tasks file for NVM\n\n- name: \"NVM | Clean-up\"\n  become: yes\n  become_user: \"root\"\n  file:\n    path: \"{{ fubarhouse_npm.nvm_install_dir }}\"\n    state: absent\n  when: fubarhouse_npm.clean_install\n\n- name: NVM | Clean-up default version from shell profiles\n  become: yes\n  become_user: \"root\"\n  lineinfile:\n    dest: \"{{ fubarhouse_npm.user_dir }}/{{ item.filename }}\"\n    regexp: '.nvm/v{{ node_version }}/bin'\n    line:  'export PATH=$PATH:{{ fubarhouse_npm.user_dir }}/.nvm/v{{ node_version }}/bin;'\n    state: absent\n  with_items:\n    - \"{{ fubarhouse_npm.shell_profiles }}\"\n  ignore_errors: yes\n  when: fubarhouse_npm.clean_install\n\n- name: NVM | Clean-up other versions from shell profiles\n  become: yes\n  become_user: \"root\"\n  lineinfile:\n    dest: \"{{ fubarhouse_npm.user_dir }}/{{ item[0].filename }}\"\n    regexp: '.nvm/v{{ item[1] }}/bin'\n    line:  'export PATH=$PATH:{{ fubarhouse_npm.user_dir }}/.nvm/v{{ item[1] }}/bin;'\n    state: absent\n  with_nested:\n    - \"{{ fubarhouse_npm.shell_profiles }}\"\n    - \"{{ node_versions }}\"\n  ignore_errors: yes\n  when: fubarhouse_npm.clean_install\n\n- name: \"NodeJS | Remove imported exports not associated to specific versions\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  lineinfile:\n    dest: \"{{ fubarhouse_npm.user_dir }}/{{ item.filename }}\"\n    line: \"export PATH=$PATH:$(npm config --global get prefix)/bin\"\n    state: absent\n  with_items: \"{{ fubarhouse_npm.shell_profiles }}\"\n  when: fubarhouse_npm.clean_install\n\n- name: \"NVM | Check\"\n  stat:\n    path: \"{{ fubarhouse_npm.nvm_install_dir }}\"\n  register: fubarhouse_npm_nvm_installed\n\n- name: \"NVM | Ensure permissions are set\"\n  become: yes\n  become_user: \"root\"\n  file:\n    path: \"{{ item.path }}\"\n    state: directory\n    mode: 0777\n    owner: \"{{ fubarhouse_user }}\"\n    recurse: yes\n  with_items: \"{{ fubarhouse_npm.folder_paths }}\"\n  changed_when: false\n\n- name: \"NVM | Clone/Update\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  git:\n    repo: \"{{ nvm_repo }}\"\n    dest: \"{{ fubarhouse_npm.nvm_install_dir }}\"\n    clone: yes\n    update: yes\n    force: yes\n    version: master\n    recursive: false\n  changed_when: false\n\n- name: \"NVM | Install\"\n  shell: \"{{ fubarhouse_npm.nvm_install_dir }}/install.sh\"\n  when: fubarhouse_npm_nvm_installed.stat.exists == false\n\n- name: \"NVM | Create an executable\"\n  template:\n    src: \"nvm.sh\"\n    dest: \"{{ fubarhouse_npm.nvm_symlink_exec }}\"\n    owner: \"{{ fubarhouse_user }}\"\n    mode: 0755\n  when: fubarhouse_npm_nvm_installed.stat.exists == false\n\n- name: \"NVM | Get versions\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  shell: \"{{ fubarhouse_npm.nvm_symlink_exec }} ls-remote\"\n  register: nodejs_available_versions\n  changed_when: false\n\n- name: NVM | Ensure shell profiles are available\n  become: yes\n  become_user: \"root\"\n  file:\n    path: \"{{ fubarhouse_npm.user_dir }}/{{ item.filename }}\"\n    state: touch\n  with_items: \"{{ fubarhouse_npm.shell_profiles }}\"\n  ignore_errors: yes\n  changed_when: false\n\n- name: NVM | Ensure shell profiles are configured for default version\n  become: yes\n  become_user: \"root\"\n  lineinfile:\n    dest: \"{{ fubarhouse_npm.user_dir }}/{{ item.filename }}\"\n    regexp: '.nvm/v{{ node_version }}/bin'\n    line:  'export PATH=$PATH:{{ fubarhouse_npm.user_dir }}/.nvm/v{{ node_version }}/bin;'\n    state: present\n  with_items:\n    - \"{{ fubarhouse_npm.shell_profiles }}\"\n  when: '\"{{ node_version }}\" in nodejs_available_versions.stdout'\n  ignore_errors: yes\n\n- name: NVM | Ensure shell profiles are configured for other versions\n  become: yes\n  become_user: \"root\"\n  lineinfile:\n    dest: \"{{ fubarhouse_npm.user_dir }}/{{ item[0].filename }}\"\n    regexp: '.nvm/v{{ item[1] }}/bin'\n    line:  'export PATH=$PATH:{{ fubarhouse_npm.user_dir }}/.nvm/v{{ item[1] }}/bin;'\n    state: present\n  when: '\"{{ item[1] }}\" in nodejs_available_versions.stdout'\n  with_nested:\n    - \"{{ fubarhouse_npm.shell_profiles }}\"\n    - \"{{ node_versions }}\"\n  ignore_errors: yes"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "30fcea99f7e1a9211915b45d571a699fdbbfca35", "filename": "roles/manage-confluence-space/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Fail when source username or password is not set\n  fail: msg=\"This role requires source_confluence_site_username and source_confluence_site_password to be set and non empty\"\n  when:\n    - (source_confluence_site_username == \"\") or (source_confluence_site_password == \"\")\n\n- name: Retrieve all contents from source space\n  uri:\n    url: '{{ confluence_space_source_url }}/rest/api/content?spaceKey={{ confluence_space_source_space_key }}&expand=ancestors'\n    method: GET\n    user: '{{ source_confluence_site_username }}'\n    password: '{{ source_confluence_site_password }}'\n    force_basic_auth: yes\n    status_code: 200\n    return_content: yes\n  register: contents_json\n  no_log: true\n\n- name: Create a tempfile for Content JSON\n  command: mktemp\n  register: uptemp\n  delegate_to: 127.0.0.1\n\n- name: Write content to file\n  copy:\n    content: \"{{ contents_json.json.results | to_json }}\"\n    dest: \"{{ uptemp.stdout }}\"\n\n- name: Initialise old to new id mapping\n  set_fact:\n    id_mapping: {}\n\n- name: Sort contents based on its dependencies\n  command: \"./contents_order_parser.py '{{ uptemp.stdout }}'\"\n  args:\n    chdir: \"{{ role_path }}/files\"\n  register: processed_contents\n  delegate_to: 127.0.0.1\n\n- name: Fail when destination username or password is not set\n  fail: msg=\"This role requires destination_confluence_site_username and destination_confluence_site_password to be set and non empty\"\n  when:\n    - (destination_confluence_site_username == \"\") or (destination_confluence_site_password == \"\")\n\n- import_tasks: create_confluence_space.yml\n\n- include_tasks: copy_confluence_content.yml\n  with_items: '{{ processed_contents.stdout }}'\n  loop_control:\n    loop_var: confluence_space_content\n\n- include_tasks: copy_confluence_attachments.yml\n  with_dict: '{{ id_mapping }}'\n  loop_control:\n    loop_var: confluence_content_ids\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "8f9d52aba792376c0f2119a2839895cabcd9825c", "filename": "roles/vpn/tasks/openssl.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- name: Ensure the pki directory is not exist\n  local_action:\n    module: file\n    dest: configs/{{ IP_subject_alt_name }}/pki\n    state: absent\n  become: no\n  when: easyrsa_reinit_existent == True\n\n- name: Ensure the pki directories are exist\n  local_action:\n    module: file\n    dest: \"configs/{{ IP_subject_alt_name }}/pki/{{ item }}\"\n    state: directory\n    recurse: yes\n  become: no\n  with_items:\n    - ecparams\n    - certs\n    - crl\n    - newcerts\n    - private\n    - reqs\n\n- name: Ensure the files are exist\n  local_action:\n    module: file\n    dest: \"configs/{{ IP_subject_alt_name }}/pki/{{ item }}\"\n    state: touch\n  become: no\n  with_items:\n    - \".rnd\"\n    - \"private/.rnd\"\n    - \"index.txt\"\n    - \"index.txt.attr\"\n    - \"serial\"\n\n- name: Generate the openssl server configs\n  local_action:\n    module: template\n    src: openssl.cnf.j2\n    dest: \"configs/{{ IP_subject_alt_name }}/pki/openssl.cnf\"\n  become: no\n\n\n- name: Build the CA pair\n  local_action: >\n    shell openssl ecparam -name prime256v1 -out ecparams/prime256v1.pem &&\n      openssl req -utf8 -new -newkey {{ algo_params | default('ec:ecparams/prime256v1.pem') }} -config openssl.cnf -keyout private/cakey.pem -out cacert.pem -x509 -days 3650 -batch -passout pass:\"{{ easyrsa_CA_password }}\" &&\n      touch {{ IP_subject_alt_name }}_ca_generated\n  become: no\n  args:\n    chdir: \"configs/{{ IP_subject_alt_name }}/pki/\"\n    creates: \"{{ IP_subject_alt_name }}_ca_generated\"\n  environment:\n    subjectAltName: \"DNS:{{ IP_subject_alt_name }},IP:{{ IP_subject_alt_name }}\"\n\n- name: Copy the CA certificate\n  local_action:\n    module: copy\n    src: \"configs/{{ IP_subject_alt_name }}/pki/cacert.pem\"\n    dest: \"configs/{{ IP_subject_alt_name }}/cacert.pem\"\n    mode: 0600\n  become: no\n\n- name: Generate the serial number\n  local_action: >\n    shell echo 01 > serial &&\n      touch serial_generated\n  become: no\n  args:\n    chdir: \"configs/{{ IP_subject_alt_name }}/pki/\"\n    creates: serial_generated\n\n- name: Build the server pair\n  local_action: >\n    shell openssl req -utf8 -new -newkey {{ algo_params | default('ec:ecparams/prime256v1.pem') }} -config openssl.cnf -keyout private/{{ IP_subject_alt_name }}.key -out reqs/{{ IP_subject_alt_name }}.req -nodes -passin pass:\"{{ easyrsa_CA_password }}\" -subj \"/CN={{ IP_subject_alt_name }}\" -batch &&\n    openssl ca -utf8 -in reqs/{{ IP_subject_alt_name }}.req -out certs/{{ IP_subject_alt_name }}.crt -config openssl.cnf -days 3650 -batch -passin pass:\"{{ easyrsa_CA_password }}\" -subj \"/CN={{ IP_subject_alt_name }}\" &&\n    touch certs/{{ IP_subject_alt_name }}_crt_generated\n  become: no\n  args:\n    chdir: \"configs/{{ IP_subject_alt_name }}/pki/\"\n    creates: certs/{{ IP_subject_alt_name }}_crt_generated\n  environment:\n    subjectAltName: \"DNS:{{ IP_subject_alt_name }},IP:{{ IP_subject_alt_name }}\"\n\n- name: Build the client's pair\n  local_action: >\n   shell openssl req -utf8 -new -newkey {{ algo_params | default('ec:ecparams/prime256v1.pem') }} -config openssl.cnf -keyout private/{{ item }}.key -out reqs/{{ item }}.req -nodes -passin pass:\"{{ easyrsa_CA_password }}\" -subj \"/CN={{ item }}\" -batch &&\n      openssl ca -utf8 -in reqs/{{ item }}.req -out certs/{{ item }}.crt -config openssl.cnf -days 3650 -batch -passin pass:\"{{ easyrsa_CA_password }}\" -subj \"/CN={{ item }}\" &&\n      touch certs/{{ item }}_crt_generated\n  become: no\n  args:\n    chdir: \"configs/{{ IP_subject_alt_name }}/pki/\"\n    creates: certs/{{ item }}_crt_generated\n  environment:\n    subjectAltName: \"DNS:{{ item }}\"\n  with_items: \"{{ users }}\"\n\n- name: Build the client's p12\n  local_action: >\n    shell openssl pkcs12 -in certs/{{ item }}.crt -inkey private/{{ item }}.key -export -name {{ item }} -out private/{{ item }}.p12 -certfile cacert.pem -passout pass:\"{{ easyrsa_p12_export_password }}\"\n  become: no\n  args:\n    chdir: \"configs/{{ IP_subject_alt_name }}/pki/\"\n  with_items: \"{{ users }}\"\n\n- name: Copy the p12 certificates\n  local_action:\n    module: copy\n    src: \"configs/{{ IP_subject_alt_name }}/pki/private/{{ item }}.p12\"\n    dest: \"configs/{{ IP_subject_alt_name }}/{{ item }}.p12\"\n    mode: 0600\n  become: no\n  with_items:\n    - \"{{ users }}\"\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "f719aaf471e80ea0e08a52adeee2aa94bfefd05b", "filename": "roles/config-clair/tasks/firewall.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Check if firewalld is installed\n  command: systemctl status firewalld\n  register: firewalld_status\n  failed_when: false\n  changed_when: false\n\n- name: Check if iptables is installed\n  command: systemctl status iptables\n  register: iptables_status\n  failed_when: false\n  changed_when: false\n\n- name: Open port in firewalld\n  firewalld:\n    port: \"{{ item }}/tcp\"\n    permanent: true\n    state: enabled\n  when: firewalld_status.rc == 0\n  with_items:\n    - \"{{ clair_host_proxy_port }}\"\n    - \"{{ clair_host_api_port }}\"\n  notify:\n  - restart firewalld\n\n- name: Ensure iptables is correctly configured\n  lineinfile:\n    insertafter: \"^-A INPUT .* --dport {{ item }} .* ACCEPT\"\n    state: present\n    dest: /etc/sysconfig/iptables\n    regexp: \"^-A INPUT .* --dport {{ item }} .* ACCEPT\"\n    line: \"-A INPUT -p TCP -m state --state NEW -m TCP --dport {{ item }} -j ACCEPT\"\n  with_items:\n    - \"{{ clair_host_proxy_port }}\"\n    - \"{{ clair_host_api_port }}\"\n  when: iptables_status.rc == 0 and firewalld_status.rc != 0\n  notify:\n  - restart iptables\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "b3879a384a8313306571d71982d93e0044c0b281", "filename": "roles/sugar-stats/templates/statistics-consolidation/stats-consolidation.conf", "repository": "iiab/iiab", "decoded_content": "[main]\ndb_user=statsconso\ndb_pass=statsconso\ndb_name=statsconso\ndb_dialect=postgresql\n\nrrd_path=/library/sugar-stats/rrd/\nlog_path=/var/log/statistics-consolidation\nlog_level=debug\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "9732ebc95c201c905ad89f763cc223489a886d3a", "filename": "meta/main.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\ngalaxy_info:\n  author: ansible-ThoTeam\n  description: Nexus Repository Manager 3.x (Sonatype)\n  company: ThoTeam\n\n  license: license (GPLv3)\n\n  min_ansible_version: 2.2\n\n  github_branch: master\n\n  platforms:\n    - name: EL\n      versions:\n        - 7\n    - name: Ubuntu\n      versions:\n        - xenial\n        - artful\n    - name: Debian\n      versions:\n        - jessie\n        - stretch\n\n  galaxy_tags:\n    - nexus\n    - nexus3\n    - java\n    - maven\n    - npm\n    - nuget\n    - yum\n    - docker\n    - pypi\n    - web\n\ndependencies: []\n"}, {"commit_sha": "2a05a5032ce341d6a1d918453164c59ea2922f58", "sha": "de201e2c5a0af701490600bae3dafd09e8970f9e", "filename": "roles/ip_forwarder/tasks/main.yml", "repository": "CSCfi/fgci-ansible", "decoded_content": "---\n- name: set ip_forward to 1 to allow kickstarting of network nodes\n  sysctl: name=net.ipv4.ip_forward value=1 sysctl_set=yes reload=no\n  remote_user: root\n- name: get iptables rules\n  shell: iptables -L; iptables -t nat -L\n  register: iptablesrules\n  remote_user: root\n- name: allow forwarding traffic in iptables\n  command: iptables -I FORWARD 1 -i \"{{ internal_interface }}\" -o \"{{ external_interface }}\" -m comment --comment \"forward from internal net\" -j ACCEPT\n  when: iptablesrules.stdout.find(\"forward from internal net\") == -1\n  remote_user: root\n- name: allow related and established traffic in forwarding chain in iptables\n  command: iptables -I FORWARD 1 -i \"{{ external_interface }}\" -o \"{{ internal_interface }}\" -m state --state RELATED,ESTABLISHED -m comment --comment \"related and established\" -j ACCEPT\n  when: iptablesrules.stdout.find(\"related and established\") == -1\n  remote_user: root\n- name: enable masquerading\n  command: iptables -t nat -A POSTROUTING -s \"{{ internal_net }}\" -o \"{{ external_interface }}\" -m comment --comment \"masquerading for internal net\" -j MASQUERADE\n  when: iptablesrules.stdout.find(\"masquerading for internal net\") == -1\n  remote_user: root\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "324772635e45c0e88c617ab3324127e6f40ffab7", "filename": "playbooks/provision-ansible-tower/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_playbook: ../prep.yml\n  tags:\n  - 'never'\n  - 'install'\n\n- import_playbook: ../osp/manage-user-network.yml\n  when:\n  - hosting_infrastructure == 'openstack'\n  tags:\n  - 'never'\n  - 'install'\n\n- import_playbook: ../osp/provision-osp-instance.yml\n  when:\n  - hosting_infrastructure == 'openstack'\n  tags:\n  - 'never'\n  - 'install'\n\n- import_playbook: ../rhsm.yml\n  tags:\n  - 'never'\n  - 'install'\n\n- hosts: ansible-tower\n  roles:\n  - role: update-host\n  tags:\n  - 'never'\n  - 'install'\n\n- import_playbook: ../ansible/tower/configure-ansible-tower.yml\n  tags:\n  - 'always'\n"}, {"commit_sha": "836dc4dd0dacc490044a14c0e39469d162b9449b", "sha": "f6ca47a727566cd7eca855a8fefd487f26aacb08", "filename": "tasks/section1.yml", "repository": "florianutz/Ubuntu1604-CIS", "decoded_content": "---\n- name: \"SCORED | 1.1.1.1 | PATCH | Ensure mounting of cramfs filesystems is disabled\"\n  lineinfile:\n      dest: /etc/modprobe.d/CIS.conf\n      regexp: \"^(#)?install cramfs(\\\\s|$)\"\n      line: \"install cramfs /bin/true\"\n      state: present\n      owner: root\n      group: root\n      mode: 0644\n      create: true\n  when:\n      - ubuntu1604cis_rule_1_1_1_1\n  tags:\n      - level1\n      - scored\n      - patch\n      - cramfs\n      - filesystems\n      - rule_1.1.1.1\n\n- name: \"SCORED | 1.1.1.1 | PATCH | Remove cramfs module\"\n  modprobe:\n      name: cramfs\n      state: absent\n  when:\n      - ubuntu1604cis_rule_1_1_1_1\n  tags:\n      - level1\n      - scored\n      - patch\n      - cramfs\n      - filesystems\n      - rule_1.1.1.1\n\n- name: \"SCORED | 1.1.1.2 | PATCH | Ensure mounting of freevxfs filesystems is disabled\"\n  lineinfile:\n      dest: /etc/modprobe.d/CIS.conf\n      regexp: \"^(#)?install freevxfs\"\n      line: \"install freevxfs /bin/true\"\n      state: present\n      create: true\n  when:\n      - ubuntu1604cis_rule_1_1_1_2\n  tags:\n      - level1\n      - scored\n      - patch\n      - freevxfs\n      - filesystems\n      - rule_1.1.1.2\n\n- name: \"SCORED | 1.1.1.2 | PATCH | Remove freevxfs module\"\n  modprobe:\n      name: freevxfs\n      state: absent\n  when:\n      - ubuntu1604cis_rule_1_1_1_2\n  tags:\n      - level1\n      - scored\n      - patch\n      - freevxfs\n      - filesystems\n      - rule_1.1.1.2\n\n- name: \"SCORED | 1.1.1.3 | PATCH | Ensure mounting of jffs2 filesystems is disabled\"\n  lineinfile:\n      dest: /etc/modprobe.d/CIS.conf\n      regexp: \"^(#)?install jffs2(\\\\s|$)\"\n      line: \"install jffs2 /bin/true\"\n      state: present\n      create: true\n  when:\n      - ubuntu1604cis_rule_1_1_1_3\n  tags:\n      - level1\n      - scored\n      - patch\n      - jffs2\n      - filesystems\n      - rule_1.1.1.3\n\n- name: \"SCORED | 1.1.1.3 | PATCH | Remove jffs2 module\"\n  modprobe:\n      name: jffs2\n      state: absent\n  when:\n      - ubuntu1604cis_rule_1_1_1_3\n  tags:\n      - level1\n      - scored\n      - patch\n      - jffs2\n      - filesystems\n      - rule_1.1.1.3\n\n- name: \"SCORED | 1.1.1.4 | PATCH | Ensure mounting of hfs filesystems is disabled\"\n  lineinfile:\n      dest: /etc/modprobe.d/CIS.conf\n      regexp: \"^(#)?install hfs(\\\\s|$)\"\n      line: \"install hfs /bin/true\"\n      state: present\n      create: true\n  when:\n      - ubuntu1604cis_rule_1_1_1_4\n  tags:\n      - level1\n      - scored\n      - patch\n      - hfs\n      - filesystems\n      - rule_1.1.1.4\n\n- name: \"SCORED | 1.1.1.4 | PATCH | Remove hfs module\"\n  modprobe:\n      name: hfs\n      state: absent\n  when:\n      - ubuntu1604cis_rule_1_1_1_4\n  tags:\n      - level1\n      - scored\n      - patch\n      - hfs\n      - filesystems\n      - rule_1.1.1.4\n\n- name: \"SCORED | 1.1.1.5 | PATCH | Ensure mounting of hfsplus filesystems is disabled\"\n  lineinfile:\n      dest: /etc/modprobe.d/CIS.conf\n      regexp: \"^(#)?install hfsplus(\\\\s|$)\"\n      line: \"install hfsplus /bin/true\"\n      state: present\n      create: true\n  when:\n      - ubuntu1604cis_rule_1_1_1_5\n  tags:\n      - level1\n      - scored\n      - patch\n      - hfsplus\n      - filesystems\n      - rule_1.1.1.5\n\n- name: \"SCORED | 1.1.1.5 | PATCH | Remove hfsplus module\"\n  modprobe:\n      name: hfsplus\n      state: absent\n  when:\n      - ubuntu1604cis_rule_1_1_1_5\n  tags:\n      - level1\n      - scored\n      - patch\n      - hfsplus\n      - filesystems\n      - rule_1.1.1.5\n\n- name: \"SCORED | 1.1.1.6 | PATCH | Ensure mounting of squashfs filesystems is disabled\"\n  lineinfile:\n      dest: /etc/modprobe.d/CIS.conf\n      regexp: \"^(#)?install squashfs(\\\\s|$)\"\n      line: \"install squashfs /bin/true\"\n      state: present\n      create: true\n  when:\n      - ubuntu1604cis_rule_1_1_1_6\n  tags:\n      - level1\n      - scored\n      - patch\n      - squashfs\n      - filesystems\n      - rule_1.1.1.6\n\n- name: \"SCORED | 1.1.1.6 | PATCH | Remove squashfs module\"\n  modprobe:\n      name: squashfs\n      state: absent\n  when:\n      - ubuntu1604cis_rule_1_1_1_6\n  tags:\n      - level1\n      - scored\n      - patch\n      - squashfs\n      - filesystems\n      - rule_1.1.1.6\n\n- name: \"SCORED | 1.1.1.7 | PATCH | Ensure mounting of udf filesystems is disabled\"\n  lineinfile:\n      dest: /etc/modprobe.d/CIS.conf\n      regexp: \"^(#)?install udf(\\\\s|$)\"\n      line: \"install udf /bin/true\"\n      state: present\n      create: true\n  when:\n      - ubuntu1604cis_rule_1_1_1_7\n  tags:\n      - level1\n      - scored\n      - patch\n      - udf\n      - filesystems\n      - rule_1.1.1.7\n\n- name: \"SCORED | 1.1.1.7 | PATCH | Remove udf module\"\n  modprobe:\n      name: udf\n      state: absent\n  when:\n      - ubuntu1604cis_rule_1_1_1_7\n  tags:\n      - level1\n      - scored\n      - patch\n      - udf\n      - filesystems\n      - rule_1.1.1.7\n\n- name: \"SCORED | 1.1.1.8 | PATCH | Ensure mounting of FAT filesystems is disabled\"\n  lineinfile:\n      dest: /etc/modprobe.d/CIS.conf\n      regexp: \"^(#)?install vfat(\\\\s|$)\"\n      line: \"install vfat /bin/true\"\n      state: present\n      create: true\n  when:\n      - ubuntu1604cis_rule_1_1_1_8\n  tags:\n      - level1\n      - scored\n      - patch\n      - vfat\n      - filesystems\n      - rule_1.1.1.8\n\n- name: \"SCORED | 1.1.1.8 | PATCH | Remove FAT module\"\n  modprobe:\n      name: vfat\n      state: absent\n  when:\n      - ubuntu1604cis_rule_1_1_1_8\n  tags:\n      - level2\n      - scored\n      - patch\n      - vfat\n      - filesystems\n      - rule_1.1.1.8\n\n- name: \"SCORED | 1.1.2 | PATCH | Ensure separate partition exists for /tmp | enable and start/restart tmp.mount\"\n  copy:\n      src: \"{{ tmp_mount_file[ansible_os_family] }}\"\n      dest: /etc/systemd/system/tmp.mount\n      owner: root\n      group: root\n      mode: 0644\n      force: true\n      remote_src: true\n  notify:\n      - systemd restart tmp.mount\n  when:\n      - ubuntu1604cis_rule_1_1_2\n      - ubuntu1604cis_skip_for_travis == false\n  tags:\n      - level2\n      - scored\n      - patch\n      - rule_1.1.2\n\n- name: \"SCORED | 1.1.2 | PATCH | Ensure separate partition exists for /tmp | enable and start/restart tmp.mount\"\n  systemd:\n      name: tmp.mount\n      daemon_reload: yes\n      enabled: yes\n      masked: no\n      state: started\n  when:\n      - ubuntu1604cis_rule_1_1_2\n      - ubuntu1604cis_skip_for_travis == false\n  tags:\n      - level2\n      - scored\n      - patch\n      - rule_1.1.2\n\n- name: \"SCORED | 1.1.3 | PATCH | Ensure nodev option set on /tmp partition\\n\n         SCORED | 1.1.4 | PATCH | Ensure nosuid option set on /tmp partition\\n\n         | drop custom tmp.mount\"\n  ini_file:\n      path: \"{{ item }}\"\n      section: Mount\n      option: Options\n      value: \"{{ tmp_mount_options[ansible_os_family] }}\"\n      no_extra_spaces: true\n  with_items:\n      - \"{{ tmp_mount_file[ansible_os_family] }}\"\n      - /etc/systemd/system/tmp.mount\n  notify:\n      - systemd restart tmp.mount\n  when:\n      - ubuntu1604cis_rule_1_1_3\n      - ubuntu1604cis_rule_1_1_4\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_1.1.3\n      - rule_1.1.4\n\n- name: \"SCORED | 1.1.5 | PATCH | Ensure separate partition exists for /var\"\n  shell: mount | grep \"on /var \"\n  register: var_mounted\n  changed_when: false\n  failed_when: false\n  when:\n      - ubuntu1604cis_rule_1_1_5\n  tags:\n      - level2\n      - scored\n      - patch\n      - rule_1.1.5\n      - skip_ansible_lint\n\n- name: \"SCORED | 1.1.6 | PATCH | Ensure separate partition exists for /var/tmp\"\n  shell: mount | grep \"on /var/tmp \"\n  register: var_tmp_mounted\n  changed_when: false\n  failed_when: false\n  when:\n      - ubuntu1604cis_rule_1_1_6\n  tags:\n      - level2\n      - scored\n      - patch\n      - rule_1.1.6\n      - skip_ansible_lint\n\n- name: \"SCORED | 1.1.7  | PATCH | Ensure nodev option set on /var/tmp partition\\n\n         SCORED | 1.1.8  | PATCH | Ensure nosuid option set on /var/tmp partition\\n\n         SCORED | 1.1.9 | PATCH | Ensure noexec option set on /var/tmp partition\"\n  mount:\n      name: /var/tmp\n      src: \"{{ ubuntu1604cis_vartmp['source'] }}\"\n      state: mounted\n      fstype: \"{{ ubuntu1604cis_vartmp['fstype'] }}\"\n      opts: \"{{ ubuntu1604cis_vartmp['opts'] }}\"\n  when:\n      - ubuntu1604cis_vartmp['enabled'] == 'yes'\n      - ubuntu1604cis_rule_1_1_7\n      - ubuntu1604cis_rule_1_1_8\n      - ubuntu1604cis_rule_1_1_9\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_1.1.7\n      - rule_1.1.8\n      - rule_1.1.9\n\n- name: \"SCORED | 1.1.10 | PATCH | Ensure separate partition exists for /var/log\"\n  shell: mount | grep \"on /var/log \"\n  register: var_log_mounted\n  changed_when: false\n  failed_when: false\n  when:\n      - ubuntu1604cis_rule_1_1_10\n  tags:\n      - level2\n      - scored\n      - patch\n      - rule_1.1.10\n      - skip_ansible_lint\n\n- name: \"SCORED | 1.1.11 | PATCH | Ensure separate partition exists for /var/log/audit\"\n  shell: mount | grep \"on /var/log/audit \"\n  register: var_log_audit_mounted\n  changed_when: false\n  failed_when: false\n  when:\n      - ubuntu1604cis_rule_1_1_11\n  tags:\n      - level2\n      - scored\n      - patch\n      - rule_1.1.11\n      - skip_ansible_lint\n\n- name: \"SCORED | 1.1.12 | PATCH | Ensure separate partition exists for /home\"\n  shell: mount | grep \"on /home \"\n  register: home_mounted\n  changed_when: false\n  failed_when: false\n  when:\n      - ubuntu1604cis_rule_1_1_12\n  tags:\n      - level2\n      - scored\n      - patch\n      - rule_1.1.12\n      - skip_ansible_lint\n\n- name: \"SCORED | 1.1.13 | PATCH | Ensure nodev option set on /home partition\"\n  mount:\n      name: \"/home\"\n      src: \"{{ item.device }}\"\n      state: mounted\n      fstype: \"{{ item.fstype }}\"\n      opts: \"nodev\"\n  when:\n      - ubuntu1604cis_rule_1_1_13\n      - item.mount == \"/home\"\n  with_items:\n      - \"{{ ansible_mounts }}\"\n  tags:\n      - scored\n      - level1\n      - patch\n      - rule_1.1.13\n\n- name: \"SCORED | 1.1.14 | PATCH | Ensure nodev option set on /dev/shm partition\\n\n         SCORED | 1.1.15 | PATCH | Ensure nosuid option set on /dev/shm partition\\n\n         SCORED | 1.1.16 | PATCH | Ensure noexec option set on /dev/shm partition\"\n  mount:\n      name: /dev/shm\n      src: tmpfs\n      state: mounted\n      fstype: tmpfs\n      opts: \"defaults,nodev,nosuid,noexec\"\n  when:\n      - ubuntu1604cis_rule_1_1_14\n      - ubuntu1604cis_rule_1_1_15\n      - ubuntu1604cis_rule_1_1_16\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_1.1.14\n      - rule_1.1.15\n      - rule_1.1.16\n\n- name: \"NOTSCORED | 1.1.17 | PATCH | Ensure nodev option set on removable media partitions\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_1_1_17\n  tags:\n      - level1\n      - notscored\n      - patch\n      - rule_1.1.18\n      - notimplemented\n\n- name: \"NOTSCORED | 1.1.18 | PATCH | Ensure nosuid option set on removable media partitions\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_1_1_18\n  tags:\n      - level1\n      - notscored\n      - patch\n      - rule_1.1.18\n      - notimplemented\n\n- name: \"NOTSCORED | 1.1.19 | PATCH | Ensure noexec option set on removable media partitions\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_1_1_19\n  tags:\n      - level1\n      - notscored\n      - patch\n      - rule_1.1.19\n      - notimplemented\n\n- name: \"SCORED | 1.1.20 | PATCH | Ensure sticky bit is set on all world-writable directories\"\n  shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type d -perm -0002 2>/dev/null | xargs chmod a+t\n  changed_when: false\n  failed_when: false\n  when:\n      - ubuntu1604cis_rule_1_1_20\n      # - sticky_bit_on_worldwritable_dirs_audit.rc == '0'\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_1.1.20\n\n- name: \"SCORED | 1.1.21 | PATCH | Disable Automounting\"\n  service:\n      name: autofs\n      enabled: false\n  when:\n      - ubuntu1604cis_allow_autofs == false and autofs_service_status.stdout == \"loaded\"\n      - ubuntu1604cis_rule_1_1_21\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_1.1.21\n\n- name: \"NOTSCORED | 1.2.1 | PATCH | Ensure package manager repositories are configured\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_1_2_1\n  tags:\n      - level1\n      - notscored\n      - patch\n      - rule_1.2.1\n\n\n- name: \"NOTSCORED | 1.2.3 | PATCH | Ensure GPG keys are configured\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_1_2_3\n  tags:\n      - level1\n      - notscored\n      - patch\n      - rule_1.2.3\n      - notimplemented\n\n- name: \"SCORED | 1.3.1 | PATCH | Ensure AIDE is installed\"\n  apt:\n      name: aide\n      state: present\n      install_recommends: false\n  when:\n      - ubuntu1604cis_rule_1_3_1\n  tags:\n      - level1\n      - scored\n      - aide\n      - patch\n      - rule_1.3.1\n\n- name: \"SCORED | 1.3.1 | PATCH | Ensure AIDE is installed\"\n  command: /usr/bin/aide --init -B 'database_out=file:/var/lib/aide/aide.db.gz'\n  args:\n      creates: /var/lib/aide/aide.db.gz\n  changed_when: false\n  failed_when: false\n  async: 45\n  poll: 0\n  when:\n      - ubuntu1604cis_config_aide\n      - ubuntu1604cis_rule_1_3_1\n  tags:\n      - level1\n      - scored\n      - aide\n      - patch\n      - rule_1.3.1\n\n- name: \"SCORED | 1.3.2 | PATCH | Ensure filesystem integrity is regularly checked\"\n  cron:\n      name: Run AIDE integrity check weekly\n      cron_file: \"{{ ubuntu1604cis_aide_cron['cron_file'] }}\"\n      user: \"{{ ubuntu1604cis_aide_cron['cron_user'] }}\"\n      minute: \"{{ ubuntu1604cis_aide_cron['aide_minute'] | default('0') }}\"\n      hour: \"{{ ubuntu1604cis_aide_cron['aide_hour'] | default('5') }}\"\n      day: \"{{ ubuntu1604cis_aide_cron['aide_day'] | default('*') }}\"\n      month: \"{{ ubuntu1604cis_aide_cron['aide_month'] | default('*') }}\"\n      weekday: \"{{ ubuntu1604cis_aide_cron['aide_weekday'] | default('*') }}\"\n      job: \"{{ ubuntu1604cis_aide_cron['aide_job'] }}\"\n  when:\n      - ubuntu1604cis_rule_1_3_2\n  tags:\n      - level1\n      - scored\n      - aide\n      - file_integrity\n      - patch\n      - rule_1.3.2\n\n- name: \"SCORED | 1.4.1 | PATCH | Ensure permissions on bootloader config are configured\"\n  file:\n      path: \"/boot/grub/grub.cfg\"\n      owner: root\n      group: root\n      mode: 0600\n  when: ansible_os_family == \"Debian\"\n  tags:\n      - level1\n      - scored\n      - grub\n      - patch\n      - rule_1.4.1\n\n- name: \"SCORED | 1.4.2 | PATCH | Ensure bootloader password is set\"\n  grub_crypt:\n      password: \"{{ ubuntu1604cis_bootloader_password }}\"\n  register: grub_pass\n  when:\n      - ubuntu1604cis_set_boot_pass\n      - ubuntu1604cis_rule_1_4_2\n  tags:\n      - level1\n      - scored\n      - grub\n      - patch\n      - rule_1.4.2\n      - notimplemented\n\n- name: \"NOTSCORED | 1.4.3 | PATCH | Ensure authentication required for single user mode\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_1_4_3\n  tags:\n      - level1\n      - notscored\n      - patch\n      - rule_1.4.3\n      - notimplemented\n\n- name: \"SCORED | 1.5.1 | PATCH | Ensure core dumps are restricted\"\n  lineinfile:\n      state: present\n      dest: /etc/security/limits.conf\n      regexp: '^#?\\\\*.*core'\n      line: '*                hard    core            0'\n      insertbefore: '^# End of file'\n  when:\n      - ubuntu1604cis_rule_1_5_1\n  tags:\n      - level1\n      - scored\n      - limits\n      - patch\n      - rule_1.5.1\n\n- name: \"SCORED | 1.5.1 | PATCH | Ensure core dumps are restricted\"\n  sysctl:\n      name: fs.suid_dumpable\n      value: 0\n      state: present\n      reload: true\n      sysctl_set: true\n      ignoreerrors: true\n  when:\n      - ubuntu1604cis_rule_1_5_1\n  tags:\n      - level1\n      - scored\n      - sysctl\n      - patch\n      - rule_1.5.1\n\n- name: \"NOTSCORED | 1.5.2 | PATCH | Ensure XD/NX support is enabled\"\n  shell: dmesg | grep -E \"NX|XD\" | grep \" active\"\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_1_5_2\n  tags:\n      - level1\n      - notscored\n      - patch\n      - rule_1.5.2\n      - notimplemented\n\n- name: \"SCORED | 1.5.3 | PATCH | Ensure address space layout randomization (ASLR) is enabled\"\n  sysctl:\n      name: kernel.randomize_va_space\n      value: 2\n      state: present\n      reload: true\n      sysctl_set: true\n      ignoreerrors: true\n  when:\n      - ubuntu1604cis_rule_1_5_3\n  tags:\n      - level1\n      - scored\n      - patch\n      - sysctl\n      - rule_1.5.3\n\n- name: \"SCORED | 1.5.4 | PATCH | Ensure prelink is disabled\"\n  command: prelink -ua\n  when:\n      - prelink_installed.rc == 0\n      - ubuntu1604cis_rule_1_5_4\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_1.5.4\n\n- name: \"SCORED | 1.5.4 | PATCH | Ensure prelink is disabled\"\n  apt:\n      name: prelink\n      state: absent\n  when:\n      - ubuntu1604cis_rule_1_5_4\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_1.5.4\n\n- name: \"SCORED | 1.6.1.1 | PATCH | Ensure SELinux is not disabled in bootloader configuration\"\n  replace:\n      dest: /etc/default/grub\n      regexp: '(selinux|enforcing)\\s*=\\s*0\\s*'\n      follow: true\n  register: selinux_grub_patch\n  ignore_errors: true\n  notify: generate new grub config\n  when:\n      - ubuntu1604cis_rule_1_6_1_1\n  tags:\n      - level2\n      - scored\n      - patch\n      - rule_1.6.1.1\n\n- name: \"SCORED | 1.6.1.2 | PATCH | Ensure the SELinux state is enforcing\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_1_6_1_2\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_1.6.1.2\n      - notimplemented\n\n- name: \"SCORED | 1.6.1.3 | PATCH | Ensure SELinux policy is configured\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_1_6_1_3\n  tags:\n      - level1\n      - scored\n      - patc3\n      - rule_1.6.1.2\n      - notimplemented\n\n- name: \"SCORED | 1.6.1.4 | PATCH | Ensure no unconfined daemons exist\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_1_6_1_4\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_1.6.1.4\n      - notimplemented\n\n- name: \"SCORED | 1.6.2.1 | PATCH | Ensure AppArmor is not disabled in bootloader configuration\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_1_6_2_1\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_1.6.2.1\n      - notimplemented\n\n- name: \"SCORED | 1.6.2.2 | PATCH | Ensure all AppArmor Profiles are enforcing\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_1_6_2_2\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_1.6.2.2\n      - notimplemented\n\n- name: \"SCORED | 1.6.3 | PATCH | Ensure SELinux or AppArmor are installed\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_1_6_3\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_1.6.3\n      - notimplemented\n\n\n- name: \"SCORED | 1.7.1.1 | PATCH | Ensure message of the day is configured properly\"\n  template:\n      src: etc/motd.j2\n      dest: /etc/motd\n  when:\n      - ubuntu1604cis_rule_1_7_1_1\n  tags:\n      - level1\n      - scored\n      - patch\n      - banner\n      - rule_1.7.1.1\n\n- name: \"NOTSCORED | 1.7.1.2 | PATCH | Ensure local login warning banner is configured properly\"\n  template:\n      src: etc/issue.j2\n      dest: /etc/issue\n  when:\n      - ubuntu1604cis_rule_1_7_1_2\n  tags:\n      - level1\n      - notscored\n      - patch\n      - banner\n      - rule_1.7.1.2\n\n- name: \"NOTSCORED | 1.7.1.3 | PATCH | Ensure remote login warning banner is configured properly\"\n  template:\n      src: etc/issue.net.j2\n      dest: /etc/issue.net\n  when:\n      - ubuntu1604cis_rule_1_7_1_3\n  tags:\n      - level1\n      - notscored\n      - patch\n      - banner\n      - rule_1.7.1.3\n\n- name: \"NOTSCORED | 1.7.1.4 | PATCH | Ensure permissions on /etc/motd are configured\"\n  file:\n      dest: /etc/motd\n      state: file\n      owner: root\n      group: root\n      mode: 0644\n  when:\n      - ubuntu1604cis_rule_1_7_1_4\n  tags:\n      - level1\n      - notscored\n      - patch\n      - perms\n      - rule_1.7.1.4\n\n- name: \"SCORED | 1.7.1.5 | PATCH | Ensure permissions on /etc/issue are configured\"\n  file:\n      dest: /etc/issue\n      state: file\n      owner: root\n      group: root\n      mode: 0644\n  when:\n      - ubuntu1604cis_rule_1_7_1_5\n  tags:\n      - level1\n      - scored\n      - patch\n      - perms\n      - rule_1.7.1.5\n\n- name: \"NOTSCORED | 1.7.1.6 | PATCH | Ensure permissions on /etc/issue.net are configured\"\n  file:\n      dest: /etc/issue.net\n      state: file\n      owner: root\n      group: root\n      mode: 0644\n  when:\n      - ubuntu1604cis_rule_1_7_1_6\n  tags:\n      - level1\n      - notscored\n      - patch\n      - perms\n      - rule_1.7.1.6\n\n- name: \"SCORED | 1.7.2 | PATCH | Ensure GDM login banner is configured\"\n  lineinfile:\n      dest: \"{{ item.file }}\"\n      regexp: \"{{ item.regexp }}\"\n      line: \"{{ item.line }}\"\n      state: present\n      create: true\n      owner: root\n      group: root\n      mode: 0644\n  with_items:\n      - { file: '/etc/dconf/profile/gdm', regexp: 'user-db', line: 'user-db:user' }\n      - { file: '/etc/dconf/profile/gdm', regexp: 'system-db', line: 'system-db:gdm' }\n      - { file: '/etc/dconf/profile/gdm', regexp: 'file-db', line: 'file-db:/usr/share/gdm/greeter-dconf-defaults' }\n      - { file: '/etc/dconf/db/gdm.d/01-banner-message', regexp: '\\[org\\/gnome\\/login-screen\\]', line: '[org/gnome/login-screen]' }\n      - { file: '/etc/dconf/db/gdm.d/01-banner-message', regexp: 'banner-message-enable', line: 'banner-message-enable=true' }\n      - { file: '/etc/dconf/db/gdm.d/01-banner-message', regexp: 'banner-message-text', line: \"banner-message-text='{{ ubuntu1604cis_warning_banner }}' \" }\n  when:\n      - ubuntu1604cis_gui\n      - ubuntu1604cis_rule_1_7_2\n  tags:\n      - level1\n      - scored\n      - patch\n      - banner\n      - rule_1.7.2\n\n- name: \"NOTSCORED | 1.8 | PATCH | Ensure updates, patches, and additional security software are installed\"\n  apt:\n      upgrade: dist\n  tags:\n      - level1\n      - notscored\n      - patch\n      - rule_1.8\n      - skip_ansible_lint\n"}, {"commit_sha": "045ff4bb9f4720739632aac2951fbf2798a99c8c", "sha": "2c667ac08ffd26a3d0399f6bbc6f72a1efa14f6a", "filename": "roles/ssh_tunneling/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- set_fact:\n    IP_subject_alt_name: \"{{ IP_subject_alt_name }}\"\n\n- name: Ensure that the sshd_config file has desired options\n  blockinfile:\n    dest: /etc/ssh/sshd_config\n    marker: '# ANSIBLE_MANAGED_ssh_tunneling_role'\n    block: |\n      Match Group algo\n          AllowTcpForwarding local\n          AllowAgentForwarding no\n          AllowStreamLocalForwarding no\n          PermitTunnel no\n          X11Forwarding no\n  notify:\n    - restart ssh\n\n- name: Ensure that the algo group exist\n  group: name=algo state=present\n\n- name: Ensure that the jail directory exist\n  file: path=/var/jail/ state=directory mode=0755  owner=root group=root\n\n- name: Ensure that the SSH users exist\n  user:\n    name: \"{{ item }}\"\n    groups: algo\n    home: '/var/jail/{{ item }}'\n    createhome: yes\n    generate_ssh_key: yes\n    shell: /bin/false\n    ssh_key_type: ecdsa\n    ssh_key_bits: 256\n    ssh_key_comment: '{{ item }}@{{ IP_subject_alt_name }}'\n    ssh_key_passphrase: \"{{ easyrsa_p12_export_password }}\"\n    state: present\n    append: yes\n  with_items: \"{{ users }}\"\n\n- name: The authorized keys file created\n  file:\n    src: '/var/jail/{{ item }}/.ssh/id_ecdsa.pub'\n    dest: '/var/jail/{{ item }}/.ssh/authorized_keys'\n    owner: \"{{ item }}\"\n    group: \"{{ item }}\"\n    state: link\n  with_items: \"{{ users }}\"\n\n- name: Generate SSH fingerprints\n  shell: >\n    ssh-keyscan {{ IP_subject_alt_name }} 2>/dev/null\n  register: ssh_fingerprints\n\n- name: The known_hosts file created\n  template: src=known_hosts.j2 dest=/root/.ssh/{{ IP_subject_alt_name }}_known_hosts\n\n- name: Fetch users SSH private keys\n  fetch: src='/var/jail/{{ item }}/.ssh/id_ecdsa' dest=configs/{{ IP_subject_alt_name }}/{{ item }}.ssh.pem flat=yes\n  with_items: \"{{ users }}\"\n\n- name: Change mode for SSH private keys\n  local_action: file path=configs/{{ IP_subject_alt_name }}/{{ item }}.ssh.pem mode=0600\n  with_items: \"{{ users }}\"\n  become: false\n\n- name: Fetch the known_hosts file\n  fetch: src='/root/.ssh/{{ IP_subject_alt_name }}_known_hosts' dest=configs/{{ IP_subject_alt_name }}/{{ IP_subject_alt_name }}_known_hosts flat=yes\n\n- name: Build the client ssh config\n  local_action:\n    module: template\n    src: ssh_config.j2\n    dest: configs/{{ IP_subject_alt_name }}/{{ item }}.ssh_config\n    mode: 0600\n  become: no\n  with_items:\n    - \"{{ users }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "fadea75b9ac832d586bda25c277b2acd8908c775", "filename": "roles/xovis/README.rst", "repository": "iiab/iiab", "decoded_content": "============\nxovis README\n============\n\nFor information on the xovis feature see https://github.com/martasd/xovis/blob/master/README.md.\n\nLinks to Services\n-----------------\n\nTo change the installation parameters edit vars/default_vars.yml:\n\nxovis_target_host: \"127.0.0.1:5984\"\nxovis_deployment_name: olpc\n\nxovis_db_name: xovis\nxovis_db_user: admin\nxovis_db_password: admin\nxovis_db_login: \"{{ xovis_db_user }}:{{ xovis_db_password }}\"\nxovis_db_url: \"http://{{ xovis_db_login }}@{{ xovis_target_host }}/{{ xovis_db_name }}\"\n\nxovis_root: \"/opt/xovis\"\nxovis_backup_dir: \"/library/users\"\nxovis_repo_url: \"https://github.com/martasd/xovis.git\"\nxovis_chart_heading: \"My School: Usage Data Visualization\"\n\nMost of these will not need changing, but you will likely want to change the deployment name, the chart heading, and the database admin password.\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "039fa93fdbc0bd426aacf5f2fd7ff124cf4eb1cf", "filename": "roles/dokuwiki/README.rst", "repository": "iiab/iiab", "decoded_content": "===============\nDokuwiki README\n===============\n\nDokuWiki is a simple to use and highly versatile Open Source wiki software that \ndoesn't require a database. It is loved by users for its clean and readable\nsyntax. The ease of maintenance, backup and integration makes it an \nadministrator's favorite. Built in access controls and authentication connectors\nmake DokuWiki especially useful in the enterprise context and the large number of\nplugins contributed by its vibrant community allow for a broad range of use cases\nbeyond a traditional wiki. \n\nhttp://dokuwiki.org/\n\nAfter Installation\n------------------\n\nHead to http://schoolserver.lan/wiki. The webpage will probably throw up an error\nsaying you haven't run install.php yet, with a link to it. Click the link to be \ntaken to the install page which does the initial configuration of the wiki. After\nthis, you should be all set!\n\nLocations\n---------\n\nEverything is copied to the /opt/dokuwiki folder. An apache configuration file is\ninstalled in the usual conf.d directory.\n\nParameters\n----------\nNone yet other than the basic enabled/disabled. Haven't really tested if they work.\n\nTodo\n----\n* Preinstall some popular plugins.\n* Additional XSCE customizations.\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "5bfb4fcbc8fbf8f080435031e34ca8b7d5126e5e", "filename": "tasks/create_repo_docker_group_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_docker_group\n    args: \"{{ _nexus_repos_docker_defaults|combine(item) }}\"\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "0f63702625efad23d4a420735c8661d89a421873", "filename": "roles/nginx/defaults/main.yml", "repository": "roots/trellis", "decoded_content": "---\nnginx_path: /etc/nginx\nnginx_logs_root: /var/log/nginx\nnginx_user: www-data\nnginx_fastcgi_buffers: 8 8k\nnginx_fastcgi_buffer_size: 8k\nnginx_ssl_path: \"{{ nginx_path }}/ssl\"\n\n# HSTS defaults\nnginx_hsts_max_age: 31536000\nnginx_hsts_include_subdomains: true\nnginx_hsts_preload: true\n\n# Fastcgi cache params\nnginx_cache_path: /var/cache/nginx\nnginx_cache_duration: 30s\nnginx_cache_key_storage_size: 10m\nnginx_cache_size: 250m\nnginx_cache_inactive: 1h\nnginx_skip_cache_uri: /wp-admin/|/xmlrpc.php|wp-.*.php|/feed/|index.php|sitemap(_index)?.xml\nnginx_skip_cache_cookie: comment_author|wordpress_[a-f0-9]+|wp-postpass|wordpress_no_cache|wordpress_logged_in\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "7c53a3d23cc0e3dc9e81c050aaa284db8d2543ce", "filename": "roles/dockerbench/defaults/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# defaults file for dockerbench\ndockerbench_run_test: false\ndockerbench_dest: /opt/dockerbench\ndockerbench_repo: https://github.com/docker/docker-bench-security.git\ndockerbench_version: master\ndockerbench_warn_threshold: 100\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "9f88591f552f9aca50f27606a9ae676758065849", "filename": "roles/deploy/hooks/finalize-after.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: WordPress Installed?\n  command: wp core is-installed\n  args:\n    chdir: \"{{ deploy_helper.new_release_path }}\"\n  register: wp_installed\n  changed_when: false\n  failed_when: wp_installed.stderr != \"\"\n\n- name: Update WP theme paths\n  command: wp eval 'wp_clean_themes_cache(); switch_theme(get_stylesheet());'\n  args:\n    chdir: \"{{ deploy_helper.new_release_path }}\"\n  when: wp_installed | success\n\n- name: Update WP database\n  command: wp core update-db\n  args:\n    chdir: \"{{ deploy_helper.new_release_path }}\"\n  when: wp_installed | success and not project.multisite.enabled | default(false)\n\n- name: Warn about updating network database.\n  debug:\n    msg: \"Updating the network database could take a long time with a large number of sites.\"\n  when: wp_installed | success and project.multisite.enabled | default(false)\n\n- name: Update WP network database\n  command: wp core update-db --network\n  args:\n    chdir: \"{{ deploy_helper.new_release_path }}\"\n  when: wp_installed | success and project.multisite.enabled | default(false)\n\n- name: Reload php-fpm\n  shell: sudo service php7.0-fpm reload\n  args:\n    chdir: \"{{ deploy_helper.new_release_path }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "51f959e9f1d1f9fc8d395f53b562affd46dc5106", "filename": "playbooks/provision-idm-server/configure-idm-server.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: idm-server\n  roles:\n  - role: config-idm-server\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "bb58659e1a5ed140ccdcafabcb7ea5270087e18d", "filename": "tasks/delete_blobstore_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: delete_blobstore\n    args: \"{{ item }}\"\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "8f6d0e837e3c3df8d201f4b6af781bce28ce1883", "filename": "tasks/conf/template-config.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Setup: All NGINX) Ensure HTML Directory Exists\"\n  file:\n    path: \"{{ item.value.html_file_location | default('/usr/share/nginx/html') }}\"\n    state: directory\n  with_dict: \"{{ nginx_html_demo_template }}\"\n  when: nginx_html_demo_template_enable | bool\n\n- name: \"(Setup: All NGINX) Dynamically Generate HTML Files\"\n  template:\n    src: \"{{ item.value.template_file | default('www/index.html.j2') }}\"\n    dest: \"{{ item.value.html_file_location | default('/usr/share/nginx/html') }}/{{ item.value.html_file_name | default('index.html') }}\"\n    backup: yes\n  with_dict: \"{{ nginx_html_demo_template }}\"\n  when: nginx_html_demo_template_enable | bool\n\n- name: \"(Setup: All NGINX) Ensure NGINX Main Directory Exists\"\n  file:\n    path: \"{{ nginx_main_template.conf_file_location | default('/etc/nginx') }}\"\n    state: directory\n  when: nginx_main_template_enable | bool\n\n- name: \"(Setup: All NGINX) Dynamically Generate NGINX Main Configuration File\"\n  template:\n    src: \"{{ nginx_main_template.template_file | default('nginx.conf.j2') }}\"\n    dest: \"{{ nginx_main_template.conf_file_location | default('/etc/nginx') }}/{{ nginx_main_template.conf_file_name | default('nginx.conf') }}\"\n    backup: yes\n  when: nginx_main_template_enable | bool\n  notify: \"(Handler: All OSs) Reload NGINX\"\n\n- name: \"(Setup: All NGINX) Ensure NGINX HTTP Directory Exists\"\n  file:\n    path: \"{{ item.value.conf_file_location | default('/etc/nginx/conf.d/') }}\"\n    state: directory\n  with_dict: \"{{ nginx_http_template }}\"\n  when: nginx_http_template_enable | bool\n\n- name: \"(Setup: All NGINX) Ensure NGINX Proxy Cache Directories Exist\"\n  file:\n    path: \"{{ item.1.path }}\"\n    state: directory\n    owner: \"{{ nginx_main_template.user | default('nginx') }}\"\n  with_subelements:\n    - \"{{ nginx_http_template }}\"\n    - reverse_proxy.proxy_cache_path\n    - skip_missing: true\n  when: nginx_http_template_enable | bool\n\n- name: \"(Setup: All NGINX) Dynamically Generate NGINX HTTP Configuration Files\"\n  template:\n    src: \"{{ item.value.template_file | default('http/default.conf.j2') }}\"\n    dest: \"{{ item.value.conf_file_location | default('/etc/nginx/conf.d/') }}/{{ item.value.conf_file_name | default('default.conf') }}\"\n    backup: yes\n  with_dict: \"{{ nginx_http_template }}\"\n  when: nginx_http_template_enable | bool\n  notify: \"(Handler: All OSs) Reload NGINX\"\n\n\n- name: \"(Setup: All NGINX) Dynamically Generate NGINX API Configuration File\"\n  template:\n    src: \"{{ nginx_rest_api_template_file | default('http/api.conf.j2') }}\"\n    dest: \"{{ nginx_rest_api_file_location | default('/etc/nginx/conf.d/api.conf') }}\"\n    backup: yes\n  notify: \"(Handler: All OSs) Reload NGINX\"\n  when: nginx_rest_api_enable | bool\n\n- name: \"(Setup: All NGINX) Ensure NGINX Stream Directory Exists\"\n  file:\n    path: \"{{ item.value.conf_file_location | default('/etc/nginx/conf.d/stream/') }}\"\n    state: directory\n  with_dict: \"{{ nginx_stream_template }}\"\n  when: nginx_stream_template_enable | bool\n\n- name: \"(Setup: All NGINX) Dynamically Generate NGINX Stream Configuration Files\"\n  template:\n    src: \"{{ item.value.template_file | default('stream/default.conf.j2') }}\"\n    dest: \"{{ item.value.conf_file_location | default('/etc/nginx/conf.d/stream/') }}/{{ item.value.conf_file_name | default('default.conf') }}\"\n    backup: yes\n  with_dict: \"{{ nginx_stream_template }}\"\n  notify: \"(Handler: All OSs) Reload NGINX\"\n  when: nginx_stream_template_enable | bool\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "dcc3c942f1f8c11c34d87618fade7faa70644201", "filename": "roles/docker/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "docker_install: True\ndocker_enabled: False\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "df1d2ead7ffd55131f556f0bcfc6e09646f2729a", "filename": "roles/config-selinux/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# \"targeted\" is the \"default\" policy for most systems\ntarget_policy: 'targeted'\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "dca1ba50528ea24afae42cb9e0c518fd69712d1c", "filename": "roles/wordpress-setup/defaults/main.yml", "repository": "roots/trellis", "decoded_content": "site_uses_local_db: \"{{ site_env.db_host == 'localhost' }}\"\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "c2e6ebfee2929a9ac54ab0df3e098751c8a4f27e", "filename": "roles/config-httpd/tasks/seed.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Seed web server with content'\n  copy:\n    src: \"{{ httpd_seed_dir }}\"\n    dest: \"{{ html_document_root | default(default_document_root) }}\"\n  when:\n  - httpd_seed_dir is defined \n  - httpd_seed_dir|trim != \"\" \n\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "08792b6c2b0a52501eccd50d2a5e763f498f54d8", "filename": "cookbooks/simplerock/metadata.rb", "repository": "rocknsm/rock", "decoded_content": "name 'simplerock'\nmaintainer 'rocknsm.io'\nmaintainer_email 'jeff@rocknsm.io'\nlicense 'all_rights'\ndescription 'Installs/Configures a simple version of ROCK'\nlong_description 'Installs/Configures a simple version of ROCK'\nversion '0.1.1'\n\ndepends 'yum', '~> 3.6.1'\ndepends 'packagecloud'\n## Tabled for now, using dcode's java headless package\n#depends 'java', '~> 1.0'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "299bbf45460383d2c62e66cd76f91e1a37452b2e", "filename": "roles/ansible/tower/manage-workflow-templates/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ndefault_ansible_tower_url: 'https://localhost'\ndefault_ansible_tower_admin_username: 'admin'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "31d8659936b762717e87765de38c475fa45ed451", "filename": "roles/notifications/md-to-html/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Test converting MD to HTML\n  hosts: localhost\n  roles:\n    - notifications/md-to-html\n  tasks:\n    - debug:\n        msg: \"{{ md_to_html.html_body_message }}\"\n    - debug:\n        msg: \"{{ md_to_html.html_message }}\"\n\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "406d6d27a37688a00f6724939db7450d1a59bf2b", "filename": "tasks/amplify/setup-debian.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: Debian/Ubuntu) Add NGINX Amplify Agent Repository\"\n  apt_repository:\n    filename: nginx-amplify\n    repo: deb http://packages.amplify.nginx.com/{{ ansible_distribution|lower }}/ {{ ansible_distribution_release|lower }} amplify-agent\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "dc35e6970f4ff6f54db608f2ff1d8ec5f1a39e59", "filename": "roles/dcos_cli/vars/prometheus.yml", "repository": "Capgemini/Apollo", "decoded_content": "dcos_cli_app_prometheus_enabled: \"{{ prometheus_enabled }}\"\ndcos_cli_app_prometheus_mem: 128\ndcos_cli_app_prometheus_cpus: 0.5\ndcos_cli_app_prometheus_instances: 1\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "2aed5c713740415d3b58347e65fc140ccc25d3c9", "filename": "roles/config-vnc-server/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Prep for VNC server install\"\n  import_tasks: prereq.yml\n  when: \n  - vnc_server_install|default(False)\n\n- name: \"Install, configure and enable VNC server\"\n  import_tasks: vnc-server.yml\n  when: \n  - vnc_server_install|default(False)\n\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "d92f27b0a011db88f6a63af413c05a9f6b065236", "filename": "roles/update-host/tasks/update-host.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Update the host\"\n  package:\n    name: \"*\"\n    state: latest\n  register: host_updated\n  when: \n    - pkg_update|default(False) \n\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "83c9bd7c8f73fb59088dbbd9b82c3b1a63357e38", "filename": "roles/wordpress-install/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- include: directories.yml\n  tags: wordpress-install-directories\n\n- name: Create .env file\n  template:\n    src: \"env.j2\"\n    dest: \"/tmp/{{ item.key }}.env\"\n    owner: \"{{ web_user }}\"\n    group: \"{{ web_group }}\"\n  with_dict: \"{{ wordpress_sites }}\"\n\n- name: Copy .env file into web root\n  command: rsync -ac --info=NAME /tmp/{{ item.key }}.env {{ www_root }}/{{ item.key }}/{{ item.value.current_path | default('current') }}/.env\n  with_dict: \"{{ wordpress_sites }}\"\n  register: env_file\n  changed_when: env_file.stdout == \"{{ item.key }}.env\"\n\n- name: Install Dependencies with Composer\n  command: composer install\n  args:\n    chdir: \"{{ www_root }}/{{ item.key }}/{{ item.value.current_path | default('current') }}/\"\n  register: composer_results\n  with_dict: \"{{ wordpress_sites }}\"\n  changed_when: \"'Nothing to install or update' not in composer_results.stderr\"\n\n- name: Install WP\n  command: wp core install\n           --allow-root\n           --url=\"{{ site_env.wp_home }}\"\n           --title=\"{{ item.value.site_title | default(item.key) }}\"\n           --admin_user=\"{{ item.value.admin_user | default('admin') }}\"\n           --admin_password=\"{{ vault_wordpress_sites[item.key].admin_password }}\"\n           --admin_email=\"{{ item.value.admin_email }}\"\n  args:\n    chdir: \"{{ www_root }}/{{ item.key }}/{{ item.value.current_path | default('current') }}/\"\n  register: wp_install_results\n  with_dict: \"{{ wordpress_sites }}\"\n  when: item.value.site_install | default(true) and not item.value.multisite.enabled | default(false)\n  changed_when: \"'WordPress is already installed.' not in wp_install_results.stdout\"\n\n- name: Install WP Multisite\n  command: wp core multisite-install\n           --allow-root\n           --url=\"{{ site_env.wp_home }}\"\n           --base=\"{{ item.value.multisite.base_path | default('/') }}\"\n           --subdomains=\"{{ item.value.multisite.subdomains | default('false') }}\"\n           --title=\"{{ item.value.site_title | default(item.key) }}\"\n           --admin_user=\"{{ item.value.admin_user | default('admin') }}\"\n           --admin_password=\"{{ vault_wordpress_sites[item.key].admin_password }}\"\n           --admin_email=\"{{ item.value.admin_email }}\"\n  args:\n    chdir: \"{{ www_root }}/{{ item.key }}/{{ item.value.current_path | default('current') }}/\"\n  register: wp_install_results\n  with_dict: \"{{ wordpress_sites }}\"\n  when: item.value.site_install | default(true) and item.value.multisite.enabled | default(false)\n  changed_when: \"'The network already exists.' not in wp_install_results.stdout\"\n\n- name: Setup Permalink Structure\n  command: wp rewrite structure {{ item.value.initial_permalink_structure | default(\"/%postname%/\") }} --allow-root\n  args:\n    chdir: \"{{ www_root }}/{{ item.key }}/{{ item.value.current_path | default('current') }}/\"\n  with_dict: \"{{ wordpress_sites }}\"\n  when: wp_install_results | changed\n\n- name: Update WP Multisite Home URL\n  command: wp option update home {{ site_env.wp_home }} --allow-root\n  args:\n    chdir: \"{{ www_root }}/{{ item.key }}/{{ item.value.current_path | default('current') }}/\"\n  with_dict: \"{{ wordpress_sites }}\"\n  when: item.value.site_install | default(true) and item.value.multisite.enabled | default(false)\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "4fec4488af03bfa5547ac9187d9ec10626fd974b", "filename": "playbooks/provision-dns-server/configure-dns-server.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n#\n# Make sure to check out the `config-dns-server` README for details on how to create the inventory\n# https://github.com/redhat-cop/infra-ansible/blob/master/roles/config-dns-server/README.md\n#\n\n\n- hosts: dns-server\n  roles:\n  - role: config-dns-server\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "4a72c347f66c059f9caa4debbafcb4cfaa7d85be", "filename": "roles/virt-install/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ndefault_http_dir: \"/var/www/html\"\ndefault_http_host: \"192.168.122.1\"\n\ndefault_connect: \"qemu:///system\"\ndefault_virt_type: \"kvm\"\ndefault_name: \"tmpvm-{{ ansible_date_time.epoch }}\"\ndefault_title: \"tmpvm-title\"\ndefault_description: \"tmpvm-description\"\ndefault_memory: \"1024\"\ndefault_vcpus: \"2\"\ndefault_disk_size: \"10\"\ndefault_disk_pool: \"default\"\ndefault_os_variant: \"rhel7.3\"\ndefault_iso: \"/tmp/rhel-server-7.3-x86_64-dvd.iso\"\ndefault_ksfile: \"/tmp/my.ks\"\ndefault_authorized_keys: \"/tmp/authorized_keys\"\ndefault_network_hostif: \"eth0\"\ndefault_network_model: \"virtio\"\n"}, {"commit_sha": "0c050ee7f22968afdb69da3b859869efea2bfffa", "sha": "7ce04c9f8f55718f6cc27998f50651e82435e0ee", "filename": "meta/main.yml", "repository": "geerlingguy/ansible-role-solr", "decoded_content": "---\ndependencies: []\n\ngalaxy_info:\n  author: geerlingguy\n  description: Apache Solr for Linux.\n  company: \"Midwestern Mac, LLC\"\n  license: \"license (BSD, MIT)\"\n  min_ansible_version: 2.2\n  platforms:\n    - name: EL\n      versions:\n      - 6\n      - 7\n    - name: Debian\n      versions:\n      - all\n    - name: Ubuntu\n      versions:\n      - all\n  galaxy_tags:\n    - development\n    - solr\n    - search\n    - lucene\n    - container\n    - apache\n    - text\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "d4a2cdaa6072534e23054883745ef596a5bf7f42", "filename": "roles/config-postgresql/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Restart PostgreSQL Service\n  systemd:\n    name: \"{{ postgresql_service }}\"\n    enabled: yes\n    state: restarted\n    daemon_reload: yes\n\n- name: restart firewalld\n  service:\n    name: firewalld\n    state: restarted\n\n- name: restart iptables\n  service:\n    name: iptables\n    state: restarted\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "d2b445360b9713faafbe1b007dff49f1e2584eea", "filename": "roles/pathagar/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "---\n# variables for pathagar\n\npathagar_subpath: /books\n\npathagar_dir: /usr/local/pathagar\npathagar_media: /library/pathagar/media\npathagar_src: '{{ pathagar_dir }}/pathagar'\npathagar_venv: '{{ pathagar_dir }}/venv'\npathagar_collectstatic: '{{ pathagar_dir }}/static'\n\npathagar_db_name: pathagar\npathagar_db_user: pathagar\npathagar_db_password: pathagar\n\npathagar_username: pathagar\npathagar_password: \"pbkdf2_sha256$10000$qkA7MPkQWHTY$AO5j/ByLC68qEt8X1c9QvieArbadYKhiBnlKe8uR6G8=\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "d8977bb363fd190c983b1ae7b11a9e90cb2abff0", "filename": "roles/1-prep/templates/iiab-extra.repo", "repository": "iiab/iiab", "decoded_content": "[iiab-extra]\nname=iiab-extra\nfailovermethod=priority\nbaseurl=http://download.iiab.io/repos/xs-extra/\nenabled=1\nmetadata_expire=1d\ngpgcheck=0\n\n[dummy-config]\nname=dummy-config\nfailovermethod=priority\nbaseurl=http://download.iiab.io/repos/xsce-extra/\nenabled=1\nmetadata_expire=1d\ngpgcheck=0\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "b65b387be8cb06b33bc8cf87c97bb84d78bb64bb", "filename": "roles/user-management/manage-user-passwd/tasks/idm-set-passwd.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Change IPA password for user: {{ item.user_name }}\"\n  ipa_user:\n    ipa_host: \"{{ ipa_host }}\"\n    ipa_user: \"{{ ipa_admin_user }}\"\n    ipa_pass: \"{{ ipa_admin_password }}\"\n    validate_certs: \"{{ ipa_validate_certs | default(False) }}\"\n    name: \"{{ item.user_name | trim }}\"\n    password: \"{{ item.password }}\"\n  with_items: \n    - \"{{ users }}\" \n  when: \n    - users is defined \n    - item.password|trim != ''\n\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "c280d5b2a4df18130a0a36f1f63334e8dc09218d", "filename": "playbooks/bb4/proxy.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- name: Setup squid proxy\n  hosts: bastion\n  gather_facts: no\n  vars_files:\n  - ../vars/bb4.yml\n  - ../group_vars/all\n  tasks:\n  - name: Install required packages\n    yum:\n      name: \"{{item}}\"\n      state: present\n    with_items: \"{{proxy_packages}}\"\n  - name: Create squid conf\n    template:\n      src: templates/squid.j2\n      dest: /etc/squid/squid.conf\n      mode: 0755\n    notify: Restart squid\n  handlers:\n    - name: Restart squid\n      service:\n        name: squid\n        state: restarted\n\n\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "c5dc7dd32be7414b513e73927e2f4d524d189b21", "filename": "tasks/create_repo_yum_hosted_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_yum_hosted\n    args: \"{{ _nexus_repos_yum_defaults|combine(item) }}\"\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "f3d19204720c1bb828a85c0369dbab1611e6e539", "filename": "roles/vpn/meta/main.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\ndependencies:\n  - { role: common, tags: common }\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "ac07828cb66b91e51b30cd432ce9678094c2c95a", "filename": "roles/rachel/README.rst", "repository": "iiab/iiab", "decoded_content": "=============\nRACHEL README\n=============\n\nThis is the second pass at adding RACHEL (http://www.rachel.worldpossible.org/) to XSCE.\nIt takes RACHEL in its entirety and the download must be copied manually.\nThis version is based on rachelusb_32EN_3.1.5.zip.\n\nDo the following:\n\n* Uuzip rachelusb_32EN_3.1.5.zip into /library.  You should get /library/rachelusb_32EN_3.1.4.\n* mkdir /library/rachel\n* cd /library/rachel\n* mv /library/rachelusb_32EN_3.1.4/RACHEL/bin .\n* you should see /library/rachel/bin/www/index.php\n* re-run ansible (making sure that rachel_enabled: True has been set in vars/local_vars.yml\n\nLocations\n---------\n\n- The RACHEL download is expected to be in /library/rachel\n- The URL is /rachel\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "613e2844b7ec6a5f906cd655af4202063e22eb7c", "filename": "roles/manage-confluence-space/tasks/create_confluence_space.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Use a unique temporary file to store the Persistent Volume object\n  command: mktemp\n  register: jsontemp\n  delegate_to: 127.0.0.1\n\n- name: Create post json\n  template:\n    src: space.j2\n    dest: '{{ jsontemp.stdout }}'\n  delegate_to: 127.0.0.1\n\n- name: Create Confluence Space\n  uri:\n    url: '{{ confluence_space_destination_url }}/rest/api/space'\n    method: POST\n    user: '{{ destination_confluence_site_username }}'\n    password: '{{ destination_confluence_site_password }}'\n    force_basic_auth: yes\n    status_code: 200\n    body_format: json\n    body: \"{{ lookup('file', '{{ jsontemp.stdout }}') }}\"\n  no_log: true"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "9415081c9b9f7d381cdd20ce282c0993f5ca9ccb", "filename": "roles/osp/admin-keystone-domain/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: yum-clean-metadata\n  command: yum clean metadata\n  args:\n    warn: no\n\n"}, {"commit_sha": "abafe1581c6c78d784cf215b214947675d49eff8", "sha": "4be243340dc7e851d30ac74cfbf741c65da86706", "filename": "roles/local/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: Add the instance to an inventory group\n  add_host:\n    name: \"{{ server_ip }}\"\n    groups: vpn-host\n    ansible_ssh_user: \"{{ server_user }}\"\n    ansible_python_interpreter: \"/usr/bin/python2.7\"\n    easyrsa_p12_export_password: \"{{ easyrsa_p12_export_password }}\"\n    cloud_provider: local\n  when: server_ip != \"localhost\"\n\n- name: Add the instance to an inventory group\n  add_host:\n    name: \"{{ server_ip }}\"\n    groups: vpn-host\n    ansible_ssh_user: \"{{ server_user }}\"\n    ansible_python_interpreter: \"/usr/bin/python2.7\"\n    ansible_connection: local\n    easyrsa_p12_export_password: \"{{ easyrsa_p12_export_password }}\"\n    cloud_provider: local\n  when: server_ip == \"localhost\"\n\n- name: Waiting for SSH to become available\n  local_action: \"wait_for port=22 host={{ server_ip }} timeout=320\"\n  when: server_ip != \"localhost\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "040d3c846b6d4bcba69faf7bc308e10a027c67f4", "filename": "roles/config-satellite/tasks/repos.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Enable repositories (with release_version)\"\n  command: > \n    hammer\n      -u \"{{ satellite_username }}\"\n      -p \"{{ satellite_password }}\"\n      repository-set enable \n      --organization \"{{ satellite_organization }}\"\n      --product \"{{ item.0.product }}\"\n      --name \"{{ item.0.name }}\"\n      --releasever \"{{ item.1 }}\"\n      --basearch \"{{ item.0.base_arch }}\"\n  with_subelements:\n  - \"{{ satellite_repositories }}\"\n  - release_version\n  register: enable_repos\n  failed_when:\n  - enable_repos.rc != 70\n  - enable_repos.rc != 0\n\n- name: \"Enable repositories (without release_version)\"\n  command: > \n    hammer\n      -u \"{{ satellite_username }}\"\n      -p \"{{ satellite_password }}\"\n      repository-set enable \n      --organization \"{{ satellite_organization }}\"\n      --product \"{{ item.product }}\"\n      --name \"{{ item.name }}\"\n      --basearch \"{{ item.base_arch }}\"\n  with_items:\n  - \"{{ satellite_repositories }}\"\n  register: enable_repos\n  failed_when:\n  - enable_repos.rc != 70\n  - enable_repos.rc != 0\n  when: \n  - item.release_version|length == 0\n\n- name: \"Get Red Hat repo ids\"\n  shell: hammer -u \"{{ satellite_username }}\" -p \"{{ satellite_password }}\" repository list --organization \"{{ satellite_organization }}\" | grep \"Red Hat\" | awk '{print $1}'\n  register: repoids\n\n# This will take awhile, so fire-and-forget\n- name: \"Synchronize Red Hat repos (fire and forget)\"\n  command: >\n    hammer\n      -u \"{{ satellite_username }}\"\n      -p \"{{ satellite_password }}\"\n      repository synchronize\n      --id \"{{ item }}\"\n      --organization \"{{ satellite_organization }}\"\n  async: 1000\n  poll: 0\n  with_items:\n  - \"{{ repoids.stdout.split('\\n') }}\"\n\n- name: \"Get tomorrow (start-date for sync plan)\"\n  shell: echo \"$(date -d tomorrow -I) 05:00:00\"\n  register: sync_date\n\n- name: \"Create sync plan\"\n  command: >\n    hammer\n      -u \"{{ satellite_username }}\"\n      -p \"{{ satellite_password }}\"\n      sync-plan create\n      --name \"{{ satellite_sync_plan }}\"\n      --organization \"{{ satellite_organization }}\"\n      --enabled true\n      --interval daily\n      --sync-date \"{{ sync_date.stdout }}\"\n  register: chk_plan\n  failed_when:\n  - chk_plan.rc != 65\n  - chk_plan.rc != 0\n\n- name: \"Add products to sync plan\"\n  command: >\n    hammer\n      -u \"{{ satellite_username }}\"\n      -p \"{{ satellite_password }}\"\n      product set-sync-plan\n      --name \"{{ item.product }}\"\n      --sync-plan \"{{ satellite_sync_plan }}\"\n      --organization \"{{ satellite_organization }}\"\n  with_items: \n  - \"{{ satellite_repositories }}\"\n\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "38f20d9974bcc1e794ab1c6599dd70f786c8a5b8", "filename": "roles/deploy/tasks/build.yml", "repository": "roots/trellis", "decoded_content": "---\n- include: \"{{ deploy_build_before | default('../hooks/example.yml') }}\"\n  tags: deploy-build-before\n\n- name: Copy project templates\n  template:\n    src: \"{{ item.src }}\"\n    dest: \"{{ deploy_helper.new_release_path }}/{{ item.dest }}\"\n    mode: \"{{ item.mode | default('0644') }}\"\n  with_items: \"{{ project_templates }}\"\n\n- name: Check if project folders exist\n  stat:\n    path: \"{{ deploy_helper.current_path }}/{{ item }}\"\n  register: project_folder_paths\n  with_items: \"{{ project_copy_folders }}\"\n\n- name: Copy project folders\n  command: cp -rp {{ deploy_helper.current_path }}/{{ item.item }} {{ deploy_helper.new_release_path }}\n  with_items: \"{{ project_folder_paths.results }}\"\n  when: item.stat.exists\n\n- include: \"{{ deploy_build_after | default('../hooks/example.yml') }}\"\n  tags: deploy-build-after\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "79dd479cc73104c67611a2f0f66fc0ad696d5a78", "filename": "roles/postgresql/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "postgresql_locale: \"en_US.UTF-8\"\n"}, {"commit_sha": "8c72df4ecfaa4188202ab0872f4500384ffe5233", "sha": "77a14db76bc242d19bc5f5be6b5b7cc7c293b776", "filename": "tasks/setup-repository.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Ensure python and deps for Ansible modules\n  become: true\n  raw: dnf install -y python2 python2-dnf libselinux-python\n  changed_when: false\n  when: _docker_os_dist == \"Fedora\"\n\n- name: Update APT cache\n  become: true\n  apt:\n    update_cache: yes\n  changed_when: false\n  when: _docker_os_dist == \"Ubuntu\" or\n        _docker_os_dist == \"Debian\"\n\n- name: Ensure packages are installed for repository setup\n  become: true\n  package:\n    name: \"{{ item }}\"\n    state: present\n  with_items:\n    - \"{{ docker_repository_related_packages[_docker_os_dist] }}\"\n  when: _docker_os_dist == \"Ubuntu\" or\n        _docker_os_dist == \"Debian\" or\n        _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Add Docker official GPG key\n  become: true\n  apt_key:\n    url: https://download.docker.com/linux/{{ _docker_os_dist|lower }}/gpg\n    state: present\n  when: (_docker_os_dist == \"Ubuntu\" and _docker_os_dist_major_version > '14') or\n        (_docker_os_dist == \"Debian\" and _docker_os_dist_major_version > '7')\n\n- name: Add Docker APT key (alternative for older Ubuntu systems without SNI).\n  become: true\n  shell: \"curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\"\n  args:\n    warn: false\n  changed_when: false\n  when: (_docker_os_dist == \"Ubuntu\" and _docker_os_dist_major_version == '14') or (_docker_os_dist == \"Debian\" and _docker_os_dist_major_version == '7')\n\n- name: Determine channels to be enabled and/or disabled\n  set_fact:\n    _docker_disable_channels: \"{{ docker_channels | difference(_docker_merged_channels) }}\"\n    _docker_enable_channels: \"{{ docker_channels | intersect(_docker_merged_channels) }}\"\n  vars:\n    _docker_mandatory_channel: [ 'stable' ]\n    _docker_merged_channels: \"{{ _docker_mandatory_channel }} + [ '{{ docker_channel }}' ]\"\n\n- name: Add Docker CE repository with correct channels (Ubuntu/Debian)\n  become: true\n  apt_repository:\n    repo: deb [arch=amd64] https://download.docker.com/linux/{{ _docker_os_dist|lower }} {{ _docker_os_dist_release }} {{ _docker_enable_channels | join(\" \") }}\n    state: present\n    filename: 'docker-ce'\n  when: _docker_os_dist == \"Ubuntu\" or\n        _docker_os_dist == \"Debian\"\n\n# Backport is required but not documented by Docker: https://github.com/moby/moby/issues/16878\n- name: Add backport repository for Debian Wheezy\n  become: true\n  apt_repository:\n    repo: deb [arch=amd64] http://ftp.debian.org/debian wheezy-backports main\n    state: present\n    filename: 'debian-backport'\n  when: _docker_os_dist == \"Debian\" and _docker_os_dist_major_version == '7'\n\n- name: Add Docker CE repository (Fedora/CentOS/RedHat)\n  become: true\n  get_url:\n    url: \"{{ docker_repository_url[_docker_os_dist] }}\"\n    dest: /etc/yum.repos.d/docker-ce.repo\n    mode: 0644\n  register: _docker_repo\n  when: _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"Fedora\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Disable Docker CE repository channels (Fedora/CentOS/RedHat)\n  become: true\n  shell: \"{{ docker_cmd_enable_disable_edge_repo[_docker_os_dist] }}\"\n  with_items: \"{{ _docker_disable_channels }}\"\n  changed_when: false\n  vars:\n    _item_enabled: false\n  when: _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"Fedora\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Enable Docker CE repository channels (Fedora/CentOS/RedHat)\n  become: true\n  shell: \"{{ docker_cmd_enable_disable_edge_repo[_docker_os_dist] }}\"\n  with_items: \"{{ _docker_enable_channels }}\"\n  changed_when: false\n  vars:\n    _item_enabled: true\n  when: _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"Fedora\" or\n        _docker_os_dist == \"RedHat\"\n\n# disable rt-beta so we don't get a 403 error retrieving repomd.xml\n- name: Check if rhel-7-server-rt-beta-rpms Repository is enabled (RedHat)\n  become: true\n  shell: \"subscription-manager repos --list-enabled | grep rhel-7-server-rt-beta-rpms\"\n  register: cmd_rhel_rt_beta_repo_enabled\n  when: _docker_os_dist == \"RedHat\"\n  changed_when: false\n  failed_when: cmd_rhel_rt_beta_repo_enabled.rc not in [ 0, 1 ]\n\n- name: Disable rhel-7-server-rt-beta-rpms Repository (RedHat)\n  become: true\n  shell: \"subscription-manager repos --disable=rhel-7-server-rt-beta-rpms\"\n  when: _docker_os_dist == \"RedHat\" and cmd_rhel_rt_beta_repo_enabled.rc == 0\n\n# container-selinux package wants this\n- name: Check if rhel-7-server-extras-rpms Repository is enabled (RedHat)\n  become: true\n  shell: \"subscription-manager repos --list-enabled | grep rhel-7-server-extras-rpms\"\n  register: cmd_rhel_extras_repo_enabled\n  when: _docker_os_dist == \"RedHat\"\n  changed_when: false\n  failed_when: cmd_rhel_extras_repo_enabled.rc not in [ 0, 1 ]\n\n- name: Enable rhel-7-server-extras-rpms Repository (RedHat)\n  become: true\n  shell: \"subscription-manager repos --enable=rhel-7-server-extras-rpms\"\n  when: _docker_os_dist == \"RedHat\" and cmd_rhel_extras_repo_enabled.rc == 1\n\n- name: Update repository cache\n  become: true\n  shell: \"{{ docker_cmd_update_repo_cache[_docker_os_dist] }}\"\n  args:\n    warn: false\n  changed_when: false"}, {"commit_sha": "1224adf2811c827a09ff0bf133fbb476901a547d", "sha": "ad567fdf2538c521ac0bdb3be64333d4a0841ec2", "filename": "tasks/configure.yml", "repository": "nusenu/ansible-relayor", "decoded_content": "---\n\n- name: Ensure local DataDir folders exist (LOCAL)\n  file:\n    path: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    state: directory\n    mode: 0700\n  delegate_to: 127.0.0.1\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - createdir\n\n- name: Ensure all relay keys exist (LOCAL)\n  local_action: command tor --PublishServerDescriptor 0 --orport auto --list-fingerprint --datadirectory \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}\" --Log \"err stdout\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Generate new Ed25519 signing keys (LOCAL)\n  local_action: command tor --keygen --SigningKeyLifetime {{ tor_signingkeylifetime_days}}\\ days --datadirectory \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}\" --Log \"err stdout\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - renewkey\n\n- name: Detect duplicate relay keys across relays (LOCAL)\n  shell: openssl sha256 -r {{ tor_offline_masterkey_dir }}/*/keys/secret_id_key {{ tor_offline_masterkey_dir }}/*/keys/ed25519_master_id_secret_key|cut -d' ' -f1|sort|uniq -d|wc -l\n  delegate_to: 127.0.0.1\n  run_once: true\n  register: dupcount\n\n- name: Abort on duplicate relay keys\n  fail: msg=\"Duplicate relay key detected! Aborting.\"\n  run_once: true\n  when: dupcount.stdout|int(1) != 0\n\n- name: Detect if Ed25519 master keys are on the relay\n  stat:\n    path: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/ed25519_master_id_secret_key\"\n  become: yes\n  register: masterkeycheck\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Abort if Ed25519 master keys are on the relay\n  fail: msg=\"\n\n            Ed25519 MASTER KEY detected on the relay - it is NOT supposed to be there! Aborting.\"\n  when: item.stat.exists == True\n  with_items: \"{{ masterkeycheck.results }}\"\n\n- name: Collect fingerprints for MyFamily (LOCAL)\n  shell: cut  -d\" \" -f2 {{ tor_offline_masterkey_dir }}/*/fingerprint|sort|xargs|sed -e 's/ /,/g'\n  delegate_to: 127.0.0.1\n  run_once: true\n  register: family\n  tags:\n   - reconfigure\n\n- name: Ensure per-instance tor users exist\n  become: yes\n  user:\n    name: _tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\n    system: yes\n    shell: /bin/false\n    createhome: no\n    home: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure per-instance config folders exist (Debian only)\n  become: yes\n  file:\n    path: \"{{ tor_ConfDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    state: directory\n    mode: 0755\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  when: ansible_pkg_mgr == 'apt'\n\n- name: Ensure DataDir exists\n  become: yes\n  file:\n    path: \"{{ tor_DataDir }}\"\n    state: directory\n    owner: root\n    mode: 0755\n\n- name: Ensure \"keys\" subfolder exists\n  become: yes\n  file:\n    path: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys\"\n    state: directory\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    group: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0700\n    recurse: yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure RSA key is in place (without overriding existing keys)\n  become: yes\n  copy:\n    src: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    dest: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0700\n    force: no\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'secret_id_key' ]\n\n- name: Fetch RSA key for comparision\n  become: yes\n  fetch:\n    src: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    dest: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}.untrustedremotekey\"\n    flat: yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'secret_id_key' ]\n\n- name: Compare local vs. remote RSA key (secret_id_key)\n  local_action: shell openssl sha256 -r {{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-\"{{ item.0.ipv4 }}_{{ item.1.orport }}\"/keys/secret_id_key*|cut -d' ' -f1|uniq -d|wc -l\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  register: rsakey\n\n- name: Abort if local and remote RSA keys do not match\n  assert:\n    that:\n      - \"item.stdout|int == 1\"\n    msg: \"Key mismatch detected! Solution: http://bit.ly/2j6wc70 Affected instance: {{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.item.0.ipv4 }}_{{ item.item.1.orport }}/keys\"\n  with_items: \"{{ rsakey.results }}\"\n\n# this task is separated from the task named \"Ensure RSA key is in place\" because it is not run with 'force=no'\n- name: Transmit new Ed25519 signing keys\n  become: yes\n  copy:\n    src: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    dest: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0700\n    setype: tor_var_lib_t\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'ed25519_signing_cert', 'ed25519_signing_secret_key' ]\n  tags:\n   - renewkey\n\n# This needs to be at the end to fix SELinux contexts recursively\n- name: Ensure per-instance DataDir have proper permissions\n  become: yes\n  file:\n    path: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    state: directory\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    group: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0700\n    recurse: yes\n    setype: tor_var_lib_t\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure Tor config directory exists\n  become: yes\n  file:\n    path: \"{{ tor_ConfDir }}\"\n    state: directory\n    owner: root\n    group: \"{{ tor_user }}\"\n    mode: 0755\n\n- name: Ensure tor-exit-notice.html is present (if we are an exit)\n  become: yes\n  template:\n    src: tor-exit-notice.html\n    dest: \"{{ tor_ConfDir }}/tor-exit-notice.html\"\n    mode: 0444\n  when: tor_ExitRelay == True and tor_ExitNoticePage == True\n\n- name: Generating torrc file(s)\n  become: yes\n  template:\n    src: torrc\n    dest: \"{{ (ansible_pkg_mgr != 'apt')| ternary(tor_ConfDir ~ '/' ~ item.0.ipv4 ~ '_' ~ item.1.orport ~ '.torrc', tor_ConfDir ~ '/' ~ item.0.ipv4 ~ '_' ~ item.1.orport ~ '/torrc') }}\"\n    owner: root\n    mode: 0644\n    backup: yes\n    validate: \"tor --verify-config -f %s\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  register: instances\n  notify:\n    - Ensure Tor instances are reloaded if its torrc changed (FreeBSD)\n    - Ensure Tor instances are reloaded if its torrc changed (Linux)\n  tags:\n   - reconfigure\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "4f1e2add53cda39820110a8b854b3ffbe134e586", "filename": "roles/common/handlers/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: restart memcached\n  service:\n    name: memcached\n    state: restarted\n\n- name: reload php-fpm\n  service:\n    name: php7.0-fpm\n    state: reloaded\n\n- name: reload nginx\n  include: reload_nginx.yml\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "746d161c738281b3698bc43a9f728862dbad8aca", "filename": "roles/config-ipa-client/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nmove_local_user_home: False\nnew_local_home_dir: \"/lclhome\"\ntemporary_username: \"lcluser\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "429e53fd5f6a919a354dc5a60b87edb2bdfeaaf9", "filename": "roles/scm/gitlab.com/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- hosts: localhost\n  remote_user: root\n  tasks:\n    - include_role:\n        name: \"{{ playbook_dir }}/../../gitlab.com\""}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "7a81c01718a09b873d5515993f85a7f9b09e443d", "filename": "roles/config-quay-enterprise/tasks/configure_systemd.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Configure systemd environment files\n  template:\n    src: \"quay.j2\"\n    dest: \"{{ systemd_environmentfile_dir}}/{{ quay_name }}\"\n  notify: \"Restart quay service\"\n\n- name: Configure systemd unit files\n  template:\n    src: \"quay.service.j2\"\n    dest: \"{{ systemd_service_dir}}/{{ quay_service }}\"\n  notify: \"Restart quay service\"\n"}, {"commit_sha": "35c4af9fd84d7a7e6bc093adc944b352e68d6ff1", "sha": "1b8fbe88430435dd9ce0ba47202fc2118e108584", "filename": "tasks/main-CentOS.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n# tasks file for ansible-role-docker-ce\n\n- name: Ensure yum-utils is installed\n  package:\n    name: yum-utils\n    state: present\n  become: true\n\n- name: Add Docker CE repository\n  get_url:\n    url: https://download.docker.com/linux/centos/docker-ce.repo\n    dest: /etc/yum.repos.d/docker-ce.repo\n    mode: 0644\n  become: true\n  register: yum_repo\n\n- name: Determine Docker CE Edge repo status\n  shell: yum-config-manager docker-ce-edge | grep enabled\n  ignore_errors: yes\n  changed_when: false\n  register: cmd_docker_ce_edge_enabled\n\n- name: Set current Docker CE Edge repo status fact\n  set_fact:\n    fact_docker_ce_edge_enabled: \"{{ cmd_docker_ce_edge_enabled.stdout == 'enabled = True' }}\"\n\n- name: Enable/Disable Docker CE Edge Repository\n  shell: yum-config-manager --{{ (docker_enable_ce_edge == true) | ternary('enable','disable') }} docker-ce-edge\n  become: true\n  when: fact_docker_ce_edge_enabled != docker_enable_ce_edge\n\n- name: Update yum cache\n  shell: yum makecache fast\n  args:\n    warn: false  \n  become: true\n  when: yum_repo.changed\n\n- name: Ensure fs.may_detach_mounts is set to avoid 'Device or resource busy'\n  sysctl:\n    name: fs.may_detach_mounts\n    value: 1\n    sysctl_file: /etc/sysctl.d/99-docker.conf\n    reload: yes\n  become: true\n  when: ansible_kernel | version_compare('4', '<')\n\n- include: main-Mountflags.yml\n  when: ansible_kernel | version_compare('4', '<')\n\n- include: main-Generic.yml\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "ceb04da08845c65296fe8935c31278b498d83688", "filename": "playbooks/templates/es-jvm.options.j2", "repository": "rocknsm/rock", "decoded_content": "## JVM configuration\n################################################################\n## IMPORTANT: JVM heap size\n################################################################\n##\n## You should always set the min and max JVM heap\n## size to the same value. For example, to set\n## the heap to 4 GB, set:\n##\n## -Xms4g\n## -Xmx4g\n##\n## See https://www.elastic.co/guide/en/elasticsearch/reference/current/heap-size.html\n## for more information\n##\n################################################################\n\n# Xms represents the initial size of total heap space\n# Xmx represents the maximum size of total heap space\n\n-Xms{{ es_mem }}g\n-Xmx{{ es_mem }}g\n\n################################################################\n## Expert settings\n################################################################\n##\n## All settings below this section are considered\n## expert settings. Don't tamper with them unless\n## you understand what you are doing\n##\n################################################################\n\n## GC configuration\n-XX:+UseConcMarkSweepGC\n-XX:CMSInitiatingOccupancyFraction=75\n-XX:+UseCMSInitiatingOccupancyOnly\n\n## optimizations\n\n# disable calls to System#gc\n-XX:+DisableExplicitGC\n\n# pre-touch memory pages used by the JVM during initialization\n-XX:+AlwaysPreTouch\n\n## basic\n\n# force the server VM\n-server\n\n# set to headless, just in case\n-Djava.awt.headless=true\n\n# ensure UTF-8 encoding by default (e.g. filenames)\n-Dfile.encoding=UTF-8\n\n# use our provided JNA always versus the system one\n-Djna.nosys=true\n\n# flags to keep Netty from being unsafe\n-Dio.netty.noUnsafe=true\n-Dio.netty.noKeySetOptimization=true\n\n# log4j 2\n-Dlog4j.shutdownHookEnabled=false\n-Dlog4j2.disable.jmx=true\n-Dlog4j.skipJansi=true\n\n## heap dumps\n\n# generate a heap dump when an allocation from the Java heap fails\n# heap dumps are created in the working directory of the JVM\n-XX:+HeapDumpOnOutOfMemoryError\n\n# specify an alternative path for heap dumps\n# ensure the directory exists and has sufficient space\n#-XX:HeapDumpPath=${heap.dump.path}\n\n## GC logging\n\n#-XX:+PrintGCDetails\n#-XX:+PrintGCTimeStamps\n#-XX:+PrintGCDateStamps\n#-XX:+PrintClassHistogram\n#-XX:+PrintTenuringDistribution\n#-XX:+PrintGCApplicationStoppedTime\n\n# log GC status to a file with time stamps\n# ensure the directory exists\n#-Xloggc:${loggc}\n\n# Elasticsearch 5.0.0 will throw an exception on unquoted field names in JSON.\n# If documents were already indexed with unquoted fields in a previous version\n# of Elasticsearch, some operations may throw errors.\n#\n# WARNING: This option will be removed in Elasticsearch 6.0.0 and is provided\n# only for migration purposes.\n#-Delasticsearch.json.allow_unquoted_field_names=true\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "a617a9ba53b15e72dc47992bdc9250fee2a58bb2", "filename": "playbooks/rhsm.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# If you want to use username/password for subscription, please ensure \n# to run the \"prep.yml\" playbook before running this playbook \n# - alternatively use the \"subscribe-host.yml\" playbook instead\n\n- hosts: rhsm_hosts\n  vars:\n    rhsm_username: \"{{ hostvars['localhost'].rhsm_username | default(omit) }}\"\n    rhsm_password: \"{{ hostvars['localhost'].rhsm_password | default(omit) }}\"\n  roles: \n  - role: rhsm\n    no_log: True\n  tags:\n  - configure_rhsm\n\n\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "190ad4bd73e4588b8e2ef18c3a75fb62e73a2d86", "filename": "tasks/install-docker.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Set version string\n  set_fact:\n    _docker_version_string: \"{{ docker_os_pkg_version_separator[_docker_os_dist] }}{{ docker_version }}\"\n  when: docker_version != ''\n\n- name: Set packages state to latest\n  set_fact:\n    _docker_pkg_state: 'latest'\n  when: docker_latest_version | bool and docker_version == ''\n\n- name: Filter out packages to match older Docker CE versions\n  set_fact:\n    _docker_packages:\n      - docker-ce\n  when:\n    - docker_version != ''\n    - docker_version is match('17.') or docker_version is match('18.03') or docker_version is match('18.06')\n\n- name: Ensure some kind of compatibility for no longer officially supported distributions since Docker CE 18.09\n  set_fact:\n    _docker_packages:\n      - docker-ce\n  when:\n    - _docker_packages is not defined\n    - (_docker_os_dist == \"Debian\" and _docker_os_dist_major_version < '9') or\n      (_docker_os_dist == \"Fedora\" and _docker_os_dist_major_version < '27') or\n      (_docker_os_dist == \"Ubuntu\" and _docker_os_dist_major_version < '16')\n\n- name: Ensure Docker CE is installed\n  become: true\n  package:\n    name: \"{{ (item is search('docker')) | ternary((item + _docker_version_string | default('')), item) }}\"\n    state: \"{{ _docker_pkg_state | default('present') }}\"\n  with_items: \"{{ _docker_packages | default(docker_packages) }}\"\n  register: _pkg_result\n  until: _pkg_result is succeeded\n  notify: restart docker\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "47eb9823c1366ded4d02ab7c1249a092de66efba", "filename": "roles/php/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Add PHP 7.0 PPA\n  apt_repository:\n    repo: \"ppa:ondrej/php\"\n    update_cache: yes\n\n- name: Install PHP 7.0\n  apt:\n    name: \"{{ item }}\"\n    state: present\n    force: yes\n  with_items:\n  - php7.0-cli\n  - php7.0-common\n  - php7.0-curl\n  - php7.0-dev\n  - php7.0-fpm\n  - php7.0-gd\n  - php7.0-mbstring\n  - php7.0-mcrypt\n  - php7.0-mysql\n  - php7.0-opcache\n  - php7.0-xml\n  - php7.0-xmlrpc\n  - php7.0-zip\n\n- name: Install Xdebug\n  apt:\n    name: php-xdebug\n    state: latest\n  when: xdebug_install | default(false)\n\n- name: xdebug configuration file\n  template:\n    src: xdebug.ini.j2\n    dest: /etc/php/7.0/mods-available/xdebug.ini\n  when: xdebug_install | default(false)\n\n- name: Start php7.0-fpm service\n  service:\n    name: php7.0-fpm\n    state: started\n    enabled: true\n\n- name: Create socket directory\n  file:\n    path: /var/run/php7.0-fpm/\n    state: directory\n\n- name: Disable default pool\n  command: mv /etc/php/7.0/fpm/pool.d/www.conf /etc/php/7.0/fpm/pool.d/www.disabled\n  args:\n    creates: /etc/php/7.0/fpm/pool.d/www.disabled\n  when: disable_default_pool\n  notify: reload php-fpm\n\n- name: PHP configuration file\n  template:\n    src: php.ini.j2\n    dest: /etc/php/7.0/fpm/php.ini\n  notify: reload php-fpm\n\n- name: php-fpm configuration file\n  template:\n    src: php-fpm.conf.j2\n    dest: /etc/php/7.0/fpm/pool.d/wordpress.conf\n  notify: reload php-fpm\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "8cf0579f668dd87064a34c267113f22fead3c565", "filename": "playbooks/freebsd.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- name: FreeBSD / HardenedBSD | Install prerequisites\n  raw: sleep 10 && env ASSUME_ALWAYS_YES=YES sudo pkg install -y python27\n\n- name: FreeBSD / HardenedBSD | Configure defaults\n  raw: sudo ln -sf /usr/local/bin/python2.7 /usr/bin/python2.7\n\n- include: facts/FreeBSD.yml\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "5492bfd076b0b39fc31e34e540abeb480662a3f5", "filename": "roles/config-container-storage-setup/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- block:\n    - name: create the docker-storage config file\n      template:\n        src: docker-storage-setup-overlayfs.j2\n        dest: /etc/sysconfig/docker-storage-setup\n        owner: root\n        group: root\n        mode: 0644\n  when:\n    - ansible_distribution_version is version_compare('7.4', '>=')\n    - ansible_distribution == \"RedHat\"\n\n- block:\n    - name: create the docker-storage-setup config file\n      template:\n        src: docker-storage-setup-dm.j2\n        dest: /etc/sysconfig/docker-storage-setup\n        owner: root\n        group: root\n        mode: 0644\n  when:\n    - ansible_distribution_version is version_compare('7.4', '<')\n    - ansible_distribution == \"RedHat\"\n\n- block:\n    - name: create the docker-storage-setup config file for CentOS\n      template:\n        src: docker-storage-setup-dm.j2\n        dest: /etc/sysconfig/docker-storage-setup\n        owner: root\n        group: root\n        mode: 0644\n  when:\n    - ansible_distribution == \"CentOS\""}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "89be223181d3d4c9af7e0241875f6f5bec3fc18b", "filename": "roles/9-local-addons/README.rst", "repository": "iiab/iiab", "decoded_content": "===================\nLocal Addons README\n===================\n\nThis role is a place to aggregate roles developed by various contributors or locally developed.\n\nDevelopment\n-----------\n\nCreate the role you wish to add to the XSCE School Server by following the pattern of another role or any other means.\n\nPackaging\n---------\n\nAdd your role into the main.yml file in the meta directory of the 7-local-addons role.  It will now get installed as part of\nthe next ansible run.\n\nMore Info\n---------\n\nHave a look at the docs section of this git repo for more detailed information."}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "289fcc16bf1b660487a622c49fbd5840f675acf9", "filename": "tasks/create_repo_bower_proxy_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_bower_proxy\n    args: \"{{ _nexus_repos_bower_defaults|combine(item) }}\""}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "997be1e5821186115e1b58bfe21dc502e91ac7ff", "filename": "roles/config-pxe/tasks/pxe-target.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Generate the ip line - if applicable\"\n  set_fact:\n    ip_config: \"{{ target_entry.ip }}::{{ target_entry.gateway }}:{{ target_entry.netmask }}::{{ target_entry.interface }}:none\"\n  when: \n  - target_entry.ip is defined\n  - target_entry.ip|trim != ''\n\n- name: \"(re)set the pxe_entries\"\n  set_fact:\n    pxe_entries: \"{{ target_entry.pxe_entries }}\"\n\n- name: \"Generate the mac-address specific grub.cfg\"\n  set_fact:\n    target_file: \"{{ tftpserver_root_dir }}/pxelinux/grub.cfg-01-{{ target_entry.mac|regex_replace(':', '-')|lower }}\"\n\n- name: \"Populate the host specific grub.cfg (UEFI) file\"\n  template:\n    src: pxelinux_uefi.j2\n    dest: \"{{ target_file }}\"\n\n- name: \"Workaround for a RHEL 7.4 uEFI bug where it expects a '-' at the end of the filename\"\n  file:\n    src: \"{{ target_file|basename }}\"\n    dest: \"{{ target_file }}-\"\n    state: link \n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "8c8a99336f0e75a4924b8a127629f9d31b3201a7", "filename": "roles/common/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- name: Gather Facts\n  setup:\n  tags:\n    - always\n\n- include: ubuntu.yml\n  when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'\n\n- include: freebsd.yml\n  when: ansible_distribution == 'FreeBSD'\n\n- name: Install tools\n  package: name=\"{{ item }}\" state=present\n  with_items:\n    - \"{{ tools|default([]) }}\"\n  tags:\n    - always\n\n- name: Sysctl tuning\n  sysctl: name=\"{{ item.item }}\" value=\"{{ item.value }}\"\n  with_items:\n    - \"{{ sysctl|default([]) }}\"\n  tags:\n    - always\n\n- meta: flush_handlers\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "5d7a21613e9469e81e06d1e8bdce11a040d862ad", "filename": "roles/schooltool/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "schooltool_install: True\nschooltool_enabled: False\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "aa78e0db1d831b8111772fd7e387fa992a42cc2f", "filename": "roles/rollback/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- include: user-release.yml\n  when: release is defined\n\n- include: prior-release.yml\n  when: release is not defined\n\n- name: Check whether target release was from a successful deploy\n  stat:\n    path: \"{{ new_release_path }}/DEPLOY_UNFINISHED\"\n  register: target\n\n- name: Fail if target release was from failed deploy\n  fail:\n    msg: \"Cannot switch to release at {{ new_release_path }}. It is from an unfinished deploy. You may manually specify a different release using --extra-vars='release=12345678901234'.\"\n  when: target.stat.exists | default(False)\n\n- name: Link 'current' directory to target release\n  file:\n    path: \"{{ project_root }}/{{ project_current_path }}\"\n    src: \"{{ new_release_path }}\"\n    state: link\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "83818f18b1c5787efafd20520bb855a348188c01", "filename": "roles/config-routes/tasks/route.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Configure route for the specific interface\"\n  template:\n    src: route.j2 \n    dest: /etc/sysconfig/network-scripts/route-{{ route.device }}\n  with_items:\n  - '{{ routes }}'\n  loop_control:\n    loop_var: route\n  when:\n  - routes is defined\n  - routes.device is defined\n  - routes.device|trim != \"\"\n  notify: 'Notify about Network reload'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "c11ae1736e37e38c0a87b72ef9c9b24f7a0ef561", "filename": "roles/keepalived/tasks/keepalived-config.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Populate the keepalived.conf file'\n  template:\n    src: keepalived_conf.j2\n    dest: '/etc/keepalived/keepalived.conf'\n  notify: 'restart keepalived'\n\n  \n"}, {"commit_sha": "1d7d3a653c598355333e7c34a54a550ed3d79cc5", "sha": "21774dbc9acb14a02786031651c5c860dc922489", "filename": "tasks/upgrade.yml", "repository": "RocketChat/Rocket.Chat.Ansible", "decoded_content": "---\n# tasks/upgrade.yml: Rocket.Chat upgrade procedures for RocketChat.Ansible\n\n  - name: Ensure automatic upgrades are permitted [UPGRADE]\n    fail:\n      msg: >-\n        It doesn't look like you've permitted automatic upgrades.\n        A new version of Rocket.Chat was released.\n        To permit automatic upgrades set 'rocket_chat_automatic_upgrades' to true\n    when: not rocket_chat_automatic_upgrades|bool\n\n  - name: Ensure the back up directory exists [UPGRADE]\n    file:\n      path: \"{{ rocket_chat_upgrade_backup_path }}\"\n      state: directory\n    when: rocket_chat_upgrade_backup|bool\n\n  - name: Back up the current Rocket.Chat instance [UPGRADE]\n    shell: >-\n      mv {{ rocket_chat_application_path }}/bundle\n      {{ rocket_chat_upgrade_backup_path }}/backup_{{ ansible_date_time.date }}\n    when: rocket_chat_upgrade_backup|bool\n\n  - name: Delete the current Rocket.Chat instance [UPGRADE]\n    file:\n      path: \"{{ rocket_chat_application_path }}/bundle\"\n      state: absent\n    when: not rocket_chat_upgrade_backup|bool\n\n  - name: Set the Rocket.Chat upgrade status [UPGRADE]\n    set_fact:\n      rocket_chat_upgraded: true\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "d356a2617d99baa7635b2484c9d1224ddb07e40d", "filename": "tasks/Linux/fetch/adoptopenjdk-fallback.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Fetch download page\n  uri:\n    url: \"{{ adoptopenjdk_api_page }}\\\n      info/releases/\\\n      openjdk{{ java_major_version }}\\\n      ?openjdk_impl={{ adoptopenjdk_impl }}\\\n      &os=linux&arch=x64\\\n      &release=latest\\\n      &type={{ java_package }}&heap_size=normal\"\n    return_content: true\n    follow_redirects: all\n  register: download_page\n\n- name: 'Find release url'\n  set_fact:\n    release_url: >-\n      {{ (download_page.content | from_json).binaries | map(attribute='binary_link') | list +\n        (download_page.content | from_json).binaries | map(attribute='checksum_link') | list }}\n\n- name: Exit if AdoptOpenJDK version is not found\n  fail:\n    msg: 'AdoptOpenJDK version {{ java_major_version }} not found'\n  when: release_url[0] is not defined\n\n- name: 'Fetch artifact checksum file {{ release_url[1] }}'\n  uri:\n    url: '{{ release_url[1] }}'\n    return_content: true\n  register: artifact_checksum_file\n\n- name: 'Get artifact checksum from file {{ release_url[1] }}'\n  set_fact:\n    artifact_checksum: >-\n      {{ artifact_checksum_file['content'] |\n      regex_search('([^\\s]+)')\n      }}\n\n- name: 'Download artifact from {{ release_url[0] }}'\n  get_url:\n    url: '{{ release_url[0] }}'\n    dest: '{{ java_download_path }}'\n    checksum: 'sha256:{{ artifact_checksum }}'\n  register: file_downloaded\n  retries: 20\n  delay: 5\n  until: file_downloaded is succeeded\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "2207054a5e6a3b66608030ab479d3e869313d9c5", "filename": "roles/8-mgmt-tools/README.rst", "repository": "iiab/iiab", "decoded_content": "======================================\nAssessment and Monitoring Tools README\n======================================\n\nThis role is a place to aggregate roles that provide tools for Administering and\nMonitoring the Server and for Assessing its use and effectiveness.\n"}, {"commit_sha": "64cbc6946b7ebc0d9a36f40d77ac86f8e3564499", "sha": "1cfb3f5414e0757a502194a7e26b31f90b07a7e2", "filename": "tasks/main.yml", "repository": "CSCfi/ansible-role-slurm", "decoded_content": "---\n\n# tasks file for ansible-role-slurm\n# Order matters.\n#\n\n- name: Slurm OS dependent variables\n  include_vars: \"{{ item }}\"\n  with_first_found:\n    - \"{{ ansible_os_family }}_{{ ansible_distribution_major_version }}.yml\"\n    - \"{{ ansible_os_family }}.yml\"\n    - default.yml\n\n  # check which version of slurm is installed\n- include: version.yml\n  when: ansible_os_family == \"RedHat\"\n\n  # common.yml is applied to all nodes\n    # configure pam\n    # template in cgroup.conf, gres.conf and slurm.conf\n    # set up logrotate and rsyslog\n- include: common.yml\n  when: ansible_os_family == \"RedHat\"\n\n  # upgrade is used to compare slurm version installed and the one ansible wants to install\n    # pauses the play on the dbd host\n- include: upgrade.yml\n  when: (slurm_accounting_storage_host == ansible_hostname) and ansible_os_family == \"RedHat\"\n\n  # slurmdbd - only applied on the node which is the slurmdbd host (can be different or the same as the slurmctld)\n    # we want a slurmdbd up before slurmctld\n    # fail if you have not defined slurm_mysql_password\n    # fetche munge.key from files/munge.key in the directory where you run ansible\n    # create slurm sql database and users\n    # template in slurmdbd.conf\n     # If there is a change to slurmdbd.conf it will restart slurmdbd with a handler (end of play)\n- include: dbd.yml\n  when: (slurm_accounting_storage_host == ansible_hostname) and ansible_os_family == \"RedHat\"\n\n  # slurmctld:\n    # munge:\n      # Creates munge.key if /etc/munge/munge.key does not exist\n      # Stores munge.key in files/munge.key in the directory where you run ansible\n      # It can also store it to NFS\n    # ensure there's a slurm unix group and user and optionally update NIS maps\n    # create directories\n    # increase sysctl values\n    # start and enable slurmdbd wherever that runs (after we ensure there's a slurm user/group)\n    # sacctmgr create cluster\n- include: service.yml\n  when: \"'slurm_service' in group_names and ansible_os_family == 'RedHat'\"\n\n  # computes\n    # get munge.key from the directory where you run ansible or NFS\n    # create namespace epilog script\n- include: compute.yml\n  when: \"'slurm_compute' in group_names and ansible_os_family == 'RedHat'\"\n\n  # submit (not on compute or service nodes)\n    # get munge.key from the directory where you run ansible\n- include: submit.yml\n  when: \"(ansible_os_family == 'RedHat') and ('slurm_compute' not in group_names) and ('slurm_service' not in group_names)\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "050a460ff737bd7af54c7325e55a935a5e3d2480", "filename": "roles/config-vnc-server/tasks/prereq.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Determine required python firewall package'\n  set_fact:\n    python_firewall_package: \"python3-firewall\"\n  when:\n  - ansible_python_version is match(\"3.*\")\n\n- name: 'Install required packages'\n  package:\n    name: '{{ item }}'\n    state: installed\n  with_items:\n  - firewalld\n  - \"{{ python_firewall_package | default('python-firewall') }}\"\n\n- name: 'Ensure firewalld is running'\n  service:\n    name: firewalld\n    state: started\n    enabled: yes\n\n- name: 'Open Firewall for NFS use'\n  firewalld:\n    port: \"{{ item }}\"\n    permanent: yes\n    state: enabled\n    immediate: yes\n  with_items:\n  - 5900/tcp\n  - 5901/tcp\n  - 5902/tcp\n  - 5903/tcp\n  - 5904/tcp\n  - 5905/tcp\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "aee2e66cd13eb2eb0b7feb13593a5f5a642cc6cb", "filename": "playbooks/roles/bb0-openstack/tasks/validate-parameters.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "\n- name: Validate STC_FLAVOR\n  assert:\n    that: \n      - lookup('env','STC_FLAVOR') == 'mini'\n    msg: \"STC_FLAVOR should be 'mini'\"    \n\n- name: Validate env variables\n  assert:\n    that: \n      - lookup('env', item ) is defined\n    msg: \"Env variable {{ item }} is NOT defined!\"\n  with_items:\n    - OS_USERNAME\n    - OS_PASSWORD\n    - OS_AUTH_URL\n    - OS_PROJECT_NAME\n    - OS_USER_DOMAIN_NAME\n    - OS_PROJECT_DOMAIN_NAME\n    - OS_IDENTITY_API_VERSION\n    - STC_RHN_PASSWORD\n    - STC_RHN_USERNAME\n    - STC_SUBSCRIPTION_POOL_ID\n\n- name: Check connection to openstack api \n  command: \"curl -s -o /dev/null --connect-timeout 3 {{ lookup('env', 'OS_AUTH_URL' ) }}\"\n  args:\n    warn: false # set warn=false to prevent warning\n\n\n# - name: Validate masters\n#   assert:\n#     that:\n#       - (master_count == 1) or (master_count == 3)\n#     msg: \"Master count is currently {{ master_count }} but must be 1 or 3\"\n\n# - name: Validate infras\n#   assert:\n#     that:\n#       - (infra_count >= 1 ) \n#       - (infra_count <= 3)\n#     msg: \"Infra count s currently {{ infra_count }} but must be between 1 and 3\"\n\n# - name: Validate nodes\n#   assert:\n#     that:\n#       - (node_count >= 1 ) \n#     msg: \"Node count {{ node_count }} must be >= 1\"\n\n# - name: Validate OpenShift HA\n#   assert:\n#     that:\n#       - (master_count == 3) and (infra_count > 1)\n#     msg: \"OpenShift HA requires 3 masters and at least 2 infra nodes\"\n#   when: openshift_ha\n\n#- name: Validate Registry HA\n#  assert:\n#    that:\n#      - (registry_replicas > 1 )\n#    msg: \"OpenShift HA requires at least 2 registry replicas\"\n#  when: openshift_ha\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "03df57f501078fb40914fe75063b9f0e670ebe9e", "filename": "roles/6-generic-apps/README.rst", "repository": "iiab/iiab", "decoded_content": "===================\nGeneric Apps README\n===================\n\nThis role is a place to aggregate roles that install apps of a more generic nature, as opposed to educational or managment.\nContent Management Systems or Chat or Wiki applications would go here.\n\n"}, {"commit_sha": "2f1ed84fec270723a1031cdc2b07b7a76a5a3bda", "sha": "218331b83a5d843d4d5e02c5b93fc131d79171c8", "filename": "meta/main.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "galaxy_info:\n  author: Bjorn Oscarsson\n  description: \"Installs and configures Docker Community Edition (CE)\"\n  min_ansible_version: 2.1\n  license: MIT\n  platforms:\n  - name: Fedora\n    versions:\n      - 24\n      - 25\n  - name: EL\n    versions:\n      - 7\n\n  galaxy_tags:\n    - docker\n    - docker-ce\n\ndependencies: []\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "7e2381aa307a5aa85b3398f909afcb1e2b9e6f83", "filename": "playbooks/files/pulledpork-disablesid.conf", "repository": "rocknsm/rock", "decoded_content": "# example disablesid.conf V3.1\n\n# Example of modifying state for individual rules\n# 1:1034,1:9837,1:1270,1:3390,1:710,1:1249,3:13010\n\n# Example of modifying state for rule ranges\n# 1:220-1:3264,3:13010-3:13013\n\n# Comments are allowed in this file, and can also be on the same line\n# As the modify state syntax, as long as it is a trailing comment\n# 1:1011 # I Disabled this rule because I could!\n\n# Example of modifying state for MS and cve rules, note the use of the : \n# in cve. This will modify MS09-008, cve 2009-0233, bugtraq 21301,\n# and all MS00 and all cve 2000 related sids!  These support regular expression\n# matching only after you have specified what you are looking for, i.e. \n# MS00-<regex> or cve:<regex>, the first section CANNOT contain a regular\n# expression (MS\\d{2}-\\d+) will NOT work, use the pcre: keyword (below)\n# for this.\n# MS09-008,cve:2009-0233,bugtraq:21301,MS00-\\d+,cve:2000-\\d+\n\n# Example of using the pcre: keyword to modify rulestate.  the pcre keyword \n# allows for full use of regular expression syntax, you do not need to designate\n# with / and all pcre searches are treated as case insensitive. For more information \n# about regular expression syntax: http://www.regular-expressions.info/\n# The following example modifies state for all MS07 through MS10 \n# pcre:MS(0[7-9]|10)-\\d+\n\n# Example of modifying state for specific categories entirely (see README.CATEGORIES)\n# VRT-web-iis,ET-shellcode,ET-emergingthreats-smtp,Custom-shellcode,Custom-emergingthreats-smtp\n\n# Any of the above values can be on a single line or multiple lines, when \n# on a single line they simply need to be separated by a ,\n# 1:9837,1:220-1:3264,3:13010-3:13013,pcre:MS(0[0-7])-\\d+,MS09-008,cve:2009-0233\n\n# The modifications in this file are for sample/example purposes only and\n# should not actively be used, you need to modify this file to fit your \n# environment.\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "6e70affbe10459a64f1cc4704a1decef16de848d", "filename": "tasks/opensource/setup-redhat.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: CentOS/RedHat) Add NGINX Repository\"\n  yum_repository:\n    name: nginx\n    baseurl: \"{{ nginx_repository.redhat }}\"\n    description: NGINX Repository\n    enabled: yes\n    gpgcheck: yes\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "b3d05785c924b490e75f58a40e8f4b6cb1e2574d", "filename": "roles/osp/admin-nova-flavor/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Create the flavor\"\n  os_nova_flavor:\n    cloud: \"{{ item.cloud | default(osp_default_cloud) | default(omit) }}\"\n    vcpus: \"{{ item.vcpus }}\"\n    ram: \"{{ item.ram }}\"\n    disk: \"{{ item.disk }}\"\n    name: \"{{ item.name }}\"\n  with_items:\n  - \"{{ osp_custom_flavors | default([]) }}\"\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "9dda3e33d5d8df8837e8fac94b71036c17a9b882", "filename": "roles/wordpress-setup/tasks/self-signed-certificate.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Generate self-signed certificates\n  shell: >\n    openssl req -subj \"/CN={{ item.value.site_hosts | first }}\" -new\n    -newkey rsa:2048 -days 3650 -nodes -x509 -sha256\n    -keyout {{ item.key }}.key -out {{ item.key }}.cert\n  args:\n    chdir: \"{{ nginx_path }}/ssl\"\n    creates: \"{{ item.key }}.*\"\n  with_dict: \"{{ wordpress_sites }}\"\n  when: item.value.ssl.enabled and item.value.ssl.provider | default('manual') == 'self-signed'\n  notify:\n    - reload nginx\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "882db5a286cc2b403a95b046824a36b8def4310e", "filename": "examples/playbooks/backup_engine.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\n# Example playbook for backup of engine\n# use with backup_engine.inv\n- hosts: engine\n  remote_user: root\n  roles:\n    - {role: ovirt-engine-backup}\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "c7cf4e1078d9ed912441d563bb36e1dca8e31f2c", "filename": "roles/config-nagios-target/tasks/nrpe_docker.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Ensure docker group exists\n  group: \n    name: docker\n    state: present\n  notify: \n  - restart docker\n\n- name: Ensure the nrpe user belongs to the docker group\n  user: \n    name: nrpe\n    groups: docker\n    append: yes\n\n- name: Copy in additional Nagios Docker plugin\n  copy: \n    src: plugins/check_docker_storage\n    dest: /usr/lib64/nagios/plugins/check_docker_storage\n    owner: root\n    group: root\n    mode: 0755\n\n- name: Copy nrpe.d Docker configuration files\n  copy: \n    src: nrpe.d/check_docker.cfg\n    dest: /etc/nrpe.d/check_docker.cfg\n    owner: root\n    group: root\n    mode: 0644\n\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "dbbb3f7a5e57e63d583d9fa84786a5a9adec6bf0", "filename": "roles/ovirt-engine-remote-db/defaults/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\novirt_engine_remote_db_port: 5432\novirt_engine_remote_db_listen_address: '*'\novirt_engine_db_name: 'engine'\novirt_engine_db_user: 'engine'\n\novirt_engine_remote_db: False\novirt_engine_dwh_remote_db: False\n\novirt_engine_dwh_db_name: 'ovirt_engine_history'\novirt_engine_dwh_db_user: 'ovirt_engine_history'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "0f56d324b4b47b708a2e10c2eb71e88d89198a3e", "filename": "roles/config-nagios-target/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: restart docker\n  service:\n    name: docker\n    state: restarted\n\n- name: reload docker\n  service:\n    name: docker\n    state: reloaded\n\n- name: restart firewalld\n  service:\n    name: firewalld\n    state: restarted\n\n- name: reload firewalld\n  service:\n    name: firewalld\n    state: reloaded\n\n- name: restart iptables\n  service:\n    name: iptables\n    state: restarted\n\n- name: reload iptables\n  service:\n    name: iptables\n    state: reloaded\n\n- name: restart nrpe\n  service:\n    name: nrpe\n    state: restarted\n\n- name: reload nrpe\n  service:\n    name: nrpe\n    state: reloaded\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a68de661ab1970b6ead613deb377aa83e8dfedf0", "filename": "roles/ansible/tower/config-ansible-tower/tests/inventory/group_vars/tower.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nansible_connection: local\n\n# NOTE: below is an example on how these params and files can be specified\n#       - please replace with valid values and files\n\nansible_tower:\n  admin_password: \"admin01\"\n  install:\n    license_file: \"{{ inventory_dir }}/../files/tower-license.json\"\n    ssl_certificate:\n      cert: \"{{ inventory_dir }}/../certs/tower.cert\"\n      key: \"{{ inventory_dir }}/../certs/tower.key\"\n    pg:\n      password: \"pg_password01\"\n    rabbitmq:\n      password: \"rabbitmq_password01\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "c09e865ab7e68599857881cd6323b3f32f27ba82", "filename": "roles/openvpn/templates/announce", "repository": "iiab/iiab", "decoded_content": "#!/bin/bash\n# disconnect our worker from everything\nDIR=$(dirname $0)\nnohup $DIR/announcer 0<&- &>/dev/null & \n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "65e45dec6899495b5ddf9169ad42134ac52f30e9", "filename": "roles/load-balancers/manage-haproxy/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- include_tasks: 'install.yml'\n- include_tasks: 'generate-config.yml'\n- include_tasks: 'activate-config.yml'\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "caf19d4aa64216274aeeb0ca771859822eba2ebf", "filename": "playbooks/files/logstash-kafka-fsf.conf", "repository": "rocknsm/rock", "decoded_content": "\ninput {\n  kafka {\n    topics => [\"fsf-raw\"]\n    add_field => { \"[@metadata][stage]\" => \"fsfraw_kafka\" }\n    # Set this to one per kafka partition to scale up\n    #consumer_threads => 4\n    group_id => \"fsf_logstash\"\n    bootstrap_servers => \"127.0.0.1:9092\"\n    codec => json\n    auto_offset_reset => \"earliest\"\n  }\n}\n\nfilter {\n  if \"_jsonparsefailure\" in [tags] {\n    drop { }\n  }\n\n  # Remove kafka_topic field\n  mutate {\n    remove_field => [ \"kafka_topic\" ]\n  }\n\n  if [@metadata][stage] == \"fsfraw_kafka\" {\n\n    # Set the timestamp\n    date { match => [ \"Scan Time\", \"ISO8601\" ] }\n    }\n}\n\noutput {\n  if [@metadata][stage] == \"fsfraw_kafka\" {\n    kafka {\n     codec => json\n     topic_id => \"fsf-clean\"\n     bootstrap_servers => \"127.0.0.1:9092\"\n    }\n\n    elasticsearch {\n      hosts => [\"127.0.0.1\"]\n      index => \"fsf-%{+YYYY.MM.dd}\"\n      manage_template => false\n      document_type => \"fsf\"\n    }\n  }\n}\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "7f105f38bab469a9c22b89f64750b5ba11954a63", "filename": "roles/scm/github.com/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- hosts: localhost\n  remote_user: root\n  tasks:\n    - include_role:\n        name: \"{{ playbook_dir }}/../../github.com\""}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "e075b0d8705005b68713f41ac2c58c100d5cd70b", "filename": "tasks/create_repo_bower_hosted_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_bower_hosted\n    args: \"{{ _nexus_repos_bower_defaults|combine(item) }}\"\n"}, {"commit_sha": "a94f9ce4fa32273fd0fad7492d36db4101423cc3", "sha": "8568499d285e92acb60eeb594298bdcb966081ec", "filename": "tasks/postinstall.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Reset internal variables for additional packages to be installed\n  set_fact:\n    _docker_additional_packages_os: []\n    _docker_additional_packages_pip: []\n\n- name: Set facts to install Docker SDK for Python\n  set_fact:\n    _docker_additional_packages_pip: \"{{ _docker_additional_packages_pip + docker_predefined_packages_pip[_docker_os_dist]['sdk'] }}\"\n  when:\n    - docker_sdk\n\n- name: Set facts to install Docker Compose\n  set_fact:\n    _docker_additional_packages_pip: \"{{ _docker_additional_packages_pip + docker_predefined_packages_pip[_docker_os_dist]['compose'] }}\"\n  when:\n    - docker_compose\n\n- name: Set facts to install Docker Stack dependencies ('docker_stack')\n  set_fact:\n    _docker_additional_packages_pip: \"{{ _docker_additional_packages_pip + docker_predefined_packages_pip[_docker_os_dist]['stack'] }}\"\n  when:\n    - docker_stack\n\n- name: Set facts with additional package to be installed\n  set_fact:\n    _docker_additional_packages_pip: \"{{ _docker_additional_packages_pip + docker_additional_packages_pip }}\"\n    _docker_additional_packages_os: \"{{ _docker_additional_packages_os + docker_additional_packages_os }}\"\n\n- name: Set facts to ensure PiP is installed if required\n  set_fact:\n    _docker_additional_packages_os: \"{{ _docker_additional_packages_os + ['python-pip', 'python-virtualenv'] }}\"\n  when:\n    - _docker_additional_packages_pip | length > 0\n\n- name: Install additional packages (OS package manager)\n  become: true\n  package:\n    name: \"{{ item }}\"\n    state: present\n  with_items:\n    - \"{{ _docker_additional_packages_os }}\"\n  when: _docker_additional_packages_os | length > 0\n\n- name: Upgrade PiP\n  become: true\n  pip:\n    name: pip\n    state: forcereinstall\n  when: docker_pip_upgrade\n\n- name: Install additional packages (PiP)\n  become: true\n  pip:\n    name: \"{{ item }}\"\n    state: present\n  with_items:\n    - \"{{ _docker_additional_packages_pip }}\"\n  when: _docker_additional_packages_pip | length > 0\n  environment:\n    PYTHONWARNINGS: ignore"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "d51a57dcb8236403c4fa082b92a8d70e7ae4c6c3", "filename": "tasks/setup-repository-Debian.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Include tasks from setup of repositories for Ubuntu\n  include_tasks: setup-repository-Ubuntu.yml\n\n# Backport is required but not documented by Docker: https://github.com/moby/moby/issues/16878\n- name: Add backport repository for Debian Wheezy\n  become: true\n  apt_repository:\n    repo: deb [arch=amd64] http://ftp.debian.org/debian wheezy-backports main\n    state: present\n    filename: 'debian-backport'\n  when: _docker_os_dist_major_version == '7'"}, {"commit_sha": "e91a55152358e890a05cf849abc7d58b8badecc2", "sha": "fed802f871f8f9312405e6f42c7ff992d46d8521", "filename": "tasks/tasks-Debian.yml", "repository": "fubarhouse/ansible-role-golang", "decoded_content": "---\n\n- name: \"Go-Lang | Install dependencies\"\n  apt:\n    name: \"{{ item }}\"\n    state: installed\n  with_items:\n    - curl\n    - gcc\n    - git\n    - findutils\n    - make\n    - rsync\n    - tar\n\n- name: \"Go-Lang | Define GOARCH\"\n  set_fact:\n    GOARCH: \"amd64\"\n  when: GOARCH is not defined\n\n- name: \"Go-Lang | Define GOOS\"\n  set_fact:\n    GOOS: \"linux\"\n  when: GOOS is not defined"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "0bba2d3dfdf41e39d7b7e5ab5e7b7dfef2b434cb", "filename": "roles/config-bonding/tests/inventory/group_vars/infra_hosts.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nbonds: \n- device: bond0.mgmt\n  bonding_opts: 'mode=4 miimon=100'\n  slaves: \n  - device: eth0\n  - device: eth1\n  ipaddr: '{{ mgmt_net_ip }}'\n  netmask: '{{ mgmt_net_netmask }}'\n  gateway: '{{ mgmt_net_gateway }}'\n  dns1: '{{ mgmt_net_dns1 }}'\n  dns2: '{{ mgmt_net_dns2 }}'\n- device: bond1.vms\n  bonding_opts: 'mode=4 miimon=100'\n  slaves: \n  - device: eth2\n  - device: eth3\n\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "98d971b0a71421e5bef01e126ac9eedacf290da2", "filename": "roles/dns/test/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: localhost\n  roles:\n  - role: dns\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "efb743710783f474a09da670c1694f3ab206f7b7", "filename": "playbooks/roles/check_proxy/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- name: ensure proxy settings uppercase with username and password\n  lineinfile:\n    dest: /etc/environment\n    state: present\n    line: \"{{item[0]}}={{ proxy_username }}:{{ proxy_password }}@{{ item[1] }}\"\n  with_together:\n  - \"{{ proxy_uc_envs }}\"\n  - \"{{ proxies }}\"\n  when: proxy_username is defined and proxy_http is defined\n- name: ensure proxy settings uppercase\n  lineinfile:\n    dest: /etc/environment\n    state: present\n    line: \"{{item[0]}}={{ item[1] }}\"\n  with_together:\n  - \"{{ proxy_uc_envs }}\"\n  - \"{{ proxies }}\"\n  when: proxy_username is not defined and proxy_http is defined\n- name: ensure no proxy settings uppercase\n  lineinfile:\n    dest: /etc/environment\n    state: present\n    line: \"NO_PROXY=127.0.0.1,localhost,.svc,{{proxy_no | default('')}}\"\n  when: proxy_http is defined\n- name: ensure proxy settings lowercase with username and password\n  lineinfile:\n    dest: /etc/environment\n    state: present\n    line: \"{{item[0]}}={{ proxy_username }}:{{ proxy_password }}@{{ item[1] }}\"\n  with_together:\n  - \"{{ proxy_lc_envs }}\"\n  - \"{{ proxies }}\"\n  when: proxy_username is defined and proxy_http is defined\n- name: ensure proxy settings lowercase\n  lineinfile:\n    dest: /etc/environment\n    state: present\n    line: \"{{item[0]}}={{ item[1] }}\"\n  with_together:\n  - \"{{ proxy_lc_envs }}\"\n  - \"{{ proxies }}\"\n  when: proxy_username is not defined and proxy_http is defined\n- name: ensure no proxy settings lowercase\n  lineinfile:\n    dest: /etc/environment\n    state: present\n    line: \"no_proxy=127.0.0.1,localhost,.svc,{{proxy_no | default('')}}\"\n  when: proxy_http is defined\n\n\n\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "64a49fc981a809b819b1b0062805781c642ac19e", "filename": "playbooks/validate.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "---\n- name: Validate proxy\n  hosts: all\n  gather_facts: yes\n  vars:\n    proxy_uc_envs:\n    - HTTP_PROXY\n    - HTTPS_PROXY\n    proxy_lc_envs:\n    - http_proxy\n    - https_proxy\n    proxies:\n    - \"{{ proxy_http }}\"\n    - \"{{ proxy_https }}\"\n  vars_files:\n  - \"{{file_env}}\"\n  - \"{{file_secrets}}\"\n  roles:\n  - check_proxy\n\n- name: ensure bastion packages.\n  hosts: bastion\n  gather_facts: yes\n  vars_files:\n  - \"{{file_env}}\"\n  roles:\n  - check_packages_bastion\n\n- name: ensure subscription\n  gather_facts: no\n  hosts: nodes\n  vars_files:\n  - \"{{file_env}}\"\n  - \"{{file_secrets}}\"\n  roles:\n  - check_subscription\n\n\n- name: ensure nodes packages.\n  hosts: nodes\n  serial: 1\n  gather_facts: no\n  vars_files:\n  - \"{{file_env}}\"\n  roles:\n  - check_networking\n  - check_packages_nodes\n\n\n- name: Validate environment\n  gather_facts: no\n  hosts: all\n  vars_files:\n  - \"{{file_env}}\"\n  - \"{{file_secrets}}\"\n  tasks:\n    - import_role:\n        name: check_disks\n    - import_role:\n        name: check_os\n    - import_role:\n        name: check_connectivity\n    - import_role:\n        name: check_sizing\n      when: inventory_hostname in groups['nodes']\n    - import_role:\n        name: check_dns\n    - import_role:\n        name: check_selinux\n    - import_role:\n        name: check_ntp\n      when: ntp_servers is defined\n    - import_role:\n        name: check_storage\n      when: inventory_hostname in groups['nodes']\n    - import_role:\n        name: check_nm\n    - import_role:\n        name: check_glusterfs\n      when: inventory_hostname in groups['glusterfs'] | default([])\n\n\n- name: Initialize firewall check\n  hosts: nodes\n  gather_facts: no\n  vars_files:\n  - \"{{file_env}}\"\n  roles:\n  - check_firewall_initialize\n\n- name: Execute firewall check\n  hosts: localhost\n  gather_facts: yes\n  vars_files:\n  - \"{{file_env}}\"\n  roles:\n  - check_firewall\n\n- name: Validate docker\n  hosts: nodes\n  gather_facts: yes\n  vars_files:\n  - \"{{file_env}}\"\n  roles:\n  - check_docker_setup\n  - check_docker_validation\n\n- name: Cleanup validation trash\n  hosts: all\n  gather_facts: yes\n  vars_files:\n  - \"{{file_env}}\"\n  roles:\n  - check_cleanup\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "1e4c4769ec7001fb357f41ff04ec0e8ecee11532", "filename": "roles/idm-host-cert/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# 'host_force_add' is used to add the host even if no DNS record(s) exists for the host\nhost_force_add: true\n\n# Description of the host entry being added/processed\nhost_description: ''\n\n# Default API version to be passed\napi_version: '2.213'\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "bf0d2505c1505c601b24d97e4733bf74554b29af", "filename": "roles/ejabberd_xs/templates/ejabberd", "repository": "iiab/iiab", "decoded_content": "#!/bin/sh -e\n\n#\n# ejabberd now handles domain changes in the initrd script\n#\nSERVICE_NAME=ejabberd-xs\n\nCONFIG_LIST=\"/etc/ejabberd/ejabberd-xs.cfg\"\n\n# taken from ejabberd spec %post\n# taken from ejabberd spec %post\n#function do-cert(){\n#    (cd /etc/ejabberd\n#    if [ ! -f ejabberd.pem ]\n#    then\t\n#\techo \"Generating SSL certificate /etc/ejabberd/ejabberd.pem...\"\n#\tHOSTNAME=$(hostname -s)\n#\tDOMAINNAME=$(hostname -d)\n#\topenssl req -new -x509 -days 36500 -nodes -out ejabberd.pem -keyout ejabberd.pem > /dev/null 2>&1 << +++\n#\t.\n#\t.\n#\t.\n#\t$DOMAINNAME\n#\t$HOSTNAME\n#\tejabberd\n#\troot@$HOSTNAME.$DOMAINNAME\n#\t+++\n#\tchown ejabberd:ejabberd ejabberd.pem\n#\tchmod 600 ejabberd.pem\n#    fi)\n#}\n\n#  This is the suffix which original versions of modified files will have\nBACKUP_SUFFIX=old\n\nshort_host=`hostname -s`\nnew_name=$short_host.$1\n\nfor config in $CONFIG_LIST;\ndo\n    if [ -e $config.in ]; then\n\tif [ -e $config ]; then\n\t    mv $config $config.$BACKUP_SUFFIX\n\tfi\n\tsed -e s/{{ iiab_hostname }}/$new_name/ $config.in > $config ;\n    else\n\techo WARNING: Skipped $config - template file is missing!\n    fi\ndone\n\n#if [ -e /etc/ejabberd/ejabberd.pem.$1 ]; then\n#    rm /etc/ejabberd/ejabberd.pem.$1\t\n#fi\n#mv /etc/ejabberd/ejabberd.pem /etc/ejabberd/ejabberd.pem.$1\n#do-cert\n\n# Since for the community edition, we don't really expect all modules to be present\n#   Just exit, and expect the user to do a restart\n\nexit 0\n\n\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "962b887b19d9682a42e535dff9a1943be1a8d8e5", "filename": "tasks/Linux/fetch/local.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Copy artifact to destination\n  copy:\n    src: '{{ transport_local }}'\n    dest: '{{ java_download_path }}'\n  register: file_downloaded\n  retries: 5\n  delay: 2\n  until: file_downloaded is succeeded\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "03b7f9f6cb7b9146c7e252de734691504b2c8198", "filename": "tasks/section_04_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: Check if the grub config file exists (Not Scored)\n    stat: path=/etc/default/grub\n    register: grub_cfg_file\n\n  - name: Determines if apparmor is set in grub config (Not Scored)\n    command: \"grep 'GRUB_CMDLINE_LINUX' /etc/default/grub\"\n    register: grub_apparmor\n    changed_when: False\n    when: grub_cfg_file.stat.exists\n    always_run: True\n\n  - name: Check if the extlinux config file exists (Not Scored)\n    stat: path=/extlinux.conf\n    register: extlinux_cfg_file\n\n  - name: Determines if apparmor is set in extlinux (Not Scored)\n    command: \"grep 'apparmor' /extlinux.conf\"\n    register: extlinux_apparmor\n    changed_when: False\n    when: extlinux_cfg_file.stat.exists\n    always_run: True\n\n  - name: Determines if apparmor is already set in boot config (Not Scored)\n    command: \"grep CONFIG_DEFAULT_SECURITY_APPARMOR /boot/config-{{ ansible_kernel }}\"\n    register: boot_apparmor\n    changed_when: False\n    always_run: True\n\n  - name: 4.5 Activate AppArmor (install) (Scored)\n    apt: >\n        name=apparmor\n        state=present\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (Kernel LSM - grub) (Scored)\n    lineinfile: >\n        dest='/etc/default/grub'\n        regexp='^GRUB_CMDLINE_LINUX=\"\"'\n        line='GRUB_CMDLINE_LINUX=apparmor=\"1 security=apparmor\"'\n        state=present\n    when: \"(use_apparmor == True) and grub_cfg_file.stat.exists and ('apparmor' not in grub_apparmor['stdout']) and ('not set' in boot_apparmor['stdout'])\"\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (Kernel LSM - extlinux) (Scored)\n    lineinfile: >\n        dest='/extlinux.conf'\n        regexp=\"^append initrd=\"\n        line=\"append initrd={{ ansible_cmdline['initrd'] }} root={{ ansible_cmdline['root'] }} console=tty0 console={{ ansible_cmdline['console'] }} apparmor=1 security=apparmor ro quiet\"\n    when: \"(use_apparmor == True) and extlinux_cfg_file.stat.exists and ('apparmor' not in extlinux_apparmor['stdout']) and ('not set' in boot_cfg_apparmor['stdout'])\"\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (start) (Scored)\n    service: >\n        name=apparmor\n        state=started\n    when: use_apparmor == True\n    register: apparmor_status\n    ignore_errors: True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Determine if Apparmor started without error (Not Scored)\n    fail: msg=\"Apparmor can not be started. This is normal behavior if you run the playbook for the first time.\\nPlease reboot the machine and run it again to proceed with the rest of the playbook.\"\n    when: apparmor_status.failed is defined\n\n  - name: 4.5 Fix rsyslog /run/utmp permissions (Not Scored)\n    lineinfile: >\n        dest=\"/etc/apparmor.d/usr.sbin.rsyslogd\"\n        line=\"  /run/utmp rk,\"\n        insertbefore=\"  /var/spool/rsyslog/ r,\"\n        state=present\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (fix profiles) (Scored)\n    service: >\n        name=rsyslog\n        state=restarted\n    changed_when: False\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (Scored)\n    command: apparmor_status\n    register: aa_status_lines\n    failed_when: '\"0 profiles are loaded\" in aa_status_lines.stdout_lines or \"0 processes are in complain mode.\" not in aa_status_lines.stdout_lines or \"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n        # - '\"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n    changed_when: False\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (enforce install) (Scored)\n    apt: >\n        name=apparmor-utils\n        state=present\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (enforce) (Scored)\n    #shell: 'aa-enforce /etc/apparmor.d/*'\n    shell: for profile in /etc/apparmor.d/*; do aa-enforce $profile; done\n    register: aaenforce_rc\n    failed_when: aaenforce_rc.rc == 1\n    changed_when: False\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "848b8e9464c602b897542f1c4150aa84a513051f", "filename": "roles/dns/manage-dns-zones/tasks/named/determine-action.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Determine if named processing is required\n  set_fact:\n    named_processing: True\n  when:\n    - item.0.named is defined or item.1.named is defined\n  with_subelements:\n    - \"{{ dns_data.views | default({}) }}\"\n    - zones\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "39444657d006331e87f7d4c164b6d81cacbb888c", "filename": "playbooks/roles/bb0-openstack/provisioner-image/build.sh", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "#!/usr/bin/env bash\n\ndocker pull registry.access.redhat.com/rhel7/rhel\ndocker build \\\n    --build-arg RH_ORG_ID=$RHN_ORG_ID \\\n    --build-arg RH_ACTIVATIONKEY=$RHN_ACTIVATIONKEY \\\n    --build-arg RH_POOL_ID=$STC_SUBSCRIPTION_POOL_ID \\\n    -t quay.io/redhat/stc-openstack-provisioner:latest \\\n    .\n\ndocker tag quay.io/redhat/stc-openstack-provisioner:latest quay.io/redhat/stc-openstack-provisioner:$(docker run -ti quay.io/redhat/stc-openstack-provisioner:latest yum info openshift-ansible | grep Version | cut -f2 -d':'|tr -d ' '|tr -d '\\r')\n\ndocker push quay.io/redhat/stc-openstack-provisioner"}, {"commit_sha": "abafe1581c6c78d784cf215b214947675d49eff8", "sha": "c229685038992cf78f6e57dfc111acbd8c683456", "filename": "roles/common/handlers/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: restart rsyslog\n  service: name=rsyslog state=restarted\n\n- name: flush routing cache\n  shell: echo 1 > /proc/sys/net/ipv4/route/flush\n\n- name: restart loopback\n  shell: ifdown lo:100 && ifup lo:100\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "324b10d0689f671987560627d52f8fd6c37d5d96", "filename": "roles/config-repo-server/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nhosted_isos: []\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "f52593e9d95bdc771e49539c8a062cf24d185790", "filename": "playbooks/files/logrotate-fsf.conf", "repository": "rocknsm/rock", "decoded_content": "/data/fsf/*.log\n{\n    rotate 3\n    missingok\n    compress\n    create 0644 fsf fsf\n}\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "0e26c994130e07079eaac5d1a5976bf5addabd8d", "filename": "roles/ovirt-engine-config/tasks/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\n- name: Tune oVirt engine with engine-config, version specific\n  shell: \"engine-config -s {{ item.key }}='{{ item.value }}' --cver={{ item.version }}\"\n  with_items: \"{{ ovirt_engine_config | default([]) }}\"\n  notify:\n    - restart of ovirt-engine service\n    - check health status of page\n  when: ovirt_engine_config is defined and item.version != \"general\"\n  tags:\n    - skip_ansible_lint\n\n- name: Tune oVirt engine with engine-config, regardless version\n  shell: \"engine-config -s {{ item.key }}='{{ item.value }}'\"\n  notify:\n    - restart of ovirt-engine service\n    - check health status of page\n  with_items: \"{{ ovirt_engine_config | default([]) }}\"\n  when: ovirt_engine_config is defined and item.version == \"general\"\n  tags:\n    - skip_ansible_lint\n\n- name: Copy property file to engine\n  copy:\n    content: \"{{ ovirt_engine_config_property_file }}\"\n    dest: \"/tmp/ovirt_engine_config.properties\"\n  when: ovirt_engine_config_property_file is defined\n\n- name: Tune oVirt engine with engine-config; from property file\n  shell: \"engine-config --properties=/tmp/ovirt_engine_config.properties\"\n  notify:\n    - restart of ovirt-engine service\n    - check health status of page\n  when: ovirt_engine_config_property_file is defined\n  tags:\n    - skip_ansible_lint\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "3e8f7f5a3eb319e0965701a39ad4cad0d921236c", "filename": "playbooks/subscription-register.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "#!/usr/bin/env ansible-playbook\n---\n- hosts: all\n  gather_facts: false\n  become: true\n  serial: 1\n  tasks:\n    - fail: \n       msg: \"Please adjust file and add subscription cred\"\n\n#    - name: Register and subscribe to multiple pools.\n#      redhat_subscription:\n#        state: present\n#        username: joe_user\n#        password: somepass\n#        pool_ids:\n#        - 0123456789abcdef0123456789abcdef\n#        - 1123456789abcdef0123456789abcdef\n#\n\n#    - name: Update the consumed subscriptions from the previous example (remove Red Hat Virtualization subscription)\n#      redhat_subscription:\n#        state: present\n#        activationkey: 1-222333444\n#        org_id: 222333444\n#        pool: '^Red Hat Enterprise Server$'\n"}, {"commit_sha": "79e29502fb4e0ff1c30c0b5396bfa1b48fb84a8e", "sha": "e1c829f76e06d24fdac063f96eaca7c6a361f338", "filename": "tasks/themes.yml", "repository": "Oefenweb/ansible-wordpress", "decoded_content": "# tasks file for wordpress, themes\n---\n- name: identify installation (theme)\n  shell: \"wp-cli --allow-root --no-color --path='{{ item.0.path }}' theme is-installed {{ item.1 }}\"\n  register: check_installation_themes\n  failed_when: False\n  changed_when: False\n  with_subelements:\n    - wordpress_installs\n    - themes\n  when: item.1\n  tags: [configuration, wordpress, wordpress-themes, wordpress-is-installed-theme]\n\n- name: install (theme)\n  shell: \"wp-cli --allow-root --no-color --path='{{ item.item.0.path }}' theme install {{ item.item.1 }} --activate\"\n  with_items: check_installation_themes.results\n  when: check_installation_themes is defined and item.item.1 and item.rc != 0\n  tags: [configuration, wordpress, wordpress-themes, wordpress-install-theme]\n\n- name: check install (theme)\n  shell: \"wp-cli --allow-root --no-color --path='{{ item.0.path }}' theme is-installed {{ item.1 }}\"\n  changed_when: False\n  with_subelements:\n    - wordpress_installs\n    - themes\n  when: item.1\n  tags: [configuration, wordpress, wordpress-themes, wordpress-install-theme-check]\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "470ed8e842485fdfe65f413af67ada1648ee3e00", "filename": "archive/roles/cicd/tasks/prerequisites.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n  \n- name: Installing Prerequisite Software\n  yum: state=present name={{item}}\n  with_items:\n  - http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm\n  - wget\n  - firewalld\n  - unzip\n  - git\n  - vim\n  tags: prerequisites\n  \n- name: Installing JQ\n  yum:\n    name: jq\n    state: present\n  tags: prerequisites\n  \n- name: Disable iptables\n  service: \n    name: iptables\n    enabled: no\n    state: stopped\n  tags: prerequisites\n  \n- name: Enable firewalld\n  service:\n    name: firewalld\n    enabled: yes\n    state: started\n  tags: prerequisites\n"}, {"commit_sha": "2a05a5032ce341d6a1d918453164c59ea2922f58", "sha": "c7e9d63a3de7d8900edb9246b64ea94df86bbd6c", "filename": "roles/dns/defaults/main.yml", "repository": "CSCfi/fgci-ansible", "decoded_content": "---\n# defaults for dns role\n\nnameserver1: \"10.0.0.1\"\nnameserver2: \"10.1.0.1\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "aaee519c31c71d03695d329cbff0e1222742fce5", "filename": "roles/user-management/manage-local-user-ssh-authkeys/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: 'authorizedkeys.yml'\n  when:\n  - user_name is defined\n  - key_url is defined\n  - key_url|trim != \"\"\n\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "503adeaf152b748defb91ae04ab0106d230433be", "filename": "roles/ejabberd_xs/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Install ejabberd packages\n  package: name={{ item }}\n           state=present\n  with_items:\n   - ejabberd-2.1.11\n  tags:\n    - download\n  when: not is_debuntu\n\n# need to use lineinfile and better regexp\n- name: Disable updating ejabberd on CentOS\n  shell: sed -i -e '/^enabled=/a exclude=ejabberd' {{ item }}\n  with_items:\n    - /etc/yum.repos.d/CentOS-Base.repo\n    - /etc/yum.repos.d/CentOS-CR.repo\n    - /etc/yum.repos.d/CentOS-fasttrack.repo\n    - /etc/yum.repos.d/CentOS-Vault.repo\n  when: ejabberd_xs_install and is_centos\n\n- name: Disable updating ejabberd on Fedora\n  shell: sed -i -e '/^enabled=/a exclude=ejabberd' {{ item }}\n  with_items:\n    - /etc/yum.repos.d/fedora.repo\n    - /etc/yum.repos.d/fedora-updates.repo\n    - /etc/yum.repos.d/fedora-updates-testing.repo\n  when: ejabberd_xs_install and ansible_distribution == \"Fedora\"\n\n- name: Configure ejabberd\n  template: backup=yes\n            src={{ item.src }}\n            dest={{ item.dest }}\n            owner=root\n            group=root\n            mode={{ item.mode }}\n  with_items:\n    - { src: 'ejabberd-xs.cfg.j2', dest: '/etc/ejabberd/ejabberd-xs.cfg' , mode: '0644' }\n    - { src: 'ejabberdctl.cfg.j2', dest: '/etc/ejabberd/ejabberdctl.cfg', mode: '0644' }\n    - { src: 'ejabberd-xs', dest: '/etc/sysconfig/ejabberd-xs', mode: '0755' }\n#    - { src: 'ejabberd-domain-config', dest: '/etc/sysconfig/olpc-scripts/domain_config.d/ejabberd', mode: '0755'}\n#    - { src: 'ejabberd', dest: '/etc/sysconfig/olpc-scripts/domain_config.d/ejabberd' , mode: '0755' }\n    - { src: 'ejabberd-xs.service.j2', dest: '/etc/systemd/system/ejabberd-xs.service', mode: '0755' }\n    - { src: 'xs-ejabberd-srg', dest: '/usr/bin/xs-ejabberd-srg' , mode: '0755' }\n    - { src: '10-ejabberdmoodle', dest: '/etc/sudoers.d/10-ejabberdmoodle', mode: '0440' }\n    - { src: 'ejabberd.tmpfiles', dest: '/etc/tmpfiles.d/ejabberd.conf', mode: '0640' }\n  register: ejabberd_config\n  when: not is_debuntu\n\n- name: Put the startup script in place - non debian\n  template: src='ejabberd-xs.init'\n            dest='/usr/libexec/ejabberd-xs'\n  when: not is_debuntu\n\n- name: Remove ejabberd_domain if domain changes\n  file: path=/etc/sysconfig/ejabberd_domain_name\n        state=absent\n  when: ejabberd_config.changed and ejabberd_config is defined and not is_debuntu\n\n- name: Enable ejabberd service\n  file: src=/etc/systemd/system/ejabberd-xs.service\n        dest=/etc/systemd/system/multi-user.target.wants/ejabberd-xs.service\n        owner=root\n        group=root\n        state=link\n  when: not is_debuntu and ejabberd_xs_enabled\n\n- name: Start ejabberd service\n  service: name=ejabberd-xs\n           state=restarted\n           enabled=yes\n  when: ejabberd_config.changed and ejabberd_xs_enabled and not is_debuntu\n\n- name: Wait for ejabberd service start\n  wait_for: port=5280\n            delay=15\n            state=started\n            timeout=300\n  when: ejabberd_config.changed and ejabberd_xs_enabled\n\n- name: Create online group\n  shell: ejabberdctl srg_create Online \"schoolserver\" Online \"Online_Users\" Online\n  when: ejabberd_config.changed and not is_debuntu and ejabberd_xs_enabled\n\n- name: Add all users to online group\n  shell: ejabberdctl srg_user_add '@online@' \"schoolserver\" Online \"schoolserver\"\n  when: ejabberd_config.changed and not is_debuntu and ejabberd_xs_enabled\n\n\n\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "bc3bf68d03e666a9f2757f309763197ceb9a86b9", "filename": "playbooks/bb00-openstack_deprovisioning.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "#!/usr/bin/env ansible-playbook\n---\n\n- hosts: localhost\n  gather_facts: False\n  become: False\n  connection: local\n  serial: 1 # Because my lab is not so fast\n  tasks:\n    - name: Parameter validation\n      import_role:\n        name: bb0-openstack\n        tasks_from: validate-parameters.yml\n\n    - name: Create mini inventory\n      import_role:\n        name: bb0-openstack\n        tasks_from: create-inventory-mini.yml\n\n\n- hosts: openstack_instances\n  gather_facts: False\n  become: False\n  connection: local\n  tasks:\n    - name: Deprovisioning instances\n      import_role:\n        name: bb0-openstack\n        tasks_from: deprovisioning.yml\n\n- hosts: localhost\n  gather_facts: False\n  become: False\n  connection: local\n  tasks:\n    - name: Deprovisioning post once\n      import_role:\n        name: bb0-openstack\n        tasks_from: deprovisioning-post-once.yml\n\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "b3ed3f9f7ba0968d394b627657ba8a235d23cac4", "filename": "playbooks/ansible/tower/configure-ansible-tower.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: ansible-tower\n  roles:\n  - role: ansible/tower/config-ansible-tower\n  - role: ansible/tower/config-ansible-tower-ldap\n  tags:\n  - 'never'\n  - 'install'\n\n- hosts: tower-management-host\n  roles:\n  - role: ansible/tower/manage-projects\n  - role: ansible/tower/manage-credential-types\n  - role: ansible/tower/manage-credentials\n  - role: ansible/tower/manage-inventories\n  - role: ansible/tower/manage-job-templates\n  tags:\n  - 'always'\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "e049b4e15f57803a90c77d08ce1cef5bf2b6393f", "filename": "playbooks/nagios/README.md", "repository": "redhat-cop/casl-ansible", "decoded_content": "# Nagios Example Run\n\nThe `nagios-target` and `nagios-server` roles can be used to setup a complete Nagios monitoring for any environment. The `nagios-target` role will prepare the targets with the correct monitoring configuratoin for use with the NRPE (Nagios Remote Plugin Executor). The target role will selectively enable the correct monitoring plugins (and correctly configured) per targets.\n\nBelow is an example inventory file for setting up the Nagios server and targets. Before executing, ensure that access to the target servers is enabled - i.e.: SSH key login for root. \n\nExample run of the playbook:\n> ansible-playbook -i \\<path_to_inventory\\> setup_nagios.yml\n\n\n```\n[all:vars]\nansible_ssh_user=root\n\n# Infrastructure Server\n[infra]\ndns.infra.example.com nagios_services=dns\nnfs.infra.example.com nagios_services=nfs\n\n[infra:vars]\nhostgroup_name=infra-servers\nhostgroup_alias=Infrastructure Servers\n\n# OpenShift 3 environment\n[openshift]\nmaster.openshift.example.com nagios_services=docker,openshift-master,openshift-node\nnode1.openshift.example.com nagios_services=docker,openshift-node\nnode2.openshift.example.com nagios_services=docker,openshift-node\nnode3.openshift.example.com nagios_services=docker,openshift-node\ndns.openshift.example.com nagios_services=dns\nnfs.openshift.example.com nagios_services=nfs\n\n[openshift:vars]\nhostgroup_name=openshift-cluster\nhostgroup_alias=OpenShift Cluster (Environment #2)\n\n\n###############################################################################\n# The 'nagios-targets' definition is required\n[nagios-targets:children]\ninfra\nopenshift\n\n# The 'nagios-servers' definition is required\n[nagios-servers]\nnagios.example.com\n```\n\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "8f974abbf2067b85845ad16b093c2a456b430142", "filename": "roles/openvpn/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "---\n\n- name: Install openvpn packages\n  package:  name={{ item }}\n            state=present\n  with_items:\n        - openvpn\n        - nmap\n  tags:\n    - download\n\n- name: Create the directory for keys\n  file: dest=/etc/openvpn/keys\n        state=directory\n        owner=root\n        group=root\n        mode=0755\n\n- name: Create the directory for scripts\n  file: dest=/etc/openvpn/scripts\n        state=directory\n        owner=root\n        group=root\n        mode=0755\n\n- name: Create a folder for iiab executable not on path\n  file: path=/usr/lib/iiab\n        state=directory\n\n- name: Configure openvpn\n  template: src={{ item.src }}\n            dest={{ item.dest }}\n            owner={{ item.owner }}\n            group=root\n            mode={{ item.mode }}\n  with_items:\n    - { src: 'ca.crt', dest: '/etc/openvpn/keys/ca.crt', owner: \"root\" , mode: '0644' }\n    - { src: 'client1.crt', dest: '/etc/openvpn/keys/client1.crt', owner: \"root\" , mode: '0644' }\n    - { src: 'client1.key', dest: '/etc/openvpn/keys/client1.key', owner: \"root\" , mode: '0600' }\n    - { src: 'announce', dest: '/etc/openvpn/scripts/announce', owner: \"root\" , mode: '0755' }\n    - { src: 'announcer', dest: '/etc/openvpn/scripts/announcer', owner: \"root\" , mode: '0755' }\n    - { src: 'silence', dest: '/etc/openvpn/scripts/silence', owner: \"root\" , mode: '0755' }\n    - { src: 'xscenet.conf', dest: '/etc/openvpn/xscenet.conf', owner: \"root\" , mode: '0644' }\n    - { src: 'iiab-vpn.conf.in', dest: '/etc/openvpn/iiab-vpn.conf.in', owner: \"root\" , mode: '0644' }\n    - { src: 'iiab-vpn', dest: '/usr/bin/iiab-vpn', owner: \"root\" , mode: '0755' }\n    - { src: 'iiab-handle', dest: '/usr/bin/iiab-handle', owner: \"root\" , mode: '0755' }\n    - { src: 'up_wan', dest: '/usr/lib/iiab/up_wan', owner: \"root\" , mode: '0755' }\n    - { src: 'start.j2', dest: '/usr/lib/iiab/start', owner: \"root\" , mode: '0755' }\n    - { src: 'iiab-remote-on', dest: '/usr/bin/iiab-remote-on', owner: \"root\" , mode: '0755' }\n    - { src: 'iiab-remote-off', dest: '/usr/bin/iiab-remote-off', owner: \"root\" , mode: '0755' }\n\n- name: put up_wan in place for debian\n  template: src=up_wan dest=/usr/lib/iiab/up_wan\n  when: is_debuntu\n\n- name: put dispatcher up for NM\n  template: src=15-openvpn dest=/etc/NetworkManager/dispatcher.d/\n  when: not is_debuntu\n\n- name: check for manually configured openvpn tunnel\n  stat: path=/etc/openvpn/iiab-vpn.conf\n  register: stat\n\n# note that ansible does not currently handle @ in a service name\n- name:  enable the openvpn tunnel at boot time\n  shell: systemctl enable openvpn@xscenet.service\n  when:  openvpn_enabled and not stat.exists is defined and is_debuntu\n\n- name:  enable the openvpn tunnel at boot time for Debian\n  shell: update-rc.d openvpn enable\n  when:  openvpn_enabled and not stat.exists is defined and is_debuntu\n\n- name:  start the openvpn tunnel now\n  shell: systemctl start openvpn@xscenet.service\n  when:  openvpn_enabled and not stat.exists is defined and not installing\n\n- name: make openvpn connection automatic\n  lineinfile: dest=/etc/crontab\n            line=\"25 *  *  *  * root (/usr/bin/systemctl start openvpn@xscenet.service) > /dev/null\"\n  when:\n            openvpn_enabled and openvpn_cron_enabled and not stat.exists is defined\n\n- name: make openvpn connection manual\n  lineinfile: dest=/etc/crontab\n            regexp=\".*/usr/bin/systemctl*\"\n            state=absent\n  when:\n            not openvpn_enabled or not openvpn_cron_enabled\n\n\n- name:    stop starting the openvpn tunnel at boot time\n  shell:   systemctl disable openvpn@xscenet.service\n  when:    not openvpn_enabled and not is_debuntu\n\n- name:    stop starting the openvpn tunnel at boot time for Debian\n  shell:   update-rc.d openvpn disable\n  when:    not openvpn_enabled and is_debuntu\n\n- name:    stop  openvpn tunnel immediately\n  shell:   systemctl stop openvpn@xscenet.service\n  ignore_errors: True\n  when:    not openvpn_enabled and not installing\n\n- name: Add openvpn to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=openvpn\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: \"openvpn\"\n    - option: description\n      value: '\"Openvpn is a means of Contacting a server anywhere on the internet via a middleman server\"'\n    - option: middleman_url\n      value: \"{{ vpn_presence }}\"\n    - option: port\n      value: \"{{ openvpn_server_port }}\"\n    - option: enabled\n      value: \"{{ openvpn_enabled }}\"\n    - option: cron_enabled\n      value: \"{{ openvpn_cron_enabled }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "6b9e77d1a634a613efbfcf5161d9158f431a9824", "filename": "roles/user-management/manage-user-passwd/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: generate-passwords.yml\n- import_tasks: idm-set-passwd.yml\n\n- name: \"New password list\"\n  debug:\n    var: user_passwords\n    verbosity: 2\n\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "4c6cdcdf3b75b5075a48db96c54d9c922d888b8d", "filename": "roles/prometheus/meta/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\ngalaxy_info:\n  author: Graham Taylor\n  description:\n  company: Capgemini\n  license: license (MIT)\n  min_ansible_version: 1.9\n  platforms:\n  - name: Ubuntu\n    versions:\n     - trusty\n\n  categories:\n  - cloud\n  - system\n\n"}, {"commit_sha": "8c72df4ecfaa4188202ab0872f4500384ffe5233", "sha": "035669f3ba0e56a81d6b3ba4c86ecd928fa9eca5", "filename": "tasks/install-docker.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Set docker-ce package state to latest\n  set_fact:\n    _docker_pkg_state: 'latest'\n  when: docker_latest_version | bool\n\n- name: Ensure docker-ce is installed\n  become: true\n  package:\n    name: \"{{ docker_pkg_name }}\"\n    state: \"{{ _docker_pkg_state | default('present') }}\"\n  notify: restart docker\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "8c28c7ebbe725c2ccf726a39d2e9263fd58b2106", "filename": "tasks/Win32NT/fetch/local.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Copy artifact to destination\n  win_copy:\n    src: '{{ transport_local }}'\n    dest: '{{ java_download_path }}\\'\n  register: file_downloaded\n  retries: 5\n  delay: 2\n  until: file_downloaded is succeeded\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "711b4c0e09ec4f89472fe7814cc5e3df3dd4db1b", "filename": "roles/config-satellite/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: \"prereq.yml\"\n- import_tasks: \"install.yml\"\n- import_tasks: \"manifest.yml\"\n- import_tasks: \"repos.yml\"\n- import_tasks: \"activation_keys.yml\"\n"}, {"commit_sha": "b7c6bfe0369646ca69beeb3dfe07e8218d61c940", "sha": "bad12c7e446bdc02185e3a628ee1aed7441b3ee6", "filename": "tasks/rhosts.yml", "repository": "dev-sec/ansible-os-hardening", "decoded_content": "---\n- name: Get user accounts | os-09\n  command: \"awk -F: '{print $1}' /etc/passwd\"\n  changed_when: False\n  check_mode: False\n  register: users\n\n- name: delete rhosts-files from system | os-09\n  file:\n    dest: '~{{ item }}/.rhosts'\n    state: 'absent'\n  with_flattened: '{{ users.stdout_lines | default([]) }}'\n\n- name: delete hosts.equiv from system | os-01\n  file:\n    dest: '/etc/hosts.equiv'\n    state: 'absent'\n\n- name: delete .netrc-files from system | os-09\n  file:\n    dest: '~{{ item }}/.netrc'\n    state: 'absent'\n  with_flattened: '{{ users.stdout_lines | default([]) }}'"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "3806b4c7ec0eb34f6909062906b41182717e89aa", "filename": "roles/docker/vars/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# vars file for docker\n"}, {"commit_sha": "3c4d272a77f8aaeb300c8b841bb7e6d8dbd76c1f", "sha": "ab4c089ddc802e16783ee03c3ee0097abc54adc8", "filename": "tasks/redhat/main.yml", "repository": "ansiblebit/oracle-java", "decoded_content": "---\n# file: oracle-java/tasks/redhat/main.yml\n#\n# Task file to install Oracle Java Development Kit in a system with a Redhat based Linux distribution.\n#\n\n- name: download Java RPM\n  shell:\n    \"curl -L  -H 'Cookie:oraclelicense=accept-securebackup-cookie' -o {{ oracle_java_dir_source }}/{{ oracle_java_rpm_filename }} {{ oracle_java_rpm_url }}\"\n  args:\n    creates: \"{{ oracle_java_dir_source }}/{{ oracle_java_rpm_filename }}\"\n  register: oracle_java_task_rpm_download\n  sudo: yes\n  tags:\n    - installation\n\n- name: install RPM\n  yum:\n    name=\"{{ oracle_java_dir_source }}/{{ oracle_java_rpm_filename }}\"\n    state=present\n  when: not oracle_java_task_rpm_download|skipped\n  sudo: yes\n  tags:\n    - installation\n\n- name: set Java version as default\n  alternatives:\n    name=\"{{ item.exe }}\"\n    link=\"/usr/bin/{{ item.exe }}\"\n    path=\"{{ item.path }}/{{ item.exe }}\"\n  when: oracle_java_set_as_default\n  with_items:\n    - { path: \"{{ oracle_java_home }}/jre/bin\", exe: 'java' }\n    - { path: \"{{ oracle_java_home }}/jre/bin\", exe: 'keytool' }\n    - { path: \"{{ oracle_java_home }}/bin\", exe: 'javac' }\n    - { path: \"{{ oracle_java_home }}/bin\", exe: 'javadoc' }\n  sudo: yes\n  when: oracle_java_task_rpm_download|changed or (oracle_java_installed and oracle_java_version_installed != oracle_java_version_string)\n  register: oracle_java_task_set_default\n\n- name: in case there were changes, check host environment again\n  include: ../check_environment.yml\n  when: not oracle_java_task_rpm_download|skipped or oracle_java_task_set_default|changed\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "52f4663c928cdf2e819f494e2f9f54ad5a26863c", "filename": "roles/config-mysql/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "- name: Restart MySQL Service\n  systemd:\n    name: \"{{ mysql_name }}\"\n    enabled: yes\n    state: restarted\n    daemon_reload: yes\n\n- name: restart firewalld\n  service:\n    name: firewalld\n    state: restarted\n\n- name: restart iptables\n  service:\n    name: iptables\n    state: restarted"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "5355de1b3aea09d95dd334892205e0d316dafdd9", "filename": "roles/dns/manage-dns-zones/tasks/route53/loop-records.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: \"Loop through zone records\"\n  include_tasks: empty-zone.yml\n  with_subelements:\n    - \"{{ r53_zone.ResourceRecordSets }}\"\n    - ResourceRecords\n  loop_control:\n    loop_var: r53_record\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "40b1ab4ceaeb88d91cae0312c0ee5cf04032238b", "filename": "playbooks/provision-satellite-server/configure-satellite-server.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: satellite-server\n  pre_tasks:\n  - import_tasks: generate-lvm-list.yml\n  roles:\n  - role: config-lvm\n  - role: config-satellite\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "f5baaece22539537743f2b00b1fed402e441db8a", "filename": "roles/memcached/defaults/main.yml", "repository": "roots/trellis", "decoded_content": "---\nmemcached_cache_size: 64\nmemcached_fs_file_max: 756024\nmemcached_listen_ip: 127.0.0.1\nmemcached_max_conn: 1024\nmemcached_port: 11211\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "ad31471d154264af299574cf527caa5085250938", "filename": "tasks/create_repo_raw_group_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_raw_group\n    args: \"{{ _nexus_repos_raw_defaults|combine(item) }}\""}, {"commit_sha": "836dc4dd0dacc490044a14c0e39469d162b9449b", "sha": "c9d611787f2fc83b0c2c2445a60b8d4818641ace", "filename": "tasks/section3.yml", "repository": "florianutz/Ubuntu1604-CIS", "decoded_content": "---\n- name: \"SCORED | 3.1.1 | PATCH | Ensure IP forwarding is disabled\"\n  sysctl:\n      name: net.ipv4.ip_forward\n      value: 0\n      state: present\n      reload: true\n      ignoreerrors: true\n  when: ubuntu1604cis_is_router == false\n  notify:\n      - sysctl flush ipv4 route table\n  tags:\n      - level1\n      - scored\n      - patch\n      - sysctl\n      - rule_3.1.1\n\n- name: \"SCORED | 3.1.2 | PATCH | Ensure packet redirect sending is disabled\"\n  sysctl:\n      name: '{{ item.name }}'\n      value: '{{ item.value }}'\n      sysctl_set: true\n      state: present\n      reload: true\n      ignoreerrors: true\n  with_items:\n      - { name: net.ipv4.conf.all.send_redirects, value: 0 }\n      - { name: net.ipv4.conf.default.send_redirects, value: 0 }\n  when: ubuntu1604cis_is_router == false\n  notify:\n      - sysctl flush ipv4 route table\n  tags:\n      - level1\n      - scored\n      - patch\n      - sysctl\n      - rule_3.1.2\n\n- name: \"SCORED | 3.2.1 | PATCH | Ensure source routed packets are not accepted\"\n  sysctl:\n      name: '{{ item.name }}'\n      value: '{{ item.value }}'\n      sysctl_set: true\n      state: present\n      reload: true\n      ignoreerrors: true\n  with_items:\n      - { name: net.ipv4.conf.all.accept_source_route, value: 0 }\n      - { name: net.ipv4.conf.default.accept_source_route, value: 0 }\n  notify:\n      - sysctl flush ipv4 route table\n  tags:\n      - level1\n      - scored\n      - patch\n      - sysctl\n      - rule_3.2.1\n\n- name: \"SCORED | 3.2.2 | PATCH | Ensure ICMP redirects are not accepted\"\n  sysctl:\n      name: '{{ item.name }}'\n      value: '{{ item.value }}'\n      sysctl_set: true\n      state: present\n      reload: true\n      ignoreerrors: true\n  with_items:\n      - { name: net.ipv4.conf.all.accept_redirects, value: 0 }\n      - { name: net.ipv4.conf.default.accept_redirects, value: 0 }\n  notify:\n      - sysctl flush ipv4 route table\n  tags:\n      - level1\n      - scored\n      - patch\n      - sysctl\n      - rule_3.2.2\n\n- name: \"SCORED | 3.2.3 | PATCH | Ensure secure ICMP redirects are not accepted\"\n  sysctl:\n      name: '{{ item.name }}'\n      value: '{{ item.value }}'\n      sysctl_set: true\n      state: present\n      reload: true\n      ignoreerrors: true\n  with_items:\n      - { name: net.ipv4.conf.all.secure_redirects, value: 0 }\n      - { name: net.ipv4.conf.default.secure_redirects, value: 0 }\n  notify:\n      - sysctl flush ipv4 route table\n  tags:\n      - level1\n      - scored\n      - patch\n      - sysctl\n      - rule_3.2.3\n\n- name: \"SCORED | 3.2.4 | PATCH | Ensure suspicious packets are logged\"\n  sysctl:\n      name: '{{ item.name }}'\n      value: '{{ item.value }}'\n      sysctl_set: true\n      state: present\n      reload: true\n      ignoreerrors: true\n  with_items:\n      - { name: net.ipv4.conf.all.log_martians, value: 1 }\n      - { name: net.ipv4.conf.default.log_martians, value: 1 }\n  notify:\n      - sysctl flush ipv4 route table\n  tags:\n      - level1\n      - scored\n      - patch\n      - sysctl\n      - rule_3.2.4\n\n- name: \"SCORED | 3.2.5 | PATCH | Ensure broadcast ICMP requests are ignored\"\n  sysctl:\n      name: net.ipv4.icmp_echo_ignore_broadcasts\n      value: 1\n      state: present\n      reload: true\n      ignoreerrors: true\n  notify:\n      - sysctl flush ipv4 route table\n  tags:\n      - level1\n      - scored\n      - patch\n      - sysctl\n      - rule_3.2.5\n\n- name: \"SCORED | 3.2.6 | PATCH | Ensure bogus ICMP responses are ignored\"\n  sysctl:\n      name: net.ipv4.icmp_ignore_bogus_error_responses\n      value: 1\n      state: present\n      reload: true\n      ignoreerrors: true\n  notify:\n      - sysctl flush ipv4 route table\n  tags:\n      - level1\n      - scored\n      - patch\n      - sysctl\n      - rule_3.2.6\n\n- name: \"SCORED | 3.2.7 | PATCH | Ensure Reverse Path Filtering is enabled\"\n  sysctl:\n      name: '{{ item.name }}'\n      value: '{{ item.value }}'\n      sysctl_set: true\n      state: present\n      reload: true\n      ignoreerrors: true\n  with_items:\n      - { name: net.ipv4.conf.all.rp_filter, value: 1 }\n      - { name: net.ipv4.conf.default.rp_filter, value: 1 }\n  notify:\n      - sysctl flush ipv4 route table\n  tags:\n      - level1\n      - scored\n      - patch\n      - sysctl\n      - rule_3.2.7\n\n- name: \"SCORED | 3.2.8 | PATCH | Ensure TCP SYN Cookies is enabled\"\n  sysctl:\n      name: net.ipv4.tcp_syncookies\n      value: 1\n      state: present\n      reload: true\n      ignoreerrors: true\n  notify:\n      - sysctl flush ipv4 route table\n  tags:\n      - level1\n      - scored\n      - patch\n      - sysctl\n      - rule_3.2.8\n\n- name: \"SCORED | 3.3.1 | PATCH | Ensure IPv6 router advertisements are not accepted\"\n  sysctl:\n      name: '{{ item.name }}'\n      value: '{{ item.value }}'\n      sysctl_set: true\n      state: present\n      reload: true\n      ignoreerrors: true\n  with_items:\n      - { name: net.ipv6.conf.all.accept_ra, value: 0 }\n      - { name: net.ipv6.conf.default.accept_ra, value: 0 }\n  when: ubuntu1604cis_ipv6_required == true\n  notify:\n      - sysctl flush ipv6 route table\n  tags:\n      - level1\n      - scored\n      - patch\n      - sysctl\n      - rule_3.3.1\n\n- name: \"SCORED | 3.3.2 | PATCH | Ensure IPv6 redirects are not accepted\"\n  sysctl:\n      name: '{{ item.name }}'\n      value: '{{ item.value }}'\n      sysctl_set: true\n      state: present\n      reload: true\n      ignoreerrors: true\n  with_items:\n      - { name: net.ipv6.conf.all.accept_redirects, value: 0 }\n      - { name: net.ipv6.conf.default.accept_redirects, value: 0 }\n  when: ubuntu1604cis_ipv6_required == true\n  notify:\n      - sysctl flush ipv6 route table\n  tags:\n      - level1\n      - scored\n      - patch\n      - sysctl\n      - rule_3.3.2\n\n- name: \"NOTSCORED | 3.3.3 | PATCH | Ensure IPv6 is disabled\"\n  lineinfile:\n      dest: /etc/modprobe.d/CIS.conf\n      regexp: \"^(#)?options ipv6 disable=\"\n      line: \"options ipv6 disable=1\"\n      create: true\n  when: ubuntu1604cis_ipv6_required == false\n  tags:\n      - level1\n      - notscored\n      - patch\n      - rule_3.3.3\n\n- name: \"SCORED | 3.4.1 | PATCH | Ensure TCP Wrappers is installed\"\n  apt:\n      name: \"{{ tcp_wrapper_package[ansible_os_family] }}\"\n      state: present\n      install_recommends: false\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_3.4.1\n\n- name: \"SCORED | 3.4.2 | PATCH | Ensure /etc/hosts.allow is configured\"\n  template:\n      src: hosts.allow.j2\n      dest: /etc/hosts.allow\n      owner: root\n      group: root\n      mode: 0644\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_3.4.2\n\n- name: \"SCORED | 3.4.3 | PATCH | Ensure /etc/hosts.deny is configured\"\n  lineinfile:\n      dest: /etc/hosts.deny\n      regexp: \"^(#)?ALL\"\n      line: \"ALL: ALL\"\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_3.4.3\n\n- name: \"SCORED | 3.4.4 | PATCH | Ensure permissions on /etc/hosts.allow are configured\"\n  file:\n      dest: /etc/hosts.allow\n      owner: root\n      group: root\n      mode: 0644\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_3.4.4\n\n- name: \"SCORED | 3.4.5 | PATCH | Ensure permissions on /etc/hosts.deny are 644\"\n  file:\n      dest: /etc/hosts.deny\n      owner: root\n      group: root\n      mode: 0644\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_3.4.5\n\n- name: \"NOTSCORED | 3.5.1 | PATCH | Ensure DCCP is disabled\"\n  lineinfile:\n      dest: /etc/modprobe.d/CIS.conf\n      regexp: \"^(#)?install dccp(\\\\s|$)\"\n      line: \"install dccp /bin/true\"\n      create: true\n  tags:\n      - level1\n      - notscored\n      - patch\n      - rule_3.5.1\n\n- name: \"NOTSCORED | 3.5.2 | PATCH | Ensure SCTP is disabled\"\n  lineinfile:\n      dest: /etc/modprobe.d/CIS.conf\n      regexp: \"^(#)?install sctp(\\\\s|$)\"\n      line: \"install sctp /bin/true\"\n      create: true\n  tags:\n      - level1\n      - notscored\n      - patch\n      - rule_3.5.2\n\n- name: \"NOTSCORED | 3.5.3 | PATCH | Ensure RDS is disabled\"\n  lineinfile:\n      dest: /etc/modprobe.d/CIS.conf\n      regexp: \"^(#)?install rds(\\\\s|$)\"\n      line: \"install rds /bin/true\"\n      create: true\n  tags:\n      - level1\n      - notscored\n      - patch\n      - rule_3.5.3\n\n- name: \"NOTSCORED | 3.5.4 | PATCH | Ensure TIPC is disabled\"\n  lineinfile:\n      dest: /etc/modprobe.d/CIS.conf\n      regexp: \"^(#)?install tipc(\\\\s|$)\"\n      line: \"install tipc /bin/true\"\n      create: true\n  tags:\n      - level1\n      - notscored\n      - patch\n      - rule_3.5.4\n\n- name: \"SCORED | 3.6 | PATCH | Ensure firewalld is installed and started |\u00a0CUSTOM\"\n  apt:\n      name: firewalld\n      state: present\n      install_recommends: false\n  when: ubuntu1604cis_firewall == \"firewalld\" and ubuntu1604cis_setup_firewall\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_3.6\n\n- name: \"SCORED | 3.6 | PATCH | Ensure firewalld is installed and started |\u00a0CUSTOM\"\n  service:\n      name: firewalld\n      state: started\n      enabled: true\n  when: ubuntu1604cis_firewall == \"firewalld\" and ubuntu1604cis_setup_firewall\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_3.6\n\n- name: \"SCORED | 3.6.1 | PATCH | Ensure iptables is installed\"\n  apt:\n      name: iptables\n      state: present\n      install_recommends: false\n  when: ubuntu1604cis_firewall == \"iptables\" and ubuntu1604cis_setup_firewall\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_3.6.1\n\n- name: \"SCORED | 3.6.1 | PATCH | Ensure iptables is installed and started\"\n  service:\n      name: iptables\n      state: started\n      enabled: true\n  when: ubuntu1604cis_firewall == \"iptables\" and ubuntu1604cis_setup_firewall\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_3.6.1\n\n- name: \"SCORED | 3.6.2 | PATCH | Ensure default deny firewall policy\"\n  lineinfile:\n      dest: /etc/firewalld/firewalld.conf\n      regexp: \"^DefaultZone\"\n      line: \"DefaultZone=drop\"\n  when: ubuntu1604cis_firewall == \"firewalld\" and ubuntu1604cis_setup_firewall\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_3.6.2\n\n- name: \"SCORED | 3.6.2 | PATCH | Ensure default deny firewall policy\"\n  firewalld:\n      state: enabled\n      zone: drop\n      permanent: true\n  when: ubuntu1604cis_firewall == \"firewalld\" and ubuntu1604cis_setup_firewall\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_3.6.2\n\n- name: \"SCORED | 3.6.2 | PATCH | Ensure default deny firewall policy\"\n  command: /bin/true\n  changed_when: false\n  when: ubuntu1604cis_firewall == \"iptables\" and ubuntu1604cis_setup_firewall\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_3.6.2\n      - notimplemented\n\n- name: \"SCORED | 3.6.3 | PATCH | Ensure loopback traffic is configured\"\n  command: /bin/true\n  changed_when: false\n  when: ubuntu1604cis_firewall == \"iptables\" and ubuntu1604cis_setup_firewall\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_3.6.3\n      - notimplemented\n\n- name: \"NOTSCORED | 3.6.4 | PATCH | Ensure outbound and established connections are configured\"\n  command: /bin/true\n  changed_when: false\n  when: ubuntu1604cis_firewall == \"iptables\" and ubuntu1604cis_setup_firewall\n  tags:\n      - level1\n      - notscored\n      - patch\n      - rule_3.6.4\n      - notimplemented\n\n- name: \"SCORED | 3.6.5 | PATCH | Ensure firewall rules exist for all open ports\"\n  firewalld:\n      service: \"{{ item }}\"\n      state: enabled\n      zone: drop\n      permanent: true\n      immediate: true\n  when: ubuntu1604cis_firewall == \"firewalld\" and ubuntu1604cis_setup_firewall\n  notify: restart firewalld\n  with_items: \"{{ ubuntu1604cis_firewall_services }}\"\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_3.6.5\n\n- name: \"SCORED | 3.6.5 | PATCH | Ensure firewall rules exist for all open ports\"\n  command: /bin/true\n  changed_when: false\n  when: ubuntu1604cis_firewall == \"iptables\" and ubuntu1604cis_setup_firewall\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_3.6.5\n      - notimplemented\n\n- name: \"NOTSCORED | 3.7 | PATCH | Ensure wireless interfaces are disabled\"\n  command: /bin/true\n  changed_when: false\n  tags:\n      - level1\n      - notscored\n      - patch\n      - rule_3.7\n      - notimplemented\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "b72652d70c05753e5eaec28b63c2c30c3817e366", "filename": "roles/config-linux-desktop/config-gnome/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Install, configure and enable Gnome\"\n  include_tasks: \"{{ distro_file }}\"\n  with_first_found:\n  - files:\n    - gnome-{{ ansible_distribution }}.yml\n    skip: true\n  loop_control:\n    loop_var: distro_file\n  when:\n  - gnome_install|default(False)\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "4a392b2d612775403efe98eb8d30111760b24449", "filename": "roles/openvpn/templates/up_wan", "repository": "iiab/iiab", "decoded_content": "#!/bin/bash\n# if the wan has recently come up, see if we need to start openvpn\nsystemctl is-enabled openvpn\nif [ $? -eq 0 ]; then\n   pgrep openvpn\n   if [ $? -ne 0 ]; then\n      systemctl start openvpn@xscenet\n   fi\nfi\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "0b1f25eaa14b1f5d178c99f08148ae1c316b7218", "filename": "archive/roles/secure-registry/tasks/main.yaml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n  - name: Create temp directory for kubeconfig\n    command: mktemp -d /tmp/openshift-ansible-XXXXXX\n    register: mktemp\n    changed_when: False\n    delegate_to: \"{{ secure_registry_master_host }}\"\n    run_once: true\n\n  - name: Copy the admin client config(s)\n    command: >\n      cp {{ openshift_master_config_dir }}/admin.kubeconfig {{ mktemp.stdout }}/admin.kubeconfig\n    changed_when: False\n    delegate_to: \"{{ secure_registry_master_host }}\"\n    run_once: true\n\n  - name: \"Check that Openshift Docker Registry exists\"\n    command: >\n      {{ openshift.common.client_binary }} --config={{ mktemp.stdout }}/admin.kubeconfig get deploymentConfig {{ registry_dc }}\n       -n {{ openshift_registry_project }}\n    register: registry_exists\n    delegate_to: \"{{ secure_registry_master_host }}\"\n    run_once: true\n\n  - fail:\n      msg: \"No docker registry found in project default\"\n    when: registry_exists.rc != 0\n    run_once: true\n    delegate_to: \"{{ secure_registry_master_host }}\"\n\n  - fail:\n      msg: \"Both registry_certificate and registry_key must be set, or neither\"\n    when: (registry_certificate == \"\" and registry_key != \"\") or (registry_certificate != \"\" and registry_key == \"\")\n    delegate_to: \"{{ secure_registry_master_host }}\"\n    run_once: true\n\n  - name: \"Collect registry service info\"\n    command: >\n      {{ openshift.common.client_binary}} get service {{ docker_registry_dc_name}}\n       -n {{ openshift_registry_project }} -o yaml\n    register: registry_svc_info\n    run_once: true\n    delegate_to: \"{{ secure_registry_master_host }}\"\n\n  - set_fact:\n      registry_svc_ip: \"{{ (registry_svc_info.stdout | from_yaml).spec.clusterIP }}\"\n    run_once: true\n    delegate_to: \"{{ secure_registry_master_host }}\"\n\n  - set_fact:\n      registry_svc_ports: [\"{{item.port}}\"]\n    with_items: \"{{ (registry_svc_info.stdout | from_yaml).spec.ports}}\"\n    run_once: true\n    delegate_to: \"{{ secure_registry_master_host }}\"\n\n  - name: \"Check if registry is already secured\"\n    uri:\n      url: \"https://{{ registry_svc_ip }}:5000\"\n      method: \"GET\"\n      status_code: '200'\n      validate_certs: no\n    run_once: true\n    delegate_to: \"{{ secure_registry_master_host }}\"\n    register: secured\n    failed_when: false\n\n  - fail:\n      msg: \"The registry is already secured\"\n    when: secured.status == 200\n    run_once: true\n    delegate_to: \"{{ secure_registry_master_host }}\"\n\n  - name: \"Creating certificate...\"\n    command: \"{{ openshift.common.admin_binary}} ca create-server-cert --signer-cert={{ openshift_master_config_dir }}/ca.crt \\\n        --signer-key={{ openshift_master_config_dir }}/ca.key \\\n        --signer-serial={{ openshift_master_config_dir }}/ca.serial.txt \\\n        --hostnames='docker-registry.default.svc.cluster.local,{{registry_svc_ip}}' \\\n        --cert=/etc/secrets/registry.crt \\\n        --key=/etc/secrets/registry.key\"\n    when: registry_certificate == \"\" and registry_key == \"\"\n    run_once: true\n    delegate_to: \"{{ secure_registry_master_host }}\"\n    args:\n      creates: '/etc/secrets/registry.crt'\n    register: cert_created\n\n  - set_fact:\n      registry_certificate: '/etc/secrets/registry.crt'\n    when: registry_certificate == \"\" and registry_key == \"\"\n    run_once: true\n    delegate_to: \"{{ secure_registry_master_host }}\"\n\n  - set_fact:\n      registry_key: '/etc/secrets/registry.key'\n    when: registry_certificate == \"/etc/secrets/registry.crt\" and registry_key == \"\"\n    run_once: true\n    delegate_to: \"{{ secure_registry_master_host }}\"\n\n  - set_fact:\n      registry_ca: '/etc/origin/master/ca.crt'\n    when: registry_ca == \"\"\n    run_once: true\n    delegate_to: \"{{ secure_registry_master_host }}\"\n\n  - name: \"Cleaning up any previous attempts\"\n    command: >\n      {{openshift.common.client_binary}} delete secrets {{registry_secret_name}}\n       -n {{openshift_registry_project}}\n    run_once: true\n    delegate_to: \"{{ secure_registry_master_host }}\"\n    register: cleanup\n    failed_when: cleanup.rc != 0 and cleanup.rc != 1\n\n  - name: \"Creating registry secret\"\n    command: >\n      {{openshift.common.client_binary}} secrets new {{registry_secret_name}}\n       {{registry_certificate}} {{registry_key}} -n {{openshift_registry_project}}\n    run_once: true\n    delegate_to: \"{{ secure_registry_master_host }}\"\n\n  - name: \"Adding secrets to registry's service account\"\n    command: >\n      {{openshift.common.client_binary}} secrets add\n      serviceaccounts/{{registry_serviceaccount}} secrets/{{registry_secret_name}}\n       -n {{openshift_registry_project}}\n    run_once: true\n    delegate_to: \"{{ secure_registry_master_host }}\"\n\n  - name: \"Adding secrets to default account\"\n    command: >\n      {{openshift.common.client_binary}} secrets add serviceaccounts/default\n      secrets/{{registry_secret_name}} -n {{openshift_registry_project}}\n    run_once: true\n    delegate_to: \"{{ secure_registry_master_host }}\"\n\n  - name: \"Ceanup any previous runs\"\n    shell: \"{{openshift.common.client_binary}} get deploymentConfig/{{registry_dc}} -n {{openshift_registry_project}} -o yaml | grep {{registry_secret_name}}\"\n    run_once: true\n    delegate_to: \"{{ secure_registry_master_host }}\"\n    register: dc_cleanup\n    failed_when: dc_cleanup.rc != 0  and dc_cleanup.rc != 1\n\n\n  - name: \"Disable DeploymentConfig change triggger\"\n    command: \"{{openshift.common.client_binary}} patch deploymentConfig/{{registry_dc}} --api-version=v1 -p '{{registry_trigger_disable}}' -n {{openshift_registry_project}}\"\n    run_once: true\n    delegate_to: \"{{ secure_registry_master_host }}\"\n\n\n  - name: \"Add secret volumes to registry deploymentConfiguration\"\n    command: >\n      {{openshift.common.client_binary}} volume deploymentConfig/{{registry_dc}}\n      --add --type=secret --secret-name={{registry_secret_name}} -m /etc/secrets\n      --overwrite -n {{openshift_registry_project}}\n    run_once: true\n    delegate_to: \"{{ secure_registry_master_host }}\"\n    when: dc_cleanup.rc == 0\n\n  - name: \"Add secret volumes to registry deploymentConfiguration\"\n    command: >\n      {{openshift.common.client_binary}} volume deploymentConfig/{{registry_dc}}\n       --add --type=secret --secret-name={{registry_secret_name}} -m /etc/secrets\n       -n {{openshift_registry_project}}\n    run_once: true\n    delegate_to: \"{{ secure_registry_master_host }}\"\n    when: dc_cleanup.rc == 1\n\n  - name: \"Enable TLS\"\n    command: >\n      {{openshift.common.client_binary}} env deploymentConfig/{{registry_dc}}\n       REGISTRY_HTTP_TLS_CERTIFICATE={{registry_certificate}}\n        REGISTRY_HTTP_TLS_KEY={{registry_key}} --overwrite\n       -n {{openshift_registry_project}}\n    run_once: true\n    delegate_to: \"{{ secure_registry_master_host }}\"\n\n  - name: \"Updating liveness probe to HTTPS scheme\"\n    command: \"{{openshift.common.client_binary}} patch deploymentConfig/{{registry_dc}} --api-version=v1 -p '{{liveness_patch}}' -n {{openshift_registry_project}}\"\n    run_once: true\n    delegate_to: \"{{ secure_registry_master_host }}\"\n\n  - name: \"Updating readinessProbe to HTTPS scheme\"\n    command: \"{{openshift.common.client_binary}} patch deploymentConfig/{{registry_dc}} --api-version=v1 -p '{{readiness_patch}}' -n {{openshift_registry_project}}\"\n    run_once: true\n    delegate_to: \"{{ secure_registry_master_host }}\"\n    when: \"{{openshift.common.version_gte_3_2_or_1_2}}\"\n\n  - name: \"Create registry certificates directory for serviceIP\"\n    file: \"state=directory path=/etc/docker/certs.d/{{registry_svc_ip}}:{{item}} mode=755\"\n    with_items: \"{{registry_svc_ports}}\"\n\n  - name: \"Create registry certificates directory for kubernetes service\"\n    file: \"state=directory path=/etc/docker/certs.d/{{registry_dc}}.default.svc.cluster.local:{{item}} mode=755\"\n    with_items: \"{{registry_svc_ports}}\"\n\n  - name: Grab CA cert\n    slurp:\n      src: \"{{registry_ca}}\"\n    register: registry_ca_file\n    run_once: true\n    delegate_to: \"{{ secure_registry_master_host }}\"\n\n  - name: \"Copy registry CA cert to kubernetes service directory\"\n    copy:\n      content: \"{{ registry_ca_file.content | b64decode }}\"\n      dest: \"/etc/docker/certs.d/{{registry_dc}}.default.svc.cluster.local:{{item}}/ca.crt\"\n    with_items: \"{{registry_svc_ports}}\"\n\n  - name: \"Copy registry CA cert to registry IP directory\"\n    copy:\n      content: \"{{ registry_ca_file.content | b64decode }}\"\n      dest: \"/etc/docker/certs.d/{{registry_svc_ip}}:{{item}}/ca.crt\"\n    with_items: \"{{registry_svc_ports}}\"\n\n\n  - name: \"Remove --insecure flag from /etc/sysconfig/docker\"\n    lineinfile:\n      dest: /etc/sysconfig/docker\n      state: absent\n      regexp: '--insecure-registry=.*172\\.30\\.0\\.0/16'\n\n  - name: \"Remove INSECURE_REGISTRY flag from /etc/sysconfig/docker\"\n    lineinfile:\n      dest: /etc/sysconfig/docker\n      state: absent\n      regexp: 'INSECURE_REGISTRY=\\\"--insecure-registry 172\\.30\\.0\\.0/16\\\"'\n\n  - name: \"Reload daemon\"\n    command: \"systemctl daemon-reload\"\n\n  - name: \"Restart docker\"\n    service: \"name=docker state=restarted\"\n\n  - name: \"Re-enable DeploymentConfig change triggger\"\n    command: \"{{openshift.common.client_binary}} patch deploymentConfig/{{registry_dc}} --api-version=v1 -p '{{registry_trigger_enable}}' -n {{openshift_registry_project}}\"\n    run_once: true\n    delegate_to: \"{{ secure_registry_master_host }}\"\n\n"}, {"commit_sha": "79e29502fb4e0ff1c30c0b5396bfa1b48fb84a8e", "sha": "9a0395f4b32444006e3d95ed99737895f1d77d10", "filename": "tasks/options.yml", "repository": "Oefenweb/ansible-wordpress", "decoded_content": "# tasks file for wordpress, options\n---\n- name: add options\n  command: \"wp-cli --allow-root --no-color --path='{{ item.0.path }}' option {{ item.1.command }} '{{ item.1.name }}' '{{ item.1.value }}'\"\n  register: check_installation_options\n  failed_when: False\n  changed_when: \"'Added' in check_installation_options.stdout\"\n  with_subelements:\n    - wordpress_installs\n    - options\n  when: item.1.command == 'add'\n  tags: [configuration, wordpress, wordpress-options]\n\n- name: update options\n  command: \"wp-cli --allow-root --no-color --path='{{ item.0.path }}' option {{ item.1.command }} '{{ item.1.name }}' '{{ item.1.value }}'\"\n  register: check_installation_options\n  changed_when: \"'unchanged' not in check_installation_options.stdout\"\n  with_subelements:\n    - wordpress_installs\n    - options\n  when: item.1.command == 'update'\n  tags: [configuration, wordpress, wordpress-options]\n\n- name: delete options\n  command: \"wp-cli --allow-root --no-color --path='{{ item.0.path }}' option {{ item.1.command }} '{{ item.1.name }}'\"\n  register: check_installation_options\n  failed_when: False\n  changed_when: \"'Could not delete' not in check_installation_options.stderr\"\n  with_subelements:\n    - wordpress_installs\n    - options\n  when: item.1.command == 'delete'\n  tags: [configuration, wordpress, wordpress-options]\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "9115ef9fb36f874be67a63363240be34825f2fea", "filename": "tasks/section_03.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - include: section_03_level1.yml\n    tags:\n      - section03\n      - level1\n\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "379c8cfac2c83d9baef1c66e84242062d12297a9", "filename": "roles/memcached/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Install memcached\n  apt:\n    name: \"{{ item }}\"\n    state: present\n    update_cache: yes\n  with_items:\n  - memcached\n  - php-memcached\n\n- name: Copy the client configuration file\n  template:\n    src: memcached.conf.j2\n    dest: /etc/memcached.conf\n  notify: restart memcached\n\n- name: Set the max open file descriptors\n  sysctl:\n    name: fs.file-max\n    value: \"{{ memcached_fs_file_max }}\"\n    state: present\n\n- name: Start the memcached service\n  service:\n    name: memcached\n    state: started\n    enabled: yes\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "72cfdcad0e57931884baedba6e81399dde19d195", "filename": "roles/zookeeper/tasks/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n\n# Generate config files in the host\n- name: create zookeeper config directory\n  file:\n    path: \"{{ zookeeper_config_dir }}\"\n    state: directory\n    follow: yes\n    mode: 0755\n  sudo: yes\n  tags:\n    - zookeeper\n\n- name: Create zookeeper config file\n  template:\n    src: zoo.cfg.j2\n    dest: \"{{ zookeeper_config_dir }}/zoo.cfg\"\n  sudo: yes\n  notify:\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: Create zookeeper environments file\n  template:\n    src: environment.j2\n    dest: \"{{ zookeeper_config_dir }}/environment\"\n  sudo: yes\n  notify:\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: Create zookeeper configuration.xsl file\n  template:\n    src: configuration.xsl.j2\n    dest: \"{{ zookeeper_config_dir }}/configuration.xsl\"\n  sudo: yes\n  notify:\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: Create zookeeper myid file\n  copy:\n    content: \"{{ zookeeper_id }}\"\n    dest: \"{{ zookeeper_config_dir }}/myid\"\n    mode: 0644\n  sudo: yes\n  notify:\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: Create zookeeper log4j file\n  template:\n    src: log4j.properties.j2\n    dest: \"{{ zookeeper_config_dir }}/log4j.properties\"\n  sudo: yes\n  notify:\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: Set Zookeeper consul service definition\n  sudo: yes\n  template:\n    src: zookeeper-consul.j2\n    dest: \"{{ consul_dir }}/zookeeper.json\"\n  notify:\n    - restart consul\n  tags:\n    - zookeeper\n\n- name: run zookeeper container\n  docker:\n    name: zookeeper\n    image: \"{{ zookeeper_image }}\"\n    state: started\n    volumes:\n    - \"{{ zookeeper_config_dir }}/:{{ zookeeper_config_dir }}/\"\n    ports:\n    - \"{{ zookeeper_client_port }}:{{ zookeeper_client_port }}\"\n    - \"{{ zookeeper_leader_connect_port }}:{{ zookeeper_leader_connect_port }}\"\n    - \"{{ zookeeper_leader_election_port }}:{{ zookeeper_leader_election_port }}\"\n    net: \"host\"\n    command: /usr/share/zookeeper/bin/zkServer.sh start-foreground\n  tags:\n    - zookeeper\n\n- name: upload zookeeper template service\n  template:\n    src: zookeeper.conf.j2\n    dest: /etc/init/zookeeper.conf\n    mode: 0755\n  sudo: yes\n  tags:\n    - zookeeper\n\n- name: ensure zookeeper is running (and enable it at boot)\n  sudo: yes\n  service:\n    name: zookeeper\n    state: started\n    enabled: yes\n  tags:\n    - zookeeper\n\n"}, {"commit_sha": "4e46e9eb277bc88f285dbc9dd980193e57f7bf48", "sha": "8c8ff044409886d99dbd09b6e67b69c7c5d55fc5", "filename": "tasks/main.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Set distribution facts\n  set_fact:\n    _docker_os_dist: \"{{ ansible_distribution }}\"\n    _docker_os_dist_release: \"{{ ansible_distribution_release }}\"\n    _docker_os_dist_major_version: \"{{ ansible_distribution_major_version }}\"\n    _docker_os_dist_check: yes\n  tags: [\"install\", \"configure\"]\n\n- name: Reinterpret distribution facts for Linux Mint 18\n  set_fact:\n    _docker_os_dist: \"Ubuntu\"\n    _docker_os_dist_release: \"xenial\"\n    _docker_os_dist_major_version: \"16\"\n  when:\n    _docker_os_dist == \"Linux Mint\" and\n    _docker_os_dist_major_version == \"18\"\n  tags: [\"install\", \"configure\"]\n\n# https://wiki.ubuntu.com/SystemdForUpstartUsers\n# Important! systemd is only fully supported in Ubuntu 15.04 and later releases\n- name: Determine usage of systemd\n  shell: \"ps -p1 | grep systemd 1>/dev/null && echo systemd || echo upstart\"\n  become: true\n  changed_when: no  \n  register: _determine_systemd_usage\n\n- name: Set fact to indicate systemd is not used\n  set_fact:\n    _docker_systemd_used: \"{{ _determine_systemd_usage is defined and _determine_systemd_usage.stdout == 'systemd' }}\"\n\n- name: Compatibility and distribution checks\n  include_tasks: checks.yml\n  tags: [\"install\", \"configure\"]\n\n- name: Setup Docker package repositories\n  include_tasks: setup-repository.yml\n  tags: [\"install\"]\n\n- name: Remove Docker versions before Docker CE\n  include_tasks: remove-pre-docker-ce.yml\n  when: docker_remove_pre_ce | bool\n  tags: [\"install\"]\n\n- name: Install Docker\n  include_tasks: install-docker.yml\n  tags: [\"install\"]\n\n- name: Configure audit logging\n  include_tasks: setup-audit.yml\n  tags: [\"configure\"]\n\n- name: Apply workarounds for bugs and/or tweaks\n  include_tasks: bug-tweaks.yml\n  tags: [\"configure\"]\n\n- name: Configure systemd service\n  include_tasks: configure-systemd.yml\n  when: _docker_systemd_used | bool  \n  tags: [\"configure\"]\n\n- name: Configure non-systemd service\n  include_tasks: configure-non-systemd.yml\n  when: _docker_systemd_used | bool == false \n  tags: [\"configure\"]\n\n- name: Configure Docker\n  include_tasks: configure-docker.yml\n  tags: [\"configure\"]\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "806da01147d99bbb8a5e127667ff1e385103e5ed", "filename": "roles/scm/add-webhooks-github/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- hosts: webhooks-server\n  tasks:\n    - include_role:\n        name: \"{{ playbook_dir }}/../../add-webhooks-github\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a00d2a82699da1f10fe1ea2a569937e0666d5db2", "filename": "roles/ansible/tower/manage-inventories/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: tower\n  roles:\n  - role: ansible/tower/manage-inventories\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "8fa123bd242f6c2e7df86d1643952dc970d76ad6", "filename": "roles/config-postgresql/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Restart PostgreSQL Service\n  systemd:\n    name: \"{{ postgresql_service }}\"\n    enabled: yes\n    state: restarted\n    daemon_reload: yes\n\n- name: restart firewalld\n  service:\n    name: firewalld\n    state: restarted"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "539fe307207767300111e957c355ae4139843ad7", "filename": "roles/deploy/tasks/update.yml", "repository": "roots/trellis", "decoded_content": "---\n- include: \"{{ deploy_update_before | default('../hooks/example.yml') }}\"\n  tags: deploy-update-before\n\n- name: Check whether project source path is a git repo\n  stat:\n    path: \"{{ project_source_path }}/.git\"\n  register: git_project\n\n- name: Get current git remote URL\n  command: git config --get remote.origin.url\n  args:\n    chdir: \"{{ project_source_path }}\"\n  register: remote_origin_url\n  when: git_project.stat.exists\n  changed_when: false\n\n- name: Update git remote URL\n  command: git remote set-url origin {{ project_git_repo }}\n  args:\n    chdir: \"{{ project_source_path }}\"\n  when: git_project.stat.exists and remote_origin_url.stdout != project_git_repo\n\n- name: Clone project files\n  git:\n    repo: \"{{ project_git_repo }}\"\n    dest: \"{{ project_source_path }}\"\n    version: \"{{ project_version }}\"\n    accept_hostkey: yes\n  ignore_errors: true\n  no_log: true\n  register: git_clone\n\n- name: Failed connection to remote repo\n  fail:\n    msg: |\n      Git repo {{ project.repo }} cannot be accessed. Please verify the repository exists and you have SSH forwarding set up correctly.\n      More info:\n      > https://roots.io/trellis/docs/deploys/#ssh-keys\n      > https://roots.io/trellis/docs/ssh-keys/#cloning-remote-repo-using-ssh-agent-forwarding\n  when: git_clone | failed\n\n- include: \"{{ deploy_update_after | default('../hooks/example.yml') }}\"\n  tags: deploy-update-after\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "20df1cf54c91f12ada571584a10e4e5606df7b5c", "filename": "roles/disconnected-git/tasks/main.yaml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- name: Install Packages\n  action: \"{{ ansible_pkg_mgr }} name={{ item }} state=present\"\n  with_items:\n    - git\n    - httpd\n    - firewalld\n    - libsemanage-python\n    \n- name: Create Git User\n  user: name=\"{{ git_user }}\"\n\n- name: Create Git User Authorized Keys\n  authorized_key:\n    user: \"{{ git_user}}\"\n    key: \"{{ item }}\"\n  with_items:\n    - \"{{ git_user_authorized_keys }}\"\n  \n- name: Create OSE Git Repository Content Home\n  file:\n    path: \"{{ item }}\"\n    state: directory\n    owner: \"{{ git_user }}\"\n    group: \"{{ git_user }}\"\n  with_items:\n    - \"{{ git_repo_home }}\"\n    - \"{{ ose_git_repo_home }}\"\n\n- name: Clone OSE Examples\n  git:\n    repo: \"{{ item }}\"\n    bare: yes\n    dest: \"{{ ose_git_repo_home }}/{{ item | basename }}\"\n  with_items:\n    - \"{{ ose_example_repos }}\"\n  tags: test\n  become: yes\n  become_user: \"{{ git_user }}\"\n  \n- name: Configure Git HTTP Configuration\n  template:\n    src: \"{{ role_path }}/templates/git.conf.j2\"\n    dest: \"/etc/httpd/conf.d/git.conf\"\n    owner: root\n    group: root\n  notify: restart httpd\n\n- name: Enable Services\n  service: name={{ item }} enabled=yes state=started   \n  with_items:\n    - firewalld\n    - httpd \n    \n- name: HTTPD SELinux Configurations\n  seboolean: \n    name: httpd_can_network_connect\n    state: yes\n    persistent: yes\n\n- name: Open Firewall for HTTPD\n  firewalld: port=80/tcp permanent=yes state=enabled immediate=yes zone=public\n  \n\n\n  "}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "57e665067915b9e9326b0c009f70260da53ee0a6", "filename": "roles/scm/gitlab.com/tests/inventory/group_vars/all.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "gitlab_api_private_token: !vault |\n          $ANSIBLE_VAULT;1.1;AES256\n          33396164373338656334643933303237616561663430343438643934363635363765626432636466\n          33396164373338656334643933303237616561663430343438643934363635363765626432636466\n          33396164373338656334643933303237616561663430343438643934363635363765626432636466\n          33396164373338656334643933303237616561663430343438643934363635363765626432636466\n          64363839383162313735303333396661303161323962656438373538313431373934\n\ngroup:\n  name: a-gitlab-org\n\nprojects:\n- repo_name: test-ci-cd\n  deploy_key_location: \"{{ lookup('file', './files/test-1.pub') }}\"\n  import_url: https://github.com/rht-labs/labs-ci-cd.git\n- repo_name: test-app\n  import_url: https://github.com/rht-labs/labs-ci-cd.git\n  deploy_key_location: \"{{ lookup('file', './files/test-2.pub') }}\"\n\nusers:\n# ONLY NUMERICAL USER ID VALUES, DO NOT ADD YOURSELF, YOU ALREADY OWN THE GROUP\n- id: 9999999 #someRealGitlabUserId"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "796d07f75d90ed330cb958b6f99009d6edad660c", "filename": "roles/deploy/hooks/example.yml", "repository": "roots/trellis", "decoded_content": "# This is a placeholder example hook file\n# To use deploy hooks, please refer to the docs at https://roots.io/trellis/docs/deploys\n#\n# tl;dr\n#   1. create a tasks file you wish to include on a certain hook\n#   2. set one of the below hook variables to \"{{ playbook_dir }}/path/to/tasks-file.yml\" in `deploy.yml`\n#\n#  Available hooks:\n#    - deploy_before\n#    - deploy_initialize_before\n#    - deploy_initialize_after\n#    - deploy_update_before\n#    - deploy_update_after\n#    - deploy_prepare_before\n#    - deploy_prepare_after\n#    - deploy_build_before\n#    - deploy_build_after\n#    - deploy_share_before\n#    - deploy_share_after\n#    - deploy_finalize_before\n#    - deploy_finalize_after\n#    - deploy_after\n"}, {"commit_sha": "f92ebbef856e59bd4563d4b5b69ee75a95ec89d5", "sha": "f62f13c069bf4d25ab456d26b83416493870a466", "filename": "roles/openshift-management/defaults/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\nopenshift_token:\nopenshift_master_url: localhost\nopenshift_login_insecure_flag: --insecure-skip-tls-verify=true\nopenshift_login_insecure: False\nopenshift_prune_builds_complete: 5\nopenshift_prune_builds_failed: 1\nopenshift_prune_builds_keep_younger: 1h0m0s\nopenshift_prune_deployments_complete: 5\nopenshift_prune_deployments_failed: 1\nopenshift_prune_deployments_keep_younger: 1h0m0s\nopenshift_prune_images_tag_revisions: 3\nopenshift_prune_images_keep_younger: 1h0m0s\nopenshift_prune_projects_keep_younger: 24 # 24 hrs by default\nopenshift_prune_projects_user_excludes: []\nopenshift_prune_projects_system_excludes: ['default', 'management-infra', 'openshift', 'openshift-infra', 'kube-system', 'logging']\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "fb31c23d3bc5f4bfda782b868e8a25f7594f5f6b", "filename": "roles/network/tasks/NM.yml", "repository": "iiab/iiab", "decoded_content": "- name: restart NetworkManager services\n  service: name=NetworkManager\n           enabled=yes\n           state=stopped\n- service: name=NetworkManager-dispatcher\n           enabled=yes\n           state=stopped\n- wait_for: path=/etc/passwd\n            delay=4\n            timeout=5\n- service: name=NetworkManager\n           enabled=yes\n           state=started\n- wait_for: path=/etc/passwd\n            delay=4\n            timeout=5\n- service: name=NetworkManager-dispatcher\n           enabled=yes\n           state=started\n- debug:  msg=\"hopefully now NM is restarted\"\n"}, {"commit_sha": "f3dd45a61b08de1b3351140cc442a705cb2fad82", "sha": "ae644edfc69ef0c637a85ce59777ae10e8b1cd6c", "filename": "tasks/fail2ban-Debian.yml", "repository": "geerlingguy/ansible-role-security", "decoded_content": "---\n- name: Install fail2ban.\n  package: name=fail2ban state=present\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "60c00767d65928744d7fde6fd125254bf4bfadc4", "filename": "roles/wordpress-setup/tasks/nginx.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Copy SSL cert\n  copy:\n    src: \"{{ item.value.ssl.cert }}\"\n    dest: \"{{ nginx_ssl_path }}/{{ item.value.ssl.cert | basename }}\"\n    mode: 0640\n  with_dict: \"{{ wordpress_sites }}\"\n  when: item.value.ssl.enabled and item.value.ssl.cert is defined\n\n- name: Copy SSL key\n  copy:\n    src: \"{{ item.value.ssl.key }}\"\n    dest: \"{{ nginx_ssl_path }}/{{ item.value.ssl.key | basename }}\"\n    mode: 0600\n  with_dict: \"{{ wordpress_sites }}\"\n  when: item.value.ssl.enabled and item.value.ssl.key is defined\n\n- name: Create includes.d directories\n  file:\n    path: \"{{ nginx_path }}/includes.d/{{ item }}\"\n    state: directory\n    mode: 0755\n  with_items: \"{{ wordpress_sites.keys() }}\"\n  register: nginx_includes_paths\n\n- name: Template files out to includes.d\n  template:\n    src: \"includes.d/{{ item }}\"\n    dest: \"{{ nginx_path }}/includes.d/{{ item[:-3] }}\"\n  with_lines: \"cd {{ role_path }}/templates/includes.d && find {{ wordpress_sites.keys() | join(' ') }} -type f -name \\\\*.conf.j2 2>/dev/null || :\"\n  register: nginx_includes_managed\n  notify: reload nginx\n\n- name: Retrieve list of existing files in includes.d\n  shell: \"find {{ nginx_includes_paths.results | map(attribute='path') | join(' ') }} -type f -name \\\\*.conf 2>/dev/null || :\"\n  register: nginx_includes_existing\n  changed_when: false\n\n- name: Remove unmanaged files from includes.d\n  file:\n    path: \"{{ item }}\"\n    state: absent\n  with_items: \"{{ nginx_includes_existing.stdout_lines |\n                  difference(nginx_includes_managed.results | default([]) | map(attribute='item') |\n                    map('regex_replace', '(.*)\\\\.j2', '/etc/nginx/includes.d/\\\\1') | list\n                  )\n               }}\"\n  notify: reload nginx\n\n- name: Create WordPress configuration for Nginx\n  template:\n    src: \"wordpress-site.conf.j2\"\n    dest: \"{{ nginx_path }}/sites-available/{{ item.key }}.conf\"\n  with_dict: \"{{ wordpress_sites }}\"\n  notify: reload nginx\n\n- name: Enable WordPress site\n  file:\n    src: \"{{ nginx_path }}/sites-available/{{ item.key }}.conf\"\n    dest: \"{{ nginx_path }}/sites-enabled/{{ item.key }}.conf\"\n    owner: root\n    group: root\n    state: link\n  with_dict: \"{{ wordpress_sites }}\"\n\n- name: test nginx conf\n  command: nginx -t\n  changed_when: false\n\n- name: trigger nginx reload\n  service:\n    name: nginx\n    state: reloaded\n  changed_when: false\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "3dafed891f34957be81df12d11d04e557ed01bfc", "filename": "roles/load-balancers/manage-haproxy/tasks/install.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- block:\n\n  - name: 'Install required packages'\n    package:\n      name: '{{ item }}'\n      state: installed\n    with_items:\n    - haproxy\n    - openssl-devel\n    - firewalld\n    - python-firewall\n    - libsemanage-python\n    - policycoreutils-python\n    notify: 'enable and start service(s)'\n\n  - name: 'Start firewalld'\n    service:\n      name: firewalld\n      state: started\n      enabled: yes\n\n  - name: 'Enable syslog logging'\n    copy:\n      src: rsyslog_haproxy.conf\n      dest: /etc/rsyslog.d/haproxy.conf\n    notify: 'restart rsyslog'\n\n  become: True\n"}, {"commit_sha": "f958689395b3fc98cacf0c605ed7b8b4b19718da", "sha": "6d7fbb2794df0c3da00e0e1e8039f471d811d641", "filename": "tasks/check_mandatory_vars.yml", "repository": "lae/ansible-role-netbox", "decoded_content": "---\n- name: Ensure installation scenario is selected\n  fail:\n    msg: \"Please choose either the stable or git scenario.\"\n  when:\n    - not netbox_stable\n    - not netbox_git\n\n- name: Ensure only one scenario is enabled\n  fail:\n    msg: \"Please select only one scenario.\"\n  when:\n    - netbox_stable and netbox_git\n\n- name: Ensure a DB connection method is defined\n  fail:\n    msg: \"Please define either database_socket (local) or database_host/database_password (TCP).\"\n  when:\n    - netbox_database_socket is not defined\n    - netbox_database_host is not defined or (netbox_database_host is defined and netbox_database_password is not defined)\n\n- name: Ensure only one DB connection method is defined\n  fail:\n    msg: \"Please define only one database connection method.\"\n  when:\n    - netbox_database_socket is defined and netbox_database_host is defined\n\n- name: Ensure Python version is valid\n  fail:\n    msg: \"Please set netbox_python to either 2 or 3.\"\n  when:\n    - netbox_python not in [2, 3]\n"}, {"commit_sha": "f92ebbef856e59bd4563d4b5b69ee75a95ec89d5", "sha": "fbc386ff441a9402f1ff2a8814d889417bebd222", "filename": "roles/openshift-management/handlers/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n- name: cleanup openshift login\n  file: path=\"{{ kubeconfig | dirname }}\" state=absent"}, {"commit_sha": "7032aee7df1c2c6e96795067285efa3b2a6de32e", "sha": "bb45445f538826dea96d2013058ac512b71a6fb8", "filename": "roles/hostnames/tasks/main.yaml", "repository": "openshift/openshift-ansible-contrib", "decoded_content": "---\n- name: Setting Hostname Fact\n  set_fact:\n    new_hostname: \"{{ custom_hostname | default(inventory_hostname) }}\"\n\n- name: Setting FQDN Fact\n  set_fact:\n    new_fqdn: \"{{ new_hostname }}.{{ dns_domain }}\"\n\n- name: Setting hostname and DNS domain\n  hostname: name=\"{{ new_fqdn }}\"\n\n- name: Check for cloud.cfg\n  stat: path=/etc/cloud/cloud.cfg\n  register: cloud_cfg\n\n- name: Prevent cloud-init updates of hostname/fqdn (if applicable)\n  lineinfile: \n    dest: /etc/cloud/cloud.cfg \n    state: present\n    regexp: \"{{ item.regexp }}\"\n    line: \"{{ item.line }}\"\n  with_items:\n    - { regexp: '^ - set_hostname', line: '# - set_hostname' }\n    - { regexp: '^ - update_hostname', line: '# - update_hostname' }\n  when: cloud_cfg.stat.exists == True\n"}, {"commit_sha": "045ff4bb9f4720739632aac2951fbf2798a99c8c", "sha": "c5b69971105752f1f114ccded912d750e6074c0f", "filename": "roles/client/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: Gather Facts\n  setup:\n\n- name: Include system based facts and tasks\n  include: systems/main.yml\n\n- name: Cheking the signature algorithm\n  local_action: >\n      shell openssl x509 -text -in certs/{{ IP_subject_alt_name }}.crt  | grep 'Signature Algorithm' | head -n1\n  become: no\n  register: sig_algo\n  args:\n    chdir: \"configs/{{ IP_subject_alt_name }}/pki/\"\n\n- name: Change the algorithm to RSA\n  set_fact:\n    Win10_Enabled: \"Y\"\n  when: '\"ecdsa\" not in sig_algo.stdout'\n\n- name: Install prerequisites\n  package: name=\"{{ item }}\" state=present\n  with_items:\n    - \"{{ prerequisites }}\"\n\n- name: Install StrongSwan\n  package: name=strongswan state=present\n\n- name: Setup the ipsec config\n  template:\n    src: \"roles/vpn/templates/client_ipsec.conf.j2\"\n    dest: \"{{ configs_prefix }}/ipsec.{{ IP_subject_alt_name }}.conf\"\n    mode: '0644'\n  with_items:\n    - \"{{ vpn_user }}\"\n  notify:\n    - restart strongswan\n\n- name: Setup the ipsec secrets\n  template:\n    src: \"roles/vpn/templates/client_ipsec.secrets.j2\"\n    dest: \"{{ configs_prefix }}/ipsec.{{ IP_subject_alt_name }}.secrets\"\n    mode: '0600'\n  with_items:\n    - \"{{ vpn_user }}\"\n  notify:\n    - restart strongswan\n\n- name: Include additional ipsec config\n  lineinfile:\n    dest: \"{{ item.dest }}\"\n    line: \"{{ item.line }}\"\n    create: yes\n  with_items:\n    - dest: \"{{ configs_prefix }}/ipsec.conf\"\n      line: \"include ipsec.*.conf\"\n    - dest: \"{{ configs_prefix }}/ipsec.secrets\"\n      line: \"include ipsec.*.secrets\"\n  notify:\n    - restart strongswan\n\n- name: Setup the certificates and keys\n  template:\n    src: \"{{ item.src }}\"\n    dest: \"{{ item.dest }}\"\n  with_items:\n    - src: \"configs/{{ IP_subject_alt_name }}/pki/certs/{{ vpn_user }}.crt\"\n      dest: \"{{ configs_prefix }}/ipsec.d/certs/{{ IP_subject_alt_name }}_{{ vpn_user }}.crt\"\n    - src: \"configs/{{ IP_subject_alt_name }}/pki/cacert.pem\"\n      dest: \"{{ configs_prefix }}/ipsec.d/cacerts/{{ IP_subject_alt_name }}.pem\"\n    - src: \"configs/{{ IP_subject_alt_name }}/pki/private/{{ vpn_user }}.key\"\n      dest: \"{{ configs_prefix }}/ipsec.d/private/{{ IP_subject_alt_name }}_{{ vpn_user }}.key\"\n  notify:\n    - restart strongswan\n"}, {"commit_sha": "481f7ad18dc225973e1d676d33e58c49cbbfe986", "sha": "a19f577b4b31ca25d01cdaf7ae75960bcb1ec991", "filename": "tasks/firewalld.yml", "repository": "openwisp/ansible-openwisp2", "decoded_content": "---\n\n- name: Enable firewalld\n  service:\n    name: firewalld\n    state: started\n    enabled: yes\n\n- name: Configure firewall\n  firewalld:\n    permanent: true\n    immediate: true\n    service: \"{{ item }}\"\n    state: enabled\n  with_items:\n    - http\n    - https\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "8eda7ca486ef6c49bb33f82dd560b405f3cbbe90", "filename": "roles/3-base-server/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Make sure there is a content directory\n  file: dest={{ doc_root }}/local_content\n        state=directory\n\n- name: Base Server Installed\n  command: echo Base Server Installed\n\n- name: Restart httpd\n  service: name={{ apache_service }}\n           state=restarted\n  when: not installing\n\n# If we got here we're done\n#- name: Record base gui version\n#  lineinfile: dest=/etc/iiab/iiab.env\n#              regexp='^BASE_VERSION=*'\n#              line='BASE_VERSION=\"{{ gui_version }}\"'\n#              state=present\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "94e49405f6b5b9331598226f228a69aec4452663", "filename": "roles/wordpress/meta/main.yml", "repository": "iiab/iiab", "decoded_content": "---\ndependencies:\n    - { role: mysql }\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "f01109633ac201fe8a0241ced637da2cb4faef0e", "filename": "playbooks/roles/bb0-openstack/tasks/deprovisioning.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "---\n- name: Delete instance\n  os_server:\n    api_timeout: 360 # Because my lab is not so fast\n    state: absent\n    auth:\n      auth_url: \"{{ lookup('env','OS_AUTH_URL') }}\"\n      project_name: \"{{ lookup('env','OS_PROJECT_NAME') }}\"\n      username: \"{{ lookup('env','OS_USERNAME') }}\"\n      password: \"{{ lookup('env','OS_PASSWORD') }}\"\n    name: \"{{ inventory_hostname }}\"\n\n- name: Delete container storage disk\n  os_volume:\n    state: absent\n    auth:\n      auth_url: \"{{ lookup('env','OS_AUTH_URL') }}\"\n      project_name: \"{{ lookup('env','OS_PROJECT_NAME') }}\"\n      username: \"{{ lookup('env','OS_USERNAME') }}\"\n      password: \"{{ lookup('env','OS_PASSWORD') }}\"\n    display_name: \"{{ inventory_hostname }}_container_storage_disk\"\n  when: ( iaas_container_storage_disk | int > 0 )\n\n- name: Delete glusterfs disk\n  os_volume:\n    state: absent\n    auth:\n      auth_url: \"{{ lookup('env','OS_AUTH_URL') }}\"\n      project_name: \"{{ lookup('env','OS_PROJECT_NAME') }}\"\n      username: \"{{ lookup('env','OS_USERNAME') }}\"\n      password: \"{{ lookup('env','OS_PASSWORD') }}\"\n    display_name: \"{{ inventory_hostname }}_glusterfs_disk\"\n  when: ( iaas_glusterfs_disk | int > 0 )\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "796ca4b9c423efbcee063b5340f82a7e321d6131", "filename": "roles/dns/manage-dns-zones-route53/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nroute53_processing: False\n\nttl: 300\n\naws_access_key: \"{{ lookup('env','AWS_ACCESS_KEY_ID') }}\"\naws_secret_key: \"{{ lookup('env','AWS_SECRET_ACCESS_KEY') }}\"\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "092959088f237d1e384c980a17fccc1a995ab1f0", "filename": "roles/dns/manage-dns-zones/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: prereq.yml\n- import_tasks: named/main.yml\n- import_tasks: route53/main.yml\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "fb12b245ecc4a6a007dba548d925b4b9ef2518fa", "filename": "roles/network/tasks/wondershaper.yml", "repository": "iiab/iiab", "decoded_content": "- name: copy wshaper service script\n  template: backup=yes\n            src=wondershaper/wondershaper.service\n            dest=/etc/systemd/system/wondershaper.service\n            mode=0644\n\n- name: copy wshaper script\n  template: backup=yes\n            src=wondershaper/wondershaper.j2\n            dest=/usr/bin/wondershaper\n            owner=root\n            group=root\n            mode=0744\n\n- name: create conf.d directory\n  file: path=/etc/conf.d\n        owner=root\n        group=root\n        mode=0755\n        state=directory\n\n- name: copy wshaper config script\n  template: src=wondershaper/wondershaper.conf\n            dest=/etc/conf.d/wondershaper.conf\n            owner=root\n            group=root\n            mode=0600\n\n- name: create fact for wondershaper config file\n  file: src=/etc/conf.d/wondershaper.conf\n        dest=/etc/ansible/facts.d/wondershaper.fact\n        owner=root\n        group=root\n        state=link\n\n- name: Add wondershaper to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=wondershaper\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: wondershaper\n    - option: description\n      value: '\"Wondershaper is a command line tool to set maximum transfer rates for network adapters\"'\n    - option: enabled\n      value: \"{{ wondershaper_enabled }}\"\n"}, {"commit_sha": "f92ebbef856e59bd4563d4b5b69ee75a95ec89d5", "sha": "1736949a26729b70b377be2d3d3bae82d0184d6a", "filename": "roles/openshift-applier/README.md", "repository": "redhat-cop/casl-ansible", "decoded_content": "# openshift-applier\n\nRole used to apply OpenShift objects to an existing OpenShift Cluster.\n\n<!-- TOC depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 -->\n\n- [openshift-applier](#openshift-applier)\n\t- [Requirements](#requirements)\n\t- [Role Usage](#role-usage)\n\t\t- [Sourcing OpenShift Object Definitions](#sourcing-openshift-object-definitions)\n\t\t- [Sourcing a directory with files](#sourcing-a-directory-with-files)\n\t\t- [Ordering of Objects in the inventory](#ordering-of-objects-in-the-inventory)\n\t\t- [Privileged Objects](#privileged-objects)\n\t\t- [Object Entries in the Inventory](#object-entries-in-the-inventory)\n\t\t- [Override default actions with `file_action` and `template_action`](#override-default-actions-with-fileaction-and-templateaction)\n\t\t- [Filtering content based on tags](#filtering-content-based-on-tags)\n\t\t- [Deprovisioning](#deprovisioning)\n\t\t- [Dependencies](#dependencies)\n\t- [Example Playbook](#example-playbook)\n\t- [License](#license)\n\t- [Author Information](#author-information)\n\n<!-- /TOC -->\n\n\n## Requirements\n\nA working OpenShift cluster that can be used to populate things like namespaces, policies and PVs (all require cluster-admin), or application level content (cluster-admin not required).\n\n\n## Role Usage\n\n### Sourcing OpenShift Object Definitions\n\nThe variable definitions come in the form of an object, `openshift_cluster_content`, which contains sub-objects containing file, template, and parameter definitions. At its simplest, this definition looks like this:\n\n```yaml\nopenshift_cluster_content:\n- galaxy_requirements: # Optional: only needed if pre/post steps are specified below\n    - \"path/to/galaxy/requirements.yml\" # Has to be a local file - e.g: with the inventory\n- object: <object_type>\n  pre_steps: # Optional: pre-steps at object level can be added if desired\n    - role: <path to an ansible role>\n  content:\n  - name: <definition_name>\n    pre_steps: # Optional: pre-steps at content level can be added if desired\n      - role: <path to an ansible role>\n        vars: # Optional: only needed if the role above needs values passed\n          <key1>: <value1>  \n    file: <file source>\n    file_action: <apply|create> # Optional: Defaults to 'apply'\n    tags: # Optional: Tags are only needed if `filter_tags` is used\n    - tag1\n    - tag2\n    post_steps: # Optional: post-steps at content level can be added if desired\n      - role: <path to an ansible role>\n  post_steps: # Optional: post-steps at object level can be added if desired\n    - role: <path to an ansible role>\n- object: <object_type>\n  content:\n  - name: <definition_name>\n    template: <template_source>\n    template_action: <apply|create> # Optional: Defaults to 'apply'\n    params: <params_file_source>\n    namespace: <target_openshift_namespace>\n```\n\nYou have the choice of sourcing a `file` or a `template`. The `file` definition expects that the sourced file has all definitions set and will NOT accept any parameters (i.e.: static content). The `template` definition expects a `params` file to be sourced along with it which will be passed into the template.\n\n**_TIP:_** Both choices give you the option of defining target namespaces in the template manually, or adding the `namespace` variable alongside the template and params (where applicable)\n\nThe `tags` definition is a list of tags that will be processed if the `filter_tags` variable/fact is supplied. See [Filtering content based on tags](https://github.com/redhat-cop/casl-ansible/tree/filter/roles/openshift-applier#filtering-content-based-on-tags) below for more details.\n\nThe pre/post definitions are a set of pre and post roles to execute before/after a particular portion of the inventory is applied. This can be before/afterthe object levels - i.e.: before and after all of the content, or before/after certain files/templates at a content level.\n\n### Sourcing a directory with files\n\nYou can source a directory composed of static files (without parameters) using `files` instead of defining each file individually.\n\nNOTE: Formerly, this was done using a separate `content_dir` structure. This has been deprecated.\n\nThat would look like this:\n```yaml\n- object: policy\n  content:\n  - name: directory of files\n    file: <path-to>/directory/\n```\nIn this example above, all of the files in the `<path-to>/directory/` directory would get sourced and applied to the cluster (native OpenShift processing).\n\n### Ordering of Objects in the inventory\n\nThe inventory content is defined as an ordered list, and hence processed in the order it is written. This is important to understand from the perspective of dependencies between your inventory content. For example; it's important to have namespaces or projectrequests defined early to ensure these exists before any of the builds or deployments defined later on in the inventory attempts to use a namespace.\n\nOne of the ways to define an OpenShift project using a file or template is to use define a `namespace` object. It would look like this:\n```yaml\n- object: namespace\n  content:\n  - name: <namespace_name>\n    file: <file_source>\n```\n\n### Privileged Objects\n\nNote that the `openshift-applier` runs at the permission level a user has, and hence defining objects requiring elevated privileges also requires the user running the `openshift-applier` to have the same level (or higher) of access to the OpenShift cluster.\n\n### Object Entries in the Inventory\n\nObjects and entries can be named as you please. In these objects definitions, you source templates that will add any in-project OpenShift objects including buildconfigs, deploymentconfigs, services, routes, etc. (*note:* these are standard OpenShift templates and no limitations is imposed from the `openshift-applier` for this content).\n\nYou can source as many templates and static files as you like.\n\nThese objects look like this:\n```yaml\n- object: <relevant_name>\n  content:\n  - name: <name_of_first_template>\n    template: <template_source>\n    params: <params_file_source>\n    namespace: <target_namespace>\n  - name: <name_of_second_template>\n    template: <template_source>\n    params: <params_file_source>\n    namespace: <target_namespace>\n  - name: <name_of_second_template>\n    file: <yaml/json_source>\n    namespace: <target_namespace>\n- object: <relevant_name>\n  content:\n  - name: <name_of_another_template>\n    template: <template_source>\n    params: <params_file_source>\n    namespace: <target_namespace>\n```\n\n**_NOTE:_** The objects are sourced and applied in the order found in the list. For objects with inter-dependencies, it is important to consider the order these are defined.\n\n**_NOTE:_** If the target namespace is not defined in each of the objects within the template, be sure to add the `namespace` variable.\n\n\n### Override default actions with `file_action` and `template_action`\n\nThe file and template entries have default handling of `apply` - i.e.: how the `oc` command applies the object(s). This can be overridden with with the inventory variables `file_action` and `template_action`. Normally this should not be necessary, but in some cases it may be necessary for various reasons such as permission levels. One example is if a `ProjectRequest` is defined as templates. In that case, if a non-privileged user tries to apply the objects it will error out as the user's permissions do not allow for `oc apply` at the cluster scope. In that case, it will be required to override the action with `template_action: create`. For example:\n\n```yaml\nopenshift_cluster_content:\n- object: projectrequest\n  content:\n  - name: \"my-space1\"\n    file: \"my-space.yml\"\n  - name: \"my-space2\"\n    template: \"my-space-template.yml\"\n    params: \"my-space-paramsfile\"\n    template_action: create       # Note the template_action set to override the default 'apply' action\n```\n\nValid `file_action` and `template_action` values are `apply`, `create`, and `delete`.\n\n### Filtering content based on tags\n\nThe `openshift-applier` supports the use of tags in the inventory (see example above) to allow for filtering which content should be processed and not. The `filter_tags` variable/fact takes a comma separated list of tags that will be processed and only content/content_dir with matching tags will be applied.\n\n**_NOTE:_** Entries in the inventory without tags will not be processed when a valid list is supplied with the `filter_tags` option.\n\n```\nfilter_tags=tag1,tag2\n\n```\n\n### Pre/Post steps\n\nThe `openshift-applier` supports the use of pre and post steps to allow for tasks to be executed before / after content is loaded up in OpenShift. This can be useful for things like:\n - waiting on a deployment to become ready before proceeding to the next\n - seeding the application with content after deployment\n - applying additional tweaks to the OpenShift objects post deployment (e.g.: labels, env variables, etc.)\n\nThe pre/post steps can be added at both the `object` level as well as the `content level`. See example at the top for more details.\n\nIn essence, the pre/post steps are ansible roles that gets executed in the order they are found in the inventory. These roles are sourced from the `galaxy_requirements` file part of the inventory. See the official [Ansible Galaxy docs for more details on the requirements yaml file](http://docs.ansible.com/ansible/latest/galaxy.html#installing-multiple-roles-from-a-file).\n\n**_NOTE:_** it is important that the repos used for pre/post roles have the `meta/main.yml` file setup correctly. See the [Ansible Galaxy docs](docs.ansible.com/ansible/latest/galaxy.html) for more details.\n\nFor roles that requires input parameters, the implementation also supports supplying variables, as part of the inventory, to the pre/post steps. See example at the top for more details.\n\n### Deprovisioning\n\nThe `openshift-applier` role also supports global deprovisioning of resources. This can be done either using `provision: false`. Setting `-e provision: false` on a run essentially acts like a big 'undo' button, re-running all files and templates through `oc delete -f <resources>`. This can be useful when you want to do a full cleanup to ensure the integrity of you IaC repo, or for simple cleanup while testing changes.\n\n### Dependencies\n\n- openshift-login: Ansible role used to login a user to the OpenShift cluster.\n\n\n## Example Playbook\n\nTBD\n\n## License\n\nBSD\n\n## Author Information\n\nRed Hat Community of Practice & staff of the Red Hat Open Innovation Labs.\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "0a82d735372ee011d35f102f8e4ce5887be62fcf", "filename": "roles/monit/templates/sshd", "repository": "iiab/iiab", "decoded_content": "check process sshd with pidfile /var/run/sshd.pid\n   start program = \"/sbin/service sshd start\" \n   stop program = \"/sbin/service sshd stop\" \n   if cpu > 60% for 3 cycles then restart\n   if totalmem > 200.0 MB for 3 cycles then restart \n   if failed host localhost port 22 type tcp then restart\n   if 3  restarts within 5 cycles then timeout\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "e517e4f3b2bca977494bbfbadded1733d4501393", "filename": "roles/config-software-src/tasks/mount-software.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Mount the software repository\" \n  mount:\n    path: \"{{ iso_repo_dir }}\"\n    src: \"{{ iso_repo_nfs }}\"\n    fstype: nfs\n    state: mounted\n\n\n"}, {"commit_sha": "b7c6bfe0369646ca69beeb3dfe07e8218d61c940", "sha": "b2ada1633fa6108b8df9f8d119fdb437726fa47b", "filename": "tasks/sysctl.yml", "repository": "dev-sec/ansible-os-hardening", "decoded_content": "---\n- name: protect sysctl.conf\n  file:\n    path: '/etc/sysctl.conf'\n    owner: 'root'\n    group: 'root'\n    mode: '0440'\n\n- name: set Daemon umask, do config for rhel-family | NSA 2.2.4.1\n  template:\n    src: 'rhel_sysconfig_init.j2'\n    dest: '/etc/sysconfig/init'\n    owner: 'root'\n    group: 'root'\n    mode: '0544'\n  when: ansible_distribution == 'RedHat' or ansible_distribution == 'Fedora' or ansible_distribution == 'CentOS' or ansible_distribution == 'Amazon'\n\n- name: install initramfs-tools\n  apt:\n    name: 'initramfs-tools'\n    state: 'present'\n    update_cache: true\n  when: ansible_os_family == 'Debian' and os_security_kernel_enable_module_loading\n\n- name: rebuild initramfs with starting pack of modules, if module loading at runtime is disabled\n  template:\n    src: 'modules.j2'\n    dest: '/etc/initramfs-tools/modules'\n    owner: 'root'\n    group: 'root'\n    mode: '0440'\n  when: ansible_os_family == 'Debian' and os_security_kernel_enable_module_loading\n  register: initramfs\n\n- name: update-initramfs\n  command: 'update-initramfs -u'\n  when: initramfs.changed\n\n- name: create a combined sysctl-dict if overwrites are defined\n  set_fact:\n    sysctl_config: '{{ sysctl_config | combine(sysctl_overwrite) }}'\n  when: sysctl_overwrite | default()\n\n- name: Change various sysctl-settings, look at the sysctl-vars file for documentation\n  sysctl:\n    name: '{{ item.key }}'\n    value: '{{ item.value }}'\n    sysctl_set: yes\n    state: present\n    reload: yes\n    ignoreerrors: yes\n  with_dict: '{{ sysctl_config }}'\n\n- name: Change various sysctl-settings on rhel6-hosts or older, look at the sysctl-vars file for documentation\n  sysctl:\n    name: '{{ item.key }}'\n    value: '{{ item.value }}'\n    state: present\n    reload: yes\n    ignoreerrors: yes\n  with_dict: '{{ sysctl_rhel_config }}'\n  when: ((ansible_distribution == 'RedHat' or ansible_distribution == 'Fedora' or ansible_distribution == 'CentOS') and ansible_distribution_major_version < '7') or ansible_distribution == 'Amazon'\n\n- name: Apply ufw defaults\n  template:\n    src: 'ufw.j2'\n    dest: '/etc/default/ufw'\n  when: ufw_manage_defaults and (ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu')\n  tags: ufw\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "d2fc834e6b02228e447c2a9a7820b0c353ce2f58", "filename": "roles/activity-server/templates/usbmount-60-xs-activity-server-installcontent", "repository": "iiab/iiab", "decoded_content": "#!/bin/bash\n# Part of the xs-activity-server package\n#\n# based on a similarly named script in the xs-rsync package\n# by Martin Langhoff <martin@laptop.org>\n#\n# Adapted for xs-activity-server by Douglas Bagnall\n# <douglas@paradise.net.nz>\n#\n# Copyright: One Laptop per Child\n\nset -e\n\nVERBOSE=yes\nMAGIC_DIR=$UM_MOUNTPOINT/xs-activity-server\n\nFINAL_DIR=/library/xs-activity-server/activities\n\nFILES_TO_RM=\"\"\n\n# combined with set -e, error() is called if something fails.\nerror(){\n    logger -puser.err -t \"xs-activity-server[$$]\" \"Error at line $(caller)\"\n    [ \"$FILES_TO_RM\" ] && rm -rf $FILES_TO_RM\n}\ntrap error ERR\n\n\n# Log a string via the syslog facility.\nlog()\n{\n    if test $1 != debug || expr \"$VERBOSE\" : \"[yY]\" > /dev/null; then\n\tlogger -p user.$1 -t \"xs-activity-server[$$]\" -- \"$2\"\n    fi\n}\n\n\nSTEPS=7\n\n[ -d $MAGIC_DIR ] || exit 0\n\nlog notice 'Found activity install directory';\nlog notice \"[1/$STEPS] Checking whether it has a manifest\";\n\nif [ -r $MAGIC_DIR/manifest.sha1 ];then\n    log notice \"[2/$STEPS] Seems to have a manifest\";\nelse\n    log err \"[2/$STEPS] Missing manifest\"\n    exit 1;\nfi\n\n## Do we have enough space?\n# note: we could use awk {'print $4'} instead of the\n# perl regex, but it breaks with long /dev nodes\n# such as those from LVMs -which wrap. The regex captures the\n# number just left of the number with the percentage sign.\nNEED=`du -s -B1M $MAGIC_DIR | awk {'print $1'}`\nHAVE=`df -B1M $FINAL_DIR | tail -n1 | \\\n    perl -pe 'm/(\\d+)\\s+\\d+\\%/; $_=($1-1);'`\nif [ $NEED -gt $HAVE ];then\n    log err 'Not enough free space in /library for these activities - cancelling';\n    exit 1;\nfi\n\n### Copy it first - as the media is bound to be slow\n# - make this atomic by cp'ing to a tmpdir, and mv'ing into place\n#   to be fail-safe\n# - mv aside manifest.sha1 and its sig\n# - TODO? we could avoid cp'ing files we already have using\n#   rsync --copy-dest instead of cp\n#\nlog notice \"[3/$STEPS] Copying activities to disk\";\nTMPDEST=`mktemp -d -p /library/xs-activity-server/tmp`\n\n#make sure the tmp directory goes\nFILES_TO_RM=\"$FILES_TO_RM '$TMPDEST'\"\n\ncp --preserve=timestamps $MAGIC_DIR/* $TMPDEST\n\n# In a tmpdir we own, safe from race conditions\n# run the checksums...\nlog notice \"[4/$STEPS] Checking the manifest\";\n# mv the manifest to a different dir\nTMPMANIF=`mktemp -d -p /library/xs-activity-server/tmp`\n\nFILES_TO_RM=\"$FILES_TO_RM '$TMPMANIF'\"\n\n\nmv $TMPDEST/manifest.sha1 $TMPMANIF/\nif [ -e $TMPDEST/manifest.sha1.sig ]; then\n    mv $TMPDEST/manifest.sha1.sig $TMPMANIF/\nfi\nxs-sum -c $TMPMANIF/manifest.sha1 -d $TMPDEST\n\n#Let syslog know what we're doing\ncd $TMPDEST\nlog notice \"found $(ls *.xo |wc -l) activities\"\nlog debug \"found these activities: $(ls *.xo)\"\ncd -\n\nlog notice \"[5/$STEPS] Copy the directories into place\";\n#XXX not checking whether this clobbers existing files.\nmv $TMPDEST/* $FINAL_DIR\n\n#So, now all the activities are in place, but maybe they're not\n#newer than what we have. So xs-regenerate-activities has to work that out.\n\nlog notice \"[6/$STEPS] Regenerating the list of available activities\";\n\n/usr/bin/xs-regenerate-activities $FINAL_DIR 2>&1 | logger -p user.debug -t \"xs-activity-server[$$]\" \n\nlog notice \"[$STEPS/$STEPS] Finished - XOs can now update activities.\";\n\n\nrm -fr $FILES_TO_RM\n"}, {"commit_sha": "79e29502fb4e0ff1c30c0b5396bfa1b48fb84a8e", "sha": "7e3f9444199129cf794c40a5ab77b3dfeb123318", "filename": "tasks/users.yml", "repository": "Oefenweb/ansible-wordpress", "decoded_content": "# tasks file for wordpress, users\n---\n- name: create (data) directory\n  file:\n    path: \"{{ wordpress_data_path }}\"\n    state: directory\n    owner: root\n    group: root\n    mode: 0755\n  tags: [configuration, wordpress, wordpress-users]\n\n- name: copy file (users)\n  copy:\n    src: \"{{ item.users.src }}\"\n    dest: \"{{ wordpress_data_path }}/{{ item.dbname }}.csv\"\n    owner: root\n    group: root\n    mode: 0644\n  register: check_copy_users\n  with_items: wordpress_installs\n  when: item.users.src is defined\n  tags: [configuration, wordpress, wordpress-users]\n\n- name: install (users)\n  shell: \"wp-cli --allow-root --no-color --path='{{ item.item.path }}' user import-csv {{ wordpress_data_path }}/{{ item.item.dbname }}.csv {{ '--skip-update' if item.item.users.skip_update | default(true) else '' }} --send-email\"\n  register: check_installation_users\n  changed_when: \"'Success' in check_installation_users.stdout\"\n  with_items: check_copy_users.results\n  when: check_copy_users is defined and item.changed\n  tags: [configuration, wordpress, wordpress-users]\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "27454c70eff39eaceb36a739c343afea21da7d3f", "filename": "roles/rhsm/tests/group_vars/test-sat6.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nrhsm_server_hostname: \"sat6.example.com\"\nrhsm_org_id: \"my_org\"\nrhsm_activationkey: \"my_activation_key\"\nrhsm_pool: \"^my_pool_name$\"\n\nrhsm_repos:\n- \"rhel-7-server-rpms\"\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "faa397002b6aa9be0f7e436e65d2cd014abf44ca", "filename": "roles/dns/config-dns-server/tasks/named/named.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Setup DNS Logging configuration\n  template:\n    src: named/logging.j2\n    dest: /etc/named/named.conf.logging\n    owner: named\n    group: named\n    mode: 0660\n  notify: restart named\n\n- name: Setup Controls configuration\n  template:\n    src: named/controls.j2\n    dest: /etc/named/named.conf.controls\n    owner: named\n    group: named\n    mode: 0660\n  notify: restart named\n\n- name: Configure named options\n  vars:\n    named_config: \"{{ dns_data.named_global_config }}\"\n  template:\n    src: named/options.j2\n    dest: /etc/named/named.conf.options\n    owner: named\n    group: named\n  notify: restart named\n"}, {"commit_sha": "96adc61e360141bb718b75d48c387b3680a8471b", "sha": "367499251edb795a54503d5308afa65d9e01900e", "filename": "tasks/compatibility-checks.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n# https://github.com/moby/moby/issues/35873\n# https://access.redhat.com/solutions/2991041\n- name: Compatibility check - Fail if both MountFlags=slave and live-restore are set\n  fail:\n    msg: >\n      Setting both `MountFlags=slave` (docker_enable_mount_flag_fix: true)\n      and `live-restore=true` (docker_daemon_config['live-restore']: true)\n      triggers a bug (https://github.com/moby/moby/issues/35873). For now,\n      don't use both.\n  when: docker_enable_mount_flag_fix\n        and (docker_daemon_config['live-restore'] is defined\n        and docker_daemon_config['live-restore'])\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "a4c8d89ba69384be289697021a413fdc2f446c38", "filename": "playbooks/deploy-rock.yml", "repository": "rocknsm/rock", "decoded_content": "---\n- hosts: all\n  vars:\n    rock_debug: \"{{ lookup('env', 'DEBUG') }}\"\n    http_proxy: \"{{ lookup('env','http_proxy') }}\"\n    https_proxy: \"{{ lookup('env', 'https_proxy') }}\"\n  tasks:\n  - name: Get default settings\n    include_vars: rocknsm_config.dist.yml\n  - name: Apply override settings, if available\n    include_vars: /etc/rocknsm/config.yml\n    ignore_errors: true\n    failed_when: false\n  - name: Debug variables\n    include: debug.yml\n    when: rock_debug is defined and rock_debug\n\n    ######################################################\n    ################# Data Directory #####################\n    ######################################################\n    ###############\n    ##### NOTE ####\n    ###############\n    # You will want to remount this to your \"good\" storage after the build.\n    # This is just to make sure all the paths in the configs are proper.\n    ###############  - file:\n  - name: Create ROCK data dir\n    file:\n      path: \"{{ rock_data_dir }}\"\n      mode: 0755\n      owner: \"{{ rock_data_user }}\"\n      group: \"{{ rock_data_group }}\"\n      state: directory\n\n  - name: Create ROCK NSM directory\n    file:\n      path: \"{{ rocknsm_dir }}\"\n      mode: 0755\n      owner: root\n      group: root\n      state: directory\n\n    ######################################################\n    ######### Configure the monitoring interface #########\n    ######################################################\n  - name: Set monitor interface config\n    template:\n      src: templates/ifcfg-monif.j2\n      dest: /etc/sysconfig/network-scripts/ifcfg-{{ item }}\n      mode: 0644\n      owner: root\n      group: root\n      force: yes\n    with_items: \"{{ rock_monifs }}\"\n\n  - name: Configure local ifup script\n    template:\n      src: templates/ifup-local.j2\n      dest: /sbin/ifup-local\n      mode: 0755\n      owner: root\n      group: root\n      force: yes\n    notify: configure monitor interfaces\n\n    #######################################################\n    #################### Disable IPv6 #####################\n    #######################################################\n  - name: Disable IPv6 for all interfaces\n    sysctl:\n      name: net.ipv6.conf.all.disable_ipv6\n      value: 1l\n      sysctl_file: \"{{ rock_sysctl_file }}\"\n\n  - name: Disable IPv6 for default interfaces\n    sysctl:\n      name: net.ipv6.conf.default.disable_ipv6\n      value: 1\n      sysctl_file: \"{{ rock_sysctl_file }}\"\n\n  - name: Disable IPv6 in SSHD\n    lineinfile:\n      dest: /etc/ssh/sshd_config\n      regexp: AddressFamily\n      line: AddressFamily inet\n    notify:\n    - sshd restart\n\n  - name: Remove localhost6 from hosts file\n    lineinfile:\n      dest: /etc/hosts\n      regexp: localhost6\n      state: absent\n\n    #######################################################\n    #################### DNS Changes ######################\n    #######################################################\n  - name: Set hostname in hosts file\n    lineinfile:\n      dest: /etc/hosts\n      insertafter: 127.0.0.1\n      line: 127.0.0.2  {{ rock_fqdn }}  {{ rock_hostname }}\n\n  - name: Set system hostname\n    hostname:\n      name: \"{{ rock_fqdn }}\"\n\n    #######################################################\n    ################## Setup Yum Repos ####################\n    #######################################################\n  - name: Setup EPEL repo\n    yum_repository:\n      name: epel\n      description: EPEL YUM repo\n      baseurl: \"{{ epel_baseurl }}\"\n      gpgkey:  \"{{ epel_gpgurl }}\"\n      gpgcheck: yes\n    when: rock_online_install\n\n  - name: Setup ELrepo Kernel repo\n    yum_repository:\n      name: elrepo-kernel\n      description: ELrepo Kernel YUM repo\n      baseurl: \"{{ elrepo_baseurl }}\"\n      gpgkey:  \"{{ elrepo_gpgurl }}\"\n      gpgcheck: yes\n    when: rock_online_install\n\n  - name: Setup Elastic repo\n    yum_repository:\n      name: elastic-5.x\n      description: Elastic Stack repository for 5.x\n      baseurl: \"{{ elastic_baseurl }}\"\n      gpgkey:  \"{{ elastic_gpgurl }}\"\n      gpgcheck: no\n    when: rock_online_install\n\n  - name: Setup ROCK NSM repo\n    yum_repository:\n      name: rocknsm\n      description: ROCK NSM repository for devel\n      baseurl: \"{{ rocknsm_baseurl }}\"\n      gpgkey:  \"{{ rocknsm_gpgurl }}\"\n      gpgcheck: no\n      cost: 750\n    when: rock_online_install\n\n  - name: Setup local offline repo\n    yum_repository:\n      name: rocknsm-local\n      description: ROCKNSM Local Repository\n      baseurl: \"{{ rocknsm_local_baseurl }}\"\n      gpgcheck: no\n      cost: 500\n    when: not rock_online_install\n\n  - name: Configure default CentOS online repos\n    yum_repository:\n      name: \"{{ item.name }}\"\n      enabled: \"{{ rock_online_install }}\"\n      description: \"CentOS-$releasever - {{ item.name | title }}\"\n      mirrorlist: \"{{ item.mirror }}\"\n      file:  CentOS-Base\n    with_items:\n      - { name: base, mirror: \"http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=os&infra=$infra\" }\n      - { name: updates, mirror: \"http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=updates&infra=$infra\" }\n      - { name: extras, mirror: \"http://mirrorlist.centos.org/?release=$releasever&arch=$basearch&repo=extras&infra=$infra\"}\n\n    #######################################################\n    ############# Install/Remove Packages #################\n    #######################################################\n  - name: Configure packages\n    set_fact:\n      rocknsm_package_list: \"{{ rocknsm_package_list }} + [ '{{ item.pkg }}']\"\n    when: (item.test is undefined) or (item.test)\n    with_items:\n      - { pkg: elasticsearch, test: \"{{with_elasticsearch}}\", state: installed }\n      - { pkg: logstash, test: \"{{with_logstash}}\", state: installed }\n      - { pkg: kibana, test: \"{{with_kibana}}\", state: installed }\n      - { pkg: filebeat, test: \"{{with_suricata or with_fsf}}\", state: installed }\n      - { pkg: nginx, test: \"{{with_nginx}}\", state: installed }\n      - { pkg: bro, test: \"{{with_bro}}\", state: installed }\n      - { pkg: bro-plugin-af_packet, test: \"{{with_bro}}\", state: installed }\n      - { pkg: bro-plugin-kafka, test: \"{{(with_bro and with_kafka)}}\", state: installed }\n      - { pkg: stenographer, test: \"{{with_stenographer}}\", state: installed }\n      - { pkg: suricata, test: \"{{with_suricata}}\", state: installed }\n      - { pkg: snort, test: \"{{with_snort}}\", state: installed }\n      - { pkg: daq, test: \"{{with_snort}}\", state: installed }\n      - { pkg: zookeeper, test: \"{{with_zookeeper}}\", state: installed }\n      - { pkg: kafka, test: \"{{with_kafka}}\", state: installed }\n      - { pkg: kafkacat, test: \"{{with_kafka}}\", state: installed }\n      - { pkg: fsf, test: \"{{with_fsf}}\", state: installed }\n      - { pkg: chrony, state: installed }\n      - { pkg: firewalld, state: installed }\n      - { pkg: postfix, state: installed }\n\n  - name: Install packages\n    yum:\n      name: \"{{ item.pkg }}\"\n      state: \"{{ item.state }}\"\n    when: (item.test is undefined) or (item.test)\n    with_items:\n      - { pkg: \"{{ rocknsm_package_list }}\", state: installed }\n\n  - name: Ensure cache directory exists\n    file:\n      dest: \"{{ rock_cache_dir }}\"\n      state: directory\n      mode: 0755\n\n  - name: Download Pulled Pork\n    get_url:\n      url: \"{{ pulledpork_url }}\"\n      dest: \"{{ rock_cache_dir }}/{{ pulledpork_filename }}\"\n      mode: 0644\n    when: rock_online_install\n\n  - name: Install Pulled Pork\n    unarchive:\n      src: \"{{ rock_cache_dir }}/{{ pulledpork_filename }}\"\n      dest: /opt\n      owner: root\n      group: root\n      creates: \"/opt/pulledpork-{{ pulledpork_release }}\"\n      remote_src: yes\n    when: \"{{ with_pulledpork }}\"\n\n    ######################################################\n    ################### Configure Time ###################\n    ######################################################\n  - name: Enable and start chrony\n    service:\n      name: chronyd\n      enabled: yes\n      state: started\n\n  - name: Set system timezone\n    command: /usr/bin/timedatectl set-timezone UTC\n    when: ansible_date_time.tz != \"UTC\"\n\n  - name: Check if RTC set to UTC\n    shell: timedatectl | awk '/RTC in local/ { print $5 }'\n    changed_when: false\n    register: chrony_local_utc\n\n  - name: Set system hardware clock to UTC\n    command: /usr/bin/timedatectl set-local-rtc no\n    when: chrony_local_utc == 'yes'\n\n    #######################################################\n    ################ Configure firewall ###################\n    #######################################################\n  - name: Enable and start firewalld\n    service:\n      name: firewalld\n      enabled: yes\n      state: started\n\n  - name: Configure firewalld\n    firewalld:\n      port: \"{{ item[1].port }}\"\n      source: \"{{ item[0] }}\"\n      permanent: yes\n      state: enabled\n      immediate: yes\n    when: (item[1].test is undefined) or item[1].test\n    with_nested:\n      - \"{{ rock_mgmt_nets }}\"\n      -\n        - { port: \"22/tcp\" }\n        - { port: \"443/tcp\",  test: \"{{ with_kibana }}\" }\n\n    ######################################################\n    ############## Configure GeoIP Databases #############\n    ######################################################\n  - name: Configure GeoIP Update\n    copy: src=GeoIP.conf dest=/etc/GeoIP.conf\n\n    # There's an issue w/ geoipupdate when env is empty\n  - name: Update GeoIP\n    shell: >\n      if [ \"x$HTTP_PROXY\" == \"x\" ]; then\n          unset HTTP_PROXY;\n      fi\n      if [ \"x$http_proxy\" == \"x\" ]; then\n          unset http_proxy;\n      fi\n      if [ \"x$HTTPS_PROXY\" == \"x\" ]; then\n          unset HTTPS_PROXY;\n      fi\n      if [ \"x$https_proxy\" == \"x\" ]; then\n          unset https_proxy;\n      fi\n      /usr/bin/geoipupdate\n    args:\n      creates: /usr/share/GeoIP/GeoLiteASNum.dat\n    register: result\n    failed_when: (result.rc != 0) and (result.rc != 1)\n\n  - name: Create GeoIP symlinks\n    file:\n      src: \"/usr/share/GeoIP/{{ item.src }}\"\n      dest: \"/usr/share/GeoIP/{{ item.dest }}\"\n      force: yes\n      state: link\n    with_items:\n      - { src: 'GeoLiteCity.dat', dest: 'GeoIPCity.dat' }\n      - { src: 'GeoLiteCountry.dat', dest: 'GeoIPCountry.dat' }\n      - { src: 'GeoLiteASNum.dat', dest: 'GeoIPASNum.dat' }\n      - { src: 'GeoLiteCityv6.dat', dest: 'GeoIPCityv6.dat' }\n\n    ######################################################\n    ################### Setup Zookeeper ##################\n    ######################################################\n  - name: Install zookeeper service file\n    copy:\n      src: zookeeper.service\n      dest: /etc/systemd/system/zookeeper.service\n      mode: 0644\n      owner: root\n      group: root\n    when: with_zookeeper\n\n  - name: Enable and start zookeeper\n    service:\n      name: zookeeper\n      state: \"{{ 'started' if enable_zookeeper else 'stopped' }}\"\n      enabled: \"{{ enable_zookeeper }}\"\n    when: with_zookeeper\n\n    ######################################################\n    ##################### Setup Kafka ####################\n    ######################################################\n  - name: Create Kafka data dir\n    file:\n      path: \"{{ kafka_data_dir }}\"\n      mode: 0755\n      owner: \"{{ kafka_user }}\"\n      group: \"{{ kafka_group }}\"\n      state: directory\n    when: with_kafka\n\n  - name: Set kafka retention\n    lineinfile:\n      dest: \"{{ kafka_config_path }}\"\n      regexp: \"log.retention.hours=\"\n      line:  \"log.retention.hours={{ kafka_retention }}\"\n      state: present\n    when: with_kafka\n\n  - name: Set kafka data dir\n    lineinfile:\n      dest: \"{{ kafka_config_path }}\"\n      regexp: \"log.dirs=\"\n      line: \"log.dirs={{ kafka_data_dir }}\"\n    when: with_kafka\n\n  - name: Enable and start kafka\n    service:\n      name: kafka\n      state: \"{{ 'started' if enable_kafka else 'stopped' }}\"\n      enabled: \"{{ enable_kafka }}\"\n    when: with_kafka\n\n    ######################################################\n    ################# Setup Elasticsearch ################\n    ######################################################\n  - name: Create Elasticsearch directory\n    file:\n      path: \"{{ es_data_dir }}\"\n      mode: 0755\n      owner: \"{{ es_user }}\"\n      group: \"{{ es_group }}\"\n      state: directory\n    when: with_elasticsearch\n\n  - name: Setup elasticsearch config\n    template:\n      src: templates/elasticsearch.yml.j2\n      dest: /etc/elasticsearch/elasticsearch.yml\n      owner: root\n      group: \"{{ es_group }}\"\n      mode: 0640\n    when: with_elasticsearch\n\n  - name: Create elasticsearch systemd override dir\n    file:\n      path: /etc/systemd/system/elasticsearch.service.d\n      owner: root\n      group: root\n      mode: 0755\n      state: directory\n    when: with_elasticsearch\n\n  - name: Enable elasticsearch memlock in service override\n    copy:\n      content: \"{{ es_memlock_override }}\"\n      dest: /etc/systemd/system/elasticsearch.service.d/override.conf\n      mode: 0644\n      owner: root\n      group: root\n    when: with_elasticsearch\n\n  - name: Setup elasticsearch data dir in sysconfig\n    lineinfile:\n      dest: /etc/sysconfig/elasticsearch\n      regexp: \"DATA_DIR=\"\n      line: \"DATA_DIR={{ es_data_dir }}\"\n    when: with_elasticsearch\n\n  - name: Setup elasticsearch jvm options\n    template:\n      src: templates/es-jvm.options.j2\n      dest: /etc/elasticsearch/jvm.options\n      mode: 0640\n      owner: root\n      group: \"{{ es_group }}\"\n    when: with_elasticsearch\n\n  - name: Install ROCK Elasticsearch cleanup script\n    template:\n      src: templates/es_cleanup.sh.j2\n      dest: /usr/local/bin/es_cleanup.sh\n      mode: 0755\n      owner: root\n      group: root\n    when: with_elasticsearch\n\n  - name: Set elasticsearch cleanup cron job\n    cron:\n      name: \"ES maintenance\"\n      cron_file: rocknsm_es_maintenance\n      hour: 0\n      minute: 1\n      user: root\n      job: /usr/local/bin/es_cleanup.sh > /dev/null 2>&1\n    when: with_elasticsearch\n\n  - name: Enable and start Elasticsearch\n    service:\n      name: elasticsearch\n      state: \"{{ 'started' if enable_elasticsearch else 'stopped' }}\"\n      enabled: \"{{ enable_elasticsearch }}\"\n    when: with_elasticsearch\n    notify:\n      - es maintenance\n\n  - name: Wait for Elasticsearch to become ready\n    wait_for: host=localhost port=9200\n    when: with_elasticsearch\n\n  - name: Check for Bro mapping templates\n    uri:\n      method: \"GET\"\n      url: http://localhost:9200/_template/bro_index\n    failed_when: False\n    register: bro_mapping\n    when: (with_elasticsearch and with_bro)\n\n  - name: Load Bro Elasticsearch mapping templates\n    uri:\n      method: PUT\n      url: http://localhost:9200/_template/bro_index\n      body: \"{{ lookup('file', 'es-bro-mappings.json')}}\"\n      body_format: json\n    when: (with_elasticsearch and with_bro) and bro_mapping.status == 404\n\n    ######################################################\n    ################### Setup Logstash ###################\n    ######################################################\n  - name: Install Bro-Kafka configuration for Logstash\n    copy:\n      src: logstash-kafka-bro.conf\n      dest: /etc/logstash/conf.d/kafka-bro.conf\n      mode: 0640\n      owner: \"{{ logstash_user }}\"\n      group: \"{{ logstash_group }}\"\n    when: with_logstash and with_bro and with_kafka\n    notify: Restart Logstash\n\n  - name: Install Suricata-Kafka configuration for Logstash\n    copy:\n      src: logstash-kafka-suricata.conf\n      dest: /etc/logstash/conf.d/kafka-suricata.conf\n      mode: 0640\n      owner: \"{{ logstash_user }}\"\n      group: \"{{ logstash_group }}\"\n    when: with_logstash and with_suricata and with_kafka\n    notify: Restart Logstash\n\n  - name: Install FSF-Kafka configuration for Logstash\n    copy:\n      src: logstash-kafka-fsf.conf\n      dest: \"/etc/logstash/conf.d/kafka-fsf.conf\"\n      mode: 0640\n      owner: \"{{ logstash_user }}\"\n      group: \"{{ logstash_group }}\"\n    when: with_logstash and with_fsf and with_kafka\n    notify: Restart Logstash\n\n  - name: Enable and start Logstash\n    service:\n      name: logstash\n      state: \"{{ 'started' if enable_logstash else 'stopped' }}\"\n      enabled: \"{{ enable_logstash }}\"\n    when: with_logstash\n\n    ######################################################\n    ################### Setup Filebeat ###################\n    ######################################################\n  - name: Add Filebeat configuration file\n    template:\n      src: filebeat.yml.j2\n      dest: /etc/filebeat/filebeat.yml\n    notify: Restart Filebeat\n\n  - name: Enable and start Filebeat\n    service:\n      name: filebeat\n      state: \"{{ 'started' if enable_filebeat else 'stopped' }}\"\n      enabled: \"{{ enable_filebeat }}\"\n    when: with_filebeat\n\n    #######################################################\n    ###################### Setup Bro  #####################\n    #######################################################\n  - name: Create bro group\n    group:\n      name: \"{{ bro_group }}\"\n      state: present\n      system: yes\n    when: with_bro\n\n  - name: Create bro user and group\n    user:\n      name: \"{{ bro_user }}\"\n      comment: \"bro service account\"\n      createhome: no\n      group: \"{{ bro_group }}\"\n      home: /opt/bro\n      shell: /sbin/nologin\n      system: yes\n      state: present\n    when: with_bro\n\n  - name: Create Bro directories\n    file:\n      path: \"{{ item }}\"\n      mode: 0755\n      owner: \"{{ bro_user }}\"\n      group: \"{{ bro_group }}\"\n      state: directory\n    with_items:\n      - \"{{ bro_data_dir }}\"\n      - \"{{ bro_data_dir }}/logs\"\n      - \"{{ bro_data_dir }}/spool\"\n    when: with_bro\n\n  - name: Create symlinks for wandering analysts\n    file:\n      dest: \"/opt/bro/{{ item }}\"\n      src:  \"{{ bro_data_dir }}/{{ item }}\"\n      state: link\n      force: yes\n    with_items:\n      - logs\n    when: with_bro\n\n  - name: Install broctl service file\n    template:\n      src: templates/broctl.service.j2\n      dest: /etc/systemd/system/broctl.service\n      owner: root\n      group: root\n      mode: 0644\n    when: with_bro\n    notify: reload systemd\n\n  - name: Create Bro node.cfg\n    template:\n      src: templates/bro-node.cfg.j2\n      dest: /opt/bro/etc/node.cfg\n      mode: 0644\n      owner: root\n      group: root\n    when: with_bro\n    notify: reload broctl\n\n\n  - name: Create broctl.cfg\n    template:\n      src: templates/bro-broctl.cfg.j2\n      dest: /opt/bro/etc/broctl.cfg\n      mode: 0644\n      owner: root\n      group: root\n    when: with_bro\n    notify: reload broctl\n\n  - name: Create bro networks.cfg\n    copy:\n      src: bro-networks.cfg\n      dest: /opt/bro/etc/networks.cfg\n      mode: 0644\n      owner: root\n      group: root\n    when: with_bro\n    notify: reload broctl\n\n  - name: Add bro custom scripts dir\n    file:\n      path: /opt/bro/share/bro/site/scripts\n      owner: root\n      group: root\n      mode: 0755\n      state: directory\n    when: with_bro\n\n  - name: Set permissions on broctl scripts dir\n    file:\n      path: /opt/bro/share/broctl/scripts\n      owner: \"{{ bro_user }}\"\n      group: \"{{ bro_user }}\"\n      mode: 0755\n      state: directory\n    when: with_bro\n\n  - name: Add README to scripts dir\n    copy:\n      src: bro-scripts-readme.txt\n      dest: /opt/bro/share/bro/site/scripts/README.txt\n      mode: 0644\n      owner: root\n      group: root\n    when: with_bro\n\n  - name: Checkout ROCK Bro scripts\n    git:\n      repo: \"{{ bro_rockscripts_repo }}\"\n      dest: /opt/bro/share/bro/site/scripts/rock\n      version: \"{{ bro_rockscripts_branch }}\"\n    when: with_bro and rock_online_install\n\n  - name: Deploy offline ROCK Bro scripts\n    unarchive:\n      src: \"{{ rock_cache_dir }}/{{ bro_rockscripts_filename }}\"\n      dest: /opt/bro/share/bro/site/scripts/\n      owner: root\n      group: root\n      creates: \"/opt/bro/share/bro/site/scripts/rock-scripts-{{ bro_rockscripts_branch | replace ('/', '-') }}\"\n      remote_src: yes\n    when: with_bro and not rock_online_install\n\n  - name: Symlink offline ROCK bro scripts\n    file:\n      src: \"/opt/bro/share/bro/site/scripts/rock-scripts-{{ bro_rockscripts_branch | replace ('/', '-') }}\"\n      dest: \"/opt/bro/share/bro/site/scripts/rock\"\n      state: link\n      force: yes\n    when: with_bro and not rock_online_install\n\n  - name: Update owner for ROCK NSM Bro scripts\n    file:\n      path: /opt/bro/share/bro/site/scripts/rock\n      owner: \"{{ bro_user }}\"\n      group: \"{{ bro_group }}\"\n      state: directory\n      recurse: yes\n      follow: yes\n    tags:\n      - bro_scripts\n    when: with_bro\n\n  - name: Add ROCK scripts to local.bro\n    lineinfile:\n      dest: /opt/bro/share/bro/site/local.bro\n      line: \"@load scripts/rock # ROCK NSM customizations\"\n      state: present\n    when: with_bro\n\n  - name: Add AF_PACKET workaround to local.bro\n    lineinfile:\n      dest: /opt/bro/share/bro/site/local.bro\n      line: \"@load scripts/rock/plugins/afpacket\"\n      state: present\n    when: with_bro\n\n  - name: Enable Bro Kafka output to local.bro\n    lineinfile:\n      dest: /opt/bro/share/bro/site/local.bro\n      line: \"@load scripts/rock/plugins/kafka\"\n      state: present\n    when: with_bro and with_kafka\n\n  - name: Enable the SMB Analyzer in local.bro\n    lineinfile:\n      dest: /opt/bro/share/bro/site/local.bro\n      line: \"@load policy/protocols/smb # Enable Bro SMB Analyzer\"\n      state: present\n    when: with_bro\n\n  - name: Add bro to path and aliases\n    copy:\n      src: profile.d-bro.sh\n      dest: /etc/profile.d/bro.sh\n      mode: 0644\n      owner: root\n      group: root\n    when: with_bro\n\n  - name: Add broctl wrapper for admin use\n    copy:\n      src: broctl.sh\n      dest: /usr/sbin/broctl\n      mode: 0754\n      owner: root\n      group: root\n    when: with_bro\n\n  - name: Create bro utility symlinks\n    file:\n      src: \"/opt/bro/bin/{{ item.src }}\"\n      dest: \"/usr/bin/{{ item.dest }}\"\n      force: yes\n      state: link\n    with_items:\n      - { src: 'bro', dest: 'bro' }\n      - { src: 'bro-cut', dest: 'bro-cut' }\n\n  - name: Set bro capabilities\n    capabilities:\n      path: /opt/bro/bin/bro\n      capability: \"{{ item }}\"\n      state: present\n    with_items:\n      - \"cap_net_raw+eip\"\n      - \"cap_net_admin+eip\"\n    when: with_bro\n\n  - name: Set capstats capabilities\n    capabilities:\n      path: /opt/bro/bin/capstats\n      capability: \"{{ item }}\"\n      state: present\n    with_items:\n      - \"cap_net_raw+eip\"\n      - \"cap_net_admin+eip\"\n    when: with_bro\n\n  - name: Set broctl cron\n    cron:\n      name: \"broctl maintenance\"\n      minute: \"*/5\"\n      cron_file: rocknsm_broctl\n      user: \"{{ bro_user }}\"\n      job: \"/opt/bro/bin/broctl cron >/dev/null 2>&1\"\n    when: with_bro\n\n  - name: Initialize bro scripts for workers\n    command: /opt/bro/bin/broctl install\n    args:\n      creates: \"{{ bro_data_dir }}/spool/broctl-config.sh\"\n    become: yes\n    become_user: \"{{ bro_user }}\"\n    when: with_bro\n\n  - name: Enable and start broctl\n    service:\n      name: broctl\n      enabled: \"{{ enable_bro }}\"\n      state: \"{{ 'started' if enable_bro else 'stopped' }}\"\n    when: with_bro\n\n    ######################################################\n    ################# Setup Stenographer #################\n    ######################################################\n  - name: Set stenographer config\n    template:\n      src: templates/stenographer-config.j2\n      dest: \"/etc/stenographer/config.{{ item.1 }}\"\n    with_indexed_items: \"{{ rock_monifs }}\"\n    when: with_stenographer\n\n  - name: Create Stenographer directories\n    file:\n      path: \"{{ stenographer_data_dir }}/{{ item[0] }}/{{ item[1] }}\"\n      mode: 0755\n      owner: \"{{ stenographer_user }}\"\n      group: \"{{ stenographer_group }}\"\n      state: directory\n    with_nested:\n      - \"{{ rock_monifs }}\"\n      - [ 'index', 'packets' ]\n    when: with_stenographer\n\n  - name: Install stenographer service files\n    copy:\n      src: \"{{ item }}\"\n      dest: \"/etc/systemd/system/{{ item }}\"\n      mode: 0644\n      owner: root\n      group: root\n    with_items:\n      - stenographer.service\n      - stenographer@.service\n    when: with_stenographer\n\n  - name: Generate stenographer keys\n    command: >\n      /usr/bin/stenokeys.sh {{ stenographer_user }} {{ stenographer_group }}\n    args:\n      creates: /etc/stenographer/certs/client_key.pem\n    when: with_stenographer\n\n  - name: Configure Stenographer service\n    service:\n      name: stenographer\n      enabled: \"{{ enable_stenographer }}\"\n      state: \"{{ 'started' if enable_stenographer else 'stopped' }}\"\n    when: with_stenographer\n\n  - name: Configure Stenographer per-interface\n    service:\n      name: \"stenographer@{{ item }}\"\n      enabled: \"{{ enable_stenographer }}\"\n      state: \"{{ 'started' if enable_stenographer else 'stopped' }}\"\n    with_items: \"{{ rock_monifs }}\"\n    when: with_stenographer\n\n    ######################################################\n    ################## Setup Suricata ####################\n    ######################################################\n  - name: Create Suricata directories\n    file:\n      path: \"{{ suricata_data_dir }}/\"\n      mode: 0755\n      owner: \"{{ suricata_user }}\"\n      group: \"{{ suricata_group }}\"\n      state: directory\n    when: with_suricata\n\n  - name: Set suricata capabilities\n    capabilities:\n      path: /usr/sbin/suricata\n      capability: \"{{ item }}\"\n      state: present\n    with_items:\n      - \"cap_net_raw+eip\"\n      - \"cap_net_admin+eip\"\n      - \"cap_ipc_lock+eip\"\n    when: with_suricata\n\n  - name: Remove suricata sysconfig file\n    file:\n      path: /etc/sysconfig/suricata\n      state: absent\n    when: with_suricata\n\n  - name: Install suricata service files\n    copy:\n      src: \"suricata.service\"\n      dest: \"/etc/systemd/system/suricata.service\"\n      mode: 0644\n      owner: root\n      group: root\n    when: with_suricata\n\n  - name: Install suricata overrides\n    template:\n      src: templates/suricata_overrides.yaml.j2\n      dest: /etc/suricata/rocknsm-overrides.yaml\n      mode: 0644\n      owner: \"{{ suricata_user }}\"\n      group: root\n    when: with_suricata\n\n  - name: Create IP reputation config dir\n    file:\n      path: /etc/suricata/rules/iplists\n      state: directory\n      owner: root\n      group: root\n      mode: 0755\n    when: with_suricata\n\n  - name: Set suricata overrides include in main config\n    lineinfile:\n      dest: /etc/suricata/suricata.yaml\n      line: \"include: rocknsm-overrides.yaml\"\n      state: present\n    when: with_suricata\n\n  - name: Enable and start suricata\n    service:\n      name: suricata\n      enabled: \"{{ enable_suricata }}\"\n      state: \"{{ 'started' if enable_suricata else 'stopped' }}\"\n    when: with_suricata\n\n  - name: Configure logrotate for suricata logs\n    template:\n      src: templates/logrotate-suricata.conf.j2\n      dest: /etc/logrotate.d/suricata.conf\n      mode: 0644\n      owner: root\n      group: root\n    when: with_suricata\n\n    ######################################################\n    ################# Setup PulledPork  ##################\n    ######################################################\n  - name: Create pulledpork directory symlink\n    file:\n      src: \"/opt/pulledpork-{{ pulledpork_release }}\"\n      dest: \"/opt/pulledpork\"\n      state: link\n      force: yes\n    when: with_pulledpork\n\n  - name: Set pulledpork executable\n    file:\n      path: /opt/pulledpork/pulledpork.pl\n      mode: 0755\n      owner: root\n      group: root\n    when: with_pulledpork\n\n  - name: Create pulledpork config dir\n    file:\n      path: /etc/pulledpork\n      mode: 0755\n      owner: root\n      group: root\n      state: directory\n    when: with_pulledpork\n\n  - name: Configure pulledpork\n    template:\n      src: templates/pulledpork.conf.j2\n      dest: /etc/pulledpork/pulledpork.conf\n      owner: root\n      group: root\n      mode: 0644\n    when: with_pulledpork\n\n  - name: Check stats of rules files\n    stat:\n      path: \"{{ pulledpork_engine_basepath }}/rules/pulledpork.rules\"\n    register: rules_file\n    when: with_pulledpork\n\n  - name: Create initial pulledpork rules-related files\n    file:\n      path: \"{{ pulledpork_engine_basepath }}/rules/pulledpork.rules\"\n      owner: root\n      group: root\n      mode: 0644\n      state: touch\n    when: with_pulledpork and not rules_file.stat.exists\n\n  - name: Schedule pulledpork to run daily\n    cron:\n      name: \"pulledpork update\"\n      cron_file: rocknsm_pulledpork\n      user: root\n      hour: \"12\"\n      minute: \"0\"\n      job: /opt/pulledpork/pulledpork.pl\n        -c /etc/pulledpork/pulledpork.conf\n        -l > /var/log/pulledpork.log 2>&1;\n        {{ \"/usr/bin/systemctl kill -s USR2 suricata;\" if with_suricata else None }}\n        {{ \"/usr/bin/systemctl restart snortd;\" if with_snort else None }}\n    when: with_pulledpork\n\n    #######################################################\n    ######################## FSF ##########################\n    #######################################################\n  - name: Create FSF data dir\n    file:\n      path: \"{{ fsf_data_dir }}\"\n      mode: 0755\n      owner: \"{{ fsf_user }}\"\n      group: \"{{ fsf_group }}\"\n      state: directory\n    when: with_fsf\n\n  - name: Create FSF archive dir\n    file:\n      path: \"{{ fsf_archive_dir }}\"\n      mode: 0755\n      owner: \"{{ fsf_user }}\"\n      group: \"{{ fsf_group }}\"\n      state: directory\n    when: with_fsf\n\n  - name: Configure logrotate for FSF logs\n    copy:\n      src: logrotate-fsf.conf\n      dest: /etc/logrotate.d/fsf.conf\n      mode: 0644\n      owner: root\n      group: root\n    when: with_fsf\n\n  - name: Configure fsf-server\n    template:\n      src: templates/fsf-server-config.j2\n      dest: /opt/fsf/fsf-server/conf/config.py\n      owner: \"{{ fsf_user }}\"\n      group: \"{{ fsf_group }}\"\n      mode: 0644\n    when: with_fsf\n\n  - name: Configure fsf-client\n    template:\n      src: templates/fsf-client-config.j2\n      dest: /opt/fsf/fsf-client/conf/config.py\n      owner: \"{{ fsf_user }}\"\n      group: \"{{ fsf_group }}\"\n      mode: 0644\n    when: with_fsf\n\n  - name: Enable and start FSF\n    service:\n      name: fsf\n      state: \"{{ 'started' if enable_fsf else 'stopped' }}\"\n      enabled: \"{{ enable_fsf }}\"\n    when: with_fsf\n\n    ######################################################\n    ################### Setup Kibana #####################\n    ######################################################\n  - name: Enable and start Kibana\n    service:\n      name: kibana\n      state: \"{{ 'started' if enable_kibana else 'stopped' }}\"\n      enabled: \"{{ enable_kibana }}\"\n    when: with_kibana\n\n  - name: Download ROCK Dashboards\n    get_url:\n      url: \"{{ rock_dashboards_url }}\"\n      dest: \"{{ rock_cache_dir }}/{{ rock_dashboards_filename }}\"\n      mode: 0644\n    when: with_kibana and rock_online_install\n\n  - name: Extract ROCK Dashboards\n    unarchive:\n      src: \"{{ rock_cache_dir }}/{{ rock_dashboards_filename }}\"\n      dest: /opt/rocknsm\n      owner: root\n      group: root\n      creates: \"/opt/rocknsm/rock-dashboards-{{ rock_dashboards_branch }}\"\n      remote_src: yes\n    when: with_kibana\n\n  - name: Query Kibana package info\n    yum:\n      list: kibana\n    register: kibana_pkg\n    when: with_kibana\n\n  - name: Store installed kibana pkg info\n    set_fact:\n      kibana_info: \"{{ kibana_pkg.results | selectattr('repo', 'match', 'installed') | first }}\"\n    when: with_kibana\n\n  - name: Check current Kibana config\n    uri:\n      method: \"GET\"\n      url: \"{{ es_url }}/.kibana/config/{{ kibana_info.version }}/_source\"\n      return_content: true\n    register: kibana_cfg\n    changed_when: false\n    until: kibana_cfg.status == 200\n    retries: 10\n    delay: 3\n    when: with_kibana\n\n  - name: Store Kibana config dict\n    set_fact:\n      kibana_config: \"{{ kibana_cfg.json }}\"\n    when: with_kibana\n\n  - name: Configure Kibana templates\n    uri:\n      method: PUT\n      url: http://localhost:9200/_template/kibana-config\n      body: >\n        { \"order\" : 0, \"template\" : \".kibana\",\n          \"settings\" :\n            { \"index.number_of_replicas\" : \"0\",\n              \"index.number_of_shards\" : \"1\" },\n          \"mappings\" : { }, \"aliases\" : { } }\n      status_code: 200,201\n    when: with_kibana\n\n  - name: Push Kibana dashboard config\n    command: >\n      /opt/rocknsm/rock-dashboards-{{ rock_dashboards_branch }}/load.sh\n        -url {{ es_url }}\n    args:\n      chdir: /opt/rocknsm/rock-dashboards-{{ rock_dashboards_branch }}/\n    when: with_kibana and (kibana_config.rock_config is undefined or kibana_config.rock_config != rock_dashboards_version)\n\n  - name: Store default Kibana index to Bro\n    set_fact:\n      kibana_config: \"{{ kibana_config | combine({'defaultIndex': 'bro-*' })}}\"\n    when: with_kibana and with_bro\n\n  - name: Store default Kibana index to Suricata\n    set_fact:\n      kibana_config: \"{{ kibana_config | combine({'defaultIndex': 'suricata-*' })}}\"\n    when: with_kibana and with_suricata and not with_bro\n\n  - name: Update Kibana config dict w/ rock_config version\n    set_fact:\n      kibana_config: \"{{ kibana_config | combine({'rock_config': rock_dashboards_version }) }}\"\n    when: with_kibana\n\n  - name: Push Kibana settings for index and rock_version\n    uri:\n      method: PUT\n      url: \"{{ es_url }}/.kibana/config/{{ kibana_info.version }}\"\n      body: \"{{ kibana_config }}\"\n      body_format: \"json\"\n      status_code: 200,201\n    when: with_kibana\n\n  - name: Add the kibanapw shell function\n    copy:\n      src: profile.d-kibanapw.sh\n      dest: /etc/profile.d/kibanapw.sh\n      mode: 0644\n      owner: root\n      group: root\n    when: with_kibana\n\n  - name: Set initial Kibana credentials\n    shell: >\n      kibuser=$(getent passwd 1000 | awk -F: '{print $1}')\n      kibpw=$(xkcdpass -a rock)\n      echo -e \"U: ${kibuser}\\nP: ${kibpw}\" > /home/${kibuser}/KIBANA_CREDS.README\n      printf \"${kibuser}:$(echo ${kibpw} | openssl passwd -apr1 -stdin)\\n\" | sudo tee -a /etc/nginx/.htpasswd > /dev/null 2>&1\n    args:\n      creates: /etc/nginx/.htpasswd\n    when: with_kibana\n\n\n    ######################################################\n    ################### Setup nginx ######################\n    ######################################################\n  - name: Install ROCK nginx configuration\n    template:\n      src: templates/nginx-rock.conf.j2\n      dest: /etc/nginx/conf.d/rock.conf\n      mode: 0644\n      owner: root\n      group: root\n    when: with_nginx and with_kibana\n\n  - name: Install nginx base configuration\n    copy:\n      src: nginx.conf\n      dest: /etc/nginx/nginx.conf\n      mode: 0644\n      owner: root\n      group: root\n    when: with_nginx\n\n  - name: Enable nginx to perform proxy connect\n    seboolean: \n      name: httpd_can_network_connect\n      state: yes \n      persistent: yes\n    when: with_nginx and with_kibana\n\n  - name: Enable and start nginx\n    service:\n      name: nginx\n      state: \"{{ 'started' if enable_nginx else 'stopped' }}\"\n      enabled: \"{{ enable_nginx }}\"\n    when: with_nginx\n\n  - name: Create easy-rsa working dir\n    file:\n      path: /opt/easy-rsa\n      state: directory\n      mode: 0750\n      owner: root\n      group: root\n    when: with_kibana and with_nginx\n\n  - name: Create working copy of easy-rsa\n    copy:\n      src: /usr/share/easy-rsa/2.0/\n      dest: /opt/easy-rsa/\n      mode: 0750\n      owner: root\n      group: root\n    when: with_kibana and with_nginx\n\n  - name: Apply easy-rsa vars template\n    template:\n      src: templates/easy-rsa-vars.j2\n      dest: /opt/easy-rsa/vars\n      mode: 0644\n    when: with_kibana and with_nginx\n\n  - name: Generate and copy Kibana keys\n    shell: >\n      cd /opt/easy-rsa\n      ./build-ca --batch nopass\n      ./build-dh --batch\n      ./build-key-server --batch {{ rock_hostname }}\n      cat keys/{{{ rock_hostname }}.crt,ca.crt} >> /etc/pki/bundle.crt\n      cp keys/{{ rock_hostname }}.key /etc/pki/bundle.key\n      cp keys/dh2048.pem /etc/pki/\n    args:\n      chdir: /opt/easy-rsa/\n      creates: /etc/pki/dh2048.pem\n    when: with_kibana and with_nginx\n\n    ######################################################\n    ############### Setup ROCKNSM Scripts ################\n    ######################################################\n  - name: Install rock start script\n    copy:\n      src: rock_start\n      dest: /usr/local/bin/rock_start\n      mode: 0700\n      owner: root\n      group: root\n\n  - name: Install rock stop script\n    copy:\n      src: rock_stop\n      dest: /usr/local/bin/rock_stop\n      mode: 0700\n      owner: root\n      group: root\n\n  - name: Install rock status script\n    copy:\n      src: rock_status\n      dest: /usr/local/bin/rock_status\n      mode: 0755\n      owner: root\n      group: root\n\n  - name: Create rock script symlinks\n    file:\n      src: \"/usr/local/bin/{{ item.src }}\"\n      dest: \"/usr/sbin/{{ item.dest }}\"\n      force: yes\n      state: link\n    with_items:\n      - { src: 'rock_start', dest: 'rock_start' }\n      - { src: 'rock_stop', dest: 'rock_stop' }\n      - { src: 'rock_status', dest: 'rock_status' }\n\n  # Training mode / Service mode not needed for AF_PACKET\n  ######################################################\n  ############### ROCKNSM Customization ################\n  ######################################################\n  - name: Install ROCK NSM /etc/issue\n    copy:\n      src: etc-issue.in\n      dest: /etc/issue.in\n      mode: 0644\n      owner: root\n      group: root\n\n  - name: NetworkManager ROCK NSM hook\n    copy:\n      src: nm-issue-update\n      dest: /etc/NetworkManager/dispatcher.d/50-rocknsm-issue-update\n      mode: 0755\n      owner: root\n      group: root\n\n  #######################################################\n  #####################  Handlers  ######################\n  #######################################################\n  handlers:\n    - name: force sync time\n      command: >\n        chronyc -a 'burst 3/4'; sleep 5; chronyc -a makestep\n\n    - name: configure monitor interfaces\n      shell: >\n        for intf in {{ rock_monifs | join(' ') }}; do\n          /sbin/ifup ${intf};\n        done\n\n    - name: sshd restart\n      service: name=sshd state=restarted\n\n    - name: es maintenance\n      command: /usr/local/bin/es_cleanup.sh\n\n    - name: reload broctl\n      service: name=broctl state=restarted\n\n    - name: create kafka bro topic\n      command: >\n        /opt/kafka/bin/kafka-topics.sh\n           --zookeeper 127.0.0.1:2181\n           --create\n           --replication-factor 1\n           --topic bro-raw\n           --partitions 1\n\n    - name: create kafka suricata topic\n      command: >\n        /opt/kafka/bin/kafka-topics.sh\n           --zookeeper 127.0.0.1:2181\n           --create\n           --replication-factor 1\n           --topic suricata-raw\n           --partitions 1\n\n    - name: create kafka fsf topic\n      command: >\n        /opt/kafka/bin/kafka-topics.sh\n           --zookeeper 127.0.0.1:2181\n           --create\n           --replication-factor 1\n           --topic fsf-raw\n           --partitions 1\n\n    - name: reload systemd\n      command: systemctl daemon-reload\n\n    - name: Restart Logstash\n      service:\n        name: logstash\n        state: restarted\n\n    - name: Restart Filebeat\n      service:\n        name: filebeat\n        state: restarted\n\n  environment:\n   http_proxy:  \"{{ http_proxy }}\"\n   https_proxy: \"{{ https_proxy }}\"\n   HTTP_PROXY:  \"{{ http_proxy }}\"\n   HTTPS_PROXY: \"{{ https_proxy }}\"\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "ffdd66d2e9caa103867773241b75fce182b3742a", "filename": "roles/remote-user/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Require manual definition of remote-user\n  fail:\n    msg: |\n      When using `--ask-pass` option, use `-u` option to define remote-user:\n      ansible-playbook server.yml -e env={{ env }} -u root --ask-pass\n  when: ansible_user is not defined and cli_ask_pass | default(false)\n\n- name: Check whether Ansible can connect as root\n  local_action: command ansible {{ inventory_hostname }} -m raw -a whoami -u root {{ cli_options | default('') }}\n  failed_when: false\n  changed_when: false\n  register: root_status\n  tags: [connection-tests]\n\n- name: Set remote user for each host\n  set_fact:\n    ansible_user: \"{{ ('root' in root_status.stdout_lines) | ternary('root', admin_user) }}\"\n  when: ansible_user is not defined\n\n- name: Announce which user was selected\n  debug:\n    msg: \"Note: Ansible will attempt connections as user = {{ ansible_user }}\"\n\n- name: Load become password\n  set_fact:\n    ansible_become_pass: \"{% for user in vault_users | default([]) if user.name == ansible_user and user.password is defined %}{% if loop.first %}{{ user.password }}{% endif %}{% endfor %}\"\n  when: ansible_user != 'root' and not cli_ask_become_pass | default(false) and ansible_become_pass is not defined\n  no_log: true\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "43fdcbcb0c1eccb41bb19a646ecf3293cbc47984", "filename": "roles/1-prep/tasks/prep.yml", "repository": "iiab/iiab", "decoded_content": "- name: Since f22, dnf has replaced yum, but ansible works with yum\n  command: dnf install -y yum\n  when: ansible_distribution == \"Fedora\" and ansible_distribution_version|int >= 22\n\n- name: Install iiab-extra repos\n  template: backup=yes\n            dest=/etc/yum.repos.d/iiab-extra.repo\n            src=iiab-extra.repo\n            owner=root\n            mode=0666\n  when: is_redhat\n\n- name: Install iiab-testing repos\n  template: backup=yes\n            dest=/etc/yum.repos.d/iiab-testing.repo\n            src=iiab-testing.repo\n            owner=root\n            mode=0666\n  when: is_redhat\n\n- name: Install rpmfusion-free-updates repo -- for exfat\n  template: dest=/etc/yum.repos.d/rpmfusion-free-updates.repo\n            src=rpmfusion-free-updates.repo\n            owner=root\n            mode=0666\n  when:     ansible_distribution == \"Fedora\"\n\n- name: Create /etc/iiab\n  file: path=/etc/iiab\n        owner=root\n        group=root\n        mode=0755\n        state=directory\n\n- name: Set XO model\n  set_fact:\n    phplib_dir: '{{ ansible_local[\"local_facts\"][\"phplib_dir\"] }}'\n    xo_model: '{{ ansible_local[\"local_facts\"][\"xo_model\"] }}'\n\n- name: Install script to fully initialize network config, and/or collect data\n# calling iiab-network-reset w/ snapshot name, stores info, but aborts reset\n# intended as a convenience function for us\n  template: src=iiab-network-reset\n            dest=/usr/bin\n            owner=root\n            group=root\n            mode=0755\n\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "2465c7a041beb09f079cc4d5c936d3142356b95e", "filename": "roles/manage-confluence-space/tasks/copy_confluence_content.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Get Content from Source\n  uri:\n    url: '{{ confluence_space_source_url }}/rest/api/content/{{ confluence_space_content.id }}?expand=body.storage,history,space,container.history,container.version,version,ancestors'\n    method: GET\n    user: '{{ source_confluence_site_username }}'\n    password: '{{ source_confluence_site_password }}'\n    force_basic_auth: yes\n    status_code: 200\n    return_content: yes\n  register: content_json\n  no_log: true\n\n- name: Map ancestor ids if any\n  set_fact: \n    content_ancestors: \"{{ content_json.json.ancestors | map(attribute='id') | list | map('extract', id_mapping) | list }}\"\n\n- name: Pick only the last ancestor\n  set_fact:\n    content_ancestors: \"{{ [-1] | map('extract', content_ancestors) | list }}\"\n  when: content_ancestors|length > 0\n\n- name: Create a tempfile for Content JSON\n  command: mktemp\n  register: jsontemp\n  delegate_to: 127.0.0.1\n\n- name: Generate Content JSON from Template\n  template:\n    src: content.j2\n    dest: '{{ jsontemp.stdout }}'\n  delegate_to: 127.0.0.1\n\n- name: Escape HTML Double Quotes\n  replace:\n    path: '{{ jsontemp.stdout }}'\n    regexp: '(?<==)(\\\")|(\\\")(?=[>\\ ])'\n    replace: '\\\"'\n\n- name: Remove literal newlines\n  replace:\n    path: '{{ jsontemp.stdout }}'\n    regexp: '\\n'\n    replace: ''\n\n- name: Unescape Single Quote\n  replace:\n    path: '{{ jsontemp.stdout }}'\n    regexp: \"\\\\'\"\n    replace: \"'\"\n\n- name: Create Content at Destination Site\n  uri:\n    url: '{{ confluence_space_destination_url }}/rest/api/content'\n    method: POST\n    user: '{{ destination_confluence_site_username }}'\n    password: '{{ destination_confluence_site_password }}'\n    force_basic_auth: yes\n    status_code: 200\n    body_format: json\n    body: \"{{ lookup('file', '{{ jsontemp.stdout }}') }}\"\n    return_content: yes\n  register: new_content_json\n  no_log: true\n\n- name: Append New id to old id mapping\n  set_fact:\n    id_mapping: \"{{ id_mapping|combine({ content_json.json.id : { 'id' : new_content_json.json.id }}) }}\"\n"}, {"commit_sha": "c5ca8972146c84a12b80cd589c873884699d06bc", "sha": "f9d90794baa32bd476419e56f9ef136b71a1e433", "filename": "tasks/main.yml", "repository": "dev-sec/ansible-nginx-hardening", "decoded_content": "---\n- name: add the OS specific variables\n  include_vars: \"{{ ansible_os_family }}.yml\"\n\n- name: config should not be worldwide read- or writeable\n  file: path=\"/etc/nginx\" mode=\"o-rw\" owner=\"root\" group=\"root\" recurse=yes\n\n- name: create additional configuration\n  template: src=\"hardening.conf.j2\" dest=\"{{nginx_config_conf_dir}}/90.hardening.conf\" owner=\"root\" group=\"root\"\n  notify: reload nginx\n\n- name: change configuration in main nginx.conf\n  lineinfile: dest=\"/etc/nginx/nginx.conf\" regexp=\"^\\s*server_tokens\" line=\"server_tokens {{nginx_server_tokens}};\" insertafter=\"http {\"\n  notify: reload nginx\n\n- name: change client_max_body_size in main nginx.conf\n  lineinfile: dest=\"/etc/nginx/nginx.conf\" regexp=\"^\\s*client_max_body_size\" line=\"client_max_body_size {{nginx_client_max_body_size}};\" insertafter=\"http {\"\n  notify: reload nginx\n\n- name: change client_body_buffer_size in main nginx.conf\n  lineinfile: dest=\"/etc/nginx/nginx.conf\" regexp=\"^\\s*client_body_buffer_size\" line=\"client_body_buffer_size {{nginx_client_body_buffer_size}};\" insertafter=\"http {\"\n  notify: reload nginx\n\n- name: change keepalive_timeout in main nginx.conf\n  lineinfile: dest=\"/etc/nginx/nginx.conf\" regexp=\"^\\s*keepalive_timeout\" line=\"keepalive_timeout {{nginx_keepalive_timeout}};\" insertafter=\"http {\"\n  notify: reload nginx\n\n- name: remove default.conf\n  file: path=\"{{nginx_default_conf}}\" state=absent\n  when: nginx_remove_default_site\n  notify: reload nginx\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "b88cfb7ca17482cab9b4c412f9f2e9fcbc5ff07e", "filename": "roles/osp/admin-volume-type/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Obtain current volume types\"\n  shell: >\n    source {{ admin_keystonerc_file }};\n    openstack volume type list -f yaml\n  register: volume_type_list\n  changed_when: False\n\n- name: \"Store away the yaml output\"\n  set_fact:\n    volume_type_list_yaml: \"{{ volume_type_list.stdout|from_yaml }}\"\n\n- name: \"Delete the volume type(s) that should NOT exist\"\n  shell: >\n    source {{ admin_keystonerc_file }};\n    openstack volume type delete \"{{ item.Name }}\"\n  with_items:\n  - \"{{ volume_type_list_yaml | get_remaining_items(cinder_volume_types, 'Name', 'name') }}\"\n\n- name: \"Create the volume type(s) that should exist\"\n  shell: >\n    source {{ admin_keystonerc_file }};\n    openstack volume type create \\\n      --public \\\n      --property \"volume_backend_name={{ item.backend }}\" \\\n      \"{{ item.name }}\"\n  with_items:\n  - \"{{ cinder_volume_types | get_remaining_items(volume_type_list_yaml, 'name', 'Name') }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "9e892972b152d96001df29e37c1e06022a56aaea", "filename": "roles/config-vlans/tasks/interfaces.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Configure VLAN interfaces\"\n  template:\n    src: vlan.j2 \n    dest: /etc/sysconfig/network-scripts/ifcfg-{{ ifcfg.device }}\n  with_items:\n  - '{{ vlans }}'\n  loop_control:\n    loop_var: ifcfg\n\n- name: \"Attempt to Bring Up VLAN interfaces\"\n  command: ifup {{ ifcfg.device }}\n  with_items:\n  - '{{ vlans }}'\n  loop_control:\n    loop_var: ifcfg\n  ignore_errors: yes\n\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "a9c85c0cca1dcd5431939a4570414266a8e38da2", "filename": "roles/ansible/tower/manage-credentials/tasks/process-credential.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Get the org id based on the org name\"\n  set_fact:\n    org_id: \"{{ item.id }}\"\n  when:\n  - item.name|trim == credential.organization|trim\n  with_items:\n  - \"{{ existing_organizations_output.rest_output }}\"\n\n- name: \"Get the credential_type id based on the name\"\n  set_fact:\n    credential_type_id: \"{{ item.id }}\"\n  when:\n  - item.name|trim == credential.credential_type|trim\n  with_items:\n  - \"{{ existing_credential_types_output.rest_output }}\"\n\n- name: \"Load up the credential\"\n  uri:\n    url: https://localhost/api/v2/credentials/\n    method: POST\n    body: \"{{ lookup('template', 'credential.j2') }}\"\n    body_format: 'json'\n    headers:\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n    user: admin\n    password: \"{{ tower_admin_password }}\"\n    validate_certs: no\n    status_code: 200,201,400\n\n- name: \"Clear/Update facts\"\n  set_fact:\n    org_id: ''\n    credential_type_id: ''\n    processed_credentials: \"{{ processed_credentials + [ { 'name': credential.name } ] }}\"\n"}, {"commit_sha": "e91a55152358e890a05cf849abc7d58b8badecc2", "sha": "8c2f0c6f8aa5b61dbdfa7e314490d2a95cf4f40e", "filename": "meta/main.yml", "repository": "fubarhouse/ansible-role-golang", "decoded_content": "galaxy_info:\n  author: Karl Hepworth\n  description: Installs the Go programming language from distribution, or build from source, and install desired packages to your Golang workspace!\n  license: MIT\n  min_ansible_version: 2.0\n  platforms:\n  - name: MacOSX\n    versions:\n    - all\n  - name: Ubuntu\n    versions:\n    - artful\n    - zesty\n    - yakkety\n    - xenial\n    - vivid\n    - wily\n    - utopic\n    - trusty\n    - saucy\n    - raring\n    - quantal\n    - precise\n  - name: EL\n    versions:\n    - 6\n    - 7\n  - name: Debian\n    versions:\n    - wheezy\n    - jessie\n    - stretch\n  galaxy_tags:\n  - go\n  - development\n  - programming\n  - language\n  - compiler\n  - package\n  - manager\ndependencies: []"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "451d688741d3653b638044fd5a6264b055987734", "filename": "roles/manage-aws-infra/tasks/create-security-group.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "# Create Security Group (SG)\n---\n\n- name: \"Create Security Group for {{ sg_name }}\"\n  ec2_group:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    name: \"{{ sg_name }}\"\n    description: \"{{ sg_description }}\"\n    vpc_id: \"{{ aws_vpc_id }}\"\n    region: \"{{ aws_region }}\"\n    state: \"present\"\n    tags:\n      env_id: \"{{ env_id }}\"\n    rules: \"{{ sg_rules }}\"\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "971f605f37ff0aa8e8351edfb0a1b50188f9b654", "filename": "roles/config-dns-server/tasks/named_keys.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Setup Domain Keys configuration\n  template:\n    src: named.conf.domain-keys.j2\n    dest: /etc/named/named.conf.domain-keys\n    owner: named\n    group: named\n    mode: 0660\n  notify: restart named\n\n- import_tasks: generate_keys.yml\n  run_once: true\n  delegate_to: \"{{ ansible_play_hosts | first }}\"\n\n- name: Setup key files for nsupdate\n  template:\n    src: domain-key.j2\n    dest: /var/named/{{ item.item }}.key\n    owner: named\n    group: named\n    mode: 0660\n  with_items:\n  - \"{{ hostvars[ansible_play_hosts | first].nsupdate_keys_captured.results }}\"\n  notify: restart named\n\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "a8a7cfe0617a36f6b88dbcffe553083fdf1e144b", "filename": "tasks/selinux-RedHat.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n\n- name: Make sure we have the necessary yum packages available for selinux\n  yum:\n    name:\n      - libselinux-python\n      - libsemanage-python\n    state: present\n"}, {"commit_sha": "64cbc6946b7ebc0d9a36f40d77ac86f8e3564499", "sha": "aee7e7fc64164613b28dd334187f0d5049d52a92", "filename": "tasks/upgrade.yml", "repository": "CSCfi/ansible-role-slurm", "decoded_content": "---\n\n#### Upgrade\n\n  - name: Pause if we are upgrading between major slurm versions on the dbd host\n    pause: prompt=\"slurm is set to be upgraded on {{ ansible_hostname }}. This is a manual task. Press ENTER when the manual steps are done.\"\n    when: (slurm_fact_fgci_slurmrepo_version != reg_slurm_yum_version_major['stdout']) and (slurm_accounting_storage_host == ansible_hostname) and (reg_slurm_yum_version_major['stdout'] != \"\")\n    # if the fgci_slurmrepo variable is not same as the version installed\n    # if we are on the slurm accouting storage host\n    # if the version installed is not \"\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "dc78c1b6ae4b3d99f976fc367bde081cb56aedb5", "filename": "roles/openvpn/templates/iiab-vpn", "repository": "iiab/iiab", "decoded_content": "#!/bin/sh\n# script to manage openvpn\nif [ ! -f \"/etc/openvpn/iiab-vpn.conf\" ]; then\n  VPNCONFIG='party-line.conf'\n  VPNIP={{ openvpn_server_virtual_ip }}\nelse\n  # expect the sourced file to set the above variables\n  source /etc/openvpn/iiab-vpn.conf\nfi\n\n# we'd like the user of this script to have root privilege\nif [ \"$(id -u)\" != \"0\" ]; then\n    echo \"This script must be run as root\" 1>&2\n    exit 1\nfi\n\ncase $1 in\n\"stop\" | \"no\" | \"off\")\n    killall openvpn\n    exit 0\n    ;;\n\"status\")\n    pid=`ps -e|grep openvpn`\n    if [ -z \"$pid\" ]; then\n        echo \"The openvpn process is not running\"\n    else\n        echo \"Openvpn is running with id $pid\"\n        ip=`ifconfig tun | gawk '(/netmask /) {print( $2);}'`\n        echo \"Local vpn tunnel address is $ip\"\n    fi\n    exit 0\n    ;;\n    \nesac\n\n# we'd like for passwords authentication to be turned off\ngrep -e^PasswordAuthentication.*[Yy]es /etc/ssh/sshd_config\nPASSWORDS_ENABLED=$?\n\nif [ $PASSWORDS_ENABLED -eq 0 ];then\n\tcase $1 in\n    \"test\" | \"unsafe\") ;;\n    *)\n\n\t\techo \"Openvpn is only safe when public/private keys are used\"\n\t\techo \" And when passwords are turned off in /etc/ssh/sshd_conf\"\n\t\texit 1\n  esac\nfi\n\n# openvpn config file directory\ndir=/etc/openvpn\n\nif [ $# -eq 0 ]; then\n  cmd=\"test\"\nelse\n  cmd=$1\nfi\n\ncase $cmd in\n\"test\" | \"unsafe\" )\n# load TUN/TAP kernel module\n    modprobe tun\n\n\t# make sure the wan is functioning\n\t# 8.8.8.8 is one of google's dns servers\n\tping -c 3 -i 3 8.8.8.8\n\tif [ $? -ne 0 ]; then\n\t\techo \"internet is not available, tunnel not possible\"\n\t\texit 1\n\tfi\n\t\n\t# check the vpn tunnel\n\tping -c 5 -i 5 \"$VPNIP\"\n\t# a zero return means the tunnel is up\n\tif [ $? -ne \"0\" ]; then\n\t\techo \"Stopping any openvpn instance\"\n\t\tkillall openvpn\n\t\tsleep 10\n\t\techo \"Starting openvpn and waiting 10 seconds for daemon to become ready\"\n    \t\topenvpn --cd $dir --daemon --config $VPNCONFIG\n\tfi\n\tsleep 10 \n\techo \"Testing VPN connection\"\n\tping -c 4 -i 4 \"$VPNIP\"\n\tif [ $? -eq 0 ]; then\n\t\techo \"vpn tunnel established\"\n\telse\n\t\techo \"vpn connection failed\"\n\tfi\n\n    ;;\nesac\n"}, {"commit_sha": "f92ebbef856e59bd4563d4b5b69ee75a95ec89d5", "sha": "6e32b56c520785a37bc7d05bd1eb2f0f936d8e77", "filename": "roles/openshift-login/tasks/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n# This role requires the following facts to be set before execution:\n# - openshift_login_url\n# - openshift_user/openshift_password OR openshift_token\n# - oc_login (optional - only set to False if a valid session / token already exists)\n\n- name: \"Set Default Login Facts\"\n  set_fact:\n    auth_token: False\n    auth_user_pass: False\n\n- name: \"Fail for Missing OpenShift Hosting Env\"\n  fail: msg=\"This role requires openshift_login_url to be set and non empty\"\n  when: \n  - openshift_login_url|trim == \"\"\n\n- name: \"Set variable openshift_user when not set\"\n  set_fact:\n    openshift_user: ''\n  when: openshift_user is not defined\n\n- name: \"Set variable openshift_password when not set\"\n  set_fact:\n    openshift_password: ''\n  when: openshift_password is not defined\n\n- name: \"Set variable openshift_token when not set\"\n  set_fact:\n    openshift_token: ''\n  when: openshift_token is not defined\n\n- name: \"Default oc_login to True when not set\"\n  set_fact:\n    oc_login: True\n  when: oc_login is not defined\n\n- name: \"Check whether we will authenticate with username & password\"\n  set_fact:\n    auth_user_pass: True\n  when:\n  - openshift_user|trim != ''\n  - openshift_password|trim != ''\n  - oc_login|bool == True\n\n- name: \"Check whether we will authenticate with a token\"\n  set_fact:\n    auth_token: True\n  when:\n  - openshift_token|trim != ''\n  - oc_login|bool == True\n\n- name: \"Fail for Missing Authentication method\"\n  fail: msg=\"This role requires either openshift_token, or openshift_user and openshift_password to be set\"\n  when:\n  - auth_token|bool == False\n  - auth_user_pass|bool == False\n  - oc_login|bool == True\n\n- name: \"Log in to OpenShift Client (username/password)\"\n  command: >\n    {{ openshift.common.client_binary }} login {{ openshift_login_url }}\n    --insecure-skip-tls-verify=true --username={{ openshift_user }} --password={{ openshift_password }}\n  changed_when: False\n  when:\n  - auth_user_pass|bool == True\n  - auth_token|bool == False\n  - oc_login|bool == True\n\n- name: \"Log in to OpenShift Client (token)\"\n  command: >\n    {{ openshift.common.client_binary }} login {{ openshift_login_url }}\n    --insecure-skip-tls-verify=true --token={{ openshift_token }}\n  changed_when: False\n  when:\n  - auth_user_pass|bool == False\n  - auth_token|bool == True\n  - oc_login|bool == True\n\n- name: \"Add token to all openshift client comands when token is set\"\n  set_fact:\n    openshift:\n      common:\n        client_binary: \"{{ openshift.common.client_binary }} --token={{ openshift_token }}\"\n        admin_binary: \"{{ openshift.common.admin_binary }} --token={{ openshift_token }}\"\n  when: auth_token|bool == True\n\n- name: \"Gather the openshift token, if not already set\"\n  command: >\n    {{ openshift.common.client_binary }} whoami -t\n  register: token_output\n  when:\n  - openshift_token|trim == ''\n\n- name: \"Set openshift_token fact when not already set\"\n  set_fact:\n    openshift_token: \"{{ token_output.stdout }}\"\n  when: \n  - token_output.stdout is defined\n  - token_output|trim != ''\n\n"}, {"commit_sha": "836dc4dd0dacc490044a14c0e39469d162b9449b", "sha": "72fcf39d155dd20912816d19b9aeb5c2d0e07518", "filename": "tasks/prelim.yml", "repository": "florianutz/Ubuntu1604-CIS", "decoded_content": "---\n# Preliminary tasks that should always be run\n# List users in order to look files inside each home directory\n- name: \"PRELIM | List users accounts\"\n  command: \"awk -F: '{print $1}' /etc/passwd\"\n  register: users\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Gather accounts with empty password fields\"\n  shell: \"cat /etc/shadow | awk -F: '($2 == \\\"\\\" ) {j++;print $1; } END {exit j}'\"\n  register: empty_password_accounts\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Gather UID 0 accounts other than root\"\n  shell: \"cat /etc/passwd | awk -F: '($3 == 0 && $1 != \\\"root\\\") {i++;print $1 } END {exit i}'\"\n  register: uid_zero_accounts_except_root\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Run apt cache update\"\n  apt:\n    update_cache: true\n  changed_when: false\n\n- name: \"PRELIM | Section 4.1 | Configure System Accounting (auditd)\"\n  apt:\n    name: \"{{ auditd_package[ansible_os_family] }}\"\n    state: present\n    install_recommends: false\n\n- name: \"PRELIM | Section 5.1 | Configure cron\"\n  apt:\n    name: \"{{ cron_package[ansible_os_family] }}\"\n    state: present\n    install_recommends: false\n\n- name: \"PRELIM | Check if prelink package is installed\"\n  command: \"{{ prelim_check_package_command[ansible_os_family] }} prelink\"\n  register: prelink_installed\n  changed_when: false\n  failed_when: false\n  check_mode: false\n  tags:\n    - skip_ansible_lint\n\n- name: \"PRELIM | Check if postfix package is installed\"\n  command: \"{{ prelim_check_package_command[ansible_os_family] }} postfix\"\n  register: postfix_installed\n  changed_when: false\n  failed_when: false\n  check_mode: false\n  tags:\n    - skip_ansible_lint\n\n# Individual service checks\n- name: \"PRELIM | Check for xinetd service\"\n  shell: \"systemctl show xinetd | grep LoadState | cut -d = -f 2\"\n  register: xinetd_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for ntpd service\"\n  shell: \"systemctl show {{ ntp_service[ansible_os_family] }} | grep LoadState | cut -d = -f 2\"\n  register: ntpd_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for chronyd service\"\n  shell: \"systemctl show {{ chrony_service[ansible_os_family] }} | grep LoadState | cut -d = -f 2\"\n  register: chronyd_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for avahi-daemon service\"\n  shell: \"systemctl show avahi-daemon | grep LoadState | cut -d = -f 2\"\n  register: avahi_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for cups service\"\n  shell: \"systemctl show cups | grep LoadState | cut -d = -f 2\"\n  register: cups_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for dhcpd service\"\n  shell: \"systemctl show dhcpd | grep LoadState | cut -d = -f 2\"\n  register: dhcpd_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for slapd service\"\n  shell: \"systemctl show slapd | grep LoadState | cut -d = -f 2\"\n  register: slapd_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for nfs service\"\n  shell: \"systemctl show nfs | grep LoadState | cut -d = -f 2\"\n  register: nfs_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for rpcbind service\"\n  shell: \"systemctl show rpcbind | grep LoadState | cut -d = -f 2\"\n  register: rpcbind_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for named service\"\n  shell: \"systemctl show named | grep LoadState | cut -d = -f 2\"\n  register: named_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for vsftpd service\"\n  shell: \"systemctl show vsftpd | grep LoadState | cut -d = -f 2\"\n  register: vsftpd_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for httpd service\"\n  shell: \"systemctl show httpd | grep LoadState | cut -d = -f 2\"\n  register: httpd_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for dovecot service\"\n  shell: \"systemctl show dovecot | grep LoadState | cut -d = -f 2\"\n  register: dovecot_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for smb service\"\n  shell: \"systemctl show smb | grep LoadState | cut -d = -f 2\"\n  register: smb_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for squid service\"\n  shell: \"systemctl show squid | grep LoadState | cut -d = -f 2\"\n  register: squid_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for snmpd service\"\n  shell: \"systemctl show snmpd | grep LoadState | cut -d = -f 2\"\n  register: snmpd_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for ypserv service\"\n  shell: \"systemctl show ypserv | grep LoadState | cut -d = -f 2\"\n  register: ypserv_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for rsh.socket service\"\n  shell: \"systemctl show rsh.socket | grep LoadState | cut -d = -f 2\"\n  register: rsh_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for rlogin.socket service\"\n  shell: \"systemctl show rlogin.socket | grep LoadState | cut -d = -f 2\"\n  register: rlogin_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for rexec.socket service\"\n  shell: \"systemctl show rexec.socket | grep LoadState | cut -d = -f 2\"\n  register: rexec_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for telnet service\"\n  shell: \"systemctl show telnet | grep LoadState | cut -d = -f 2\"\n  register: telnet_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for tftp service\"\n  shell: \"systemctl show tftp | grep LoadState | cut -d = -f 2\"\n  register: tftp_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for rsyncd service\"\n  shell: \"systemctl show rsyncd | grep LoadState | cut -d = -f 2\"\n  register: rsyncd_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for ntalk service\"\n  shell: \"systemctl show ntalk | grep LoadState | cut -d = -f 2\"\n  register: ntalk_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for autofs service\"\n  shell: \"systemctl show autofs | grep LoadState | cut -d = -f 2\"\n  register: autofs_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check for rhnsd service\"\n  shell: \"systemctl show rhnsd | grep LoadState | cut -d = -f 2\"\n  register: rhnsd_service_status\n  changed_when: false\n  check_mode: false\n\n- name: \"PRELIM | Check the grub configuration\"\n  stat:\n    path: /boot/grub/grub.cfg\n  register: grub_cfg\n"}, {"commit_sha": "abafe1581c6c78d784cf215b214947675d49eff8", "sha": "276ebfe6de56fc15d82829f771ffb54333826f96", "filename": "roles/ssh_tunneling/handlers/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: restart ssh\n  service: name=ssh state=restarted\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "b42fdd8b7d0047682fa5f329dc83d7893187f0a7", "filename": "examples/playbooks/provision_hypervisor.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\n# example playbook for provisioning hypervisors\n# use with examples/inventory/provision_hypervisor.inventory\n- hosts: hypervisors\n  remote_user: root\n  roles:\n    - {role: ovirt-common}\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "7461428fc924dec840cf5405acaa7d7cf3a92e1f", "filename": "tasks/main.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- import_tasks: prerequisites/install-prerequisites.yml\n  tags: nginx_prerequisites\n\n- import_tasks: keys/apt-key.yml\n  when:\n    - ansible_os_family == \"Debian\"\n    - nginx_install_from == \"nginx_repository\"\n      or nginx_amplify_enable\n      or nginx_controller_enable\n      or nginx_unit_enable\n  tags: nginx_aptkey\n\n- import_tasks: keys/rpm-key.yml\n  when:\n    - ansible_os_family == \"RedHat\"\n      or ansible_os_family == \"Suse\"\n    - nginx_install_from == \"nginx_repository\"\n      or nginx_amplify_enable\n      or nginx_controller_enable\n      or nginx_unit_enable\n  tags: nginx_rpmkey\n\n- import_tasks: keys/apk-key.yml\n  when: ansible_os_family == \"Alpine\"\n  tags: nginx_apkkey\n\n- name: \"(Install: Debian/Ubuntu/CentOS/RedHat/FreeBSD) Install NGINX\"\n  block:\n\n    - import_tasks: opensource/install-oss.yml\n      when: nginx_type == \"opensource\"\n      tags: nginx_install_oss\n\n    - import_tasks: plus/install-plus.yml\n      when: nginx_type == \"plus\"\n      tags: nginx_install_plus\n\n    - import_tasks: conf/cleanup-config.yml\n      when: nginx_cleanup_config | bool\n      tags: nginx_cleanup_config\n\n    - import_tasks: conf/upload-config.yml\n      when: nginx_main_upload_enable\n            or nginx_http_upload_enable\n            or nginx_stream_upload_enable\n            or nginx_html_upload_enable\n            or nginx_ssl_upload_enable\n      tags: nginx_upload_config\n\n    - import_tasks: conf/template-config.yml\n      when: nginx_main_template_enable\n            or nginx_http_template_enable\n            or nginx_stream_template_enable\n            or nginx_rest_api_enable\n      tags: nginx_template_config\n\n    - import_tasks: conf/setup-status.yml\n      when: nginx_status_enable | bool\n      tags: nginx_setup_status\n\n    - import_tasks: modules/install-modules.yml\n      when: true in nginx_modules.values()\n      tags: nginx_install_modules\n\n    - import_tasks: conf/debug-output.yml\n      when: nginx_debug_output | bool\n      tags: nginx_debug_output\n\n    - import_tasks: plus/delete-license.yml\n      when: nginx_type == \"plus\" and nginx_delete_license\n      tags: nginx_delete_license\n\n  when: nginx_enable | bool\n\n- import_tasks: amplify/install-amplify.yml\n  when:\n    - nginx_amplify_enable | bool\n    - nginx_amplify_api_key is defined\n    - nginx_amplify_api_key | length > 0\n  tags: nginx_install_amplify\n\n- import_tasks: controller/install-controller.yml\n  when:\n    - nginx_controller_enable | bool\n    - nginx_controller_api_key is defined\n    - nginx_controller_api_key | length > 0\n    - nginx_controller_api_endpoint is defined\n    - nginx_controller_api_endpoint | length > 0\n  tags: nginx_install_controller\n\n- import_tasks: unit/install-unit.yml\n  when: nginx_unit_enable | bool\n  tags: nginx_install_unit\n"}, {"commit_sha": "96adc61e360141bb718b75d48c387b3680a8471b", "sha": "c8d08f35f8c1e8bd91473e0b78c5325dbde65b82", "filename": "tasks/configure-docker.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Ensure /etc/docker directory exists\n  file:\n    path: /etc/docker\n    state: directory\n    mode: 0755\n  become: true\n\n- name: Configure Docker daemon (file)\n  copy:\n    src: \"{{ docker_daemon_config_file }}\"\n    dest: /etc/docker/daemon.json\n  become: true\n  notify: restart docker\n  when: docker_daemon_config_file is defined\n\n- name: Configure Docker daemon (variables)\n  copy:\n    content: \"{{ docker_daemon_config | to_nice_json }}\"\n    dest: /etc/docker/daemon.json\n  become: true\n  notify: restart docker\n  when: docker_daemon_config_file is not defined and\n        docker_daemon_config is defined\n\n- name: Ensure Docker default user namespace is defined in subuid and subgid\n  lineinfile:\n    path: \"{{ item }}\"\n    regexp: '^dockremap'\n    line: 'dockremap:500000:65536'\n  become: yes\n  with_items:\n    - /etc/subuid\n    - /etc/subgid\n  when: (_docker_os_dist == \"CentOS\" or _docker_os_dist == \"RedHat\") and\n        ((docker_daemon_config is defined and\n        docker_daemon_config['userns-remap'] is defined and\n        docker_daemon_config['userns-remap'] == 'default') or\n        docker_bug_usermod|bool == true)\n\n- name: Ensure thin-provisioning-tools is installed when devicemapper is used (Ubuntu)\n  package:\n    name: thin-provisioning-tools\n    state: present\n  become: yes\n  when: (_docker_os_dist == \"Ubuntu\" or _docker_os_dist == \"Debian\") and\n        docker_daemon_config['storage-driver'] is defined and\n        docker_daemon_config['storage-driver'] == 'devicemapper'\n\n- name: Enable Docker service\n  service:\n    name: docker\n    enabled: yes\n  notify: restart docker\n  register: docker_service\n  become: yes\n\n- name: Trigger start/restart of Docker\n  service:\n    name: docker\n  notify: restart docker\n  changed_when: docker_service.status.SubState != \"running\"\n  when: docker_service.status is defined\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "92d91c805cb53f8f195838d41015e09d2cabbdd3", "filename": "playbooks/osp/delete-osp-instance.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Delete Instance(s)\n  hosts: localhost\n  vars:\n    osp_resource_state: absent \n  roles:\n  - osp/admin-instance\n  - osp/admin-sec-group\n  - osp/admin-volume\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "426a767f83ff2985ff81676d36affc906c9ec865", "filename": "roles/config-chrony/tasks/chrony.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Ensure chrony service is enabled and started\" \n  service:\n    name: chronyd\n    enabled: yes\n    state: started\n\n- name: \"Ensure chrony is listening on the correct subnet\"\n  lineinfile: \n    path: /etc/chrony.conf\n    regexp: '#?allow .+'\n    line: \"allow {{ chrony_allow_subnet }}\"\n  notify: 'Reload chrony' \n\n- name: \"Ensure chrony has a fall-back in case of failed external sync\"\n  lineinfile: \n    path: /etc/chrony.conf\n    regexp: '#?local stratum .+'\n    line: \"local stratum 10\"\n  notify: 'Reload chrony' \n\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "59255cc6bfaa7a7cfe582bc0760ddfba28bd5b25", "filename": "roles/rollback/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- include: user-release.yml\n  when: release is defined\n\n- include: prior-release.yml\n  when: release is not defined\n\n- name: Check whether target release was from a successful deploy\n  stat:\n    path: \"{{ new_release_path }}/DEPLOY_UNFINISHED\"\n  register: target\n\n- name: Fail if target release was from failed deploy\n  fail:\n    msg: \"Cannot switch to release at {{ new_release_path }}. It is from an unfinished deploy. You may manually specify a different release using --extra-vars='release=12345678901234'.\"\n  when: target.stat.exists | default(False)\n\n- name: Link 'current' directory to target release\n  file:\n    path: \"{{ project_root }}/current\"\n    src: \"{{ new_release_path }}\"\n    state: link\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "4b80962e325aaecc2da6b438474426b9541e7df5", "filename": "tasks/Linux/fetch/security-fetch/security-fetch-oracle-fallback.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Download security policy artifact from Oracle OTN\n  get_url:\n    url: '{{ fallback_oracle_security_policy_artifacts[java_major_version|int] }}'\n    dest: '{{ java_download_path }}'\n    mode: 0755\n    headers:\n      Cookie: >-\n        gpw_e24=http%3A%2F%2Fwww.oracle.com%2F;\n        oraclelicense=accept-securebackup-cookie;\n        --no-check-certificate\n  register: policy_file_downloaded\n  retries: 15\n  delay: 5\n  until: policy_file_downloaded is succeeded\n\n- name: Downloaded security policy artifact\n  set_fact:\n    security_policy_java_artifact: '{{ policy_file_downloaded.dest }}'\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "c948f41b1c3706fba7d755f1abab3f044d3acbe8", "filename": "tasks/create_repo_pypi_group_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_pypi_group\n    args: \"{{ _nexus_repos_pypi_defaults|combine(item) }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "957c06557daeec168133459666527e4b7a1d1ca3", "filename": "roles/calibre/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "calibre_port: 8080\ncalibre_dbpath: \"/library/calibre\"\ncalibre_src_url: \"https://raw.githubusercontent.com/kovidgoyal/calibre/master/setup/linux-installer.py\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "7f21f0379ba2290bf6c30dd188f8678898b7e080", "filename": "roles/ansible/tower/manage-job-templates/tasks/process-job-template.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Get the inventory id based on the inventory name\"\n  set_fact:\n    inventory_id: \"{{ item.id }}\"\n  when:\n  - item.name|trim == job_template.inventory|trim\n  with_items:\n  - \"{{ existing_inventories_output.rest_output }}\"\n\n- name: \"Get the project id based on the project name\"\n  set_fact:\n    project_id: \"{{ item.id }}\"\n  when:\n  - item.name|trim == job_template.project|trim\n  with_items:\n  - \"{{ existing_projects_output.rest_output }}\"\n\n- name: \"Get the credential id based on the credential name\"\n  set_fact:\n    credential_id: \"{{ item.id }}\"\n  when:\n  - item.name|trim == job_template.credential|trim\n  with_items:\n  - \"{{ existing_credentials_output.rest_output }}\"\n\n- name: \"Load up the job template\"\n  uri:\n    url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}/api/v2/job_templates/\"\n    user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n    password: \"{{ ansible_tower.admin_password }}\"\n    force_basic_auth: yes\n    method: POST\n    body: \"{{ lookup('template', 'job-template.j2') }}\"\n    body_format: 'json'\n    headers:\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n    validate_certs: no\n    status_code: 200,201,400\n\n# Utilize the `rest_get` library routine to ensure REST pagination is handled\n- name: \"Obtain the current roles\"\n  rest_get:\n    host_url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}\"\n    rest_user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n    rest_password: \"{{ ansible_tower.admin_password }}\"\n    api_uri: \"/api/v2/roles/\"\n  register: existing_roles_output\n\n- name: \"Assign the Team(s) Permission(s)\"\n  vars:\n    permissions_object: \"teams\"\n    permissions_value: \"{{ team }}\"\n  include_tasks: set-permissions.yml\n  when:\n  - job_template.permissions is defined\n  - job_template.permissions.teams is defined\n  with_items:\n  - \"{{ job_template.permissions.teams }}\"\n  loop_control:\n    loop_var: team\n\n- name: \"Assign the User(s) Permission(s)\"\n  vars:\n    permissions_object: \"users\"\n    permissions_value: \"{{ user }}\"\n  include_tasks: set-permissions.yml\n  when:\n  - job_template.permissions is defined\n  - job_template.permissions.users is defined\n  with_items:\n  - \"{{ job_template.permissions.users }}\"\n  loop_control:\n    loop_var: user\n\n- name: \"Clear/Update facts\"\n  set_fact:\n    inventory_id: ''\n    project_id: ''\n    processed_job_templates: \"{{ processed_job_templates + [ {'name': job_template.name } ] }}\"\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "99a4d2c1d2275425c6e70cc8bf6bc2c9678f151e", "filename": "playbooks/roles/bb0-openstack/vars/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "---\n# vars file for provisioning_openstack\n\nstack_name: openshift\nheat_template: files/openshift_single_lbaas.yaml\nbastion_flavor: \"m1.small\"\nmaster_flavor: \"m1.large\"\ninfra_flavor: \"m1.large\"\nnode_flavor: \"m1.large\"\n\n# In GB\nmaster_container_disk_size: 15\nmaster_glusterfs_disk_size: 100\ninfra_container_disk_size: 15\ninfra_glusterfs_disk_size: 100\nnode_container_disk_size: 15\nnode_glusterfs_disk_size: 100\n\n# domain_name: \"{{ domain_name }}\"\n# external_network: \"{{ external_network }}\"\n# service_network: \"{{ service_network }}\"\n# service_subnet: \"{{ service_subnet_id }}\"\n# ssh_key_name: \"default\"\n# image: \"{{ image }}\"\n\n\n# vars file for init-openstack\n#\n\nos_sec_groups:\n  - name: ssh_only\n    rules:\n      - { proto: 'tcp', port: 22 }\n  - name: ose3_sdn\n    rules:\n      - { proto: 'tcp', port: 4789 }\n      - { proto: 'udp', port: 4789 }\n  - name: ose3_node\n    rules:\n      - { proto: 'tcp', port: 10250 }\n      - { proto: 'udp', port: 10250 }\n  - name: ose3_master\n    rules:\n      - { proto: 'tcp', port: 53 }\n      - { proto: 'tcp', port: 443 }\n      - { proto: 'tcp', port: 2379 }\n      - { proto: 'tcp', port: 2380 }\n      - { proto: 'tcp', port: 4001 }\n      - { proto: 'tcp', port: 5000 }\n      - { proto: 'tcp', port: 8443 }\n      - { proto: 'tcp', port: 24224}\n      - { proto: 'udp', port: 53 }\n      - { proto: 'udp', port: 2379 }\n      - { proto: 'udp', port: 2380 }\n      - { proto: 'udp', port: 4001 }\n      - { proto: 'udp', port: 24224 }\n  - name: ose3_router\n    rules:\n      - { proto: 'tcp', port: 80 }\n      - { proto: 'tcp', port: 443 }\n      - { proto: 'tcp', port: 8443 }\n  - name: cloudforms\n    rules:\n      - { proto: 'tcp', port: 80 }\n      - { proto: 'tcp', port: 443 }\n  - name: nagios\n    rules:\n      - { proto: 'tcp', port: 80 }\n      - { proto: 'tcp', port: 443 }\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "cd5f953cde2b5332a1d25055ea0be42f6ea3ef31", "filename": "playbooks/container-registry/templates/haproxy_backend.cfg.j2", "repository": "redhat-cop/infra-ansible", "decoded_content": "\n\n# Make sure the name matches the frontend name\nbackend quay_http\n    balance roundrobin\n\n    {% for host in groups.quay_enterprise %}\n    server quay_http_{{ hostvars[host]['inventory_hostname'] }} {{ hostvars[host]['ansible_eth0']['ipv4']['address'] }}:80 check\n    {% endfor %}\n\n# Make sure the name matches the frontend name\nbackend quay_https\n    mode tcp\n    balance source\n    option httpchk GET /health/instance\n    http-check expect status 200\n\n    {% for host in groups.quay_enterprise %}\n    server quay_https_{{ hostvars[host]['inventory_hostname'] }} {{ hostvars[host]['ansible_eth0']['ipv4']['address'] }}:443 check check-ssl verify none\n    {% endfor %}\n\n# Make sure the name matches the frontend name\nbackend redis\n    mode tcp\n    option tcp-check\n    tcp-check send PING\\r\\n\n    tcp-check expect string +PONG\n    tcp-check send info\\ replication\\r\\n\n    tcp-check expect string role:master\n    tcp-check send QUIT\\r\\n\n    tcp-check expect string +OK\n    {% for host in groups.redis %}\n    server redis_{{ hostvars[host]['inventory_hostname'] }} {{ hostvars[host]['ansible_eth0']['ipv4']['address'] }}:6379 check inter 1s\n    {% endfor %}\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "59e696ef99127f2941113d668cf4199c3571d35e", "filename": "tasks/controller/setup-redhat.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: CentOS/RedHat) Add NGINX Controller Agent Repository\"\n  yum_repository:\n    name: nginx-controller\n    baseurl: http://packages.nginx.org/controller/centos/$releasever/$basearch/\n    description: NGINX Controller Agent\n    gpgcheck: yes\n"}, {"commit_sha": "a94f9ce4fa32273fd0fad7492d36db4101423cc3", "sha": "7eb51932988fa7e4e7e55e89411775ad69a1669e", "filename": "tasks/configure-docker.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Ensure /etc/docker directory exists\n  become: true\n  file:\n    path: /etc/docker\n    state: directory\n    mode: 0755\n\n- name: Configure Docker daemon (file)\n  become: true\n  copy:\n    src: \"{{ docker_daemon_config_file }}\"\n    dest: /etc/docker/daemon.json\n  notify: restart docker\n  when: docker_daemon_config_file is defined\n\n- name: Configure Docker daemon (variables)\n  become: true\n  copy:\n    content: \"{{ docker_daemon_config | to_nice_json }}\"\n    dest: /etc/docker/daemon.json\n  notify: restart docker\n  when: docker_daemon_config_file is not defined and\n        docker_daemon_config is defined\n\n- name: Ensure Docker default user namespace is defined in subuid and subgid\n  become: true\n  lineinfile:\n    path: \"{{ item }}\"\n    regexp: '^dockremap'\n    line: 'dockremap:500000:65536'\n  with_items:\n    - /etc/subuid\n    - /etc/subgid\n  when: (_docker_os_dist == \"CentOS\" or _docker_os_dist == \"RedHat\") and\n        ((docker_daemon_config is defined and\n        docker_daemon_config['userns-remap'] is defined and\n        docker_daemon_config['userns-remap'] == 'default') or\n        docker_bug_usermod|bool == true)\n\n- name: Ensure Docker users are added to the docker group\n  become: true\n  user:\n    name: \"{{ item }}\"\n    groups: docker\n    append: true\n  with_items: \"{{ docker_users }}\"\n\n- name: Ensure thin-provisioning-tools is installed when devicemapper is used (Ubuntu)\n  become: true\n  package:\n    name: thin-provisioning-tools\n    state: present\n  when: (_docker_os_dist == \"Ubuntu\" or _docker_os_dist == \"Debian\") and\n        docker_daemon_config['storage-driver'] is defined and\n        docker_daemon_config['storage-driver'] == 'devicemapper'\n\n- name: Enable Docker service\n  become: true\n  service:\n    name: docker\n    enabled: yes\n  notify: restart docker\n  register: docker_service\n\n- name: Trigger start/restart of Docker\n  service:\n    name: docker\n  notify: restart docker\n  changed_when: docker_service.status.SubState != \"running\"\n  when: docker_service.status is defined\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "22c8afadf237a9e38952682e54971170d760e713", "filename": "tasks/configure-docker.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n# https://wiki.ubuntu.com/SystemdForUpstartUsers\n# Important! systemd is only fully supported in Ubuntu 15.04 and later releases\n- name: Determine usage of systemd\n  become: true\n  shell: \"ps -p1 | grep systemd 1>/dev/null && echo systemd || echo upstart\"\n  changed_when: no\n  check_mode: no\n  register: _determine_systemd_usage\n  tags:\n    - skip_ansible_lint\n\n- name: Set fact to indicate systemd is used or not\n  set_fact:\n    _docker_systemd_used: \"{{ _determine_systemd_usage is defined and _determine_systemd_usage.stdout == 'systemd' }}\"\n\n- name: Configure systemd service\n  include_tasks: configure-docker/configure-systemd.yml\n  when: _docker_systemd_used | bool\n\n- name: Configure non-systemd service\n  include_tasks: configure-docker/configure-non-systemd.yml\n  when: not _docker_systemd_used | bool\n\n- name: Ensure /etc/docker directory exists\n  become: true\n  file:\n    path: /etc/docker\n    state: directory\n    mode: 0755\n\n- name: Configure Docker daemon (file)\n  become: true\n  copy:\n    src: \"{{ docker_daemon_config_file }}\"\n    dest: /etc/docker/daemon.json\n  notify: restart docker\n  when: docker_daemon_config_file is defined\n\n- name: Fetch Docker daemon status\n  become: true\n  service:\n    name: docker\n  register: _docker_status_check\n  when: docker_plugins | length > 0\n\n- name: Configure Docker daemon (variables)\n  become: true\n  copy:\n    content: \"{{ docker_daemon_config | to_nice_json }}\"\n    dest: /etc/docker/daemon.json\n  notify: restart docker\n  when:\n    - docker_daemon_config_file is not defined\n    - docker_daemon_config is defined\n    - _docker_status_check.status is not defined or\n      (_docker_status_check.status is defined and\n      _docker_status_check.status.SubState is defined and\n      _docker_status_check.status.SubState != \"running\")\n\n- name: Ensure Docker default user namespace is defined in subuid and subgid\n  become: true\n  lineinfile:\n    path: \"{{ item }}\"\n    regexp: '^dockremap'\n    line: 'dockremap:500000:65536'\n  with_items:\n    - /etc/subuid\n    - /etc/subgid\n  when: (_docker_os_dist == \"CentOS\" or _docker_os_dist == \"RedHat\") and\n        ((docker_daemon_config is defined and\n        docker_daemon_config['userns-remap'] is defined and\n        docker_daemon_config['userns-remap'] == 'default') or\n        docker_bug_usermod | bool)\n\n- name: Ensure Docker users are added to the docker group\n  become: true\n  user:\n    name: \"{{ item }}\"\n    groups: docker\n    append: true\n  with_items: \"{{ docker_users }}\"\n\n- name: Ensure devicemapper prerequisites are fulfilled\n  block:\n    - name: Ensure lvm2 is installed\n      become: true\n      package:\n        name: lvm2\n        state: present\n      register: _pkg_result\n      until: _pkg_result is succeeded\n\n    - name: Ensure thin-provisioning-tools is installed\n      become: true\n      package:\n        name: thin-provisioning-tools\n        state: present\n      register: _pkg_result\n      until: _pkg_result is succeeded\n      when: (_docker_os_dist == \"Ubuntu\" or (_docker_os_dist == \"Debian\" and _docker_os_dist_major_version > '7'))\n  when:\n    - docker_daemon_config['storage-driver'] is defined\n    - docker_daemon_config['storage-driver'] == 'devicemapper'\n\n- name: Enable Docker service\n  become: true\n  service:\n    name: docker\n    enabled: yes\n  notify: restart docker\n  register: _docker_service\n\n- name: Trigger start/restart of Docker\n  service:\n    name: docker\n  notify: restart docker\n  changed_when: _docker_service.status.SubState != \"running\"\n  when: _docker_service.status is defined and _docker_service.status.SubState is defined\n\n- name: Install and configure Docker plugins\n  include_tasks: configure-docker/configure-docker-plugins.yml\n  when: docker_plugins | length > 0"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "86e265e95027fd4472e4dda64e5eece96276bfa7", "filename": "roles/manage-confluence-space/tasks/download_attachment.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Download attachment from source\n  get_url:\n    url: '{{ confluence_source_url }}/wiki/{{ attachment_data._links.download }}'\n    dest: '{{ attachment_tempdir.path }}/{{ attachment_data.title }}'\n    force: yes\n    force_basic_auth: yes\n    url_username: '{{ confluence_source_username }}'\n    url_password: '{{ confluence_source_password }}'\n  no_log: true\n  delegate_to: 127.0.0.1\n\n- name: Upload attachment to destination\n  command: 'curl -u {{ confluence_destination_username }}:{{ confluence_destination_password }} -X POST -H \"X-Atlassian-Token: no-check\" -F \"file=@{{ attachment_tempdir.path }}/{{ attachment_data.title }}\" {{ confluence_destination_url }}/wiki/rest/api/content/{{ confluence_content_ids.value.id }}/child/attachment'\n  delegate_to: 127.0.0.1\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "6f808f47eb929b30bc6a3c205904910d7b2e1f82", "filename": "tasks/nexus_install.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- name: Download nexus_package\n  get_url:\n    url: \"http://download.sonatype.com/nexus/3/{{ nexus_package }}\"\n    dest: \"{{ nexus_download_dir }}/{{ nexus_package }}\"\n    force: no\n  notify:\n    - nexus-service-stop\n\n- name: Ensure Nexus o/s group exists\n  group:\n    name: \"{{ nexus_os_group }}\"\n    state: present\n\n- name: Ensure Nexus o/s user exists\n  user:\n    name: \"{{ nexus_os_user }}\"\n    group: \"{{ nexus_os_group }}\"\n    shell: \"/bin/bash\"\n    state: present\n\n- name: Ensure Nexus installation directory exists\n  file:\n    path: \"{{ nexus_installation_dir }}\"\n    state: \"directory\"\n\n- name: Unpack Nexus download\n  unarchive:\n    src: \"{{ nexus_download_dir }}/{{ nexus_package }}\"\n    dest: \"{{ nexus_installation_dir }}\"\n    creates: \"{{ nexus_installation_dir }}/nexus-{{ nexus_version }}\"\n    force: no\n    copy: false\n  notify:\n    - nexus-service-stop\n\n- meta: flush_handlers\n\n- name: Update symlink nexus-latest\n  file:\n    path: \"{{ nexus_installation_dir }}/nexus-latest\"\n    src: \"{{ nexus_installation_dir }}/nexus-{{ nexus_version }}\"\n    owner: \"{{ nexus_os_user }}\"\n    group: \"{{ nexus_os_group }}\"\n    state: link\n  register: nexus_latest_version\n\n- name: Delete unpacked data directory\n  file:\n    path: \"{{ nexus_installation_dir }}/nexus-latest/data\"\n    state: absent\n\n- name: Get path to default settings\n  set_fact:\n    nexus_default_settings_file: \"{{ nexus_installation_dir }}/nexus-latest/etc/org.sonatype.nexus.cfg\"\n  when: nexus_version < '3.1.0'\n\n- name: Get path to default settings\n  set_fact:\n    nexus_default_settings_file: \"{{ nexus_installation_dir }}/nexus-latest/etc/nexus-default.properties\"\n  when: nexus_version >= '3.1.0'\n\n- name: Get application settings directories\n  set_fact:\n    nexus_app_dir_settings_dirs:\n      - \"{{ nexus_installation_dir }}/nexus-latest/etc\"\n  when: nexus_version < '3.1.0'\n\n- name: Get application settings directories\n  set_fact:\n    nexus_app_dir_settings_dirs:\n      - \"{{ nexus_installation_dir }}/nexus-latest/etc\"\n      - \"{{ nexus_installation_dir }}/nexus-latest/etc/karaf\"\n      - \"{{ nexus_installation_dir }}/nexus-latest/etc/jetty\"\n      - \"{{ nexus_installation_dir }}/nexus-latest/etc/fabric\"\n      - \"{{ nexus_installation_dir }}/nexus-latest/etc/logback\"\n      - \"{{ nexus_installation_dir }}/nexus-latest/etc/scripts\"\n  when: nexus_version >= '3.1.0'\n\n- name: Get rest API endpoint (v < 3.8.0)\n  set_fact:\n    nexus_rest_api_endpoint: \"service/siesta/rest/v1/script\"\n  when: nexus_version < '3.8.0'\n\n- name: Get rest API endpoint (v >= 3.8.0)\n  set_fact:\n    nexus_rest_api_endpoint: \"service/rest/v1/script\"\n  when: nexus_version >='3.8.0'\n\n- name: Allow nexus to create first-time install configuration files in  {{ nexus_installation_dir }}/nexus-latest/etc\n  file:\n    path: \"{{ item }}\"\n    state: \"directory\"\n    owner: \"{{ nexus_os_user }}\"\n    group: \"{{ nexus_os_group }}\"\n    mode: \"0755\"\n    recurse: false\n  with_items: \"{{ nexus_app_dir_settings_dirs }}\"\n  when: nexus_latest_version.changed\n  register: chown_config_first_time\n  tags:\n    # hard to run as a handler for time being\n    - skip_ansible_lint\n\n- name: Create Nexus data directory\n  file:\n    path: \"{{ nexus_data_dir }}\"\n    state: \"directory\"\n    owner: \"{{ nexus_os_user }}\"\n    group: \"{{ nexus_os_group }}\"\n\n- name: Setup Nexus data directory\n  lineinfile:\n    dest: \"{{ nexus_installation_dir }}/nexus-latest/bin/nexus.vmoptions\"\n    regexp: \"^-Dkaraf.data=.*\"\n    line: \"-Dkaraf.data={{ nexus_data_dir }}\"\n\n- name: Setup JVM logfile directory\n  lineinfile:\n    dest: \"{{ nexus_installation_dir }}/nexus-latest/bin/nexus.vmoptions\"\n    regexp: \"^-XX:LogFile=.*\"\n    line: \"-XX:LogFile={{ nexus_data_dir }}/log/jvm.log\"\n\n- name: Setup Nexus default timezone\n  lineinfile:\n    dest: \"{{ nexus_installation_dir }}/nexus-latest/bin/nexus.vmoptions\"\n    regexp: \"^-Duser.timezone=.*\"\n    line: \"-Duser.timezone={{ nexus_timezone }}\"\n\n- name: Create Nexus tmp/backup directory\n  file:\n    path: \"{{ item }}\"\n    state: \"directory\"\n    owner: \"{{ nexus_os_user }}\"\n    group: \"{{ nexus_os_group }}\"\n  with_items:\n    - \"{{ nexus_tmp_dir }}\"\n    - \"{{ nexus_backup_dir }}\"\n\n- name: Setup Nexus tmp directory\n  lineinfile:\n    dest: \"{{ nexus_installation_dir }}/nexus-latest/bin/nexus.vmoptions\"\n    regexp: \"^-Djava.io.tmpdir=.*\"\n    line: \"-Djava.io.tmpdir={{ nexus_tmp_dir }}\"\n\n- name: Set NEXUS_HOME for the service user\n  lineinfile:\n    dest: \"/home/{{ nexus_os_user }}/.bashrc\"\n    regexp: \"^export NEXUS_HOME=.*\"\n    line: \"export NEXUS_HOME={{ nexus_installation_dir }}/nexus-latest\"\n\n- name: Set nexus user\n  lineinfile:\n    dest: \"{{ nexus_installation_dir }}/nexus-latest/bin/nexus.rc\"\n    regexp: \".*run_as_user=.*\"\n    line: \"run_as_user=\\\"{{ nexus_os_user }}\\\"\"\n\n- name: Set nexus port\n  lineinfile:\n    dest: \"{{ nexus_default_settings_file }}\"\n    regexp: \"^application-port=.*\"\n    line: \"application-port={{ nexus_default_port }}\"\n\n- name: Set nexus context path\n  lineinfile:\n    dest: \"{{ nexus_default_settings_file }}\"\n    regexp: \"^nexus-context-path=.*\"\n    line: \"nexus-context-path={{ nexus_default_context_path }}\"\n\n- name: Bind nexus service to 127.0.0.1 only\n  lineinfile:\n    dest: \"{{ nexus_default_settings_file }}\"\n    regexp: \"^application-host=.*\"\n    line: \"application-host=127.0.0.1\"\n  when: httpd_setup_enable\n\n- name: Create systemd service configuration\n  template:\n    src: \"nexus.service\"\n    dest: \"/etc/systemd/system\"\n  notify:\n    - systemd-reload\n\n- block:\n    - name: \"Deploy backup restore script\"\n      template:\n        src: \"nexus-blob-restore.sh.j2\"\n        dest: \"{{ nexus_script_dir }}/nexus-blob-restore.sh\"\n        mode: 0755\n    - name: \"Symlink backup restore script to /sbin\"\n      file:\n        src: \"{{ nexus_script_dir }}/nexus-blob-restore.sh\"\n        dest: \"/sbin/nexus-blob-restore.sh\"\n        state: link\n  when: nexus_backup_configure | bool\n\n- name: 'Check if data directory is empty (first-time install)'\n  command: \"ls {{ nexus_data_dir }}\"\n  register: nexus_data_dir_contents\n  check_mode: no\n  changed_when: false\n\n- name: Clean cache for upgrade process\n  file:\n    path: \"{{ nexus_data_dir }}/clean_cache\"\n    state: touch\n  when: nexus_latest_version.changed and nexus_data_dir_contents.stdout != \"\"\n  tags:\n    # hard to run as a handler for time being\n    - skip_ansible_lint\n\n- meta: flush_handlers\n\n- name: Enable nexus service and make sure it is started\n  systemd:\n    name: nexus.service\n    enabled: yes\n    state: started\n  notify:\n    - wait-for-nexus\n    - wait-for-nexus-port\n\n- meta: flush_handlers\n\n- name: Chown configuration files from {{ nexus_installation_dir }}/nexus-latest/etc back to root\n  file:\n    path: \"{{ nexus_installation_dir }}/nexus-latest/etc\"\n    owner: \"root\"\n    group: \"root\"\n    mode: a=rX,u+w\n    recurse: true\n  when: chown_config_first_time.changed\n  tags:\n    # hard to run as a handler for time being\n    - skip_ansible_lint\n\n- name: Prevent nexus to create any new configuration files in  {{ nexus_installation_dir }}/nexus-latest/etc\n  file:\n    path: \"{{ item }}\"\n    state: \"directory\"\n    owner: \"root\"\n    group: \"root\"\n    mode: \"0755\"\n    recurse: false\n  with_items: \"{{ nexus_app_dir_settings_dirs }}\"\n\n- name: First-time install admin password\n  set_fact:\n    current_nexus_admin_password: 'admin123'\n  when: nexus_data_dir_contents.stdout == \"\"\n\n- name: Subsequent re-provision admin password\n  set_fact:\n    current_nexus_admin_password: \"{{ nexus_admin_password }}\"\n  when: nexus_data_dir_contents.stdout != \"\"\n  no_log: true\n\n- name: Create directory to hold current groovy scripts for reference\n  file:\n    path: \"{{ nexus_data_dir }}/groovy-raw-scripts/current\"\n    state: directory\n    owner: root\n    group: root\n\n- name: Upload new scripts\n  synchronize:\n    archive: no\n    checksum: yes\n    recursive: yes\n    delete: yes\n    mode: push\n    use_ssh_args: yes\n    src: \"files/groovy/\"\n    dest: \"{{ nexus_data_dir }}/groovy-raw-scripts/new/\"\n\n- name: Sync new scripts to old and get differences\n  shell: 'rsync -ric {{ nexus_data_dir }}/groovy-raw-scripts/new/ {{ nexus_data_dir }}/groovy-raw-scripts/current/ | cut -d\" \" -f 2 | sed \"s/\\.groovy//g\"'\n  register: nexus_groovy_files_changed\n  check_mode: no\n  changed_when: false\n  # simple check on changed files kept on host\n  # skip ansible lint (we don't want to use synchronize module for this)\n  args:\n    warn: false\n\n- name: Declare new or changed groovy scripts in nexus\n  include: declare_script_each.yml\n  with_items: \"{{ nexus_groovy_files_changed.stdout_lines}}\"\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "665e710bdbf2363c365035a76e691311008dc21b", "filename": "roles/docker/defaults/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# defaults file for docker\ndocker_graph_dir: /var/lib/docker\ndocker_tmp_dir: /var/lib/docker/tmp"}, {"commit_sha": "abafe1581c6c78d784cf215b214947675d49eff8", "sha": "959ec6f09a63c094e7abb7c779af32447cd0e185", "filename": "roles/cloud-gce/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "- set_fact:\n    credentials_file_lookup: \"{{ lookup('file', '{{ credentials_file }}') }}\"\n    ssh_public_key_lookup: \"{{ lookup('file', '{{ ssh_public_key }}') }}\"\n\n- name: \"Creating a new instance...\"\n  gce:\n    instance_names: \"{{ server_name }}\"\n    zone: \"{{ zone }}\"\n    machine_type: n1-standard-1\n    image: ubuntu-1604\n    service_account_email: \"{{ credentials_file_lookup.client_email  }}\"\n    credentials_file: \"{{ credentials_file  }}\"\n    project_id: \"{{ credentials_file_lookup.project_id  }}\"\n    metadata: '{\"sshKeys\":\"root:{{ ssh_public_key_lookup }}\"}'\n  register: google_vm\n\n- name: Add the instance to an inventory group\n  add_host:\n    name: \"{{ google_vm.instance_data[0].public_ip }}\"\n    groups: vpn-host\n    ansible_ssh_user: ubuntu\n    ansible_python_interpreter: \"/usr/bin/python2.7\"\n    easyrsa_p12_export_password: \"{{ easyrsa_p12_export_password }}\"\n    cloud_provider: gce\n    ipv6_support: no\n\n- name: Firewall configured\n  local_action:\n    module: gce_net\n    name: \"{{ google_vm.instance_data[0].network }}\"\n    fwname: \"algo-ikev2\"\n    allowed: \"udp:500,4500;tcp:22\"\n    state: \"present\"\n    src_range: 0.0.0.0/0\n    service_account_email: \"{{ credentials_file_lookup.client_email }}\"\n    credentials_file: \"{{ credentials_file  }}\"\n    project_id: \"{{ credentials_file_lookup.project_id }}\"\n\n- name: Waiting for SSH to become available\n  local_action: \"wait_for port=22 host={{ google_vm.instance_data[0].public_ip }} timeout=320\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "bcde6c3de5b963d16c1d5b5e4679b1a439d3c8de", "filename": "roles/config-clair/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Restart Clair Service\n  systemd:\n    name: \"{{ clair_name }}\"\n    enabled: yes\n    state: restarted\n    daemon_reload: yes\n\n- name: restart firewalld\n  service:\n    name: firewalld\n    state: restarted"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "f780fbcb7548d364a38b05afc38e6ec110028fcc", "filename": "roles/openvpn/templates/iiab-handle", "repository": "iiab/iiab", "decoded_content": "#!/bin/bash\n# script to write a handle file that identifies the openvpn client to server\necho\necho\nread -p \"what identifying handle would you like to use? \" ans\nif [ \"$ans\" == \"\" ]; then\n  if [ -f /etc/iiab/handle ]; then\n    rm -f /etc/iiab/handle\n  fi\nelse\n  echo $ans > /etc/iiab/handle \nfi\n{{ systemctl_program }} restart openvpn@xscenet\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "c78970507e72b9c98a2784aa155ab6b17ec1edb4", "filename": "roles/1-prep/tasks/iiab_ini.yml", "repository": "iiab/iiab", "decoded_content": "# workaround for fact that auto create does not work on ini_file\n- name: Create iiab config file\n  file: dest='{{ iiab_config_file }}'\n        state=touch\n\n- name: Add location section to config file\n  ini_file: dest='{{ iiab_config_file }}'\n            section=location\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: 'iiab_base'\n      value: '{{ iiab_base }}'\n    - option: 'iiab_dir'\n      value: '{{ iiab_dir }}'\n\n- name: add version section\n  ini_file: dest='{{ iiab_config_file }}'\n            section=version\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: 'distribution'\n      value: '{{ ansible_distribution }}'\n    - option: 'arch'\n      value: '{{ ansible_architecture }}'\n    - option: 'iiab_branch'\n      value: '{{ ansible_local[\"local_facts\"][\"iiab_branch\"] }}'\n    - option: 'iiab_commit'\n      value: '{{ ansible_local[\"local_facts\"][\"iiab_commit\"] }}'\n    - option: 'install_date'\n      value: '{{ ansible_date_time[\"iso8601\"] }}'\n    - option: 'install_xo'\n      value: '{{ xo_model }}'\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "c9c0f58a33aae26023e101208a83a64bf2682fc2", "filename": "playbooks/templates/bro-node.cfg.j2", "repository": "rocknsm/rock", "decoded_content": "[logger]\ntype=logger\nhost=localhost\nenv_vars=fanout_id=0\n\n[manager]\ntype=manager\nhost=localhost\nenv_vars=fanout_id=0\n\n[proxy-1]\ntype=proxy\nhost=localhost\nenv_vars=fanout_id=0\n\n{% set procs_per_worker = (bro_cpu | int) // (rock_monifs|length) %}\n{% for iface in rock_monifs %}\n[{{ iface }}]\ntype=worker\nhost=localhost\n{%if procs_per_worker >=2 %}\ninterface=af_packet::{{ iface }}\nlb_method=custom\nlb_procs={{ (bro_cpu | int) // loop.length }}\n{% else %}\ninterface={{ iface }}\n{% endif %}\nenv_vars=fanout_id={{ 42 + loop.index0 }}\n{# TODO: add logic for pinning processes #}\n{% endfor %}\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "972d5db65c0e03f14fdac59a6e9df9c47144fb8b", "filename": "roles/ansible/tower/config-ansible-tower-ldap/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: tower\n  roles:\n  - role: ansible/tower/config-ansible-tower-ldap\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "e4eccedb6dbd85dedf5cf034bae93149a7cc4da1", "filename": "roles/network/tasks/hostapd.yml", "repository": "iiab/iiab", "decoded_content": "- name: Create a config file for hostapd\n  template: src=hostapd/hostapd.conf.j2\n            dest=/etc/hostapd/hostapd.conf\n            owner=root\n            group=root\n            mode=0644\n  when: iiab_wireless_lan_iface != \"none\"\n\n- name: Disable the Access Point Hostapd program\n  service: enabled=no\n           name=hostapd.service\n           state=stopped\n  when: iiab_wireless_lan_iface == \"none\" or iiab_network_mode == \"Appliance\" or not hostapd_enabled\n\n- name: Use custom systemd unit file to start hostapd\n  template: src=hostapd/hostapd.service.j2\n            dest=/etc/systemd/system/hostapd.service\n            owner=root\n            group=root\n            mode=0644\n\n- name: ask systemd to reread the unit files for hostapd\n  shell: systemctl daemon-reload\n\n- name: Enable the Access Point Hostapd program\n  service: enabled=yes\n           name=hostapd.service\n           state=restarted\n  when: iiab_wireless_lan_iface != \"none\" and iiab_network_mode != \"Appliance\" and hostapd_enabled\n\n- name: Checking if slave is active waiting 10 seconds\n  shell: \"sleep {{ hostapd_wait }} | brctl show | grep {{ iiab_wireless_lan_iface }}\"\n  ignore_errors: True\n  changed_when: False\n  register: wifi_slave\n  when: iiab_lan_iface == \"br0\" and iiab_wireless_lan_iface != \"none\"\n\n- name: Restart hostapd if slave is inactive\n  service: name=hostapd.service\n           state=restarted\n  when: is_debuntu and iiab_lan_iface == \"br0\" and item|trim == \"\"\n  with_items:\n      - \"{{ wifi_slave.stdout }}\"\n  ignore_errors: true\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "4a10624d76f14ad37069ecc636841c52fa862122", "filename": "tasks/create_repo_docker_hosted_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_docker_hosted\n    args: \"{{ _nexus_repos_docker_defaults|combine(item) }}\"\n"}, {"commit_sha": "a9f9815335a6b9c73bed7e3dcd75e14cd973fbb5", "sha": "809052a01bb365b98b554ae461859fa29dea51e0", "filename": "tasks/redhat.yml", "repository": "CSCfi/ansible-role-cuda", "decoded_content": "---\n# tasks file for ansible-role-cuda\n#\n- name: add nvidia CUDA repo\n  template: src=nvidia.repo.j2 dest=/etc/yum.repos.d/nvidia.repo owner=root group=root mode=0644 backup=yes\n\n- name: install cuda software - this is slow - restart if cuda_restart_node_on_install is True\n  yum: name={{ item }} state=present\n  with_items: cuda_packages | default({})\n  when: cuda_packages.0 != \"\"\n  register: cuda_packages_installation\n  notify:\n   - ZZ CUDA Restart server\n   - ZZ CUDA Wait for server to restart\n"}, {"commit_sha": "7032aee7df1c2c6e96795067285efa3b2a6de32e", "sha": "0063ee7112449faba0436e15488e438c43e52092", "filename": "playbooks/dns-provision.yaml", "repository": "openshift/openshift-ansible-contrib", "decoded_content": "---\n- hosts: localhost\n  pre_tasks:\n    - include: roles/common/pre_tasks/pre_tasks.yml\n  roles:\n    # Provision DNS\n    - role: openstack-create\n      type: \"dns\"\n      key_name: \"{{ openstack_key_name }}\"\n      image_name: \"{{ openshift_openstack_image_name }}\"\n      flavor_name: \"m1.small\"\n      security_groups: \"dns,default\"\n      register_host_group: \"dns,openshift\"\n      node_count: \"1\"\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "98278cef15c017b9026ed5b58ff1b1ba2dfa3b06", "filename": "roles/dns_adblocking/handlers/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: restart dnsmasq\n  service: name=dnsmasq state=restarted\n\n- name: restart apparmor\n  service: name=apparmor state=restarted\n"}, {"commit_sha": "49010188a985bfe713552eb8980cfa0d7a888daf", "sha": "0f3b01c8b159f03ff0f95e5250ead6e79ee2331f", "filename": "roles/openshift-replicas-ready/tasks/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n- name: Verify Required Parameters\n  fail:\n    msg: \"'resource' and 'type' Parameters Must be Provided!\"\n  when: type is not defined or type|trim == '' or resource is not defined or resource|trim == ''\n\n- name: \"Set the target namespace option if supplied\"\n  set_fact:\n    target_namespace: \"-n {{ namespace }}\"\n  when:\n  - namespace is defined\n  - namespace|trim != ''\n\n- name: Query Replica Status\n  command: >\n    oc get {{ type }}/{{ resource }} {{ target_namespace }} -o json\n  register: query_result\n  delay: \"{{ delay | int }}\"\n  retries: \"{{ retries | int }}\"\n  until: (query_result.stdout | from_json)['spec']['replicas'] | default(\"0\") | int == (query_result.stdout | from_json)['status']['readyReplicas'] | default(\"0\") | int\n  failed_when: (query_result.stdout | from_json)['spec']['replicas'] is not defined\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "d027daa5881432263f5a3783adca1d69ff283ef7", "filename": "tasks/Win32NT/security_policy.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: 'Fetch oracle security policy with {{ java_unlimited_policy_transport }} transport'\n  include_tasks: '{{ transport_driver }}'\n  with_first_found:\n    - 'fetch/security-fetch/security-winfetch-{{ java_unlimited_policy_transport }}.yml'\n    - 'fetch/unknown-transport.yml'\n  loop_control:\n    loop_var: transport_driver\n  when:\n    - java_unlimited_policy_enabled\n    - java_full_version is version('8.151', '<')\n\n- name: Block\n  block:\n    - name: Unzip patch file\n      win_unzip:\n        src: '{{ security_policy_java_artifact }}'\n        dest: '{{ java_act_path }}\\jre\\lib\\security\\'\n        creates: '{{ java_act_path }}\\jre\\lib\\security\\{{ security_patch_folders[java_major_version|int] }}'\n\n    - name: Apply patch file\n      win_copy:\n        src: '{{ java_act_path }}\\jre\\lib\\security\\{{ security_patch_folders[java_major_version|int] }}\\{{ policy_item }}'\n        dest: '{{ java_act_path }}\\jre\\lib\\security\\'\n        remote_src: true\n      loop:\n        - local_policy.jar\n        - US_export_policy.jar\n      loop_control:\n        loop_var: policy_item\n  when: java_full_version is version('8.151', '<')\n\n- name: 'Apply setting'\n  win_lineinfile:\n    path: '{{ java_act_path }}\\jre\\lib\\security\\java.security'\n    line: 'crypto.policy=unlimited'\n  when: java_major_version | int < 9\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "722761dda97e1959f75da5dd30396fc9566e7be4", "filename": "roles/network/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "---\n# The values here are default local variables.\ngui_wan_iface: \"unset\"\ngui_static_wan_ip: \"unset\"\ngui_desired_network_role: Gateway\nwondershaper_dspeed: \"4096\"\nwondershaper_upspeed: \"1024\"\n# WiFi\nhost_ssid: IIAB\nhostapd_wait: 10\nhost_wifi_mode: g\nhost_channel: 6\nhost_wireless_n: False\nhost_country_code: US\nhostapd_secure: True\nhostapd_password: \"iiab2017\"\ndriver_name: nl80211\nnetwork_config_dir: /etc/network/interfaces.d\niiab_network_mode: \"Gateway\"\ndns_jail_enabled: False\nservices_externally_visible: False\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "730836b4c982dbcd07058fe385538d0e06516dab", "filename": "playbooks/templates/logrotate-suricata.conf.j2", "repository": "rocknsm/rock", "decoded_content": "/data/suricata/*.log /data/suricata/*.json\n{\n    rotate {{ suricata_retention }}\n    missingok\n    compress\n    create 0644 suricata suricata\n    sharedscripts\n    postrotate\n        systemctl kill -s HUP --kill-who=main suricata.service\n    endscript\n}\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "916b56539bd330c1fa0588c1071ce2932e61654d", "filename": "roles/nginx/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Add Nginx PPA\n  apt_repository:\n    repo: \"ppa:nginx/development\"\n    update_cache: yes\n\n- name: Install Nginx\n  apt:\n    name: nginx\n    state: present\n    force: yes\n\n- name: Create SSL directory\n  file:\n    mode: 0700\n    path: \"{{ nginx_path }}/ssl\"\n    state: directory\n\n- name: Generate strong unique Diffie-Hellman group.\n  command: openssl dhparam -out dhparams.pem 2048\n  args:\n    chdir: \"{{ nginx_path }}/ssl\"\n    creates: \"{{ nginx_path }}/ssl/dhparams.pem\"\n  notify: reload nginx\n  tags: [diffie-hellman]\n\n- name: Grab h5bp/server-configs-nginx\n  git:\n    repo: \"https://github.com/h5bp/server-configs-nginx.git\"\n    dest: \"{{ nginx_path }}/h5bp-server-configs\"\n    version: 82181a672a7c26f9bc8744fead80318d8a2520b1\n    force: yes\n\n- name: Move h5bp configs\n  command: cp -R {{ nginx_path }}/h5bp-server-configs/h5bp {{ nginx_path }}/h5bp\n  args:\n    creates: \"{{ nginx_path }}/h5bp/\"\n\n- name: Create nginx.conf\n  template:\n    src: nginx.conf.j2\n    dest: \"{{ nginx_path }}/nginx.conf\"\n  notify: reload nginx\n\n- name: Disable default server\n  file:\n    path: \"{{ nginx_path }}/sites-enabled/default\"\n    state: absent\n  notify: reload nginx\n\n- name: Enable better default site to drop unknown requests\n  command: cp {{ nginx_path }}/h5bp-server-configs/sites-available/no-default {{ nginx_path }}/sites-enabled/no-default.conf\n  args:\n    creates: \"{{ nginx_path }}/sites-enabled/no-default.conf\"\n  notify: reload nginx\n\n- name: Create base WordPress config\n  template:\n    src: wordpress.conf.j2\n    dest: \"{{ nginx_path }}/wordpress.conf\"\n\n- name: Create base WordPress subdirectory Multisite config\n  template:\n    src: wordpress_multisite_subdirectories.conf.j2\n    dest: \"{{ nginx_path }}/wordpress_multisite_subdirectories.conf\"\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "3fc8e213463d90eb5bbf497b05d02bd040b57133", "filename": "tasks/Linux/install/sapjvm_tarball.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Check that the java_folder exists\n  stat:\n    path: '{{ java_path }}/{{ java_folder }}/bin'\n  register: java_folder_bin\n\n- name: 'Install java {{ java_full_version }} from tarball'\n  block:\n  - name: Mkdir for java installation\n    file:\n      path: '{{ java_path }}/{{ java_folder }}'\n      state: directory\n\n  - name: Create temporary directory\n    tempfile:\n      state: directory\n    register: temp_dir\n\n  - name: Unarchive to temporary directory\n    unarchive:\n      src: '{{ java_artifact }}'\n      dest: '{{ temp_dir.path }}'\n      remote_src: true\n      list_files: true\n    register: unarchived_folder\n\n  - name: Sync from temporary directory\n    synchronize:\n      src: '{{ temp_dir.path }}/{{ unarchived_folder.files[0].split(\"/\")[0] }}/'\n      dest: '{{ java_path }}/{{ java_folder }}'\n      recursive: true\n      archive: false\n      checksum: true\n    delegate_to: '{{ inventory_hostname }}'\n\n  - name: Set permissions for java installation\n    file:\n      path: '{{ java_path }}/{{ java_folder }}'\n      recurse: true\n      owner: root\n      group: root\n      mode: 0755\n  when: not java_folder_bin.stat.exists\n"}, {"commit_sha": "a77a8900bb9032eb97498fbb9149d4504e73b0b5", "sha": "aa32ea430b8f0dfdd6c46e29e7c90543c6a83dc9", "filename": "tasks/install.yml", "repository": "geerlingguy/ansible-role-solr", "decoded_content": "---\n- name: Ensure lsof is present (RedHat).\n  yum: name=lsof state=present\n  when: ansible_os_family == \"RedHat\"\n\n- name: Ensure setfacl support is present.\n  package: name=acl state=present\n\n- name: Run Solr installation script.\n  shell: >\n    {{ solr_workspace }}/{{ solr_filename }}/bin/install_solr_service.sh\n    {{ solr_workspace }}/{{ solr_filename }}.tgz\n    -i {{ solr_install_dir }}\n    -d {{ solr_home }}\n    -u {{ solr_user }}\n    -s {{ solr_service_name }}\n    -p {{ solr_port }}\n    creates={{ solr_install_path }}/bin/solr\n  register: solr_install_script_result\n\n# Workaround for bug https://github.com/ansible/ansible-modules-core/issues/915.\n- name: Ensure solr is stopped (RHEL 7 workaround).\n  command: service {{ solr_service_name }} stop\n  when: >\n    (ansible_os_family == 'RedHat')\n    and (ansible_distribution_version.split(\".\")[0] == '7')\n    and (solr_install_script_result.changed)\n  failed_when: false\n\n- name: Run systemd daemon_reload (RHEL 7 workaround).\n  systemd:\n    name: solr\n    daemon_reload: yes\n  when: >\n    (ansible_os_family == 'RedHat')\n    and (ansible_distribution_version.split(\".\")[0] == '7')\n    and (solr_install_script_result.changed)\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "26a3c2a7f715822b353cfaecac956806885abda6", "filename": "roles/monit/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Install monit package\n  package: name=monit\n           state=present\n  tags:\n    - download\n\n- name: Install chkconfig package -- not in debian 9\n  package: name=chkconfig\n           state=present\n  when: is_debian and ansible_distribution_major_version == \"8\"\n  tags:\n    - download\n\n- name: Update main config file\n  template: backup=yes\n            src=monitrc\n            dest=/etc/monitrc\n            owner=root\n            group=root\n            mode=0600\n\n- name: Update config files\n  template: src={{ item }}\n            dest=/etc/monit.d/{{ item }}\n            owner=root\n            group=root\n            force=yes\n            mode=0755\n  with_items: watchdog\n  register: monit_config\n  when: false\n  until: monit_config | success\n  retries: 5\n  delay: 1\n\n#TODO: create systemd script\n- name: Enable monit service\n  command: chkconfig monit on\n  when: is_debian and ansible_local.local_facts.os_ver == \"debian-8\"\n\n#- name: Restart monit service\n#  command: service monit restart\n\n- name: Add monit to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=monit\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: monit\n    - option: description\n      value: '\"Monit is a background service monitor which can correct problems, send email, restart services\"'\n    - option: enabled\n      value: \"{{ monit_enabled }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "6255b9e7a1401cf871b40b9f85ab08265650d7a9", "filename": "roles/activity-server/files/bin/xs-check-activities", "repository": "iiab/iiab", "decoded_content": "#!/usr/bin/python\n# Copyright (C) 2008 One Laptop Per Child Association, Inc.\n# Licensed under the terms of the GNU GPL v2 or later; see COPYING for details.\n#\n# written by Douglas Bagnall <douglas@paradise.net.nz>\n\n\"\"\"This script reads activity.info from bundle files and reports on\ntheir quality.\n\"\"\"\n\nimport xs_activities\nimport sys, os\n\nxs_activities.USE_STDERR = True\n\nshow_all = '--show-all' in sys.argv\nif show_all:\n    sys.argv.remove('--show-all')\n\n\ntry:\n    directory = sys.argv[1]\n    os.stat(directory)\nexcept (IndexError, OSError):\n    print __doc__\n    print \"USAGE: %s DIRECTORY\" % sys.argv[0]\n    sys.exit(1)\n\nxs_activities.check_all_bundles(directory, show_all)\n\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "8b63c4b6dd9c42a928490102fa8c47fbdfdba80a", "filename": "roles/manage-confluence-space/tasks/download_attachment.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Download attachment from source\n  get_url:\n    url: '{{ confluence_space_source_url }}{{ attachment_data._links.download }}'\n    dest: '{{ attachment_tempdir.path }}/{{ attachment_data.title }}'\n    force: yes\n    force_basic_auth: yes\n    url_username: '{{ source_confluence_site_username }}'\n    url_password: '{{ source_confluence_site_password }}'\n  no_log: true\n  delegate_to: 127.0.0.1\n\n- name: Upload attachment to destination\n  command: 'curl -u {{ destination_confluence_site_username }}:{{ destination_confluence_site_password }} -X POST -H \"X-Atlassian-Token: no-check\" -F \"file=@{{ attachment_tempdir.path }}/{{ attachment_data.title }}\" {{ confluence_space_destination_url }}/rest/api/content/{{ confluence_content_ids.value.id }}/child/attachment'\n  delegate_to: 127.0.0.1\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "9f0e7db352db2bd4a0125b1bf414fa249c8bb00f", "filename": "playbooks/manage-confluence-space/README.md", "repository": "redhat-cop/infra-ansible", "decoded_content": "## Confluence Space Playbook\nThis playbook is used to copy confluence space from one location to another.\n\n### Example\nPlease refer to the [roles](../../roles/manage-confluence-space/README.md) directory for information regarding the variables required to run this playbook.\n\n### Running the playbook\n`$ ansible-playbook -i invetory playbook.yaml`\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "0a7553e5c2761be4a190bdfc18ee361b340192a0", "filename": "roles/osp/packstack-install/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Prepare the OSP hosts\"\n  import_tasks: host-prep.yml\n\n- import_tasks: packstack-install-prep.yml\n  run_once: true\n  delegate_to: \"{{ ansible_play_hosts | first }}\"\n\n- import_tasks: sync-keys.yml\n\n- import_tasks: packstack-install.yml\n  run_once: true\n  delegate_to: \"{{ ansible_play_hosts | first }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "219decd7ce4300d1e39da582857bf842e79e971a", "filename": "roles/config-satellite/tasks/install.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Install Satellite with default parameters\"\n  command: > \n    satellite-installer \n      --scenario satellite\n      --foreman-initial-organization \"{{ satellite_organization }}\"\n      --foreman-initial-location \"{{ satellite_location }}\"\n      --foreman-admin-username \"{{ satellite_username }}\"\n      --foreman-admin-password \"{{ satellite_password }}\"\n      --foreman-proxy-dns-managed=false\n      --foreman-proxy-dhcp-managed=false\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "f1b1c19d37e3bd7dd953901f33db6f027aea6c66", "filename": "playbooks/openshift/aws/provision.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- hosts: localhost\n  roles:\n  - role: manage-aws-infra\n    operation: inventory_gen_e2c\n\n- hosts: localhost\n  roles:\n  - role: manage-aws-infra\n    operation: deploy\n\n- name: Refresh Server inventory\n  hosts: localhost\n  connection: local\n  gather_facts: False\n  tasks:\n  - meta: refresh_inventory\n\n- hosts: localhost\n  roles:\n  - role: manage-aws-infra\n    operation: inventory_gen_hosts\n\n- name: Refresh Server inventory\n  hosts: localhost\n  connection: local\n  gather_facts: False\n  tasks:\n  - meta: refresh_inventory\n\n- hosts: cluster_hosts\n  gather_facts: false\n  tasks:\n  - name: Debug hostvar\n    debug:\n      msg: \"{{ hostvars[inventory_hostname] }}\"\n      verbosity: 2\n  - name: waiting for server to come back\n    local_action: wait_for host={{ hostvars[inventory_hostname]['ansible_host'] }} port=22 delay=30 timeout=300\n    become: false\n\n- hosts: cluster_hosts\n  tasks:\n  - name: Set Openshift Hostnames\n    set_fact:\n      openshift_hostname: \"{{ ec2_private_dns_name }}\"\n      openshift_public_hostname: \"{{ ec2_public_dns_name }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "3b4916dca9d043bea827e0ebe603d00a33425e8c", "filename": "roles/user-management/manage-idm-users/tasks/configure_group.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n  - name: Create IPA group\n    ipa_group:\n      ipa_host: \"{{ ipa_host | default(ansible_host)}}\"\n      ipa_user: \"{{ ipa_admin_user }}\"\n      ipa_pass: \"{{ ipa_admin_password }}\"\n      validate_certs: \"{{ ipa_validate_certs | default(True) }}\"\n      name: \"{{ item.name | trim }}\"\n      state: \"{{ item.state | default('present') }}\"\n      user: \"{{ item.members | default('[]') }}\"\n    with_items: \"{{ user_groups }}\"\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "5b89ada72ea1237beb5bbcf0c139ea02413a502a", "filename": "roles/ansible/tower/config-ansibletower/tasks/install.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"install epel-release\"\n  package:\n    name: \"https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm\"\n    state: present\n\n- name: \"Set installation dir fact\"\n  set_fact:\n    ansible_tower_dir: \"{{ ansible_tower_download_url |\u00a0basename |\u00a0regex_replace('.tar.gz','') }}\"\n\n- name: \"Check if installer dir exists\"\n  stat: \n    path: \"{{ ansible_tower_dir }}\"\n  register: installer_dir\n\n- name: \"Download & Unpack Ansible Tower installer\"\n  shell: curl {{\u00a0default_ansible_tower_url }} | tar xzf -\n  when: not installer_dir.stat.exists\n\n- name: \"Set up the Ansible Tower inventory\"\n  template:\n    src: inventory.j2\n    dest: \"{{ ansible_tower_dir }}/inventory\"\n  register: inventory\n\n- name: \"run tower installer\"\n  shell: ./setup.sh\n  args:\n    chdir: \"{{ ansible_tower_dir }}\"\n\n- name: \"Wait for Tower to become available before proceeding (30 sec max)\"\n  uri:\n    url: https://localhost/api/v1/config/\n    method: GET\n    user: admin\n    password: \"{{ tower_admin_password }}\"\n    validate_certs: no\n  register: status_output\n  until: status_output.status == 200\n  retries: 6\n  delay: 5\n\n- name: \"Add Tower license\"\n  uri: \n    url: https://localhost/api/v1/config/\n    method: POST\n    body: '{{\u00a0lookup(\"file\", tower_license_file) | from_json |\u00a0combine({\"eula_accepted\":\"true\"}) | to_json }}'\n    body_format: 'json'\n    headers:\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n    user: admin\n    password: \"{{ tower_admin_password }}\" \n    validate_certs: no\n\n- name: \"Download and Install the 'oc' client for OpenShift interactions\"\n  shell: curl {{\u00a0oc_client_download_url }} | tar -C /bin/ -xzf -\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "e4a41dd1ea63fba264e3b5379b26b9f4ff38a41e", "filename": "roles/manage-jira/tasks/prepare_vars.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Configure Jira Variables\n  set_fact:\n    jira_url: \"{{ atlassian.jira.url | default(atlassian.url) }}\"\n    jira_username: \"{{ atlassian.jira.username | default(atlassian.username) }}\"\n    jira_password: \"{{ atlassian.jira.password | default(atlassian.password) }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "eeb7ab25900f0b6f58c1cd3152151adb331fe2a7", "filename": "roles/user-management/manage-local-user-password/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- include_tasks: 'password.yml'\n  when: \n  - user_name is defined\n  - user_name|trim != \"\"\n  - clear_text_password is defined\n  - clear_text_password|trim != \"\"\n\n"}, {"commit_sha": "3848dbe33432b38a7e7ebad0da63826355cf1b4c", "sha": "7f76d026f116c2db3f76d80b0a7dda918d68c7ee", "filename": "tasks/install.yml", "repository": "geerlingguy/ansible-role-solr", "decoded_content": "---\n- name: Ensure lsof is present (RedHat).\n  yum: name=lsof state=present\n  when: ansible_os_family == \"RedHat\"\n\n- name: Run Solr installation script.\n  shell: >\n    {{ solr_workspace }}/{{ solr_filename }}/bin/install_solr_service.sh\n    {{ solr_workspace }}/{{ solr_filename }}.tgz\n    -i {{ solr_install_dir }}\n    -d {{ solr_home }}\n    -u {{ solr_user }}\n    -s {{ solr_service_name }}\n    -p {{ solr_port }}\n    creates={{ solr_install_path }}/bin/solr\n  register: solr_install_script_result\n\n# Workaround for bug https://github.com/ansible/ansible-modules-core/issues/915.\n- name: Ensure solr is stopped (RHEL 7 workaround).\n  command: service {{ solr_service_name }} stop\n  when: >\n    (ansible_os_family == 'RedHat')\n    and (ansible_distribution_version.split(\".\")[0] == '7')\n    and (solr_install_script_result.changed)\n  failed_when: false\n\n- name: Run systemd daemon_reload (RHEL 7 workaround).\n  systemd:\n    name: solr\n    daemon_reload: yes\n  when: >\n    (ansible_os_family == 'RedHat')\n    and (ansible_distribution_version.split(\".\")[0] == '7')\n    and (solr_install_script_result.changed)\n"}, {"commit_sha": "35c4af9fd84d7a7e6bc093adc944b352e68d6ff1", "sha": "e4ddf321778ccd8b1da9cfeb9d074e3b4f49a69f", "filename": "tasks/main-Mountflags.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "- name: Ensure /etc/systemd/system/docker.service.d directory exists\n  file: \n    path: /etc/systemd/system/docker.service.d\n    state: directory\n    mode: 0755\n  become: yes\n\n- name: Copy systemd drop-in for Docker Mount Flags slave configuration\n  copy:\n    src: files/etc/systemd/system/docker.service.d/mountflags-slave.conf\n    dest: /etc/systemd/system/docker.service.d/mountflags-slave.conf\n  become: yes\n\n"}, {"commit_sha": "f958689395b3fc98cacf0c605ed7b8b4b19718da", "sha": "0b07fc6f0ef98a6e2cc76929b37c9a772c86ab65", "filename": "tasks/install_via_git.yml", "repository": "lae/ansible-role-netbox", "decoded_content": "---\n- name: Clone specified NetBox git repository\n  git:\n    repo: \"{{ netbox_git_uri }}\"\n    dest: \"{{ netbox_git_repo_path }}\"\n    version: \"{{ netbox_git_version }}\"\n  register: __netbox_git_repo\n\n- name: Create git deployment directory for NetBox\n  file:\n    path: \"{{ netbox_git_deploy_path }}\"\n    state: directory\n\n- name: Archive and extract snapshot of git repository\n  shell: 'git archive \"{{ netbox_git_version }}\" | tar -x -C \"{{ netbox_git_deploy_path }}\"'\n  args:\n    chdir: \"{{ netbox_git_repo_path }}\"\n  notify:\n    - reload netbox.service\n  when:\n    - __netbox_git_repo | changed\n\n- name: Symlink git repository to current NetBox directory\n  file:\n    src: \"{{ netbox_git_deploy_path }}\"\n    dest: \"{{ netbox_current_path }}\"\n    state: link\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "d416330867f7a7d3b80b521d922f83b1cd5e8f4e", "filename": "roles/prometheus/vars/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# vars file for prometheus\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "4066bf28fc6bf58d40e4afeec462a0b66e4598ee", "filename": "roles/registrator/defaults/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# defaults file for registrator\nregistrator_image: \"gliderlabs/registrator:master\"\nregistrator_uri: \"consul://{{ ansible_default_ipv4.address }}:8500\"\nregistrator_rebuild_container: False\nregistrator_docker_socket: \"/var/run/weave/weave.sock\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "efbf3dffd19c81fb963a5091e932a6d1797a4686", "filename": "roles/config-idm-server/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n# tasks file for idm\n\n- import_tasks: 'prep.yml'\n- import_tasks: 'configure_idm.yml'\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "06230fd3e341f42e093413d5aa0ddf68d5a958e9", "filename": "playbooks/openshift/openstack/dns.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n- name: \"Set the private(internal) and public(external) DNS to use (if provided)\"\n  include_tasks: dns-records.yml\n  with_items:\n    - \"{{ nsupdate_config | default([]) }}\"\n  loop_control:\n    loop_var: nsupdate\n  when:\n    - nsupdate.view is defined\n    - nsupdate.view == 'private' or nsupdate.view == 'public'\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "55be4841408efc38cb6b35e4612ab25c7c5e02a1", "filename": "roles/config-satellite/tasks/satellite.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Install Satellite with default parameters\"\n  command: > \n    satellite-installer \n      --scenario satellite\n      --foreman-initial-organization \"{{ satellite_organization }}\"\n      --foreman-initial-location \"{{ satellite_location }}\"\n      --foreman-admin-username \"{{ satellite_username }}\"\n      --foreman-admin-password \"{{ satellite_password }}\"\n      --foreman-proxy-dns-managed=false\n      --foreman-proxy-dhcp-managed=false\n\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "198426ca4e010e8ce12c3a4a645404017846b7da", "filename": "playbooks/files/suricata.yaml", "repository": "rocknsm/rock", "decoded_content": "%YAML 1.1\n---\n\n# Suricata configuration file. In addition to the comments describing all\n# options in this file, full documentation can be found at:\n# https://redmine.openinfosecfoundation.org/projects/suricata/wiki/Suricatayaml\n\n##\n## Step 1: inform Suricata about your network\n##\n\nvars:\n  # more specifc is better for alert accuracy and performance\n  address-groups:\n    HOME_NET: \"[192.168.0.0/16,10.0.0.0/8,172.16.0.0/12]\"\n    #HOME_NET: \"[192.168.0.0/16]\"\n    #HOME_NET: \"[10.0.0.0/8]\"\n    #HOME_NET: \"[172.16.0.0/12]\"\n    #HOME_NET: \"any\"\n\n    EXTERNAL_NET: \"!$HOME_NET\"\n    #EXTERNAL_NET: \"any\"\n\n    HTTP_SERVERS: \"$HOME_NET\"\n    SMTP_SERVERS: \"$HOME_NET\"\n    SQL_SERVERS: \"$HOME_NET\"\n    DNS_SERVERS: \"$HOME_NET\"\n    TELNET_SERVERS: \"$HOME_NET\"\n    AIM_SERVERS: \"$EXTERNAL_NET\"\n    DNP3_SERVER: \"$HOME_NET\"\n    DNP3_CLIENT: \"$HOME_NET\"\n    MODBUS_CLIENT: \"$HOME_NET\"\n    MODBUS_SERVER: \"$HOME_NET\"\n    ENIP_CLIENT: \"$HOME_NET\"\n    ENIP_SERVER: \"$HOME_NET\"\n\n  port-groups:\n    HTTP_PORTS: \"80\"\n    SHELLCODE_PORTS: \"!80\"\n    ORACLE_PORTS: 1521\n    SSH_PORTS: 22\n    DNP3_PORTS: 20000\n    MODBUS_PORTS: 502\n\n\n##\n## Step 2: select the rules to enable or disable\n##\n\ndefault-rule-path: /etc/suricata/rules\nrule-files:\n - pulledpork.rules      # Default file dropped by pulledpork in rules dir\n# - decoder-events.rules # available in suricata sources under rules dir\n# - stream-events.rules  # available in suricata sources under rules dir\n - http-events.rules    # available in suricata sources under rules dir\n - smtp-events.rules    # available in suricata sources under rules dir\n - dns-events.rules     # available in suricata sources under rules dir\n - tls-events.rules     # available in suricata sources under rules dir\n #- modbus-events.rules  # available in suricata sources under rules dir\n - app-layer-events.rules  # available in suricata sources under rules dir\n - files.rules             # available in suricata sources under rules dir\n\nclassification-file: /etc/suricata/classification.config\nreference-config-file: /etc/suricata/reference.config\n# threshold-file: /etc/suricata/threshold.config\n\n\n##\n## Step 3: select outputs to enable\n##\n\n# The default logging directory.  Any log or output file will be\n# placed here if its not specified with a full path name. This can be\n# overridden with the -l command line parameter.\ndefault-log-dir: /var/log/suricata/\n\n# global stats configuration\nstats:\n  enabled: yes\n  # The interval field (in seconds) controls at what interval\n  # the loggers are invoked.\n  interval: 8\n\n# Configure the type of alert (and other) logging you would like.\noutputs:\n  # a line based alerts log similar to Snort's fast.log\n  - fast:\n      enabled: yes\n      filename: fast.log\n      append: yes\n      #filetype: regular # 'regular', 'unix_stream' or 'unix_dgram'\n\n  # Extensible Event Format (nicknamed EVE) event log in JSON format\n  - eve-log:\n      enabled: yes\n      filetype: regular #regular|syslog|unix_dgram|unix_stream|redis\n      filename: eve.json\n      #prefix: \"@cee: \" # prefix to prepend to each log entry\n      # the following are valid when type: syslog above\n      #identity: \"suricata\"\n      #facility: local5\n      #level: Info ## possible levels: Emergency, Alert, Critical,\n                   ## Error, Warning, Notice, Info, Debug\n      #redis:\n      #  server: 127.0.0.1\n      #  port: 6379\n      #  mode: list ## possible values: list (default), channel\n      #  key: suricata ## key or channel to use (default to suricata)\n      # Redis pipelining set up. This will enable to only do a query every\n      # 'batch-size' events. This should lower the latency induced by network\n      # connection at the cost of some memory. There is no flushing implemented\n      # so this setting as to be reserved to high traffic suricata.\n      #  pipelining:\n      #    enabled: yes ## set enable to yes to enable query pipelining\n      #    batch-size: 10 ## number of entry to keep in buffer\n      types:\n        - alert:\n            # payload: yes             # enable dumping payload in Base64\n            # payload-buffer-size: 4kb # max size of payload buffer to output in eve-log\n            # payload-printable: yes   # enable dumping payload in printable (lossy) format\n            # packet: yes              # enable dumping of packet (without stream segments)\n            http: yes                # enable dumping of http fields\n            tls: yes                 # enable dumping of tls fields\n            ssh: yes                 # enable dumping of ssh fields\n            smtp: yes                # enable dumping of smtp fields\n\n            # Enable the logging of tagged packets for rules using the\n            # \"tag\" keyword.\n            tagged-packets: yes\n\n            # HTTP X-Forwarded-For support by adding an extra field or overwriting\n            # the source or destination IP address (depending on flow direction)\n            # with the one reported in the X-Forwarded-For HTTP header. This is\n            # helpful when reviewing alerts for traffic that is being reverse\n            # or forward proxied.\n            xff:\n              enabled: no\n              # Two operation modes are available, \"extra-data\" and \"overwrite\".\n              mode: extra-data\n              # Two proxy deployments are supported, \"reverse\" and \"forward\". In\n              # a \"reverse\" deployment the IP address used is the last one, in a\n              # \"forward\" deployment the first IP address is used.\n              deployment: reverse\n              # Header name where the actual IP address will be reported, if more\n              # than one IP address is present, the last IP address will be the\n              # one taken into consideration.\n              header: X-Forwarded-For\n        - http:\n            extended: yes     # enable this for extended logging information\n            # custom allows additional http fields to be included in eve-log\n            # the example below adds three additional fields when uncommented\n            #custom: [Accept-Encoding, Accept-Language, Authorization]\n        - dns:\n            # control logging of queries and answers\n            # default yes, no to disable\n            query: yes     # enable logging of DNS queries\n            answer: yes    # enable logging of DNS answers\n            # control which RR types are logged\n            # all enabled if custom not specified\n            #custom: [a, aaaa, cname, mx, ns, ptr, txt]\n        - tls:\n            extended: yes     # enable this for extended logging information\n        - files:\n            force-magic: no   # force logging magic on all logged files\n            force-md5: no     # force logging of md5 checksums\n        #- drop:\n        #    alerts: yes      # log alerts that caused drops\n        #    flows: all       # start or all: 'start' logs only a single drop\n        #                     # per flow direction. All logs each dropped pkt.\n        - smtp:\n            #extended: yes # enable this for extended logging information\n            # this includes: bcc, message-id, subject, x_mailer, user-agent\n            # custom fields logging from the list:\n            #  reply-to, bcc, message-id, subject, x-mailer, user-agent, received,\n            #  x-originating-ip, in-reply-to, references, importance, priority,\n            #  sensitivity, organization, content-md5, date\n            #custom: [received, x-mailer, x-originating-ip, relays, reply-to, bcc]\n            # output md5 of fields: body, subject\n            # for the body you need to set app-layer.protocols.smtp.mime.body-md5\n            # to yes\n            #md5: [body, subject]\n\n        - ssh\n        - stats:\n            totals: yes       # stats for all threads merged together\n            threads: no       # per thread stats\n            deltas: no        # include delta values\n        # bi-directional flows\n        - flow\n        # uni-directional flows\n        #- netflow\n\n  # alert output for use with Barnyard2\n  - unified2-alert:\n      enabled: yes\n      filename: unified2.alert\n\n      # File size limit.  Can be specified in kb, mb, gb.  Just a number\n      # is parsed as bytes.\n      limit: 32mb\n\n      # Sensor ID field of unified2 alerts.\n      sensor-id: 0\n\n      # Include payload of packets related to alerts. Defaults to true, set to\n      # false if payload is not required.\n      payload: yes\n\n      # HTTP X-Forwarded-For support by adding the unified2 extra header or\n      # overwriting the source or destination IP address (depending on flow\n      # direction) with the one reported in the X-Forwarded-For HTTP header.\n      # This is helpful when reviewing alerts for traffic that is being reverse\n      # or forward proxied.\n      xff:\n        enabled: no\n        # Two operation modes are available, \"extra-data\" and \"overwrite\". Note\n        # that in the \"overwrite\" mode, if the reported IP address in the HTTP\n        # X-Forwarded-For header is of a different version of the packet\n        # received, it will fall-back to \"extra-data\" mode.\n        mode: extra-data\n        # Two proxy deployments are supported, \"reverse\" and \"forward\". In\n        # a \"reverse\" deployment the IP address used is the last one, in a\n        # \"forward\" deployment the first IP address is used.\n        deployment: reverse\n        # Header name where the actual IP address will be reported, if more\n        # than one IP address is present, the last IP address will be the\n        # one taken into consideration.\n        header: X-Forwarded-For\n\n  # a line based log of HTTP requests (no alerts)\n  - http-log:\n      enabled: no\n      filename: http.log\n      append: yes\n      #extended: yes     # enable this for extended logging information\n      #custom: yes       # enabled the custom logging format (defined by customformat)\n      #customformat: \"%{%D-%H:%M:%S}t.%z %{X-Forwarded-For}i %H %m %h %u %s %B %a:%p -> %A:%P\"\n      #filetype: regular # 'regular', 'unix_stream' or 'unix_dgram'\n\n  # a line based log of TLS handshake parameters (no alerts)\n  - tls-log:\n      enabled: no  # Log TLS connections.\n      filename: tls.log # File to store TLS logs.\n      append: yes\n      #filetype: regular # 'regular', 'unix_stream' or 'unix_dgram'\n      #extended: yes # Log extended information like fingerprint\n\n  # output module to store certificates chain to disk\n  - tls-store:\n      enabled: no\n      #certs-log-dir: certs # directory to store the certificates files\n\n  # a line based log of DNS requests and/or replies (no alerts)\n  - dns-log:\n      enabled: no\n      filename: dns.log\n      append: yes\n      #filetype: regular # 'regular', 'unix_stream' or 'unix_dgram'\n\n  # Packet log... log packets in pcap format. 3 modes of operation: \"normal\"\n  # \"multi\" and \"sguil\".\n  #\n  # In normal mode a pcap file \"filename\" is created in the default-log-dir,\n  # or are as specified by \"dir\".\n  # In multi mode, a file is created per thread. This will perform much\n  # better, but will create multiple files where 'normal' would create one.\n  # In multi mode the filename takes a few special variables:\n  # - %n -- thread number\n  # - %i -- thread id\n  # - %t -- timestamp (secs or secs.usecs based on 'ts-format'\n  # E.g. filename: pcap.%n.%t\n  #\n  # Note that it's possible to use directories, but the directories are not\n  # created by Suricata. E.g. filename: pcaps/%n/log.%s will log into the\n  # per thread directory.\n  #\n  # Also note that the limit and max-files settings are enforced per thread.\n  # So the size limit when using 8 threads with 1000mb files and 2000 files\n  # is: 8*1000*2000 ~ 16TiB.\n  #\n  # In Sguil mode \"dir\" indicates the base directory. In this base dir the\n  # pcaps are created in th directory structure Sguil expects:\n  #\n  # $sguil-base-dir/YYYY-MM-DD/$filename.<timestamp>\n  #\n  # By default all packets are logged except:\n  # - TCP streams beyond stream.reassembly.depth\n  # - encrypted streams after the key exchange\n  #\n  - pcap-log:\n      enabled: no\n      filename: log.pcap\n\n      # File size limit.  Can be specified in kb, mb, gb.  Just a number\n      # is parsed as bytes.\n      limit: 1000mb\n\n      # If set to a value will enable ring buffer mode. Will keep Maximum of \"max-files\" of size \"limit\"\n      max-files: 2000\n\n      mode: normal # normal, multi or sguil.\n      #sguil-base-dir: /nsm_data/\n      #ts-format: usec # sec or usec second format (default) is filename.sec usec is filename.sec.usec\n      use-stream-depth: no #If set to \"yes\" packets seen after reaching stream inspection depth are ignored. \"no\" logs all packets\n      honor-pass-rules: no # If set to \"yes\", flows in which a pass rule matched will stopped being logged.\n\n  # a full alerts log containing much information for signature writers\n  # or for investigating suspected false positives.\n  - alert-debug:\n      enabled: no\n      filename: alert-debug.log\n      append: yes\n      #filetype: regular # 'regular', 'unix_stream' or 'unix_dgram'\n\n  # alert output to prelude (http://www.prelude-technologies.com/) only\n  # available if Suricata has been compiled with --enable-prelude\n  - alert-prelude:\n      enabled: no\n      profile: suricata\n      log-packet-content: no\n      log-packet-header: yes\n\n  # Stats.log contains data from various counters of the suricata engine.\n  - stats:\n      enabled: yes\n      filename: stats.log\n      totals: yes       # stats for all threads merged together\n      threads: no       # per thread stats\n      #null-values: yes  # print counters that have value 0\n\n  # a line based alerts log similar to fast.log into syslog\n  - syslog:\n      enabled: no\n      # reported identity to syslog. If ommited the program name (usually\n      # suricata) will be used.\n      #identity: \"suricata\"\n      facility: local5\n      #level: Info ## possible levels: Emergency, Alert, Critical,\n                   ## Error, Warning, Notice, Info, Debug\n\n  # a line based information for dropped packets in IPS mode\n  - drop:\n      enabled: no\n      filename: drop.log\n      append: yes\n      #filetype: regular # 'regular', 'unix_stream' or 'unix_dgram'\n\n  # output module to store extracted files to disk\n  #\n  # The files are stored to the log-dir in a format \"file.<id>\" where <id> is\n  # an incrementing number starting at 1. For each file \"file.<id>\" a meta\n  # file \"file.<id>.meta\" is created.\n  #\n  # File extraction depends on a lot of things to be fully done:\n  # - stream reassembly depth. For optimal results, set this to 0 (unlimited)\n  # - http request / response body sizes. Again set to 0 for optimal results.\n  # - rules that contain the \"filestore\" keyword.\n  - file-store:\n      enabled: no       # set to yes to enable\n      log-dir: files    # directory to store the files\n      force-magic: no   # force logging magic on all stored files\n      force-md5: no     # force logging of md5 checksums\n      force-filestore: no # force storing of all files\n      #waldo: file.waldo # waldo file to store the file_id across runs\n\n  # output module to log files tracked in a easily parsable json format\n  - file-log:\n      enabled: no\n      filename: files-json.log\n      append: yes\n      #filetype: regular # 'regular', 'unix_stream' or 'unix_dgram'\n\n      force-magic: no   # force logging magic on all logged files\n      force-md5: no     # force logging of md5 checksums\n\n  # Log TCP data after stream normalization\n  # 2 types: file or dir. File logs into a single logfile. Dir creates\n  # 2 files per TCP session and stores the raw TCP data into them.\n  # Using 'both' will enable both file and dir modes.\n  #\n  # Note: limited by stream.depth\n  - tcp-data:\n      enabled: no\n      type: file\n      filename: tcp-data.log\n\n  # Log HTTP body data after normalization, dechunking and unzipping.\n  # 2 types: file or dir. File logs into a single logfile. Dir creates\n  # 2 files per HTTP session and stores the normalized data into them.\n  # Using 'both' will enable both file and dir modes.\n  #\n  # Note: limited by the body limit settings\n  - http-body-data:\n      enabled: no\n      type: file\n      filename: http-data.log\n\n  # Lua Output Support - execute lua script to generate alert and event\n  # output.\n  # Documented at:\n  # https://redmine.openinfosecfoundation.org/projects/suricata/wiki/Lua_Output\n  - lua:\n      enabled: no\n      #scripts-dir: /etc/suricata/lua-output/\n      scripts:\n      #   - script1.lua\n\n# Logging configuration.  This is not about logging IDS alerts/events, but\n# output about what Suricata is doing, like startup messages, errors, etc.\nlogging:\n  # The default log level, can be overridden in an output section.\n  # Note that debug level logging will only be emitted if Suricata was\n  # compiled with the --enable-debug configure option.\n  #\n  # This value is overriden by the SC_LOG_LEVEL env var.\n  default-log-level: notice\n\n  # The default output format.  Optional parameter, should default to\n  # something reasonable if not provided.  Can be overriden in an\n  # output section.  You can leave this out to get the default.\n  #\n  # This value is overriden by the SC_LOG_FORMAT env var.\n  #default-log-format: \"[%i] %t - (%f:%l) <%d> (%n) -- \"\n\n  # A regex to filter output.  Can be overridden in an output section.\n  # Defaults to empty (no filter).\n  #\n  # This value is overriden by the SC_LOG_OP_FILTER env var.\n  default-output-filter:\n\n  # Define your logging outputs.  If none are defined, or they are all\n  # disabled you will get the default - console output.\n  outputs:\n  - console:\n      enabled: yes\n      # type: json\n  - file:\n      enabled: no\n      level: info\n      filename: /var/log/suricata/suricata.log\n      # type: json\n  - syslog:\n      enabled: no\n      facility: local5\n      format: \"[%i] <%d> -- \"\n      # type: json\n\n\n##\n## Step 4: configure common capture settings\n##\n## See \"Advanced Capture Options\" below for more options, including NETMAP\n## and PF_RING.\n##\n\n# Linux high speed capture support\naf-packet:\n  - interface: eth0\n    # Number of receive threads. \"auto\" uses the number of cores\n    #threads: auto\n    # Default clusterid. AF_PACKET will load balance packets based on flow.\n    cluster-id: 99\n    # Default AF_PACKET cluster type. AF_PACKET can load balance per flow or per hash.\n    # This is only supported for Linux kernel > 3.1\n    # possible value are:\n    #  * cluster_round_robin: round robin load balancing\n    #  * cluster_flow: all packets of a given flow are send to the same socket\n    #  * cluster_cpu: all packets treated in kernel by a CPU are send to the same socket\n    #  * cluster_qm: all packets linked by network card to a RSS queue are sent to the same\n    #  socket. Requires at least Linux 3.14.\n    #  * cluster_random: packets are sent randomly to sockets but with an equipartition.\n    #  Requires at least Linux 3.14.\n    #  * cluster_rollover: kernel rotates between sockets filling each socket before moving\n    #  to the next. Requires at least Linux 3.10.\n    # Recommended modes are cluster_flow on most boxes and cluster_cpu or cluster_qm on system\n    # with capture card using RSS (require cpu affinity tuning and system irq tuning)\n    cluster-type: cluster_flow\n    # In some fragmentation case, the hash can not be computed. If \"defrag\" is set\n    # to yes, the kernel will do the needed defragmentation before sending the packets.\n    defrag: yes\n    # After Linux kernel 3.10 it is possible to activate the rollover option: if a socket is\n    # full then kernel will send the packet on the next socket with room available. This option\n    # can minimize packet drop and increase the treated bandwidth on single intensive flow.\n    #rollover: yes\n    # To use the ring feature of AF_PACKET, set 'use-mmap' to yes\n    use-mmap: yes\n    # Lock memory map to avoid it goes to swap. Be careful that over suscribing could lock\n    # your system\n    mmap-locked: yes\n    # Use experimental tpacket_v3 capture mode, only active if use-mmap is true\n    tpacket-v3: yes\n    # Ring size will be computed with respect to max_pending_packets and number\n    # of threads. You can set manually the ring size in number of packets by setting\n    # the following value. If you are using flow cluster-type and have really network\n    # intensive single-flow you could want to set the ring-size independently of the number\n    # of threads:\n    #ring-size: 2048\n    # Block size is used by tpacket_v3 only. It should set to a value high enough to contain\n    # a decent number of packets. Size is in bytes so please consider your MTU. It should be\n    # a power of 2 and it must be multiple of page size (usually 4096).\n    #block-size: 32768\n    # tpacket_v3 block timeout: an open block is passed to userspace if it is not\n    # filled after block-timeout milliseconds.\n    #block-timeout: 10\n    # On busy system, this could help to set it to yes to recover from a packet drop\n    # phase. This will result in some packets (at max a ring flush) being non treated.\n    use-emergency-flush: yes\n    # recv buffer size, increase value could improve performance\n    # buffer-size: 32768\n    # Set to yes to disable promiscuous mode\n    # disable-promisc: no\n    # Choose checksum verification mode for the interface. At the moment\n    # of the capture, some packets may be with an invalid checksum due to\n    # offloading to the network card of the checksum computation.\n    # Possible values are:\n    #  - kernel: use indication sent by kernel for each packet (default)\n    #  - yes: checksum validation is forced\n    #  - no: checksum validation is disabled\n    #  - auto: suricata uses a statistical approach to detect when\n    #  checksum off-loading is used.\n    # Warning: 'checksum-validation' must be set to yes to have any validation\n    #checksum-checks: kernel\n    # BPF filter to apply to this interface. The pcap filter syntax apply here.\n    #bpf-filter: port 80 or udp\n    # You can use the following variables to activate AF_PACKET tap or IPS mode.\n    # If copy-mode is set to ips or tap, the traffic coming to the current\n    # interface will be copied to the copy-iface interface. If 'tap' is set, the\n    # copy is complete. If 'ips' is set, the packet matching a 'drop' action\n    # will not be copied.\n    #copy-mode: ips\n    #copy-iface: eth1\n\n  # Put default values here. These will be used for an interface that is not\n  # in the list above.\n  - interface: default\n    #threads: auto\n    defrag: yes\n    cluster-type: cluster_flow\n    use-mmap: yes\n    mmap-locked: yes\n    #rollover: yes\n    tpacket-v3: yes\n    use-emergency-flush: yes\n\n# Cross platform libpcap capture support\npcap:\n  - interface: eth0\n    # On Linux, pcap will try to use mmaped capture and will use buffer-size\n    # as total of memory used by the ring. So set this to something bigger\n    # than 1% of your bandwidth.\n    #buffer-size: 16777216\n    #bpf-filter: \"tcp and port 25\"\n    # Choose checksum verification mode for the interface. At the moment\n    # of the capture, some packets may be with an invalid checksum due to\n    # offloading to the network card of the checksum computation.\n    # Possible values are:\n    #  - yes: checksum validation is forced\n    #  - no: checksum validation is disabled\n    #  - auto: suricata uses a statistical approach to detect when\n    #  checksum off-loading is used. (default)\n    # Warning: 'checksum-validation' must be set to yes to have any validation\n    #checksum-checks: auto\n    # With some accelerator cards using a modified libpcap (like myricom), you\n    # may want to have the same number of capture threads as the number of capture\n    # rings. In this case, set up the threads variable to N to start N threads\n    # listening on the same interface.\n    #threads: 16\n    # set to no to disable promiscuous mode:\n    #promisc: no\n    # set snaplen, if not set it defaults to MTU if MTU can be known\n    # via ioctl call and to full capture if not.\n    #snaplen: 1518\n  # Put default values here\n  - interface: default\n    #checksum-checks: auto\n\n# Settings for reading pcap files\npcap-file:\n  # Possible values are:\n  #  - yes: checksum validation is forced\n  #  - no: checksum validation is disabled\n  #  - auto: suricata uses a statistical approach to detect when\n  #  checksum off-loading is used. (default)\n  # Warning: 'checksum-validation' must be set to yes to have checksum tested\n  checksum-checks: auto\n\n# See \"Advanced Capture Options\" below for more options, including NETMAP\n# and PF_RING.\n\n\n##\n## Step 5: App Layer Protocol Configuration\n##\n\n# Configure the app-layer parsers. The protocols section details each\n# protocol.\n#\n# The option \"enabled\" takes 3 values - \"yes\", \"no\", \"detection-only\".\n# \"yes\" enables both detection and the parser, \"no\" disables both, and\n# \"detection-only\" enables protocol detection only (parser disabled).\napp-layer:\n  protocols:\n    tls:\n      enabled: yes\n      detection-ports:\n        dp: 443\n\n      #no-reassemble: yes\n    dcerpc:\n      enabled: yes\n    ftp:\n      enabled: yes\n    ssh:\n      enabled: yes\n    smtp:\n      enabled: yes\n      # Configure SMTP-MIME Decoder\n      mime:\n        # Decode MIME messages from SMTP transactions\n        # (may be resource intensive)\n        # This field supercedes all others because it turns the entire\n        # process on or off\n        decode-mime: yes\n\n        # Decode MIME entity bodies (ie. base64, quoted-printable, etc.)\n        decode-base64: yes\n        decode-quoted-printable: yes\n\n        # Maximum bytes per header data value stored in the data structure\n        # (default is 2000)\n        header-value-depth: 2000\n\n        # Extract URLs and save in state data structure\n        extract-urls: yes\n        # Set to yes to compute the md5 of the mail body. You will then\n        # be able to journalize it.\n        body-md5: no\n      # Configure inspected-tracker for file_data keyword\n      inspected-tracker:\n        content-limit: 100000\n        content-inspect-min-size: 32768\n        content-inspect-window: 4096\n    imap:\n      enabled: detection-only\n    msn:\n      enabled: detection-only\n    smb:\n      enabled: yes\n      detection-ports:\n        dp: 139\n    # Note: Modbus probe parser is minimalist due to the poor significant field\n    # Only Modbus message length (greater than Modbus header length)\n    # And Protocol ID (equal to 0) are checked in probing parser\n    # It is important to enable detection port and define Modbus port\n    # to avoid false positive\n    modbus:\n      # How many unreplied Modbus requests are considered a flood.\n      # If the limit is reached, app-layer-event:modbus.flooded; will match.\n      #request-flood: 500\n\n      enabled: no\n      detection-ports:\n        dp: 502\n      # According to MODBUS Messaging on TCP/IP Implementation Guide V1.0b, it\n      # is recommended to keep the TCP connection opened with a remote device\n      # and not to open and close it for each MODBUS/TCP transaction. In that\n      # case, it is important to set the depth of the stream reassembling as\n      # unlimited (stream.reassembly.depth: 0)\n    # smb2 detection is disabled internally inside the engine.\n    #smb2:\n    #  enabled: yes\n    dns:\n      # memcaps. Globally and per flow/state.\n      #global-memcap: 16mb\n      #state-memcap: 512kb\n\n      # How many unreplied DNS requests are considered a flood.\n      # If the limit is reached, app-layer-event:dns.flooded; will match.\n      #request-flood: 500\n\n      tcp:\n        enabled: yes\n        detection-ports:\n          dp: 53\n      udp:\n        enabled: yes\n        detection-ports:\n          dp: 53\n    http:\n      enabled: yes\n      # memcap: 64mb\n\n      # default-config:           Used when no server-config matches\n      #   personality:            List of personalities used by default\n      #   request-body-limit:     Limit reassembly of request body for inspection\n      #                           by http_client_body & pcre /P option.\n      #   response-body-limit:    Limit reassembly of response body for inspection\n      #                           by file_data, http_server_body & pcre /Q option.\n      #   double-decode-path:     Double decode path section of the URI\n      #   double-decode-query:    Double decode query section of the URI\n      #   response-body-decompress-layer-limit:\n      #                           Limit to how many layers of compression will be\n      #                           decompressed. Defaults to 2.\n      #\n      # server-config:            List of server configurations to use if address matches\n      #   address:                List of ip addresses or networks for this block\n      #   personalitiy:           List of personalities used by this block\n      #   request-body-limit:     Limit reassembly of request body for inspection\n      #                           by http_client_body & pcre /P option.\n      #   response-body-limit:    Limit reassembly of response body for inspection\n      #                           by file_data, http_server_body & pcre /Q option.\n      #   double-decode-path:     Double decode path section of the URI\n      #   double-decode-query:    Double decode query section of the URI\n      #\n      #   uri-include-all:        Include all parts of the URI. By default the\n      #                           'scheme', username/password, hostname and port\n      #                           are excluded. Setting this option to true adds\n      #                           all of them to the normalized uri as inspected\n      #                           by http_uri, urilen, pcre with /U and the other\n      #                           keywords that inspect the normalized uri.\n      #                           Note that this does not affect http_raw_uri.\n      #                           Also, note that including all was the default in\n      #                           1.4 and 2.0beta1.\n      #\n      #   meta-field-limit:       Hard size limit for request and response size\n      #                           limits. Applies to request line and headers,\n      #                           response line and headers. Does not apply to\n      #                           request or response bodies. Default is 18k.\n      #                           If this limit is reached an event is raised.\n      #\n      # Currently Available Personalities:\n      #   Minimal, Generic, IDS (default), IIS_4_0, IIS_5_0, IIS_5_1, IIS_6_0,\n      #   IIS_7_0, IIS_7_5, Apache_2\n      libhtp:\n         default-config:\n           personality: IDS\n\n           # Can be specified in kb, mb, gb.  Just a number indicates\n           # it's in bytes.\n           request-body-limit: 100kb\n           response-body-limit: 100kb\n\n           # inspection limits\n           request-body-minimal-inspect-size: 32kb\n           request-body-inspect-window: 4kb\n           response-body-minimal-inspect-size: 40kb\n           response-body-inspect-window: 16kb\n\n           # response body decompression (0 disables)\n           response-body-decompress-layer-limit: 2\n\n           # auto will use http-body-inline mode in IPS mode, yes or no set it statically\n           http-body-inline: auto\n\n           # Take a random value for inspection sizes around the specified value.\n           # This lower the risk of some evasion technics but could lead\n           # detection change between runs. It is set to 'yes' by default.\n           #randomize-inspection-sizes: yes\n           # If randomize-inspection-sizes is active, the value of various\n           # inspection size will be choosen in the [1 - range%, 1 + range%]\n           # range\n           # Default value of randomize-inspection-range is 10.\n           #randomize-inspection-range: 10\n\n           # decoding\n           double-decode-path: no\n           double-decode-query: no\n\n         server-config:\n\n           #- apache:\n           #    address: [192.168.1.0/24, 127.0.0.0/8, \"::1\"]\n           #    personality: Apache_2\n           #    # Can be specified in kb, mb, gb.  Just a number indicates\n           #    # it's in bytes.\n           #    request-body-limit: 4096\n           #    response-body-limit: 4096\n           #    double-decode-path: no\n           #    double-decode-query: no\n\n           #- iis7:\n           #    address:\n           #      - 192.168.0.0/24\n           #      - 192.168.10.0/24\n           #    personality: IIS_7_0\n           #    # Can be specified in kb, mb, gb.  Just a number indicates\n           #    # it's in bytes.\n           #    request-body-limit: 4096\n           #    response-body-limit: 4096\n           #    double-decode-path: no\n           #    double-decode-query: no\n\n# Limit for the maximum number of asn1 frames to decode (default 256)\nasn1-max-frames: 256\n\n\n##############################################################################\n##\n## Advanced settings below\n##\n##############################################################################\n\n##\n## Run Options\n##\n\n# Run suricata as user and group.\n#run-as:\n#  user: suri\n#  group: suri\n\n# Some logging module will use that name in event as identifier. The default\n# value is the hostname\n#sensor-name: suricata\n\n# Default pid file.\n# Will use this file if no --pidfile in command options.\n#pid-file: /var/run/suricata.pid\n\n# Daemon working directory\n# Suricata will change directory to this one if provided\n# Default: \"/\"\n#daemon-directory: \"/\"\n\n# Suricata core dump configuration. Limits the size of the core dump file to\n# approximately max-dump. The actual core dump size will be a multiple of the\n# page size. Core dumps that would be larger than max-dump are truncated. On\n# Linux, the actual core dump size may be a few pages larger than max-dump.\n# Setting max-dump to 0 disables core dumping.\n# Setting max-dump to 'unlimited' will give the full core dump file.\n# On 32-bit Linux, a max-dump value >= ULONG_MAX may cause the core dump size\n# to be 'unlimited'.\n\ncoredump:\n  max-dump: unlimited\n\n# If suricata box is a router for the sniffed networks, set it to 'router'. If\n# it is a pure sniffing setup, set it to 'sniffer-only'.\n# If set to auto, the variable is internally switch to 'router' in IPS mode\n# and 'sniffer-only' in IDS mode.\n# This feature is currently only used by the reject* keywords.\nhost-mode: auto\n\n# Number of packets preallocated per thread. The default is 1024. A higher number \n# will make sure each CPU will be more easily kept busy, but may negatively \n# impact caching.\n#\n# If you are using the CUDA pattern matcher (mpm-algo: ac-cuda), different rules\n# apply. In that case try something like 60000 or more. This is because the CUDA\n# pattern matcher buffers and scans as many packets as possible in parallel.\n#max-pending-packets: 1024\n\n# Runmode the engine should use. Please check --list-runmodes to get the available\n# runmodes for each packet acquisition method. Defaults to \"autofp\" (auto flow pinned\n# load balancing).\n#runmode: autofp\n\n# Specifies the kind of flow load balancer used by the flow pinned autofp mode.\n#\n# Supported schedulers are:\n#\n# round-robin       - Flows assigned to threads in a round robin fashion.\n# active-packets    - Flows assigned to threads that have the lowest number of\n#                     unprocessed packets (default).\n# hash              - Flow alloted usihng the address hash. More of a random\n#                     technique. Was the default in Suricata 1.2.1 and older.\n#\n#autofp-scheduler: active-packets\n\n# Preallocated size for packet. Default is 1514 which is the classical\n# size for pcap on ethernet. You should adjust this value to the highest\n# packet size (MTU + hardware header) on your system.\n#default-packet-size: 1514\n\n# Unix command socket can be used to pass commands to suricata.\n# An external tool can then connect to get information from suricata\n# or trigger some modifications of the engine. Set enabled to yes\n# to activate the feature. You can use the filename variable to set\n# the file name of the socket.\nunix-command:\n  enabled: no\n  #filename: custom.socket\n\n# Magic file. The extension .mgc is added to the value here.\n#magic-file: /usr/share/file/magic\n#magic-file: \n\nlegacy:\n  uricontent: enabled\n\n##\n## Detection settings\n##\n\n# Set the order of alerts bassed on actions\n# The default order is pass, drop, reject, alert\n# action-order:\n#   - pass\n#   - drop\n#   - reject\n#   - alert\n\n# IP Reputation\n#reputation-categories-file: /etc/suricata/iprep/categories.txt\n#default-reputation-path: /etc/suricata/iprep\n#reputation-files:\n# - reputation.list\n\n# When run with the option --engine-analysis, the engine will read each of\n# the parameters below, and print reports for each of the enabled sections\n# and exit.  The reports are printed to a file in the default log dir\n# given by the parameter \"default-log-dir\", with engine reporting\n# subsection below printing reports in its own report file.\nengine-analysis:\n  # enables printing reports for fast-pattern for every rule.\n  rules-fast-pattern: yes\n  # enables printing reports for each rule\n  rules: yes\n\n#recursion and match limits for PCRE where supported\npcre:\n  match-limit: 3500\n  match-limit-recursion: 1500\n\n##\n## Advanced Traffic Tracking and Reconstruction Settings\n##\n\n# Host specific policies for defragmentation and TCP stream\n# reassembly. The host OS lookup is done using a radix tree, just\n# like a routing table so the most specific entry matches.\nhost-os-policy:\n  # Make the default policy windows.\n  windows: [0.0.0.0/0]\n  bsd: []\n  bsd-right: []\n  old-linux: []\n  linux: []\n  old-solaris: []\n  solaris: []\n  hpux10: []\n  hpux11: []\n  irix: []\n  macos: []\n  vista: []\n  windows2k3: []\n\n# Defrag settings:\n\ndefrag:\n  memcap: 32mb\n  hash-size: 65536\n  trackers: 65535 # number of defragmented flows to follow\n  max-frags: 65535 # number of fragments to keep (higher than trackers)\n  prealloc: yes\n  timeout: 60\n\n# Enable defrag per host settings\n#  host-config:\n#\n#    - dmz:\n#        timeout: 30\n#        address: [192.168.1.0/24, 127.0.0.0/8, 1.1.1.0/24, 2.2.2.0/24, \"1.1.1.1\", \"2.2.2.2\", \"::1\"]\n#\n#    - lan:\n#        timeout: 45\n#        address:\n#          - 192.168.0.0/24\n#          - 192.168.10.0/24\n#          - 172.16.14.0/24\n\n# Flow settings:\n# By default, the reserved memory (memcap) for flows is 32MB. This is the limit\n# for flow allocation inside the engine. You can change this value to allow\n# more memory usage for flows.\n# The hash-size determine the size of the hash used to identify flows inside\n# the engine, and by default the value is 65536.\n# At the startup, the engine can preallocate a number of flows, to get a better\n# performance. The number of flows preallocated is 10000 by default.\n# emergency-recovery is the percentage of flows that the engine need to\n# prune before unsetting the emergency state. The emergency state is activated\n# when the memcap limit is reached, allowing to create new flows, but\n# prunning them with the emergency timeouts (they are defined below).\n# If the memcap is reached, the engine will try to prune flows\n# with the default timeouts. If it doens't find a flow to prune, it will set\n# the emergency bit and it will try again with more agressive timeouts.\n# If that doesn't work, then it will try to kill the last time seen flows\n# not in use.\n# The memcap can be specified in kb, mb, gb.  Just a number indicates it's\n# in bytes.\n\nflow:\n  memcap: 128mb\n  hash-size: 65536\n  prealloc: 10000\n  emergency-recovery: 30\n  #managers: 1 # default to one flow manager\n  #recyclers: 1 # default to one flow recycler thread\n\n# This option controls the use of vlan ids in the flow (and defrag)\n# hashing. Normally this should be enabled, but in some (broken)\n# setups where both sides of a flow are not tagged with the same vlan\n# tag, we can ignore the vlan id's in the flow hashing.\nvlan:\n  use-for-tracking: true\n\n# Specific timeouts for flows. Here you can specify the timeouts that the\n# active flows will wait to transit from the current state to another, on each\n# protocol. The value of \"new\" determine the seconds to wait after a hanshake or\n# stream startup before the engine free the data of that flow it doesn't\n# change the state to established (usually if we don't receive more packets\n# of that flow). The value of \"established\" is the amount of\n# seconds that the engine will wait to free the flow if it spend that amount\n# without receiving new packets or closing the connection. \"closed\" is the\n# amount of time to wait after a flow is closed (usually zero).\n#\n# There's an emergency mode that will become active under attack circumstances,\n# making the engine to check flow status faster. This configuration variables\n# use the prefix \"emergency-\" and work similar as the normal ones.\n# Some timeouts doesn't apply to all the protocols, like \"closed\", for udp and\n# icmp.\n\nflow-timeouts:\n\n  default:\n    new: 30\n    established: 300\n    closed: 0\n    emergency-new: 10\n    emergency-established: 100\n    emergency-closed: 0\n  tcp:\n    new: 60\n    established: 600\n    closed: 60\n    emergency-new: 5\n    emergency-established: 100\n    emergency-closed: 10\n  udp:\n    new: 30\n    established: 300\n    emergency-new: 10\n    emergency-established: 100\n  icmp:\n    new: 30\n    established: 300\n    emergency-new: 10\n    emergency-established: 100\n\n# Stream engine settings. Here the TCP stream tracking and reassembly\n# engine is configured.\n#\n# stream:\n#   memcap: 32mb                # Can be specified in kb, mb, gb.  Just a\n#                               # number indicates it's in bytes.\n#   checksum-validation: yes    # To validate the checksum of received\n#                               # packet. If csum validation is specified as\n#                               # \"yes\", then packet with invalid csum will not\n#                               # be processed by the engine stream/app layer.\n#                               # Warning: locally generated trafic can be\n#                               # generated without checksum due to hardware offload\n#                               # of checksum. You can control the handling of checksum\n#                               # on a per-interface basis via the 'checksum-checks'\n#                               # option\n#   prealloc-sessions: 2k       # 2k sessions prealloc'd per stream thread\n#   midstream: false            # don't allow midstream session pickups\n#   async-oneside: false        # don't enable async stream handling\n#   inline: no                  # stream inline mode\n#   max-synack-queued: 5        # Max different SYN/ACKs to queue\n#\n#   reassembly:\n#     memcap: 64mb              # Can be specified in kb, mb, gb.  Just a number\n#                               # indicates it's in bytes.\n#     depth: 1mb                # Can be specified in kb, mb, gb.  Just a number\n#                               # indicates it's in bytes.\n#     toserver-chunk-size: 2560 # inspect raw stream in chunks of at least\n#                               # this size.  Can be specified in kb, mb,\n#                               # gb.  Just a number indicates it's in bytes.\n#                               # The max acceptable size is 4024 bytes.\n#     toclient-chunk-size: 2560 # inspect raw stream in chunks of at least\n#                               # this size.  Can be specified in kb, mb,\n#                               # gb.  Just a number indicates it's in bytes.\n#                               # The max acceptable size is 4024 bytes.\n#     randomize-chunk-size: yes # Take a random value for chunk size around the specified value.\n#                               # This lower the risk of some evasion technics but could lead\n#                               # detection change between runs. It is set to 'yes' by default.\n#     randomize-chunk-range: 10 # If randomize-chunk-size is active, the value of chunk-size is\n#                               # a random value between (1 - randomize-chunk-range/100)*toserver-chunk-size\n#                               # and (1 + randomize-chunk-range/100)*toserver-chunk-size and the same\n#                               # calculation for toclient-chunk-size.\n#                               # Default value of randomize-chunk-range is 10.\n#\n#     raw: yes                  # 'Raw' reassembly enabled or disabled.\n#                               # raw is for content inspection by detection\n#                               # engine.\n#\n#     chunk-prealloc: 250       # Number of preallocated stream chunks. These\n#                               # are used during stream inspection (raw).\n#     segments:                 # Settings for reassembly segment pool.\n#       - size: 4               # Size of the (data)segment for a pool\n#         prealloc: 256         # Number of segments to prealloc and keep\n#                               # in the pool.\n#     zero-copy-size: 128       # This option sets in bytes the value at\n#                               # which segment data is passed to the app\n#                               # layer API directly. Data sizes equal to\n#                               # and higher than the value set are passed\n#                               # on directly.\n#\nstream:\n  memcap: 64mb\n  checksum-validation: yes      # reject wrong csums\n  inline: auto                  # auto will use inline mode in IPS mode, yes or no set it statically\n  reassembly:\n    memcap: 256mb\n    depth: 1mb                  # reassemble 1mb into a stream\n    toserver-chunk-size: 2560\n    toclient-chunk-size: 2560\n    randomize-chunk-size: yes\n    #randomize-chunk-range: 10\n    #raw: yes\n    #chunk-prealloc: 250\n    #segments:\n    #  - size: 4\n    #    prealloc: 256\n    #  - size: 16\n    #    prealloc: 512\n    #  - size: 112\n    #    prealloc: 512\n    #  - size: 248\n    #    prealloc: 512\n    #  - size: 512\n    #    prealloc: 512\n    #  - size: 768\n    #    prealloc: 1024\n    #  - size: 1448\n    #    prealloc: 1024\n    #  - size: 65535\n    #    prealloc: 128\n    #zero-copy-size: 128\n\n# Host table:\n#\n# Host table is used by tagging and per host thresholding subsystems.\n#\nhost:\n  hash-size: 4096\n  prealloc: 1000\n  memcap: 32mb\n\n# IP Pair table:\n#\n# Used by xbits 'ippair' tracking.\n#\n#ippair:\n#  hash-size: 4096\n#  prealloc: 1000\n#  memcap: 32mb\n\n\n##\n## Performance tuning and profiling\n##\n\n# The detection engine builds internal groups of signatures. The engine\n# allow us to specify the profile to use for them, to manage memory on an\n# efficient way keeping a good performance. For the profile keyword you\n# can use the words \"low\", \"medium\", \"high\" or \"custom\". If you use custom\n# make sure to define the values at \"- custom-values\" as your convenience.\n# Usually you would prefer medium/high/low.\n#\n# \"sgh mpm-context\", indicates how the staging should allot mpm contexts for\n# the signature groups.  \"single\" indicates the use of a single context for\n# all the signature group heads.  \"full\" indicates a mpm-context for each\n# group head.  \"auto\" lets the engine decide the distribution of contexts\n# based on the information the engine gathers on the patterns from each\n# group head.\n#\n# The option inspection-recursion-limit is used to limit the recursive calls\n# in the content inspection code.  For certain payload-sig combinations, we\n# might end up taking too much time in the content inspection code.\n# If the argument specified is 0, the engine uses an internally defined\n# default limit.  On not specifying a value, we use no limits on the recursion.\ndetect:\n  profile: medium\n  custom-values:\n    toclient-groups: 3\n    toserver-groups: 25\n  sgh-mpm-context: auto\n  inspection-recursion-limit: 3000\n  # If set to yes, the loading of signatures will be made after the capture\n  # is started. This will limit the downtime in IPS mode.\n  #delayed-detect: yes\n\n  # the grouping values above control how many groups are created per\n  # direction. Port whitelisting forces that port to get it's own group.\n  # Very common ports will benefit, as well as ports with many expensive\n  # rules.\n  grouping:\n    #tcp-whitelist: 53, 80, 139, 443, 445, 1433, 3306, 3389, 6666, 6667, 8080\n    #udp-whitelist: 53, 135, 5060\n\n  profiling:\n    # Log the rules that made it past the prefilter stage, per packet\n    # default is off. The threshold setting determines how many rules\n    # must have made it past pre-filter for that rule to trigger the\n    # logging.\n    #inspect-logging-threshold: 200\n    grouping:\n      dump-to-disk: false\n      include-rules: false      # very verbose\n      include-mpm-stats: false\n\n# Select the multi pattern algorithm you want to run for scan/search the\n# in the engine.\n#\n# The supported algorithms are:\n# \"ac\"      - Aho-Corasick, default implementation\n# \"ac-bs\"   - Aho-Corasick, reduced memory implementation\n# \"ac-cuda\" - Aho-Corasick, CUDA implementation\n# \"ac-ks\"   - Aho-Corasick, \"Ken Steele\" variant\n# \"hs\"      - Hyperscan, available when built with Hyperscan support\n#\n# The default mpm-algo value of \"auto\" will use \"hs\" if Hyperscan is\n# available, \"ac\" otherwise.\n#\n# The mpm you choose also decides the distribution of mpm contexts for\n# signature groups, specified by the conf - \"detect.sgh-mpm-context\".\n# Selecting \"ac\" as the mpm would require \"detect.sgh-mpm-context\"\n# to be set to \"single\", because of ac's memory requirements, unless the\n# ruleset is small enough to fit in one's memory, in which case one can\n# use \"full\" with \"ac\".  Rest of the mpms can be run in \"full\" mode.\n#\n# There is also a CUDA pattern matcher (only available if Suricata was\n# compiled with --enable-cuda: b2g_cuda. Make sure to update your\n# max-pending-packets setting above as well if you use b2g_cuda.\n\nmpm-algo: auto\n\n# Select the matching algorithm you want to use for single-pattern searches.\n#\n# Supported algorithms are \"bm\" (Boyer-Moore) and \"hs\" (Hyperscan, only\n# available if Suricata has been built with Hyperscan support).\n#\n# The default of \"auto\" will use \"hs\" if available, otherwise \"bm\".\n\nspm-algo: auto\n\n# Suricata is multi-threaded. Here the threading can be influenced.\nthreading:\n  set-cpu-affinity: no\n  # Tune cpu affinity of threads. Each family of threads can be bound\n  # on specific CPUs.\n  #\n  # These 2 apply to the all runmodes:\n  # management-cpu-set is used for flow timeout handling, counters\n  # worker-cpu-set is used for 'worker' threads\n  #\n  # Additionally, for autofp these apply:\n  # receive-cpu-set is used for capture threads\n  # verdict-cpu-set is used for IPS verdict threads\n  #\n  cpu-affinity:\n    - management-cpu-set:\n        cpu: [ 0 ]  # include only these cpus in affinity settings\n    - receive-cpu-set:\n        cpu: [ 0 ]  # include only these cpus in affinity settings\n    - worker-cpu-set:\n        cpu: [ \"all\" ]\n        mode: \"exclusive\"\n        # Use explicitely 3 threads and don't compute number by using\n        # detect-thread-ratio variable:\n        # threads: 3\n        prio:\n          low: [ 0 ]\n          medium: [ \"1-2\" ]\n          high: [ 3 ]\n          default: \"medium\"\n    #- verdict-cpu-set:\n    #    cpu: [ 0 ]\n    #    prio:\n    #      default: \"high\"\n  #\n  # By default Suricata creates one \"detect\" thread per available CPU/CPU core.\n  # This setting allows controlling this behaviour. A ratio setting of 2 will\n  # create 2 detect threads for each CPU/CPU core. So for a dual core CPU this\n  # will result in 4 detect threads. If values below 1 are used, less threads\n  # are created. So on a dual core CPU a setting of 0.5 results in 1 detect\n  # thread being created. Regardless of the setting at a minimum 1 detect\n  # thread will always be created.\n  #\n  detect-thread-ratio: 1.0\n\n# Profiling settings. Only effective if Suricata has been built with the\n# the --enable-profiling configure flag.\n#\nprofiling:\n  # Run profiling for every xth packet. The default is 1, which means we\n  # profile every packet. If set to 1000, one packet is profiled for every\n  # 1000 received.\n  #sample-rate: 1000\n\n  # rule profiling\n  rules:\n\n    # Profiling can be disabled here, but it will still have a\n    # performance impact if compiled in.\n    enabled: yes\n    filename: rule_perf.log\n    append: yes\n\n    # Sort options: ticks, avgticks, checks, matches, maxticks\n    sort: avgticks\n\n    # Limit the number of items printed at exit (ignored for json).\n    limit: 100\n\n    # output to json\n    json: yes\n\n  # per keyword profiling\n  keywords:\n    enabled: yes\n    filename: keyword_perf.log\n    append: yes\n\n  # per rulegroup profiling\n  rulegroups:\n    enabled: yes\n    filename: rule_group_perf.log\n    append: yes\n\n  # packet profiling\n  packets:\n\n    # Profiling can be disabled here, but it will still have a\n    # performance impact if compiled in.\n    enabled: yes\n    filename: packet_stats.log\n    append: yes\n\n    # per packet csv output\n    csv:\n\n      # Output can be disabled here, but it will still have a\n      # performance impact if compiled in.\n      enabled: no\n      filename: packet_stats.csv\n\n  # profiling of locking. Only available when Suricata was built with\n  # --enable-profiling-locks.\n  locks:\n    enabled: no\n    filename: lock_stats.log\n    append: yes\n\n  pcap-log:\n    enabled: no\n    filename: pcaplog_stats.log\n    append: yes\n\n##\n## Netfilter integration\n##\n\n# When running in NFQ inline mode, it is possible to use a simulated\n# non-terminal NFQUEUE verdict.\n# This permit to do send all needed packet to suricata via this a rule:\n#        iptables -I FORWARD -m mark ! --mark $MARK/$MASK -j NFQUEUE\n# And below, you can have your standard filtering ruleset. To activate\n# this mode, you need to set mode to 'repeat'\n# If you want packet to be sent to another queue after an ACCEPT decision\n# set mode to 'route' and set next-queue value.\n# On linux >= 3.1, you can set batchcount to a value > 1 to improve performance\n# by processing several packets before sending a verdict (worker runmode only).\n# On linux >= 3.6, you can set the fail-open option to yes to have the kernel\n# accept the packet if suricata is not able to keep pace.\nnfq:\n#  mode: accept\n#  repeat-mark: 1\n#  repeat-mask: 1\n#  route-queue: 2\n#  batchcount: 20\n#  fail-open: yes\n\n#nflog support\nnflog:\n    # netlink multicast group\n    # (the same as the iptables --nflog-group param)\n    # Group 0 is used by the kernel, so you can't use it\n  - group: 2\n    # netlink buffer size\n    buffer-size: 18432\n    # put default value here\n  - group: default\n    # set number of packet to queue inside kernel\n    qthreshold: 1\n    # set the delay before flushing packet in the queue inside kernel\n    qtimeout: 100\n    # netlink max buffer size\n    max-size: 20000\n\n##\n## Advanced Capture Options\n##\n\n# Netmap support\n#\n# Netmap operates with NIC directly in driver, so you need FreeBSD wich have\n# built-in netmap support or compile and install netmap module and appropriate\n# NIC driver on your Linux system.\n# To reach maximum throughput disable all receive-, segmentation-,\n# checksum- offloadings on NIC.\n# Disabling Tx checksum offloading is *required* for connecting OS endpoint\n# with NIC endpoint.\n# You can find more information at https://github.com/luigirizzo/netmap\n#\nnetmap:\n   # To specify OS endpoint add plus sign at the end (e.g. \"eth0+\")\n - interface: eth2\n   # Number of receive threads. \"auto\" uses number of RSS queues on interface.\n   #threads: auto\n   # You can use the following variables to activate netmap tap or IPS mode.\n   # If copy-mode is set to ips or tap, the traffic coming to the current\n   # interface will be copied to the copy-iface interface. If 'tap' is set, the\n   # copy is complete. If 'ips' is set, the packet matching a 'drop' action\n   # will not be copied.\n   # To specify the OS as the copy-iface (so the OS can route packets, or forward\n   # to a service running on the same machine) add a plus sign at the end\n   # (e.g. \"copy-iface: eth0+\"). Don't forget to set up a symmetrical eth0+ -> eth0\n   # for return packets. Hardware checksumming must be *off* on the interface if\n   # using an OS endpoint (e.g. 'ifconfig eth0 -rxcsum -txcsum -rxcsum6 -txcsum6' for FreeBSD\n   # or 'ethtool -K eth0 tx off rx off' for Linux).\n   #copy-mode: tap\n   #copy-iface: eth3\n   # Set to yes to disable promiscuous mode\n   # disable-promisc: no\n   # Choose checksum verification mode for the interface. At the moment\n   # of the capture, some packets may be with an invalid checksum due to\n   # offloading to the network card of the checksum computation.\n   # Possible values are:\n   #  - yes: checksum validation is forced\n   #  - no: checksum validation is disabled\n   #  - auto: suricata uses a statistical approach to detect when\n   #  checksum off-loading is used.\n   # Warning: 'checksum-validation' must be set to yes to have any validation\n   #checksum-checks: auto\n   # BPF filter to apply to this interface. The pcap filter syntax apply here.\n   #bpf-filter: port 80 or udp\n #- interface: eth3\n   #threads: auto\n   #copy-mode: tap\n   #copy-iface: eth2\n   # Put default values here\n - interface: default\n\n# PF_RING configuration. for use with native PF_RING support\n# for more info see http://www.ntop.org/products/pf_ring/\npfring:\n  - interface: eth0\n    # Number of receive threads (>1 will enable experimental flow pinned\n    # runmode)\n    threads: 1\n\n    # Default clusterid.  PF_RING will load balance packets based on flow.\n    # All threads/processes that will participate need to have the same\n    # clusterid.\n    cluster-id: 99\n\n    # Default PF_RING cluster type. PF_RING can load balance per flow.\n    # Possible values are cluster_flow or cluster_round_robin.\n    cluster-type: cluster_flow\n    # bpf filter for this interface\n    #bpf-filter: tcp\n    # Choose checksum verification mode for the interface. At the moment\n    # of the capture, some packets may be with an invalid checksum due to\n    # offloading to the network card of the checksum computation.\n    # Possible values are:\n    #  - rxonly: only compute checksum for packets received by network card.\n    #  - yes: checksum validation is forced\n    #  - no: checksum validation is disabled\n    #  - auto: suricata uses a statistical approach to detect when\n    #  checksum off-loading is used. (default)\n    # Warning: 'checksum-validation' must be set to yes to have any validation\n    #checksum-checks: auto\n  # Second interface\n  #- interface: eth1\n  #  threads: 3\n  #  cluster-id: 93\n  #  cluster-type: cluster_flow\n  # Put default values here\n  - interface: default\n    #threads: 2\n\n# For FreeBSD ipfw(8) divert(4) support.\n# Please make sure you have ipfw_load=\"YES\" and ipdivert_load=\"YES\"\n# in /etc/loader.conf or kldload'ing the appropriate kernel modules.\n# Additionally, you need to have an ipfw rule for the engine to see\n# the packets from ipfw.  For Example:\n#\n#   ipfw add 100 divert 8000 ip from any to any\n#\n# The 8000 above should be the same number you passed on the command\n# line, i.e. -d 8000\n#\nipfw:\n\n  # Reinject packets at the specified ipfw rule number.  This config\n  # option is the ipfw rule number AT WHICH rule processing continues\n  # in the ipfw processing system after the engine has finished\n  # inspecting the packet for acceptance.  If no rule number is specified,\n  # accepted packets are reinjected at the divert rule which they entered\n  # and IPFW rule processing continues.  No check is done to verify\n  # this will rule makes sense so care must be taken to avoid loops in ipfw.\n  #\n  ## The following example tells the engine to reinject packets\n  # back into the ipfw firewall AT rule number 5500:\n  #\n  # ipfw-reinjection-rule-number: 5500\n\n\nnapatech:\n    # The Host Buffer Allowance for all streams\n    # (-1 = OFF, 1 - 100 = percentage of the host buffer that can be held back)\n    hba: -1\n\n    # use_all_streams set to \"yes\" will query the Napatech service for all configured\n    # streams and listen on all of them. When set to \"no\" the streams config array\n    # will be used.\n    use-all-streams: yes\n\n    # The streams to listen on\n    streams: [1, 2, 3]\n\n# Tilera mpipe configuration. for use on Tilera TILE-Gx.\nmpipe:\n\n  # Load balancing modes: \"static\", \"dynamic\", \"sticky\", or \"round-robin\".\n  load-balance: dynamic\n\n  # Number of Packets in each ingress packet queue. Must be 128, 512, 2028 or 65536\n  iqueue-packets: 2048\n\n  # List of interfaces we will listen on.\n  inputs:\n  - interface: xgbe2\n  - interface: xgbe3\n  - interface: xgbe4\n\n\n  # Relative weight of memory for packets of each mPipe buffer size.\n  stack:\n    size128: 0\n    size256: 9\n    size512: 0\n    size1024: 0\n    size1664: 7\n    size4096: 0\n    size10386: 0\n    size16384: 0\n\n##\n## Hardware accelaration\n##\n\n# Cuda configuration.\ncuda:\n  # The \"mpm\" profile.  On not specifying any of these parameters, the engine's\n  # internal default values are used, which are same as the ones specified in\n  # in the default conf file.\n  mpm:\n    # The minimum length required to buffer data to the gpu.\n    # Anything below this is MPM'ed on the CPU.\n    # Can be specified in kb, mb, gb.  Just a number indicates it's in bytes.\n    # A value of 0 indicates there's no limit.\n    data-buffer-size-min-limit: 0\n    # The maximum length for data that we would buffer to the gpu.\n    # Anything over this is MPM'ed on the CPU.\n    # Can be specified in kb, mb, gb.  Just a number indicates it's in bytes.\n    data-buffer-size-max-limit: 1500\n    # The ring buffer size used by the CudaBuffer API to buffer data.\n    cudabuffer-buffer-size: 500mb\n    # The max chunk size that can be sent to the gpu in a single go.\n    gpu-transfer-size: 50mb\n    # The timeout limit for batching of packets in microseconds.\n    batching-timeout: 2000\n    # The device to use for the mpm.  Currently we don't support load balancing\n    # on multiple gpus.  In case you have multiple devices on your system, you\n    # can specify the device to use, using this conf.  By default we hold 0, to\n    # specify the first device cuda sees.  To find out device-id associated with\n    # the card(s) on the system run \"suricata --list-cuda-cards\".\n    device-id: 0\n    # No of Cuda streams used for asynchronous processing. All values > 0 are valid.\n    # For this option you need a device with Compute Capability > 1.0.\n    cuda-streams: 2\n\n##\n## Include other configs\n##\n\n# Includes.  Files included here will be handled as if they were\n# inlined in this configuration file.\n#include: include1.yaml\n#include: include2.yaml\n"}, {"commit_sha": "045ff4bb9f4720739632aac2951fbf2798a99c8c", "sha": "173d9696708c11628bfae6cb0eb4eb5ec1e3c061", "filename": "roles/cloud-ec2/defaults/main.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\nec2_vpc_nets:\n  cidr_block: 172.251.0.0/23\n  subnet_cidr: 172.251.1.0/24\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "90a86ee3ad1381f1a0fb4e41e0ddc675d08fe82c", "filename": "roles/dns_adblocking/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: Gather Facts\n  setup:\n\n- name: Dnsmasq installed\n  package: name=dnsmasq\n\n- name: Ensure that the dnsmasq user exist\n  user: name=dnsmasq groups=nogroup append=yes state=present\n\n- name: The dnsmasq directory created\n  file: dest=/var/lib/dnsmasq state=directory mode=0755 owner=dnsmasq group=nogroup\n\n- include: ubuntu.yml\n  when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'\n\n- include: freebsd.yml\n  when: ansible_distribution == 'FreeBSD'\n\n- meta: flush_handlers\n\n- name: Dnsmasq configured\n  template: src=dnsmasq.conf.j2 dest=\"{{ config_prefix|default('/') }}etc/dnsmasq.conf\"\n  notify:\n    - restart dnsmasq\n\n- name: Adblock script created\n  template: src=adblock.sh dest=/usr/local/sbin/adblock.sh owner=root group=\"{{ root_group|default('root') }}\" mode=0755\n\n- name: Adblock script added to cron\n  cron:\n    name: Adblock hosts update\n    minute: 10\n    hour: 2\n    job: /usr/local/sbin/adblock.sh\n    user: dnsmasq\n\n- name: Update adblock hosts\n  shell: >\n    sudo -u dnsmasq \"/usr/local/sbin/adblock.sh\"\n\n- name: Dnsmasq enabled and started\n  service: name=dnsmasq state=started enabled=yes\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "ba0e31b0a7f94c98e906413c9933ea7731d38c41", "filename": "roles/deploy/hooks/build-after.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Check for composer.json in project root or project_subtree_path\n  stat:\n    path: \"{{ deploy_helper.new_release_path }}/composer.json\"\n  register: composer_json\n\n- name: Fail if composer.json not found\n  fail:\n    msg: \"Unable to find a `composer.json` file in the root of '{{ deploy_helper.new_release_path }}'. Make sure your repo has a `composer.json` file in its root or edit `repo_subtree_path` for '{{ site }}' in `wordpress_sites.yml` so it points to the directory with a `composer.json` file.\"\n  when: not composer_json.stat.exists\n\n- name: Install Composer dependencies\n  command: composer install --no-ansi --no-dev --no-interaction --no-progress --optimize-autoloader --no-scripts\n  args:\n    chdir: \"{{ deploy_helper.new_release_path }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "abfb860454fb2afcfef60de885f95bfb42f141ea", "filename": "roles/osp/admin-keystone-domain/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Add EPEL temporary repository (but leave it disabled)\"\n  yum_repository:\n    name: tmp-epel\n    description: EPEL YUM repo\n    baseurl: http://download.fedoraproject.org/pub/epel/7/$basearch\n    metalink: https://mirrors.fedoraproject.org/metalink?repo=epel-7&arch=$basearch\n    gpgcheck: no\n    enabled: no\n\n- name: \"Install python-pip from EPEL\"\n  yum:\n    name: python-pip\n    enablerepo: tmp-epel\n    state: present\n\n- name: \"Install Python Shade using pip\"\n  pip:\n    name: shade\n\n- name: \"Clear out temporary EPEL repository\"\n  yum_repository:\n    name: tmp-epel\n    state: absent\n  notify: yum-clean-metadata\n\n- name: \"Create the LDAP domain(s)\"\n  os_keystone_domain:\n    cloud: \"{{ item.cloud | default(osp_default_cloud) }}\"\n    description: \"{{ item.domain }} Domain\"\n    name: \"{{ item.domain }}\"\n  with_items:\n  - \"{{ keystone_ldap }}\"\n\n- name: \"Restart keystone (httpd) to ensure config has been applied\"\n  service:\n    name: httpd\n    state: restarted\n\n- name: \"Wait a bit for keystone to catch up\"\n  pause:\n    seconds: 15\n"}, {"commit_sha": "a77a8900bb9032eb97498fbb9149d4504e73b0b5", "sha": "1d50a2c4f3e374c1f080a3ccf380dfd71a83813d", "filename": "tasks/cores.yml", "repository": "geerlingguy/ansible-role-solr", "decoded_content": "---\n- name: Check current list of Solr cores.\n  uri:\n    url: http://localhost:{{ solr_port }}/solr/admin/cores\n    return_content: yes\n  register: solr_cores_current\n\n- name: Ensure Solr conf directories exist.\n  file:\n    path: \"{{ solr_home }}/data/{{ item }}/conf\"\n    state: directory\n    owner: \"{{ solr_user }}\"\n    group: \"{{ solr_user }}\"\n    recurse: yes\n  when: \"'{{ item }}' not in '{{ solr_cores_current.content }}'\"\n  with_items: \"{{ solr_cores }}\"\n\n- name: Ensure core configuration directories exist.\n  shell: \"cp -r {{ solr_install_path }}/example/files/conf/ {{ solr_home }}/data/{{ item }}/\"\n  when: \"'{{ item }}' not in '{{ solr_cores_current.content }}'\"\n  with_items: \"{{ solr_cores }}\"\n\n- name: Create configured cores.\n  shell: \"{{ solr_install_path }}/bin/solr create -c {{ item }}\"\n  when: \"'{{ item }}' not in '{{ solr_cores_current.content }}'\"\n  with_items: \"{{ solr_cores }}\"\n  become: yes\n  become_user: \"{{ solr_user }}\"\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "ecf88dc58efa7d475e8b571ef997c367abbefd2f", "filename": "tasks/create_repo_maven_proxy_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_maven_proxy\n    args: \"{{ _nexus_repos_maven_defaults|combine(item) }}\""}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "b1dc1fb0545a93ef8e460415b78466c073cc8d8b", "filename": "roles/scm/gitlab.com/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n# defaults file for gitlab\ngitlab_api_base: https://gitlab.com/api/v4\ngitlab_api_projects: \"{{ gitlab_api_base }}/projects\"\ngitlab_api_groups: \"{{ gitlab_api_base }}/groups\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "ee6039a96d01ef2d2c0efe1662ce9d4d015eac57", "filename": "roles/idm-host-cert/tasks/create-host-cert.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Update newline characters in CSR content\"\n  set_fact:\n    cert_csr: \"{{ csr_content.csr|replace('\\n', '\\\\n') }}\"\n\n- name: \"Create Certificate for host\"\n  uri:\n    url: \"https://{{ idm_fqdn }}/ipa/session/json\"\n    method: POST\n    body: '{\"method\": \"cert_request\", \"params\":[[\"{{ cert_csr }}\"],{\"principal\": \"host/{{ host_name }}@{{ host_realm }}\", \"request_type\": \"pkcs10\", \"add\": False, \"version\": \"{{ api_version }}\" }],\"id\":0}'\n    body_format: json\n    validate_certs: no\n    return_content: yes\n    headers:\n      Cookie: \"{{ idm_session.set_cookie }}\"\n      referer: \"https://{{ idm_fqdn }}/ipa\"\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n  register: host_cert\n\n- name: \"Error out if the request returned an error\"\n  fail:\n    msg: \"ERROR: request failed with message: {{ host_cert.json.error.message }}\"\n  when:\n  - host_cert.json.error is defined\n  - host_cert.json.error.message is defined\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "36416fb2cd6cc1678057243cf2054cef344179ff", "filename": "roles/osp/admin-network/tasks/manage-subnets.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Set up subnet(s)\"\n  os_subnet:\n    cloud: \"{{ item.cloud | default(osp_default_cloud) | default(omit) }}\"\n    state: \"{{ item.state | default(osp_resource_state) | default('present') }}\"\n    network_name: \"{{ item.network_name }}\"\n    name: \"{{ item.name | default(omit) }}\"\n    cidr: \"{{ item.cidr }}\"\n    gateway_ip: \"{{ item.gateway_ip | default(omit) }}\"\n    dns_nameservers: \"{{ item.dns_nameservers }}\"\n    allocation_pool_start: \"{{ item.allocation_pool_start | default(omit) }}\"\n    allocation_pool_end: \"{{ item.allocation_pool_end | default(omit) }}\"\n    enable_dhcp: \"{{ item.enable_dhcp | default(omit) }}\"\n    project: \"{{ item.project | default(omit) }}\"\n  with_items:\n  - \"{{ osp_subnets | default([]) }}\"\n"}, {"commit_sha": "49010188a985bfe713552eb8980cfa0d7a888daf", "sha": "38de3273970abd91dc60210dd77f8eb6a112906c", "filename": "roles/openshift-route-status/README.md", "repository": "redhat-cop/casl-ansible", "decoded_content": "# openshift-route-status\n\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "05ede48d89898aba814889be8db478c65db84edc", "filename": "roles/7-edu-apps/README.rst", "repository": "iiab/iiab", "decoded_content": "===================================\nEducational Apps and Content README\n===================================\n\nThis role is a place to aggregate roles that provide Educational Content or\nare specifically targetted at pedagogical activities. \n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "4b30f33b11667123754312a48ab6aa42deb625ab", "filename": "roles/haproxy/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: prereq.yml\n- import_tasks: haproxy.yml\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "76074ae84786037c1029ac0a912e5a25bf261c88", "filename": "roles/elgg/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "elgg_xx: elgg\nelgg_version: \"2.3.4\"\n\n# elgg_mysql_password: defined in default_vars\nelgg_url: /elgg\nelgg_upload_path: /library/elgg\nelgg_install: True\nelgg_enabled: False\n\n# following variables used in elgg engine/settings.php template\ndbuser: Admin\ndbpassword: changeme\ndbname: elggdb\ndbhost: localhost\ndbprefix: elgg_\n\n# The following variables must be in sync with template/elggdb.sql.j2\n# If you change them, you will probably have to rebuild the database.\n# They can be changed from the administrative interface once elgg is installed.\n\nelgg_admin_user: Admin\nelgg_admin_password: changeme\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "9d7ea39bab65e2cd9b98bde0b4406c3b5bf546e3", "filename": "roles/network/tasks/dhcpd.yml", "repository": "iiab/iiab", "decoded_content": "- name: Install dhcp package\n  package: name=isc-dhcp-server\n           state=present\n  when: is_debuntu\n  tags:\n    - download\n\n- name: Install dhcp package\n  package: name=dhcp\n           state=present\n  when: not is_debuntu\n  tags:\n    - download\n\n- name: Create non-privileged user\n  user: name=dhcpd\n        createhome=no\n\n- name: Configure dhcpd\n  template: src={{ item.src }}\n            dest={{ item.dest }}\n            owner=root\n            group=root\n            mode={{ item.mode }}\n  with_items:\n   - { src: 'dhcp/dhcpd-iiab.conf.j2', dest: '/etc/dhcpd-iiab.conf', mode: '0644' }\n   - { src: 'dhcp/dhcpd.service', dest: '/etc/systemd/system/dhcpd.service', mode: '0644' }\n\n- name: Create dhcpd needed files\n  command: touch /var/lib/dhcpd/dhcpd.leases\n           creates=/var/lib/dhcpd/dhcpd.leases\n  when: is_redhat\n\n- name: Check leases permissions\n  file: path=/var/lib/dhcpd/dhcpd.leases\n        owner=dhcpd\n        group=dhcpd\n        mode=0644\n        state=file\n  when: is_redhat\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "117b1a2fafaa572f19560a47ebc40c762f9d9e26", "filename": "playbooks/templates/hosts-v3.10.j2", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "# Create an OSEv3 group that contains the masters and nodes groups\n[OSEv3:children]\nmasters\nnodes\netcd\n{% if lb is defined %}\nlb\n{% endif %}\nbastion\n{% if cns is defined %}\nglusterfs\n{% endif %}\n\n# Set variables common for all OSEv3 hosts\n[OSEv3:vars]\nansible_ssh_user={{ssh_user}}\nansible_become={% if ssh_user == \"root\" %}no{% else %}yes{% endif %}\n\n# https://github.com/openshift/openshift-ansible/blob/master/DEPLOYMENT_TYPES.md\ndeployment_type=openshift-enterprise\ncontainerized=false\n\n# Skip env validation\nopenshift_disable_check=disk_availability,memory_availability\n\n# Configure usage of openshift_clock role.\nopenshift_clock_enabled=true\n\n# Set upgrade restart mode for full system restarts\nopenshift_rolling_restart_mode=system\n\n# Enable cockpit\nosm_use_cockpit=false\nosm_cockpit_plugins=['cockpit-kubernetes', 'cockpit-pcp', 'setroubleshoot-server']\n\n# Docker / Registry Configuration\nopenshift_docker_disable_push_dockerhub=True\nopenshift_docker_options=\"--log-driver=journald --log-level=warn --ipv6=false\"\nopenshift_docker_insecure_registries=docker-registry.default.svc,docker-registry.default.svc.cluster.local\n\n# Native high availability cluster method with optional load balancer.\n\nopenshift_master_cluster_method=native\nopenshift_master_cluster_hostname={{api_dns}}\nopenshift_master_cluster_public_hostname={{api_dns}}\nopenshift_master_api_port=8443\nopenshift_master_console_port=8443\n\n\n# Configure nodeIP in the node config\n# This is needed in cases where node traffic is desired to go over an\n# interface other than the default network interface.\n\n# Configure the multi-tenant SDN plugin (default is 'redhat/openshift-ovs-subnet')\nos_sdn_network_plugin_name=redhat/openshift-ovs-multitenant\n\n# Configure SDN cluster network and kubernetes service CIDR blocks. These\n# network blocks should be private and should not conflict with network blocks\n# in your infrastructure that pods may require access to. Can not be changed\n# after deployment.\nosm_cluster_network_cidr=10.1.0.0/16\nopenshift_portal_net=172.30.0.0/16\nosm_host_subnet_length=8\n\n#Proxy\n{% if proxy_http is defined %}\nopenshift_http_proxy={% if proxy_username is defined %}{{proxy_username}}{% if proxy_password is defined %}:{{proxy_password}}{% endif %}@{% endif %}{{proxy_http}}\n{% endif %}\n{% if proxy_https is defined %}\nopenshift_https_proxy={% if proxy_username is defined %}{{proxy_username}}{% if proxy_password is defined %}:{{proxy_password}}{% endif %}@{% endif %}{{proxy_https}}\n{% endif %}\n{% if proxy_no is defined %}\nopenshift_no_proxy='{{proxy_no}}'\n{% endif %}\nopenshift_generate_no_proxy_hosts=true\n\n# htpasswd auth\nopenshift_master_identity_providers=[{'name': 'htpasswd_auth', 'login': 'true', 'challenge': 'true', 'kind': 'HTPasswdPasswordIdentityProvider'}]\n\n# Provide local certificate paths which will be deployed to masters\nopenshift_master_overwrite_named_certificates=true\n\n# Install the openshift examples\nopenshift_install_examples=true\nopenshift_examples_modify_imagestreams=true\n\n# default subdomain to use for exposed routes\nopenshift_master_default_subdomain={{ apps_dns | replace(\"*.\",\"\")  }}\n\n# Openshift Registry Options\nopenshift_hosted_registry_storage_kind=glusterfs\nopenshift_hosted_registry_replicas=1\n\n#OCS\nopenshift_storage_glusterfs_namespace=ocs\nopenshift_storage_glusterfs_name=ocs\nopenshift_storage_glusterfs_wipe=True\nopenshift_storage_glusterfs_storageclass=true\nopenshift_storage_glusterfs_storageclass_default=true\nopenshift_storage_glusterfs_image=registry.access.redhat.com/rhgs3/rhgs-server-rhel7\nopenshift_storage_glusterfs_heketi_image=registry.access.redhat.com/rhgs3/rhgs-volmanager-rhel7\nopenshift_storage_glusterfs_block_deploy=True\nopenshift_storage_glusterfs_block_host_vol_create=true\nopenshift_storage_glusterfs_block_host_vol_size=50\nopenshift_storage_glusterfs_block_storageclass=true\n\n# Metrics deployment\nopenshift_metrics_install_metrics=true\nopenshift_metrics_hawkular_hostname=metrics.{{ apps_dns | replace(\"*.\",\"\")}}\nopenshift_metrics_cassandra_replicas=1\nopenshift_metrics_cassandra_limits_memory=2Gi\nopenshift_metrics_hawkular_replicas=1\nopenshift_metrics_duration=5\nopenshift_metrics_cassandra_pvc_size=5Gi\nopenshift_metrics_cassandra_storage_type=dynamic\nopenshift_metrics_cassandra_pvc_storage_class_name=glusterfs-ocs-block\n\n# Logging deployment\nopenshift_logging_install_logging=true\nopenshift_logging_kibana_hostname=logging.{{ apps_dns | replace(\"*.\",\"\")  }}\nopenshift_logging_use_ops=false\nopenshift_logging_public_master_url=https://{{api_dns}}:8443\nopenshift_logging_curator_default_days=7\nopenshift_logging_es_pvc_size=10Gi\nopenshift_logging_es_pvc_dynamic=true\nopenshift_logging_es_pvc_storage_class_name=glusterfs-ocs-block\nopenshift_logging_es_memory_limit=8Gi\n\n# Prometheus\nopenshift_cluster_monitoring_operator_install=true\nopenshift_cluster_monitoring_operator_prometheus_storage_capacity=5Gi\nopenshift_cluster_monitoring_operator_node_selector={\"node-role.kubernetes.io/infra\":\"true\"}\n\n# Service brokers\n\n#openshift_service_catalog_image_version=latest\n#ansible_service_broker_local_registry_whitelist=['.*-apb$']\n#openshift_template_service_broker_namespaces=['openshift']\n\n# Grafana\nopenshift_grafana_storage_type=pvc\nopenshift_grafana_sc_name=glusterfs-ocs\nopenshift_grafana_storage_volume_size=1Gi\nopenshift_grafana_node_selector={\"node-role.kubernetes.io/infra\":\"true\"}\n\n\n[masters]\n{% for master in masters %}\n{{master}}\n{% endfor %}\n\n[etcd]\n{% for master in masters %}\n{{master}}\n{% endfor %}\n\n{% if lb is defined %}\n[lb]\n{{lb}}\n{% endif %}\n\n{% if cns is defined %}\n[glusterfs]\n{% for cns_node in cns %}\n{{cns_node}} glusterfs_ip={{ cns_hosts[loop.index0] }} glusterfs_devices='[\"/dev/{{ocs_disk}}\"]'\n{% endfor %}\n{% endif %}\n\n[nodes]\n{% for master in masters %}\n{{master}} openshift_node_group_name='{% if infranodes is defined %}node-config-master{% endif %}{% if infranodes is not defined %}node-config-master-infra{% endif %}'\n{% endfor %}\n\n{% if infranodes is defined %}\n{% for infra_node in infranodes %}\n{{infra_node}} openshift_node_group_name='node-config-infra'\n{% endfor %}\n{% endif %}\n\n{% for node in nodes %}\n{{node}} openshift_node_group_name='node-config-compute'\n{% endfor %}\n\n[bastion]\n{% if bastion is defined %}\n{{bastion}}\n{% endif %}\n"}, {"commit_sha": "f958689395b3fc98cacf0c605ed7b8b4b19718da", "sha": "334798d3008a06430942fafdbaa387ffe0f5ef49", "filename": "tasks/main.yml", "repository": "lae/ansible-role-netbox", "decoded_content": "---\n# tasks file for lae.netbox\n- include: check_mandatory_vars.yml\n\n- name: Gather OS specific variables\n  include_vars: \"{{ item }}\"\n  with_first_found:\n    - \"{{ ansible_distribution|lower }}-{{ ansible_distribution_version }}.yml\"\n    - \"{{ ansible_distribution|lower }}-{{ ansible_distribution_major_version }}.yml\"\n    - \"{{ ansible_distribution|lower }}.yml\"\n    - \"{{ ansible_os_family|lower }}.yml\"\n\n- include: \"install_packages_{{ ansible_pkg_mgr }}.yml\"\n\n- name: Install virtualenv via pip\n  pip:\n    name: virtualenv\n    state: latest\n    executable: \"{{ netbox_pip3_binary if (netbox_python == 3) else netbox_pip2_binary }}\"\n\n- name: Create NetBox user group\n  group:\n    name: \"{{ netbox_group }}\"\n\n- name: Create NetBox user and home directory\n  user:\n    name: \"{{ netbox_user }}\"\n    group: \"{{ netbox_group }}\"\n    home: \"{{ netbox_home }}\"\n\n- name: Ensure Postgres database exists (via socket)\n  postgresql_db:\n    name: \"{{ netbox_database }}\"\n    login_user: \"{{ netbox_database_user }}\"\n    login_unix_socket: \"{{ netbox_database_socket }}\"\n  become: True\n  become_user: \"{{ netbox_database_user }}\"\n  when:\n    - netbox_database_socket is defined\n    - netbox_database_host is not defined\n\n- name: Ensure Postgres database exists (via TCP)\n  postgresql_db:\n    name: \"{{ netbox_database }}\"\n    login_host: \"{{ netbox_database_host }}\"\n    port: \"{{ netbox_database_port }}\"\n    login_user: \"{{ netbox_database_user }}\"\n    login_password: \"{{ netbox_database_password }}\"\n  when:\n    - netbox_database_socket is not defined\n    - netbox_database_host is defined\n\n- include: deploy_netbox.yml\n  become: True\n  become_user: \"{{ netbox_user }}\"\n\n- name: Install uWSGI via pip\n  pip:\n    name: uwsgi\n    state: latest\n    executable: \"{{ netbox_pip3_binary if (netbox_python == 3) else netbox_pip2_binary }}\"\n  notify:\n    - reload netbox.service\n\n- name: Configure uWSGI NetBox application\n  template:\n    src: uwsgi.ini.j2\n    dest: \"{{ netbox_shared_path }}/uwsgi.ini\"\n    owner: \"{{ netbox_user }}\"\n    group: \"{{ netbox_group }}\"\n  notify:\n    - reload netbox.service\n\n- name: Install NetBox socket unit file\n  template:\n    src: netbox.socket.j2\n    dest: /lib/systemd/system/netbox.socket\n  notify:\n    - restart netbox.socket\n\n- name: Install NetBox service unit file\n  template:\n    src: netbox.service.j2\n    dest: /lib/systemd/system/netbox.service\n  notify:\n    - restart netbox.service\n\n- name: Start and enable NetBox' socket/service\n  systemd:\n    name: \"{{ item }}\"\n    state: started\n    enabled: yes\n  with_items:\n    - netbox.socket\n    - netbox.service\n"}, {"commit_sha": "a5a5c4d74b7b0fd14f534dda1f41f903d1a58abf", "sha": "ac9c6db35acbe3774904f5df5516715dc08f34e8", "filename": "tasks/npm.yml", "repository": "fubarhouse/ansible-role-nodejs", "decoded_content": "---\n# Tasks file for NPM\n\n- name: \"NPM | Make sure NPM can be found\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  shell: which npm | cat\n  changed_when: false\n  register: which_npm\n  failed_when: 'which_npm.stdout.find(\"npm\") == -1'\n\n- name: \"NPM | Configure\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  shell: \"{{ which_npm.stdout }} config set prefix /usr/local\"\n  when: '\"npm\" in \"{{ which_npm.stdout }}\"'\n  changed_when: false\n  failed_when: false\n\n- name: \"NPM | Ensure installed and updated\"\n  become: yes\n  become_user: root\n  npm:\n    name: \"{{ item }}\"\n    executable: \"{{ which_npm.stdout }}\"\n    global: yes\n  with_items:\n    - \"{{ node_packages }}\"\n  when: '\"npm\" in \"{{ which_npm.stdout }}\"'\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "af779d1e0835ca6e5e2e098bbb3dd8806b05e775", "filename": "roles/consul/tasks/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# tasks file for consul\n- name: remove consul override\n  file:\n    path: /etc/init/consul.override\n    state: absent\n\n- name: configure consul\n  sudo: yes\n  template:\n    src: consul.json.j2\n    dest: /etc/consul.d/consul.json\n    owner: root\n    group: root\n    mode: 0644\n  notify:\n    - restart consul\n  tags:\n    - consul\n\n- name: configure atlas for consul\n  sudo: yes\n  template:\n    src: atlas.json.j2\n    dest: /etc/consul.d/atlas.json\n    owner: root\n    group: root\n    mode: 0644\n  when: consul_atlas_join\n  notify:\n    - restart consul\n  tags:\n    - consul\n\n- name: enable consul\n  sudo: yes\n  service:\n    name: consul\n    enabled: yes\n    state: started\n  tags:\n    - consul\n\n# Give some time for leader election to occur\n- name: wait for leader\n  wait_for:\n    host: \"{{ consul_bind_addr }}\"\n    port: 8301\n    delay: 10\n  tags:\n    - consul\n\n- name: remove consul-join override\n  file:\n    path: /etc/init/consul-join.override\n    state: absent\n  when: consul_join is defined\n  tags:\n    - consul\n\n- name: configure consul-join\n  sudo: yes\n  template:\n    src: consul-join.j2\n    dest: /etc/service/consul-join\n    owner: root\n    group: root\n    mode: 0644\n  notify:\n    - restart consul\n  when: consul_join is defined\n  tags:\n    - consul\n\n# We need to force reload here because sometimes Consul gets in a weird\n# state where it cannot elect a cluster leader. Simply restarting the service\n# seems to allow it to recover automatically.\n- name: force reload consul\n  sudo: yes\n  command: /sbin/restart consul\n  tags:\n    - consul\n\n- name: force wait for leader\n  wait_for:\n    host: \"{{ consul_bind_addr }}\"\n    port: 8301\n    delay: 10\n  tags:\n    - consul\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "4b4d28fe16337eeb2087be1edcf7eea30ddf5ef7", "filename": "roles/ajenti/tasks/ajenti-wondershaper.yml", "repository": "iiab/iiab", "decoded_content": "- name: Install wondershaper ajenti plugin\n  pip: name=\"{{ iiab_download_url }}\"/ajenti-plugin-wondershaper-0.3.tar.gz\n  when: internet_available\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "940a41fb192bb1109e9cf5929295ba68c101c015", "filename": "roles/user-management/manage-users/tasks/create_group.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n  - name: Create IPA group\n    ipa_group:\n      ipa_host: \"{{ ipa_host | default(ansible_host)}}\"\n      ipa_user: \"{{ ipa_admin_user }}\"\n      ipa_pass: \"{{ ipa_admin_password }}\"\n      validate_certs: \"{{ ipa_validate_certs | default(True) }}\"\n      name: \"{{ item.name | trim }}\"\n    with_items: \"{{ user_groups }}\"\n"}, {"commit_sha": "a94f9ce4fa32273fd0fad7492d36db4101423cc3", "sha": "c5d463dcd3632f0b0f9fe7cea264276b11435e81", "filename": "tasks/bug-tweaks.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "- name: Configuration to avoid 'Device or resource busy'\n  block:\n  - name: Stat /proc/sys/fs/may_detach_mounts (CentOS/RedHat)\n    stat:\n      path: /proc/sys/fs/may_detach_mounts\n    register: may_detach_mounts\n\n  - name: Ensure fs.may_detach_mounts is set to avoid 'Device or resource busy' (CentOS/RedHat)\n    become: true\n    sysctl:\n      name: fs.may_detach_mounts\n      value: 1\n      sysctl_file: /etc/sysctl.d/99-docker.conf\n      reload: yes\n    when: may_detach_mounts.stat.exists\n\n  # Keep for compatibility reasons of this role. Now everything is in the same file.\n  - name: Remove systemd drop-in for Docker Mount Flags slave configuration (CentOS/RedHat)\n    become: true\n    file:\n      path: /etc/systemd/system/docker.service.d/mountflags-slave.conf\n      state: absent\n    notify: restart docker\n\n  - name: Set systemd service MountFlags option to \"slave\" to prevent \"device busy\" errors on CentOS/RedHat 7.3 kernels (CentOS/RedHat)\n    set_fact:\n      docker_systemd_service_config_tweaks: \"{{ docker_systemd_service_config_tweaks + _systemd_service_config_tweaks }}\"\n    vars:\n      _systemd_service_config_tweaks:\n        - 'MountFlags=slave'\n  when:\n    - _docker_os_dist == \"CentOS\" or _docker_os_dist == \"RedHat\"\n    - docker_enable_mount_flag_fix | bool\n    - ansible_kernel | version_compare('4', '<')\n\n- name: Best effort handling to directlvm for Debian 8 to get uniform behavior across distributions\n  block:\n  - name: Create LVM thinpool for Docker according to Docker documentation\n    include_tasks: lvm-thinpool.yml\n    vars:\n      pool:\n        name: thinpool\n        volume_group: docker\n        physical_volumes: \"{{ docker_daemon_config['storage-opts'] | select('match', '^dm.directlvm_device.+') | list | regex_replace('dm.directlvm_device=\\\\s*(.+)', '\\\\1') }}\"\n        metadata_size: \"1%VG\"\n        data_size: \"95%VG\"\n\n  - name: Modify storage-opts to handle problems with thinpool on Debian 8\n    set_fact:\n      _modified_storage_config: \"{{ (docker_daemon_config['storage-opts'] | difference(_exclusions)) + ['dm.thinpooldev=/dev/mapper/docker-thinpool-tpool'] }}\"\n    vars:\n      _exclusions: \"{{ docker_daemon_config['storage-opts'] | select('match', '^dm.directlvm_device.+') | list }}\"\n\n  - name: Update Docker daemon configuration to handle consistency between distributions\n    set_fact:\n      docker_daemon_config: \"{{ docker_daemon_config | combine(_updated_item, recursive=true) }}\"\n    vars:\n      _updated_item: \"{ 'storage-opts': {{ _modified_storage_config }} }\"\n\n  - name: Updated Docker daemon configuration\n    debug:\n      var: docker_daemon_config\n  when:\n    - _docker_os_dist == \"Debian\"\n    - _docker_os_dist_major_version == '8'\n    - docker_daemon_config['storage-opts'] is defined\n    - docker_daemon_config['storage-opts'] | select('match', '^dm.directlvm_device.+')\n"}, {"commit_sha": "51dcdf691a7801895b569a5a927e30030d8feb70", "sha": "9f61426bcd70b089e5359a0897bd8fec65b1930d", "filename": "handlers/main.yml", "repository": "nusenu/ansible-relayor", "decoded_content": "---\n#- name: restart tor\n#  service: name=tor state=restarted\n\n- name: stop-and-disable default tor\n  become: yes\n  service: name=tor state=stopped enabled=no\n\n- name: restart apparmor\n  become: yes\n  service: name=apparmor state=restarted\n\n- name: systemctl daemon-reload\n  become: yes\n  command: systemctl daemon-reload\n\n- name: re-gather facts\n  setup:\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "97d3228920d9814c67a2562b195ff0a12c81c95a", "filename": "roles/sshd/README.md", "repository": "roots/trellis", "decoded_content": "## What is ansible-sshd?\n\nIt is an [ansible](http://www.ansible.com/home) role to install openssh-server and configure it.\n\n### What problem does it solve and why is it useful?\n\nOften times you want to disable root logins and password based logins. This role sets those options by default but it also exposes every config value found in the default ubuntu 14.04 `sshd_config` file.\n\n## Role variables\n\nBelow is a list of default values along with a description of what they do.\n\n```\n# To view what these commands do, check out:\n# http://www.openssh.com/cgi-bin/man.cgi?query=sshd_config\n\nsshd_port: 22\nsshd_listen_address: 0.0.0.0\nsshd_protocol: 2\nsshd_host_rsa_key: /etc/ssh/ssh_host_rsa_key\nsshd_host_dsa_key: /etc/ssh/ssh_host_dsa_key\nsshd_host_ecdsa_key: /etc/ssh/ssh_host_ecdsa_key\nsshd_use_privilege_separation: true\nsshd_key_regeneration_interval: 3600\nsshd_server_key_bits: 768\nsshd_syslog_facility: AUTH\nsshd_log_level: INFO\nsshd_login_grace_time: 120\nsshd_permit_root_login: true\nsshd_strict_modes: true\nsshd_rsa_authentication: true\nsshd_pubkey_authentication: true\nsshd_authorized_keys_file: \"%h/.ssh/authorized_keys\"\nsshd_ignore_rhosts: true\nsshd_rhosts_rsa_authentication: false\nsshd_host_based_authentication: false\nsshd_ignore_user_known_hosts: false\nsshd_permit_empty_passwords: false\nsshd_challenge_response_authentication: false\nsshd_password_authentication: false\nsshd_gss_api_authentication: false\nsshd_gss_api_cleanup_credentials: true\nsshd_x11_forwarding: true\nsshd_x11_display_offset: 10\nsshd_print_motd: false\nsshd_print_last_log: true\nsshd_tcp_keep_alive: true\nsshd_max_startups: 10:30:100\nsshd_banner: none\nsshd_accept_env: LANG LC_*\nsshd_subsystem: sftp /usr/lib/openssh/sftp-server\nsshd_use_pam: true\n```\n\n## Attribution\n\nMany thanks to [nickjj](https://github.com/nickjj/) for creating the [original version](https://github.com/nickjj/ansible-sshd/) of this role.\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "c0af12e9c17457447ca2f5419898b1f1a972be7e", "filename": "roles/common/tasks/reload_nginx.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: reload nginx\n  command: nginx -t\n  register: nginx_test\n  notify: \"{{ (ansible_version.full | version_compare('2.1.1.0', '>=') and role_path | basename == 'common') | ternary('perform nginx reload', omit) }}\"\n\n- name: perform nginx reload\n  service:\n    name: nginx\n    state: reloaded\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "831dfc44c1ffda863e72f764edc9cedb8e683d4e", "filename": "roles/dns/manage-dns-zones-bind/tasks/process-zones.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Ensure the view directory exists\n  file:\n    path: \"{{ dns_zone_temp_config_dir }}/{{ view.name }}\"\n    state: directory\n\n- name: Set server config facts\n  set_fact:\n    view_recursion: \"{{ view.named.recursion | default(common_recursion) }}\"\n\n- name: Prepare the view pre-zones content\n  vars:\n    view_name: \"{{ view.name }}\"\n    view_recursion: \"{{ view_recursion }}\"\n  template:\n    src: view-config-1.j2\n    dest: \"{{ dns_zone_temp_config_dir }}/{{ view.name }}/0001-{{ view.name }}.cfg\"\n    owner: \"{{ bind_user }}\"\n    group: \"{{ bind_group }}\"\n    mode: 0660\n  when:\n    - view.state|default('present') == 'present'\n\n- name: Initialize flags\n  set_fact:\n    processed_zones: False\n\n- include_tasks: process-one-zone.yml\n  with_items:\n    - \"{{ view.zones }}\"\n  loop_control:\n    loop_var: \"zone\"\n\n- block:\n  - name: Prepare the view post-zones content\n    vars:\n      view_forwarders: \"{{ view.default_forwarders | default(['127.0.0.1']) }}\"\n    template:\n      src: view-config-2.j2\n      dest: \"{{ dns_zone_temp_config_dir }}/{{ view.name }}/0003-{{ view.name }}.cfg\"\n      owner: \"{{ bind_user }}\"\n      group: \"{{ bind_group }}\"\n      mode: 0660\n\n  - name: Assemble the complete view file\n    assemble:\n      src: \"{{ dns_zone_temp_config_dir }}/{{ view.name }}\"\n      dest: \"{{ dns_zone_temp_config_dir }}/view/{{ view.name }}.cfg\"\n  when:\n    - processed_zones|bool == True\n    - view.state|default('present') == 'present'\n\n- name: Remove temporary view if no zones were processed\n  file:\n    path: \"{{ dns_zone_temp_config_dir }}/{{ view.name }}\"\n    state: absent\n  when:\n    - processed_zones|bool == False\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "10f2b6ccf77c257ea15c11c5303c45ae69e5c01d", "filename": "playbooks/osp/provision-osp-instance.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Provision Instance(s)\n  hosts: localhost\n  roles:\n  - role: osp/admin-volume\n  - role: osp/admin-sec-group\n  - role: osp/admin-instance\n\n- name: Refresh Server inventory\n  hosts: localhost\n  gather_facts: False\n  tasks:\n  - meta: refresh_inventory\n\n- name: Print Instance info + Wait for Instances to come alive\n  hosts: osp_instances\n  gather_facts: false\n  tasks:\n  - name: Debug hostvar\n    debug:\n      msg: \"{{ hostvars[inventory_hostname] }}\"\n      verbosity: 2\n  - name: waiting for server to come back\n    local_action:\n      module: wait_for\n      host: \"{{ hostvars[inventory_hostname]['ansible_ssh_host'] }}\"\n      port: 22\n      delay: 10\n      timeout: 300\n\n- name: \"Ensure the host is ready for Ansible\"\n  hosts: osp_instances\n  gather_facts: no\n  roles:\n  - role: ansible/prep-for-ansible\n\n- name: \"Workaround for .novalocal\"\n  hosts: osp_instances\n  tasks:\n  - name: \"Eliminate the .novalocal at the end of the FQDN\"\n    hostname:\n      name: \"{{ ansible_fqdn | regex_replace('(.*).novalocal$', '\\\\1') }}\"\n  - name: \"Ensure the local host can resolve by its own IP\"\n    lineinfile:\n      path: /etc/hosts\n      regexp: \"^{{ ansible_default_ipv4.address }}.*\"\n      line: \"{{ ansible_default_ipv4.address }} {{ ansible_fqdn | regex_replace('(.*).novalocal$', '\\\\1') }}\"\n  - name: \"Ensure the changes stick during reboot\"\n    stat: path=/etc/cloud/cloud.cfg\n    register: cloud_cfg\n  - lineinfile:\n      dest: /etc/cloud/cloud.cfg\n      state: present\n      regexp: \"{{ item.regexp }}\"\n      line: \"{{ item.line }}\"\n    with_items:\n    - { regexp: '^ - set_hostname', line: '# - set_hostname' }\n    - { regexp: '^ - update_hostname', line: '# - update_hostname' }\n    when: cloud_cfg.stat.exists == True\n\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "445fa7d58dcc39b242b17065c04322ef2b3753ab", "filename": "archive/roles/openshift-common/defaults/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\ndefault_openshift_storage_disk_volume: \"/dev/vdb\"\ndefault_openshift_master_count: 1\ndefault_openshift_node_count: 2\ndefault_openshift_app_domain: \"apps\"\ndefault_openshift_openstack_flavor_name: \"m1.medium\"\ndefault_openshift_openstack_image_name: \"_OS1_rhel-guest-image-7.2-20151102.0.x86_64.qcow2\"\ndefault_openshift_openstack_master_storage_size: 10\ndefault_openshift_openstack_node_storage_size: 10\ndefault_openshift_openstack_master_security_groups:\n  - name: default\n    rules: []\n  - name: ose3_master\n    rules:\n    - name: tcp-22\n      from_port: 22\n      to_port: 22\n      protocol: tcp\n      cidr: 0.0.0.0/0\n    - name: tcp-80\n      from_port: 80\n      to_port: 80\n      protocol: tcp\n      cidr: 0.0.0.0/0\n    - name: tcp-443\n      from_port: 443\n      to_port: 443\n      protocol: tcp\n      cidr: 0.0.0.0/0\n    - name: tcp-8443\n      from_port: 8443\n      to_port: 8443\n      protocol: tcp\n      cidr: 0.0.0.0/0\n    - name: udp-4789\n      from_port: 4789\n      to_port: 4789\n      protocol: udp\n      cidr: 0.0.0.0/0\n    - name: tcp-53\n      from_port: 53\n      to_port: 53\n      protocol: tcp\n      cidr: 0.0.0.0/0\n    - name: udp-53\n      from_port: 53\n      to_port: 53\n      protocol: udp\n      cidr: 0.0.0.0/0\n    - name: tcp-8053\n      from_port: 8053\n      to_port: 8053\n      protocol: tcp\n      cidr: 0.0.0.0/0\n    - name: udp-8053\n      from_port: 8053\n      to_port: 8053\n      protocol: udp\n      cidr: 0.0.0.0/0\n    - name: tcp-2379\n      from_port: 2379\n      to_port: 2379\n      protocol: tcp\n      cidr: 0.0.0.0/0\n    - name: tcp-2380\n      from_port: 2380\n      to_port: 2380\n      protocol: tcp\n      cidr: 0.0.0.0/0\n    - name: tcp-4001\n      from_port: 4001\n      to_port: 4001\n      protocol: tcp\n      cidr: 0.0.0.0/0\ndefault_openshift_openstack_node_security_groups:\n  - name: default\n    rules: []\n  - name: ose3_nodes\n    rules:\n    - name: tcp-22\n      from_port: 22\n      to_port: 22\n      protocol: tcp\n      cidr: 0.0.0.0/0\n    - name: tcp-80\n      from_port: 80\n      to_port: 80\n      protocol: tcp\n      cidr: 0.0.0.0/0\n    - name: tcp-443\n      from_port: 443\n      to_port: 443\n      protocol: tcp\n      cidr: 0.0.0.0/0\n    - name: udp-4789\n      from_port: 4789\n      to_port: 4789\n      protocol: udp\n      cidr: 0.0.0.0/0\n    - name: tcp-10250\n      from_port: 10250\n      to_port: 10250\n      protocol: tcp\n      cidr: 0.0.0.0/0\ndefault_openshift_openstack_dns_security_groups:\n  - name: default\n    rules: []\n  - name: dns\n    rules:\n    - name: ssh\n      from_port: 22\n      to_port: 22\n      protocol: tcp\n      cidr: 0.0.0.0/0\n    - name: dns-tcp-53\n      from_port: 53\n      to_port: 53\n      protocol: tcp\n      cidr: 0.0.0.0/0\n    - name: dns-udp-53\n      from_port: 53\n      to_port: 53\n      protocol: udp\n      cidr: 0.0.0.0/0\ndefault_openshift_openstack_nfs_security_groups:\n  - name: default\n    rules: []\n  - name: nfs\n    rules:\n    - name: ssh\n      from_port: 22\n      to_port: 22\n      protocol: tcp\n      cidr: 0.0.0.0/0\n    - name: nfs-tcp-111\n      from_port: 111\n      to_port: 111\n      protocol: tcp\n      cidr: 0.0.0.0/0\n    - name: nfs-udp-111\n      from_port: 111\n      to_port: 111\n      protocol: udp\n      cidr: 0.0.0.0/0\n    - name: nfs-tcp-2049\n      from_port: 2049\n      to_port: 2049\n      protocol: tcp\n      cidr: 0.0.0.0/0\n    - name: nfs-udp-2049\n      from_port: 2049\n      to_port: 2049\n      protocol: udp\n      cidr: 0.0.0.0/0\n"}, {"commit_sha": "e91a55152358e890a05cf849abc7d58b8badecc2", "sha": "1d6585d8100d418a798ed1100192b38d7eb94998", "filename": "tasks/setup.yml", "repository": "fubarhouse/ansible-role-golang", "decoded_content": "---\n\n- name: \"Go-Lang | Define user variable for ssh use\"\n  set_fact:\n    fubarhouse_user: \"{{ ansible_ssh_user }}\"\n  when: ansible_ssh_user is defined and fubarhouse_user is not defined\n\n- name: \"Go-Lang | Define user variable for non-ssh use\"\n  set_fact:\n    fubarhouse_user: \"{{ ansible_user_id }}\"\n  when: ansible_ssh_user is not defined and fubarhouse_user is not defined\n\n- name: \"Go-Lang | Get $HOME\"\n  shell: \"echo $HOME\"\n  register: shell_home_dir\n  changed_when: false\n  when: fubarhouse_user_dir is not defined\n\n- name: \"Go-Lang | Set $HOME\"\n  set_fact:\n    fubarhouse_user_dir: \"{{ shell_home_dir.stdout }}\"\n  when: fubarhouse_user_dir is not defined\n\n- name: \"Go-Lang | Include OS-Specific tasks (CentOS)\"\n  include: tasks-CentOS.yml\n  when: ansible_distribution == \"CentOS\"\n\n- name: \"Go-Lang | Include OS-Specific tasks (Darwin)\"\n  include: tasks-Darwin.yml\n  when: ansible_os_family == 'Darwin'\n\n- name: \"Go-Lang | Include OS-Specific tasks (Debian)\"\n  include: tasks-Debian.yml\n  when: ansible_os_family == \"Debian\"\n\n- name: \"Go-Lang | Include OS-Specific tasks (FreeBSD)\"\n  include: tasks-Debian.yml\n  when: ansible_distribution == 'FreeBSD'\n\n- name: \"Go-Lang | Include OS-Specific tasks (RedHat)\"\n  include: tasks-RedHat.yml\n  when:\n    - ansible_os_family == \"RedHat\"\n    - ansible_distribution != \"CentOS\"\n\n- name: \"Go-Lang | Define GOROOT\"\n  set_fact:\n    GOROOT: /usr/local/go\n  when: GOROOT is not defined\n\n- name: \"Go-Lang | Define GOPATH\"\n  set_fact:\n    GOPATH: \"{{ fubarhouse_user_dir }}/go\"\n  when:\n    - GOROOT is defined\n    - GOPATH is not defined\n\n- name: \"Go-Lang | Define GOROOT_BOOTSTRAP\"\n  set_fact:\n    GOROOT_BOOTSTRAP: /usr/local/go1.4\"\n  when:\n   - fubarhouse_user_dir is defined\n   - GOROOT_BOOTSTRAP is not defined\n   - build_go_from_source|bool == true\n\n- name: \"Go-Lang | Define version comparrison string\"\n  set_fact:\n    go_version_string: \"go{{ go_version }}\"\n  changed_when: false\n\n- name: \"Go-Lang | Looking for compiled binary in GOROOT_BOOTSTRAP installation\"\n  stat:\n    path: \"{{ GOROOT_BOOTSTRAP }}/bin/go\"\n  register: go_binary_bootstrap\n  failed_when: false\n  when:\n   - GOROOT_BOOTSTRAP is defined\n   - build_go_from_source|bool == true\n\n- name: \"Go-Lang | Define URL for distribution\"\n  set_fact:\n    go_distribution_filename: \"go{{ go_version }}.{{ GOOS }}-{{ GOARCH }}\"\n  when: build_go_from_source|bool == false\n\n- name: \"Go-Lang | Define URL for source\"\n  set_fact:\n    go_distribution_filename: \"go{{ go_version }}.src\"\n  when: build_go_from_source|bool == true\n\n- name: \"Go-Lang | Looking for existing installation\"\n  stat:\n    path: \"{{ GOROOT }}/bin/go\"\n  register: go_binary\n  failed_when: false\n\n- name: \"Go-Lang | Getting version information\"\n  shell: \"{{ GOROOT }}/bin/go version | cat\"\n  environment:\n    GOPATH: \"{{ GOPATH }}\"\n    GOROOT: \"{{ GOROOT }}\"\n  register: current_go_version\n  changed_when: false\n\n- name: \"Go-Lang | Define expected version output\"\n  set_fact:\n    expected_go_version_output: \"go version {{ go_version_string }} {{ GOOS }}/{{ GOARCH }}\"\n  when: expected_go_version_output is not defined"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "c98d8c8deab38b822bbf189616e6cc03e0ba8853", "filename": "playbooks/provision-bastion/bastion.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- import_playbook: ../osp/manage-user-network.yml\n  when:\n  - hosting_infrastructure == 'openstack'\n\n- import_playbook: ../osp/provision-osp-instance.yml\n  when:\n  - hosting_infrastructure == 'openstack'\n\n\n- import_playbook: install.yml\n"}, {"commit_sha": "9662c15ce2e4260fac5cc2bfdf5aaaaf0a2191dd", "sha": "17df5f59b5d000afc9346a267aa8d8e8450deb22", "filename": "tasks/section_12_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 12.1 Verify Permissions on /etc/passwd (Scored)\n    file: path=/etc/passwd mode=0644\n    tags:\n      - section12\n      - section12.1\n\n  - name: 12.2 Verify Permissions on /etc/shadow (Scored)\n    file: path=/etc/shadow mode='o-rwx,g-rw'\n    tags:\n      - section12\n      - section12.2\n\n  - name: 12.3 Verify Permissions on /etc/group (Scored)\n    file: path=/etc/group mode=0644\n    tags:\n      - section12\n      - section12.3\n\n  - name: 12.4 Verify User/Group Ownership on /etc/passwd (Scored)\n    file: path=/etc/passwd owner=root group=root\n    tags:\n      - section12\n      - section12.4\n\n  - name: 12.5 Verify User/Group Ownership on /etc/shadow (Scored)\n    file: path=/etc/shadow owner=root group=shadow\n    tags:\n      - section12\n      - section12.5\n\n  - name: 12.6 Verify User/Group Ownership on /etc/group (Scored)\n    file: path=/etc/group owner=root group=root\n    tags:\n      - section12\n      - section12.6\n\n  - name: 12.7 Find World Writable Files (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -0002 -print\n    changed_when: False\n    failed_when: False\n    register: world_files\n    tags:\n      - section12\n      - section12.7\n\n  - name: 12.7 Find World Writable Files (Not Scored)\n    debug: msg={{ item }}\n    with_items:\n        world_files.stdout_lines\n    tags:\n      - section12\n      - section12.7\n\n  - name: 12.8 Find Un-owned Files and Directories (check) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -nogroup -ls\n    changed_when: False\n    failed_when: False\n    register: unowned_files\n    tags:\n      - section12\n      - section12.8\n\n  - name: 12.8 Find Un-owned Files and Directories (Scored)\n    debug: msg={{ item }}\n    with_items:\n        unowned_files.stdout_lines\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.9 Find Un-grouped Files and Directories (check) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -nogroup -ls\n    changed_when: False\n    failed_when: False\n    register: ungrouped_files\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.9 Find Un-grouped Files and Directories (Scored)\n    debug: msg={{ item }}\n    with_items:\n        ungrouped_files.stdout_lines\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.10 Find SUID System Executables (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -4000 -print\n    changed_when: False\n    failed_when: False\n    register: suid_files\n    tags:\n      - section12\n      - section12.10\n\n  - name: 12.10 Find SUID System Executables (Not Scored)\n    debug: msg={{ item }}\n    with_items:\n        suid_files.stdout_lines\n    tags:\n      - section12\n      - section12.10\n\n  - name: 12.11 Find SGID System Executables (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -2000 -print\n    changed_when: False\n    failed_when: False\n    register: gsuid_files\n    tags:\n      - section12\n      - section12.11\n\n  - name: 12.11 Find SGID System Executables (Not Scored)\n    debug: msg={{ item }}\n    with_items:\n        gsuid_files.stdout_lines\n    tags:\n      - section12\n      - section12.10\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "7d673dfe585f8b758c0b83ee0cd4ca7c48c4cf61", "filename": "tasks/Linux/install/RedHat.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Install java packages\n  yum:\n    name: '{{ (transport == \"repositories\") | ternary(jdk_package, java_artifact) }}'\n    state: present\n  register: package_install\n  until: package_install is succeeded\n"}, {"commit_sha": "1224adf2811c827a09ff0bf133fbb476901a547d", "sha": "40c2a0aab1694994d5a45958f0086449cf1d43e4", "filename": "tasks/linux_service.yml", "repository": "nusenu/ansible-relayor", "decoded_content": "---\n\n# Linux/systemd section (uses service module)\n# ===========================================\n\n- name: Ensure Tor instances are enabled and started (Linux/systemd)\n  become: yes\n  service:\n    name: \"tor@{{ item.0.ipv4 }}_{{ item.1.orport }}.service\"\n    enabled: yes\n    state: started\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n"}, {"commit_sha": "ccab58ae5d697bb64abd86558f79c34161d2fb00", "sha": "ccf36c43c90cf228f18543c10d1fab4021bd69a8", "filename": "handlers/main.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- name: systemd-reload\n  systemd:\n    daemon-reload: yes\n    name: nexus.service\n\n- name: nexus systemd service restart\n  systemd:\n    name: nexus.service\n    state: restarted\n    no_block: yes\n  listen: nexus-service-restart\n  when: \"ansible_service_mgr == 'systemd'\"\n\n- name: nexus sysv service restart\n  service:\n    name: nexus\n    state: restarted\n  listen: nexus-service-restart\n  when: \"ansible_service_mgr != 'systemd'\"\n\n- name: nexus systemd service stop\n  systemd:\n    name: nexus.service\n    state: stopped\n  listen: nexus-service-stop\n  when: nexus_systemd_service_file.stat.exists\n\n- name: nexus sysv service stop\n  service:\n    name: nexus\n    state: stopped\n  listen: nexus-service-stop\n  when: nexus_sysv_service_file.stat.exists\n\n- name: wait-for-nexus\n  wait_for:\n    path: \"{{ nexus_data_dir }}/log/nexus.log\"\n    search_regex: \"Started Sonatype Nexus .*\"\n    timeout: 1800\n\n- name: wait-for-nexus-port\n  wait_for:\n    port: \"{{ nexus_default_port }}\"\n    timeout: \"{{ nexus_wait_for_port_timeout | default(omit) }}\"\n  retries: \"{{ nexus_wait_for_port_retries | default(omit) }}\"\n  register: wait_for_result\n  until: wait_for_result is success\n\n- name: httpd-service-reload\n  systemd:\n    name: \"{{ httpd_package_name }}.service\"\n    state: reloaded\n    enabled: yes\n    no_block: yes\n\n- name: wait-for-httpd\n  wait_for:\n    port: 443\n    delay: 5\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "9d3bce93a4c680a8a00fff3aab83818bd215c696", "filename": "roles/config-quay-enterprise/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Restart quay service\n  systemd:\n    name: \"{{ quay_service }}\"\n    enabled: yes\n    state: restarted\n    daemon_reload: yes\n\n- name: restart firewalld\n  service:\n    name: firewalld\n    state: restarted\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "4e6701bbd54a78990ffe99072988b4c627dedf5a", "filename": "roles/dns/manage-dns-zones-bind/tasks/prereq.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Fail when required items are not defined\n  fail:\n    msg: \"view name and zones must be defined for each dictionary record\"\n  when:\n    - (item.name is not defined) or\n      (item.zones is not defined)\n  with_items:\n    - \"{{ dns_data.views | default({}) }}\"\n\n- name: Use a unique temporary directory to store the config files pre-assemble\n  tempfile:\n    state: directory\n    prefix: dns-zone\n  register: dns_zone_tempdir\n  notify:\n    - 'cleanup temp'\n\n- name: Store away the temporary configuration files directory name\n  set_fact:\n    dns_zone_temp_config_dir: \"{{ dns_zone_tempdir.path }}\"\n"}, {"commit_sha": "f958689395b3fc98cacf0c605ed7b8b4b19718da", "sha": "98d6cb68c1e3dbf2de2899cda3d3245a66daa473", "filename": "tasks/install_packages_yum.yml", "repository": "lae/ansible-role-netbox", "decoded_content": "---\n- name: Install EPEL repository\n  yum:\n    name: epel-release\n    state: installed\n  when:\n    - netbox_python == 3\n\n- name: Install required packages for selected NetBox configuration\n  yum:\n    name: \"{{ item }}\"\n    state: latest\n    update_cache: yes\n  with_items:\n    - \"{{ netbox_python3_packages if (netbox_python == 3) else netbox_python2_packages }}\"\n    - \"{{ netbox_packages }}\"\n    - \"{{ netbox_ldap_packages if netbox_ldap_enabled else [] }}\"\n    - \"{{ 'git' if netbox_git else [] }}\"\n    - python-psycopg2\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "7223aa7c4f94518a058e5a9a2aa290d1d94c378e", "filename": "roles/dns/manage-dns-zones-route53/tasks/process-zones.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- include_tasks: process-one-zone.yml\n  with_items:\n  - \"{{ view.zones }}\"\n  loop_control:\n    loop_var: \"zone\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "a1676aa0cf5eebb061a24ce79b14028a4c905e7e", "filename": "roles/activity-server/files/lang_templates/fr/page", "repository": "iiab/iiab", "decoded_content": "<!DOCTYPE html>\n<META http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n<body>\n<h1 id=\"olpc-activity-group-name\">Activit\u00e9s disponibles localement</h1>\n<p id=\"olpc-activity-group-desc\">Ces activit\u00e9s sont stock\u00e9es sur le serveur de l\u2019\u00e9cole.</p>\n%(activities)s\n</body>\n</html>\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "209746310e7c6b42eae17e87dcc86f4788cc5189", "filename": "roles/config-nagios-target/tasks/install-epel.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Installing EPEL Software Repo\n  package:\n    name=\"{{item}}\"\n    state=present\n  with_items:\n  - http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm\n  tags: epel\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a8aaef9500ad78c65d8cf61e7e9f6007c2f9bd24", "filename": "roles/config-ipa-client/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Install, configure and enable IPA/IdM integration\"\n  import_tasks: ipa.yml\n  when: \n  - ipa_client_install|default(False)\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "127ca483073186cfb4ec6ce968cc4c9d7293968b", "filename": "roles/dns/manage-dns-zones-route53/tasks/process-views.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- include_tasks: process-zones.yml\n  with_items:\n    - \"{{ dns_data.views }}\"\n  loop_control:\n    loop_var: \"view\"\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "578fb793f136c1f47e7dcbae3ecb3b6e8b9b857e", "filename": "roles/ssh_tunneling/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- set_fact:\n    IP_subject_alt_name: \"{{ IP_subject_alt_name }}\"\n\n- name: Ensure that the sshd_config file has desired options\n  blockinfile:\n    dest: /etc/ssh/sshd_config\n    marker: '# {mark} ANSIBLE MANAGED BLOCK ssh_tunneling_role'\n    block: |\n      Match Group algo\n          AllowTcpForwarding local\n          AllowAgentForwarding no\n          AllowStreamLocalForwarding no\n          PermitTunnel no\n          X11Forwarding no\n  notify:\n    - restart ssh\n\n- name: Ensure that the algo group exist\n  group: name=algo state=present\n\n- name: Ensure that the jail directory exist\n  file: path=/var/jail/ state=directory mode=0755 owner=root group=\"{{ root_group|default('root') }}\"\n\n- name: Ensure that the SSH users exist\n  user:\n    name: \"{{ item }}\"\n    groups: algo\n    home: '/var/jail/{{ item }}'\n    createhome: yes\n    generate_ssh_key: yes\n    shell: /bin/false\n    ssh_key_type: ecdsa\n    ssh_key_bits: 256\n    ssh_key_comment: '{{ item }}@{{ IP_subject_alt_name }}'\n    ssh_key_passphrase: \"{{ easyrsa_p12_export_password }}\"\n    state: present\n    append: yes\n  with_items: \"{{ users }}\"\n\n- name: The authorized keys file created\n  file:\n    src: '/var/jail/{{ item }}/.ssh/id_ecdsa.pub'\n    dest: '/var/jail/{{ item }}/.ssh/authorized_keys'\n    owner: \"{{ item }}\"\n    group: \"{{ item }}\"\n    state: link\n  with_items: \"{{ users }}\"\n\n- name: Generate SSH fingerprints\n  shell: >\n    ssh-keyscan {{ IP_subject_alt_name }} 2>/dev/null\n  register: ssh_fingerprints\n\n- name: Fetch users SSH private keys\n  fetch: src='/var/jail/{{ item }}/.ssh/id_ecdsa' dest=configs/{{ IP_subject_alt_name }}/{{ item }}.ssh.pem flat=yes\n  with_items: \"{{ users }}\"\n\n- name: Change mode for SSH private keys\n  local_action: file path=configs/{{ IP_subject_alt_name }}/{{ item }}.ssh.pem mode=0600\n  with_items: \"{{ users }}\"\n  become: false\n\n- name: Fetch the known_hosts file\n  local_action:\n    module: template\n    src: known_hosts.j2\n    dest: configs/{{ IP_subject_alt_name }}/known_hosts\n  become: no\n\n- name: Build the client ssh config\n  local_action:\n    module: template\n    src: ssh_config.j2\n    dest: configs/{{ IP_subject_alt_name }}/{{ item }}.ssh_config\n    mode: 0600\n  become: no\n  with_items:\n    - \"{{ users }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "6086cd98763240b4760616a80323272d687e6582", "filename": "roles/activity-server/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "activity_server_enabled: False\nactivity_server_install: True\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a978d0a66004287f574390169097e4149f944d35", "filename": "roles/virt-install/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ndefault_http_dir: \"/var/www/html\"\ndefault_http_host: \"192.168.122.1\"\n\ndefault_connect: \"qemu:///system\"\ndefault_virt_type: \"kvm\"\ndefault_name: \"tmpvm-{{ ansible_date_time.epoch }}\"\ndefault_title: \"tmpvm-title\"\ndefault_description: \"tmpvm-description\"\ndefault_memory: \"1024\"\ndefault_vcpus: \"2\"\ndefault_disk_size: \"10\"\ndefault_disk_pool: \"default\"\ndefault_os_variant: \"rhel7.3\"\ndefault_iso: \"/tmp/rhel-server-7.3-x86_64-dvd.iso\"\ndefault_ksfile: \"/tmp/my.ks\"\ndefault_authorized_keys: \"/tmp/authorized_keys\"\ndefault_network_hostif: \"eth0\"\ndefault_network_model: \"virtio\"\ndefault_network_type: \"direct\"\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "437472c40ce4a0ef370f21bff7f569f53adf4a14", "filename": "roles/wp-cli/defaults/main.yml", "repository": "roots/trellis", "decoded_content": "wp_cli_version: 0.24.0\nwp_cli_bin_path: /usr/bin/wp\nwp_cli_phar_url: \"https://github.com/wp-cli/wp-cli/releases/download/v{{ wp_cli_version }}/wp-cli-{{ wp_cli_version }}.phar\"\nwp_cli_completion_url: \"https://raw.githubusercontent.com/wp-cli/wp-cli/v{{ wp_cli_version }}/utils/wp-completion.bash\"\nwp_cli_completion_path: /etc/bash_completion.d/wp-completion.bash\n"}, {"commit_sha": "beb41b82405655aa385bb8297bf49ada1a4eb14c", "sha": "1c899585b0a887d149a183218fb2befdb99845f1", "filename": "tasks/Linux/system.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Perform install from artifacts\n  block:\n    - name: Install requirements\n      package:\n        name: '{{ java_package_requirements }}'\n        state: present\n      register: installed_packages\n      until: installed_packages is succeeded\n      when: transport != 'repositories'\n\n    - name: 'Perform {{ java_binary_type }} install'\n      include_tasks: '{{ install_task }}'\n      with_first_found:\n        - 'install/{{ java_distribution }}_{{ java_binary_type }}.yml'\n        - 'install/{{ java_binary_type }}.yml'\n        - 'install/{{ ansible_os_family }}.yml'\n      loop_control:\n        loop_var: install_task\n\n    - name: Find java_folder\n      find:\n        paths: '{{ java_path }}'\n        recurse: false\n        file_type: directory\n        patterns: '{{ java_folder }}'\n        use_regex: true\n      register: java_dir\n\n    - name: Set actual java directory\n      set_fact:\n        java_folder: \"{{ java_dir.files | map(attribute='path') | list | last | basename }}\"\n\n    - name: Put java profile\n      template:\n        src: java.sh.j2\n        dest: /etc/profile.d/java.sh\n        owner: root\n        group: root\n        mode: 0555\n\n    - name: Check for java binaries existence\n      stat:\n        path: '{{ java_path }}/{{ java_folder }}/bin/{{ binary }}'\n      register: java_binary_collection\n      loop:\n        - java\n        - javac\n        - jar\n        - keytool\n      loop_control:\n        loop_var: binary\n\n    - name: Update alternatives\n      alternatives:\n        name: '{{ java_item.binary }}'\n        path: '{{ java_path }}/{{ java_folder }}/bin/{{ java_item.binary }}'\n        link: '/usr/bin/{{ java_item.binary }}'\n        priority: 100\n      when: java_item.stat.exists | bool\n      loop: '{{ java_binary_collection.results }}'\n      loop_control:\n        loop_var: java_item\n  become: true\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "56d351e28a79f333da4a9fb5070d243e70f34da6", "filename": "roles/config-postgresql/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\nmode: containerized\n\npostgresql_name: postgresql\npostgresql_service: \"{{ postgresql_name }}.service\"\n\n#Systemd\nsystemd_service_dir: /usr/lib/systemd/system\nsystemd_environmentfile_dir: /etc/sysconfig\n\n# Postgresql\npostgresql_image: registry.access.redhat.com/rhscl/postgresql-96-rhel7:latest\npostgresql_storage_dir: /var/lib/{{ postgresql_name }}\npostgresql_container_storage_dir: /var/lib/pgsql/data\npostgresql_database: sampledb\npostgresql_container_port: 5432\npostgresql_host_port: 5432\n\n# These Values will be randomaly generated if not defined\n#postgresql_username: postgresql\n#postgresql_password: postgresql\n#postgresql_admin_user: postgresqladmin\n#postgresql_admin_password: postgresqladmin\n\npostgresql_db_uri: \"postgresql://{{ postgresql_admin_user }}:{{ postgresql_admin_password }}@{{ database_service }}/{{ postgresql_database }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "dbbff4bbc0b6c7b43fd050d181e90986865347fe", "filename": "roles/iiab-admin/tasks/access.yml", "repository": "iiab/iiab", "decoded_content": "- name: Install textmode remote access packages\n  package: name={{ item }}\n           state=present\n  with_items:\n        - screen\n        - lynx\n  tags:\n    - download\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "e419e037a695a856042cbe2b70f7fc0fdca85d9a", "filename": "roles/virt-install/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: \"prereq.yml\"\n- import_tasks: \"create_vm.yml\"\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "0c411a69d34de1e274b279b9c47dfc9041916a61", "filename": "tasks/Win32NT/install/sapjvm_tarball.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Check that the java_folder exists\n  win_stat:\n    path: '{{ java_path }}\\{{ java_folder }}/bin'\n  register: java_folder_bin\n\n- name: Install java from tarball\n  block:\n    - name: Mkdir for java installation\n      win_file:\n        path: '{{ java_path }}\\{{ java_folder }}'\n        state: directory\n\n    - name: Create temporary directory\n      win_tempfile:\n        state: directory\n      register: temp_dir_path\n\n    - name: Unarchive to temporary directory\n      win_unzip:\n        src: '{{ java_artifact }}'\n        dest: '{{ temp_dir_path }}'\n\n    - name: Find java_folder in temp\n      win_find:\n        paths: '{{ temp_dir_path }}'\n        recurse: false\n        file_type: directory\n      register: java_temp_folder\n\n    - name: Copy from temporary directory\n      win_copy:\n        src: '{{ java_temp_folder.files | map(attribute=\"path\") | list | last }}\\'\n        dest: '{{ java_path }}\\{{ java_folder }}'\n        remote_src: true\n\n    - name: Check choco\n      win_chocolatey:\n        name: chocolatey\n        state: present\n\n    # https://help.sap.com/viewer/65de2977205c403bbc107264b8eccf4b/Cloud/en-US/76137f42711e1014839a8273b0e91070.html\n    - name: 'Install vcredist package prior to using SAP JVM'\n      win_chocolatey:\n        name: vcredist2013\n      register: choco_install\n      retries: 15\n      delay: 5\n      until: choco_install is succeeded\n  when: not java_folder_bin.stat.exists\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "030fd87530ad839ce63b27d512ccf21b2e6f7ccf", "filename": "roles/ansible/tower/config-ansible-tower-ldap/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- block: # when ansible_tower.ldap is defined\n\n  - include_tasks: ldap.yml\n\n  when:\n  - ansible_tower.ldap is defined\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "95d350a0b13944be982bdb27548731205ef7bcb4", "filename": "roles/config-quay-enterprise/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Include Container Credentials\n  include_tasks: container_credentials.yml\n  when: (quay_registry_server | trim != \"\") and ((quay_registry_auth | trim != \"\") or (quay_registry_email | trim != \"\"))\n\n- name: Configure Storage Directories\n  file:\n    state: directory\n    owner: root\n    group: root\n    mode: g+rw\n    path: \"{{ item }}\"\n  with_items:\n    - \"{{ quay_config_dir }}\"\n    - \"{{ quay_storage_dir }}\"\n    - \"{{ postgresql_storage_dir }}\"\n    - \"{{ redis_storage_dir }}\"\n\n- name: Include systemd configurations\n  include_tasks: configure_systemd.yml\n\n- name: Check if quay configuration exists\n  stat:\n    path: \"{{ quay_config_dir }}/config.yaml\"\n  register: quay_config_stat_result\n\n- name: Setup initial quay configuration file\n  template:\n    src: config.yaml.j2\n    dest: \"{{ quay_config_dir }}/config.yaml\"\n    owner: root\n    group: root\n    mode: g+rw\n  when: not quay_config_stat_result.stat.exists\n\n- name: Include firewall tasks\n  include_tasks: firewall.yml\n\n- name: Start quay\n  systemd:\n    name: \"{{ quay_name }}\"\n    enabled: yes\n    state: started\n    daemon_reload: yes \n    \n    "}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "e6f5ecf3f5c972a89ddd5c7d26febdbe57158fe2", "filename": "tasks/section_02_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 2.1 Create Separate Partition for /tmp (Scored)\n    command: grep '\\s/tmp\\s' /etc/fstab\n    register: tmp_partition\n    failed_when: tmp_partition.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section2\n      - section2.1\n\n  - name: 2.2 - 4 Set nodev, nosuid, noexec option for /tmp Partition (Scored)\n    mount: name=\"/tmp\" src=\"/tmp\" state=\"mounted\" opts=\"nodev,nosuid,noexec\" fstype=ext4\n    when: partitioning == True\n    tags:\n      - section2\n      - section2.2\n      - section2.3\n      - section2.4\n\n  - name: 2.5 Create Separate Partition for /var (Scored)\n    command: grep '\\s/var\\s' /etc/fstab\n    register: var_partition\n    failed_when: var_partition.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section2\n      - section2.5\n\n  - name: 2.6 Bind Mount the /var/tmp directory to /tmp (Scored)\n    mount: name=\"/var/tmp\" src=\"/tmp\" opts=bind state=mounted fstype=ext4\n    when: partitioning == True\n    tags:\n      - section2\n      - section2.6\n\n  - name: 2.7 Create Separate Partition for /var/log (Scored)\n    command: grep '\\s/var\\/log\\s' /etc/fstab\n    register: var_log_partition\n    failed_when: var_log_partition.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section2\n      - section2.7\n\n  - name: 2.8 Create Separate Partition for /var/log/audit (Scored)\n    command: grep '\\s/var\\/log\\/audit\\s' /etc/fstab\n    register: var_log_audit_partition\n    failed_when: var_log_audit_partition.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section2\n      - section2.8\n\n  - name: 2.9 Create Separate Partition for /home (Scored)\n    command: grep '\\s/home\\s' /etc/fstab\n    register: home_partition\n    failed_when: home_partition.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section2\n      - section2.9\n\n  - name: 2.10 Add nodev Option to /home (Scored)\n    mount: name=\"/home\" src=\"/home\" state=mounted opts=remount,nodev fstype=\"ext4\"\n    when: partitioning == True\n    tags:\n      - section2\n      - section2.10\n\n  - name: 2.11 Add nodev Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nodev option\"\n    tags:\n      - section2\n      - section2.11\n\n  - name: 2.12 Add noexec Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have noexec option\"\n    tags:\n      - section2\n      - section2.12\n\n  - name: 2.13 Add nosuid Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nosuid option\"\n    tags:\n      - section2\n      - section2.13\n\n  - name: 2.14 - 16 Add nodev Option to /run/shm Partition (Scored)\n    mount: name=\"/run/shm\" src=\"/run/shm\" state=\"mounted\" opts=\"nodev,nosuid,noexec\" fstype=\"tmpfs\"\n    when: run_shm_read_only == False\n    tags:\n      - section2\n      - section2.14\n      - section2.15\n      - section2.16\n\n  - name: 2.17.1 Set Sticky Bit on All World-Writable Directories (preparation) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type d -perm -0002 -print 2>/dev/null\n    failed_when: False\n    changed_when: False\n    always_run: True\n    register: sticky_bit_dirs\n    tags:\n      - section2\n      - section2.17\n      - section2.17.1\n\n  - name: 2.17.2 Set Sticky Bit on All World-Writable Directories (Scored)\n    file:\n        path: \"{{ item }}\"\n        mode: \"a+t\"\n    with_items: sticky_bit_dirs.stdout_lines\n    tags:\n      - section2\n      - section2.17\n      - section2.17.2\n\n  - name: 2.25 Disable Automounting (stat) (Scored)\n    stat: >\n        path=/etc/init/autofs.conf\n    register: autofs_file\n    tags:\n      - section2\n      - section2.25\n      \n  - name: 2.25 Disable Automounting (Scored)\n    lineinfile: >\n        dest=/etc/init/autofs.conf\n        line='#start on runlevel [2345]'\n        regexp='start on runlevel'\n        state=present\n    when: autofs_file.stat.exists == True\n    tags:\n      - section2\n      - section2.25\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "e76d8ac83f00ce47440468d4c9347e365b91422d", "filename": "tasks/modules/install-perl.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: All OSs) Install NGINX Open Source Perl Module\"\n  package:\n    name: nginx-module-perl\n    state: present\n  when: nginx_type == \"opensource\"\n\n- name: \"(Install: All OSs) Install NGINX Plus Perl Module\"\n  package:\n    name: nginx-plus-module-perl\n    state: present\n  when: nginx_type == \"plus\"\n\n- name: \"(Setup: All NGINX) Load NGINX Perl Module\"\n  lineinfile:\n    path: /etc/nginx/nginx.conf\n    insertbefore: BOF\n    line: load_module modules/ngx_http_perl_module.so;\n  when: not nginx_main_template_enable\n  notify: \"(Handler: All OSs) Reload NGINX\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "bdcf5faf549a33044bd7ad252941426c665b2d01", "filename": "roles/notifications/send-email/tests/inventory/group_vars/all.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nmail:\n  host: \"smtp.example.com\"\n  port: \"465\"\n  username: \"user1@example.com\"\n  password: \"pa55word\"\n  secure: \"always\"\n  headers:\n  - 'Reply-To=user2@example.com'\n  to:\n  - \"person1@example.com\"\n  - \"person2@example.com\"\n  subject: \"Test Message 1\"\n  body: \"<html><body><h1>This is a H1 header</h1></body></html>\"\n  subtype: \"html\"\n\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "f9e64465b6f59f65a821aee284acf85b39faa59a", "filename": "roles/registrator/tasks/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n\n- name: wait for weave socket to be ready.\n  wait_for:\n    port: 6783\n    delay: 10\n\n- name: destroy old marathon container\n  when: registrator_rebuild_container\n  docker:\n    name: registrator\n    image: \"{{ registrator_image }}\"\n    state: absent\n\n# tasks file for docker registrator\n- name: run registrator container\n  docker:\n    name: registrator\n    image: \"{{ registrator_image }}\"\n    state: started\n    restart_policy: always\n    net: host\n    command: \"-internal -resync=10 {{ registrator_uri }}\"\n    volumes:\n    - \"{{ registrator_docker_socket }}:/tmp/docker.sock\"\n  environment: proxy_env\n  tags:\n    - registrator\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "7803b880f221f6db045c2cb57f6b373698f47add", "filename": "roles/usb-lib/templates/umount.d/70-usb-library", "repository": "iiab/iiab", "decoded_content": "#!/bin/bash\n# Remove symlink in /library/content to autmounted usb drive\n#\n# based on a similar script in the xs-rsync package\n# by Martin Langhoff <martin@laptop.org>\n#\n# and the adaptation for xs-activity-server by Douglas Bagnall\n# <douglas@paradise.net.nz>\n#\n# by Tim Moody tim@timmoody.com\n\nCONTENT_LINK_USB=`basename $UM_MOUNTPOINT | awk '{print toupper($0)}'`\nCONTENT_LINK=\"{{ doc_root }}/local_content/$CONTENT_LINK_USB\"\n\nlogger -p user.notice -t \"70-usb-library\" -- \"Attempting to remove link $CONTENT_LINK.\"\n\nif [ -L $CONTENT_LINK ]; then\n{% if is_debuntu %}\n  /bin/rm $CONTENT_LINK\n{% else %}\n  /usr/bin/rm $CONTENT_LINK\n{% endif %}\n  logger -p user.notice -t \"70-usb-library\" -- \"$CONTENT_LINK removed.\"\nfi\n"}, {"commit_sha": "8c72df4ecfaa4188202ab0872f4500384ffe5233", "sha": "3ea5ca44e7f5302d29eeab9e0e981cd6aafac10a", "filename": "meta/main.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "galaxy_info:\n  author: Bjorn Oscarsson\n  description: \"Installs and configures Docker Community Edition (CE)\"\n  min_ansible_version: 2.4\n  license: MIT\n  platforms:\n  - name: Fedora\n    versions:\n      - 24\n      - 25\n      - 26\n      - 27\n      - 28\n\n  - name: EL\n    versions:\n      - 7\n\n  - name: Debian\n    versions:\n      - wheezy\n      - jessie\n      - stretch\n\n  - name: Ubuntu\n    versions:\n      - trusty\n      - xenial\n      - bionic\n\n  galaxy_tags:\n    - docker\n    - containers\n    - system\n\ndependencies: []\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "5c738fcb7d730e1f1744448dfee085451d75b068", "filename": "roles/config-linux-desktop/config-mate/tasks/mate-Fedora.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: \"Install additional packages for MATE\"\n  dnf:\n    name: \"{{ item }}\"\n    state: present\n  with_items:\n  - '@MATE Desktop'\n\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "3308fa7b4d7e69c6ed2aa0bfd1689860a8398d8b", "filename": "playbooks/common.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- name: Check the system\n  raw: uname -a\n  register: OS\n\n- name: Ubuntu pre-tasks\n  include: ubuntu.yml\n  when: '\"Ubuntu\" in OS.stdout'\n\n- name: FreeBSD pre-tasks\n  include: freebsd.yml\n  when: '\"FreeBSD\" in OS.stdout'\n\n- name: Ensure the algo ssh key exist on the server\n  authorized_key:\n    user: \"{{ ansible_ssh_user }}\"\n    state: present\n    key: \"{{ lookup('file', '{{ SSH_keys.public }}') }}\"\n  tags: [ 'cloud' ]\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "cfe4b9b5fb0508a8d266a61fa38b59f3fe10085d", "filename": "roles/nfs-server/tests/nfs-server.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: nfs-server\n  roles: \n  - role: nfs-server\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "9ad549c790217e2a1d5c260a4bf622042277cd4b", "filename": "roles/activity-server/files/bin/xs-regenerate-activities", "repository": "iiab/iiab", "decoded_content": "#!/usr/bin/python\n# Copyright (C) 2008 One Laptop Per Child Association, Inc.\n# Licensed under the terms of the GNU GPL v2 or later; see COPYING for details.\n#\n# written by Douglas Bagnall <douglas@paradise.net.nz>\n\n\"\"\"Read activity.info files from a directory full of activity bundles\nand write an appropriate html manifest of the most recent versions.\nThe manifest uses the OLPC activity microformat:\n\n http://wiki.laptop.org/go/Activity_microformat\n\nThis is put in a place where apache can find it, and apache will serve\nit and the activities to the laptops.  Messages go to /var/log/user.log.\n\"\"\"\n\nimport os\nimport sys\nimport shutil\nfrom time import time\n\nimport xs_activities\n\nINPUT_DIR = \"/library/xs-activity-server/activities\"\nOUTPUT_LINK = \"/library/xs-activity-server/www\"\n\ntry:\n    CURRENT_DIR = os.readlink(OUTPUT_LINK)\nexcept OSError:\n    CURRENT_DIR = None\n\n\ndef create_dir_manifest(dir_path):\n    manifest = []\n    os.chdir(dir_path)\n    for root, dirs, files in os.walk(\".\"):\n        for filename in files:\n            if not filename.endswith(\".xo\") and not filename.endswith(\".xol\"):\n                continue\n\n            path = os.path.join(root, filename)\n            s = os.stat(path)\n            manifest.append((path, s.st_ino))\n\n    manifest.sort()\n    return manifest\n\n\ndef input_changed():\n    if CURRENT_DIR is None:\n        return True\n\n    input_manifest = create_dir_manifest(INPUT_DIR)\n    current_manifest = create_dir_manifest(CURRENT_DIR)\n    return input_manifest != current_manifest\n\n\nif not input_changed():\n    # no changes or nothing to do\n    sys.exit(0)\n\n# create new output dir\nOUTPUT_DIR = OUTPUT_LINK + \".\" + str(time())\nos.mkdir(OUTPUT_DIR)\n\n# link in all activities\nos.chdir(INPUT_DIR)\nfor root, dirs, files in os.walk(\".\"):\n    output_dir = os.path.join(OUTPUT_DIR, root)\n    if not os.path.isdir(output_dir):\n        os.makedirs(output_dir)\n\n    for filename in files:\n        if not filename.endswith(\".xo\") and not filename.endswith(\".xol\"):\n            continue\n\n        path = os.path.join(root, filename)\n        output_path = os.path.join(output_dir, filename)\n        os.link(path, output_path)\n\n    # create html index\n    output_html = os.path.join(output_dir, 'index.html')\n    xs_activities.htmlise_bundles(output_dir, output_html)\n\n\n# update symlink atomically\nlink = OUTPUT_DIR + \".lnk\"\nos.symlink(OUTPUT_DIR, link)\nos.rename(link, OUTPUT_LINK)\n\n# remove old index\nif CURRENT_DIR is not None:\n    shutil.rmtree(CURRENT_DIR, ignore_errors=True)\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "caea144f23cc4b3bcbe55cf62884e59a9335c997", "filename": "roles/config-quay-builder/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Restart Quay Builder Service\n  systemd:\n    name: \"{{ quay_builder_service }}\"\n    enabled: yes\n    state: restarted\n    daemon_reload: yes"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "c0ce8eb5ad1f13fd863636cadc5a2ee0d4c02de7", "filename": "roles/letsencrypt/tasks/certificates.yml", "repository": "roots/trellis", "decoded_content": "- name: Generate private keys\n  shell: openssl genrsa 4096 > {{ letsencrypt_keys_dir }}/{{ item.key }}.key\n  args:\n    creates: \"{{ letsencrypt_keys_dir }}/{{ item.key }}.key\"\n  when: site_uses_letsencrypt\n  with_dict: \"{{ wordpress_sites }}\"\n  tags: [letsencrypt_keys]\n\n- name: Ensure correct permissions on private keys\n  file:\n    path: \"{{ letsencrypt_keys_dir }}/{{ item.key }}.key\"\n    mode: 0600\n  when: site_uses_letsencrypt\n  with_dict: \"{{ wordpress_sites }}\"\n  tags: [letsencrypt_keys]\n\n- name: Generate CSRs for single domain keys\n  shell: openssl req -new -sha256 -key \"{{ letsencrypt_keys_dir }}/{{ item.key }}.key\" -subj \"/CN={{ item.value.site_hosts[0] }}\" > {{ acme_tiny_data_directory }}/csrs/{{ item.key }}.csr\n  args:\n    creates: \"{{ acme_tiny_data_directory }}/csrs/{{ item.key }}.csr\"\n  when: site_uses_letsencrypt and item.value.site_hosts | length == 1 and not item.value.www_redirect | default(true)\n  with_dict: \"{{ wordpress_sites }}\"\n  tags: [letsencrypt_keys]\n\n- name: Generate CSRs for multiple domain keys\n  shell: \"openssl req -new -sha256 -key '{{ letsencrypt_keys_dir }}/{{ item.key }}.key' -subj '/' -reqexts SAN -config <(cat /etc/ssl/openssl.cnf <(printf '[SAN]\\nsubjectAltName=DNS:{{ item.value.site_hosts | reverse_www(enabled=item.value.www_redirect | default(true)) | join(',DNS:') }}')) > {{ acme_tiny_data_directory }}/csrs/{{ item.key }}.csr\"\n  args:\n    executable: /bin/bash\n    creates: \"{{ acme_tiny_data_directory }}/csrs/{{ item.key }}.csr\"\n  when: site_uses_letsencrypt and item.value.www_redirect | default(true)\n  with_dict: \"{{ wordpress_sites }}\"\n  tags: [letsencrypt_keys]\n\n- name: Generate the initial certificate\n  command: ./renew-certs.py\n  args:\n    chdir: \"{{ acme_tiny_data_directory }}\"\n  register: generate_initial_cert\n  changed_when: generate_initial_cert.stdout is defined and 'Created' in generate_initial_cert.stdout\n\n- name: Disable Nginx site\n  file:\n    path: \"{{ nginx_path }}/sites-enabled/letsencrypt-{{ item.key }}.conf\"\n    state: absent\n  with_dict: \"{{ wordpress_sites }}\"\n\n- name: Test nginx conf\n  command: nginx -t\n  changed_when: false\n\n- name: Trigger nginx reload\n  service:\n    name: nginx\n    state: reloaded\n  changed_when: false\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "edc7c72ac34c0fcacdcba8578f5e4190dc10bb62", "filename": "roles/haproxy-config/tasks/prereq.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Use a unique temporary directory to store the config files pre-assemble'\n  command: mktemp -d\n  register: tempdir\n\n- name: 'Store away the temp names'\n  set_fact:\n    haproxy_temp_dir: '{{ tempdir.stdout }}'\n  notify: 'cleanup temp'\n\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "6da3600a379c5932d60310a51f3628811c0aa2f5", "filename": "tasks/plus/setup-freebsd.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: FreeBSD) Add NGINX Plus Repository\"\n  blockinfile:\n    path: /etc/pkg/nginx-plus.conf\n    create: yes\n    block: |\n      nginx-plus: {\n      URL: pkg+https://plus-pkgs.nginx.com/freebsd/${ABI}/latest\n      ENABLED: yes\n      MIRROR_TYPE: SRV\n      }\n\n- name: \"(Install: FreeBSD) Verify NGINX Plus License\"\n  blockinfile:\n    path: /usr/local/etc/pkg.conf\n    block: |\n      PKG_ENV: { SSL_NO_VERIFY_PEER: \"1\",\n      SSL_CLIENT_CERT_FILE: \"/etc/ssl/nginx/nginx-repo.crt\",\n      SSL_CLIENT_KEY_FILE: \"/etc/ssl/nginx/nginx-repo.key\" }\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "f48416abcd2e6f058d7afe38cd83c4735e797a71", "filename": "roles/mariadb/templates/disable-binary-logging.cnf", "repository": "roots/trellis", "decoded_content": "[mysqld]\nskip-log-bin\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "79975ce10bfe111053aedf85eefa68be689576bd", "filename": "roles/config-docker-compose/tasks/docker-compose.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: \"Install additional packages for Docker Compose\"\n  package:\n    name: \"{{ item }}\"\n    state: latest\n  with_items:\n  - docker-compose\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "c87c83240ae8dc27773bf9e890e030acb6107055", "filename": "tasks/modules/install-image-filter.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: All OSs) Install NGINX Open Source Image Filter Module\"\n  package:\n    name: nginx-module-image-filter\n    state: present\n  when: nginx_type == \"opensource\"\n\n- name: \"(Install: All OSs) Install NGINX Plus Image Filter Module\"\n  package:\n    name: nginx-plus-module-image-filter\n    state: present\n  when: nginx_type == \"plus\"\n\n- name: \"(Setup: All NGINX) Load NGINX Image Filter Module\"\n  lineinfile:\n    path: /etc/nginx/nginx.conf\n    insertbefore: BOF\n    line: load_module modules/ngx_http_image_filter_module.so;\n  when: not nginx_main_template_enable\n  notify: \"(Handler: All OSs) Reload NGINX\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "01fefd6196f847661c2a9e4b7125fa1ba8d1d555", "filename": "roles/config-repo-server/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: repo_server\n  roles:\n    - config-repo-server\n"}, {"commit_sha": "2a05a5032ce341d6a1d918453164c59ea2922f58", "sha": "cefc856580b935971d1f77d87f212f80920423a7", "filename": "roles/network_interface/defaults/main.yml", "repository": "CSCfi/fgci-ansible", "decoded_content": "---\nnetwork_ether_interfaces: []\nnetwork_bridge_interfaces: []\nnetwork_bond_interfaces: []\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "906d425322371df3b71c25b1c6465fbaffc026eb", "filename": "tasks/Win32NT/install/chocolatey.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Check choco\n  win_chocolatey:\n    name: chocolatey\n    state: present\n\n- name: 'Install {{ choco_java_package }} from chocolatey'\n  win_chocolatey:\n    name: '{{ choco_java_package }}'\n  register: choco_install\n  retries: 15\n  delay: 5\n  until: choco_install is succeeded\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "8e23db88225825dc2613958323a515422af5c8bc", "filename": "roles/2-common/templates/zzz_iiab.sh", "repository": "iiab/iiab", "decoded_content": "# Add back sbin dirs to unprivileged users PATH\ncase $PATH in\n\t*/sbin/*) ;;\n\t*) PATH=/usr/local/sbin:/usr/sbin:/sbin:$PATH ;;\nesac\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "e99eb5f420bd831656b3b91c196ae3dde13396c6", "filename": "roles/dns/config-dns-server-bind/tasks/named.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Setup DNS Logging configuration\n  template:\n    src: logging.j2\n    dest: /etc/named/named.conf.logging\n    owner: named\n    group: named\n    mode: 0660\n  notify: restart named\n\n- name: Setup Controls configuration\n  template:\n    src: controls.j2\n    dest: /etc/named/named.conf.controls\n    owner: named\n    group: named\n    mode: 0660\n  notify: restart named\n\n- name: Configure named options\n  vars:\n    named_config: \"{{ dns_data.named_global_config | default({}) }}\"\n  template:\n    src: options.j2\n    dest: /etc/named/named.conf.options\n    owner: named\n    group: named\n  notify: restart named\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "5f3ebf02789de8a9b53ae3f52bb2609285b842f2", "filename": "roles/config-quay-enterprise/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Restart quay service\n  systemd:\n    name: \"{{ quay_name }}\"\n    enabled: yes\n    state: restarted\n    daemon_reload: yes\n\n- name: restart firewalld\n  service:\n    name: firewalld\n    state: restarted\n\n- name: restart iptables\n  service:\n    name: iptables\n    state: restarted"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "351fbce8617f93559df7da7e59fcb2e0e1914360", "filename": "playbooks/prepare_ssh.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "---\n- name: Collect information about subscription and remote user\n  hosts: localhost\n  gather_facts: no\n  vars_files:\n  - \"{{file_env}}\"\n  tasks:\n  - name: Create key for remote user\n    user:\n      name: \"{{ssh_user}}\"\n      generate_ssh_key: yes\n      ssh_key_bits: 2048\n      ssh_key_file: .ssh/id_rsa\n- name: Distribute public keys and populate known_hosts\n  gather_facts: no\n  hosts: all\n  vars_files:\n  - \"{{file_env}}\"\n  tasks:\n  - set_fact:\n      ssh_dir: /root/.ssh\n    when: ssh_user == 'root'\n  - set_fact:\n      ssh_dir: \"/home/{{ssh_user}}/.ssh\"\n    when: ssh_user != 'root'\n  - name: Remove old known_hosts\n    file:\n      path: \"{{ssh_dir}}/known_hosts\"\n      state: absent\n  - name: Add key to authorized_keys\n    authorized_key:\n      user: \"{{ssh_user}}\"\n      state: present\n      key: \"{{ lookup('file', ssh_dir+'/id_rsa.pub') }}\"\n  - name: Run ssh-keyscan to add keys to known_hosts\n    local_action: \"shell ssh-keyscan {{ inventory_hostname }} >> {{ssh_dir}}/known_hosts\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "2ab0410296f3d17af58542c0a178f199243f8959", "filename": "roles/dns/config-dns-server-bind/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: prereq.yml\n- import_tasks: named.yml\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "2dd3355e1b09e239b460c3d23fd292039f1ef95a", "filename": "playbooks/templates/ifcfg-monif.j2", "repository": "rocknsm/rock", "decoded_content": "TYPE=Ethernet\nBOOTPROTO=none\nIPV4_FAILURE_FATAL=no\nIPV6INIT=no\nIPV6_FAILURE_FATAL=no\nNAME={{ item }}\nDEVICE={{ item }}\nONBOOT=yes\nNM_CONTROLLED=no\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "4056fb7ce44fff4570199cf2f4fa536aeec3375a", "filename": "tasks/setup_ldap_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: setup_ldap\n    args:\n      name: \"{{ item.ldap_name }}\"\n      protocol: \"{{ item.ldap_protocol }}\"\n      hostname: \"{{ item.ldap_hostname }}\"\n      port: \"{{ item.ldap_port }}\"\n      auth: \"{{ item.ldap_auth | default('none') }}\"\n      username: \"{{ item.ldap_auth_username | default('') }}\"\n      password: \"{{ item.ldap_auth_password | default('') }}\"\n      search_base: \"{{ item.ldap_search_base }}\"\n      user_base_dn: \"{{ item.ldap_user_base_dn | default('ou=users') }}\"\n      user_ldap_filter: \"{{ item.ldap_user_filter | default('') }}\"\n      user_object_class: \"{{ item.ldap_user_object_class }}\"\n      user_id_attribute: \"{{ item.ldap_user_id_attribute }}\"\n      user_real_name_attribute: \"{{ item.ldap_user_real_name_attribute }}\"\n      user_email_attribute: \"{{ item.ldap_user_email_attribute }}\"\n      map_groups_as_roles: \"{{ item.ldap_map_groups_as_roles | default(false) }}\"\n      map_groups_as_roles_type: \"{{ item.ldap_map_groups_as_roles_type | default('static') }}\"\n      user_memberof_attribute: \"{{ item.ldap_user_memberof_attribute | default('memberOf') }}\"\n      group_base_dn: \"{{ item.ldap_group_base_dn | default('ou=groups') }}\"\n      group_object_class: \"{{ item.ldap_group_object_class | default('groupOfNames') }}\"\n      group_id_attribute: \"{{ item.ldap_group_id_attribute | default('cn') }}\"\n      group_member_attribute: \"{{ item.ldap_group_member_attribute | default('member') }}\"\n      group_member_format: \"{{ item.ldap_group_member_format | default('uid=${username},ou=users,dc=yourcompany') }}\"\n      user_subtree: \"{{ item.ldap_user_subtree | default(false) }}\"\n      group_subtree: \"{{ item.ldap_group_subtree | default(false) }}\"\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "84a25d6dac1243af655939053b7dc8931147c6ed", "filename": "playbooks/roles/check_os/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- assert:\n    that:\n      - (ansible_distribution == 'RedHat' and ansible_distribution_version == '7.4') or\n        (ansible_distribution == 'RedHat' and ansible_distribution_version == '7.5') or\n        (ansible_distribution == 'RedHat' and ansible_distribution_version == '7.6')\n    msg: \"The only supported platforms for this release are RHEL 7.4 or RHEL 7.5 or RHEL 7.6\"\n"}, {"commit_sha": "481f7ad18dc225973e1d676d33e58c49cbbfe986", "sha": "ea5f610b8895fc8d280776ede923a005a98a4b17", "filename": "tasks/selinux.yml", "repository": "openwisp/ansible-openwisp2", "decoded_content": "---\n\n- name: Set http_can_network_connect\n  seboolean:\n    name: httpd_can_network_connect\n    state: yes\n    persistent: yes\n\n- name: Set SELinux permissive mode (for testing puropses)\n  selinux:\n    state: permissive\n    policy: targeted\n\n- name: Set correct labels for nginx logs\n  sefcontext:\n    target: '{{ openwisp2_path }}/log/(.*)?'\n    setype: httpd_log_t\n    state: present\n\n- name: Set label on log directory\n  sefcontext:\n    target: '{{ openwisp2_path }}/log'\n    setype: httpd_log_t\n    state: present\n\n- name: Relabel files\n  command: /usr/sbin/restorecon -R {{ openwisp2_path }}\n  changed_when: false\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "7f867d73b11e9dfb6365ae9e42f28b80c8d15d0c", "filename": "meta/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\ndependencies:\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "61b70d6a836b0bdfe1aaebcb097fd2d711208c46", "filename": "roles/network/templates/named/localhost.zone", "repository": "iiab/iiab", "decoded_content": "$TTL\t86400\n@\t\tIN SOA\t@       root (\n\t\t\t\t\t42\t\t; serial (d. adams)\n\t\t\t\t\t3H\t\t; refresh\n\t\t\t\t\t15M\t\t; retry\n\t\t\t\t\t1W\t\t; expiry\n\t\t\t\t\t1D )\t\t; minimum\n\n\t        IN NS\t\t@\n\t \tIN A\t\t127.0.0.1\n\t\tIN AAAA\t\t::1\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "193a24db58c169c7fa59d9bf118a9cd4461d867c", "filename": "roles/calibre/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Get Calibre setup file\n# the installer works for intel fedora, and Centos, and deals with dependencies\n  get_url:\n    url=\"{{ calibre_src_url }}\"\n    dest=\"{{ downloads_dir }}/calibre-installer.py\"\n    mode=0755\n  when: ansible_distribution == \"CentOS\"\n\n- name: Install Calibre\n  shell: \"{{ downloads_dir }}/calibre-installer.py >> /dev/null\"\n  args:\n    creates: /usr/bin/calibre-uninstall\n  when: calibre_install and ansible_distribution == 'CentOS'\n\n- name: Install Calibre rpms\n# the fedora rpm arm version, though older, takes care of dependencies, and exists\n  package:  name={{ item }}\n            state=present\n  with_items:\n    - calibre\n  when: calibre_install and ansible_distribution != 'CentOS'\n\n- name: Create Calibre service(s) and support scripts\n  template: backup=no\n            src={{ item.src }}\n            dest={{ item.dest }}\n            owner=root\n            group=root\n            mode={{ item.mode }}\n  with_items:\n    - { src: 'calibre-serve.service.j2', dest: '/etc/systemd/system/calibre-serve.service', mode: '0644'}\n    - { src: 'calibre.conf', dest: '/etc/{{ apache_config_dir }}', mode: '0644'}\n  when: calibre_install\n\n- name: Create the link for sites-enabled\n  file: src=/etc/apache2/sites-available/calibre.conf\n        dest=/etc/apache2/sites-enabled/calibre.conf\n        state=link\n  when: is_debuntu and calibre_enabled\n\n- name: Enable Calibre server\n  service: name=calibre-serve\n           enabled=yes\n           state=started\n  #async: 900\n  #poll: 5\n  when: calibre_enabled\n\n- name: Disable Calibre server\n  service: name=calibre-serve\n           enabled=no\n           state=stopped\n  when: not calibre_enabled\n\n- name: Add Calibre to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=calibre\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: description\n      value: '\"Calibre epub book server\"'\n    - option: url\n      value: \"{{ calibre_src_url }}\"\n    - option: database\n      value: \"{{ calibre_dbpath }}\"\n    - option: port\n      value: \"{{ calibre_port }}\"\n    - option: enabled\n      value: \"{{ calibre_enabled }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "d8666882c4d08e32881ce7d177c35967471c4128", "filename": "roles/osm/templates/map_search.py", "repository": "iiab/iiab", "decoded_content": "# Internet-in-a-Box System\n# By Braddock Gaskill, 16 Feb 2013\n# Modified by Tim Moody, 8 Apr 2016\nfrom utils import whoosh_open_dir_32_or_64\n# from whoosh.qparser import QueryParser\nfrom whoosh.qparser import MultifieldParser\nfrom whoosh import sorting\n\nfrom utils import whoosh2dict\n\n\nclass MapSearch(object):\n    def __init__(self, index_dir):\n        \"\"\"Initialize a search object.\n        index_dir is the Whoosh index directory to use.\"\"\"\n        self.index_dir = index_dir\n\n    def search(self, query, page=1, pagelen=20):\n        \"\"\"Return a sorted list of results.\n        pagelen specifies the number of hits per page.\n        page specifies the page of results to return (first page is 1)\n        Set pagelen = None or 0 to retrieve all results.\n        \"\"\"\n        query = unicode(query)  # Must be unicode\n        population_sort_facet = sorting.FieldFacet(\"population\", reverse=True)\n        ix = whoosh_open_dir_32_or_64(self.index_dir)\n        with ix.searcher() as searcher:\n            # query = QueryParser(\"ngram_name\", ix.schema).parse(query)\n            mparser = MultifieldParser([\"ngram_name\", \"admin1_code\", \"country_code\"], schema=ix.schema)\n            query = mparser.parse(query)\n            if pagelen is not None and pagelen != 0:\n                try:\n                    results = searcher.search_page(query, page, pagelen=pagelen)\n                except ValueError, e:  # Invalid page number\n                    results = []\n            else:\n                results = searcher.search(query, limit=None)\n            #r = [x.items() for x in results]\n            r = whoosh2dict(results)\n        ix.close()\n        # experiment with tucking away content for display in popup.\n        print r\n        for d in r:\n            d['popupText'] = 'test content'\n            d['name'] = d['name'] + ', ' + d['admin1_code'] + ', ' + d['country_code']\n\n        return r\n\n    def count(self, query):\n        \"\"\"Return total number of matching documents in index\"\"\"\n        query = unicode(query)  # Must be unicode\n        ix = whoosh_open_dir_32_or_64(self.index_dir)\n        with ix.searcher() as searcher:\n            query = QueryParser(\"title\", ix.schema).parse(query)\n            results = searcher.search(query)\n            n = len(results)\n        ix.close()\n        return n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "c048fee9b9bbc87461ac44c1089380639e55b9c7", "filename": "roles/ansible/tower/config-ansible-tower/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# ansible_tower_download_url: http://releases.ansible.com/ansible-tower/setup/ansible-tower-setup-latest.tar.gz\nansible_tower_download_url: https://releases.ansible.com/ansible-tower/setup/ansible-tower-setup-3.3.0-1.tar.gz\n\n# oc clients found at 'https://mirror.openshift.com/pub/openshift-v3/clients/'\nansible_tower_oc_download_url: https://mirror.openshift.com/pub/openshift-v3/clients/3.10.47/linux/oc.tar.gz\n\n# EPEL release can be changed, but default to '-latest'\nansible_tower_epel_download_url: https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm\n\ndefault_ansible_tower_url: 'https://localhost'\ndefault_ansible_tower_admin_username: 'admin'\n"}, {"commit_sha": "b7c6bfe0369646ca69beeb3dfe07e8218d61c940", "sha": "8979725f1dc9cab6f8991c3a2f86bb3168025dbd", "filename": "tasks/main.yml", "repository": "dev-sec/ansible-os-hardening", "decoded_content": "---\n- name: Set OS family dependent variables\n  include_vars: '{{ ansible_os_family }}.yml'\n  tags: always\n\n- name: Set OS dependent variables\n  include_vars: '{{ item }}'\n  with_first_found:\n    - files:\n      - '{{ ansible_distribution }}-{{ ansible_distribution_major_version }}.yml'\n      - '{{ ansible_distribution }}.yml'\n      - '{{ ansible_os_family }}-{{ ansible_distribution_major_version }}.yml'\n      skip: true\n  tags: always\n\n- import_tasks: limits.yml\n  tags: limits\n\n- import_tasks: login_defs.yml\n  tags: login_defs\n\n- include_tasks: minimize_access.yml\n  tags: minimize_access\n\n- import_tasks: pam.yml\n  tags: pam\n\n- import_tasks: modprobe.yml\n  tags: modprobe\n\n- import_tasks: profile.yml\n  tags: profile\n\n- import_tasks: securetty.yml\n  tags: securetty\n\n- import_tasks: suid_sgid.yml\n  when: os_security_suid_sgid_enforce\n  tags: suid_sgid\n\n- import_tasks: sysctl.yml\n  tags: sysctl\n\n- import_tasks: user_accounts.yml\n  tags: user_accounts\n\n- import_tasks: rhosts.yml\n  tags: rhosts\n\n- import_tasks: yum.yml\n  when: ansible_os_family == 'RedHat'\n  tags: yum\n\n- import_tasks: apt.yml\n  when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'\n  tags: apt\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "20e1017dc4c3dc6be1a6780f70739f78a9c286a0", "filename": "tasks/Linux/install/tarball.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Mkdir for java installation\n  file:\n    path: '{{ java_path }}/{{ java_folder }}'\n    state: directory\n    owner: root\n    group: root\n    mode: 0755\n\n- name: 'Install java {{ java_full_version }}'\n  unarchive:\n    src: '{{ java_artifact }}'\n    dest: '{{ java_path }}/{{ java_folder }}'\n    remote_src: true\n    owner: root\n    group: root\n    mode: 0755\n    extra_opts: [--strip-components=1]\n    creates: '{{ java_path }}/{{ java_folder }}/bin/'\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "b32c4dc56da3c7c975852615c332e670396f54fb", "filename": "roles/dns/manage-dns-zones/tasks/route53/get-zone-records.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Get all hosted zones\n  route53_facts:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    query: hosted_zone\n  register: hosted_zones\n\n- name: Get all records from zones\n  route53_facts:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    query: record_sets\n    hosted_zone_id: \"{{ item.Id | replace('/hostedzone/', '')}}\"\n  with_items:\n    - \"{{ hosted_zones.HostedZones | default({}) }}\"\n  register: zones_records\n  when:\n    - hosted_zones|length > 0\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "192c3372e5b5ae00d3c77eec0ff7f284e931e048", "filename": "roles/scm/gitlab.com/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Create new Gitlab Group in {{ gitlab_group_name }}\n  uri:\n    url: '{{ gitlab_api_groups }}'\n    headers:\n      Accept: application/json\n      Private-Token: '{{ gitlab_api_private_token }}'\n    method: POST\n    status_code: 201\n    body_format: json\n    body: '{\n             \"name\": \"{{ group.name }}\",\n             \"path\": \"{{ group.path | default(group.name) }}\",\n             \"description\": \"{{ group.description | default(group.name) }}\",\n             \"visibility\": \"{{ group.visibility | default(\"private\") }}\",\n             \"lfs_enabled\": {{ group.lfs_enabled | default(\"false\") }},\n             \"request_access_enabled\": {{ group.request_access_enabled | default(\"false\") }},\n           }'\n  register: groups_json_response\n\n- debug: msg={{ groups_json_response.json.id }}\n\n- name: Add Users to Gitlab Group\n  uri:\n    url: '{{ gitlab_api_groups }}/{{ group.name }}/members'\n    headers:\n      Accept: application/json\n      Private-Token: '{{ gitlab_api_private_token }}'\n    method: POST\n    status_code: 201\n    body_format: json\n    body: '{\n             \"user_id\": \"{{ item.id }}\",\n             \"access_level\": \"{{ item.access_level | default(40) }}\"\n           }'\n  register: users_json_response\n  with_items: \"{{ users }}\"\n\n- debug: msg={{ users_json_response }}\n\n- name: Add Project to existing Gitlab Group\n  uri:\n    url: '{{ gitlab_api_projects }}'\n    headers:\n      Accept: application/json\n      Private-Token: '{{ gitlab_api_private_token }}'\n    method: POST\n    status_code: 201\n    body_format: json\n    body: '{\n             \"name\": \"{{ item.repo_name }}\",\n             \"path\": \"{{ item.path | default(item.repo_name) }}\",\n             \"namespace_id\": {{ groups_json_response.json.id }},\n             \"description\": \"{{ item.description | default(item.repo_name) }}\",\n             \"issues_enabled\": {{ item.issues_enabled | default(\"true\") }},\n             \"merge_requests_enabled\": {{ item.merge_requests_enabled | default(\"true\") }},\n             \"wiki_enabled\": {{ item.wiki_enabled | default(\"true\") }},\n             \"visibility\": \"{{ item.visibility | default(\"private\") }}\",\n             \"import_url\": \"{{ item.import_url }}\",\n             \"lfs_enabled\": {{ item.lfs_enabled | default(\"false\") }},\n             \"printing_merge_request_link_enabled\": {{ item.printing_merge_request_link_enabled | default(\"true\") }}\n           }'\n  register: projects_json_response\n  with_items: \"{{ projects }}\"\n\n- debug: msg={{ projects_json_response }}\n\n- name: Add a new deploy key to the gitlab repositories\n  uri:\n    url: '{{ gitlab_api_projects }}/{{ item.1.json.id }}/deploy_keys'\n    headers:\n      Accept: application/json\n      Private-Token: '{{ gitlab_api_private_token }}'\n    method: POST\n    status_code: 201\n    body_format: json\n    body: '{\n             \"title\": \"deploy-key-{{ item.0.repo_name }}\",\n             \"key\": \"{{ item.0.deploy_key_location }}\",\n             \"can_push\": {{ item.0.can_push | default(\"true\") }}\n           }'\n  register: deploy_keys_json_response\n  when: item.0.repo_name == item.1.json.name\n  with_together:\n    - \"{{ projects }}\"\n    - \"{{ projects_json_response.results }}\"\n\n- debug: msg={{ deploy_keys_json_response }}"}, {"commit_sha": "f92ebbef856e59bd4563d4b5b69ee75a95ec89d5", "sha": "dff68da9ad46fb5cc41a1b5e6dec270cd093276b", "filename": "roles/openshift-management/tasks/prune-images.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- name: Prune Images\n  shell: oc adm prune images --keep-tag-revisions={{ openshift_prune_images_tag_revisions }}  --keep-younger-than={{ openshift_prune_images_keep_younger }} --confirm\n  environment:\n    KUBECONFIG: \"{{ kubeconfig }}\""}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "3716bf8b4704dd36d0c237291886740b1bf6a1ba", "filename": "roles/ovirt-collect-logs/tasks/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\n- name: Include correct variables based on system\n  include_vars: \"{{ ovirt_collect_logs_from_system }}.yml\"\n\n- name: Ensure required archive tools\n  yum:\n    name: \"{{ item }}\"\n    state: \"present\"\n  with_items:\n    - gzip\n    - tar\n\n# Prepare place to store data\n\n- name: Clean temporary directory and previous archive\n  file:\n    path: \"{{ item }}\"\n    state: \"absent\"\n  with_items:\n    - \"{{ ovirt_collect_logs_tmp_dir }}\"\n    - \"{{ ovirt_collect_logs_archive }}\"\n\n- name: Create temporary directory\n  file:\n    path: \"{{ ovirt_collect_logs_tmp_dir }}\"\n    state: \"directory\"\n    mode: \"0777\"\n\n# Collect common stuff\n- name: Dump system information using shell commands\n  shell: \"{{ item.value }} &> {{ ovirt_collect_logs_tmp_dir }}/{{ item.key }}.txt\"\n  with_dict: \"{{ ovirt_collect_logs_shell_commands }}\"\n  ignore_errors: true\n  tags:\n    - skip_ansible_lint # check for shell module is not working correctly in Lint\n\n\n- name: Link common logs\n  file:\n    src: \"{{ item.src }}\"\n    dest: \"{{ ovirt_collect_logs_tmp_dir }}/{{ item.dest }}\"\n    state: link\n  with_items:\n    - { src: \"/var/log/messages\", dest: \"messages\" }\n\n# Collect system specific stuff\n\n- include: \"{{ ovirt_collect_logs_from_system }}.yml\"\n\n# Fetch stuff to local system\n- name: Archive logs\n  shell: \"tar {{ ovirt_collect_logs_tar_optional_params}}\n            -hczf {{ ovirt_collect_logs_archive }}\n            {{ ovirt_collect_logs_tmp_dir }}\"\n  ignore_errors: true\n  tags:\n    - skip_ansible_lint # achive module has insufficient functionality\n\n- name: Fetch logs\n  fetch:\n    src: \"{{ ovirt_collect_logs_archive }}\"\n    dest: \"logs/{{ ovirt_collect_logs_from_system }}-{{ ansible_hostname }}/ovirt-engine-logs.tar.gz\"\n    flat: yes\n"}, {"commit_sha": "96adc61e360141bb718b75d48c387b3680a8471b", "sha": "dcaec52544a89fcdb12393ba13a645caf3541c47", "filename": "tasks/configure-non-systemd.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "- name: Combine Docker daemon environment variable configuration\n  set_fact:\n    docker_service_envs: \"{{ docker_service_envs | combine(_docker_service_opts) | combine(docker_daemon_envs) }}\"\n  vars:\n    _docker_service_opts:\n      DOCKER_OPTS: \"{{ docker_daemon_opts }}\"\n\n- name: Setup Docker environment file {{ docker_envs_dir[_docker_os_dist] }}/docker\n  template:\n    src: docker-envs.j2\n    dest: \"{{ docker_envs_dir[_docker_os_dist] }}/docker\"\n  become: yes\n  notify: restart docker\n  vars:\n    docker_envs: \"{{ docker_service_envs }}\""}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "f4167b7a4155c046ff5164f2c3053dc5d879fc2a", "filename": "tasks/opensource/setup-suse.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: SUSE) Add NGINX Repository\"\n  zypper_repository:\n    name: \"nginx-{{ nginx_branch }}\"\n    repo: \"{{ nginx_repository.suse }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "7dd9390b8dff26d8d16dee350b623e084865c64b", "filename": "roles/config-nagios-server/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Setup hostgroup directories\n  file:\n    path: /etc/nagios/objects/{{hostvars[item]['hostgroup_name']}}\n    state: directory\n    mode: 0755\n  with_items: \"{{groups['nagios-targets']}}\"\n\n- name: Setup common hostgroup configuration\n  template:\n    src: common.cfg.j2 \n    dest: /etc/nagios/objects/{{hostvars[item]['hostgroup_name']}}/common.cfg\n    owner: root\n    group: root\n    mode: 0644 \n  with_items: \"{{groups['nagios-targets']}}\"\n\n- name: Setup the hosts in the hostgroup configuration\n  template:\n    src: host.cfg.j2 \n    dest: /etc/nagios/objects/{{hostvars[item]['hostgroup_name']}}/{{hostvars[item]['inventory_hostname_short']}}.cfg\n    owner: root\n    group: root\n    mode: 0644 \n  with_items: \"{{groups['nagios-targets']}}\"\n\n- name: Add common hostgroup configuration to master nagios configuration file\n  lineinfile:\n    dest: /etc/nagios/nagios.cfg\n    regexp: \"^cfg_file=/etc/nagios/objects/{{hostvars[item]['hostgroup_name']}}/common.cfg\"\n    line: \"cfg_file=/etc/nagios/objects/{{hostvars[item]['hostgroup_name']}}/common.cfg\"\n  with_items: \"{{groups['nagios-targets']}}\"\n\n- name: Add host configuration to master nagios configuration file\n  lineinfile:\n    dest: /etc/nagios/nagios.cfg\n    regexp: \"^cfg_file=/etc/nagios/objects/{{hostvars[item]['hostgroup_name']}}/{{hostvars[item]['inventory_hostname_short']}}.cfg\"\n    line: \"cfg_file=/etc/nagios/objects/{{hostvars[item]['hostgroup_name']}}/{{hostvars[item]['inventory_hostname_short']}}.cfg\"\n  with_items: \"{{groups['nagios-targets']}}\"\n\n- name: Restart nagios\n  service:\n    name: nagios\n    state: restarted\n\n"}, {"commit_sha": "3c4d272a77f8aaeb300c8b841bb7e6d8dbd76c1f", "sha": "ec32b1eb3c804dcb0176a41a339d8493b59c69cb", "filename": "meta/main.yml", "repository": "ansiblebit/oracle-java", "decoded_content": "---\n# file: oracle-java/meta/main.yml\n#\n# meta file\n#\ngalaxy_info:\n  author: Pedro Salgado\n  description: Role to install Oracle Java.\n  company: ansiblebit.org\n  license: BSD\n  min_ansible_version: 1.9.3\n  platforms:\n    - name: CentOS\n      versions:\n        - all\n        - any\n        - 7\n        - 6\n    - name: Debian\n      versions:\n        - jessie\n        - wheezy\n    - name: MacOSX\n      versions:\n        - 10.10.2\n        - 10.10.1\n        - 10.9.5\n        - 10.9.4\n        - 10.9.3\n        - 10.9.2\n        - 10.9.1\n    - name: RedHat\n      versions:\n        - all\n        - any\n        - 7\n        - 6\n    - name: Ubuntu\n      versions:\n        - vivid\n        - trusty\n        - precise\n  categories:\n    - development\n    - system\ndependencies:\n  - role: ansiblebit.launchpad-ppa-webupd8\n    when: (ansible_distribution | lower == 'debian') or (ansible_distribution | lower == 'ubuntu')\n"}, {"commit_sha": "1d7d3a653c598355333e7c34a54a550ed3d79cc5", "sha": "14ac638d187c072fb483221db5cab06985e2c47c", "filename": "tasks/mongodb.yml", "repository": "RocketChat/Rocket.Chat.Ansible", "decoded_content": "---\n# tasks/mongodb.yml: MongoDB configuration for RocketChat.Ansible\n  - include_vars: \"{{ item }}\"\n    with_first_found:\n      - \"{{ ansible_distribution }}_{{ ansible_distribution_major_version }}.yml\"\n      - \"{{ ansible_os_family }}_{{ ansible_distribution_major_version }}.yml\"\n      - \"{{ ansible_distribution }}.yml\"\n      - \"{{ ansible_os_family }}.yml\"\n\n  - name: Ensure the MongoDB repository key has been imported\n    apt_key:\n      keyserver: \"{{ rocket_chat_mongodb_keyserver }}\"\n      id: \"{{ rocket_chat_mongodb_gpg_key }}\"\n    when: ansible_os_family == \"Debian\"\n    tags: repo\n\n  - name: Ensure the MongoDB repository is present\n    apt_repository:\n      repo: \"{{ rocket_chat_mongodb_apt_repo }}\"\n      state: present\n    when: ansible_os_family == \"Debian\"\n    tags: repo\n\n  - name: Ensure MongoDB Server is present\n    package:\n      name: \"{{ rocket_chat_mongodb_packages }}\"\n      state: present\n\n  - name: Deploy MongoDB service configuration\n    template:\n      src: \"{{ rocket_chat_mongodb_config_template }}\"\n      dest: /etc/mongod.conf\n    notify: Restart the MongoDB service\n\n  - meta: flush_handlers\n\n  - name: Ensure the MongoDB service is started/enabled\n    service:\n      name: mongod\n      state: started\n      enabled: yes\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "68e6c2e58dd77f36c37d15c6c14898ea37e6eeec", "filename": "tasks/create_repo_bower_hosted_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_bower_hosted\n    args: \"{{ _nexus_repos_bower_defaults|combine(item) }}\""}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "ecf50727f5cb0fbc82ba1e5590eaebf3ae65a795", "filename": "roles/dhcp/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: prereq.yml\n\n# build the config file locally\n- import_tasks: dhcpconfig.yml\n  delegate_to: localhost\n  run_once: true\n\n# install the packages and copy the file from the local system\n- import_tasks: dhcp.yml\n"}, {"commit_sha": "3c4d272a77f8aaeb300c8b841bb7e6d8dbd76c1f", "sha": "17c17884e1ffc5be1225a3938049c23c007acbc1", "filename": "tasks/main.yml", "repository": "ansiblebit/oracle-java", "decoded_content": "---\n# file: oracle-java/tasks/main.yml\n#\n# tasks file\n#\n\n- name: check host environment\n  include: check_environment.yml\n\n## include OS family specific variables\n\n- name: include OS family/distribution specific variables\n  include_vars: \"{{ item }}\"\n  with_first_found:\n    - \"../defaults/{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml\"\n    - \"../defaults/{{ ansible_distribution | lower }}.yml\"\n    - \"../defaults/{{ ansible_os_family | lower }}.yml\"\n\n- name: debug variables\n  include: debug.yml\n  tags:\n    - debug\n\n## include OS family specific task file\n\n- name: if darwin/macosx, include distribution specific task file\n  include: \"darwin/macosx.yml\"\n  when: ansible_os_family | lower == 'darwin' and ansible_distribution | lower == 'macosx'\n\n- name: if debian, include family specific task file\n  include: \"debian/main.yml\"\n  when: ansible_os_family | lower == 'debian'\n\n- name: if redhat, include family specific task file\n  include: \"redhat/main.yml\"\n  when: ansible_os_family | lower == 'redhat'\n\n- name: check if operating system is suported\n  fail:\n    msg: \"The operating system ({{ ansible_os_family }}) of the target machine ({{ inventory_hostname }}) is not currently supported.\"\n  when: oracle_java_os_supported is not defined or not oracle_java_os_supported\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "96c1d83e8f8775604465c68230b874780375c8c2", "filename": "roles/dns/manage-dns-zones-route53/tasks/process-one-zone.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Remove Zone entries prior to remove the Zone\n  include_tasks: loop-zones.yml\n  when:\n    - zone.state == \"absent\"\n\n- name: Ensure the private zone is on the desired state\n  route53_zone:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    zone: \"{{ zone.dns_domain }}\"\n    vpc_id: \"{{ zone.route53.vpc_id }}\"\n    vpc_region: \"{{ zone.route53.vpc_region }}\"\n    state: \"{{ zone.state | default('present') }}\"\n  when:\n    - view.name == \"private\"\n\n- name: Ensure the public zone is on the desired state\n  route53_zone:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    zone: \"{{ zone.dns_domain }}\"\n    state: \"{{ zone.state | default('present') }}\"\n  when:\n    - view.name == \"public\"\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "f0127923e6cf4a7a6997a2e41b54cbf40679994e", "filename": "tasks/create_repo_maven_group_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_maven_group\n    args: \"{{ _nexus_repos_maven_defaults|combine(item) }}\"\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "57e0b8d766f3614b85fffaf2bba4bff7cddd8747", "filename": "playbooks/openshift/delete-cluster.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n#- hosts: seed-hosts\n#  roles:\n#  - openshift-ansible-contrib/roles/openshift-pv-cleanup\n\n- import_playbook: openstack/delete.yml\n  when:\n  - hosting_infrastructure == 'openstack'\n\n- import_playbook: aws/delete.yml\n  when:\n  - hosting_infrastructure == 'aws'\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "6000cbe58fbadf0704c8de9207752785936211e3", "filename": "roles/idmgr/templates/idmgr", "repository": "iiab/iiab", "decoded_content": "#  This is a configuration file for the OLPC idmgr\n#  See http://wiki.laptop.org/go/School_Identity_Manager\nBACKUP={{ iiab_hostname }}.{{ iiab_domain }}\nPRESENCE={{ iiab_hostname }}.{{ iiab_domain }}\nBIND_ADDRESS=0.0.0.0\n"}, {"commit_sha": "a9f9815335a6b9c73bed7e3dcd75e14cd973fbb5", "sha": "3d39a0288b7ddfc77f2380773a9fc25b2705c60e", "filename": "tasks/main.yml", "repository": "CSCfi/ansible-role-cuda", "decoded_content": "---\n# tasks file for ansible-role-cuda\n#\n  - include: redhat.yml\n    when: ansible_os_family == \"RedHat\" and gpu == True\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "e5b14b42e1074dca3a8720c74788afba79171ddf", "filename": "inventory/sample.osp.example.com.d/files/policy/01-clusterroles.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "apiVersion: v1\nkind: List\nitems:\n- apiVersion: v1\n  kind: ClusterRole\n  metadata:\n    creationTimestamp: null\n    name: cluster-admin-custom\n  rules:\n  - apiGroups:\n    - '*'\n    attributeRestrictions: null\n    resources:\n    - '*'\n    verbs:\n    - '*'\n  - apiGroups: null\n    attributeRestrictions: null\n    nonResourceURLs:\n    - '*'\n    resources: []\n    verbs:\n    - '*'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "d3fbaeeb2efd469552540606cac3cfb12650bf40", "filename": "roles/config-linux-desktop/config-gnome/tasks/gnome-Fedora.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: \"Install additional packages for Gnome\"\n  dnf:\n    name: \"{{ item }}\"\n    state: present\n  with_items:\n  - '@gnome'\n\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "5ba1b00ffddf308d5b1b22565e89f06b46bffacc", "filename": "roles/haproxy/handlers/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# handlers file for haproxy\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "381566cb72bcbd41072796cdac6fc35deb783702", "filename": "roles/2-common/tasks/fl.yml", "repository": "iiab/iiab", "decoded_content": "- name: Create /opt/iiab/iiab\n  file: path={{ iiab_dir }}\n        owner=root\n        group=root\n        mode=0755\n        state=directory\n\n- name: Create /opt/iiab/yum-packages\n  file: path={{ yum_packages_dir }}\n        owner=root\n        group=root\n        mode=0755\n        state=directory\n\n- name: Create /opt/iiab/pip-packages\n  file: path={{ pip_packages_dir }}\n        owner=root\n        group=root\n        mode=0755\n        state=directory\n\n- name: Create /opt/iiab/downloads\n  file: path={{ downloads_dir }}\n        owner=root\n        group=root\n        mode=0755\n        state=directory\n\n- name: Create various library directories\n  file: path={{ item }}\n        owner=root\n        group=root\n        mode=0755\n        state=directory\n  with_items:\n    - /library/downloads/zims\n    - /library/downloads/rachel\n    - /library/working/zims\n    - /library/working/rachel\n    - \"{{ iiab_zim_path }}/content\"\n    - \"{{ iiab_zim_path }}/index\"\n    - \"{{ doc_root }}/modules\"\n\n- name: Create directory for common packages\n  file: path={{ item }}\n        mode=0755\n        owner=root\n        group=root\n        state=directory\n  with_items:\n    - \"{{ doc_root }}/common/css\"\n    - \"{{ doc_root }}/common/js\"\n    - \"{{ doc_root }}/common/fonts\"\n    - \"{{ doc_root }}/common/html\"\n    - \"{{ doc_root }}/common/images\"\n    - \"{{ doc_root }}/common/assets\"\n    - \"{{ doc_root }}/common/services\"\n\n- name: Create olpc-scripts directory\n  file: path={{ item }}\n        owner=root\n        group=root\n        mode=0755\n        state=directory\n  with_items:\n    - /etc/sysconfig/olpc-scripts/\n    - /etc/sysconfig/olpc-scripts/setup.d/installed/\n\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "07cf39f2ba8cce457c5c9295d396213f0d7650ba", "filename": "playbooks/container-registry/README.md", "repository": "redhat-cop/infra-ansible", "decoded_content": "# Quay Enterprise\n\nThis playbook provides support for deploying [Quay Enterprise](https://coreos.com/quay-enterprise/) and its required dependencies.\n\n## Components\n\nThe following sets of resources are provisioned by this playbook:\n\n* [Redis](https://redis.io/)\n* Database Persistence ([PostgreSQL](https://www.postgresql.org/) or [MySQL](https://www.mysql.com/))\n* Load Balancer ([HAProxy](http://www.haproxy.org/))\n* [Quay Enterprise](https://coreos.com/quay-enterprise/)\n* [Clair](https://coreos.com/clair)\n\n## Inventory Options\n\nThe deployment of Quay Enterprise is driven by the inventory found in the [quay-enterprise](../../inventory/quay-enterprise) folder.\n\nFive host groups are available and configured in the [hosts](../../inventory/quay-enterprise/hosts) file:\n\n```\n[quay_enterprise]\n\n[db]\n\n[redis]\n\n[clair]\n\n[lb]\n```\n\nThe following is a list of the most commonly utilized inventory variables used to drive the execution (not comprehensive):\n\n| variable | info |\n|---|---|\n|quay_registry_auth|Base64 encoded value to access a secured registry for Quay|\n|database_type|Database type (`postgresql` or `mysql`)|\n|docker_install|Boolean whether to install and configure docker|\n|quay_hostname|Hostname to configure the optionally generated SSL certificate|\n|quay_superuser_username|Quay superuser username|\n|quay_superuser_password|Quay superuser password|\n|quay_superuser_email|Quay superuser email|\n\nAdditional variables can be utilized by inspecting the variables provided by each role.\n\n## Playbook Execution\n\nExecute the following command to provision the Quay ecosystem:\n\n```\n$ ansible-playbook -i ../../inventory/quay-enterprise  quay-enterprise.yml\n```\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "63db5b5cbcc936341624c66a5f7f221673962718", "filename": "roles/wordpress-setup/tasks/database.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Create database of sites\n  mysql_db:\n    name: \"{{ site_env.db_name }}\"\n    state: present\n    login_host: \"{{ site_env.db_host }}\"\n    login_user: \"{{ mysql_root_user }}\"\n    login_password: \"{{ mysql_root_password }}\"\n  with_dict: \"{{ wordpress_sites }}\"\n  when: site_uses_local_db and item.value.db_create | default(True)\n\n- name: Create/assign database user to db and grant permissions\n  mysql_user:\n    name: \"{{ site_env.db_user }}\"\n    password: \"{{ site_env.db_password }}\"\n    append_privs: yes\n    priv: \"{{ site_env.db_name }}.*:ALL\"\n    state: present\n    login_host: \"{{ site_env.db_host }}\"\n    login_user: \"{{ mysql_root_user }}\"\n    login_password: \"{{ mysql_root_password }}\"\n  with_dict: \"{{ wordpress_sites }}\"\n  when: site_uses_local_db and item.value.db_create | default(True)\n\n- name: Copy database dump\n  copy:\n    src: \"{{ item.value.db_import }}\"\n    dest: /tmp\n  with_dict: \"{{ wordpress_sites }}\"\n  when: item.value.db_import | default(False)\n\n- name: Import database\n  mysql_db:\n    name: \"{{ site_env.db_name }}\"\n    state: import\n    target: \"/tmp/{{ item.value.db_import | basename }}\"\n    login_host: \"{{ site_env.db_host }}\"\n    login_user: \"{{ site_env.db_user }}\"\n    login_password: \"{{ site_env.db_password }}\"\n  with_dict: \"{{ wordpress_sites }}\"\n  when: item.value.db_import | default(False)\n  notify: reload nginx\n"}, {"commit_sha": "49010188a985bfe713552eb8980cfa0d7a888daf", "sha": "0fbe713516425e5aba4fb7cc752229c0bed7cec9", "filename": "roles/sync-keys/tasks/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- name: \"Push Administrator's SSH Keys\"\n  authorized_key:\n    user: \"{{ ansible_ssh_user }}\"\n    key: \"{{ key_url }}\"\n  when: key_url is defined and key_url != \"\"\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "edda2d9a987e00954031c7433bf5608b685fcc57", "filename": "roles/ferm/defaults/main.yml", "repository": "roots/trellis", "decoded_content": "---\nferm_enabled: true\nferm_limit_portscans: false\n\nferm_default_policy_input: DROP\nferm_default_policy_output: ACCEPT\nferm_default_policy_forward: DROP\n\nferm_input_list: []\nferm_input_group_list: []\nferm_input_host_list: []\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "2060c19ff2d268ea040c5dbfea29161a0c491371", "filename": "roles/2-common/tasks/fedora.yml", "repository": "iiab/iiab", "decoded_content": "- name: Keep yum cache\n  ini_file: dest=/etc/yum.conf\n            section=main\n            option=keepcache\n            value=1\n\n- name: Install Fedora specifc packages\n  package: name={{ item }}\n           state=present\n  with_items:\n   - mtd-utils\n\n- name: Install optional exFAT packages for Fedora\n  shell: yum --enablerepo=rpmfusion-free-updates install exfat-utils fuse-exfat\n  when: exFAT_enabled == \"True\"\n\n#- name: Disable updating ansible on Fedora\n#  shell: sed -i -e '/^enabled=/a exclude=ansible' {{ item }}\n#  with_items:\n#    - /etc/yum.repos.d/fedora.repo\n#    - /etc/yum.repos.d/fedora-updates.repo\n#    - /etc/yum.repos.d/fedora-updates-testing.repo\n#  when: ansible_distribution == \"Fedora\"\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "abe8057dfa10b4ab03743188c4c813a46cfe5bac", "filename": "playbooks/roles/common/tasks/main.yml", "repository": "rocknsm/rock", "decoded_content": "---\n# main.yml - Common tasks for ROCK\n- include: hostname.yml\n- include: epel.yml\n- include: pkginstall.yml\n- include: timedatectl.yml\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "7078424fb99d0eafaccedefb5606e2f0df523468", "filename": "roles/user-management/manage-user-passwd/tasks/generate-one-password.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Set password to given value or default\"\n  set_fact:\n    password: \"{{ item.password | default('') }}\"\n\n- name: \"Create random password\"\n  set_fact:\n    password: \"{{ lookup('password','/dev/null length=16') }}\"\n  when:\n  - item.generate_password is defined\n  - item.generate_password == True\n  - password|trim == ''\n\n\n- name: \"Add new user passwords\"\n  set_fact:\n    user_passwords: \"{{ user_passwords|default({}) | combine({ item.user_name: password }) }}\"\n\n\n"}, {"commit_sha": "7032aee7df1c2c6e96795067285efa3b2a6de32e", "sha": "0b03d4ef5793c04c5f9db504cbcee078426f05b4", "filename": "roles/dns/handlers/main.yml", "repository": "openshift/openshift-ansible-contrib", "decoded_content": "---\n- name: restart named\n  service: name=named state=restarted\n\n- name: reload named\n  service: name=named state=reloaded\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "5925f23cbfe6e68f6b09d03dca6c7fc2a9a5f19d", "filename": "playbooks/roles/check_ntp/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "---\n- name: Determine if chrony is installed\n  command: rpm -q chrony\n  failed_when: false\n  register: chrony_installed\n\n- name: Determine if ntp is installed\n  command: rpm -q ntp\n  failed_when: false\n  register: ntp_installed\n\n- name: Install chrony package\n  package:\n    name: chrony\n    state: present\n  when: ntp_installed.rc != 0\n\n- name: Install ntp package\n  package:\n    name: ntp\n    state: present\n  when: chrony_installed.rc != 0\n\n- name: Create chrony conf\n  template:\n    src: templates/chrony.j2\n    dest: /etc/chrony.conf\n    mode: 0644\n  notify: Restart chrony\n  when: ntp_installed.rc != 0 and ntp_servers is defined and (ntp_servers|length > 0)\n\n- name: Create ntp conf\n  template:\n    src: templates/chrony.j2\n    dest: /etc/ntp.conf\n    mode: 0644\n  notify: Restart ntp\n  when: chrony_installed.rc != 0 and ntp_servers is defined and (ntp_servers|length > 0)\n\n \n- name: Start and enable chronyd/ntpd\n  command: timedatectl set-ntp true\n\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "f42c601b0371afc9eedc0f5825209912f86ab8f0", "filename": "roles/config-redis/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Restart Redis Service\n  systemd:\n    name: \"{{ redis_service }}\"\n    enabled: yes\n    state: restarted\n    daemon_reload: yes\n\n- name: restart firewalld\n  service:\n    name: firewalld\n    state: restarted\n\n- name: restart iptables\n  service:\n    name: iptables\n    state: restarted\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "4ad68b2c9abcbfad2edc523dec0486f9dd8c5e25", "filename": "roles/4-server-options/README.rst", "repository": "iiab/iiab", "decoded_content": "=====================\nServer Options README\n=====================\n\nThis role is a place to aggregate roles that may be optionally added to the basic server,\nwhereas the roles in base-server are required. As in the case of the base-server the\nfunctionality here is not packages that are not directly consumed by users, which are in common,\nnor specific applications, such as those found in the apps and tools roles."}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "7c3c26507a21ffa4ffc4aa879de8b09bbe4008af", "filename": "roles/config-quay-enterprise/tasks/container_credentials.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Check if container credential file exists\n  stat:\n    path: \"{{ container_credentials_file }}\"\n  register: container_credential_stat_result\n\n- block:\n  - name: Read content of container credentials file\n    slurp:\n      path: \"{{ container_credentials_file }}\"\n    register: remote_container_credentials_file\n\n  - name: Set content of container credentials file\n    set_fact:\n      container_credentials_file_content: \"{{ remote_container_credentials_file.content| b64decode | from_json }}\"\n  when: container_credential_stat_result.stat.exists\n\n- name: Create Quay credentials variable\n  set_fact:\n    quay_container_credentials:\n      auths: \"{ '{{quay_registry_server}}':{ 'email': '{{ quay_registry_email }}', 'auth': '{{ quay_registry_auth }}' } }\"\n\n- name: Create merged credentials file content\n  set_fact:\n    container_credentials_file_content: \"{{ container_credentials_file_content | combine(quay_container_credentials, recursive=True) }}\"\n\n- name: Create directory for container credentials file\n  file:\n    state: directory\n    path: \"{{ container_credentials_file | dirname }}\"\n\n- name: Update container credentials file\n  copy:\n    content: \"{{container_credentials_file_content | to_nice_json }}\"\n    dest: \"{{ container_credentials_file }}\"\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "965405720ca148dbcbb50fa925a241167ec593f8", "filename": "roles/rollback/tasks/user-release.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Check whether user-specified release exists\n  stat:\n    path: \"{{ project_root }}/releases/{{ release }}\"\n  register: specified\n\n- name: Get name of current symlinked release\n  shell: \"basename $(readlink current)\"\n  args:\n    chdir: \"{{ project_root }}\"\n  register: current_release\n\n- name: Fail if user-specified release doesn't exist or is already active\n  fail:\n    msg: \"Cannot switch to release {{ release }}. Either it does not exist or it is the active release.\"\n  when: specified.stat.isdir | default(False) == False or current_release.stdout_lines[0] == release\n\n- name: Create new_release_path variable\n  set_fact:\n    new_release_path: \"{{ project_root }}/releases/{{ release }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "b8ec4cd8f9478c5bfed438fdc725209076cb2b6f", "filename": "roles/munin/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Install munin package\n  package: name={{ item }}\n           state=present\n  with_items:\n    - munin\n    - munin-node\n    - munin-plugins-extra\n    - libcgi-fast-perl\n    - libapache2-mod-fcgid\n  tags:\n    - download\n  when: is_debuntu\n\n- name: Install munin package\n  package: name={{ item }}\n           state=present\n  with_items:\n    - munin\n    - munin-node\n  tags:\n    - download\n  when: not is_debuntu\n\n- name: Copy munin config file\n  template: src={{ item.src }}\n            dest={{ item.dest }}\n            owner=root\n            group=root\n            mode=0644\n  with_items:\n    - { src: 'munin.conf.j2', dest: '/etc/munin/munin.conf' }\n    - { src: 'munin24.conf.j2', dest: '/etc/{{ apache_config_dir }}/munin24.conf' }\n\n- name: Create admin user\n  htpasswd: path=/etc/munin/munin-htpasswd\n            name=Admin\n            password=changeme\n            create=yes\n            state=present\n\n- name: Enable munin-node service\n  service: name=munin-node\n           enabled=yes\n           state=started\n  when: munin_enabled\n\n- name: Enable apache lookup\n  file: src=/etc/apache2/sites-available/munin24.conf\n        dest=/etc/apache2/sites-enabled/munin24.conf\n        state=link\n  when: munin_enabled and is_debuntu\n\n- name: disable apache lookup\n  file: src=/etc/apache2/sites-available/munin24.conf\n        dest=/etc/apache2/sites-enabled/munin24.conf\n        state=absent\n  when: not munin_enabled and is_debuntu\n\n- name: Disable munin-node service when it becomes disabled\n  service: name=munin-node\n           enabled=no\n           state=stopped\n  when: not munin_enabled\n\n- name: If mysql is enabled, let munin monitor it\n  copy: dest=/etc/munin/plugins/\n        src={{ item }}\n  with_items:\n    - /usr/share/munin/plugins/mysql_\n    - /usr/share/munin/plugins/mysql_bytes\n    - /usr/share/munin/plugins/mysql_innodb\n    - /usr/share/munin/plugins/mysql_isam_space_\n    - /usr/share/munin/plugins/mysql_queries\n    - /usr/share/munin/plugins/mysql_slowqueries\n    - /usr/share/munin/plugins/mysql_threads\n  when: mysql_enabled\n\n- name: Add munin to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=munin\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: munin\n    - option: description\n      value: '\"Munin is a networked resource monitoring tool that can help analyze resource trends and \\\"what just happened to kill our performance?\\\" problems.\"'\n    - option: installed\n      value: \"{{ munin_install }}\"\n    - option: enabled\n      value: \"{{ munin_enabled }}\"\n\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "29d9f4b19d47af385b27f6d8581bdb35c21caf0f", "filename": "archive/playbooks/registry/provision-openstack.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- hosts: localhost\n  pre_tasks:\n  - include: roles/common/pre_tasks/pre_tasks.yml\n  roles:\n    - role: common\n    - role: openshift-common\n    # Provision Master\n    - role: openstack-create\n      type: \"registry\"\n      key_name: \"{{ openstack_key_name }}\"\n      image_name: \"ose3_1-base\"\n      flavor_name: \"{{ openshift_openstack_flavor_name }}\"\n      security_groups: \"docker-registry,default\"\n      register_host_group: \"registry\"\n      node_count: \"1\"\n- hosts: registry\n  roles:\n    - role: registry\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "594430a0b747e5d7ec429146dc1b59aa569140d4", "filename": "roles/dns/manage-dns-records/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: localhost\n  roles:\n  - role: dns/manage-dns-records\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "29183b1467773e5d99aa8181e866e37d8f02a81f", "filename": "roles/activity-server/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "# assume apache in admin group\n\n- name: Create xs-activity-server directory tree\n  file: path={{ item }}\n        mode=0755\n        owner=root\n        group=admin\n        state=directory\n  with_items:\n    - /library/xs-activity-server\n    - /library/xs-activity-server/activities\n    - /library/xs-activity-server/lang_templates\n    - /library/xs-activity-server/www.0\n    - /library/xs-activity-server/tmp\n\n# Wish synchronize worked, but it doesn't\n\n- name: Copy language templates\n  command: rsync -a {{ iiab_dir }}/roles/activity-server/files/lang_templates /library/xs-activity-server/\n\n- name: Copy default index files\n  copy: src={{ item }}\n        dest=/library/xs-activity-server/www.0\n        mode=0755\n        owner=root\n        group=root\n  with_fileglob:\n        - www.0/index.html.*\n\n- name: Point www to www.0 as default\n  file: src=/library/xs-activity-server/www.0\n        dest=/library/xs-activity-server/www\n        owner=root\n        group=admin\n        state=link\n\n- name: Chown language templates\n  file: path=/library/xs-activity-server/lang_templates\n        mode=0644\n        owner=root\n        group=admin\n        state=directory\n        recurse=yes\n\n# We should have a var for python site-packages directory\n\n- name: Create xs-activity-server python site-packages directory\n  file: path=/usr/lib/python2.7/site-packages/xs_activities\n        mode=0755\n        owner=root\n        group=root\n        state=directory\n\n- name: Install Python module\n  copy: src=xs_activities/__init__.py\n        dest=/usr/lib/python2.7/site-packages/xs_activities\n        mode=0644\n        owner=root\n        group=root\n\n- name: Copy scripts to /usr/bin\n  copy: src={{ item }}\n        dest=/usr/bin\n        mode=0755\n        owner=root\n        group=root\n  with_items:\n        - bin/xs-regenerate-activities\n        - bin/xs-check-activities\n\n# Do in ansible what was done in /etc/sysconfig/olpc-scripts/setup.d/xs-activity-server script\n\n- name: Copy xs-activity-server config file\n  template: src=xs-activity-server.conf\n            dest=/etc/{{ apache_config_dir }}\n            owner=root\n            group=root\n            mode=0644\n\n- name: enable mod_expires for debian\n  command: a2enmod expires\n  when: is_debuntu\n\n- name: create the link which enables the site\n  file: src=/etc/apache2/sites-available/xs-activity-server.conf\n        dest=/etc/apache2/sites-enabled/xs-activity-server.conf\n        state=link\n  when: activity_server_enabled and is_debuntu\n\n- name: delete the link which enables the site\n  file: src=/etc/apache2/sites-available/xs-activity-server.conf\n        dest=/etc/apache2/sites-enabled/xs-activity-server.conf\n        state=absent\n  when: not activity_server_enabled and is_debuntu\n\n\n- name: Copy xs-activity-server usbmount file\n  template: src=usbmount-60-xs-activity-server-installcontent\n        dest=/etc/usbmount/mount.d\n        owner=root\n        group=root\n        mode=0755\n\n# TODO: Fix multiview so it supports portal language menu\n#       For it only supports client's language code\n\n# TODO: Upload Activity via web interface\n#       and figure out what to do with olpc_activities.service\n\n# short term addition of link for upload-activity server\n# ln -sf /usr/share/xs-config/cfg/html/top/en/cntr_upl_activity.php {{ doc_root }}/upload_activity.php\n\n\n- name: Restart httpd\n  service: name={{ apache_service }}\n           enabled=yes\n           state=restarted\n\n- name: add xs-activity-server to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=activity-server\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: \"Activity Server\"\n    - option: description\n      value: \"Download an Activity.\"\n    - option: path\n      value: /activities\n    - option: enabled\n      value: \"{{ xo_services_enabled }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "35228714e39a4ee12a113b8de9affbcf9ce53096", "filename": "playbooks/manage-jira/README.md", "repository": "redhat-cop/infra-ansible", "decoded_content": "## Jira Project Playbook\nThis playbook is used to automate the creation of project on Jira.\n\n### Example\nPlease refer to the [roles](../../roles/manage-jira/README.md) directory for information regarding the variables required to run this playbook.\n\n### Running the playbook\n`$ ansible-playbook -i inventory playbook.yaml`\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "acd7afccf71005adefdbdfbe8a5f0b2b1455bbce", "filename": "roles/dns/manage-dns-zones-route53/tasks/empty-zone.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Remove records in Private zone\n  route53:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    state: absent\n    zone: \"{{ zone.dns_domain }}\"\n    private_zone: \"true\"\n    vpc_id: \"{{ zone.route53.vpc_id }}\"\n    value: \"{{ r53_record.1.Value }}\"\n    record: \"{{ r53_record.0.Name }}\"\n    ttl: \"{{ r53_record.0.TTL }}\"\n    type: \"{{ r53_record.0.Type }}\"\n  when:\n    - zone.dns_domain + \".\" == r53_zone.item.Name\n    - view.name == \"private\"\n    - r53_record.0.Name != r53_zone.item.Name\n    - r53_record.0.Type != \"SOA\"\n    - r53_record.0.Type != \"NS\"\n\n- name: Remove records in Public zone\n  route53:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    state: absent\n    zone: \"{{ zone.dns_domain }}\"\n    record: \"{{ r53_record.0.Name }}\"\n    ttl: \"{{ r53_record.0.TTL }}\"\n    value: \"{{ r53_record.1.Value }}\"\n    type: \"{{ r53_record.0.Type }}\"\n  when:\n    - zone.dns_domain + \".\" == r53_zone.item.Name\n    - view.name == \"public\"\n    - r53_record.0.Name != r53_zone.item.Name\n    - r53_record.0.Type != \"SOA\"\n    - r53_record.0.Type != \"NS\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "031a0c03061e8f6449be56930c68fafbf9af4b41", "filename": "roles/1-prep/tasks/detected_redhat.yml", "repository": "iiab/iiab", "decoded_content": "- name: Checking for ifcfg-WAN file - Can Fail\n  stat: path=/etc/sysconfig/network-scripts/ifcfg-WAN\n  register: has_ifcfg_WAN\n  when: not first_run\n\n- name: Setting ifcfg-WAN True\n  set_fact:\n    has_WAN: True\n  when: has_ifcfg_WAN.stat is defined and has_ifcfg_WAN.stat.exists\n\n# DETECT -- gateway and wireless\n- name: Get a list of slaves from previous config - Can Fail\n  shell: \"egrep -rn BRIDGE=br0 /etc/sysconfig/network-scripts/ifcfg-* | gawk -F'[-:]' '{print $3}'\"\n  register: ifcfg_slaves\n  ignore_errors: True\n  changed_when: False\n  when: not first_run\n\n# returns list of paths\n- name: Find gateway config based on device\n  shell: \"egrep -rn {{ device_gw }} /etc/sysconfig/network-scripts/ifcfg* | gawk -F ':' '{print $1}'\"\n  register: ifcfg_gw_device\n  ignore_errors: True\n  changed_when: False\n  when: not first_run and device_gw != \"none\"\n\n# last match wins\n- name: Setting has ifcfg gw based on device if found\n  set_fact:\n    has_ifcfg_gw: \"{{ item|trim }}\"\n  ignore_errors: True\n  when: ifcfg_gw_device.stdout_lines is defined and item|trim != \"\" and item|trim != \"/etc/sysconfig/network-scripts/ifcfg-LAN\"\n  with_items:\n      - \"{{ ifcfg_gw_device.stdout_lines }}\"\n\n# returns path\n- name: Find active gateway config based on macaddress - Can Fail\n  shell: \"egrep -irn {{ ansible_default_ipv4.macaddress }} /etc/sysconfig/network-scripts/ifcfg* | gawk -F ':' '{print $1}' | head -n 1\"\n  register: ifcfg_gw_mac\n  ignore_errors: True\n  changed_when: False\n  when: ansible_default_ipv4.gateway is defined\n\n- name: Set has ifcfg gw based on on macaddress if found\n  set_fact:\n    has_ifcfg_gw: \"{{ ifcfg_gw_mac.stdout|trim }}\"\n  when: ifcfg_gw_mac.changed and ifcfg_gw_mac.stdout != \"\"\n\n# could use something else\n- name: Find wifi gateway config if present - Can Fail\n  shell: egrep -rn ESSID /etc/sysconfig/network-scripts/ifcfg* | gawk -F ':' '{print $1}' | gawk -F '/' '{print $5}'\n  register: ifcfg_WAN_wifi\n  ignore_errors: True\n\n#returns file name\n- name: Setting has_wifi_gw based on ESSID if found - Can Fail\n  set_fact:\n    has_wifi_gw: \"{{ item|trim }}\"\n  when: ifcfg_WAN_wifi.changed and item|trim != \"\"\n  with_items:\n      - \"{{ ifcfg_WAN_wifi.stdout_lines }}\"\n\n- name: Finding device for wifi AP gateway - Can Fail\n  shell: egrep -rn DEVICE /etc/sysconfig/network-scripts/{{ has_wifi_gw }} |  gawk -F '=' '{print $2}'\n  register: AP_device\n  ignore_errors: True\n  when: has_wifi_gw != \"none\" and has_ifcfg_gw != \"none\"\n\n- name: Setting wifi device\n  set_fact:\n    ap_device: \"{{ AP_device.stdout }}\"\n  when: AP_device.stdout is defined and AP_device.stdout != \"\"\n\n#unused\n#- name: Get a list of ifcfg files to delete - Can Fail\n#  shell: \"ls -1 /etc/sysconfig/network-scripts/ifcfg-* | grep -v -e ifcfg-lo  -e ifcfg-WAN -e {{ has_wifi_gw }}\"\n#  register: ifcfg_files\n#  changed_when: False\n#  ignore_errors: True\n#  when: num_lan_interfaces >= \"1\" or iiab_wireless_lan_iface != \"none\"\n\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "ff4e4ad7202a6df93e47a212d828b8620a40de3e", "filename": "tasks/plus/delete-license.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(All OSs) Delete NGINX Plus License\"\n  file:\n    path: /etc/ssl/nginx\n    state: absent\n"}, {"commit_sha": "1224adf2811c827a09ff0bf133fbb476901a547d", "sha": "22cae057f979ca9cf9a02c8393eca244eb26390a", "filename": "tasks/apt_prepare.yml", "repository": "nusenu/ansible-relayor", "decoded_content": "---\n\n- name: Ensure torproject gpg key is installed (A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89)\n  become: yes\n  apt_key:\n    data: \"{{ lookup('file', 'deb.torproject.org_A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89.pub') }}\"\n    id: A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89\n    state: present\n\n- name: Ensure torproject.org repository is present (APT)\n  become: yes\n  apt_repository:\n    repo: 'deb http://deb.torproject.org/torproject.org {{ tor_distribution_release }} main'\n    state: present\n    update_cache: yes\n\n- name: Ensure torproject.org alpha repo is present if enabled (APT)\n  become: yes\n  apt_repository:\n    repo: 'deb http://deb.torproject.org/torproject.org tor-experimental-{{ tor_alpha_version }}.x-{{ tor_distribution_release }} main'\n    state: present\n    update_cache: yes\n  when: tor_alpha == True\n\n# Background:\n# https://github.com/nusenu/ansible-relayor/issues/72\n- name: Ensure systemd generator folder exists (Debian Testing and Ubuntu)\n  become: yes\n  file:\n    path: /etc/systemd/system-generators\n    state: directory\n    mode: 0755\n  when: ansible_lsb.codename != 'jessie'\n\n- name: Ensure custom systemd generator is in place (Debian/Ubuntu only)\n  become: yes\n  copy:\n    src: tor-generator\n    dest: \"{{ (ansible_lsb.codename == 'jessie')|ternary('/lib/systemd/system-generators/relayor-generator', '/etc/systemd/system-generators/tor-generator') }}\"\n    owner: root\n    mode: 0755\n\n- name: Ensure the maintainer's generator is disabled (Debian 8 only)\n  become: yes\n  command: dpkg-statoverride --update --add root root 644 /lib/systemd/system-generators/tor-generator\n  when: ansible_lsb.codename == 'jessie'\n  ignore_errors: yes\n\n#- name: Ensure AppArmor allows access to necessary files (Ubuntu)\n#  become: yes\n#  lineinfile: dest=/etc/apparmor.d/local/system_tor line={{ item }}\n#  with_items:\n#    - '/etc/tor/enabled/*\\ r,'\n#    - '/{,var/}run/tor/*.pid\\ w,'\n#    - '/var/lib/tor/**\\ w,'\n#  when: ansible_distribution == 'Ubuntu'\n#  notify: restart apparmor\n\n#- meta: flush_handlers\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "f66401b80ce88cc9237662f169bcaeff52b70a50", "filename": "roles/teamviewer/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "teamviewer_url: \"{{ iiab_download_url }}\"\nteamviewer_rpm_file: teamviewer_10.0.41499.i686.rpm\nteamviewer_install: True\nteamviewer_enabled: False\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "67e4417576c3c4b6cf93a8bb956525d5c78f1c5e", "filename": "roles/rhsm/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# Use a 'block' to ensure \"become: True\" for all tasks since\n# all of these tasks require elevated privileges\n- block:\n\n  # Need to use the 'command' module for this task since the \"redhat_subscription\" module\n  # won't do a full \"clean\" when using the \"state: absent\" option\n  # - note the 'warn: False' set because of this situation\n  - name: 'Unregister the system if already registered - if this is a force re-registration'\n    command: \"{{ item }}\"\n    args:\n      warn: False\n    with_items:\n    - 'subscription-manager clean'\n    - 'subscription-manager remove --all'\n    - 'yum remove -y \"katello-ca-consumer-*\"'\n    when:\n    - (rhsm_force_register|default('no'))|lower == 'yes'\n\n  # Need to use the 'command' module for this task since the \"yum\" module\n  # won't honor an \"upgrade\" of the RPM in case where the source server changed. \n  # - note the 'warn: False' set because of this situation\n  - name: \"Install Satellite certificate (if applicable)\"\n    command: \"rpm -Uh --force http://{{ rhsm_server_hostname }}/pub/katello-ca-consumer-latest.noarch.rpm\"\n    args:\n      warn: False\n    when:\n    - rhsm_server_hostname is defined\n    - rhsm_server_hostname|trim != ''\n\n  - name: 'Register system using Red Hat Subscription Manager'\n    redhat_subscription:\n      state: present\n      username: \"{{ rhsm_username | default(omit) }}\"\n      password: \"{{ rhsm_password | default(omit) }}\"\n      pool_ids: \"{{ rhsm_pool_ids | default(omit) }}\"\n      pool: \"{{ rhsm_pool | default(omit) }}\"\n      autosubscribe: \"{{ ((rhsm_pool is defined or rhsm_pool_ids is defined or rhsm_activationkey is defined) | ternary(omit, true)) }}\"\n      server_hostname: \"{{ rhsm_server_hostname | default(omit) }}\"\n      activationkey: \"{{ rhsm_activationkey | default(omit) }}\"\n      org_id: \"{{ rhsm_org_id | default(omit) }}\"\n      force_register: \"{{ rhsm_force_register | default(omit) }}\"\n\n  - name: \"Obtain currently enabled repos\"\n    shell: 'subscription-manager repos --list-enabled | sed -ne \"s/^Repo ID:[^a-zA-Z0-9]*\\(.*\\)/\\1/p\"'\n    register: enabled_repos\n\n  # Build the list of repos to disable/enable before calling 'subscription-manager' as it's a very \n  # expensive command to run and hence better to call just once (especially with a long list of repos)\n  - name: \"Build command line for repos to disable\"\n    set_fact:\n      repos_params: \"{{ repos_params|default('') }} --disable={{ item }}\"\n    with_items: \n    - \"{{ enabled_repos.stdout_lines | difference(rhsm_repos) }}\"\n\n  - name: \"Build command line for repos to enable\"\n    set_fact:\n      repos_params: \"{{ repos_params|default('') }} --enable={{ item }}\"\n    with_items:\n    - \"{{ rhsm_repos | difference(enabled_repos.stdout_lines) }}\"\n\n  - name: \"Run 'subscription-manager to disable/enable repos\"\n    command: \"subscription-manager repos {{ repos_params }}\"\n    when:\n    - repos_params is defined \n    - repos_params|trim != ''\n\n  # End of outer block for \"become: True\"\n  become: True\n\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "30bf01be9656d2b8028e33b5c3dab3591489041f", "filename": "tasks/Linux/fetch/s3.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Download artifact from s3\n  aws_s3:\n    bucket: '{{ transport_s3_bucket }}'\n    object: '{{ transport_s3_path }}'\n    dest: '{{ java_download_path }}/{{ transport_s3_path | basename }}'\n    aws_access_key: '{{ transport_s3_aws_access_key }}'\n    aws_secret_key: '{{ transport_s3_aws_secret_key }}'\n    mode: get\n    overwrite: different\n    ignore_nonexistent_bucket: true\n  retries: 5\n  delay: 2\n\n- name: Set downloaded artifact vars\n  set_fact:\n    file_downloaded:\n      dest: '{{ java_download_path }}/{{ transport_s3_path | basename }}'\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "518cfc927c881ed6fe264dddc79938065f37eb25", "filename": "roles/rachel/tasks/rachel_enabled.yml", "repository": "iiab/iiab", "decoded_content": "- name: Copy RACHEL httpd conf file\n  template: src=rachel.conf.j2\n            dest=/etc/{{ apache_config_dir }}/rachel.conf\n\n- name: enable Rachel\n  file: path=/etc/apache2/sites-enabled/rachel.conf\n        src=/etc/apache2/sites-available/rachel.conf\n        state=link\n  when: rachel_enabled and is_debuntu\n\n- name: Remove RACHEL conf file if we are disabled\n  file: path=/etc/apache2/sites-enabled/rachel.conf\n        state=absent\n  when: not rachel_enabled and is_debuntu\n\n# This probably doesn't work, but we can't get search to work either\n- name: Create link to rachel mysql db from mysql data dir\n  file: src={{ rachel_mysqldb_path }}\n        dest=/var/lib/mysql/sphider_plus\n        owner=root\n        group=admin\n        state=link\n\n- name: Set mysql password\n  lineinfile: regexp=mysql_password1\n              line=\"$mysql_password1 = '{{ mysql_root_password }}';\"\n              state=present\n              dest={{ rachel_content_path }}/rsphider/settings/database.php\n\n- name: Restart mysqld service\n  service: name={{ mysql_service }}\n           state=restarted\n\n- name: Restart apache2 service\n  service: name={{ apache_service }}\n           state=restarted\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "2412c9383870e4cfe82bb29985a3c167552e3c7c", "filename": "tasks/Linux/system_repositories.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Perform install from repositories\n  block:\n    - name: 'Perform repo install'\n      include_tasks: '{{ install_task }}'\n      with_first_found:\n        - 'install/{{ ansible_os_family }}_{{ java_distribution }}.yml'\n        - 'install/{{ ansible_os_family }}.yml'\n      loop_control:\n        loop_var: install_task\n\n    - name: Finalize binary paths\n      include_tasks: finalize_paths.yml\n  become: true\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "5db3ab6d07aef9878d52305772f2dcf9af678795", "filename": "tasks/section_12_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 12.1 Verify Permissions on /etc/passwd (Scored)\n    file: path=/etc/passwd mode=0644\n    tags:\n      - section12\n      - section12.1\n\n  - name: 12.2 Verify Permissions on /etc/shadow (Scored)\n    file: path=/etc/shadow mode='o-rwx,g-rw'\n    tags:\n      - section12\n      - section12.2\n\n  - name: 12.3 Verify Permissions on /etc/group (Scored)\n    file: path=/etc/group mode=0644\n    tags:\n      - section12\n      - section12.3\n\n  - name: 12.4 Verify User/Group Ownership on /etc/passwd (Scored)\n    file: path=/etc/passwd owner=root group=root\n    tags:\n      - section12\n      - section12.4\n\n  - name: 12.5 Verify User/Group Ownership on /etc/shadow (Scored)\n    file: path=/etc/shadow owner=root group=shadow\n    tags:\n      - section12\n      - section12.5\n\n  - name: 12.6 Verify User/Group Ownership on /etc/group (Scored)\n    file: path=/etc/group owner=root group=root\n    tags:\n      - section12\n      - section12.6\n\n  - name: 12.7 Find World Writable Files (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -0002 -print\n    changed_when: False\n    failed_when: False\n    register: world_files\n    tags:\n      - section12\n      - section12.7\n\n  - name: 12.7 Find World Writable Files (Not Scored)\n    debug: msg=\"{{ item }}\"\n    with_items:\n        world_files.stdout_lines\n    tags:\n      - section12\n      - section12.7\n\n  - name: 12.8 Find Un-owned Files and Directories (check) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -nouser -ls\n    changed_when: False\n    failed_when: False\n    register: unowned_files\n    tags:\n      - section12\n      - section12.8\n\n  - name: 12.8 Find Un-owned Files and Directories (Scored)\n    debug: msg=\"{{ item }}\"\n    with_items:\n        unowned_files.stdout_lines\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.9 Find Un-grouped Files and Directories (check) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -nogroup -ls\n    changed_when: False\n    failed_when: False\n    register: ungrouped_files\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.9 Find Un-grouped Files and Directories (Scored)\n    debug: >\n        msg=\"{{ item }}\"\n    with_items:\n        ungrouped_files.stdout_lines\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.10 Find SUID System Executables (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -4000 -print\n    changed_when: False\n    failed_when: False\n    register: suid_files\n    tags:\n      - section12\n      - section12.10\n\n  - name: 12.10 Find SUID System Executables (Not Scored)\n    debug: msg=\"{{ item }}\"\n    with_items:\n        suid_files.stdout_lines\n    tags:\n      - section12\n      - section12.10\n\n  - name: 12.11 Find SGID System Executables (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -2000 -print\n    changed_when: False\n    failed_when: False\n    register: gsuid_files\n    tags:\n      - section12\n      - section12.11\n\n  - name: 12.11 Find SGID System Executables (Not Scored)\n    debug: msg=\"{{ item }}\"\n    with_items:\n        gsuid_files.stdout_lines\n    tags:\n      - section12\n      - section12.10\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "3d7e271c6e2e565d4345ed8bad84ea07ebd2ed90", "filename": "roles/httpd/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Install httpd required packages\n  package: name={{ item }}\n           state=present\n  with_items:\n    - apache2\n    - php{{ php_version }}\n    - php{{ php_version }}-curl\n#    - php{{ php_version }}-sqlite\n  tags:\n    - download\n  when: is_debian\n\n- name: Debian changed sqlite name\n  package: name=php{{ php_version }}-sqlite\n  when: is_debian and ansible_distribution_major_version == \"8\"\n\n#- name: Debian changed sqlite name\n#  package: name=php{{ php_version }}-sqlite3\n#  when: ansible_local.local_facts.os_ver == \"debian-9\"\n\n-  name: Install httpd required packages\n   package: name={{ item }}\n            state=present\n   with_items:\n     - apache2\n     - php\n   tags:\n     - download\n   when: is_ubuntu\n\n- name: Install httpd required packages\n  package: name={{ item }}\n           state=present\n  with_items:\n    - httpd\n    - php\n    - php-curl\n#    - php-sqlite\n  tags:\n    - download\n  when: is_redhat\n\n- name: remove the default apache2 config file\n  file: path=/etc/apache2/sites-enabled/000-default.conf\n        src=/etc/apache2/sites-available/000-default.conf\n        state=absent\n  when: is_debuntu\n\n- name: Create httpd config files\n  template: backup=yes\n            src={{ item.src }}\n            dest={{ item.dest }}\n            owner=root\n            group=root\n            mode={{ item.mode }}\n  with_items:\n      - { src: '010-iiab.conf.j2' , dest: '/etc/{{ apache_config_dir }}/010-iiab.conf', mode: '0755' }\n      - { src: 'proxy_ajp.conf.j2' , dest: '/etc/{{ apache_config_dir }}/proxy_ajp.conf', mode: '0644' }\n      - { src: 'php.ini.j2' , dest: '/etc/php.ini' , mode: '0644' }\n\n# remove symlinks for mpm-event, replace with mpm-prefork\n- name: Remove mpm event links\n  file: path=/etc/apache2/mods-enabled/{{ item }}\n        state=absent\n  with_items:\n      - mpm_event.conf\n      - mpm_event.load\n  when: is_debuntu\n\n- name: create symlinks for mpm-prefork\n  file: path=/etc/apache2/mods-enabled/{{ item }}\n        src=/etc/apache2/mods-available/{{ item }}\n        state=link\n  with_items:\n      - mpm_prefork.conf\n      - mpm_prefork.load\n  when: is_debuntu\n\n- name: turn on mod_proxy\n  command: a2enmod {{ item }}\n  with_items:\n     - proxy\n     - proxy_html\n     - headers\n     - rewrite\n  when: is_debuntu\n\n- name: create symlinks for enabling our site\n  file: path=/etc/apache2/sites-enabled/{{ item }}\n        src=/etc/apache2/sites-available/{{ item }}\n        state=link\n  with_items:\n      - 010-iiab.conf\n  when: is_debuntu\n\n- name: Remove the default site container\n  file: dest=/etc/apache2/000-default.conf\n        state=absent\n  when: is_debuntu\n\n- name: Create http pid dir\n  file: path=/var/run/{{ apache_user }}\n        mode=0755\n        owner=root\n        group=root\n        state=directory\n\n- name: create admin group\n  group: name=admin\n         state=present\n\n- name: Add apache user to admin group\n  user: name={{ apache_user }}\n        groups=admin\n        state=present\n        createhome=no\n\n- name: Create httpd log dir\n  file: path=/var/log/{{ apache_service }}\n        mode=0755\n        owner={{ apache_user }}\n        group={{ apache_user }}\n        state=directory\n\n- name: Enable httpd\n  service: name={{ apache_service }}\n           enabled=yes\n\n- name: Create iiab-info directory\n  file: path={{ doc_root }}/info\n        mode=0755\n        owner={{ apache_user }}\n        group={{ apache_user }}\n        state=directory\n\n- name: Remove iiab-info.conf\n  file: dest=/etc/{{ apache_config_dir }}/iiab-info.conf\n        state=absent\n\n- name: Remove iiab-info.conf symlink\n  file: dest=/etc/apache2/sites-enabled/iiab-info.conf\n        state=absent\n  when: is_debuntu\n\n- include: html.yml\n  tags:\n    - base\n\n- include: home-page.yml\n\n- name: place the script to generate home pages\n  template: src=refresh-wiki-docs.sh\n            dest=/usr/bin/iiab-refresh-wiki-docs\n            mode=0755\n\n- name: Give apache_user permission for poweroff\n  template: src=020_apache_poweroff.j2\n            dest=/etc/sudoers.d/020_apache_poweroff\n            mode=0755\n  when: allow_apache_sudo\n\n- name: Remove apache_user permission for poweroff\n  file: dest=/etc/sudoers.d/020_apache_poweroff\n        state=absent\n  when: not allow_apache_sudo\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "b569af4e75ddd44626370273342cae1e0702f2dc", "filename": "roles/dns/manage-dns-zones/tasks/named/process-views.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Ensure the final view directory exists\n  file:\n    path: \"{{ dns_zone_temp_config_dir }}/view\"\n    state: directory\n\n- include_tasks: process-zones.yml\n  with_items:\n    -  \"{{ dns_data.views }}\"\n  loop_control:\n    loop_var: \"view\"\n\n- name: Assemble the final view configuration\n  assemble:\n    src: \"{{ dns_zone_temp_config_dir }}/view\"\n    dest: \"/etc/named/named.conf.view\"\n  notify: restart named\n\n- name: Setup ACLs\n  vars:\n    named_views: \"{{ dns_data.views }}\"\n  template:\n    src: named/acl.j2\n    dest: /etc/named/named.conf.acl\n    owner: named\n    group: named\n    mode: 0660\n  notify: restart named\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "c442458972b469a08427d021b2a17d8f59771707", "filename": "roles/config-idm-server/tasks/prep.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Install required packages'\n  package:\n    name: '{{ item }}'\n    state: installed\n  with_items:\n  - ipa-server\n  - firewalld\n  - python-firewall\n\n- name: 'Ensure firewalld is running'\n  service:\n    name: firewalld\n    state: started\n    enabled: yes\n\n- name: 'Open Firewall for IdM use'\n  firewalld:\n    service: \"{{ item }}\"\n    permanent: yes\n    state: enabled\n    immediate: yes\n  with_items:\n  - ntp\n  - http \n  - https\n  - ldap\n  - ldaps\n  - kerberos\n  - kpasswd\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "0974b1defb8cb3b6c44a247802e2e448d24c64eb", "filename": "roles/config-linux-desktop/config-mate/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Install, configure and enable MATE Desktop\"\n  include_tasks: \"{{ distro_file }}\"\n  with_first_found:\n  - files:\n    - mate-{{ ansible_distribution }}.yml\n    skip: true\n  loop_control:\n    loop_var: distro_file\n  when:\n  - mate_install|default(False)\n\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "1d513f0bd12afb752197f30cc01002c4ba1d453b", "filename": "roles/config-quay-enterprise/tasks/firewall.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Check if firewalld is installed\n  command: systemctl status firewalld\n  register: firewalld_status\n  failed_when: false\n  changed_when: false\n\n- name: Check if iptables is installed\n  command: systemctl status iptables\n  register: iptables_status\n  failed_when: false\n  changed_when: false\n\n- name: Open port in firewalld\n  firewalld:\n    port: \"{{ item }}/TCP\"\n    permanent: true\n    state: enabled\n  when: firewalld_status.rc == 0\n  with_items:\n    - \"{{ quay_http_port }}\"\n    - \"{{ quay_https_port }}\"\n  notify:\n  - restart firewalld\n\n- name: Ensure iptables is correctly configured \n  lineinfile:\n    insertafter: \"^-A INPUT .* --dport {{ item }} .* ACCEPT\"\n    state: present\n    dest: /etc/sysconfig/iptables\n    regexp: \"^-A INPUT .* --dport {{ item }} .* ACCEPT\"\n    line: \"-A INPUT -p TCP -m state --state NEW -m TCP --dport {{ item }} -j ACCEPT\"\n  with_items:\n    - \"{{ quay_http_port }}\"\n    - \"{{ quay_https_port }}\"\n  when: iptables_status.rc == 0 and firewalld_status.rc != 0 \n  notify:\n  - restart iptables\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "f4bc8fcbbfe52b3e73b5f65f2c47957e08d898b0", "filename": "roles/manage-jira/tasks/create_project_category.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Create Jira Project Category\n  uri:\n    url: \"{{ jira_url }}/rest/api/2/projectCategory\"\n    method: POST\n    user: \"{{ jira_username }}\"\n    password: \"{{ jira_password }}\"\n    return_content: yes\n    force_basic_auth: yes\n    body_format: json\n    header:\n      - Accept: 'application/json'\n      - Content-Type: 'application/json'\n    body: \"{ 'name': '{{ atlassian.jira.project.category_name }}',\n              'description': '{{ atlassian.jira.project.category_description }}' }\"\n    status_code: 201\n  register: category\n\n- name: Set fact for Category ID\n  set_fact:\n    CategoryID: \"{{ category.json.id }}\"\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "a9420601f248a200ad9261db79816d15be25030e", "filename": "roles/serverspec/meta/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\ngalaxy_info:\n  author: your name\n  description:\n  company: Capgemini\n  # If the issue tracker for your role is not on github, uncomment the\n  # next line and provide a value\n  # issue_tracker_url: http://example.com/issue/tracker\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (GPLv2, CC-BY, etc)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  #platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  #- name: Ubuntu\n  #  versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n  #  - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  #categories:\n  #- cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  #- system\n  #- web\ndependencies: []\n  # List your role dependencies here, one per line.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "18245501e1d7c9b159a258e546e94e0bef377d0c", "filename": "roles/dns/manage-dns-records/tests/inventory/group_vars/all.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ndns_records_rm:\n- view: private\n  zone: first.example.com\n  server: \"192.168.48.26\"\n  key_name: \"private-first.example.com\"\n  key_secret: \"EhZfRtlHgy7xTIi2LeVSGsBj99Sb8IGB6K30ovg13dE=\"\n  key_algorithm: \"hmac-sha256\"\n  entries:\n  - type: A\n    record: master\n    value: 172.16.10.19\ndns_records_add:\n- view: private\n  zone: first.example.com\n  server: \"192.168.48.26\"\n  key_name: \"private-first.example.com\"\n  key_secret: \"EhZfRtlHgy7xTIi2LeVSGsBj99Sb8IGB6K30ovg13dE=\"\n  key_algorithm: \"hmac-sha256\"\n  entries:\n  - type: A\n    record: master\n    value: 172.16.10.20\n  - type: A\n    record: node1\n    value: 172.16.10.20\n  - type: A\n    record: node2\n    value: 172.16.10.21\n  - type: A\n    record: node3\n    value: 172.16.10.22\n- view: private\n  zone: second.example.com\n  server: \"192.168.48.26\"\n  key_name: \"private-second.example.com\"\n  key_secret: \"+UYdpSzdQyZ20V9/2Ud9RjHFz9Pouqn4aXP3V9X/gq4=\"\n  key_algorithm: \"hmac-sha256\"\n  entries:\n  - type: A\n    record: master\n    value: 172.17.10.20\n  - type: A\n    record: node1\n    value: 172.17.10.20\n  - type: A\n    record: node2\n    value: 172.17.10.21\n- view: public\n  zone: first.example.com\n  server: \"192.168.48.26\"\n  key_name: \"public-first.example.com\"\n  key_secret: \"5RZv5wMtKS/fZtjtc2bXS2s6L5+cXN2x53jSkEtwNjk=\"\n  key_algorithm: \"hmac-sha256\"\n  entries:\n  - type: A\n    record: master\n    value: 10.9.77.20\n  - type: A\n    record: node1\n    value: 10.9.77.20\n  - type: A\n    record: node2\n    value: 10.9.77.21\n  - type: A\n    record: node3\n    value: 10.9.77.22\n- view: public\n  zone: second.example.com\n  server: \"192.168.48.26\"\n  key_name: \"public-second.example.com\"\n  key_secret: \"7VKvn5iZ64l+s42XT/hllJSxS6CjE3369tOy85vkBk4=\"\n  key_algorithm: \"hmac-sha256\"\n  entries:\n  - type: A\n    record: master\n    value: 10.8.88.20\n  - type: A\n    record: node1\n    value: 10.8.88.20\n  - type: A\n    record: node2\n    value: 10.8.88.21\n"}, {"commit_sha": "ccab58ae5d697bb64abd86558f79c34161d2fb00", "sha": "6c3026dc1d7482b511ac90db4c17f1e751621c3e", "filename": "tasks/httpd_reverse_proxy_config.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n\n- name: Copy {{ httpd_package_name }} vhost\n  template:\n    src: \"nexus-vhost.conf\"\n    dest: \"{{ httpd_config_dir }}\"\n  notify:\n    - httpd-service-reload\n    - wait-for-httpd\n\n- name: Copy SSL certificate and optional chain file\n  copy:\n    src: \"{{ item }}\"\n    dest: \"{{ certificate_file_dest }}\"\n    mode: 0600\n  when: (httpd_copy_ssl_files | bool) and (item | length > 0)\n  notify:\n    - httpd-service-reload\n    - wait-for-httpd\n  loop: \"{{ [httpd_ssl_certificate_file] + [httpd_ssl_certificate_chain_file | default()] | unique }}\"\n\n- name: Copy SSL certificate key file\n  copy:\n    src: \"{{ httpd_ssl_certificate_key_file }}\"\n    dest: \"{{ certificate_key_dest }}\"\n    mode: 0600\n  when: httpd_copy_ssl_files | bool\n  notify:\n    - httpd-service-reload\n    - wait-for-httpd\n\n- name: Setsebool httpd_can_network_connect\n  seboolean:\n    name: httpd_can_network_connect\n    persistent: yes\n    state: yes\n  when: ansible_selinux.status is defined and ansible_selinux.status == \"enabled\"\n\n- meta: flush_handlers\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "4d9d5227eeea1768b784718fbdc5142f01078b0b", "filename": "roles/cups/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "cups_install: True\ncups_enabled: False\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "3c8c5d870ead6131ed56e07e002756cac436a67a", "filename": "roles/setup-slack/tasks/create_channels.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Create channel\n  uri:\n    url: \"https://slack.com/api/channels.create?token={{ slack_token }}&name={{ channel.name }}\"\n    method: GET\n    status: [200]\n    return_content: yes\n  register: channel_data\n  when: channel.private == False\n\n- name: Create group\n  uri:\n    url: \"https://slack.com/api/groups.create?token={{ slack_token }}&name={{ channel.name }}\"\n    method: GET\n    status: [200]\n    return_content: yes\n  register: channel_data\n  when: channel.private == True\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "eda1098472e94d786e91e01acadb23d50275e20c", "filename": "roles/users/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Ensure sudo group is present\n  group:\n    name: sudo\n    state: present\n\n- name: Ensure sudo group has sudo privileges\n  lineinfile:\n    dest: /etc/sudoers\n    state: present\n    regexp: \"^%sudo\"\n    line: \"%sudo ALL=(ALL:ALL) ALL\"\n    validate: \"/usr/sbin/visudo -cf %s\"\n\n- name: Fail if root login will be disabled but admin_user will not be a sudoer\n  assert:\n    that:\n      - \"{% for user in users if user.name == admin_user %}{% if loop.first %}{{ 'sudo' in user.groups }}{% endif %}{% else %}{{ false }}{% endfor %}\"\n      - \"{% for user in vault_users | default([]) if user.name == admin_user %}{% if loop.first %}{{ user.password is defined }}{% endif %}{% else %}{{ false }}{% endfor %}\"\n    msg: |\n      When `sshd_permit_root_login: false`, you must add `sudo` to the `groups` for admin_user (in `users` hash), and set a password for admin_user in `vault_users` (in `group_vars/{{ env }}/vault.yml`). Otherwise Ansible could lose the ability to run the necessary sudo commands. {% if sudoer_passwords is defined or vault_sudoer_passwords is defined %}\n\n\n      Please note that `sudoer_passwords` and `vault_sudoer_passwords have been replaced with `vault_users`. {% endif %}\n      More info:\n      > https://roots.io/trellis/docs/security/#admin-user-sudoer-password\n  when: not sshd_permit_root_login\n  tags: sshd\n\n- name: Setup users\n  user:\n    name: \"{{ item.name }}\"\n    group: \"{{ item.groups[0] }}\"\n    groups: \"{{ item.groups | join(',') }}\"\n    password: '{% for user in vault_users | default([]) if user.name == item.name and user.password is defined %}{% if loop.first %}{{ user.password | password_hash(\"sha512\", user.salt[:16] | default(None) | regex_replace(\"[^\\.\\/a-zA-Z0-9]\", \"x\")) }}{% endif %}{% else %}{{ None }}{% endfor %}'\n    state: present\n    shell: /bin/bash\n    update_password: always\n  with_items: \"{{ users }}\"\n\n- name: Add web user sudoers items for services\n  template:\n    src: sudoers.d.j2\n    dest: \"/etc/sudoers.d/{{ web_user }}-services\"\n    mode: 0440\n    owner: root\n    group: root\n    validate: \"/usr/sbin/visudo -cf %s\"\n  when: web_sudoers\n\n- name: Add SSH keys\n  authorized_key:\n    user: \"{{ item.0.name }}\"\n    key: \"{{ item.1 }}\"\n  with_subelements:\n    - \"{{ users | default([]) }}\"\n    - keys\n\n- name: Check whether Ansible can connect as admin_user\n  local_action: command ansible {{ inventory_hostname }} -m ping -u {{ admin_user }} {{ cli_options | default('') }}\n  failed_when: false\n  changed_when: false\n  become: no\n  register: admin_user_status\n  when: (ansible_user != admin_user and not sshd_permit_root_login) or (cli_ask_pass and not sshd_password_authentication)\n  tags: [connection-tests, sshd]\n\n- include: connection-warnings.yml\n  when: admin_user_status | failed\n  tags: [connection-tests, sshd]\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "479251ab3723b37d483f3f1dea513f6e2c00837e", "filename": "roles/network/templates/named/named.local", "repository": "iiab/iiab", "decoded_content": "$TTL\t86400\n@       IN      SOA     localhost. root.localhost.  (\n                                      1997022700 ; Serial\n                                      28800      ; Refresh\n                                      14400      ; Retry\n                                      3600000    ; Expire\n                                      86400 )    ; Minimum\n        IN      NS      localhost.\n1       IN      PTR     localhost.\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "dfad4e4616b660ee5a6f6f66f53a85963c4eea9e", "filename": "playbooks/container-registry/quay-enterprise.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Install Quay Enterprise\n  hosts: quay_enterprise\n  tasks:\n    - name: Configure Docker\n      include_role:\n        name: config-container-storage-setup\n      when: docker_install|default(false)\n\n    - name: Install Docker\n      include_role:\n        name: config-docker\n      when: docker_install|default(false)\n\n    - name: Include Quay Role\n      include_role:\n        name: config-quay-enterprise\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "1551150dc2a302e3e6abbd96f030a84592b4b25a", "filename": "roles/config-repo-server/tasks/mount-iso.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Ensure the ISO mount dir exist\"\n  file:\n    path: \"{{ item.iso_file_target }}\"\n    state: directory\n  with_items:\n  - \"{{ hosted_isos }}\"\n\n- name: \"Mount the ISOs\"\n  mount:\n    path: \"{{ item.iso_file_target }}\"\n    src: \"{{ item.iso_file_path }}\"\n    fstype: iso9660\n    state: mounted\n  with_items:\n  - \"{{ hosted_isos }}\"\n\n\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "61fd7b40f571337ec2bc88611abdb2e2c3a589a4", "filename": "roles/config-packages/tests/inventory/group_vars/all.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nlist_of_packages_to_install:\n - 'vim'\n - 'git'\n - 'ansible'\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "8bbb2e41081d489f35eea8025e554529b7f8b699", "filename": "examples/playbooks/iso_uploader_conf.yaml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\n# example playbook set ISO uploader username and password\n# use with examples/inventory/iso_uploader_conf.inv\n- hosts: iso-uploader-host\n  remote_user: root\n  roles:\n    - {role: ovirt-iso-uploader-conf}\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "1468f93db4b0eaaffc19ba2123bcbb804c1d8252", "filename": "roles/dns/manage-dns-zones-route53/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: determine-action.yml\n\n- block:\n    - import_tasks: prereq.yml\n    - import_tasks: get-zone-records.yml\n    - import_tasks: process-views.yml\n  when:\n    - route53_processing|bool == True\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "9e5461d2facf950f7f3c6aba477fc3e3166e7b7f", "filename": "roles/client/tasks/systems/Debian.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- set_fact:\n    prerequisites: []\n    configs_prefix: /etc/\n"}, {"commit_sha": "3c4d272a77f8aaeb300c8b841bb7e6d8dbd76c1f", "sha": "e590cc27c3e9d17b4819e3378de4964ad39d9679", "filename": "tasks/debian/main.yml", "repository": "ansiblebit/oracle-java", "decoded_content": "---\n# file: oracle-java/tasks/debian/main.yml\n#\n# Task file to install Oracle Java Development Kit in a system with a Debian based Linux distribution.\n#\n\n- name: accept Oracle license\n  shell: \"echo oracle-java{{ oracle_java_version }}-installer shared/accepted-oracle-license-v1-1 select true | sudo /usr/bin/debconf-set-selections\"\n  changed_when: no\n  sudo: yes\n\n- name: ensure Java is installed\n  apt:\n    name=\"oracle-java{{ oracle_java_version }}-installer\"\n    state={{ oracle_java_state }}\n    cache_valid_time={{ oracle_java_cache_valid_time }}\n    update_cache=yes\n  register: oracle_java_task_apt_install\n  sudo: yes\n\n- name: set Java version as default\n  apt:\n    name=\"oracle-java{{ oracle_java_version }}-set-default\"\n    state=latest\n  register: oracle_java_task_set_default\n  when: oracle_java_set_as_default\n  sudo: yes\n\n- name: in case there were changes, check host environment again\n  include: ../check_environment.yml\n  when: oracle_java_task_apt_install|changed or oracle_java_task_set_default|changed\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "920fd837d21f98293990f9d509e08a18e59a8b2a", "filename": "roles/haproxy/tasks/prereq.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Install required packages'\n  package:\n    name: '{{ item }}'\n    state: installed\n  with_items:\n  - haproxy\n  - openssl-devel\n  - firewalld\n  - python-firewall\n  - libsemanage-python\n  notify: 'enable and start service(s)'\n\n- name: 'Start firewalld'\n  service: \n    name: firewalld\n    state: started\n    enabled: yes\n\n- name: 'Open Firewall for HAproxy use'\n  firewalld: \n    port: \"{{item}}\"\n    permanent: yes\n    state: enabled\n    immediate: yes\n  with_items:\n  - 80/tcp\n  - 443/tcp\n  - 8443/tcp\n\n- name: 'Enable syslog logging' \n  copy:\n    src: rsyslog_haproxy.conf\n    dest: /etc/rsyslog.d/haproxy.conf\n  notify: 'restart rsyslog'\n\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "093d3212a62559ba8511915c4b918340136d9383", "filename": "roles/wordpress-install/tasks/directories.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Create web root of sites\n  file:\n    path: \"{{ www_root }}/{{ item.key }}/{{ item.value.current_path | default('current') }}/web\"\n    owner: \"{{ web_user }}\"\n    group: \"{{ web_group }}\"\n    mode: 0755\n    state: directory\n  with_dict: \"{{ wordpress_sites }}\"\n\n- name: Create shared folder of sites\n  file:\n    path: \"{{ www_root }}/{{ item.key }}/shared\"\n    owner: \"{{ web_user }}\"\n    group: \"{{ web_group }}\"\n    mode: 0755\n    state: directory\n  with_dict: \"{{ wordpress_sites }}\"\n\n- name: Change site owner to user\n  file:\n    path: \"{{ www_root }}/{{ item.key }}\"\n    owner: \"{{ web_user }}\"\n    group: \"{{ web_group }}\"\n    state: directory\n    recurse: yes\n  with_dict: \"{{ wordpress_sites }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "37b0494e43015945e34470aebb48fef88dedaa14", "filename": "roles/config-ipa-client/tasks/prereq-Fedora.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Install additional packages for IPA/IdM\"\n  package:\n    name: \"{{ item }}\"\n    state: latest\n  with_items:\n  - ipa-client\n  - libsss_sudo\n  - sssd-nfs-idmap\n  - libselinux-python\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "53e586ecaa4c2a73249f70e78aa6e6a9c3955e6c", "filename": "playbooks/templates/fsf-client-config.j2", "repository": "rocknsm/rock", "decoded_content": "#!/usr/bin/env python\n#\n# Basic configuration attributes for scanner client.\n#\n\n# 'IP Address' is a list. It can contain one element, or more.\n# If you put multiple FSF servers in, the one your client chooses will\n# be done at random. A rudimentary way to distribute tasks.\nSERVER_CONFIG = { 'IP_ADDRESS' : ['localhost',],\n                  'PORT' : 5800 }\n\n# Full path to debug file if run with --suppress-report\nCLIENT_CONFIG = { 'LOG_FILE' : '{{ fsf_client_logfile }}' }\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "7de2c790ae28e7122495e3277cde460192feb7d6", "filename": "roles/samba/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "---\n  smbuser : smbuser\n  smbpassword : $6$51iiab$VXzRJK88k9k8SXd5sjs37bEbVQ9x4ob1ng7A5PSGyoVXTKQrhu.89BRuXZAgn8a2DPqZkKDcCpqCZVOs.cieT/ \n#  python -c 'import crypt; print crypt.crypt(\"smbpw\", \"$6$51iiab\")'\n  shared_dir : /library/public\n  samba_enabled : false\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "8ffd19b4b7e0a1d1d5ba2cac310f5d3b20ef5d42", "filename": "roles/config-vnc-server/tasks/prereq.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Install required packages'\n  package:\n    name: '{{ item }}'\n    state: installed\n  with_items:\n  - firewalld\n  - python-firewall\n\n- name: 'Ensure firewalld is running'\n  service:\n    name: firewalld\n    state: started\n    enabled: yes\n\n- name: 'Open Firewall for NFS use'\n  firewalld:\n    port: \"{{ item }}\"\n    permanent: yes\n    state: enabled\n    immediate: yes\n  with_items:\n  - 5900/tcp\n  - 5901/tcp\n  - 5902/tcp\n  - 5903/tcp\n  - 5904/tcp\n  - 5905/tcp\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "54752e5c08fa93ab74e5be024783cbc3bd97aa8a", "filename": "roles/manage-jira/tasks/create_project.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Create Jira Project\n  uri:\n    url: \"{{ jira_url }}/rest/api/2/project\"\n    method: POST\n    user: \"{{ jira_username }}\"\n    password: \"{{ jira_password }}\"\n    return_content: yes\n    force_basic_auth: yes\n    body_format: json\n    header:\n      - Accept: 'application/json'\n      - Content-Type: 'application/json'\n    body: \"{ 'key': '{{ atlassian.jira.project.key }}',\n             'name': '{{ atlassian.jira.project.name }}',\n             'projectTypeKey': '{{ atlassian.jira.project.type_key | default('software')}}',\n             'projectTemplateKey': '{{ atlassian.jira.project.template_key | default('com.pyxis.greenhopper.jira:gh-simplified-scrum')}}',\n             'description': '{{ atlassian.jira.project.description }}',\n             'lead': '{{ atlassian.jira.lead }}',\n             'assigneeType': 'PROJECT_LEAD',\n             'avatarId': 10200,\n             'permissionScheme': '{{ atlassian.jira.permission_scheme.id | default(PermissionScheme) }}',\n             'notificationScheme': 10000, \n             'categoryId': '{{ CategoryID }}' \n           }\"\n    status_code: 201         \n  register: result\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "2dddc1a488b704a2c24616a54e1242ec0417b989", "filename": "roles/user-management/manage-users/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: create_user.yml\n\n- import_tasks: create_group.yml\n\n- include_tasks: add_user_to_group.yml\n  with_items: \"{{ user_groups }}\"\n  loop_control:\n    loop_var: \"this_group\"\n\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "396bc5df4cdc019131e34ada58fc99ea2cbfa814", "filename": "roles/virt-install/tasks/prereq.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Install required packages'\n  package:\n    name: '{{ item }}'\n    state: installed\n  with_items:\n  - virt-install\n  - httpd\n\n- name: 'Enable and start libvirtd'\n  service:\n    name: libvirtd\n    enabled: yes\n    state: started\n\n- name: 'Enable and start httpd'\n  service:\n    name: httpd\n    enabled: no\n    state: started\n\n- name: 'Enable and start firewalld'\n  service:\n    name: firewalld\n    enabled: yes\n    state: started\n\n- name: 'Ensure firewalld is open for httpd traffic'\n  firewalld:\n    service: http\n    state: enabled\n    permanent: no\n    immediate: yes\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "b2f222b6ac2e3fa11aa9f97a93e3ba26f6e0ac8a", "filename": "roles/ovirt-engine-setup/meta/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\ngalaxy_info:\n  author: \"Petr Kubica\"\n  description: \"oVirt setup installer\"\n  company: \"Red Hat\"\n  license: \"GPLv3\"\n  min_ansible_version: 1.9\n  platforms:\n  - name: EL\n    versions:\n    - all\n  galaxy_tags:\n    - installer\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "2e224c13dd35db7447721f579e25873637fb6f44", "filename": "docs/ansible-roles.md", "repository": "trailofbits/algo", "decoded_content": "# Ansible Roles\n\n## Required roles\n\n* **Common**\n  * Installs several required packages and software updates, then reboots if necessary\n  * Configures network interfaces, and enables packet forwarding on them\n* **VPN**\n  * Installs [strongSwan](https://www.strongswan.org/), enables AppArmor, limits CPU and memory access, and drops user privileges\n  * Builds a Certificate Authority (CA) with [easy-rsa-ipsec](https://github.com/ValdikSS/easy-rsa-ipsec) and creates one client certificate per user\n  * Bundles the appropriate certificates into Apple mobileconfig profiles for each user\n  * Configures IPtables to block traffic that might pose a risk to VPN users, such as [SMB/CIFS](https://medium.com/@ValdikSS/deanonymizing-windows-users-and-capturing-microsoft-and-vpn-accounts-f7e53fe73834)\n\n## Optional roles\n\n* **Security Enhancements**\n  * Enables [unattended-upgrades](https://help.ubuntu.com/community/AutomaticSecurityUpdates) to ensure available patches are always applied\n  * Modify features like core dumps, kernel parameters, and SUID binaries to limit possible attacks\n  * Enhances SSH with modern ciphers and seccomp, and restricts access to old or unwanted features like X11 forwarding and SFTP\n* **Proxy-based Adblocking and Compression**\n  * Installs [Privoxy](https://www.privoxy.org/) with an ad blocking ruleset\n  * Installs Apache with [mod_pagespeed](http://modpagespeed.com/) as an HTTP proxy\n  * Constrains Privoxy and Apache with AppArmor and cgroups CPU and memory limitations\n* **DNS-based Adblocking**\n  * Install the [dnsmasq](http://www.thekelleys.org.uk/dnsmasq/doc.html) local resolver with a blacklist for advertising domains\n  * Constrains dnsmasq with AppArmor and cgroups CPU and memory limitations\n* **SSH Tunneling**\n  * Adds a restricted `algo` group with no shell access and limited SSH forwarding options\n  * Creates one limited, local account per user and an SSH public key for each\n"}, {"commit_sha": "a94f9ce4fa32273fd0fad7492d36db4101423cc3", "sha": "3bb50e06a06b157c128e62b26b5c35c04d7cf1ea", "filename": "tasks/lvm-thinpool.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "- name: Create LVM volume group\n  become: true\n  lvg:\n    pvs: '{{ pool.physical_volumes }}'\n    state: present\n    vg: '{{ pool.volume_group }}'\n  when: pool.physical_volumes|default(None)\n\n- name: Check if data volume exists\n  become: true\n  stat:\n    path: '/dev/mapper/{{ pool.volume_group }}-{{ pool.name }}'\n  ignore_errors: true\n  register: _volume\n\n- name: Create data volume\n  become: true\n  lvol:\n    lv: '{{ pool.name }}'\n    size: '{{ pool.data_size }}'\n    vg: '{{ pool.volume_group }}'\n  register: _datavolume_created\n  when: not _volume.stat.exists\n\n- name: Create meta data volume\n  become: true\n  lvol:\n    lv: '{{ pool.name }}meta'\n    size: '{{ pool.metadata_size }}'\n    vg: '{{ pool.volume_group }}'\n  when: _datavolume_created | changed\n\n- name: Convert data volume to thinpool\n  become: true\n  shell:\n    lvconvert\n        -y\n        --zero n\n        -c 512K\n        --thinpool \"{{ pool.volume_group }}/{{ pool.name }}\"\n        --poolmetadata \"{{ pool.volume_group }}/{{ pool.name }}meta\"\n  when: _datavolume_created | changed"}, {"commit_sha": "045ff4bb9f4720739632aac2951fbf2798a99c8c", "sha": "9339113c788c19e69895e392c76c28e7596f443f", "filename": "roles/cloud-gce/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "- set_fact:\n    credentials_file_path: \"{{ credentials_file | default(lookup('env','GCE_CREDENTIALS_FILE_PATH')) }}\"\n    ssh_public_key_lookup: \"{{ lookup('file', '{{ SSH_keys.public }}') }}\"\n\n- set_fact:\n    credentials_file_lookup: \"{{ lookup('file', '{{ credentials_file_path }}') }}\"\n\n- set_fact:\n    service_account_email: \"{{ credentials_file_lookup.client_email | default(lookup('env','GCE_EMAIL')) }}\"\n    project_id: \"{{ credentials_file_lookup.project_id | default(lookup('env','GCE_PROJECT')) }}\"\n\n- name: \"Creating a new instance...\"\n  gce:\n    instance_names: \"{{ server_name }}\"\n    zone: \"{{ zone }}\"\n    machine_type: f1-micro\n    image: ubuntu-1604\n    service_account_email: \"{{ service_account_email  }}\"\n    credentials_file: \"{{ credentials_file_path  }}\"\n    project_id: \"{{ project_id  }}\"\n    metadata: '{\"sshKeys\":\"root:{{ ssh_public_key_lookup }}\"}'\n    tags:\n      - \"environment-algo\"\n  register: google_vm\n\n- name: Add the instance to an inventory group\n  add_host:\n    name: \"{{ google_vm.instance_data[0].public_ip }}\"\n    groups: vpn-host\n    ansible_ssh_user: ubuntu\n    ansible_python_interpreter: \"/usr/bin/python2.7\"\n    ansible_ssh_private_key_file: \"{{ SSH_keys.private }}\"\n    cloud_provider: gce\n    ipv6_support: no\n\n- name: Firewall configured\n  local_action:\n    module: gce_net\n    name: \"{{ google_vm.instance_data[0].network }}\"\n    fwname: \"algo-ikev2\"\n    allowed: \"udp:500,4500;tcp:22\"\n    state: \"present\"\n    src_range: 0.0.0.0/0\n    service_account_email: \"{{ credentials_file_lookup.client_email }}\"\n    credentials_file: \"{{ credentials_file  }}\"\n    project_id: \"{{ credentials_file_lookup.project_id }}\"\n\n- set_fact:\n    cloud_instance_ip: \"{{ google_vm.instance_data[0].public_ip }}\"\n\n- name: Ensure the group gce exists in the dynamic inventory file\n  lineinfile:\n    state: present\n    dest: configs/inventory.dynamic\n    line: '[gce]'\n\n- name: Populate the dynamic inventory\n  lineinfile:\n    state: present\n    dest: configs/inventory.dynamic\n    insertafter: '\\[gce\\]'\n    regexp: \"^{{ google_vm.instance_data[0].public_ip }}.*\"\n    line: \"{{ google_vm.instance_data[0].public_ip }}\"\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "1e7dcfe42ba1b5fe50a12bb89ad8371bd09ec23f", "filename": "playbooks/files/profile.d-kibanapw.sh", "repository": "rocknsm/rock", "decoded_content": "# Set passwords\nfunction kibanapw() { if [ $# -lt 2 ]; then echo -e \"Usage: kibanapw USER PASSWORD\\nUsers will be added to /etc/nginx/.htpasswd\"; else egrep \"^${1}:\" /etc/nginx/.htpasswd > /dev/null 2>&1; if [[ $? -eq 0 ]]; then sudo sed -i \"/${1}\\:/d\" /etc/nginx/.htpasswd; fi; printf \"${1}:$(echo ${2} | openssl passwd -apr1 -stdin)\\n\" | sudo tee -a /etc/nginx/.htpasswd > /dev/null 2>&1; fi; }\n\n# Enable Auth\nfunction enable_kibana_auth() { sudo sed -i 's/#auth_basic/auth_basic/g' /etc/nginx/conf.d/rock.conf; }\n\n# Disable Auth\nfunction disable_kibana_auth() { sudo sed -i 's/auth_basic/#auth_basic/g' /etc/nginx/conf.d/rock.conf; }\n"}, {"commit_sha": "8c72df4ecfaa4188202ab0872f4500384ffe5233", "sha": "9f5f97689499ceb3289e7a21e6a647035bfdd90e", "filename": "tasks/main.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Set distribution facts\n  set_fact:\n    _docker_os_dist: \"{{ ansible_distribution }}\"\n    _docker_os_dist_release: \"{{ ansible_distribution_release }}\"\n    _docker_os_dist_major_version: \"{{ ansible_distribution_major_version }}\"\n    _docker_os_dist_check: yes\n  tags: [\"install\", \"configure\"]\n\n- name: Reinterpret distribution facts for Linux Mint 18\n  set_fact:\n    _docker_os_dist: \"Ubuntu\"\n    _docker_os_dist_release: \"xenial\"\n    _docker_os_dist_major_version: \"16\"\n  when:\n    _docker_os_dist == \"Linux Mint\" and\n    _docker_os_dist_major_version == \"18\"\n  tags: [\"install\", \"configure\"]\n\n# https://wiki.ubuntu.com/SystemdForUpstartUsers\n# Important! systemd is only fully supported in Ubuntu 15.04 and later releases\n- name: Determine usage of systemd\n  become: true\n  shell: \"ps -p1 | grep systemd 1>/dev/null && echo systemd || echo upstart\"\n  changed_when: no\n  check_mode: no\n  register: _determine_systemd_usage\n\n- name: Set fact to indicate systemd is not used\n  set_fact:\n    _docker_systemd_used: \"{{ _determine_systemd_usage is defined and _determine_systemd_usage.stdout == 'systemd' }}\"\n\n- name: Temporary handling of deprecated variable docker_enable_ce_edge (#54)\n  set_fact:\n    docker_channel: edge\n  when:\n    - docker_enable_ce_edge is defined\n    - docker_enable_ce_edge == true\n\n- name: Compatibility and distribution checks\n  include_tasks: checks.yml\n  tags: [\"install\", \"configure\"]\n\n- name: Setup Docker package repositories\n  include_tasks: setup-repository.yml\n  tags: [\"install\"]\n\n- name: Remove Docker versions before Docker CE\n  include_tasks: remove-pre-docker-ce.yml\n  when: docker_remove_pre_ce | bool\n  tags: [\"install\"]\n\n- name: Install Docker\n  include_tasks: install-docker.yml\n  tags: [\"install\"]\n\n- name: Configure audit logging\n  include_tasks: setup-audit.yml\n  tags: [\"configure\"]\n\n- name: Apply workarounds for bugs and/or tweaks\n  include_tasks: bug-tweaks.yml\n  tags: [\"configure\"]\n\n- name: Configure systemd service\n  include_tasks: configure-systemd.yml\n  when: _docker_systemd_used | bool\n  tags: [\"configure\"]\n\n- name: Configure non-systemd service\n  include_tasks: configure-non-systemd.yml\n  when: _docker_systemd_used | bool == false\n  tags: [\"configure\"]\n\n- name: Configure Docker\n  include_tasks: configure-docker.yml\n  tags: [\"configure\"]\n\n- name: Postinstall tasks\n  include_tasks: postinstall.yml\n  tags: [\"install\"]"}, {"commit_sha": "bc7af5efcd2c8565acee0dc5948c8b752f6c8990", "sha": "e0c431a41226ce09f2764a738310e2d016903298", "filename": "tasks/ansible", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n\n\n  - name: 8.1.1.1 Configure Data Retention\n    lineinfile: dest='/etc/audit/auditd.conf' regexp='max_log_file' line='max_log_file = {{max_log_file}}' state=present\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n\n  - name: 8.1.1.2 Configure Data Retention\n    lineinfile: dest='/etc/audit/auditd.conf' regexp='space_left_action'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.2\n\n  - name: 8.1.1.3 Configure Data Retention\n    lineinfile: dest='/etc/audit/auditd.conf' regexp='action_mail_acct'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.3\n\n  - name: 8.1.1.4 Configure Data Retention\n    lineinfile: dest='/etc/audit/auditd.conf' regexp='admin_space_left_action'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.4\n\n  - name: 8.1.1.5 Configure Data Retention\n    lineinfile: dest='/etc/audit/auditd.conf' regexp='max_log_file_action'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.5\n\n  - name: 8.1.2.1 Install and Enable auditd Service (Scored)\n    action: command >\n      ' dpkg -s auditd'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.2\n      - section8.1.2.1\n\n  - name: 8.1.2.2 Install and Enable auditd Service (Scored)\n    action: command >\n      ' ls /etc/rc*.d/S*auditd'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.2\n      - section8.1.2.2\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    lineinfile: dest='/boot/grub/grub.cfg' regexp='\"linux\"'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.4.1 Record Events That Modify Date and Time Information (Scored)\n    lineinfile: dest='/etc/audit/audit.rules' regexp='time-change'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.4\n      - section8.1.4.1\n\n  - name: 8.1.4.2 Record Events That Modify Date and Time Information (Scored)\n    lineinfile: dest='/etc/audit/audit.rules' regexp='time-change'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.4\n      - section8.1.4.2\n\n  - name: 8.1.5 Record Events That Modify User/Group Information (Scored)\n    lineinfile: dest='/etc/audit/audit.rules' regexp='identity'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.5\n\n  - name: 8.1.6.1 Record Events That Modify the System's Network Environment(Scored)\n    lineinfile: dest='/etc/audit/audit.rules' regexp='system-locale'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.6\n      - section8.1.6.1\n\n  - name: 8.1.6.2 Record Events That Modify the System's Network Environment(Scored)\n    lineinfile: dest='/etc/audit/audit.rules' regexp='system-locale'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.6\n      - section8.1.6.2\n\n  - name: 8.1.7 Record Events That Modify the System's Mandatory AccessControls (Scored)\n    lineinfile: dest='/etc/audit/audit.rules' regexp='MAC-policy'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.7\n\n  - name: 8.1.8 Collect Login and Logout Events (Scored)\n    lineinfile: dest='/etc/audit/audit.rules' regexp='logins'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.8\n\n  - name: 8.1.9 Collect Session Initiation Information (Scored)\n    lineinfile: dest='/etc/audit/audit.rules' regexp='session'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.9\n\n  - name: 8.1.10.1 Collect Discretionary Access Control Permission ModificationEvents (Scored)\n    lineinfile: dest='/etc/audit/audit.rules' regexp='perm_mod'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.10\n      - section8.1.10.1\n\n  - name: 8.1.10.2 Collect Discretionary Access Control Permission ModificationEvents (Scored)\n    lineinfile: dest='/etc/audit/audit.rules' regexp='perm_mod'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.10\n      - section8.1.10.2\n\n  - name: 8.1.11.1 Collect Unsuccessful Unauthorized Access Attempts to Files(Scored)\n    lineinfile: dest='/etc/audit/audit.rules' regexp='access'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.11\n      - section8.1.11.1\n\n  - name: 8.1.11.2 Collect Unsuccessful Unauthorized Access Attempts to Files(Scored)\n    lineinfile: dest='/etc/audit/audit.rules' regexp='access'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.11\n      - section8.1.11.2\n\n  - name: 8.1.12.1 Collect Use of Privileged Commands (Scored)\n    lineinfile: dest='/etc/audit/audit.rules' regexp='access'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.12\n      - section8.1.12.1\n\n  - name: 8.1.12.2 Collect Use of Privileged Commands (Scored)\n    lineinfile: dest='/etc/audit/audit.rules' regexp='access'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.12\n      - section8.1.12.2\n\n  - name: 8.1.13.1 Collect Successful File System Mounts (Scored)\n    lineinfile: dest='/etc/audit/audit.rules' regexp='mounts'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.13\n      - section8.1.13.1\n\n  - name: 8.1.13.2 Collect Successful File System Mounts (Scored)\n    lineinfile: dest='/etc/audit/audit.rules' regexp='mounts'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.13\n      - section8.1.13.2\n\n  - name: 8.1.14.1 Collect File Deletion Events by User (Scored)\n    lineinfile: dest='/etc/audit/audit.rules' regexp='delete'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.14\n      - section8.1.14.1\n\n  - name: 8.1.14.2 Collect File Deletion Events by User (Scored)\n    lineinfile: dest='/etc/audit/audit.rules' regexp='delete'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.14\n      - section8.1.14.2\n\n  - name: 8.1.15 Collect Changes to System Administration Scope (sudoers)(Scored)\n    lineinfile: dest='/etc/audit/audit.rules' regexp='scope'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.15\n\n  - name: 8.1.16 Collect System Administrator Actions (sudolog) (Scored)\n    lineinfile: dest='/etc/audit/audit.rules' regexp='actions'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.16\n\n  - name: 8.1.17 Collect Kernel Module Loading and Unloading (Scored)\n    lineinfile: dest='/etc/audit/audit.rules' regexp='modules'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.17\n\n  - name: 8.1.18 Make the Audit Configuration Immutable (Scored)\n    action: command >\n      ' tail -n 1 /etc/audit/audit.rules'\n    tags:\n      - section8\n      - section8.1\n      - section8.1.18\n\n  - name: 8.3.1 Install AIDE (Scored)\n    action: command >\n      ' dpkg -s aide'\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.2 Implement Periodic Execution of File Integrity (Scored)\n    action: command >\n      ' crontab -u root -l | grep aide'\n    tags:\n      - section8\n      - section8.3\n      - section8.3.2\n"}, {"commit_sha": "d25113e8fab871b2ead95ca976c5a43e4759ea26", "sha": "0fa9d9ae451a7f8eb1c45da80b30164d7a5b3745", "filename": "tasks/auth_initialization_ald.yml", "repository": "UnderGreen/ansible-role-mongodb", "decoded_content": "- name: create administrative user siteRootAdmin port=yes\n  mongodb_user:\n    database: admin\n    name: \"{{ item.name }}\"\n    password: \"{{ item.password }}\"\n    roles: \"{{ item.roles }}\"\n    login_host: 127.0.0.1\n    login_port: \"{{ ansible_local.mongodb.mongodb.mongodb_login_port }}\"\n  with_items:\n    - {\n      name: \"{{ mongodb_root_admin_name }}\",\n      password: \"{{ mongodb_root_admin_password }}\",\n      roles: \"root\"\n      }\n\n- name: create administrative user siteUserAdmin port=yes\n  mongodb_user:\n    database: admin\n    name: \"{{ item.name }}\"\n    password: \"{{ item.password }}\"\n    roles: \"{{ item.roles }}\"\n    login_host: 127.0.0.1\n    login_port: \"{{ ansible_local.mongodb.mongodb.mongodb_login_port }}\"\n  with_items:\n    - {\n      name: \"{{ mongodb_user_admin_name }}\",\n      password: \"{{ mongodb_user_admin_password }}\",\n      roles: \"userAdminAnyDatabase\"\n      }\n\n- name: create normal users\n  mongodb_user:\n    database: \"{{ item.database }}\"\n    name: \"{{ item.name }}\"\n    password: \"{{ item.password }}\"\n    roles: \"{{ item.roles }}\"\n    replica_set: \"{{ mongodb_conf_replSet }}\"\n    login_host: 127.0.0.1\n    login_port: \"{{ ansible_local.mongodb.mongodb.mongodb_login_port }}\"\n    login_user: \"{{ mongodb_user_admin_name }}\"\n    login_password: \"{{ mongodb_user_admin_password }}\"\n  with_items:\n    - \"{{ mongodb_users }}\"\n  when: mongodb_users is defined\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "4490c038e9463955409ccfd645aba97d8c145902", "filename": "roles/dns/manage-dns-zones-route53/tasks/determine-action.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Determine if Route53 processing is required\n  set_fact:\n    route53_processing: True\n  when:\n    - item.1.route53 is defined\n  with_subelements:\n    - \"{{ dns_data.views | default({}) }}\"\n    - zones\n"}, {"commit_sha": "2a05a5032ce341d6a1d918453164c59ea2922f58", "sha": "ba494982f91e8faace829bf60b9abf1409c794b9", "filename": "roles/provision_vm/templates/kickstart.cfg", "repository": "CSCfi/fgci-ansible", "decoded_content": "# basics\ntext\nskipx\ncmdline\ninstall\nreboot\nfirstboot --disable\nurl --url=\"{{ location }}\"\n\n# localization\nlang en_GB\nkeyboard fi\ntimezone --utc Europe/Helsinki\n\n# repos\n{% if repos is defined %}\n{% for repo in repos %}\nrepo --name=\"{{ repo.name }}\" --baseurl=\"{{ repo.url }}\"\n{% endfor %}\n{% endif %}\n\n{% if networks is defined %}\n{% for network in networks %}\n{{ network }}\n{% endfor %}\n{% endif %}\n\n# firewall\nfirewall --enabled --service=ssh\n\n{% if firewall_rules is defined %}\n{% for firewall_rule in firewall_rules %}\n{{ firewall_rule }}\n{% endfor %}\n{% endif %}\n\n# authentication\nrootpw --iscrypt {{ rootpwhash }}\nauthconfig --useshadow --passalgo=sha512 --kickstart\nselinux --disabled\n\n# disks\nbootloader --location=mbr --append=\"selinux=0 nomodeset\"\nzerombr\nclearpart --all --initlabel\npart / --fstype=\"ext4\" --grow --size=4000 --ondrive=vda\npart swap --asprimary --size=1024 --ondrive=vda\n\n%packages --nobase\n@core\n@server-policy\nvim-enhanced\nopenssh-clients\n%end\n\n################################################################################\n\n%post --log=/root/post-ks-log\n/usr/bin/yum clean all\n/usr/bin/yum update -y --skip-broken\necho \"{{ internal_ip }} {{ fqdn }}\" >> /etc/hosts\n\n{% if root_keys is defined %}\n{% for root_key in root_keys %} \nmkdir /root/.ssh && chmod 600 /root/.ssh\necho \"{{ root_key }}\" >> /root/.ssh/authorized_keys\nchmod 400 /root/.ssh/authorized_keys\n{% endfor %}\n{% endif %}\n\n{% if routes is defined %}\n{% for route in routes %} \n/sbin/ip route add {{ route }}\n{% endfor %}\n{% endif %}\n%end\n#\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "28478e1ed574f41fec3320f8b308692c8ed3feb2", "filename": "roles/remote-user/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Determine whether to connect as root or admin_user\n  local_action: command ansible {{ inventory_hostname }} -m ping{{ (inventory_file == None) | ternary('', ' -i ' + inventory_file | string) }} -u root\n  failed_when: false\n  changed_when: false\n  register: root_status\n\n- name: Set remote user for each host\n  set_fact:\n    ansible_ssh_user: \"{{ root_status | success | ternary('root', admin_user) }}\"\n\n- name: Announce which user was selected\n  debug:\n    msg: \"Note: Ansible will attempt connections as user = {{ ansible_ssh_user }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "502f3dc1cd15305a4df8d0e896c72e68048f461e", "filename": "roles/1-prep/tasks/detected_network.yml", "repository": "iiab/iiab", "decoded_content": "- name: Checking iiab_domain_name\n  shell: \"cat /etc/sysconfig/iiab_domain_name\"\n  register: prior_domain\n  when: not first_run\n\n# above always registers\n- name: Checking for prior domain name\n  set_fact:\n    iiab_domain: \"{{ prior_domain.stdout }}\"\n  when: not first_run and prior_domain.stdout != \"lan\" and prior_domain.stdout != \"\"\n\n- name: iiab_wan_device\n  shell: \"cat /etc/sysconfig/iiab_wan_device\"\n  register: prior_gw\n  when: not first_run\n\n- name: Checking for old device gateway interface for device test\n  set_fact:\n    device_gw: \"{{ prior_gw.stdout }}\"\n    device_gw2: \"{{ prior_gw.stdout }}\"\n  when: not first_run and prior_gw is defined and prior_gw.stdout != \"\"\n\n#pause checking\n\n# Discover  do we have a gateway? -- if ansible detects gateway, becomes WAN candidate\n- name: Finding gateway\n  set_fact:\n    discovered_wan_iface: \"{{ ansible_default_ipv4.alias }}\"\n  when: 'ansible_default_ipv4.gateway is defined'\n\n- name: Verify gateway present\n  shell: ping -c2 \"{{ ansible_default_ipv4.gateway }}\" &> /dev/null ; echo $?\n  register: gw_active_test\n  when: discovered_wan_iface != \"none\"\n\n- name: Recording gateway response\n  set_fact:\n     gw_active: True\n  when: discovered_wan_iface != \"none\" and gw_active_test.stdout == \"0\"\n\n- name: Test for internet access\n  get_url: url=\"{{ iiab_download_url }}/heart-beat.txt\" dest=/tmp/heart-beat.txt\n  ignore_errors: True\n#  async: 10\n#  poll: 2\n  register: internet_access_test\n\n- name: Set internet_available true if wget succeeded\n  set_fact:\n     internet_available: True\n  when: not internet_access_test|failed and not disregard_network\n\n- name: Cleanup internet test file\n  file: path=/tmp/heart-beat.txt\n        state=absent\n\n- name: Setting wan if detected\n  set_fact:\n    iiab_wan_iface: \"{{ discovered_wan_iface }}\"\n    device_gw: \"{{ discovered_wan_iface }}\"\n  when: discovered_wan_iface != \"none\"\n\n- name: RedHat Network detection\n  include: detected_redhat.yml\n  when: is_redhat\n\n# WIRELESS -- if any wireless is detected as gateway, it becomes WAN\n- name: Look for any wireless interfaces\n  shell: \"cat /proc/net/wireless | grep -v -e Inter -e face | awk -F: '{print $1}' \"\n  register: wireless_list1\n  ignore_errors: True\n  changed_when: False\n\n- name: Set the discovered wireless, if found\n  set_fact:\n     wifi1: \"{{ item|trim }}\"\n     discovered_wireless_iface: \"{{ item|trim }}\"\n  when: item|trim != \"\" and item|trim != discovered_wan_iface\n  with_items:\n      - \"{{ wireless_list1.stdout_lines }}\"\n\n# WIRELESS -- Sigh... Not all drivers update /proc/net/wireless correctly\n- name: Look for any wireless interfaces take 2\n  shell: \"ls -la /sys/class/net/*/phy80211 | awk -F / '{print $5}'\"\n  register: wireless_list2\n  ignore_errors: True\n  changed_when: False\n\n# Last device is used\n- name: Set the discovered wireless, if found take 2\n  set_fact:\n     wifi2: \"{{ item|trim }}\"\n     discovered_wireless_iface: \"{{ item|trim }}\"\n  when: wireless_list2.stdout != \"\" and item|trim != discovered_wan_iface\n  with_items:\n      - \"{{ wireless_list2.stdout_lines }}\"\n\n- name: Count Wifi ifaces\n  shell: \"ls -la /sys/class/net/*/phy80211 | awk -F / '{print $5}' | wc -l\"\n  register: count_wifi_interfaces\n\n- name: Remember number of Wifi devices\n  set_fact:\n      num_wifi_interfaces: \"{{ count_wifi_interfaces.stdout|int }}\"\n\n# XO hack here ap_device would not be active therefore not set with\n# wired as gw use ap_device to exclude eth0 from network calulations\n\n- name: XO override 2 wifi on LAN\n  set_fact:\n      ap_device: \"eth0\"\n  when: iiab_wan_iface != \"eth0\" and discovered_wireless_iface != \"none\" and xo_model == \"XO-1.5\"\n\n# takes adapter name\n- name: Blacklisted wifi adapter\n  set_fact:\n      ap_device: \"{{ blacklist_wifi }}\"\n  when: blacklist_wifi is defined and discovered_wireless_iface != iiab_wan_iface and num_wifi_interfaces >= \"2\"\n\n# LAN - pick non WAN's\n- name: Create list of  LAN (non wan) ifaces\n  shell: ls /sys/class/net | grep -v -e wwlan -e ppp -e lo -e br0 -e tun -e {{ device_gw }} -e {{ ap_device }}\n  register: lan_list_result\n  ignore_errors: True\n  changed_when: false\n\n# Select an adapter that is not WAN and not wireless\n# if there is more than one the last one wins\n- name: Set iiab discovered lan fact\n  set_fact:\n    discovered_lan_iface: \"{{ item|trim }}\"\n  when: item|trim != discovered_wireless_iface and item|trim != discovered_wan_iface\n  with_items:\n      - \"{{ lan_list_result.stdout_lines }}\"\n\n- name: Count LAN ifaces\n  shell: ls /sys/class/net | grep -v  -e wwlan -e ppp -e lo -e br0 -e tun -e {{ device_gw }} -e {{ ap_device }} | wc -l\n  register: num_lan_interfaces_result\n  ignore_errors: True\n  changed_when: false\n\n# facts are apparently all stored as text, so do text comparisons from here on\n- name: Calulate number of LAN interfaces including WiFi\n  set_fact:\n      num_lan_interfaces: \"{{ num_lan_interfaces_result.stdout|int }}\"\n\n# If 2 interfaces found in gateway mode, with one wifi, declare other to be wan\n#- name: In gateway mode with one wifi adapter, the other is WAN\n#  set_fact:\n#      iiab_wan_iface: \"{{ discovered_lan_iface }}\"\n#      iiab_lan_iface: \"{{ discovered_wireless_iface }}\"\n#      num_lan_interfaces: \"1\"\n#  when: iiab_lan_enabled and iiab_wan_enabled and num_lan_interfaces == \"2\" and discovered_wireless_iface != \"none\" and iiab_wan_iface == \"none\"\n\n- name: Set the variable for wireless_iface if present\n  set_fact:\n       iiab_wireless_lan_iface: \"{{ discovered_wireless_iface }}\"\n  when: discovered_wireless_iface != \"none\" and discovered_wireless_iface != iiab_wan_iface\n\n#unused\n#- name: Get a list of ifcfg files to delete\n# moved to detected_redhat\n\n# use value only if present\n- name: Setting detected lan\n  set_fact:\n    iiab_lan_iface: \"{{ discovered_lan_iface }}\"\n  when: 'discovered_lan_iface != \"none\" and num_lan_interfaces == \"1\"'\n\n- name: for debian, always use bridging\n  set_fact:\n     iiab_lan_iface: br0\n  when: 'discovered_lan_iface != \"none\" and num_lan_interfaces >= \"1\" and is_debuntu'\n\n- name: 2 or more devices on the LAN - use bridging\n  set_fact:\n     iiab_lan_iface: br0\n  when: 'discovered_lan_iface != \"none\" and num_lan_interfaces >= \"2\" and not is_debian'\n\n- name: WiFi is on the LAN - use bridging\n  set_fact:\n    iiab_lan_iface: br0\n  when: iiab_wireless_lan_iface != \"none\"\n\n# OK try old gw this is a best guess based on what's in\n# /etc/sysconfig/iiab_wan_device's last state intended to\n# provide a seed value to display in the GUI when no\n# gateway is present but we had one.\n- name: Has old gateway and no discovered gateway setting WAN\n  set_fact:\n    gui_wan_iface: \"{{ device_gw }}\"\n  when: user_wan_iface == \"auto\" and device_gw != \"none\" and discovered_wan_iface == \"none\"\n\n- name: Add location section to config file\n  ini_file: dest='{{ iiab_config_file }}'\n            section=network\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n  - option: 'gw_active'\n    value:  '{{ gw_active }}'\n  - option: 'internet_available'\n    value:  '{{ internet_available }}'\n  - option: 'has_ifcfg_gw'\n    value: '{{ has_ifcfg_gw }}'\n  - option: 'discovered_wan_iface'\n    value: '{{ discovered_wan_iface }}'\n  - option: 'prior_gateway_(device_gw2)'\n    value: '{{ device_gw2 }}'\n  - option: 'wireless_list_1(wifi1)'\n    value: '{{ wifi1 }}'\n  - option: 'wireless_list_2(wifi2)'\n    value: '{{ wifi2 }}'\n  - option: 'num_wifi_interfaces'\n    value: '{{ num_wifi_interfaces }}'\n  - option: 'discovered_wireless_iface'\n    value: '{{ discovered_wireless_iface }}'\n  - option: 'iiab_wireless_lan_iface'\n    value: '{{ iiab_wireless_lan_iface }}'\n  - option: 'num_lan_interfaces'\n    value: '{{ num_lan_interfaces }}'\n  - option: 'discovered_lan_iface'\n    value: '{{ discovered_lan_iface }}'\n  - option: 'gui_static_wan'\n    value: '{{ gui_static_wan }}'\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "e3a2d87548913fb6fcb200832808560e6aba1e42", "filename": "tasks/plus/setup-redhat.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: CentOS/RedHat/Oracle Linux) Add NGINX Plus Repository\"\n  yum_repository:\n    name: nginx-plus\n    baseurl: >-\n      https://plus-pkgs.nginx.com/centos/{{ (ansible_distribution_version | float >= 7.4 and ansible_distribution_version | float < 8.0)\n      | ternary(ansible_distribution_major_version | int, 7.4) }}/$basearch/\n    description: NGINX Plus Repository\n    sslclientcert: /etc/ssl/nginx/nginx-repo.crt\n    sslclientkey: /etc/ssl/nginx/nginx-repo.key\n    enabled: yes\n    gpgcheck: yes\n  when: ansible_distribution != \"Amazon\"\n\n- name: \"(Install: Amazon Linux) Add NGINX Plus Repository\"\n  yum_repository:\n    name: nginx-plus\n    baseurl: >-\n      https://plus-pkgs.nginx.com/amzn{{ (ansible_distribution_version == \"2\")\n      | ternary('2', '') }}/$releasever/$basearch\n    description: NGINX Plus Repository\n    sslclientcert: /etc/ssl/nginx/nginx-repo.crt\n    sslclientkey: /etc/ssl/nginx/nginx-repo.key\n    enabled: yes\n    gpgcheck: yes\n  when: ansible_distribution == \"Amazon\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "677254353595f1c4ed5d837d598eb8138a8c4e0b", "filename": "roles/config-docker/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Install, configure and enable Docker\"\n  import_tasks: docker.yml\n  when: \n  - docker_install|default(False)\n\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "27121c2e9a20fe16f3c2d904b7772143ce6dceaf", "filename": "playbooks/provision-satellite-server/configure-satellite-server.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n#\n# Make sure to check out the `config-satellite` README for details on how to create the inventory\n# https://github.com/redhat-cop/infra-ansible/blob/master/roles/config-satellite/README.md\n#\n\n- hosts: satellite_servers\n  roles:\n  - role: config-satellite\n"}, {"commit_sha": "6fada6f2a7515ab18178ae350168c3de147c4dd0", "sha": "cb0a66602252f977ac7fa146c29716eb457a8572", "filename": "tasks/configure.yml", "repository": "inkatze/wildfly", "decoded_content": "---\n# task file for wildfly\n\n- name: Create wildfly etc directory\n  file:\n    path: '{{ wildfly_conf_dir }}'\n    state: directory\n    owner: '{{ wildfly_user }}'\n    group: '{{ wildfly_group }}'\n    mode: '0750'\n\n- name: Copy wildfly configuration\n  template:\n    src: wildfly.conf.j2\n    dest: '{{ wildfly_conf_dir }}/wildfly.conf'\n    owner: root\n    group: root\n    mode: '0640'\n  notify:\n    - restart wildfly\n    - change standalone data mode\n\n- name: Copy wildfly properties file\n  template:\n    src: wildfly.properties.j2\n    dest: '{{ wildfly_conf_dir }}/wildfly.properties'\n    owner: '{{ wildfly_user }}'\n    group: '{{ wildfly_group }}'\n    mode: '0640'\n  notify:\n    - restart wildfly\n    - change standalone data mode\n\n- name: Copy wildfly init script\n  template: src=wildfly.init.j2 dest={{ wildfly_init_dir }}/wildfly owner=root\n            group=root mode=0750\n  when: ansible_service_mgr == 'init'\n  notify:\n    - restart wildfly\n    - change standalone data mode\n\n- name: Copy wildfly systemd unit file\n  template: src=wildfly.service.j2 dest={{ wildfly_systemd_dir }}/wildfly owner=root\n            group=root mode=0640\n  when: ansible_service_mgr == 'systemd'\n  notify:\n    - restart wildfly\n    - change standalone data mode\n\n  firewalld:\n    port: '{{ wildfly_manage_http_port }}/tcp'\n    permanent: yes\n    immediate: yes\n    state: enabled\n\n- name: Open wildfly management https tcp port\n  firewalld:\n    port: '{{ wildfly_manage_https_port }}/tcp'\n    permanent: yes\n    immediate: yes\n    state: enabled\n\n- name: Open wildfly http tcp port\n  firewalld:\n    port: '{{ wildfly_http_port }}/tcp'\n    permanent: yes\n    immediate: yes\n    state: enabled\n\n- name: Open wildfly https tcp port\n  firewalld:\n    port: '{{ wildfly_https_port }}/tcp'\n    permanent: yes\n    immediate: yes\n    state: enabled\n\n- name: Enable and start the service\n  service:\n    name: wildfly\n    state: started\n    enabled: yes\n\n- name: Change standalone data mode\n  file:\n    path: '{{ wildfly_dir }}/standalone/data'\n    owner: '{{ wildfly_user }}'\n    group: '{{ wildfly_group }}'\n    mode: '0750'\n    recurse: yes\n\n- name: Delete wildfly tar file\n  file:\n    path: '{{ wildfly_download_dir }}/{{ wildfly_download_file }}'\n    state: absent\n\n- name: Create a version file\n  template:\n    src: version.j2\n    dest: '{{ wildfly_version_file }}'\n    owner: '{{ wildfly_user }}'\n    group: '{{ wildfly_group }}'\n    mode: '0750'\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "70cf3aa8effc872e8cdf61c54cb0056fbd7644f3", "filename": "tasks/section_09.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - include: section_09_level1.yml\n    tags:\n      - section09\n      - level1\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "1d25ceb676c6c0716597e7b295893975c5d3af59", "filename": "roles/user-management/manage-idm-users/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: configure_user.yml\n\n- import_tasks: configure_group.yml\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "73cf244d29872c80bfc99595c7433dd6080e88ed", "filename": "roles/ansible/tower/manage-credentials/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: tower\n  roles:\n  - role: ansible/tower/manage-credentials\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "75b6a11e48cb162c80474fa157f3a8cd624035a4", "filename": "roles/owncloud/templates/owncloud.list", "repository": "iiab/iiab", "decoded_content": "deb https://download.owncloud.org/download/repositories/stable/Ubuntu_16.04/ /\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "55354b1042cb41f1b6debc75e9dafbcc2f8e0a08", "filename": "roles/letsencrypt/README.md", "repository": "roots/trellis", "decoded_content": "# Let\u2019s encrypt/acme-tiny role for Ansible\n\n## License\n\nMIT\n\n## Author Information\n\nThis role was created by Andreas Wolf. Visit my [website](http://a-w.io) and [Github profile](https://github.com/andreaswolf/) or follow me on [Twitter](https://twitter.com/andreaswo).\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "ca4fca3c349519467aed490387a8687cb232da62", "filename": "roles/cfme-ocp-provider/defaults/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\ncfme_host:\ncfme_username:\ncfme_password:\nocp_master_host: kubernetes.default.svc.cluster.local\nocp_master_port: 443\nocp_token:\nhawkular_token:\nhawkular_host: hawkular-metrics.openshift-infra.svc.cluster.local\nhawkular_port: 443\nocp_container_provier_name: OCP\ndefault_token_sa_namespace: management-infra\ndefault_token_sa_name: management-admin"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "cc028bec15e9ad0f93d6ab2578cf983e89499212", "filename": "roles/handlers/handlers/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "- name: restart consul\n  service:\n    name: consul\n    state: restarted\n  sudo: yes\n  notify:\n    - wait for consul to listen\n\n- name: wait for consul to listen\n  wait_for:\n    port: 8500\n\n- name: restart docker\n  service:\n   name: docker\n   state: restarted\n  sudo: yes\n  notify:\n  - wait for weave to listen\n\n- name: wait for weave to listen\n  wait_for:\n    port: 6783\n    delay: 10\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "c1da19f1d383c7b38bc686d449cedc9ebf8f6b11", "filename": "tasks/Linux/fetch/sapmachine-fallback.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: 'Prepare for latest minor version'\n  block:\n    - name: 'Fetch version page'\n      uri:\n        url: 'https://sap.github.io/SapMachine/latest/{{ java_major_version }}/'\n        return_content: true\n        status_code: [200, 404]\n      register: version_page\n\n    - name: Find release version\n      set_fact:\n        release_version: >-\n          {{ version_page.content | regex_search('(1.*[.|-]\\d)') }}\n  when: java_minor_version == '*'\n\n- name: 'Fetch artifact page'\n  uri:\n    url: '{{ release_page }}'\n    status_code: [200, 404]\n    return_content: true\n    body_format: json\n  register: artifact_page\n\n- name: Exit if SapMachine version is wrong\n  fail:\n    msg: >-\n      {{ 'SapMachine version ' + java_major_version|string\n              + (java_minor_version == '*') | ternary('', '.' + java_minor_version|string)\n                  + '_' + java_arch|string + ' for Linux is not supported!' }}\n  when: artifact_page.status == 404\n\n- name: Get artifact link\n  set_fact:\n    artifact_link: \"{{ artifact_page.json | json_query(\\\"assets[?name=='\\\" + release_name + \\\".tar.gz'].browser_download_url\\\") }}\"\n\n- name: Get checksum link\n  set_fact:\n    checksum_link: \"{{ artifact_page.json | json_query(\\\"assets[?name=='\\\" + release_name + \\\".sha256.txt'].browser_download_url\\\") }}\"\n\n- name: 'Fetch artifact checksum file'\n  uri:\n    url: '{{ checksum_link[0] }}'\n    return_content: true\n  register: artifact_checksum_file\n\n- name: Find artifact checksum\n  set_fact:\n    artifact_checksum: >-\n      {{ artifact_checksum_file.content | regex_search('(^\\w*)') }}\n\n- name: 'Download artifact'\n  get_url:\n    url: '{{ artifact_link[0] }}'\n    dest: '{{ java_download_path }}'\n    checksum: 'sha256:{{ artifact_checksum }}'\n  register: file_downloaded\n  retries: 20\n  delay: 5\n  until: file_downloaded is succeeded\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "f78dba7177df9a8eb38d610b2af3c3b7ef317a18", "filename": "roles/elgg/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "# Assume we only get here if elgg_install: True\n# Assume mysql is running\n\n- name: download current version from our copy\n  shell: wget {{ iiab_download_url }}/elgg-{{ elgg_version }}.zip -c -P {{ downloads_dir }}\n         creates={{ downloads_dir }}/elgg-{{ elgg_version }}.zip\n  when: internet_available\n\n- name: Determine if software is already expanded\n  stat: path=/opt/elgg-{{ elgg_version }}/index.php\n  register: elgg\n\n# use unzip and shell until unarchive works again\n# unarchive: dest=/opt/\n#            src={{ downloads_dir }}/elgg-{{ elgg_version }}.zip\n\n- name: Expand it to our location unless already done\n  shell: \"/usr/bin/unzip -o {{ downloads_dir }}/elgg-{{ elgg_version }}.zip -d /opt\"\n  when: elgg.stat.exists is defined and not elgg.stat.exists\n\n- name: Create a link to the versioned elgg folder\n  file: src=./elgg-{{ elgg_version }}\n        dest=/opt/elgg\n        owner={{ apache_user }}\n        group={{ apache_user }}\n        state=link\n        force=true\n\n# use template to fix up settings in engine/settings.php with our variables substituted\n# into engine/settings.example.php\n# note this will overwrite any manual settings\n- name: Substitute our parameters in engine/settings.example.php\n  template: src=\"settings.php.j2\"\n            dest=\"/opt/{{ elgg_xx }}/elgg-config/settings.php\"\n            owner={{ apache_user }}\n            group={{ apache_user }}\n\n# The name of this file changed from 1.9 to 1.10.\n- name: Copy default .htaccess to the root directory of elgg tree\n  copy: src=\"/opt/{{ elgg_xx }}/vendor/elgg/elgg/install/config/htaccess.dist\"\n        dest=\"/opt/{{ elgg_xx }}/.htaccess\"\n        mode=0644\n        owner={{ apache_user }}\n        group={{ apache_user }}\n\n#regexp='^#RewriteBase'\n- name: Modify .htaccess to have RewriteBase as our directory\n  lineinfile: backup=no\n              dest=\"/opt/{{ elgg_xx }}/.htaccess\"\n              state=present\n              insertafter='^#RewriteBase'\n              line=\"RewriteBase {{ elgg_url }}/\"\n\n- name: Change permissions on engine directory so apache can write\n  file: path=/opt/elgg/engine/ owner={{ apache_user }} mode=0755 state=directory\n\n- name: Create an upload directory that Apache can write in or elgg\n  file: path={{ elgg_upload_path }} state=directory owner={{ apache_user }}\n\n- name: change ownership\n  file: path=/opt/elgg-{{ elgg_version }}\n        owner={{ apache_user }}\n        group={{ apache_user }}\n        recurse=yes\n        state=directory\n\n- name: Create a mysql database for elgg - can be run more than once\n  mysql_db: name={{ dbname }}\n  register: create_elgg_database\n\n- name: Create a user to access the elgg database - can be run more than once\n  mysql_user: name={{ dbuser }} host={{ item }} password={{ dbpassword }} priv={{ dbname }}.*:ALL\n  with_items:\n        - 127.0.0.1\n        - ::1\n        - localhost\n\n- name: Create file to load database\n  template: src=elggdb.sql.j2\n            dest=/tmp/elggdb.sql\n\n# elggdb.sql obtained with mysqldump --skip-add-drop-table elggdb > elggdb.sql\n# tar up a mysqldump of freshly installed database and use it in the install to avoid the startup\n# form, which worries me a lot. (/var/lib/mysql/elggdb)\n\n- name: Load elgg database dump\n  mysql_db: name={{ dbname }}\n            state=import\n            target=/tmp/elggdb.sql\n  when: create_elgg_database.changed\n\n- name: Remove database dump after load\n  file: name=/tmp/elggdb.sql state=absent\n\n- name: Install config file for elgg in Apache\n  template: src=elgg.conf dest=/etc/{{ apache_config_dir }}/elgg.conf\n\n- name: Enable elgg for debuntu (will already be enabled above for Redhat)\n  file: path=/etc/apache2/sites-enabled/elgg.conf\n        src=/etc/apache2/sites-available/elgg.conf\n        state=link\n  when: elgg_enabled and is_debuntu\n\n- name: Disable elgg for debuntu\n  file: path=/etc/apache2/sites-enabled/elgg.conf\n        state=absent\n  when: not elgg_enabled and is_debuntu\n\n- name: Disable elgg for Redhat - remove config file for elgg in Apache\n  file: dest=/etc/{{ apache_config_dir }}/elgg.conf\n        state=absent\n  when: not elgg_enabled and is_redhat\n\n- name: add elgg to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=elgg\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: elgg-social-netwoking\n    - option: description\n      value: '\"Elgg is an award-winning social networking engine, delivering the building blocks that enable businesses, schools, universities and associations to create their own fully-featured social networks and applications\"'\n    - option: path\n      value: /opt/elgg\n    - option: enabled\n      value: \"{{ elgg_enabled }}\"\n\n- name: Restart apache, so it picks up the new aliases\n  service: name={{ apache_service }} state=restarted\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "e22e3d80f7ad597ca398e573273556729ca0d2fb", "filename": "roles/ansible/tower/manage-credential-types/tasks/process-credential-type.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Get the credential_type id based on the name\"\n  set_fact:\n    credential_type_id: \"{{ item.id }}\"\n  when:\n  - item.name|trim == credential_type.name|trim\n  with_items:\n  - \"{{ existing_credential_types_output.rest_output }}\"\n\n- name: \"Load up the credential type\"\n  uri:\n    url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}/api/v2/credential_types/\"\n    user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n    password: \"{{ ansible_tower.admin_password }}\"\n    force_basic_auth: yes\n    method: POST\n    body: \"{{ lookup('template', 'credential-type.j2') }}\"\n    body_format: 'json'\n    headers:\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n    validate_certs: no\n    status_code: 201\n  when: credential_type_id is not defined\n\n- name: \"Update existing credential type\"\n  uri:\n    url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}/api/v2/credential_types/{{ credential_type_id }}/\"\n    user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n    password: \"{{ ansible_tower.admin_password }}\"\n    force_basic_auth: yes\n    method: PUT\n    body: \"{{ lookup('template', 'credential-type.j2') }}\"\n    body_format: 'json'\n    headers:\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n    validate_certs: no\n    status_code: 200\n  when: credential_type_id is defined\n\n- name: \"Clear/Update facts\"\n  set_fact:\n    credential_type_id: ''\n    processed_credential_types: \"{{ processed_credential_types + [ { 'name': credential_type.name.name } ] }}\"\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "8bfe866ec56ce70abe953eeab3199c301cf6fd27", "filename": "tasks/nexus-restore.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- name: Make sure nexus is stopped\n  debug:\n    msg: \"trigger nexus stop\"\n  changed_when: true\n  notify:\n    - nexus-service-stop\n\n- meta: flush_handlers\n\n- name: \"Run restoration script\"\n  shell: \"nexus-blob-restore.sh {{ nexus_restore_point }} 2>&1 | tee -a {{ nexus_restore_log }}\"\n  tags:\n    # This is only run when a restore point is defined\n    # shut-off ansible-lint error on this one: this is the desired way of doing it\n    - skip_ansible_lint\n\n  notify:\n    - nexus-service-restart\n    - wait-for-nexus\n    - wait-for-nexus-port\n\n- meta: flush_handlers\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "7981ab9e0ba3a910d03b465b1c02d108320c5aca", "filename": "roles/config-quay-enterprise/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Verify Storage Type\n  fail:\n    msg: \"Invalid Database Type. 'quay_database_type' must be 'postgres' or 'mysql'\"\n  when: quay_database_type not in [\"postgresql\",\"mysql\"]\n\n- name: Verify Clair Endpoint\n  fail:\n    msg: Clar Endpoint Must Be Specified\n  when: quay_clair_enable is defined and quay_clair_enable|bool and (quay_clair_endpoint is not defined or quay_clair_endpoint|trim == \"\")\n\n- name: Set PostgreSQL Facts\n  set_fact:\n    quay_db_uri: \"{{ postgresql_db_uri }}\"\n  when: quay_database_type == \"postgresql\"\n\n- name: Set MySQL Facts\n  set_fact:\n    quay_db_uri: \"{{ mysql_db_uri }}\"\n  when: quay_database_type == \"mysql\"\n\n- name: Set HTTP Protocol\n  set_fact:\n    quay_http_protocol: \"{{ (quay_ssl_enable|bool)| ternary('https','http') }}\"\n\n- name: Include Container Credentials\n  include_tasks: container_credentials.yml\n  when: (quay_registry_server | trim != \"\") and ((quay_registry_auth | trim != \"\") or (quay_registry_email | trim != \"\"))\n\n- name: Configure Storage Directories\n  file:\n    state: directory\n    owner: root\n    group: root\n    mode: g+rw\n    path: \"{{ item }}\"\n  with_items:\n    - \"{{ quay_config_dir }}\"\n    - \"{{ quay_storage_dir }}\"\n\n- name: Include systemd configurations\n  include_tasks: configure_systemd.yml\n\n- name: Set SSL Facts\n  set_fact:\n    quay_ssl_enable: \"{{ quay_ssl_enable }}\"\n\n- name: Set Fact for Custom SSL Certificates\n  set_fact:\n    quay_ssl_cert_file: \"{{ quay_ssl_cert_file }}\"\n    quay_ssl_key_file: \"{{ quay_ssl_key_file }}\"\n  when: quay_ssl_enable|bool and (quay_ssl_key_file is defined and quay_ssl_key_file|trim != \"\" and quay_ssl_cert_file is defined and quay_ssl_cert_file|trim != \"\")\n\n- name: Create SSL Certificates\n  block:\n    - name: Create Temporary SSL Directory\n      command: mktemp -d /tmp/quay-ssl-XXXXXXX\n      register: quay_ssl_remote_tmp_dir_mktemp\n      delegate_to: \"{{ groups['quay_enterprise'][0] }}\"\n      when: quay_ssl_remote_tmp_dir is undefined and quay_ssl_remote_tmp_dir|trim == \"\"\n\n    - name: Set Fact for Remote SSL Directory\n      set_fact:\n        quay_ssl_remote_tmp_dir: \"{{ quay_ssl_remote_tmp_dir if quay_ssl_remote_tmp_dir is defined and quay_ssl_remote_tmp_dir|trim == '' else quay_ssl_remote_tmp_dir_mktemp.stdout }}\"\n      when: quay_ssl_remote_tmp_dir is undefined and quay_ssl_remote_tmp_dir|trim == \"\"\n\n    - name: Create SSL Certificate\n      command: openssl req -nodes -x509 -newkey rsa:4096 -keyout {{ quay_ssl_remote_tmp_dir }}/ssl.key -out {{ quay_ssl_remote_tmp_dir }}/ssl.cert -subj \"/C={{ quay_ssl_generate_country }}/ST={{ quay_ssl_generate_state }}/L={{ quay_ssl_generate_city }}/O={{ quay_ssl_generate_organization }}/OU={{ quay_ssl_generate_organizational_unit }}/CN={{ quay_server_hostname }}\" -days {{ quay_ssl_generate_days_validity }}\n      delegate_to: \"{{ groups['quay_enterprise'][0] }}\"\n\n    - name: Fetch SSL Certifictes\n      fetch:\n        src:  \"{{ item.src }}\"\n        dest: \"{{ item.dest }}\"\n        flat: true\n        fail_on_missing: yes\n      delegate_to: \"{{ groups['quay_enterprise'][0] }}\"\n      run_once: true\n      with_items:\n        - { src: \"{{ quay_ssl_remote_tmp_dir }}/ssl.key\", dest: \"{{ quay_ssl_local_tmp_dir }}/ssl.key\" }\n        - { src: \"{{ quay_ssl_remote_tmp_dir }}/ssl.cert\", dest: \"{{ quay_ssl_local_tmp_dir }}/ssl.cert\" }\n\n    - name: Delete Remote SSL Certificates\n      file:\n        state: absent\n        path: \"{{ quay_ssl_remote_tmp_dir }}\"\n      delegate_to: \"{{ groups['quay_enterprise'][0] }}\"\n\n    - name: Set Fact for Custom SSL Certificates\n      set_fact:\n        quay_ssl_cert_file: \"{{ quay_ssl_local_tmp_dir }}/ssl.cert\"\n        quay_ssl_key_file: \"{{ quay_ssl_local_tmp_dir }}/ssl.key\"\n  when: quay_ssl_enable|bool and (quay_ssl_key_file is not defined or quay_ssl_key_file|trim == \"\" or quay_ssl_cert_file is not defined or quay_ssl_cert_file|trim == \"\")\n\n- name: Copy SSL Certificates\n  copy:\n    src: \"{{ item.src }}\"\n    dest: \"{{ item.dest }}\"\n    owner: root\n    group: root\n    mode: g+rw\n  notify: Restart quay service\n  with_items:\n    - { src: \"{{ quay_ssl_key_file }}\", dest: \"{{ quay_config_dir }}/ssl.key\" }\n    - { src: \"{{ quay_ssl_cert_file }}\", dest: \"{{ quay_config_dir }}/ssl.cert\" }\n  when: quay_ssl_enable|bool\n\n- name: Check if Quay configuration exists\n  stat:\n    path: \"{{ quay_config_dir }}/config.yaml\"\n  register: quay_config_stat_result\n\n- name: Configure BitTorrent Pepper Value\n  set_fact:\n    bittorrent_filename_pepper: \"{{ 'hostname' | to_uuid | upper }}\"\n\n- name: Setup initial quay configuration file\n  template:\n    src: config.yaml.j2\n    dest: \"{{ quay_config_dir }}/config.yaml\"\n    owner: root\n    group: root\n    mode: g+rw\n  notify: Restart quay service\n  when: not quay_config_stat_result.stat.exists\n\n- name: Include firewall tasks\n  include_tasks: firewall.yml\n\n- name: Setup Initial User and Configuration\n  include_tasks: complete_setup.yml\n  when: not quay_config_stat_result.stat.exists and quay_superuser_username is defined and quay_superuser_username|trim != \"\" and quay_superuser_password is defined and quay_superuser_password|trim != \"\" and quay_superuser_email is defined and quay_superuser_email|trim != \"\"\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "2ee208a7a96a8e91ec4073b7fbbc333724f9c1ac", "filename": "roles/config-quay-enterprise/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# Base Configurations\nquay_name: quay\npostgresql_name: postgresql\nredis_name: redis\nquay_service: \"{{ quay_name }}.service\"\npostgresql_service: \"{{ postgresql_name }}.service\"\nredis_service: \"{{ redis_name }}.service\"\nquay_server_hostname: \"\"\n\n#Systemd\nsystemd_service_dir: /usr/lib/systemd/system\nsystemd_environmenfile_dir: /etc/sysconfig\n\n# Quay\nquay_image: quay.io/coreos/quay:v2.9.1\nquay_config_dir: /opt/quay/config\nquay_container_config_dir: /conf/stack\nquay_storage_dir: /opt/quay/storage\nquay_container_storage_dir: /datastorage\n\n# Postgresql\npostgresql_image: registry.access.redhat.com/rhscl/postgresql-96-rhel7:latest\npostgresql_storage_dir: /opt/postgresql/data\npostgresql_container_storage_dir: /var/lib/pgsql/data\npostgresql_database: quay\npostgresql_admin_user: postgres\npostgresql_username: quay\npostgresql_password: quay\npostgresql_admin_password: quay\n\n# Redis\nredis_image: quay.io/quay/redis:latest\nredis_storage_dir: /opt/redis/data\nredis_container_storage_dir: /var/lib/redis\n\n# Container Credentials\ncontainer_credentials_file: /root/.docker/config.json\ncontainer_credentials_file_content: {}\nquay_registry_server: quay.io\nquay_registry_auth:\nquay_registry_email:"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "8678af22ce3bc1c50f50f3dba26e98b86f13c4d1", "filename": "roles/httpd/tasks/html.yml", "repository": "iiab/iiab", "decoded_content": "- name: Copy css files\n  copy: src={{ item }}\n        dest={{ doc_root }}/common/css\n        mode=0644\n        owner=root\n        group=root\n  with_fileglob:\n        - html/css/*.css\n\n- name: Copy js files\n  copy: src={{ item }}\n        dest={{ doc_root }}/common/js\n        mode=0644\n        owner=root\n        group=root\n  with_fileglob:\n        - html/js/*.js\n\n- name: Copy fonts files\n  copy: src={{ item }}\n        dest={{ doc_root }}/common/fonts\n        mode=0644\n        owner=root\n        group=root\n  with_fileglob:\n        - html/fonts/*\n\n- name: Copy html files\n  copy: src={{ item }}\n        dest={{ doc_root }}/common/html\n        mode=0644\n        owner=root\n        group=root\n  with_fileglob:\n        - html/html/*\n\n- name: Copy assets files\n  copy: src={{ item }}\n        dest={{ doc_root }}/common/assets\n        mode=0644\n        owner=root\n        group=root\n  with_fileglob:\n        - html/assets/*\n\n# copy all services, even if not permissioned elsewhere\n- name: Copy services files\n  copy: src={{ item }}\n        dest={{ doc_root }}/common/services\n        mode=0644\n        owner=root\n        group=root\n  with_fileglob:\n        - html/services/*\n\n- name: Create symlink from assets to iiab.ini\n  file: src=/etc/iiab/iiab.ini\n        dest={{ doc_root }}/common/assets/iiab.ini\n        owner=root\n        group=root\n        state=link\n"}, {"commit_sha": "2f1ed84fec270723a1031cdc2b07b7a76a5a3bda", "sha": "75ff6c055fc23df0862174d082b393824af8f750", "filename": "tasks/main-CentOS.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n# tasks file for ansible-role-docker-ce\n\n- name: Ensure yum-utils is installed\n  package:\n    name: yum-utils\n    state: present\n  become: true\n\n- name: Add Docker CE repository\n  shell: yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n  args:\n    creates: /etc/yum.repos.d/docker-ce.repo\n  become: true\n  register: yum_repo\n\n- name: Update yum cache\n  shell: yum makecache fast\n  become: true\n  when: yum_repo.changed\n\n- include: main-Generic.yml\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "2b6e59f5ff6883e633f00651eac1c13891a4f28a", "filename": "roles/serverspec/defaults/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# defaults file for serverspec\nserverspec_run_tests: false\nserverspec_upload_folder: false\nserverspec_tests_path: /vagrant\nserverspec_install_bundler: true\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "cc01b58bff011a64745b7f2a210a5a3fa0045764", "filename": "roles/manage-jira/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- include_tasks: prepare_vars.yml \n\n- include_tasks: create_project_category.yml\n \n- include_tasks: create_permission_scheme.yml\n\n- include_tasks: create_project.yml\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "15ff947232abd96a4448d1dddecc27d92999ae1b", "filename": "tasks/setup-repository-Ubuntu.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Update APT cache\n  become: true\n  apt:\n    update_cache: yes\n  changed_when: false\n  register: _pkg_result\n  until: _pkg_result is succeeded\n  when:\n    - docker_network_access\n\n- name: Ensure packages are installed for repository setup\n  become: true\n  package:\n    name: \"{{ item }}\"\n    state: present\n  with_items:\n    - \"{{ docker_repository_related_packages[_docker_os_dist] }}\"\n  register: _pkg_result\n  until: _pkg_result is succeeded\n  when:\n    - docker_network_access\n\n- name: Add Docker official GPG key\n  become: true\n  apt_key:\n    url: https://download.docker.com/linux/{{ _docker_os_dist|lower }}/gpg\n    state: present\n  register: _pkg_result\n  until: _pkg_result is succeeded\n  when: \n    - docker_network_access\n    - (_docker_os_dist == \"Ubuntu\" and _docker_os_dist_major_version > '14') or\n      (_docker_os_dist == \"Debian\" and _docker_os_dist_major_version > '7')\n\n- name: Add Docker APT key (alternative for older Ubuntu systems without SNI).\n  become: true\n  shell: \"curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\"\n  args:\n    warn: false\n  changed_when: false\n  when: \n    - docker_network_access\n    - (_docker_os_dist == \"Ubuntu\" and _docker_os_dist_major_version == '14') or \n      (_docker_os_dist == \"Debian\" and  _docker_os_dist_major_version == '7')\n  tags:\n    - skip_ansible_lint\n\n- name: Determine channels to be enabled and/or disabled\n  set_fact:\n    _docker_disable_channels: \"{{ docker_channels | difference(_docker_merged_channels) }}\"\n    _docker_enable_channels: \"{{ docker_channels | intersect(_docker_merged_channels) }}\"\n  vars:\n    _docker_mandatory_channel: []\n    _docker_merged_channels: \"{{ _docker_mandatory_channel }} + [ '{{ docker_channel }}' ]\"\n\n- name: Add Docker CE repository with correct channels (Ubuntu/Debian)\n  become: true\n  apt_repository:\n    repo: \"deb [arch=amd64] https://download.docker.com/linux/{{ _docker_os_dist|lower }} \\\n      {{ ansible_lsb.codename }} {{ _docker_enable_channels | join(' ') }}\"\n    state: present\n    filename: 'docker-ce'\n"}, {"commit_sha": "4eeee9eb934aff6fd8af0b32e75128c884379f1d", "sha": "a02dca46af5049c0535e79c2ac7017e19e09fcea", "filename": "tasks/install.yml", "repository": "geerlingguy/ansible-role-solr", "decoded_content": "---\n- name: Ensure lsof is present (RedHat).\n  yum: name=lsof state=present\n  when: ansible_os_family == \"RedHat\"\n\n- name: Run Solr installation script.\n  shell: >\n    {{ solr_workspace }}/{{ solr_filename }}/bin/install_solr_service.sh\n    {{ solr_workspace }}/{{ solr_filename }}.tgz\n    -i {{ solr_install_dir }}\n    -d {{ solr_home }}\n    -u {{ solr_user }}\n    -s {{ solr_service_name }}\n    -p {{ solr_port }}\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "30dfc6f138aa3371add33554d5a348641bf3454b", "filename": "roles/osm/templates/etc.iiab.conf", "repository": "iiab/iiab", "decoded_content": ";; Local Configuration file for Internet-in-a-Box\n;;\n;;\n;\n;; [DEFAULT] is a special section.  Any settings there\n;; will automatically appear in all other sections.\n[DEFAULT]\n; Location of our dataset\nknowledge_dir = /library/knowledge\n; repeat all the other assignments to get the new dir\nprocessed_dir = %(knowledge_dir)s/processed\nmodules_dir = %(knowledge_dir)s/modules\ndata_dir = %(knowledge_dir)s/data\n\n; If search_for_knowledge_dir is true, then\n; the system will search all mounted volumes\n; for a \"knowledge/\" directory if the path\n; specified in knowledge_dir does not exist.\nsearch_for_knowledge_dir = True\n\n; Machine architecture.  This is set by the\n; application at run-time.\narch = unset\nbin_dir = %(knowledge_dir)s/sys/bin-%(arch)s\n\n"}, {"commit_sha": "dfc0ba24f91ba11cb33f713bd44c861c8070c006", "sha": "0397f62e61187b3e4120b513bfadb81d3abf34f8", "filename": "tasks/main-CentOS.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n# tasks file for ansible-role-docker-ce\n\n- name: Ensure yum-utils is installed\n  package:\n    name: yum-utils\n    state: present\n  become: true\n\n- name: Add Docker CE repository\n  get_url:\n    url: https://download.docker.com/linux/centos/docker-ce.repo\n    dest: /etc/yum.repos.d/docker-ce.repo\n    mode: 0644\n  become: true\n  register: yum_repo\n\n- name: Determine Docker CE Edge repo status\n  shell: yum-config-manager docker-ce-edge | grep enabled\n  ignore_errors: yes\n  changed_when: false\n  register: cmd_docker_ce_edge_enabled\n\n- name: Set current Docker CE Edge repo status fact\n  set_fact:\n    fact_docker_ce_edge_enabled: \"{{ cmd_docker_ce_edge_enabled.stdout == 'enabled = True' }}\"\n\n- name: Enable/Disable Docker CE Edge Repository\n  shell: yum-config-manager --{{ (docker_enable_ce_edge == true) | ternary('enable','disable') }} docker-ce-edge\n  become: true\n  when: fact_docker_ce_edge_enabled != docker_enable_ce_edge\n\n- name: Update yum cache\n  shell: yum makecache fast\n  args:\n    warn: false  \n  become: true\n  when: yum_repo.changed\n\n- include: main-Mountflags.yml\n  when: \"{{ ansible_kernel | version_compare('4', '<') }}\"\n\n- include: main-Generic.yml\n"}, {"commit_sha": "1d7d3a653c598355333e7c34a54a550ed3d79cc5", "sha": "f48ae6a9e04b2747e527c7fd2b6a9505de44eac1", "filename": "handlers/main.yml", "repository": "RocketChat/Rocket.Chat.Ansible", "decoded_content": "---\n# handlers/main.yml: Handlers for RocketChat.Ansible\n  - name: Reload the Nginx service\n    service: name=nginx state=reloaded\n\n  - name: Restart the MongoDB service\n    service: name=mongod state=restarted\n\n  - name: Upgrade Rocket.Chat\n    include: upgrade.yml\n    when: rocket_chat_deploy_state.stat.exists\n    tags:\n      - upgrade\n\n  - name: Update the Rocket.Chat service configuration\n    shell: \"{{ rocket_chat_service_update_command }}\"\n    when: rocket_chat_service_update_command is defined\n\n  - name: Restart the Rocket.Chat service\n    service: name=rocketchat state=restarted\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "9d3e2999b50d47e9d0b7ffb443bf3108391384df", "filename": "playbooks/bb1/add_user.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- name: Create new user\n  hosts: masters[0]\n  gather_facts: false\n  vars_prompt:\n  - name: username\n    prompt: Username\n    private: false\n  - name: password\n    prompt: Password\n    private: true\n  tasks:\n  - name: Add user\n    command: \"htpasswd -b /etc/origin/master/htpasswd {{username}} {{password}}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "d07965e78c474fd528110d205434e9bcba91611f", "filename": "roles/mysql/tasks/centos.yml", "repository": "iiab/iiab", "decoded_content": "    - name: Install MySQL\n      package: name={{ item }}\n               state=present\n      with_items:\n        - mysql-connector-python\n        - mariadb-server\n        - mariadb\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "98539eeab07c2ef468fde0bcb57bfc0bf0fff4c2", "filename": "roles/ansible/tower/manage-credential-types/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: tower\n  roles:\n  - role: ansible/tower/manage-credential-types"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "c78ffcaf5bd960d4e4db2ee3f26226cb0b5c2a60", "filename": "tasks/create_repo_npm_proxy_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_npm_proxy\n    args: \"{{ _nexus_repos_npm_defaults|combine(item) }}\"\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "1646ab63a3c4854dec9d21dec888318b9d95ea5b", "filename": "roles/user-management/manage-users/tests/create_idm.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n# This test covers the full feature set provided by the role\n\n- name: Create Test Identities\n  hosts: ipa\n\n  vars_files:\n    - vars/idm.json\n\n  vars:\n    ipa_admin_user: admin\n    ipa_admin_password: test123\n    ipa_host: idm.example.com \n\n  roles:\n    - manage-users\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "faea03a28e08d10e2d9ad7e101a41dba2814fca1", "filename": "handlers/main.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n# handlers file for ansible-role-docker-ce\n\n- name: restart docker\n  become: yes\n  service:\n    name: docker\n    state: restarted\n  tags: [\"install\", \"configure\"]\n\n- name: reload docker\n  become: yes\n  service:\n    name: docker\n    state: reloaded\n  tags: [\"install\", \"configure\"]\n\n# Workaround because systemd cannot be used: https://github.com/ansible/ansible/issues/22171\n- name: restart auditd\n  become: yes\n  command: service auditd restart\n  args:\n    warn: no\n  tags: [\"install\", \"configure\"]\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "e2f62318187a2c5ef26c5cd54c1419eb71fcd9c2", "filename": "tasks/setup-repository.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Include tasks for distribution {{ _docker_os_dist }} to setup repository\n  include_tasks: setup-repository-{{ _docker_os_dist }}.yml\n\n- name: Update repository cache\n  become: true\n  shell: \"{{ docker_cmd_update_repo_cache[_docker_os_dist] }}\"\n  args:\n    warn: false\n  changed_when: false\n  register: _result\n  until: _result is succeeded\n  when: docker_network_access\n  tags:\n    - skip_ansible_lint"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "e4fca181b4a2cacb32da4692642813d069e14b90", "filename": "roles/ansible/tower/manage-workflow-templates/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: tower\n  roles:\n  - role: ansible/tower/manage-workflow-templates\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "266baed251308d5a331e3bd6cd1c8db9091a7e76", "filename": "roles/manage-aws-infra/defaults/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\ndelete_vpc: false\n\ndefault_root_volume: '/dev/sda1'\ndefault_docker_volume: '/dev/xvdb'\ndefault_cns_volume: '/dev/xvdg'\n\ndefault_root_volume_size: '50'\ndefault_docker_volume_size: '40'\ndefault_cns_volume_size: '200'\n\n\ndefault_ocp_ssh_sg_rules:\n  - proto: tcp\n    from_port: 22\n    to_port: 22\n    cidr_ip: 0.0.0.0/0\n\ndefault_ocp_master_sg_rules:\n  - proto: udp\n    from_port: 8053\n    to_port: 8053\n    cidr_ip: 0.0.0.0/0\n  - proto: tcp\n    from_port: 8053\n    to_port: 8053\n    cidr_ip: 0.0.0.0/0\n  - proto: tcp\n    from_port: 8443\n    to_port: 8443\n    cidr_ip: 0.0.0.0/0\n  - proto: tcp\n    from_port: 443\n    to_port: 443\n    cidr_ip: 0.0.0.0/0\n  - proto: udp\n    from_port: 53\n    to_port: 53\n    cidr_ip: 0.0.0.0/0\n  - proto: tcp\n    from_port: 53\n    to_port: 53\n    cidr_ip: 0.0.0.0/0\n  - proto: udp\n    from_port: 4789\n    to_port: 4789\n    cidr_ip: 0.0.0.0/0\n\ndefault_ocp_app_node_sg_rules:\n  - proto: udp\n    from_port: 4789\n    to_port: 4789\n    cidr_ip: 0.0.0.0/0\n  - proto: tcp\n    from_port: 10250\n    to_port: 10250\n    cidr_ip: 0.0.0.0/0\n\ndefault_ocp_infra_node_sg_rules:\n  - proto: tcp\n    from_port: 80\n    to_port: 80\n    cidr_ip: 0.0.0.0/0\n  - proto: tcp\n    from_port: 443\n    to_port: 443\n    cidr_ip: 0.0.0.0/0\n\ndefault_ocp_cns_node_sg_rules:\n  - proto: tcp\n    from_port: 24007\n    to_port: 24007\n    cidr_ip: 0.0.0.0/0\n  - proto: tcp\n    from_port: 24008\n    to_port: 24008\n    cidr_ip: 0.0.0.0/0\n  - proto: tcp\n    from_port: 2222\n    to_port: 2222\n    cidr_ip: 0.0.0.0/0\n  - proto: tcp\n    from_port: 49152\n    to_port: 49664\n    cidr_ip: 0.0.0.0/0\n  - proto: tcp\n    from_port: 24010\n    to_port: 24010\n    cidr_ip: 0.0.0.0/0\n  - proto: tcp\n    from_port: 3260\n    to_port: 3260\n    cidr_ip: 0.0.0.0/0\n  - proto: tcp\n    from_port: 111\n    to_port: 111\n    cidr_ip: 0.0.0.0/0\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "280f2d6dfe174aff5a0d45d3058173ed3860eb01", "filename": "roles/elgg/README.rst", "repository": "iiab/iiab", "decoded_content": "===========\nELGG README\n===========\n\nElgg is an award-winning social networking engine, delivering the building blocks\nthat enable businesses, schools, universities and associations to create their own\nfully-featured social networks and applications.\n\nhttp://elgg.org/\n\nAfter Installation\n------------------\n\nGo to http://box.lan/elgg and log on as Admin with password changeme.\n\nChange the following:\n\n* Administrator password\n\n* Title to appear on elgg screens and any other settings as desired.\n\nLocations\n---------\n\n- The uploaded files are expected to be in /library/elgg\n- The URL is /elgg\n\nParameters\n----------\n\nPlease review vars/main.yml as the installation parameters have\nsome constraints.\n\nUsers and Passwords\n-------------------\n\nThere are a number of seemilingly similar user names and passwords in this installation:\n\n* dbuser - the mysql user that elgg uses to access the database.  This is a local variable\n           the name of which corresponds to that in the elgg settings.php file.\n\n* dbpassword - password for dbuser. This is also a local variable\n               the name of which corresponds to that in the elgg settings.php file.\n\n* elgg_mysql_password - this is the global name for dbpassword in default_vars.yml.\n\n* elgg_admin_user - the elgg (not mysql) user that is the administrator.\n\n* elgg_admin_password - the password for elgg_admin_user.\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "00eb0495f73f92553c722f8b35f3bd057259c0b9", "filename": "tasks/section_06.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - include: section_06_level1.yml\n    tags:\n      - section06\n      - level1\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "b70487523b453e17ebd779b656188476f099494d", "filename": "playbooks/minishift-remote/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_playbook: ../prep.yml\n  when:\n  - rhsm_register|default(False)\n\n- import_playbook: ../osp/manage-user-network.yml\n  when:\n    - (provision_infrastructure | default(False)) | bool\n    - hosting_infrastructure == 'openstack'\n\n- import_playbook: ../osp/provision-osp-instance.yml\n  when:\n    - (provision_infrastructure | default(False)) | bool\n    - hosting_infrastructure == 'openstack'\n\n- hosts: minishift_remote\n  tasks:\n    - name: Set IP address of OpenStack instance\n      set_fact:\n        minishift_host_ip: \"{{ openstack.public_v4 }}\"\n      when:\n        - (provision_infrastructure | default(False)) | bool\n        - hosting_infrastructure == 'openstack'\n\n- hosts: minishift_remote\n  tasks:\n    - name: \"Subscribe RHEL based instances\"\n      include_role: \n        name: rhsm\n      vars:\n        rhsm_username: \"{{ hostvars['localhost'].rhsm_username|default(omit) }}\"\n        rhsm_password: \"{{ hostvars['localhost'].rhsm_password|default(omit) }}\"\n      when:\n        - rhsm_register|default(False)\n\n- import_playbook: configure-minishift-remote.yml"}, {"commit_sha": "f3dd45a61b08de1b3351140cc442a705cb2fad82", "sha": "c69f1056565a4509b53a7d530353c10dab6322eb", "filename": "tasks/autoupdate-RedHat.yml", "repository": "geerlingguy/ansible-role-security", "decoded_content": "---\n- name: Install yum-cron.\n  package: name=yum-cron state=present\n\n- name: Ensure yum-cron is running and enabled on boot.\n  service: name=yum-cron state=started enabled=yes\n\n- name: Configure autoupdates (RHEL 7).\n  lineinfile:\n    dest: \"/etc/yum/yum-cron.conf\"\n    regexp: '^apply_updates = .+'\n    line: 'apply_updates = yes'\n  when: security_autoupdate_enabled and ansible_distribution_major_version | int == 7\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "28cb524633eabd49f8af723380de82cd00251c00", "filename": "roles/network/tasks/computed_network.yml", "repository": "iiab/iiab", "decoded_content": "# just lie about active gateway present on XOs to suppress ifcfg-WAN\n# auto-creation/moving with XOs using NM/system-connections/ via keyfile.\n# ifcfg-rh acts on /etc/sys*/net*/ifcfg-* where we search for devices.\n- name: Setting XO has wifi gateway\n  set_fact:\n     user_wan_iface: \"{{ discovered_wan_iface }}\"\n  when: discovered_wan_iface != \"none\" and xo_model != \"none\" and has_ifcfg_gw == \"none\"\n\n- name: Checking for NetworkManager-config-server\n  shell: rpm -qa | grep  NetworkManager-config-server | wc -l\n  register: strict_networking_check\n\n- name: Found Checking for NetworkManager-config-server\n  set_fact:\n     strict_networking: True\n  when: strict_networking_check == \"1\"\n\n- name: Use restricted network features\n  set_fact:\n     iiab_demo_mode: True\n  when: teamviewer_install and not strict_networking\n\n- name: XO wants usb wifi interface as AP mode\n  set_fact:\n     iiab_wireless_lan_iface: \"{{ discovered_lan_iface }}\"\n  when: num_wifi_interfaces >= \"2\" and xo_model != \"none\" and discovered_wan_iface != \"none\" and discovered_wireless_iface == \"eth0\"\n\n# static backout suppy new template file\n- name: gui-static-wan\n  set_fact:\n    wan_ip: dhcp\n    gui_static_wan_ip: undefined\n  when: gui_static_wan_ip != \"unset\" and not gui_static_wan\n\n- name: undo gui-static-wan by requesting new template file\n  set_fact:\n     has_WAN: False\n  when: gui_static_wan_ip != \"unset\" and not gui_static_wan\n\n# figure out more than one interfaces to detect.\n- name: Using GUI_STATIC info\n  set_fact:\n    has_WAN: False\n    has_ifcfg_gw: \"none\"\n    wan_ip: \"{{ gui_static_wan_ip }}\"\n    wan_netmask: \"{{ gui_static_wan_netmask }}\"\n    wan_gateway: \"{{ gui_static_wan_gateway }}\"\n    wan_nameserver: \"{{ gui_static_wan_nameserver }}\"\n  when: gui_static_wan and user_wan_iface != \"auto\"\n\n# we need to have an interface name for ifcfg-WAN to be able to change gateway\n# the DEVICE from the gui. Thanks to George for proving my point about knowing\n# what device to switch to.\n#- name: Using GUI_WAN info\n#  set_fact:\n#    user_wan_iface: \"{{ gui_wan_iface }}\"\n#  when: gui_wan_iface != \"unset\" and gui_desired_network_role is defined and gui_desired_network_role != \"LanController\"\n\n# should make the GUI buttons the last call\n- name: Checking iiab_wan_enabled\n  set_fact:\n    user_wan_iface: \"none\"\n  when: 'not iiab_wan_enabled'\n\n# gui wants LanController # keeps ifcfg-WAN but onboot=no\n# the change over might be a little bumpy ATM.\n- name: Setting GUI wants LanController\n  set_fact:\n    device_gw: \"none\"\n    user_wan_iface: \"none\"\n    iiab_gateway_enabled: \"False\"\n  when: gui_desired_network_role is defined and gui_desired_network_role == \"LanController\"\n\n# device_gw is used with the LAN detection and LAN's ifcfg file deletion.\n# single interface vars/ users would need to set iiab_wan_enabled False as above, to disable the WAN\n# and set user_lan_iface = <device> to suppress the auto detection for the same effect.\n\n- name: Setting user_lan_iface for LanController for single interface\n  set_fact:\n     user_lan_iface: \"{{ discovered_wan_iface }}\"\n  when: discovered_wan_iface != \"none\" and num_lan_interfaces == \"0\" and gui_desired_network_role is defined and gui_desired_network_role == \"LanController\"\n\n# override with user_wan_iface setting if no longer in auto\n- name: setting user WAN fact\n  set_fact:\n    iiab_wan_iface: \"{{ user_wan_iface }}\"\n  when: user_wan_iface != \"auto\"\n\n# user disabled interface - overriding all other entries\n- name: Checking iiab_lan_enabled\n  set_fact:\n    user_lan_iface: \"none\"\n  when: 'not iiab_lan_enabled'\n\n# gui wants Appliance Note: could of used iiab_lan_enabled false\n- name: Setting GUI wants Appliance\n  set_fact:\n    user_lan_iface: \"none\"\n    iiab_gateway_enabled: \"False\"\n  when: gui_desired_network_role is defined and gui_desired_network_role == \"Appliance\"\n\n# gui wants Gateway\n- name: Setting GUI wants and has active Gateway\n  set_fact:\n    user_lan_iface: \"auto\"\n    user_wan_iface: \"{{ iiab_wan_iface }}\"\n  when: gui_desired_network_role is defined and gui_desired_network_role == \"Gateway\" and iiab_wan_iface != \"none\"\n\n# make it so number 2 vars should use user_wan_iface but we can cover a single\n# wired if dhcp fails the interface should revert to LAN, static address should\n# stick around but testing gateway response is not preformed.\n- name: User wants single wired interface as static or dhcp gateway\n  set_fact:\n     user_wan_iface: \"{{ discovered_lan_iface }}\"\n  when: num_lan_interfaces == \"1\" and user_lan_iface == \"auto\" and user_wan_iface == \"auto\"\n\n- name: No LAN configured - Appliance mode\n  set_fact:\n    iiab_network_mode: \"Appliance\"\n  when: iiab_lan_iface == \"none\"\n\n- name: LAN configured - LanController mode\n  set_fact:\n    iiab_network_mode: \"LanController\"\n  when: iiab_lan_iface != \"\" and iiab_wan_iface == \"none\"\n\n- name: LAN configured - Gateway mode\n  set_fact:\n    iiab_network_mode: \"Gateway\"\n  when: iiab_lan_iface != \"none\" and iiab_wan_iface != \"none\"\n\n# override with user_lan_iface setting if no longer in auto\n- name: Setting user LAN fact\n  set_fact:\n    iiab_lan_iface: \"{{ user_lan_iface }}\"\n  when: 'user_lan_iface != \"auto\"'\n\n# so this works\n- name: interface count\n  shell: ls /sys/class/net | grep -v -e lo | wc | awk '{print $1}'\n  register: adapter_count\n\n# well if there ever was a point to tell the user thing are FUBAR this is it.\n- name: We're hosed no work interfaces\n  set_fact:\n    iiab_network_mode: \"No_network_found\"\n  when: adapter_count.stdout|int == \"0\"\n\n# well if there ever was a point to tell the user thing are FUBAR this is it.\n- name: I'm not guessing declare gateway please\n  set_fact:\n    iiab_network_mode: \"Undetectable_use_local_vars\"\n    iiab_wan_iface: \"none\"\n  when: adapter_count.stdout|int >= \"5\" and device_gw == \"none\" and gui_wan_iface == \"unset\" and gui_static_wan is defined\n\n- name: Add location section to config file\n  ini_file: dest='{{ iiab_config_file }}'\n            section=network\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n  - option: 'iiab_wan_enabled'\n    value: '{{ iiab_wan_enabled }}'\n  - option: 'user_wan_iface'\n    value: '{{ user_wan_iface }}'\n  - option: 'iiab_wan_iface'\n    value: '{{ iiab_wan_iface }}'\n  - option: 'iiab_lan_enabled'\n    value: '{{ iiab_lan_enabled }}'\n  - option: 'user_lan_iface'\n    value: '{{ user_lan_iface }}'\n  - option: 'iiab_lan_iface'\n    value: '{{ iiab_lan_iface }}'\n  - option: 'iiab_network_mode'\n    value: '{{ iiab_network_mode }}'\n  - option: 'hostapd_enabled'\n    value: '{{ hostapd_enabled }}'\n  - option: 'host_ssid'\n    value: '{{ host_ssid }}'\n  - option: 'host_wifi_mode'\n    value: '{{ host_wifi_mode }}'\n  - option: 'host_channel'\n    value: '{{ host_channel }}'\n"}, {"commit_sha": "d7fbb1f61d1191166152acc249d0e910859619ca", "sha": "d2893bcfb3c4cfc0ec7a2b9d4b33496d780c1bf4", "filename": "tasks/main.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Set distribution facts\n  set_fact:\n    _docker_os_dist: \"{{ ansible_distribution }}\"\n    _docker_os_dist_release: \"{{ ansible_distribution_release }}\"\n    _docker_os_dist_major_version: \"{{ ansible_distribution_major_version }}\"\n    _docker_os_dist_check: yes\n  tags: [\"install\", \"configure\"]\n\n- name: Reinterpret distribution facts for Linux Mint 18\n  set_fact:\n    _docker_os_dist: \"Ubuntu\"\n    _docker_os_dist_release: \"xenial\"\n    _docker_os_dist_major_version: \"16\"\n  when:\n    _docker_os_dist == \"Linux Mint\" and\n    _docker_os_dist_major_version == \"18\"\n  tags: [\"install\", \"configure\"]\n\n# https://wiki.ubuntu.com/SystemdForUpstartUsers\n# Important! systemd is only fully supported in Ubuntu 15.04 and later releases\n- name: Determine usage of systemd\n  become: true\n  shell: \"ps -p1 | grep systemd 1>/dev/null && echo systemd || echo upstart\"\n  changed_when: no\n  register: _determine_systemd_usage\n\n- name: Set fact to indicate systemd is not used\n  set_fact:\n    _docker_systemd_used: \"{{ _determine_systemd_usage is defined and _determine_systemd_usage.stdout == 'systemd' }}\"\n\n- name: Compatibility and distribution checks\n  include_tasks: checks.yml\n  tags: [\"install\", \"configure\"]\n\n- name: Setup Docker package repositories\n  include_tasks: setup-repository.yml\n  tags: [\"install\"]\n\n- name: Remove Docker versions before Docker CE\n  include_tasks: remove-pre-docker-ce.yml\n  when: docker_remove_pre_ce | bool\n  tags: [\"install\"]\n\n- name: Install Docker\n  include_tasks: install-docker.yml\n  tags: [\"install\"]\n\n- name: Configure audit logging\n  include_tasks: setup-audit.yml\n  tags: [\"configure\"]\n\n- name: Apply workarounds for bugs and/or tweaks\n  include_tasks: bug-tweaks.yml\n  tags: [\"configure\"]\n\n- name: Configure systemd service\n  include_tasks: configure-systemd.yml\n  when: _docker_systemd_used | bool\n  tags: [\"configure\"]\n\n- name: Configure non-systemd service\n  include_tasks: configure-non-systemd.yml\n  when: _docker_systemd_used | bool == false\n  tags: [\"configure\"]\n\n- name: Configure Docker\n  include_tasks: configure-docker.yml\n  tags: [\"configure\"]\n\n- name: Postinstall tasks\n  include_tasks: postinstall.yml\n  tags: [\"install\"]"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "cde15b2322887f0b4f40ebbe8dd1629375516fa4", "filename": "tasks/create_repo_docker_proxy_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_docker_proxy\n    args: \"{{ _nexus_repos_docker_defaults|combine(item) }}\"\n"}, {"commit_sha": "dfc0ba24f91ba11cb33f713bd44c861c8070c006", "sha": "f4304222375ebc295e5ec770f8940729cb867e45", "filename": "tasks/main-Generic.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n# tasks file for ansible-role-docker-ce\n\n- name: Copy Docker audit rules\n  copy:\n    src: files/etc/audit/rules.d/docker.rules\n    dest: /etc/audit/rules.d/docker.rules\n  become: yes\n  notify: restart auditd\n  when: docker_enable_audit == true\n\n- name: Ensure Docker audit rules are removed\n  file:\n    path: /etc/audit/rules.d/docker.rules\n    state: absent\n  become: yes\n  notify: restart auditd\n  when: docker_enable_audit == false\n\n- name: Determine Docker version\n  command: bash -c \"docker version | grep Version | awk '{print $2}'\"\n  ignore_errors: yes\n  changed_when: false\n  register: cmd_docker_version\n\n- name: Set fact if old Docker installation shall be removed\n  set_fact:\n    remove_old_docker: \"{{docker_remove_pre_ce | bool }} == true and {{ cmd_docker_version.stdout_lines[0] | search('-ce') }} == false\"\n  when: cmd_docker_version.stdout_lines is defined and cmd_docker_version.stdout_lines[0] is defined\n\n- name: Check if Docker is running\n  command: systemctl status docker\n  ignore_errors: yes\n  changed_when: false\n  register: service_docker_status\n  when: remove_old_docker | default(false) | bool == true\n  become: true\n\n- name: Stop Docker service\n  service:\n    name: docker\n    state: stopped\n  when: \"service_docker_status.rc | default(1) == 0\"\n\n- name: Remove old Docker installation before Docker CE\n  package:\n    name: \"{{ item }}\"\n    state: absent\n  become: true\n  when: remove_old_docker|default(false) | bool == true\n  with_items:\n    - docker\n    - docker-common\n    - container-selinux\n    - docker-selinux\n    - docker-engine\n\n- name: Ensure docker-ce is the latest version\n  package:\n    name: docker-ce\n    state: latest\n  become: true\n  notify: restart docker\n\n- name: Ensure /etc/docker directory exists\n  file:\n    path: /etc/docker\n    state: directory\n    mode: 0755\n  become: true\n\n- name: Configure Docker daemon (file)\n  copy:\n    src: \"{{ docker_daemon_config_file }}\"\n    dest: /etc/docker/daemon.json\n  become: true\n  notify: restart docker\n  when: docker_daemon_config_file is defined\n\n- name: Configure Docker daemon (variables)\n  copy:\n    content: \"{{ docker_daemon_config | to_nice_json }}\"\n    dest: /etc/docker/daemon.json\n  become: true\n  notify: restart docker\n  when: docker_daemon_config_file is not defined and \n        docker_daemon_config is defined\n\n- name: Ensure Docker default user namespace is defined in subuid and subgid\n  lineinfile:\n    path: \"{{ item }}\"\n    regexp: '^dockremap'\n    line: 'dockremap:500000:65536'\n  become: yes\n  with_items:\n    - /etc/subuid\n    - /etc/subgid\n  when: (docker_daemon_config is defined and\n        docker_daemon_config['userns-remap'] is defined and\n        docker_daemon_config['userns-remap'] == 'default') or\n        docker_bug_usermod|bool == true\n\n- name: Enable and start Docker service\n  service:\n    name: docker\n    state: started\n    enabled: true\n  become: true\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "d8773365b0af21afd366d39754a67c6b55c4cd56", "filename": "roles/osp/packstack-install/tasks/host-prep.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Disable firewalld and NetworkManager\"\n  service:\n    name: \"{{ item }}\"\n    state: stopped\n    enabled: no\n  with_items:\n  - 'NetworkManager'\n  - 'firewalld'\n\n- name: \"Enable and start 'network' service\"\n  service:\n    name: \"{{ item }}\"\n    state: started\n    enabled: yes\n  with_items:\n  - 'network'\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "1c2ebc923d09dfba3ab049f8a55c616d6c58bd53", "filename": "roles/disconnected-git/handlers/main.yaml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n- name: restart httpd\n  service: \n    name: httpd\n    state: restarted"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "96b7aa20d78e3d5a786155c336ab5e77c3888156", "filename": "tasks/modules/install-geoip.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: CentOS) Install GeoIP Required CentOS Dependencies\"\n  yum:\n    name:\n      - epel-release\n  when: ansible_distribution == \"CentOS\"\n\n- name: \"(Install: All OSs) Install NGINX Open Source GeoIP Module\"\n  package:\n    name: nginx-module-geoip\n    state: present\n  when: nginx_type == \"opensource\"\n\n- name: \"(Install: All OSs) Install NGINX Plus GeoIP Module\"\n  package:\n    name: nginx-plus-module-geoip\n    state: present\n  when: nginx_type == \"plus\"\n\n- name: \"(Setup: All NGINX) Load NGINX GeoIP Module\"\n  lineinfile:\n    path: /etc/nginx/nginx.conf\n    insertbefore: BOF\n    line: \"{{ item }}\"\n  with_items:\n    - load_module modules/ngx_http_geoip_module.so;\n    - load_module modules/ngx_stream_geoip_module.so;\n  when: not nginx_main_template_enable\n  notify: \"(Handler: All OSs) Reload NGINX\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "53bc5212449d571ba9e4642e5690c6e2a59dc6c4", "filename": "roles/setup-slack/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Test slack setup\n  hosts: localhost\n  roles:\n    - setup-slack"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "6d7266b35ac0526451c1520ef820a4173560a0f6", "filename": "roles/zookeeper/handlers/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# handlers file for zookeeper\n- name: restart zookeeper\n  service:\n    name: zookeeper\n    state: restarted\n  sudo: yes\n\n- name: start zookeeper\n  service:\n    name: zookeeper\n    state: started\n  sudo: yes\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "076ea111c8bf9d916dd3f52677703bb4e1903ee8", "filename": "roles/haproxy/tasks/haproxy.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Copy the HAproxy config file to a temp location for validity checking'\n  copy: \n    src: '{{ haproxy_temp_file }}'\n    dest: '{{ temp_new_file }}'\n\n- name: 'Check the validity' \n  command: 'haproxy -c -f {{ temp_new_file }}'\n  notify: 'remove tmp new file'\n\n- name: 'Copy and activate the HAproxy config file'\n  copy: \n    src: '{{ haproxy_temp_file }}'\n    dest: '/etc/haproxy/haproxy.cfg'\n    backup: 'yes'\n  notify: 'reload haproxy'\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "88932ebd08e2a8469a4b1803222b7ca7d560ba0d", "filename": "tasks/Win32NT/install/package.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Install java packages\n  win_package:\n    path: '{{ java_artifact }}'\n    product_id: '{{ java_product_id }}'\n    state: present\n    arguments: '/s INSTALLDIR=\"{{ java_path }}\\{{ java_folder }}\"'\n    creates_path: '{{ java_path }}\\{{ java_folder }}'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "b8780bdfa288d1b130c6a9a62fdec50cc32d0a99", "filename": "roles/osp/packstack-install/tasks/prereq.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Install required packages'\n  package:\n    name: '{{ item }}'\n    state: installed\n  with_items:\n  - openstack-packstack\n\n- name: 'Ensure necessary directories exists'\n  file:\n    path: \"{{ ssl_cert_directory }}\"\n    state: directory\n\n- name: 'Copy certificates over to the host'\n  copy:\n    src: \"{{ ssl_cert_src_dir }}\"\n    dest: \"{{ ssl_cert_directory }}\"\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "fc0f0c8493cfd25e3b74c1db31296d10cd970dc9", "filename": "roles/user-management/manage-atlassian-users/tasks/create_atlassian_groups.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Create Group\n  uri:\n    url: '{{ atlassian_url }}/rest/api/2/group'\n    method: POST\n    status_code: [201, 400]\n    user: '{{ atlassian_username }}'\n    password: '{{ atlassian_password }}'\n    force_basic_auth: yes\n    body_format: json\n    body: \"{'name': '{{ group }}' }\"\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "5804bc65c2d68f7904bc7059f4ae02f0e81ff41f", "filename": "roles/ovirt-engine-backup/defaults/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\novirt_engine_type: 'ovirt-engine'\novirt_backup_mode: 'backup'\novirt_backup_archive: '/tmp/engine-backup.gzip'\novirt_backup_log_file: '/tmp/engine-backup.log'\novirt_backup_scope: 'all'\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "7870b1f5818e981a3a75575ba8541a46ee71672d", "filename": "roles/ansible/tower/manage-projects/tests/inventory/group_vars/tower.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ntower_admin_password: \"admin01\"\n\nansible_tower_projects:\n- name: \"Project1\"\n  description: \"My Project\"\n  scm_type: \"git\"\n  scm_url: \"https://github.com/redhat-cop/infra-ansible.git\"\n  scm_branch: \"master\"\n  organization: \"Default\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "aed7770b152443fb4b7d3557f6c99a61e0a3cdda", "filename": "roles/network/templates/avahi/portal.service", "repository": "iiab/iiab", "decoded_content": "<?xml version=\"1.0\" standalone='no'?><!--*-nxml-*-->\n<!DOCTYPE service-group SYSTEM \"avahi-service.dtd\">\n<service-group>\n<name replace-wildcards=\"yes\">PORTAL at %h </name>\n<service>\n<type>_http._tcp</type>\n<port>80</port>\n</service>\n</service-group>\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "f78df9481cb2da316c9aa3add5f5ca27af2c3aa6", "filename": "roles/dcos_cli/handlers/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# handlers file for dcos-cli\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "b741aa3dbce62c5259099ec357a14dfd1ac7e2ff", "filename": "playbooks/nagios/roles", "repository": "redhat-cop/casl-ansible", "decoded_content": "../../roles"}, {"commit_sha": "e91a55152358e890a05cf849abc7d58b8badecc2", "sha": "226ab0cade95711a11672eaf780e290b5c39fa7c", "filename": "tasks/install.yml", "repository": "fubarhouse/ansible-role-golang", "decoded_content": "---\n- name: \"Go-Lang | Define shell exports\"\n  set_fact:\n    shell_exports:\n      - regex: \"export GOROOT\"\n        lineinfile: \"export GOROOT={{ GOROOT }}\"\n      - regex: \"export GOPATH\"\n        lineinfile: \"export GOPATH={{ GOPATH }}\"\n      - regex: \"PATH:{{ GOROOT }}/bin\"\n        lineinfile: \"export $PATH:{{ GOROOT }}/bin\"\n      - regex: \"PATH:{{ GOPATH }}\"\n        lineinfile: \"export $PATH=$PATH:{{ GOPATH }}\"\n      - regex: \"PATH:{{ GOPATH }}/bin\"\n        lineinfile: \"export $PATH=$PATH:{{ GOPATH }}/bin\"\n  when: shell_exports is not defined\n\n- name: \"Go-Lang | Include bootstrap tasks\"\n  include: install-bootstrap.yml\n  when:\n    - install_go_bootstrap|bool == true\n    - go_binary_bootstrap.stat.exists|bool == false\n    - GOROOT_BOOTSTRAP is defined\n    - expected_go_version_output|string not in current_go_version.stdout|default('')\n\n- name: \"Go-Lang | Include source build tasks\"\n  include: install-git.yml\n  when:\n    - build_go_from_source|bool == true\n    - expected_go_version_output|string not in current_go_version.stdout|default('')\n\n- name: \"Go-Lang | Include distro install tasks\"\n  include: install-distro.yml\n  when:\n    - build_go_from_source|bool == false\n    - expected_go_version_output|string not in current_go_version.stdout|default('')\n\n- name: \"Go-Lang | Detect configured shell profiles\"\n  stat:\n    path: \"{{ fubarhouse_user_dir }}/{{ item }}\"\n  changed_when: false\n  failed_when: false\n  with_items: \"{{ shell_profiles }}\"\n  register: stat_shell_profiles\n  when:\n  - stat_shell_profiles is defined\n  - shell_profiles is defined\n\n- name: \"Go-Lang | Ensure shell profiles are configured\"\n  lineinfile:\n    dest: \"{{ item[0].stat.path }}\"\n    regexp: \"{{ item[1].regex }}\"\n    line: \"{{ item[1].lineinfile }}\"\n    state: present\n  with_nested:\n  - \"{{ stat_shell_profiles.results }}\"\n  - \"{{ shell_exports }}\"\n  when:\n  - stat_shell_profiles is defined\n  - shell_profiles is defined\n  - item[0].stat.exists|bool == true\n\n- name: \"Go-Lang | Verify version\"\n  shell: \"{{ GOROOT }}/bin/go version\"\n  environment:\n    GOROOT: \"{{ GOROOT }}\"\n    GOPATH: \"{{ GOPATH }}\"\n  register: go_version_output\n  failed_when: go_version_string not in go_version_output.stdout\n  changed_when: false\n\n- name: \"Go-Lang | Restart shell\"\n  shell: \"{{ fubarhouse_user_dir }}/{{ item }}\"\n  with_items: \"{{ shell_profiles }}\"\n  failed_when: false\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "7b9ade87ed0e2abf2cd4ef66a42bce2b06ca0995", "filename": "playbooks/roles", "repository": "redhat-cop/casl-ansible", "decoded_content": "../roles/"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "f5394ce16e6b8f5854b62fe4618eb0a8f72621c5", "filename": "roles/config-iscsi-client/tasks/configure_lvm.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Detect the physical device based on iSCSI lun\"\n  shell: 'lsscsi | sed -ne \"s/.*:{{ disk.lun }}].*{{ iscsi_brand }}.*\\(\\/dev\\/.*\\)$/\\1/p\"'\n  register: lsscsi\n\n- name: \"Detect the multipath device id based on physical device\"\n  shell: 'multipath -l {{ lsscsi.stdout_lines[0] }} | sed -ne \"s/\\([^ ]*\\).*{{ iscsi_brand }}.*/\\1/p\"' \n  register: multipath_id\n\n- name: \"Setup and create PV & VG\"\n  lvg:\n    vg: \"{{ disk.vg }}\"\n    pvs: \"/dev/mapper/{{ multipath_id.stdout }}\"\n    force: yes\n\n- name: \"Setup LV\"\n  lvol: \n    vg: \"{{ disk.vg }}\"\n    lv: \"{{ disk.lv }}\"\n    force: yes\n    size: \"100%VG\"\n  when: \n  - disk.lv is defined\n  - disk.lv|trim != ''\n\n- name: \"Create file system on share\"\n  filesystem:\n    fstype: xfs\n    dev: \"/dev/mapper/{{ disk.vg }}-{{ disk.lv }}\"\n  when: \n  - disk.lv is defined\n  - disk.lv|trim != ''\n\n- name: \"Ensure the base dir for the mount point exists\" \n  file:\n    path: \"{{ disk.mount_path|dirname }}\"\n    state: directory\n  when: \n  - disk.mount_path is defined\n  - disk.mount_path|trim != ''\n\n- name: \"Mount the share\"\n  mount:\n    src: \"/dev/mapper/{{ disk.vg }}-{{ disk.lv }}\"\n    path: \"{{ disk.mount_path }}\"\n    opts: _netdev\n    fstype: xfs \n    state: mounted\n  when: \n  - disk.mount_path is defined\n  - disk.mount_path|trim != ''\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "13e7d4f5c8a2d598b0eac088ece3b316008e22b5", "filename": "roles/config-selinux/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Configure SELinux\"\n  selinux:\n    state: \"{{ target_state | default('enforcing') }}\"\n    policy: \"{{ (target_state == 'disabled') | ternary(omit, target_policy) }}\"\n\n- name: \"Relabel SElinux contexts\"\n  command: \"restorecon -r {{ selinux_relabel_dir | default('/') }}\"\n  when: selinux_relabel | default('no') | bool\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "8f142579065ef690e154e5a47a5d72934d548982", "filename": "roles/virt-install/tasks/virt-install.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Populate values for virt install run\"\n  set_fact:\n    virtinstall_connect: \"{{ hostvars[vm]['libvirt_connect'] | default(default_connect) }}\"\n    virtinstall_virt_type: \"{{ hostvars[vm]['libvirt_virt_type'] | default(default_virt_type) }}\"\n    virtinstall_name: \"{{ hostvars[vm]['libvirt_name'] | default(default_name) }}\"\n    virtinstall_title: \"{{ hostvars[vm]['libvirt_title'] | default(default_title) }}\"\n    virtinstall_description: \"{{ hostvars[vm]['libvirt_description'] | default(default_description) }}\"\n    virtinstall_memory: \"{{ hostvars[vm]['libvirt_memory'] | default(default_memory) }}\"\n    virtinstall_vcpus: \"{{ hostvars[vm]['libvirt_vcpus'] | default(default_vcpus) }}\"\n    virtinstall_disk_size: \"{{ hostvars[vm]['libvirt_disk_size'] | default(default_disk_size) }}\"\n    virtinstall_disk_pool: \"{{ hostvars[vm]['libvirt_disk_pool'] | default(default_disk_pool) }}\"\n    virtinstall_os_variant: \"{{ hostvars[vm]['libvirt_os_variant'] | default(default_os_variant) }}\"\n    virtinstall_iso: \"{{ hostvars[vm]['libvirt_iso'] | default(default_iso) }}\"\n    virtinstall_ksfile: \"{{ hostvars[vm]['libvirt_ksfile'] | default(default_ksfile) }}\"\n    virtinstall_authorized_keys: \"{{ hostvars[vm]['libvirt_authorized_keys'] | default(default_authorized_keys) }}\"\n    virtinstall_http_host: \"{{ hostvars[vm]['libvirt_http_host'] | default(default_http_host) }}\"\n    virtinstall_network_hostif: \"{{ hostvars[vm]['libvirt_network_hostif'] | default(default_network_hostif) }}\"\n    virtinstall_network_model: \"{{ hostvars[vm]['libvirt_network_model'] | default(default_network_model) }}\"\n    virtinstall_network_type: \"{{ hostvars[vm]['libvirt_network_type'] | default(default_network_type) }}\"\n\n- name: \"Make KS file available on the target host\"\n  copy: \n    src: \"{{ virtinstall_ksfile }}\"\n    dest: \"/tmp/{{ virtinstall_ksfile | basename }}\"\n\n- name: \"Make the authorized_keys file available on the target host\"\n  copy: \n    src: \"{{ virtinstall_authorized_keys }}\"\n    dest: \"{{ default_http_dir }}/{{ virtinstall_authorized_keys | basename }}\"\n  notify: 'Remove authorized_keys'\n\n- name: \"Make a mount point for install purpose\"\n  tempfile:\n    state: directory\n    prefix: install\n    path: \"{{ default_http_dir }}\"\n  register: http_mount\n  when: \n  - mounted_iso[virtinstall_iso] is not defined\n\n- name: \"Mount ISO to serv it up with http\"\n  mount:\n    src: \"{{ virtinstall_iso }}\"\n    path: \"{{ http_mount.path }}\"\n    opts: loop\n    fstype: iso9660\n    state: mounted\n  notify: 'Unmount install ISO'\n  when:\n  - mounted_iso[virtinstall_iso] is not defined\n\n- name: 'Track mounted iso'\n  set_fact: \n    mounted_iso: \"{{ mounted_iso | combine({ virtinstall_iso : http_mount.path }) }}\"\n  when:\n  - mounted_iso[virtinstall_iso] is not defined\n\n- name: \"Set Fact for VM command\"\n  set_fact:\n    virt_install_commands: \"{{ virt_install_commands | default([]) + [ ('virt-install' + ' --connect ' + virtinstall_connect + ' --virt-type ' + virtinstall_virt_type + ' --name ' + virtinstall_name + ' --metadata \\\"title=' + virtinstall_title + ',description=' + virtinstall_description + ',name=' + virtinstall_name + '\\\"' + ' --network \\\"type='+ virtinstall_network_type + ',source=' + virtinstall_network_hostif + ',source_mode=bridge,model=' + virtinstall_network_model + '\\\"' + ' --memory ' + virtinstall_memory + ' --vcpus ' + virtinstall_vcpus + ' --disk pool=' + virtinstall_disk_pool + ',size=' + virtinstall_disk_size + ',bus=virtio' + ' --os-variant ' + virtinstall_os_variant + ' --location http://' + virtinstall_http_host + '/' + mounted_iso[virtinstall_iso] | basename + ' --initrd-inject=/tmp/' + virtinstall_ksfile | basename + ' --extra-args \\\"inst.repo=http://' + virtinstall_http_host + '/' + mounted_iso[virtinstall_iso] | basename + ' inst.ks=file:/' + virtinstall_ksfile | basename + '\\\"' + ' --graphics spice ' + ' --video qxl ' + ' --channel spicevmc ' + ' --autostart ') ] }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "53be2f52dcbbadb8caf3723f156205ede2158400", "filename": "roles/config-redis/tasks/firewall.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Check if firewalld is installed\n  command: systemctl status firewalld\n  register: firewalld_status\n  failed_when: false\n  changed_when: false\n\n- name: Check if iptables is installed\n  command: systemctl status iptables\n  register: iptables_status\n  failed_when: false\n  changed_when: false\n\n- name: Open port in firewalld\n  firewalld:\n    port: \"{{ redis_host_port }}/tcp\"\n    permanent: true\n    state: enabled\n  when: firewalld_status.rc == 0\n  notify:\n  - restart firewalld\n\n- name: Open iptables Redis firewall port for future sessions\n  lineinfile:\n    insertbefore: \"-A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT\"\n    state: present\n    dest: /etc/sysconfig/iptables\n    regexp: \"^-A INPUT .* --dport {{ redis_host_port }} .* ACCEPT\"\n    line: \"-A INPUT -p tcp -m state --state NEW -m tcp --dport {{ redis_host_port }} -j ACCEPT\"\n  when: iptables_status.rc == 0 and firewalld_status.rc != 0\n  # notify:\n  # - restart iptables\n\n- name: Open iptables Redis firewall port for current session\n  iptables:\n    action: insert\n    protocol: tcp\n    destination_port: \"{{ redis_host_port }}\"\n    state: present\n    chain: INPUT\n    jump: ACCEPT\n  when: iptables_status.rc == 0 and firewalld_status.rc != 0\n"}, {"commit_sha": "9662c15ce2e4260fac5cc2bfdf5aaaaf0a2191dd", "sha": "7e5e505661a5357db1dae855ef1fdb3bfe181740", "filename": "tasks/section_02_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: Check the presence of the file \"cis.conf\" under modprobe.d\n    stat: >\n        path=/etc/modprobe.d/CIS.conf\n    register: cis_conf_file\n    tags:\n      - section2\n      - section2.18\n\n  - name: Create the file \"cis.conf\" under modprobe.d if doesn't exist\n    file: >\n        dest=/etc/modprobe.d/CIS.conf state=touch\n    when: not cis_conf_file.stat.exists\n    tags:\n      - section2\n      - section2.18\n\n  - name: 2.18 Disable Mounting of cramfs Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install cramfs /bin/true'\n        state=present\n    tags:\n      - section2\n      - section2.18\n\n  - name: 2.19 Disable Mounting of freevxfs Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install freevxfs /bin/true'\n        state=present\n    tags:\n      - section2\n      - section2.19\n\n  - name: 2.20 Disable Mounting of jffs2 Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install jffs2 /bin/true'\n        state=present\n    tags:\n      - section2\n      - section2.20\n\n  - name: 2.21 Disable Mounting of hfs Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install hfs /bin/true'\n        state=present\n    tags:\n      - section2\n      - section2.21\n\n  - name: 2.22 Disable Mounting of hfsplus Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install hfsplus /bin/true'\n        state=present\n    tags:\n      - section2\n      - section2.22\n\n  - name: 2.23 Disable Mounting of squashfs Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install squashfs /bin/true'\n        state=present\n    tags:\n      - section2\n      - section2.23\n\n  - name: 2.24 Disable Mounting of udf Filesystems (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install udf /bin/true'\n        state=present\n    tags:\n      - section2\n      - section2.24\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "d0d01b30a44d44379ff2966d645002c1e2d3d8b4", "filename": "roles/nginx/defaults/main.yml", "repository": "roots/trellis", "decoded_content": "---\nnginx_path: /etc/nginx\nnginx_logs_root: /var/log/nginx\nnginx_user: www-data\nnginx_fastcgi_buffers: 8 8k\nnginx_ssl_path: \"{{ nginx_path }}/ssl\"\n\n# HSTS defaults\nnginx_hsts_max_age: 31536000\nnginx_hsts_include_subdomains: true\nnginx_hsts_preload: true\n\n# Fastcgi cache params\nnginx_cache_path: /var/cache/nginx\nnginx_cache_duration: 30s\nnginx_cache_key_storage_size: 10m\nnginx_cache_size: 250m\nnginx_cache_inactive: 1h\nnginx_skip_cache_uri: /wp-admin/|/xmlrpc.php|wp-.*.php|/feed/|index.php|sitemap(_index)?.xml\nnginx_skip_cache_cookie: comment_author|wordpress_[a-f0-9]+|wp-postpass|wordpress_no_cache|wordpress_logged_in\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "d427df97940ce5ca390df67a1eee49ae0daf4287", "filename": "roles/mariadb/templates/disable-binary-logging.cnf", "repository": "roots/trellis", "decoded_content": "# {{ ansible_managed }}\n\n[mysqld]\nskip-log-bin\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "748c7d02a0102999902fba01153340f5b15a3092", "filename": "tasks/setup_role_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: setup_role\n    args: \"{{ item }}\""}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "ffdd498988f8a911f2f9ad08cb1a164cbdba9897", "filename": "roles/user-management/manage-idm-users/tests/create_idm.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n# This test covers the full feature set provided by the role\n\n- name: Create Test Identities\n  hosts: ipa\n\n  vars_files:\n    - vars/idm.json\n\n  vars:\n    ipa_admin_user: admin\n    ipa_admin_password: test123\n    ipa_host: idm.example.com \n\n  roles:\n    - user-management/manage-idm-users\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "f46c813e2e1d46d0940e169a897c6c2d252fa507", "filename": "roles/ansible/tower/manage-job-templates/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- block: # when ansible_tower.job_templates is defined\n\n  - name: \"Initilize facts\"\n    set_fact:\n      processed_job_templates: []\n      existing_job_templates_output: []\n      existing_inventories_output: []\n      existing_projects_output: []\n      existing_credentials_output: []\n\n  # Utilize the `rest_get` library routine to ensure REST pagination is handled\n  - name: \"Get the existing inventories\"\n    rest_get:\n      host_url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}\"\n      rest_user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      rest_password: \"{{ ansible_tower.admin_password }}\"\n      api_uri: \"/api/v2/inventories/\"\n    register: existing_inventories_output\n\n  # Utilize the `rest_get` library routine to ensure REST pagination is handled\n  - name: \"Get the existing projects\"\n    rest_get:\n      host_url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}\"\n      rest_user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      rest_password: \"{{ ansible_tower.admin_password }}\"\n      api_uri: \"/api/v2/projects/\"\n    register: existing_projects_output\n\n  # Utilize the `rest_get` library routine to ensure REST pagination is handled\n  - name: \"Get the existing job templates\"\n    rest_get:\n      host_url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}\"\n      rest_user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      rest_password: \"{{ ansible_tower.admin_password }}\"\n      api_uri: \"/api/v2/job_templates/\"\n    register: existing_job_templates_output\n\n  # Utilize the `rest_get` library routine to ensure REST pagination is handled\n  - name: \"Get the existing credentials\"\n    rest_get:\n      host_url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}\"\n      rest_user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      rest_password: \"{{ ansible_tower.admin_password }}\"\n      api_uri: \"/api/v2/credentials/\"\n    register: existing_credentials_output\n\n  # Utilize the `rest_get` library routine to ensure REST pagination is handled\n  - name: \"Get the existing users\"\n    rest_get:\n      host_url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}\"\n      rest_user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      rest_password: \"{{ ansible_tower.admin_password }}\"\n      api_uri: \"/api/v2/users/\"\n    register: existing_users_output\n\n  # Utilize the `rest_get` library routine to ensure REST pagination is handled\n  - name: \"Get the existing teams\"\n    rest_get:\n      host_url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}\"\n      rest_user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      rest_password: \"{{ ansible_tower.admin_password }}\"\n      api_uri: \"/api/v2/teams/\"\n    register: existing_teams_output\n\n  - name: \"Process the inventory job template\"\n    include_tasks: process-job-template.yml\n    with_items:\n    - \"{{ ansible_tower.job_templates }}\"\n    loop_control:\n      loop_var: job_template\n\n  - name: \"Elminate the job templates that should not be present\"\n    uri:\n      url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}/api/v2/job_templates/{{ item.id }}/\"\n      user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      password: \"{{ ansible_tower.admin_password }}\"\n      force_basic_auth: yes\n      method: DELETE\n      validate_certs: no\n      status_code: 200,204\n    with_items:\n    - \"{{ existing_job_templates_output.rest_output | get_remaining_items(processed_job_templates, 'name', 'name')}}\"\n\n  when:\n  - ansible_tower.job_templates is defined\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "7055c2aeee8236e33559c3b80339053f3e110b42", "filename": "roles/user-management/manage-atlassian-users/tasks/add_user_to_groups.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Add user to groups\n  uri:\n    url: '{{ atlassian_url }}/rest/api/2/group/user?groupname={{ item }}'\n    method: POST\n    user: '{{ atlassian_username }}'\n    password: '{{ atlassian_password }}'\n    force_basic_auth: yes\n    status_code: [201, 400]\n    body_format: json\n    body: \"{'name': '{{ atlassian_user.email.split(\\'@\\') | first }}', 'password': '{{ atlassian_user.password }}', 'emailAddress': '{{ atlassian_user.email }}', 'displayName': '{{ atlassian_user.firstname }} {{ atlassian_user.lastname }}' }\"\n    return_content: yes\n  with_items: '{{ atlassian_user.groups }}'\n  when: atlassian_user.groups|length > 0\n"}, {"commit_sha": "045ff4bb9f4720739632aac2951fbf2798a99c8c", "sha": "cc3ee72a072a14c95cd3909ac08f6fdf18a64810", "filename": "roles/vpn/defaults/main.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\nstrongswan_enabled_plugins:\n  - aes\n  - gcm\n  - hmac\n  - kernel-netlink\n  - nonce\n  - openssl\n  - pem\n  - pgp\n  - pkcs12\n  - pkcs7\n  - pkcs8\n  - pubkey\n  - random\n  - revocation\n  - sha2\n  - socket-default\n  - stroke\n  - x509\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "fb6e438205fe583a8c10fe3e3c688061c20cc844", "filename": "roles/openvpn/templates/ca.crt", "repository": "iiab/iiab", "decoded_content": "-----BEGIN CERTIFICATE-----\nMIIE+jCCA+KgAwIBAgIJANTpdrUZJByXMA0GCSqGSIb3DQEBCwUAMIGuMQswCQYD\nVQQGEwJVUzELMAkGA1UECBMCTlkxFDASBgNVBAcTC05ld1lvcmtDaXR5MRQwEgYD\nVQQKEwtVbmxlYXNoS2lkczEVMBMGA1UECxMMU2Nob29sU2VydmVyMRcwFQYDVQQD\nEw5VbmxlYXNoS2lkcyBDQTEQMA4GA1UEKRMHRWFzeVJTQTEkMCIGCSqGSIb3DQEJ\nARYVZ2Vvcmdlamh1bnRAZ21haWwuY29tMB4XDTE0MDYxMjA2NTMyNloXDTI0MDYw\nOTA2NTMyNlowga4xCzAJBgNVBAYTAlVTMQswCQYDVQQIEwJOWTEUMBIGA1UEBxML\nTmV3WW9ya0NpdHkxFDASBgNVBAoTC1VubGVhc2hLaWRzMRUwEwYDVQQLEwxTY2hv\nb2xTZXJ2ZXIxFzAVBgNVBAMTDlVubGVhc2hLaWRzIENBMRAwDgYDVQQpEwdFYXN5\nUlNBMSQwIgYJKoZIhvcNAQkBFhVnZW9yZ2VqaHVudEBnbWFpbC5jb20wggEiMA0G\nCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC0uD76v+a7kKtwF08tTpA52Pc+NFsF\naErL3tcb3uQy27eB4naT/IV3YRCeIBmP5Wsx5znM9R7TpjITjfB/BVBGkF2/ffBl\nM6iOukCi1YFypQn33ygwzLDyfjy7iO4g6xvDwPI/gPzO6rLoOohaE77wolfUvMWQ\nbI1aEqh8k/M/WJqCeq8SgmtCh28zoc6aWIcgcX9+YLdhSHELxn0eMo8fKi17Wz/v\n7yupyLmks2M4+LZfCmY1wU9id8KrhEbXmoMcU2PoZYJxnml+gbQJbBCYwZ7lq1wY\n2e6XjssMFeecQoTyiA1osqoSlKx76deYn0cQw4rDAOEGyk8WFHZjsrZ5AgMBAAGj\nggEXMIIBEzAdBgNVHQ4EFgQUvQz5dfEcqP4Wcvvkp7MswZGK9E0wgeMGA1UdIwSB\n2zCB2IAUvQz5dfEcqP4Wcvvkp7MswZGK9E2hgbSkgbEwga4xCzAJBgNVBAYTAlVT\nMQswCQYDVQQIEwJOWTEUMBIGA1UEBxMLTmV3WW9ya0NpdHkxFDASBgNVBAoTC1Vu\nbGVhc2hLaWRzMRUwEwYDVQQLEwxTY2hvb2xTZXJ2ZXIxFzAVBgNVBAMTDlVubGVh\nc2hLaWRzIENBMRAwDgYDVQQpEwdFYXN5UlNBMSQwIgYJKoZIhvcNAQkBFhVnZW9y\nZ2VqaHVudEBnbWFpbC5jb22CCQDU6Xa1GSQclzAMBgNVHRMEBTADAQH/MA0GCSqG\nSIb3DQEBCwUAA4IBAQChBTaO3RPfk67LJpF1NhG4DQSb6dZxvNin+0CiYluJkUN8\nAfHKqg1T7GuzxdDxA6J8F6Kk3ORLm90qNg1XjpUl++1PtgHaY8zboCmdLlqqboDE\nWBGBM4muQ7Hr7dorzRe7eYqydHA8tEeg5/6c9TU3Yl4YaHPIn0XJrrUKHYPvmEMv\nf11ip0PqzA6CYUfsYkozN1PShckOcs/Dk+r4o9cheVasEHVUott7ya5FFlNcP//I\nRYAfqbygPCQ3TbYrXri+fXkAljsywIVshM/HWyMWVBulXyF+Ko1UyTCyk+MZfNpq\nvPhW9Y+9BMGjd1j/9PO5JQU1hm/BSh/VayW63q1k\n-----END CERTIFICATE-----\n"}, {"commit_sha": "beb41b82405655aa385bb8297bf49ada1a4eb14c", "sha": "e145b9c5a1817963f4affa16c47313e811f3a05a", "filename": "tasks/main.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Load a system variables file based on distribution or OS family\n  include_vars: '{{ distribution }}'\n  with_first_found:\n    - '{{ ansible_os_family }}.yml'\n    - default.yml\n  loop_control:\n    loop_var: distribution\n\n- name: Set base variables based on java distribution\n  include_vars: 'java_distro_configs/{{ java_distribution }}_vars.yml'\n\n- name: 'Fetch oracle artifact with {{ transport }} transport'\n  include_tasks: '{{ transport_driver }}'\n  with_first_found:\n    - '{{ ansible_system }}/fetch/{{ transport }}.yml'\n    - unknown-transport.yml\n  loop_control:\n    loop_var: transport_driver\n\n- name: Set parse variables based on java distribution\n  include_vars: java_parts.yml\n  when:\n    - transport != 'repositories'\n    - java_binary_type != 'chocolatey'\n\n- name: Choose platform based task\n  include_tasks: '{{ platform }}'\n  with_first_found:\n    - '{{ ansible_system }}/system.yml'\n    - not-supported.yml\n  loop_control:\n    loop_var: platform\n\n- name: Apply security policy patch\n  include_tasks: '{{ platform }}'\n  with_first_found:\n    - '{{ ansible_system }}/security_policy.yml'\n    - not-supported.yml\n  loop_control:\n    loop_var: platform\n  when:\n    - java_unlimited_policy_enabled\n    - java_distribution == 'oracle_java'\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "b7a47c05a1326bd469535173a64555370d45878b", "filename": "roles/owncloud/tasks/owncloud_enabled.yml", "repository": "iiab/iiab", "decoded_content": "# This chould go in computed_network.yml, but here for now\n\n- name: Compute owncloud listen ip addr for owncloud.conf\n  set_fact:\n     owncloud_required_ip: \"{{ ansible_default_ipv4.network }}/{{ ansible_default_ipv4.netmask }}\"\n  when: ansible_default_ipv4.network is defined\n\n- name: Enable owncloud by copying template to httpd config\n  template: src=owncloud.conf.j2\n            dest=/etc/{{ apache_config_dir }}/owncloud.conf\n            owner=root\n            group=root\n            mode=0644\n\n- name: Enable owncloud\n  file: path=/etc/apache2/sites-enabled/owncloud.conf\n        src=/etc/apache2/sites-available/owncloud.conf\n        state=link\n  when: owncloud_enabled and is_debuntu\n\n- name: Disable owncloud\n  file: path=/etc/apache2/sites-enabled/owncloud.conf\n        state=absent\n  when: not owncloud_enabled and is_debuntu\n\n- name: Restart apache, so it picks up the new aliases\n  service: name={{ apache_service }} state=restarted\n\n- name: Run owncloud initial install wizard\n  shell: curl http://{{ iiab_hostname }}{{ owncloud_url }}/index.php\n\n- name: Remove Rewrite URL\n  lineinfile: regexp='overwrite.cli.url'\n              state=absent\n              dest=\"{{ owncloud_prefix }}/owncloud/config/config.php\"\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "20c4c58cfade12582ee1658a23dfc5239fd094fc", "filename": "playbooks/openshift/openstack/roles", "repository": "redhat-cop/casl-ansible", "decoded_content": "../../../roles"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "0db73efca087cbb62839ca672f89cb27c9fc8094", "filename": "roles/docker/meta/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\ngalaxy_info:\n  author: Graham Taylor\n  description:\n  company: Capgemini\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (MIT)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: Ubuntu\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n     - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies: []\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "9bb0982fcbbe5147fc4d09915adbd8bdf04b66ad", "filename": "roles/7-edu-apps/meta/main.yml", "repository": "iiab/iiab", "decoded_content": "dependencies:\n   - { role: moodle, tags: ['olpc','moodle','edu-apps'], when: moodle_install }\n   - { role: osm, tags: ['osm','edu-apps'], when: osm_install }\n   - { role: pathagar, tags: ['pathagar','edu-apps'], when: pathagar_install }\n   - { role: rachel, tags: ['rachel','edu-apps'], when: rachel_install }\n   - { role: kalite, tags: ['kalite','edu-apps'], when: kalite_install }\n   - { role: kiwix, tags: ['kiwix','edu-apps'], when: kiwix_install }\n   - { role: sugarizer, tags: ['sugarizer','edu-apps'], when: sugarizer_install }\n#   - { role: debian_schooltool, tags: ['schooltool','debian_schooltool','edu-apps'], when: debian_schooltool_install and is_debuntu }\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "792c90d47f9b618ce437ecd62042983b251f11a9", "filename": "roles/config-container-storage-setup/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "docker_dev: /dev/vdb\ndocker_vg: docker-vol\ndocker_data_size: 95%VG\ncontainer_root_lv_name: dockerlv\ncontainer_root_lv_mount_path: /var/lib/docker"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "0f3f1a5a0c3b6c644d6274f03b2cfa6e62a437d2", "filename": "roles/zookeeper/meta/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\ngalaxy_info:\n  author: Graham Taylor\n  description:\n  company: Capgemini\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (MIT)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: Ubuntu\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n     - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies:\n  - role: handlers\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "54cedab0bf1cb2259df94ebd3f96c56c9a7c1d41", "filename": "roles/user-management/list-users-by-group/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: manage-users-host\n  gather_facts: no\n  roles:\n  - role: list-users-by-group \n  tasks:\n  - debug:\n      msg: \"{{ list_of_users }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "688ba1c090fff040afd95c1889d8d46815ffb8d1", "filename": "roles/kalite/tasks/setup-f18.yml", "repository": "iiab/iiab", "decoded_content": "# This is for Fedora 18, assumed to be an XO\n\n- name: Run the setup using kalite manage F18\n  command: \"/usr/bin/su {{ kalite_user }} -c '{{ kalite_root }}/bin/kalite manage setup --username={{ kalite_user }} --password={{ kalite_password }} --noinput'\"\n  async: 900\n  poll: 10\n\n- name: Finish setup by running kalite start F18\n  command: \"/usr/bin/su {{ kalite_user }} -c '{{ kalite_root }}/bin/kalite start'\"\n  async: 900\n  poll: 10\n\n- name: Stop kalite server started in previous step because we use systemd\n  command: \"/usr/bin/su {{ kalite_user }} -c '{{ kalite_root }}/bin/kalite stop'\"\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "ea41ad38009fae2f80e72e4f65792986cab06d1e", "filename": "playbooks/roles/common/tasks/hostname.yml", "repository": "rocknsm/rock", "decoded_content": "- name: Set hostname to FQDN\n  hostname: name={{ fq_hostname }}\n\n- name: Static entry in hosts file\n  lineinfile: \n  args:\n    dest: /etc/hosts \n    insertbefore: '^127\\.0\\.0\\.1' \n    state: present \n    line: '{{ ansible_default_ipv4.address }} {{ fq_hostname }} {{ ansible_hostname }}'\n"}, {"commit_sha": "7032aee7df1c2c6e96795067285efa3b2a6de32e", "sha": "d9056afc94e78cafb61794ec0c785e57e869364e", "filename": "roles/dns/test/records.yml", "repository": "openshift/openshift-ansible-contrib", "decoded_content": "- hosts: localhost\n  roles:\n  - role: dns\n    dns_records_rm:\n    - view: private\n      zone: first.example.com\n      entries:\n      - type: A\n        hostname: master\n        ip: 172.16.10.19\n    dns_records_add:\n    - view: private\n      zone: first.example.com\n      entries:\n      - type: A\n        hostname: master\n        ip: 172.16.10.20\n      - type: A\n        hostname: node1\n        ip: 172.16.10.20\n      - type: A\n        hostname: node2\n        ip: 172.16.10.21\n      - type: A\n        hostname: node3\n        ip: 172.16.10.22\n    - view: private\n      zone: second.example.com\n      entries:\n      - type: A\n        hostname: master\n        ip: 172.17.10.20\n      - type: A\n        hostname: node1\n        ip: 172.17.10.20\n      - type: A \n        hostname: node2\n        ip: 172.17.10.21\n    - view: public\n      zone: first.example.com\n      entries:\n      - type: A \n        hostname: master\n        ip: 10.9.77.20\n      - type: A \n        hostname: node1\n        ip: 10.9.77.20\n      - type: A\n        hostname: node2\n        ip: 10.9.77.21\n      - type: A\n        hostname: node3\n        ip: 10.9.77.22\n    - view: public\n      zone: second.example.com\n      entries:\n      - type: A\n        hostname: master\n        ip: 10.8.88.20\n      - type: A\n        hostname: node1\n        ip: 10.8.88.20\n      - type: A\n        hostname: node2\n        ip: 10.8.88.21\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "ea9dc27d4a727edcdfc07e55c370f20c939997b7", "filename": "roles/osp/packstack-post/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Include 'mariadb' processing\"\n  include_tasks: \"mariadb.yml\"\n  when:\n  - \"'mariadb' in osp_roles.split(',')\"\n\n- name: \"Include 'keystone' processing\"\n  include_tasks: \"keystone.yml\"\n  when:\n  - \"'keystone' in osp_roles.split(',')\"\n\n- name: \"Include 'cinder' processing\"\n  include_tasks: \"cinder.yml\"\n  when:\n  - \"'cinder' in osp_roles.split(',')\"\n\n- name: \"Include 'nova' processing\"\n  include_tasks: \"nova.yml\"\n  when:\n  - \"'nova' in osp_roles.split(',')\"\n"}, {"commit_sha": "1d7d3a653c598355333e7c34a54a550ed3d79cc5", "sha": "089c99aef70bc84cb96a4bcd8ec4a7b25a56f670", "filename": "meta/main.yml", "repository": "RocketChat/Rocket.Chat.Ansible", "decoded_content": "---\ngalaxy_info:\n  author: Calum MacRae\n  description: Deploy Rocket.Chat\n  #company: your company (optional)\n  # If the issue tracker for your role is not on github, uncomment the\n  # next line and provide a value\n  # issue_tracker_url: http://example.com/issue/tracker\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: MIT\n  min_ansible_version: 1.9.4\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  - name: EL\n    versions:\n  #  - all\n  #  - 5\n  #  - 6\n    - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #  - 21\n  #  - 22\n  #- name: Windows\n  #  versions:\n  #  - all\n  #  - 2012R2\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: Ubuntu\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n    - trusty\n  #  - utopic\n  #  - vivid\n    - xenial\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  - name: Debian\n    versions:\n  #  - all\n  #  - etch\n    - jessie\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  galaxy_tags:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  - database\n  - database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  - networking\n  - packaging\n  - system\n  - web\n  - chat\ndependencies: []\n  # List your role dependencies here, one per line.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "31b34488ecb01d6738c4d1a59126870506c4e209", "filename": "roles/dnsmasq/vars/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# vars file for dnsmasq\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "d60e50803f116d4309300d3e369f911ae46b9677", "filename": "meta/main.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\ngalaxy_info:\n  author: ansible-ThoTeam\n  description: Nexus Repository Manager 3.x (Sonatype)\n  company: ThoTeam\n\n  license: license (GPLv3)\n\n  min_ansible_version: 2.5.4\n\n  github_branch: master\n\n  platforms:\n    - name: EL\n      versions:\n        - 7\n    - name: Ubuntu\n      versions:\n        - xenial\n        - bionic\n    - name: Debian\n      versions:\n        - jessie\n        - stretch\n\n  galaxy_tags:\n    - nexus\n    - nexus3\n    - java\n    - maven\n    - npm\n    - nuget\n    - yum\n    - docker\n    - pypi\n    - web\n\ndependencies: []\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "0cfaf3657cc8d710a9e5588b006d54f41fbc9ddc", "filename": "roles/config-idm-server/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n# defaults file for idm\n\nidm_principal: admin\n\n"}, {"commit_sha": "79e29502fb4e0ff1c30c0b5396bfa1b48fb84a8e", "sha": "b89d14acaeea14e2701e1023dc14edda789a7462", "filename": "tasks/chown.yml", "repository": "Oefenweb/ansible-wordpress", "decoded_content": "# tasks file for wordpress, chown\n---\n- name: change owner (and group)\n  file:\n    path: \"{{ item.path }}\"\n    owner: \"{{ item.owner | default('www-data') }}\"\n    group: \"{{ item.group | default(item.owner) | default('www-data') }}\"\n    recurse: true\n  with_items: wordpress_installs\n  tags: [configuration, wordpress, wordpress-chown]\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "3c2132a8395510082dcda84aa6f333b46b594e23", "filename": "playbooks/files/zookeeper.service", "repository": "rocknsm/rock", "decoded_content": "# Licensed to the Apache Software Foundation (ASF) under one or more\n# contributor license agreements.  See the NOTICE file distributed with\n# this work for additional information regarding copyright ownership.\n# The ASF licenses this file to You under the Apache License, Version 2.0\n# (the \"License\"); you may not use this file except in compliance with\n# the License.  You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n[Unit]\nDescription=Zookeeper distributed coordination server\nAfter=network.target\n\n[Service]\nUser=zookeeper\nGroup=zookeeper\nSyslogIdentifier=zookeeper\nEnvironmentFile=/etc/zookeeper/java.env\nExecStart=/usr/bin/java \\\n  -Dzookeeper.log.dir=/var/log/zookeeper \\\n  -Dzookeeper.root.logger=${ZOO_LOG4J_PROP} \\\n  -cp \"/usr/lib/zookeeper/zookeeper-3.4.8.jar:/usr/lib/zookeeper/lib/*\" \\\n  -Dlog4j.configuration=file:/etc/zookeeper/log4j.properties \\\n  -Dcom.sun.management.jmxremote \\\n  -Dcom.sun.management.jmxremote.local.only=false \\\n  org.apache.zookeeper.server.quorum.QuorumPeerMain \\\n  /etc/zookeeper/zoo.cfg\n\n[Install]\nWantedBy=multi-user.target\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "a9b047bb3047a424ae744e86b02a788a6b932412", "filename": "roles/network/templates/named/localdomain.zone", "repository": "iiab/iiab", "decoded_content": "$TTL\t86400\n@\t\tIN SOA\tlocalhost root (\n\t\t\t\t\t42\t\t; serial (d. adams)\n\t\t\t\t\t3H\t\t; refresh\n\t\t\t\t\t15M\t\t; retry\n\t\t\t\t\t1W\t\t; expiry\n\t\t\t\t\t1D )\t\t; minimum\n\t        IN NS\t\tlocalhost\nlocalhost\tIN A\t\t127.0.0.1\n\t\t\n"}, {"commit_sha": "a94f9ce4fa32273fd0fad7492d36db4101423cc3", "sha": "ea43181c3cbef322147ad703a1389d78fa6f2b48", "filename": "tasks/configure-non-systemd.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "- name: Combine Docker daemon environment variable configuration\n  set_fact:\n    docker_service_envs: \"{{ docker_service_envs | combine(_docker_service_opts) | combine(docker_daemon_envs) }}\"\n  vars:\n    _docker_service_opts:\n      DOCKER_OPTS: \"{{ docker_daemon_opts }}\"\n\n- name: Setup Docker environment file {{ docker_envs_dir[_docker_os_dist] }}/docker\n  become: true\n  template:\n    src: docker-envs.j2\n    dest: \"{{ docker_envs_dir[_docker_os_dist] }}/docker\"\n  notify: restart docker\n  vars:\n    docker_envs: \"{{ docker_service_envs }}\""}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "055ed50a4bbf79142a4e14650e3a9660eb8fb6e5", "filename": "tasks/checks/distribution-checks-CentOS.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Fail if unsupported CentOS version\n  fail:\n    msg: \"CentOS 7 or later is required!\"\n  when: _docker_os_dist_major_version < '7'\n"}, {"commit_sha": "64cbc6946b7ebc0d9a36f40d77ac86f8e3564499", "sha": "33973da3e48cd3a178c58efc01398a74cd9b6864", "filename": "meta/main.yml", "repository": "CSCfi/ansible-role-slurm", "decoded_content": "---\ngalaxy_info:\n  author: Johan Guldmyr\n  description:  Installs and configures slurm on a cluster\n  company: CSC - IT Center for Science Ltd.\n  # If the issue tracker for your role is not on github, uncomment the\n  # next line and provide a value\n  # issue_tracker_url: http://example.com/issue/tracker\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: MIT\n  min_ansible_version: 2.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your \n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  - name: EL\n    versions:\n    - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #  - 21\n  #  - 22\n  #- name: Windows\n  #  versions:\n  #  - all\n  #  - 2012R2\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  #- name: Ubuntu\n  #  versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n  #  - trusty\n  #  - utopic\n  #  - vivid\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - jessie\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  galaxy_tags:\n   - clustering\n   - system\ndependencies:\n  # List your role dependencies here, one per line.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n  - { src: ansible-role-pam, name: ansible-role-pam }\n \n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "16b231a72b1cd4880d74fbc334f37fcfdf0bc9ff", "filename": "tasks/declare_script_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- name: Removing (potential) previously declared Groovy script {{ item }}\n  uri:\n    url: \"http://localhost:{{ nexus_default_port }}{{ nexus_default_context_path }}{{ nexus_rest_api_endpoint }}/{{ item }}\"\n    user: 'admin'\n    password: \"{{ current_nexus_admin_password }}\"\n    method: DELETE\n    force_basic_auth: yes\n    status_code: 204,404\n\n- name: Declaring Groovy script {{ item }}\n  uri:\n    url: \"http://localhost:{{ nexus_default_port }}{{ nexus_default_context_path }}{{ nexus_rest_api_endpoint }}\"\n    user: 'admin'\n    password: \"{{ current_nexus_admin_password }}\"\n    body_format: json\n    method: POST\n    force_basic_auth: yes\n    status_code: 204\n    body:\n      name: \"{{ item }}\"\n      type: 'groovy'\n      content: \"{{ lookup('file', 'groovy/' + item + '.groovy') }}\"\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "d3e4405061c905c6ed89757645f46f6a74e50786", "filename": "roles/letsencrypt/tasks/certificates.yml", "repository": "roots/trellis", "decoded_content": "- name: Generate private keys\n  shell: openssl genrsa 4096 > {{ letsencrypt_keys_dir }}/{{ item.key }}.key\n  args:\n    creates: \"{{ letsencrypt_keys_dir }}/{{ item.key }}.key\"\n  when: site_uses_letsencrypt\n  with_dict: \"{{ wordpress_sites }}\"\n  tags: [letsencrypt_keys]\n\n- name: Ensure correct permissions on private keys\n  file:\n    path: \"{{ letsencrypt_keys_dir }}/{{ item.key }}.key\"\n    mode: 0600\n  when: site_uses_letsencrypt\n  with_dict: \"{{ wordpress_sites }}\"\n  tags: [letsencrypt_keys]\n\n- name: Generate CSRs\n  shell: \"openssl req -new -sha256 -key '{{ letsencrypt_keys_dir }}/{{ item.key }}.key' -subj '/' -reqexts SAN -config <(cat /etc/ssl/openssl.cnf <(printf '[SAN]\\nsubjectAltName=DNS:{{ site_hosts | join(',DNS:') }}')) > {{ acme_tiny_data_directory }}/csrs/{{ item.key }}.csr\"\n  args:\n    executable: /bin/bash\n    creates: \"{{ acme_tiny_data_directory }}/csrs/{{ item.key }}.csr\"\n  when: site_uses_letsencrypt\n  with_dict: \"{{ wordpress_sites }}\"\n  tags: [letsencrypt_keys]\n\n- name: Generate the initial certificate\n  command: ./renew-certs.py\n  args:\n    chdir: \"{{ acme_tiny_data_directory }}\"\n  register: generate_initial_cert\n  changed_when: generate_initial_cert.stdout is defined and 'Created' in generate_initial_cert.stdout\n  notify: reload nginx\n\n- name: Disable Nginx site\n  file:\n    path: \"{{ nginx_path }}/sites-enabled/letsencrypt-{{ item.key }}.conf\"\n    state: absent\n  with_dict: \"{{ wordpress_sites }}\"\n  when: sites_need_confs\n  notify: reload nginx\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "e5c3a0d5a8087bc89c1a58f9c0d35d7a01c19a67", "filename": "playbooks/manage-confluence-space/playbook.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "--- \n- hosts: confluence\n  roles: \n    - manage-confluence-space\n"}, {"commit_sha": "f92ebbef856e59bd4563d4b5b69ee75a95ec89d5", "sha": "7e36aff2c1dc2479bc12a6e30c7ed044f8d79e9c", "filename": "roles/openshift-defaults/defaults/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\nopenshift:\n  common:\n    client_binary: \"oc\"\n    admin_binary: \"oc adm\"\ndocker:\n  common:\n    client_binary: \"docker\"\n"}, {"commit_sha": "7032aee7df1c2c6e96795067285efa3b2a6de32e", "sha": "89965381442868e62c1462e0c74d45f3cd0fd415", "filename": "roles/dns-server/test/role.yml", "repository": "openshift/openshift-ansible-contrib", "decoded_content": "- hosts: localhost\n  roles:\n  - role: dns-server\n    named_config_allow_transfer:\n    - 192.168.10.11\n    - 192.168.10.12\n    named_config_views:\n    - name: private\n      acl_entry: \n      - 172.16.0.0/16\n      - 172.17.0.0/16\n      zone:\n      - dns_domain: first.example.com\n      - dns_domain: second.example.com\n    - name: public\n      zone:\n      - dns_domain: first.example.com\n      - dns_domain: second.example.com\n      forwarder:\n      - 8.8.8.8\n      - 8.8.4.4\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "8e9a4afebbf672baee52b5f25e2df2ad51981e38", "filename": "roles/dns/config-dns-server-bind/handlers/restart_named.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Check current state of 'named'\n  shell: systemctl status named\n  register: current_service_state\n  ignore_errors: true\n\n- name: Restart service if already running\n  service:\n    name: named\n    state: restarted\n  when:\n  - current_service_state.rc == 0\n"}, {"commit_sha": "c5ca8972146c84a12b80cd589c873884699d06bc", "sha": "e2dd2895d9ddac698a20326b5c2a521d941c8779", "filename": "handlers/main.yml", "repository": "dev-sec/ansible-nginx-hardening", "decoded_content": "- name: reload nginx\n  service: name={{ nginx_service_name }} state=reloaded\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "404340d75f153d7d472bb5e8cc59a59b182f7f53", "filename": "roles/update-host/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: update-host.yml\n- import_tasks: reboot-host.yml\n- import_tasks: wait-for-host.yml \n"}, {"commit_sha": "abafe1581c6c78d784cf215b214947675d49eff8", "sha": "703e5d051d801951af162518a37f5dc3e85be594", "filename": "playbooks/digitalocean.yml", "repository": "trailofbits/algo", "decoded_content": "- name: Enable IPv6 on the droplet\n  uri:\n    url: \"https://api.digitalocean.com/v2/droplets/{{ do_droplet_id }}/actions\"\n    method: POST\n    body:\n      type: enable_ipv6\n    body_format: json\n    status_code: 201\n    HEADER_Authorization: \"Bearer {{ do_access_token }}\"\n    HEADER_Content-Type: \"application/json\"\n\n- name: Get Droplet networks\n  uri:\n    url: \"https://api.digitalocean.com/v2/droplets/{{ do_droplet_id }}\"\n    method: GET\n    status_code: 200\n    HEADER_Authorization: \"Bearer {{ do_access_token }}\"\n    HEADER_Content-Type: \"application/json\"\n  register: droplet_info\n\n- name: IPv6 configured\n  template: src=roles/cloud-digitalocean/templates/20-ipv6.cfg.j2 dest=/etc/network/interfaces.d/20-ipv6.cfg owner=root group=root mode=0644\n  with_items: \"{{ droplet_info.json.droplet.networks.v6 }}\"\n  notify:\n    - reload eth0\n\n- name: IPv6 included into the network config\n  lineinfile: dest=/etc/network/interfaces line='source /etc/network/interfaces.d/20-ipv6.cfg' state=present\n  notify:\n    - reload eth0\n\n- meta: flush_handlers\n\n- name: Wait for SSH to become available\n  local_action: \"wait_for port=22 host={{ inventory_hostname }} timeout=320\"\n  become: false\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "4ecd54639f64f6b8c503806d2087a0257ae42720", "filename": "roles/dns/manage-dns-zones-bind/tests/inventory/group_vars/all.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ndns_data:\n  views:\n    - name: \"private\"\n      zones:\n        - dns_domain: \"roletest1.com\"\n          state: present\n        - dns_domain: \"roletest2.com\"\n          state: present\n    - name: \"public\"\n      zones:\n        - dns_domain: \"roletest3.com\"\n          state: absent\n        - dns_domain: \"roletest4.com\"\n          state: absent\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "3f566e87fc415af4c15979f0b035ce4592b12f97", "filename": "roles/usb-lib/templates/content_dir.conf", "repository": "iiab/iiab", "decoded_content": "# configure  for local content\n\nAlias /content {{ doc_root }}/local_content\nAlias /local_content {{ doc_root }}/local_content\nAlias /USB {{ doc_root }}/local_content\nAlias /usb {{ doc_root }}/local_content\n\n<Directory {{ doc_root }}/local_content>\n    Require all granted\n    Options +Indexes\n    IndexOptions FancyIndexing\n    IndexOptions HTMLTable\n    IndexOptions SuppressColumnsorting\n    IndexOptions Charset=UTF-8\n</Directory>\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "40345b19e5c1ce2001e80b0b18ce6d39e69209a6", "filename": "roles/ansible/tower/manage-projects/tasks/process-project.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Get the org id based on the org name\"\n  set_fact:\n    org_id: \"{{ item.id }}\"\n  when:\n  - item.name|trim == project.organization|trim\n  with_items:\n  - \"{{ existing_organizations_output.rest_output }}\"\n\n- name: \"Load up the project\"\n  uri:\n    url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}/api/v2/projects/\"\n    user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n    password: \"{{ ansible_tower.admin_password }}\"\n    force_basic_auth: yes\n    method: POST\n    body: \"{{ lookup('template', 'project.j2') }}\"\n    body_format: 'json'\n    headers:\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n    validate_certs: no\n    status_code: 200,201,400\n  register: project_output\n\n- name: \"Clear/Update facts\"\n  set_fact:\n    org_id: ''\n    processed_projects: \"{{ processed_projects + [ { 'name': project.name } ] }}\"\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "c5b9c9487cb3cf2a86e9ad6a16998654c8acb81e", "filename": "meta/main.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "galaxy_info:\n  role_name: docker_ce\n  author: Bjorn Oscarsson\n  company: none\n  description: \"Installs and configures Docker Community Edition (CE)\"\n  min_ansible_version: 2.5\n  license: MIT\n  platforms:\n  - name: Fedora\n    versions:\n      - 25\n      - 26\n      - 27\n      - 28\n      - 29\n\n  - name: EL\n    versions:\n      - 7\n\n  - name: Debian\n    versions:\n      - wheezy\n      - jessie\n      - stretch\n      - buster\n\n  - name: Ubuntu\n    versions:\n      - trusty\n      - artful\n      - xenial\n      - bionic\n      - cosmic\n\n  galaxy_tags:\n    - docker\n    - containers\n    - virtualization\n    - compose\n    - orchestration\n    - system\n\ndependencies: []\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "c1d7760c224e0e2f58a320c4ca590156e5b062bb", "filename": "tasks/bug-tweaks/tweak-debian8-directlvm.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "- name: Create LVM thinpool for Docker according to Docker documentation\n  include_tasks: lvm-thinpool.yml\n  vars:\n    pool:\n      name: thinpool\n      volume_group: docker\n      physical_volumes: \"{{ docker_daemon_config['storage-opts'] | select('match', '^dm.directlvm_device.+') \\\n        | list | regex_replace('dm.directlvm_device=\\\\s*(.+)', '\\\\1') }}\"\n      metadata_size: \"1%VG\"\n      data_size: \"95%VG\"\n\n- name: Modify storage-opts to handle problems with thinpool on Debian 8\n  set_fact:\n    _modified_storage_config: \"{{ (docker_daemon_config['storage-opts'] | difference(_exclusions)) + \\\n      ['dm.thinpooldev=/dev/mapper/docker-thinpool-tpool'] }}\"\n  vars:\n    _exclusions: \"{{ docker_daemon_config['storage-opts'] | select('match', '^dm.directlvm_device.+') | list }}\"\n\n- name: Update Docker daemon configuration to handle consistency between distributions\n  set_fact:\n    docker_daemon_config: \"{{ docker_daemon_config | combine(_updated_item, recursive=true) }}\"\n  vars:\n    _updated_item: \"{ 'storage-opts': {{ _modified_storage_config }} }\"\n\n- name: Updated Docker daemon configuration\n  debug:\n    var: docker_daemon_config\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "c3f8ea513b12ead7523a3971b66f86f36f15fdc4", "filename": "roles/mesos/tasks/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "- include: master.yml\n- include: slave.yml\n"}, {"commit_sha": "7032aee7df1c2c6e96795067285efa3b2a6de32e", "sha": "ed57a299378391bc1d247ada73a2b94cc0f644b4", "filename": "roles/common/pre_tasks/pre_tasks.yml", "repository": "openshift/openshift-ansible-contrib", "decoded_content": "---\n- name: Generate Environment ID\n  shell: echo \"$(date +%s)\"\n  register: env_random_id\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "3f7cdcca12bda693066f03531c98c333e24c4efd", "filename": "tasks/create_blobstore_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- name: Create directory for blob store.\n  file:\n    path: \"{{ item['path'] }}\"\n    owner: \"{{ nexus_os_user }}\"\n    group: \"{{ nexus_os_group }}\"\n    state: directory\n    recurse: true\n\n- include: call_script.yml\n  vars:\n    script_name: create_blobstore\n    args: \"{{ item }}\"\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "4b650f603226dc7f9abdad557ea9947b65454354", "filename": "tasks/checks/distribution-checks-RedHat.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Fail if unsupported RedHat version\n  fail:\n    msg: \"RedHat 7 or later is required!\"\n  when: _docker_os_dist_major_version < '7'\n"}, {"commit_sha": "8c72df4ecfaa4188202ab0872f4500384ffe5233", "sha": "2e28616f7378bdc60055d77883dea5513e2dfaf6", "filename": "tasks/distribution-checks.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Fail if unsupported CentOS/RedHat version\n  fail:\n    msg: \"CentOS/RedHat 7 or later is required!\"\n  when: (_docker_os_dist == \"CentOS\" or _docker_os_dist == \"RedHat\") and\n        _docker_os_dist_major_version < '7'\n\n- name: Fail if unsupported Fedora version\n  fail:\n    msg: \"Fedora 24 or later is required!\"\n  when: _docker_os_dist == \"Fedora\" and\n        _docker_os_dist_major_version < '24'\n\n- name: Fail if unsupported Ubuntu version\n  fail:\n    msg: \"Ubuntu 14 or later is required!\"\n  when: _docker_os_dist == \"Ubuntu\" and\n        _docker_os_dist_major_version < '14'\n\n- name: Fail if unsupported Debian version\n  fail:\n    msg: \"Debian 7 (wheezy) or later is required!\"\n  when: _docker_os_dist == \"Debian\" and\n        _docker_os_dist_major_version < '7'\n\n- name: Fail if kernel version is lower than 3.10\n  fail:\n    msg: \"Kernel version 3.10 or later is required!\"\n  when: ansible_kernel | version_compare(\"3.10\", '<')\n\n- name: Fail if this roles does not support the distribution\n  fail:\n    msg: \"Distribution {{ _docker_os_dist }} is not supported by this role!\"\n  when: _docker_os_dist != \"Fedora\" and\n        _docker_os_dist != \"CentOS\" and\n        _docker_os_dist != \"RedHat\" and\n        _docker_os_dist != \"Ubuntu\" and\n        _docker_os_dist != \"Debian\"\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "ddb435834a1e09440fea388bf54b1ead4ad93fc2", "filename": "tasks/section_09_level1_03.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 9.3.1 Set SSH Protocol to 2 (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Protocol'\n        state=present\n        line='Protocol 2'\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n  - name: 9.3.2 Set LogLevel to INFO (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^LogLevel'\n        state=present\n        line='LogLevel INFO'\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.2\n\n  - name: 9.3.3 Set Permissions on /etc/ssh/sshd_config (Scored)\n    file: path='/etc/ssh/sshd_config' owner=root group=root mode=600\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.3\n\n#Regroups sections 9.3.4 9.3.7 9.3.8 9.3.9 9.3.10\n  - name: 9.3.{4,7,8,9,10} Disable some SSH options (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^{{ item }}'\n        line='{{ item }} no'\n        state=present\n    with_items:\n      - X11Forwarding\n      - HostbasedAuthentication\n      - PermitRootLogin\n      - PermitEmptyPasswords\n      - PermitUserEnvironment\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.4\n      - section9.3.7\n      - section9.3.8\n      - section9.3.9\n      - section9.3.10\n\n  - name: 9.3.5 Set SSH MaxAuthTries to 4 or Less (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^MaxAuthTries'\n        line='MaxAuthTries 4'\n        state=present\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.5\n\n  - name: 9.3.6 Set SSH IgnoreRhosts to Yes (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^IgnoreRhosts'\n        line='IgnoreRhosts yes'\n        state=present\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.6\n\n  - name: 9.3.11 Use Only Approved Cipher in Counter Mode (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Ciphers'\n        line='Ciphers aes128-ctr,aes192-ctr,aes256-ctr'\n        state=present\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.11\n\n  - name: 9.3.12.1 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveInterval'\n        line='ClientAliveInterval 300'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.1\n\n  - name: 9.3.12.2 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveCountMax'\n        line='ClientAliveCountMax 0'\n        state=present\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.2\n\n  - name: 9.3.13.1 Limit Access via SSH (Scored)\n    shell: grep AllowUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.1\n\n  - name: 9.3.13.2 Limit Access via SSH (Scored)\n    shell: grep AllowGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.2\n\n  - name: 9.3.13.3 Limit Access via SSH (Scored)\n    shell: grep DenyUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.3\n\n  - name: 9.3.13.4 Limit Access via SSH (Scored)\n    shell: grep DenyGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.4\n\n  - name: 9.3.14 Set SSH Banner (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Banner'\n        line='Banner /etc/issue.net'\n        state=present\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.14\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "05c6ed9d66f6e6e5765c5d1a3f436d9bef7a7c8f", "filename": "roles/config-software-src/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: all\n  roles:\n    - config-software-src\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "4e93769f741eaa700c6f9b5258b2a952209d8c55", "filename": "roles/iiab-admin/templates/profile_ssh_warn.sh", "repository": "iiab/iiab", "decoded_content": "#!/bin/bash\n# credit to the folks at raspberry pi foundatioon\ncheck_hash ()\n{\n   if ! id -u iiab-admin > /dev/null 2>&1 ; then return 0 ; fi\n   if grep -q \"^PasswordAuthentication\\s*no\" /etc/ssh/sshd_config ; then return 0 ; fi\n   SHADOW=\"$(sudo -n grep -E '^iiab-admin:' /etc/shadow 2>/dev/null)\"\n   test -n \"${SHADOW}\" || return 0\n   if echo $SHADOW | grep -q \"iiab-admin:!\" ; then return 0 ; fi\n   SHADOW_PW=$(echo $SHADOW | cut -d: -f2)\n   if [ \"$SHADOW_PW\" != '{{ iiab_admin_passw_hash }}' ]; then return 0 ; fi\n\n\t\techo\n\t\techo \"SSH is enabled and the default password for the 'iiab-admin' user is unchanged.\"\n\t\techo \"This is a security risk - please login as the 'iiab-admin' user and type 'passwd' to change password.\"\n\t\techo\n}\n\nsystemctl is-active {{ sshd_service }} > /dev/null && check_hash\nunset check_hash\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "f1cbe81f3ef63ba92e497def24062ed31c3bf5a5", "filename": "roles/nfs-server/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ndefault_nfs_owner: \"nfsnobody\"\ndefault_nfs_group: \"nfsnobody\"\ndefault_nfs_mode: \"0777\"\n\ndefault_nfs_vg_name: \"nfs\"\ndefault_nfs_lv_name: \"exports\"\ndefault_nfs_share_basedir: \"/exports\"\ndefault_nfs_share_options: \"rw,root_squash,no_wdelay\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "7b66997eb5742476edb49fb346295b9586250ca8", "filename": "roles/config-clair/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# Base Configurations\nclair_name: clair\nclair_service: \"{{ clair_name }}.service\"\nclair_address: \"\"\n\n#Systemd\nsystemd_service_dir: /usr/lib/systemd/system\nsystemd_environmentfile_dir: /etc/sysconfig\n\n# Clair\nclair_image: quay.io/coreos/clair-jwt:v2.0.4\nclair_config_dir: /var/lib/clair/config\nclair_container_config_dir: /config\nclair_ssl_trust_configure: False\nclair_ssl_trust_src_file: /tmp/clair-ssl-trust.crt\nclair_ssl_trust_host_file: \"{{ clair_config_dir }}/ca.crt\"\nclair_ssl_trust_container_file: /usr/local/share/ca-certificates/ca.crt\n\n# Quay\nquay_enterprise_address: \"\"\n\n# PostgreSQL\n# External Databases\npostgresql_ssl_enabled: False\npostgresql_username: \"clair\"\npostgresql_password: \"clair\"\npostgresql_database: \"clair\"\npostgresql_host: \"\"\npostgresql_port: \"5432\"\npostgresql_db_uri: \"postgresql://{{ postgresql_username }}:{{ postgresql_password }}@{{ postgresql_host if postgresql_host is defined and postgresql_host|trim != '' else hostvars[inventory_hostname]['ansible_eth0']['ipv4']['address'] }}:{{ postgresql_port | default('5432') }}/{{ postgresql_database | default('clair') }}{{ '?sslmode=disable' if not postgresql_ssl_enabled }}\"\n\n# Ports\nclair_host_proxy_port: 6060\nclair_container_proxy_port: 6060\nclair_host_api_port: 6061\nclair_container_api_port: 6061\n\n# SSL\n#clair_ssl_enable: True\n#clair_ssl_key_file: \"\"\n#clair_ssl_cert_file: \"\"\n#clair_ssl_generate_city: Raleigh\n#clair_ssl_generate_state: NC\n#clair_ssl_generate_country: US\n#clair_ssl_generate_organization: Red Hat\n#clair_ssl_generate_organizational_unit: CoP\n#clair_ssl_generate_days_validity: 365"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "63e4e8f4b630f6174c5d9d6b671fe00dac5a95fb", "filename": "roles/manage-confluence-space/tasks/copy_confluence_content.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Get Content from Source\n  uri:\n    url: '{{ confluence_source_url }}/wiki/rest/api/content/{{ confluence_space_content.id }}?expand=body.storage,history,space,container.history,container.version,version,ancestors'\n    method: GET\n    user: '{{ confluence_source_username }}'\n    password: '{{ confluence_source_password }}'\n    force_basic_auth: yes\n    status_code: 200\n    return_content: yes\n  register: content_json\n\n- name: Map ancestor ids if any\n  set_fact: \n    content_ancestors: \"{{ content_json.json.ancestors | map(attribute='id') | list | map('extract', id_mapping) | list }}\"\n\n- name: Pick only the last ancestor\n  set_fact:\n    content_ancestors: \"{{ [-1] | map('extract', content_ancestors) | list }}\"\n  when: content_ancestors|length > 0\n\n- name: Get the current page version\n  uri:\n    url: '{{ confluence_destination_url }}/wiki/rest/api/space/{{ atlassian.confluence.destination.key }}/content?expand=homepage,version'\n    method: GET\n    user: '{{ confluence_destination_username }}'\n    password: '{{ confluence_destination_password }}'\n    force_basic_auth: yes\n    status_code: 200\n    return_content: yes\n  register: homepage_content\n  no_log: false\n\n- name: set homepage at destination\n  block:\n    - set_fact:\n        homepage:\n          body:\n            storage:\n              value: \"{{ content_json.json.body.storage.value }}\"\n              representation: \"storage\"\n          title: \"{{ atlassian.confluence.destination.name }}\"\n          type: \"{{ content_json.json.type }}\"\n          space:\n            key: \"{{ atlassian.confluence.destination.key }}\"\n          version:\n            number: \"{{ homepage_content.json['page']['results'][0]['version']['number'] + 1 }}\"\n    - uri:\n        url: '{{ confluence_destination_url }}/wiki/rest/api/content/{{ destination_homepage_id }}'\n        method: PUT\n        user: '{{ confluence_destination_username }}'\n        password: '{{ confluence_destination_password }}'\n        force_basic_auth: yes\n        status_code: 200\n        body_format: json\n        body: \"{{  homepage | to_json }}\"\n        return_content: yes\n      register: homepage_content_json\n\n    - set_fact:\n       id_mapping: \"{{ id_mapping|combine({ content_json.json.id : { 'id' : homepage_content_json.json.id }}) }}\"\n  when: content_json.json.id == source_homepage_id\n\n- name: set payload for create contect\n  set_fact:\n    payload:\n      id: \"{{ content_json.json.id }}\"\n      title: \"{{ content_json.json.title }}\"\n      type: \"{{ content_json.json.type }}\"\n      space:\n        key: \"{{ atlassian.confluence.destination.key }}\"\n      body:\n        storage:\n          value: \"{{ content_json.json.body.storage.value }}\"\n          representation: \"storage\"\n\n- name: if page is child add ancestors\n  set_fact:\n    payload: \"{{ payload | combine( {'ancestors': content_ancestors} )}}\"\n  when: content_json.json.ancestors|length > 1\n\n- name: Create Content at Destination Site\n  uri:\n    url: '{{ confluence_destination_url }}/wiki/rest/api/content'\n    method: POST\n    user: '{{ confluence_destination_username }}'\n    password: '{{ confluence_destination_password }}'\n    force_basic_auth: yes\n    status_code: 200\n    body_format: json\n    body: \"{{  payload |  to_json }}\"\n    return_content: yes\n  register: new_content_json\n\n- name: Append New id to old id mapping\n  set_fact:\n    id_mapping: \"{{ id_mapping|combine({ content_json.json.id : { 'id' : new_content_json.json.id }}) }}\"\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "35c87a7f4c58a943fa84a671b29971d7b9a23258", "filename": "roles/ansible/tower/config-ansibletower/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: install.yml\n\n- import_tasks: ldap.yml\n  when:\n  - ldap_config|default(False) \n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "2dc1d4de43a2b5577dde53fb79f209cfc37d444d", "filename": "roles/network/templates/wondershaper/wondershaper.conf", "repository": "iiab/iiab", "decoded_content": "[wondershaper]\n# Adapter\n#\nIFACE=\"{{ iiab_wan_iface }}\"\n\n# Download rate in Kbps\n#\nDSPEED={{ wondershaper_dspeed }}\n\n# Upload rate in Kbps\n\nUSPEED={{ wondershaper_upspeed }}\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "75502149757275a990e75a26f4d1889d1e86cb09", "filename": "tasks/selinux-Debian.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n\n- name: Make sure we have the necessary deb packages available for selinux\n  apt:\n    name: \"{{ item }}\"\n    update_cache: yes\n    state: present\n  with_items:\n    - python-selinux\n    - python-semanage\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "66de7cf25fafd0ba3781adf31c808827fcb8821a", "filename": "playbooks/install.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_playbook: \"prep.yml\"\n\n- import_playbook: \"infra-hosts.yml\"\n\n- import_playbook: \"infra-virt-hosts.yml\"\n\n- import_playbook: \"vm.yml\"\n\n- import_playbook: \"services.yml\"\n\n- import_playbook: \"lb-vms.yml\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "efbeb185950ffadc348a2709b94c7f6299783aa2", "filename": "roles/moodle/templates/moodle_installer", "repository": "iiab/iiab", "decoded_content": "#!/bin/bash -x\nsudo -u {{ apache_user }} /usr/bin/php {{ moodle_base }}/admin/cli/install.php \\\n--wwwroot=http://{{ iiab_hostname }}.{{ iiab_domain }}/moodle --dataroot={{ moodle_data }} \\\n--dbtype=pgsql --dbname={{ moodle_database_name }} --dbuser=Admin --dbpass=changeme \\\n--fullname=Your_School --shortname=School \\\n--adminuser=admin --adminpass=changeme \\\n--non-interactive --agree-license\nchown {{ apache_user }}:{{ apache_user }} {{ moodle_base }}/config.php"}, {"commit_sha": "b7c6bfe0369646ca69beeb3dfe07e8218d61c940", "sha": "02421a585860a24b51b70dfba78bd5ad8e8daef4", "filename": "tasks/login_defs.yml", "repository": "dev-sec/ansible-os-hardening", "decoded_content": "---\n- name: create login.defs | os-05, os-05b\n  template:\n    src: 'login.defs.j2'\n    dest: '/etc/login.defs'\n    owner: 'root'\n    group: 'root'\n    mode: '0444'\n\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "b5f5d9f545a6741f34f617a18f3c4c5ab3be1f2b", "filename": "roles/config-postgresql/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Install Containerized PostgreSQL\n  include_tasks: install_containerized.yml\n  when: mode == \"containerized\"\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "99f5cce06c7598c74e61d25cb9b06a51f10f5a77", "filename": "playbooks/files/rock_stop", "repository": "rocknsm/rock", "decoded_content": "#!/bin/bash\n\nfunction feature_enabled() {\n  if grep -qiE \"^with_$1: (true|yes)\" /etc/rocknsm/config.yml; then\n    grep -qiE \"^enable_$1: (true|yes)\" /etc/rocknsm/config.yml;\n    return $?\n  else\n    return 1\n  fi\n}\n\nif feature_enabled fsf; then\n  echo \"Stopping FSF...\"\n  systemctl stop fsf\nfi\n\nif feature_enabled stenographer; then\n  echo \"Stopping Stenographer...\"\n  systemctl stop stenographer\nfi\n\nif feature_enabled suricata; then\n  echo \"Stopping Suricata...\"\n  systemctl stop suricata\nfi\n\nif feature_enabled snort; then\n  echo \"Stopping Snort...\"\n  systemctl stop snortd\nfi\n\nif feature_enabled bro; then\n  echo \"Stopping Bro...\"\n  systemctl stop broctl\nfi\n\nif feature_enabled logstash; then\n  echo \"Stopping Logstash...\"\n  systemctl stop logstash\nfi\n\nif feature_enabled kibana; then\n  echo \"Stopping Kibana...\"\n  systemctl stop kibana\nfi\n\nif feature_enabled elasticsearch; then\n  echo \"Stopping Elasticsearch...\"\n  systemctl stop elasticsearch\nfi\n\nif feature_enabled kafka; then\n  echo \"Stopping Kafka...\"\n  systemctl stop kafka\nfi\n\nif feature_enabled zookeeper; then\n  echo \"Stopping Zookeeper...\"\n  systemctl stop zookeeper\nfi\n\nexit 0\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "9dad6927eb8c2d558ec0af3bf3f0c3b272795c1b", "filename": "roles/osp/admin-sec-group/test/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: all\n  connection: local\n  roles:\n  - role: osp/admin-sec-group\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "57dc4e20360324afec0743f3ab4ce0f7cb28361a", "filename": "roles/config-nagios-target/tasks/nrpe_openshift_master.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Copy in additional Nagios service plugin\n  copy: \n    src: plugins/check_service.sh\n    dest: /usr/lib64/nagios/plugins/check_service.sh\n    owner: root\n    group: root\n    mode: 0755\n\n- name: Copy nrpe.d OpenShift node configuration files\n  copy: \n    src: nrpe.d/check_openshift_master.cfg\n    dest: /etc/nrpe.d/check_openshift_master.cfg\n    owner: root\n    group: root\n    mode: 0644\n\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "7179d6df76d18227a6040e5e693c4fa043b742b7", "filename": "tasks/modules/install-modules.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- import_tasks: install-njs.yml\n  when: nginx_modules.njs | default(false)\n\n- import_tasks: install-perl.yml\n  when: nginx_modules.perl | default(false)\n\n- import_tasks: install-geoip.yml\n  when: nginx_modules.geoip | default(false)\n\n- import_tasks: install-image-filter.yml\n  when: nginx_modules.image_filter | default(false)\n\n- import_tasks: install-rtmp.yml\n  when: nginx_modules.rtmp | default(false) and nginx_type == \"plus\"\n\n- import_tasks: install-xslt.yml\n  when: nginx_modules.xslt | default(false)\n\n- import_tasks: install-waf.yml\n  when: nginx_modules.waf | default(false) and nginx_type == \"plus\"\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "85c9745cb34d0e6ab571d3257cbffa8dc6bcea6b", "filename": "roles/manage-aws-infra/tasks/deploy-cluster.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "# Tasks to deploy AWS infra based in the requested intance numbers\n---\n\n################################################################################\n# Masters\n\n- name: \"Prepare facts to Create Master(s)\"\n  set_fact:\n    ec2_name: \"{{ env_id }}-ocp-{{ master_name }}\"\n    ec2_image: \"{{ aws_image_name }}\"\n    ec2_instance_type: \"{{ master_flavor | default('m4.xlarge') }}\"\n    ec2_group: \"{{ aws_master_sgroups | default(['ocp-ssh', 'ocp-master', 'ocp-app-node']) }}\"\n    ec2_instance_tags:\n      group: \"{{ group_masters_tag }}\"\n      node_labels: \"{{ labels_masters_tag }}\"\n      env_id: \"{{ env_id }}\"\n    ec2_volumes:\n      - device_name: \"{{ master_root_volume }}\"\n        volume_size: \"{{ master_root_volume_size }}\"\n        volume_type: gp2\n      - device_name: \"{{ docker_storage_block_device }}\"\n        volume_size: \"{{ docker_storage_volume_size }}\"\n        volume_type: gp2\n    ec2_num_instances: \"{{ aws_num_masters }}\"\n    ec2_sg:\n      - name: \"ocp-ssh\"\n        description: \"OCP SSH\"\n        rules: \"{{ ocp_ssh_sg_rules|default([]) + default_ocp_ssh_sg_rules }}\"\n      - name: \"ocp-master\"\n        description: \"OCP Master\"\n        rules: \"{{ ocp_master_sg_rules|default([]) + default_ocp_master_sg_rules }}\"\n      - name: \"ocp-app-node\"\n        description: \"OCP App Node\"\n        rules: \"{{ ocp_app_node_sg_rules|default([]) + default_ocp_app_node_sg_rules }}\"\n\n- name: \"Ensure the necessary Security Groups Exists for the Master(s)\"\n  vars:\n    sg_name: \"{{ item.name }}\"\n    sg_description: \"{{ item.description }}\"\n    sg_rules: \"{{ item.rules }}\"\n  include_tasks: create-security-group.yml\n  with_items:\n    - \"{{ ec2_sg }}\"\n\n- name: \"Create Master(s) based on above facts\"\n  include_tasks: create-instance.yml\n  when:\n    - ec2_num_instances > 0\n\n- name: \"Store away the instance information\"\n  set_fact:\n    master_instances: \"{{ ec2_instances }}\"\n\n- name: \"Clear facts\"\n  set_fact:\n    ec2_instances: ''\n\n\n################################################################################\n# Infra Nodes\n\n- name: \"Prepare facts to Create Infra Node(s)\"\n  set_fact:\n    ec2_name: \"{{ env_id }}-ocp-{{ infra_node_name }}\"\n    ec2_image: \"{{ infra_image_name | default(aws_image_name) }}\"\n    ec2_instance_type: \"{{ infra_flavor | default('i3.xlarge') }}\"\n    ec2_group: \"{{ aws_infra_node_sgroups | default(['ocp-ssh', 'ocp-infra-node', 'ocp-app-node']) }}\"\n    ec2_instance_tags:\n      group: \"{{ group_infra_nodes_tag }}\"\n      node_labels: \"{{ labels_infra_nodes_tag }}\"\n      env_id: \"{{ env_id }}\"\n    ec2_volumes:\n      - device_name: \"{{ infra_node_root_volume }}\"\n        volume_size: \"{{ infra_node_root_volume_size }}\"\n        volume_type: gp2\n      - device_name: \"{{ docker_storage_block_device }}\"\n        volume_size: \"{{ docker_storage_volume_size }}\"\n        volume_type: gp2\n    ec2_num_instances: \"{{ aws_num_infra_nodes }}\"\n    ec2_sg:\n      - name: \"ocp-ssh\"\n        description: \"OCP SSH\"\n        rules: \"{{ ocp_ssh_sg_rules|default([]) + default_ocp_ssh_sg_rules }}\"\n      - name: \"ocp-app-node\"\n        description: \"OCP App Node\"\n        rules: \"{{ ocp_app_node_sg_rules|default([]) + default_ocp_app_node_sg_rules }}\"\n      - name: \"ocp-infra-node\"\n        description: \"OCP Infra Node\"\n        rules: \"{{ ocp_infra_node_sg_rules|default([]) + default_ocp_infra_node_sg_rules }}\"\n\n- name: \"Ensure the necessary Security Groups Exists for the Infra Node(s)\"\n  vars:\n    sg_name: \"{{ item.name }}\"\n    sg_description: \"{{ item.description }}\"\n    sg_rules: \"{{ item.rules }}\"\n  include_tasks: create-security-group.yml\n  with_items:\n    - \"{{ ec2_sg }}\"\n\n- name: \"Create Infra Node(s) based on above facts\"\n  include_tasks: create-instance.yml\n  when:\n    - ec2_num_instances > 0\n\n- name: \"Store away the instance information\"\n  set_fact:\n    infra_node_instances: \"{{ ec2_instances }}\"\n\n- name: \"Clear facts\"\n  set_fact:\n    ec2_instances: ''\n\n\n################################################################################\n# App Nodes\n\n- name: \"Prepare facts to Create App Node(s)\"\n  set_fact:\n    ec2_name: \"{{ env_id }}-ocp-{{ app_node_name }}\"\n    ec2_image: \"{{ app_node_image_name | default(aws_image_name) }}\"\n    ec2_instance_type: \"{{ app_node_flavor | default('m4.xlarge') }}\"\n    ec2_group: \"{{ aws_app_node_sgroups | default(['ocp-ssh', 'ocp-app-node']) }}\"\n    ec2_instance_tags:\n      group: \"{{ group_app_nodes_tag }}\"\n      node_labels: \"{{ labels_app_nodes_tag }}\"\n      env_id: \"{{ env_id }}\"\n    ec2_volumes:\n      - device_name: \"{{ app_node_root_volume }}\"\n        volume_size: \"{{ app_node_root_volume_size }}\"\n        volume_type: gp2\n      - device_name: \"{{ docker_storage_block_device }}\"\n        volume_size: \"{{ docker_storage_volume_size }}\"\n        volume_type: gp2\n    ec2_num_instances: \"{{ aws_num_app_nodes }}\"\n    ec2_sg:\n      - name: \"ocp-ssh\"\n        description: \"OCP SSH\"\n        rules: \"{{ ocp_ssh_sg_rules|default([]) + default_ocp_ssh_sg_rules }}\"\n      - name: \"ocp-app-node\"\n        description: \"OCP App Node\"\n        rules: \"{{ ocp_app_node_sg_rules|default([]) + default_ocp_app_node_sg_rules }}\"\n\n- name: \"Ensure the necessary Security Groups Exists for the App Node(s)\"\n  vars:\n    sg_name: \"{{ item.name }}\"\n    sg_description: \"{{ item.description }}\"\n    sg_rules: \"{{ item.rules }}\"\n  include_tasks: create-security-group.yml\n  with_items:\n    - \"{{ ec2_sg }}\"\n\n- name: \"Create App Node(s) based on above facts\"\n  include_tasks: create-instance.yml\n  when:\n    - ec2_num_instances > 0\n\n- name: \"Store away the instance information\"\n  set_fact:\n    app_node_instaces: \"{{ ec2_instances }}\"\n\n- name: \"Clear facts\"\n  set_fact:\n    ec2_instances: ''\n\n\n################################################################################\n# CNS Nodes\n\n- name: \"Prepare facts to Create CNS Node(s)\"\n  set_fact:\n    ec2_name: \"{{ env_id }}-ocp-{{ cns_node_name | default('') }}\"\n    ec2_image: \"{{ cns_node_image_name | default(aws_image_name) }}\"\n    ec2_instance_type: \"{{ cns_node_flavor | default('m4.xlarge') }}\"\n    ec2_group: \"{{ aws_cns_node_sgroups | default(['ocp-ssh', 'ocp-app-node', 'ocp-cns-node']) }}\"\n    ec2_instance_tags:\n      group: \"{{ group_cns_nodes_tag | default('') }}\"\n      node_labels: \"{{ labels_cns_nodes_tag | default('') }}\"\n      env_id: \"{{ env_id }}\"\n    ec2_volumes:\n      - device_name: \"{{ cns_node_root_volume }}\"\n        volume_size: \"{{ cns_node_root_volume_size }}\"\n        volume_type: gp2\n      - device_name: \"{{ docker_storage_block_device }}\"\n        volume_size: \"{{ docker_storage_volume_size }}\"\n        volume_type: gp2\n      - device_name: \"{{ cns_node_glusterfs_volume }}\"\n        volume_size: \"{{ cns_node_glusterfs_volume_size }}\"\n        volume_type: gp2\n    ec2_num_instances: \"{{ aws_num_cns_nodes | default(0) }}\"\n    ec2_sg:\n      - name: \"ocp-ssh\"\n        description: \"OCP SSH\"\n        rules: \"{{ ocp_ssh_sg_rules|default([]) + default_ocp_ssh_sg_rules }}\"\n      - name: \"ocp-app-node\"\n        description: \"OCP App Node\"\n        rules: \"{{ ocp_app_node_sg_rules|default([]) + default_ocp_app_node_sg_rules }}\"\n      - name: \"ocp-cns-node\"\n        description: \"OCP CNS Node\"\n        rules: \"{{ ocp_cns_node_sg_rules|default([]) + default_ocp_cns_node_sg_rules }}\"\n\n- name: \"Ensure the necessary Security Groups Exists for the CNS Node(s)\"\n  vars:\n    sg_name: \"{{ item.name }}\"\n    sg_description: \"{{ item.description }}\"\n    sg_rules: \"{{ item.rules }}\"\n  include_tasks: create-security-group.yml\n  with_items:\n    - \"{{ ec2_sg }}\"\n  when:\n    - ec2_num_instances > 0\n\n- name: \"Create CNS Node(s) based on above facts\"\n  include_tasks: create-instance.yml\n  when:\n    - ec2_num_instances > 0\n\n- name: \"Store away the instance information\"\n  set_fact:\n    cns_node_instances: \"{{ ec2_instances }}\"\n\n- name: \"Clear facts\"\n  set_fact:\n    ec2_instances: ''\n\n\n################################################################################\n# Elastic IP assignments\n\n- name: Create elastic IP for Master Node (Non HA Mode)\n  ec2_eip:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    region: \"{{ aws_region }}\"\n    in_vpc: yes\n    state: present\n    release_on_disassociation: yes\n    device_id: \"{{ master_instances.results[0].instances[0].id }}\"\n  when: not ha_mode\n  register: master_eip\n\n- name: Create elastic IP for Infra Node (Non HA Mode)\n  ec2_eip:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    region: \"{{ aws_region }}\"\n    in_vpc: yes\n    state: present\n    release_on_disassociation: yes\n    device_id: \"{{ infra_node_instances.results[0].instances[0].id }}\"\n  when: not ha_mode\n  register: infra_eip\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "5dfba28358408db871316d05ded3388319b22c2d", "filename": "roles/zookeeper/defaults/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# defaults file for zookeeper\nzookeeper_config_dir: \"/etc/zookeeper/conf\"\nzookeeper_image: \"mesosphere/mesos:0.25.0-0.2.70.ubuntu1404\"\nzookeeper_client_port: 2181\nzookeeper_leader_connect_port: 2888\nzookeeper_leader_election_port: 3888\nzookeeper_server_group: zookeeper_servers\nzookeeper_id: \"\n\t{%- if zookeeper_host_list is defined -%}\n\t\t{%- for host in zookeeper_host_list.split() -%}\n\t\t\t{%- if host == ansible_eth0.ipv4.address -%}\n\t        \t{{ loop.index }}\n\t\t\t{%- endif -%}\n\t\t{%- endfor -%}\n\t{%- else -%}\n    \t{%- for host in groups[zookeeper_server_group] -%}\n      \t\t{%- if host == 'default' or host == inventory_hostname or host == ansible_fqdn or host in ansible_all_ipv4_addresses -%}\n        \t\t{{ loop.index }}\n  \t\t\t{%- endif -%}\n    \t{%- endfor -%}\n    {%- endif -%}\n\"\nconsul_dir: /etc/consul.d\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "bfd26caf7ab11c290c6671bcab11bc5bd4a1b046", "filename": "handlers/main.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: restart auditd\n    service: name=auditd state=restarted\n    changed_when: False\n    ignore_errors: True\n\n  - name: restart rsyslog\n    service: name=rsyslog state=restarted\n    changed_when: False\n    ignore_errors: True\n\n  - name: restart ssh\n    service: name=ssh state=restarted\n    changed_when: False\n    ignore_errors: True\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "57fb450e1407d1e424ccc1270712634885d834be", "filename": "roles/zookeeper/vars/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# vars file for zookeeper\nzookeeper_leader_port: \"2888\"\nzookeeper_election_port: \"3888\"\n"}, {"commit_sha": "1224adf2811c827a09ff0bf133fbb476901a547d", "sha": "f40f09e17c15f44734450898474f24f1090abac6", "filename": "tasks/freebsd_service.yml", "repository": "nusenu/ansible-relayor", "decoded_content": "---\n\n# tor_intances defines the number and configurations of instances\n# an instance is defined with the following fields:\n# inst_name:configfile:username:groupname:pidfile:data_dir\n# username/groupname is set to root to be able to bind to <1024 ports\n# but privileges are dropped afterwards (torrc User parameter)\n- name: Ensure Tor multi-instance configuration is present (FreeBSD)\n  become: yes\n  lineinfile:\n    dest: /etc/rc.conf\n    line: \"tor_instances=\\\"${tor_instances} {{ item.0.ipv4 }}_{{ item.1.orport }}:{{ tor_ConfDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}.torrc:root:root:{{ tor_PidDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/pid:{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\\\"\"\n    create: yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n# this task is a workaround, because 'service tor status'\n# fails if this line is not present (which in turn fails the ansible service module)\n- name: ensure tor instance FreeBSD\n  become: yes\n  lineinfile:\n    dest: /etc/rc.conf\n    line: \"tor_enable=\\\"YES\\\"\"\n    create: yes\n\n- name: Ensure PidDir exists (FreeBSD)\n  become: yes\n  file:\n    path: \"{{ tor_PidDir }}\"\n    state: directory\n    owner: root\n    mode: 0755\n\n- name: Ensure PidDir is owned by per-instance tor_user (FreeBSD)\n  become: yes\n  file:\n    path: \"{{ tor_PidDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    state: directory\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0700\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n# this affects all instances\n- name: Ensure Tor instances are running and enabled (FreeBSD)\n  become: yes\n  service:\n    name: tor\n    enabled: yes\n    state: started\n"}, {"commit_sha": "f26e6a5f816bc8f8672d0b80aa761ae8c459d30a", "sha": "6e18f241a33ae8303c3561e394ef83b4a9bb094b", "filename": "tasks/checks.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- include: distribution-checks.yml\n  when:\n    _docker_os_dist_check | bool\n    \n- include: compatibility-checks.yml\n\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "7c1b240be3fdc7f5b173b36f90d73f879a9e25dc", "filename": "playbooks/provision-satellite-server/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# Please see `inventory/satellite-server` for an example inventory to be used with \n# this playbook to provision a Satellite Server  \n\n- import_playbook: ../prep.yml\n\n- import_playbook: ../osp/manage-user-network.yml\n  when:\n  - hosting_infrastructure == 'openstack'\n\n- import_playbook: ../osp/provision-osp-instance.yml\n  when:\n  - hosting_infrastructure == 'openstack'\n\n- hosts: satellite_servers\n  vars:\n    rhsm_username: \"{{ hostvars['localhost'].rhsm_username }}\"\n    rhsm_password: \"{{ hostvars['localhost'].rhsm_password }}\"\n  roles: \n  - role: rhsm\n  - role: update-host\n \n- hosts: satellite_servers\n  pre_tasks:\n  - import_tasks: generate-lvm-list.yml \n  roles:\n  - role: config-lvm\n\n- import_playbook: configure-satellite-server.yml\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "1ec607113beaefdb950773f63a1f037268c446b2", "filename": "roles/ansible/tower/manage-workflow-templates/tasks/set-permissions.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Obtain team id based on the team name\"\n  set_fact:\n    object_id: \"{{ item.id }}\"\n  when:\n  - permissions_object == \"teams\"\n  - item.name|trim == permissions_value.name|trim\n  with_items:\n  - \"{{ existing_teams_output.rest_output }}\"\n\n- name: \"Obtain user id based on the username\"\n  set_fact:\n    object_id: \"{{ item.id }}\"\n  when:\n  - permissions_object == \"users\"\n  - item.username|trim == permissions_value.name|trim\n  with_items:\n  - \"{{ existing_users_output.rest_output }}\"\n\n- name: \"Obtain role id based on the workflow_template name + role name\"\n  set_fact:\n    role_id: \"{{ item.id }}\"\n  when:\n  - item.summary_fields is defined\n  - item.summary_fields.resource_name is defined\n  - item.summary_fields.resource_name|trim == workflow_template.name|trim\n  - item.name|trim == permissions_value.role|trim\n  with_items:\n  - \"{{ existing_roles_output.rest_output }}\"\n\n- name: \"Set Permission\"\n  uri:\n    url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}/api/v2/{{ permissions_object }}/{{ object_id }}/roles/\"\n    user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n    password: \"{{ ansible_tower.admin_password }}\"\n    force_basic_auth: yes\n    method: POST\n    body: \"{{ { 'id': role_id|int } }}\"\n    body_format: 'json'\n    headers:\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n    validate_certs: no\n    status_code: 200,204\n  when:\n  - object_id is defined\n  - object_id|trim != ''\n  - role_id is defined\n  - role_id|trim != ''\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "83e4d8f61d574ffcc7315e09c2a781aee38249fa", "filename": "tasks/main.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - include: check_requirements.yml\n\n  - include: section_01.yml\n    tags: section01\n\n  - include: section_02.yml\n    tags: section02\n\n  - include: section_03.yml\n    tags: section03\n\n  - include: section_04.yml\n    tags: section04\n\n  - include: section_05.yml\n    tags: section05\n\n  - include: section_06.yml\n    tags: section06\n\n  - include: section_07.yml\n    tags: section07\n\n  - include: section_08.yml\n    tags: section08\n\n  - include: section_09.yml\n    tags: section09\n\n  - include: section_10.yml\n    tags: section10\n\n  - include: section_11.yml\n    tags: section11\n\n  - include: section_12.yml\n    tags: section12\n\n  - include: section_13.yml\n    tags: section13\n\n"}, {"commit_sha": "d25113e8fab871b2ead95ca976c5a43e4759ea26", "sha": "14fad3e18b1ae9fd6de0fdd0ae89ca3a59dd72cc", "filename": "tasks/configure.yml", "repository": "UnderGreen/ansible-role-mongodb", "decoded_content": "---\n\n- name: Create keyFile\n  copy:\n    dest: \"{{ mongodb_conf_keyFile }}\"\n    content: \"{{ mongodb_keyfile_content }}\"\n    owner: \"{{ mongodb_user }}\"\n    group: \"root\"\n    mode: 0600\n  when: mongodb_conf_replSet != ''\n\n- name: Configure log rotation\n  template: src=logrotate.conf.j2 dest=/etc/logrotate.d/mongodb.conf\n  when: mongodb_logrotate\n\n- name: ensure mongodb started and enabled\n  service: name={{ mongodb_daemon_name }} state=started enabled=yes\n\n- name: wait MongoDB port is listening\n  wait_for: host=\"{{ mongodb_conf_bind_ip }}\"port=\"{{ mongodb_conf_port }}\" delay=10 timeout=60 state=started\n  #when: systemd.stat.exists == true\n\n- include: auth_initialization.yml\n  when: mongodb_conf_auth\n\n- name: Create mongodb user\n  user: name={{mongodb_user}} group={{mongodb_user}}\n\n- name: Configure database directory\n  file: state=directory path={{ mongodb_conf_dbpath }} owner={{mongodb_user}} group={{mongodb_user}} mode=0755\n\n- name: Configure logs\n  file: state=file path={{ mongodb_conf_logpath }} owner={{mongodb_user}} group={{mongodb_user}} mode=0644\n\n- name: Configure mongodb\n  template: src=mongod.conf.j2 dest=/etc/mongod.conf owner=root group=root mode=0644\n  register: config_result\n\n- name: mongodb restart\n  service: name={{ mongodb_daemon_name }} state=restarted\n  when: config_result|changed\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "1affd1db7f7d2f5e5e5523faed743cf323859443", "filename": "roles/ansible/tower/config-ansible-tower-ldap/tests/inventory/group_vars/tower.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nansible_connection: local\n\n# NOTE: below is an example on how these params and files can be specified\n#       - please replace with valid values and files\n\nansible_tower:\n  admin_password: \"admin01\"\n  ldap:\n    ca_cert: \"{{ inventory_dir }}/../files/ca.crt\"\n    uri: \"ldaps://idm.test.example.com:636\"\n    bind_dn: \"uid=bind-user,cn=users,cn=accounts,dc=test,dc=example,dc=com\"\n    bind_password: \"my-bind-secret\"\n    user_search_dn: \"cn=users,cn=accounts,dc=test,dc=example,dc=com\"\n    user_dn_template: \"uid=%(user)s,cn=users,cn=accounts,dc=test,dc=example,dc=com\"\n    group_search_dn: \"cn=groups,cn=accounts,dc=test,dc=example,dc=com\"\n    require_group: \"cn=tower-users,cn=groups,cn=accounts,dc=test,dc=example,dc=com\"\n    admin_group: \"cn=tower-admins,cn=groups,cn=accounts,dc=test,dc=example,dc=com\"\n    organization_map:\n    - name: \"My Admin Org\"\n      admin_group: \"cn=tower-admins,cn=groups,cn=accounts,dc=test,dc=example,dc=com\"\n      user_groups:\n      - \"cn=tower-users,cn=groups,cn=accounts,dc=test,dc=example,dc=com\"\n    - name: \"My Support Org\"\n      admin_group: \"cn=tower-admins,cn=groups,cn=accounts,dc=test,dc=example,dc=com\"\n      user_groups:\n      - \"cn=tower-users,cn=groups,cn=accounts,dc=test,dc=example,dc=com\"\n      - \"cn=tower-support,cn=groups,cn=accounts,dc=test,dc=example,dc=com\"\n    team_map:\n    - name: \"My First Team\"\n      organization: \"First Org\"\n      user_groups:\n      - \"cn=users1,cn=groups,cn=accounts,dc=test,dc=example,dc=com\"\n      - \"cn=users2,cn=groups,cn=accounts,dc=test,dc=example,dc=com\"\n    - name: \"My Second Team\"\n      organization: \"Second Org\"\n      user_groups:\n      - \"cn=users1,cn=groups,cn=accounts,dc=test,dc=example,dc=com\"\n"}, {"commit_sha": "3c4d272a77f8aaeb300c8b841bb7e6d8dbd76c1f", "sha": "93232d84320723e14cda3deb1fe351fdae1d1e66", "filename": "tasks/check_environment.yml", "repository": "ansiblebit/oracle-java", "decoded_content": "---\n# file: oracle-java/tasks/check_environment.yml\n#\n# task to set host facts:\n#   - Java is installed?\n#   - which Java version is installed?\n#\n\n# determine if Java is already installed\n\n- name: register oracle_java_installed\n  shell: \"which java\"\n  register: oracle_java_task_installed\n  ignore_errors: yes\n  changed_when: False\n# oracle_java_installed.rc == 0 : installed\n# oracle_java_installed.rc == 1 : not installed\n\n- name: echo oracle_java_task_installed\n  debug:\n    msg=\"oracle_java_task_installed={{ oracle_java_task_installed }}\"\n  when: oracle_java_task_installed is defined\n  tags:\n    - debug\n\n- name: set fact oracle_java_installed\n  set_fact:\n    oracle_java_installed={{ oracle_java_task_installed.rc == 0 }}\n  changed_when: False\n\n- name: echo oracle_java_installed\n  debug:\n    msg=\"oracle_java_installed={{ oracle_java_installed }}\"\n  when: oracle_java_installed is defined\n  tags:\n    - debug\n\n\n# determine which Java version is installed\n\n- name: if Java is installed, check version\n  shell: java -version 2>&1 | head -n 1 | awk '{ print $3 }' | awk -F '\"' '{ print $2 }'\n  when: oracle_java_installed\n  register: oracle_java_task_version\n  changed_when: False\n\n- name: echo oracle_java_task_version\n  debug:\n    msg=\"oracle_java_task_version={{ oracle_java_task_version }}\"\n  when: oracle_java_task_version is defined\n  tags:\n    - debug\n\n- name: set fact oracle_java_installed_version\n  set_fact:\n    oracle_java_version_installed={{ oracle_java_task_version.stdout }}\n  when: oracle_java_installed\n  changed_when: False\n\n- name: echo oracle_java_version_installed\n  debug:\n    msg=\"oracle_java_version_installed={{ oracle_java_version_installed }}\"\n  when: oracle_java_version_installed is defined\n  tags:\n    - debug\n\n- name: echo oracle_java_version_string\n  debug:\n    msg=\"oracle_java_version_string={{ oracle_java_version_string }}\"\n  when: oracle_java_version_string is defined\n  tags:\n    - debug\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "8e12f5479a1f492a3837ed0f07da9f9128ba239f", "filename": "roles/dns/config-dns-server-bind/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: restart named\n  import_tasks: restart_named.yml\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "13df6eb4b458c5fcc3573f278fb386a54e5344a8", "filename": "roles/monit/templates/postgresql", "repository": "iiab/iiab", "decoded_content": "check process postgresql with pidfile /library/pgsql-iiab/postmaster.pid\n    start program = \"/sbin/service postgresql-iiab start\"\n    stop  program = \"/sbin/service postgresql-iiab stop\"\n if failed unixsocket /var/run/postgresql/.s.PGSQL.5432 protocol pgsql then restart\n if failed host localhost port 5432 protocol pgsql then restart\n if 5 restarts within 5 cycles then timeout\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a2d5a6297b024178f5b9f61c5cebfd10725d4a0b", "filename": "roles/config-docker/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ndocker_username: root"}, {"commit_sha": "f3dd45a61b08de1b3351140cc442a705cb2fad82", "sha": "0f85032c3a0da029664a5e3865968a47708c90be", "filename": "tasks/ssh.yml", "repository": "geerlingguy/ansible-role-security", "decoded_content": "---\n- name: Update SSH configuration to be more secure.\n  lineinfile:\n    dest: \"{{ security_ssh_config_path }}\"\n    regexp: \"{{ item.regexp }}\"\n    line: \"{{ item.line }}\"\n    state: present\n  with_items:\n    - regexp: \"^PasswordAuthentication\"\n      line: \"PasswordAuthentication {{ security_ssh_password_authentication }}\"\n    - regexp: \"^PermitRootLogin\"\n      line: \"PermitRootLogin {{ security_ssh_permit_root_login }}\"\n    - regexp: \"^Port\"\n      line: \"Port {{ security_ssh_port }}\"\n    - regexp: \"^UseDNS\"\n      line: \"UseDNS {{ security_ssh_usedns }}\"\n    - regexp: \"^PermitEmptyPasswords\"\n      line: \"PermitEmptyPasswords {{ security_ssh_permit_empty_password }}\"\n    - regexp: \"^ChallengeResponseAuthentication\"\n      line: \"ChallengeResponseAuthentication {{ security_ssh_challenge_response_auth }}\"\n    - regexp: \"^GSSAPIAuthentication\"\n      line: \"GSSAPIAuthentication {{ security_ssh_gss_api_authentication }}\"\n    - regexp: \"^X11Forwarding\"\n      line: \"X11Forwarding {{ security_ssh_x11_forwarding }}\"\n  notify: restart ssh\n\n- name: Add configured user accounts to passwordless sudoers.\n  lineinfile:\n    dest: /etc/sudoers\n    regexp: '^{{ item }}'\n    line: '{{ item }} ALL=(ALL) NOPASSWD: ALL'\n    state: present\n    validate: 'visudo -cf %s'\n  with_items: \"{{ security_sudoers_passwordless }}\"\n  when: security_sudoers_passwordless | length > 0\n\n- name: Add configured user accounts to passworded sudoers.\n  lineinfile:\n    dest: /etc/sudoers\n    regexp: '^{{ item }}'\n    line: '{{ item }} ALL=(ALL) ALL'\n    state: present\n    validate: 'visudo -cf %s'\n  with_items: \"{{ security_sudoers_passworded }}\"\n  when: security_sudoers_passworded | length > 0\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "49b0886bbd40391639c51424ca226f5966e37936", "filename": "roles/letsencrypt/tasks/setup.yml", "repository": "roots/trellis", "decoded_content": "- name: Create directories and set permissions\n  file:\n    mode: \"{{ item.mode | default(omit) }}\"\n    path: \"{{ item.path }}\"\n    state: directory\n  with_items:\n    - path: \"{{ acme_tiny_data_directory }}\"\n      mode: '0700'\n    - path: \"{{ acme_tiny_data_directory }}/csrs\"\n    - path: \"{{ acme_tiny_software_directory }}\"\n    - path: \"{{ acme_tiny_challenges_directory }}\"\n    - path: \"{{ letsencrypt_certs_dir }}\"\n      mode: '0700'\n\n- name: Clone acme-tiny repository\n  git:\n    dest: \"{{ acme_tiny_software_directory }}\"\n    repo: \"{{ acme_tiny_repo }}\"\n    version: \"{{ acme_tiny_commit }}\"\n    accept_hostkey: yes\n\n- name: Copy Lets Encrypt account key source file\n  copy:\n    src: \"{{ letsencrypt_account_key_source_file }}\"\n    dest: \"{{ letsencrypt_account_key }}\"\n  when: letsencrypt_account_key_source_file is defined\n\n- name: Copy Lets Encrypt account key source contents\n  copy:\n    content: \"{{ letsencrypt_account_key_source_content | trim }}\"\n    dest: \"{{ letsencrypt_account_key }}\"\n  when: letsencrypt_account_key_source_content is defined\n\n- name: Generate a new account key\n  shell: openssl genrsa 4096 > {{ letsencrypt_account_key }}\n  args:\n    creates: \"{{ letsencrypt_account_key }}\"\n  register: generate_account_key\n  when: letsencrypt_account_key_source_content is not defined and letsencrypt_account_key_source_file is not defined\n\n- name: Generate certificate renewal script\n  template:\n    src: renew-certs.py\n    dest: \"{{ acme_tiny_data_directory }}/renew-certs.py\"\n    mode: 0700\n\n- name: Download intermediate certificate\n  get_url:\n    url: \"{{ letsencrypt_intermediate_cert_url }}\"\n    dest: \"{{ letsencrypt_intermediate_cert_path }}\"\n    sha256sum: \"{{ letsencrypt_intermediate_cert_sha256sum }}\"\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "c96251b81fc8d703a133809e82e9458a2dc011fb", "filename": "roles/haproxy-config/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'cleanup temp'\n  file:\n    path: '{{ haproxy_temp_dir }}'\n    state: absent\n\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "17f3b5d668be90290fc3450c84ebe8a4b040d623", "filename": "roles/user-management/manage-user-passwd/tasks/generate-passwords.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- include_tasks: generate-one-password.yml\n  with_items:\n    - \"{{ users }}\"\n\n- name: \"Add password to users dict\"\n  set_fact:\n    users_tmp: \"{{ users_tmp|default([]) + [ item | combine( { 'password': user_passwords[item.user_name] } )] }}\"\n  with_items:\n    - \"{{ users }}\"\n\n- name: \"Copy rebuilt structure to users structure\"\n  set_fact:\n    users: \"{{ users_tmp }}\"\n\n"}, {"commit_sha": "473bab1042b717eb6a6641b7240516af4dbae4d8", "sha": "79e6ea6acc0ceb532ac961fe2144b67ed1b377a1", "filename": "tasks/setup.yml", "repository": "fubarhouse/ansible-role-golang", "decoded_content": "---\n\n# Define system-specific variables for fubarhouse.golang.\n\n- name: \"Go-Lang | Define user variable for ssh use\"\n  set_fact:\n    fubarhouse_user: \"{{ ansible_ssh_user }}\"\n  when: ansible_ssh_user is defined and fubarhouse_user is not defined\n\n- name: \"Go-Lang | Define user variable for non-ssh use\"\n  set_fact:\n    fubarhouse_user: \"{{ ansible_user_id }}\"\n  when: ansible_ssh_user is not defined and fubarhouse_user is not defined\n\n- name: \"Go-Lang | Get $HOME\"\n  shell: \"echo $HOME\"\n  register: shell_home_dir\n  changed_when: false\n  when: fubarhouse_user_dir is not defined\n\n- name: \"Go-Lang | Set $HOME\"\n  set_fact:\n    fubarhouse_user_dir: \"{{ shell_home_dir.stdout }}\"\n  when: fubarhouse_user_dir is not defined\n\n- name: \"Go-Lang | Define GOROOT\"\n  set_fact:\n    GOROOT: \"{{ fubarhouse_user_dir }}/go\"\n  when:\n    - GOROOT is not defined\n\n- name: \"Go-Lang | Define GOPATH\"\n  set_fact:\n    GOPATH: \"{{ GOROOT }}/bin\"\n  when:\n    - GOROOT is defined\n    - GOPATH is not defined\n\n- name: \"Go-Lang | Define GOROOT_BOOTSTRAP\"\n  set_fact:\n    GOROOT_BOOTSTRAP: \"{{ fubarhouse_user_dir }}/go1.4\"\n  when:\n   - fubarhouse_user_dir is defined\n   - GOROOT_BOOTSTRAP is not defined\n   - build_go_from_source|bool == true\n\n- name: \"Go-Lang | Looking for compiled binary in GOROOT_BOOTSTRAP installation\"\n  stat:\n    path: \"{{ GOROOT_BOOTSTRAP }}/bin/go\"\n  register: go_binary_bootstrap\n  failed_when: false\n  when:\n   - GOROOT_BOOTSTRAP is defined\n   - build_go_from_source|bool == true\n\n- name: \"Go-Lang | Define GOARCH for 32-bit systems\"\n  set_fact:\n    GOARCH: \"386\"\n  when:\n    - '\"386\" in ansible_architecture'\n    - GOARCH is not defined\n\n- name: \"Go-Lang | Define GOARCH for 64-bit systems\"\n  set_fact:\n    GOARCH: \"amd64\"\n  when:\n    - ansible_architecture == 'x86_64' or ansible_distribution == 'CentOS' or ansible_distribution == 'Debian' or ansible_distribution == 'Red Hat Enterprise Linux' or ansible_distribution == 'RedHat' or ansible_distribution == 'Ubuntu' or ansible_distribution == 'Ubuntu'\n    - GOARCH is not defined\n\n- name: \"Go-Lang | Define GOOS for Darwin systems\"\n  set_fact:\n    GOOS: \"darwin\"\n  when:\n    - ansible_os_family == 'Darwin'\n    - ansible_distribution == 'MacOSX'\n    - GOOS is not defined\n\n- name: \"Go-Lang | Define GOOS for FreeBSD systems\"\n  set_fact:\n    GOOS: \"freebsd\"\n  when:\n    - ansible_distribution == 'FreeBSD'\n    - GOOS is not defined\n\n- name: \"Go-Lang | Define GOOS for linux systems\"\n  set_fact:\n    GOOS: \"linux\"\n  when:\n    - ansible_architecture == 'x86_64' or ansible_distribution == 'CentOS' or ansible_distribution == 'Debian' or ansible_distribution == 'Red Hat Enterprise Linux' or ansible_distribution == 'RedHat' or ansible_distribution == 'Ubuntu' or ansible_distribution == 'Ubuntu'\n    - GOOS is not defined\n\n- name: \"Go-Lang | Define URL for distribution\"\n  set_fact:\n    go_distribution_filename: \"go{{ go_version }}.{{ GOOS }}-{{ GOARCH }}\"\n  when: build_go_from_source|bool == false\n\n- name: \"Go-Lang | Define URL for source\"\n  set_fact:\n    go_distribution_filename: \"go{{ go_version }}.src\"\n  when: build_go_from_source|bool == true\n\n- name: \"Go-Lang | Looking for existing installation\"\n  stat:\n    path: \"{{ GOROOT }}/bin/go\"\n  register: go_binary\n  failed_when: false\n\n- name: \"Go-Lang | Define GOROOT\"\n  set_fact:\n    GOROOT: \"{{ GOROOT }}\"\n  when: GOROOT is defined\n\n- name: \"Go-Lang | Define GOPATH\"\n  set_fact:\n    GOPATH: \"{{ GOROOT }}/bin\"\n  when:\n    - GOPATH is not defined\n    - GOROOT is defined\n\n- name: \"Go-Lang | Getting version information\"\n  become: yes\n  become_user: \"root\"\n  shell: \"{{ GOPATH }}/go version\"\n  environment:\n    GOPATH: \"{{ GOPATH }}\"\n    GOROOT: \"{{ GOROOT }}\"\n  register: current_go_version\n  changed_when: false\n  when: go_binary.stat.exists|bool == true\n\n- name: \"Go-Lang | Define expected version output\"\n  set_fact:\n    expected_go_version_output: \"go version go{{ go_version }} {{ GOOS }}/{{ GOARCH }}\"\n  when: expected_go_version_output is not defined"}, {"commit_sha": "64cbc6946b7ebc0d9a36f40d77ac86f8e3564499", "sha": "a1ca98ab0b516e28cfff857df61d00d533a1235f", "filename": "tasks/version.yml", "repository": "CSCfi/ansible-role-slurm", "decoded_content": "---\n\n#### Version\n\n  - name: Get version of installed slurm RPM\n    shell: yum list installed slurm | grep slurm | awk '{print $2}' | cut -d'-' -f1\n    register: reg_slurm_yum_version\n    check_mode: no\n    changed_when: False\n\n  - name: Get version of installed slurm RPM major version\n    shell: yum list installed slurm | grep slurm | awk '{print $2}' | cut -d'-' -f1|cut -d \".\" -f1-2|sed -e 's/\\.//'\n    register: reg_slurm_yum_version_major\n    check_mode: no\n    changed_when: False\n\n  - name: Set fact with contents of fgci_slurmrepo_version with only the numbers\n    set_fact: slurm_fact_fgci_slurmrepo_version=\"{{ fgci_slurmrepo_version | replace('fgcislurm', '')}}\"\n\n  - name: print custom facts in verbose mode\n    debug: var=item verbosity=1\n    with_items:\n     - \"{{ reg_slurm_yum_version['stdout'] }}\"\n     - \"{{ slurm_fact_fgci_slurmrepo_version }}\"\n     - \"{{\u00a0reg_slurm_yum_version_major['stdout'] }}\"\n"}, {"commit_sha": "ccab58ae5d697bb64abd86558f79c34161d2fb00", "sha": "ed19dc5e4e3db8dd64d8c27c289c0dd4ef88c30f", "filename": "tasks/setup_ldap_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: setup_ldap\n    args:\n      name: \"{{ item.ldap_name }}\"\n      protocol: \"{{ item.ldap_protocol }}\"\n      hostname: \"{{ item.ldap_hostname }}\"\n      port: \"{{ item.ldap_port }}\"\n      use_trust_store: \"{{ item.ldap_use_trust_store | default(false) | bool }}\"\n      auth: \"{{ item.ldap_auth | default('none') }}\"\n      username: \"{{ item.ldap_auth_username | default('') }}\"\n      password: \"{{ item.ldap_auth_password | default('') }}\"\n      search_base: \"{{ item.ldap_search_base }}\"\n      user_base_dn: \"{{ item.ldap_user_base_dn | default('ou=users') }}\"\n      user_ldap_filter: \"{{ item.ldap_user_filter | default('') }}\"\n      user_object_class: \"{{ item.ldap_user_object_class }}\"\n      user_id_attribute: \"{{ item.ldap_user_id_attribute }}\"\n      user_real_name_attribute: \"{{ item.ldap_user_real_name_attribute }}\"\n      user_email_attribute: \"{{ item.ldap_user_email_attribute }}\"\n      map_groups_as_roles: \"{{ item.ldap_map_groups_as_roles | default(false) }}\"\n      map_groups_as_roles_type: \"{{ item.ldap_map_groups_as_roles_type | default('static') }}\"\n      user_memberof_attribute: \"{{ item.ldap_user_memberof_attribute | default('memberOf') }}\"\n      group_base_dn: \"{{ item.ldap_group_base_dn | default('ou=groups') }}\"\n      group_object_class: \"{{ item.ldap_group_object_class | default('groupOfNames') }}\"\n      group_id_attribute: \"{{ item.ldap_group_id_attribute | default('cn') }}\"\n      group_member_attribute: \"{{ item.ldap_group_member_attribute | default('member') }}\"\n      group_member_format: \"{{ item.ldap_group_member_format | default('uid=${username},ou=users,dc=yourcompany') }}\"\n      user_subtree: \"{{ item.ldap_user_subtree | default(false) }}\"\n      group_subtree: \"{{ item.ldap_group_subtree | default(false) }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "9ef8b0d3f81c6ccb42c498a3624284dfa9501998", "filename": "roles/ansible/tower/config-ansible-tower/tasks/install.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- block: # become: True\n\n  - name: \"install epel-release\"\n    package:\n      name: \"{{ ansible_tower_epel_download_url }}\"\n      state: present\n\n  - name: \"Set installation dir fact\"\n    set_fact:\n      ansible_tower_dir: \"{{ ansible_tower_download_url |\u00a0basename |\u00a0regex_replace('.tar.gz','') }}\"\n\n  - name: \"Check if installer dir exists\"\n    stat:\n      path: \"{{ ansible_tower_dir }}\"\n    register: installer_dir\n\n  - name: \"Download & Unpack Ansible Tower installer\"\n    shell: curl {{\u00a0ansible_tower_download_url }} | tar xzf -\n    args:\n      warn: False\n    when: not installer_dir.stat.exists\n\n  - name: \"Set up the Ansible Tower inventory\"\n    template:\n      src: inventory.j2\n      dest: \"{{ ansible_tower_dir }}/inventory\"\n    register: inventory\n\n  - name: \"run tower installer\"\n    shell: ./setup.sh\n    args:\n      chdir: \"{{ ansible_tower_dir }}\"\n\n  - name: \"Wait for Tower to become available before proceeding (30 sec max)\"\n    uri:\n      url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}/api/v1/config/\"\n      user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      password: \"{{ ansible_tower.admin_password }}\"\n      force_basic_auth: yes\n      method: GET\n      validate_certs: no\n    register: status_output\n    until: status_output.status == 200\n    retries: 6\n    delay: 5\n\n  - name: \"Add Tower license\"\n    uri:\n      url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}/api/v1/config/\"\n      user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      password: \"{{ ansible_tower.admin_password }}\"\n      force_basic_auth: yes\n      method: POST\n      body: '{{\u00a0lookup(\"file\", ansible_tower.install.license_file) | from_json |\u00a0combine({\"eula_accepted\":\"true\"}) | to_json }}'\n      body_format: 'json'\n      headers:\n        Content-Type: \"application/json\"\n        Accept: \"application/json\"\n      validate_certs: no\n\n  - name: \"Download and Install the 'oc' client for OpenShift interactions\"\n    shell: curl {{ ansible_tower_oc_download_url }} | tar -C /bin/ -xzf -\n    args:\n      warn: False\n    when:\n    - ansible_tower_oc_download_url|trim != ''\n\n  - name: \"Copy custom Tower SSL certificate and Key\"\n    block:\n      - copy:\n          src: \"{{ ansible_tower.install.ssl_certificate.cert }}\"\n          dest: /etc/tower/tower.cert\n        notify:\n        - restart-tower\n      - copy:\n          src: \"{{ ansible_tower.install.ssl_certificate.key }}\"\n          dest: /etc/tower/tower.key\n        notify:\n        - restart-tower\n    when:\n    - ansible_tower.install.ssl_certificate is defined\n\n  become: True\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "7ce364f1d86cc1fc7e58305844f7b09a08e36aee", "filename": "roles/manage-confluence-space/tasks/copy_confluence_attachments.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Get attachment data\n  uri:\n    url: '{{ confluence_space_source_url }}/rest/api/content/{{ confluence_content_ids.key }}/child/attachment'\n    method: GET\n    user: '{{ source_confluence_site_username }}'\n    password: '{{ source_confluence_site_password }}'\n    force_basic_auth: yes\n    status_code: 200\n    return_content: yes\n  register: attachments_json\n  no_log: true\n\n- name: Create temp directory for downloaded attachments\n  tempfile:\n    state: directory\n  register: attachment_tempdir\n\n- include_tasks: download_attachment.yml\n  with_items: '{{ attachments_json.json.results }}'\n  loop_control:\n    loop_var: attachment_data\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "dec5069f57f73239761e4b4c81b0f81a6fd5ff2e", "filename": "roles/postgresql/templates/postgresql-iiab.service", "repository": "iiab/iiab", "decoded_content": "{% if is_debuntu %}\n[Unit]\nDescription=PostgreSQL database server\nAfter=network.target\n\n[Service]\nType=forking\n\nUser=postgres\nGroup=postgres\n\n# Where to send early-startup messages from the server (before the logging\n# options of postgresql.conf take effect)\n# This is normally controlled by the global default set by systemd\n# StandardOutput=syslog\n\n# Disable OOM kill on the postmaster\nOOMScoreAdjust=-1000\n# ... but allow it still to be effective for child processes\n# (note that these settings are ignored by Postgres releases before 9.5)\nEnvironment=PG_OOM_ADJUST_FILE=/proc/self/oom_score_adj\nEnvironment=PG_OOM_ADJUST_VALUE=0\n\n# Maximum number of seconds pg_ctl will wait for postgres to start.  Note that\n# PGSTARTTIMEOUT should be less than TimeoutSec value.\nEnvironment=PGSTARTTIMEOUT=270\n\nEnvironment=PGDATA=/library/pgsql-iiab\n\nExecStart=/usr/lib/postgresql/{{ postgresql_version }}/bin/pg_ctl start -D ${PGDATA} -s -w -t ${PGSTARTTIMEOUT}\nExecStop=/usr/lib/postgresql/{{ postgresql_version }}/bin/pg_ctl stop -D ${PGDATA} -s -m fast\nExecReload=/usr/lib/postgresql/{{ postgresql_version }}/bin/pg_ctl reload -D ${PGDATA} -s\n\n# Give a reasonable amount of time for the server to start up/shut down.\n# Ideally, the timeout for starting PostgreSQL server should be handled more\n# nicely by pg_ctl in ExecStart, so keep its timeout smaller than this value.\nTimeoutSec=300\n\n[Install]\nWantedBy=multi-user.target\n{% else %}\n# --postgres_xs.service\n.include /usr/lib/systemd/system/postgresql.service\n[Service]\nEnvironment=PGDATA=/library/pgsql-iiab\n{% endif %}\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "a6b1530ba50a54e7edd0424fd3a61e97ded1eeb9", "filename": "roles/vpn/tasks/ipec_configuration.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- name: Setup the config files from our templates\n  template:\n    src: \"{{ item.src }}\"\n    dest: \"{{ item.dest }}\"\n    owner: \"{{ item.owner }}\"\n    group: \"{{ item.group }}\"\n    mode: \"{{ item.mode }}\"\n  with_items:\n    - src: strongswan.conf.j2\n      dest: \"{{ config_prefix|default('/') }}etc/strongswan.conf\"\n      owner: root\n      group: \"{{ root_group|default('root') }}\"\n      mode: \"0644\"\n    - src: ipsec.conf.j2\n      dest: \"{{ config_prefix|default('/') }}etc/ipsec.conf\"\n      owner: root\n      group: \"{{ root_group|default('root') }}\"\n      mode: \"0644\"\n    - src: ipsec.secrets.j2\n      dest: \"{{ config_prefix|default('/') }}etc/ipsec.secrets\"\n      owner: strongswan\n      group: \"{{ root_group|default('root') }}\"\n      mode: \"0600\"\n  notify:\n    - restart strongswan\n\n- name: Get loaded plugins\n  shell: >\n    find {{ config_prefix|default('/') }}etc/strongswan.d/charon/ -type f -name '*.conf' -exec basename {} \\; | cut -f1 -d.\n  register: strongswan_plugins\n\n- name: Disable unneeded plugins\n  lineinfile: dest=\"{{ config_prefix|default('/') }}etc/strongswan.d/charon/{{ item }}.conf\" regexp='.*load.*' line='load = no' state=present\n  notify:\n    - restart strongswan\n  when: item not in strongswan_enabled_plugins and item not in strongswan_additional_plugins\n  with_items: \"{{ strongswan_plugins.stdout_lines }}\"\n\n- name: Ensure that required plugins are enabled\n  lineinfile: dest=\"{{ config_prefix|default('/') }}etc/strongswan.d/charon/{{ item }}.conf\" regexp='.*load.*' line='load = yes' state=present\n  notify:\n    - restart strongswan\n  when: item in strongswan_enabled_plugins or item in strongswan_additional_plugins\n  with_items: \"{{ strongswan_plugins.stdout_lines }}\"\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "1788aeebe801c06bbdbb67f0a7418289d556c829", "filename": "roles/rollback/tasks/prior-release.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Get list position of current symlinked release\n  shell: \"ls releases | grep -n $(basename $(readlink {{ project_current_path }})) | cut -f1 -d:\"\n  args:\n    chdir: \"{{ project_root }}\"\n  register: current_release_position\n\n- name: Fail if current release is the oldest available release\n  fail:\n    msg: \"Currently symlinked to earliest available release. Cannot rollback. You may manually specify a different release using --extra-vars='release=12345678901234'.\"\n  when: current_release_position.stdout_lines[0] == \"1\"\n\n- name: Collect list of releases\n  command: ls releases\n  args:\n    chdir: \"{{ project_root }}\"\n  register: releases\n\n- name: Create new_release_path variable\n  set_fact:\n    new_release_path: \"{{ project_root }}/releases/{{ releases.stdout_lines[(current_release_position.stdout_lines[0] | int - 2)] }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "bc2d346811b98873ee014bc2f62859293c6779e6", "filename": "roles/config-ipa-client/tasks/ipa-install.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Include prereqs per the type of OS\"\n  include_tasks: \"{{ distro_file }}\"\n  with_first_found:\n  - files:\n    - prereq-{{ ansible_distribution }}.yml\n    skip: true\n  loop_control:\n    loop_var: distro_file\n\n- import_tasks: move-local-user-home.yml\n\n- name: \"Ensure SUDO access for main user (if any)\"\n  lineinfile:\n    path: /etc/sudoers.d/10-idm-user\n    regexp: \"^{{ main_user }}\"\n    line: \"{{ main_user }} ALL=(ALL) NOPASSWD:ALL\"\n    create: yes\n  when:\n  - main_user is defined\n  - main_user|trim != \"\"\n\n- name: \"Ensure SUDO access for group (if any)\"\n  lineinfile:\n    path: /etc/sudoers.d/11-idm-admin-group\n    regexp: \"^%{{ admin_group }}\"\n    line: \"%{{ admin_group }} ALL=(ALL) NOPASSWD:ALL\"\n    create: yes\n  when:\n  - admin_group is defined\n  - admin_group|trim != \"\"\n\n- name: \"Set up the IPA/IdM client integration\"\n  command: 'ipa-client-install -U --automount-location={{ ipa_automount_location }} -p \"{{ ipa_username }}\" -w \"{{ ipa_password }}\" --domain=\"{{ ipa_domain }}\" --force-join'\n\n- name: \"Workaround for missing sss in nsswitch.conf\"\n  lineinfile:\n    path: /etc/nsswitch.conf\n    regexp: '^automount:.*files'\n    line: 'automount: files sss'\n    state: present\n  register: automount_line\n\n- name: \"Restart sssd if nsswitch.conf was updated\"\n  service:\n    name: sssd\n    state: restarted\n  when:\n  - automount_line.changed\n\n- name: \"Restart autofs if nsswitch.conf was updated\"\n  service:\n    name: autofs\n    state: restarted\n  when:\n  - automount_line.changed\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "316a890454f3e520db2fbc244c9818ac47c74be9", "filename": "playbooks/manage-users/manage-atlassian-users.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Create Atlassian Users\n  hosts: localhost\n  roles:\n    - user-management/manage-atlassian-users\n  no_log: true\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "6e95ac7dcc047c0ecfbce844db06c23ad924f5fb", "filename": "roles/manage-aws-infra/tasks/start_stop_instances.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "# Start and Stop AWS OCP Cluster based on given state\n---\n- name: Ensure ec2 instances are in {{ operation }} state\n  ec2:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    region: \"{{ aws_region }}\"\n    instance_tags:\n      env_id: \"{{ env_id }}\"\n    state: \"{{ operation }}\"\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "8941da80439573e9e2b2ab0a3f8c25da72c27224", "filename": "playbooks/openshift/aws/delete.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n- hosts: localhost\n  roles:\n  - role: manage-aws-infra\n    operation: absent\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "2e818c51ed84a0facfc962fa5ca9664dd5077403", "filename": "tasks/controller/install-controller.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- import_tasks: setup-debian.yml\n  when: ansible_os_family == \"Debian\"\n\n- import_tasks: setup-redhat.yml\n  when: ansible_os_family == \"RedHat\"\n\n- name: \"(Install: All OSs) Install NGINX Controller Agent\"\n  package:\n    name: nginx-controller-agent\n    state: present\n\n- name: \"(Setup: All OSs) Copy NGINX Controller Agent Configuration Template\"\n  copy:\n    remote_src: yes\n    src: /etc/controller-agent/agent.controller.conf.default\n    dest: /etc/controller-agent/agent.conf\n\n- name: \"(Setup: All OSs) Copy NGINX Configurator Agent Configuration Template\"\n  copy:\n    remote_src: yes\n    src: /etc/controller-agent/agent.configurator.conf.default\n    dest: /etc/controller-agent/agent.configurator.conf\n\n- name: \"(Setup: All OSs) Configure NGINX Controller Agent API Key\"\n  lineinfile:\n    dest: /etc/controller-agent/agent.conf\n    regexp: api_key =.*\n    line: \"api_key = {{ nginx_controller_api_key }}\"\n\n- name: \"(Setup: All OSs) Configure NGINX Controller Agent API URL\"\n  lineinfile:\n    dest: /etc/controller-agent/agent.conf\n    regexp: api_url =.*\n    line: \"api_url = {{ nginx_controller_api_endpoint }}\"\n\n- name: \"(Setup: All OSs) Configure NGINX Controller Agent API Hostname\"\n  lineinfile:\n    dest: /etc/controller-agent/agent.conf\n    regexp: hostname =.*\n    line: \"hostname = {{ ansible_hostname }}\"\n  notify: \"(Handler: All OSs) Start NGINX Controller Agent\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "b0341521ae8f2e9792693da0b9fdf29ddd6ae523", "filename": "roles/ejabberd/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Install ejabberd packages\n  package: name={{ item }}\n           state=present\n  with_items:\n   - ejabberd\n  tags:\n    - download\n\n- name: Configure ejabberd\n  template: backup=yes\n            src={{ item.src }}\n            dest={{ item.dest }}\n            owner=root\n            group=root\n            mode={{ item.mode }}\n  with_items:\n    - { src: 'ejabberd-xs.cfg.j2', dest: '/etc/ejabberd/ejabberd-xs.cfg' , mode: '0644' }\n    - { src: 'ejabberdctl.cfg.j2', dest: '/etc/ejabberd/ejabberdctl.cfg', mode: '0644' }\n    - { src: 'ejabberd-xs', dest: '/etc/sysconfig/ejabberd-xs', mode: '0755' }\n#    - { src: 'ejabberd-domain-config', dest: '/etc/sysconfig/olpc-scripts/domain_config.d/ejabberd', mode: '0755'}\n#    - { src: 'ejabberd', dest: '/etc/sysconfig/olpc-scripts/domain_config.d/ejabberd' , mode: '0755' }\n    - { src: 'ejabberd-xs.service.j2', dest: '/etc/systemd/system/ejabberd-xs.service', mode: '0755' }\n    - { src: 'xs-ejabberd-srg', dest: '/usr/bin/xs-ejabberd-srg' , mode: '0755' }\n    - { src: '10-ejabberdmoodle', dest: '/etc/sudoers.d/10-ejabberdmoodle', mode: '0440' }\n    - { src: 'ejabberd.tmpfiles', dest: '/etc/tmpfiles.d/ejabberd.conf', mode: '0640' }\n  register: ejabberd_config\n\n- name: Put the startup script in place - debian\n  template: src='ejabberd-xs.init'\n            dest='/etc/init.d/ejabberd-xs'\n  when: is_debuntu\n\n- name: Put the startup script in place - non debian\n  template: src='ejabberd-xs.init'\n            dest='/usr/libexec/ejabberd-xs'\n  when: not is_debuntu\n\n- name: Remove ejabberd_domain if domain changes\n  file: path=/etc/sysconfig/ejabberd_domain_name\n        state=absent\n  when: ejabberd_config.changed\n\n- name: Enable ejabberd service\n  file: src=/etc/systemd/system/ejabberd-xs.service\n        dest=/etc/systemd/system/multi-user.target.wants/ejabberd-xs.service\n        owner=root\n        group=root\n        state=link\n\n- name: Start ejabberd service\n  service: name=ejabberd-xs\n           state=restarted\n           enabled=yes\n  when: ejabberd_config.changed and ejabberd_enabled\n\n- name: Wait for ejabberd service start\n  wait_for: port=5280\n            delay=15\n            state=started\n            timeout=300\n  when: ejabberd_config.changed and ejabberd_enabled\n\n- name: Create online group\n  shell: ejabberdctl srg_create Online \"schoolserver\" Online \"Online_Users\" Online\n  when: ejabberd_config.changed and not is_debuntu\n\n- name: Add all users to online group\n  shell: ejabberdctl srg_user_add '@online@' \"schoolserver\" Online \"schoolserver\"\n  when: ejabberd_config.changed and not is_debuntu\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "7a0ef3fc31348ec5874c31c73335da9012f5b994", "filename": "roles/samba/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "---\n# Create a smbuser\n#\n\n- name: create smb user\n  user: name=\"{{ smbuser }}\" shell=/sbin/nologin password=\"{{ smbpassword }}\"\n\n- name: create the public folder\n  file: dest=\"{{ shared_dir }}\" owner=\"{{ smbuser }}\" group=\"{{ smbuser }}\" mode=0777 state=directory\n\n# Install and configure samba server (requires ports 137, 138, 139, 445 open).\n- name: Ensure Samba-related packages are installed.\n  package: name={{ item }}\n           state=present\n  with_items:\n  - samba\n  - samba-client\n  - samba-common\n  - cifs-utils\n  tags:\n    - samba\n    - download\n\n- name: put our smb.conf in place\n  template: src=smb.conf.j2 dest=/etc/samba/smb.conf\n\n- name: Ensure Samba is running and set to start on boot.\n  service: name={{ smb_service }} state=started enabled=yes\n  tags:\n    - samba\n  when : samba_enabled\n\n- name: netbios name server is running and set to start on boot.\n  service: name={{ nmb_service }} state=started enabled=yes\n  tags:\n    - samba\n  when : samba_enabled\n\n- name: Disable Samba if that is wanted\n  service: name={{ smb_service }} state=stopped enabled=no\n  tags:\n    - samba\n  when : not samba_enabled\n\n- name: Disable Samba name server if that is wanted\n  service: name={{ nmb_service }} state=stopped enabled=no\n  tags:\n    - samba\n  when : not samba_enabled\n\n- name: Add samba to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=samba\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: samba\n    - option: description\n      value: '\"Samba is a Microsoft compatible remote file access system  - generalized to CIFS --common internet file system\"'\n    - option: enabled\n      value: \"{{ samba_enabled }}\"\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "d2548eb500ff0fb50a6f7ecb57ce132a706a1935", "filename": "roles/mesos/handlers/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# handlers file for mesos\n- name: start mesos master\n  sudo: yes\n  service:\n    name: mesos-master\n    state: started\n\n- name: start mesos slave\n  sudo: yes\n  service:\n    name: mesos-slave\n    state: started\n\n- name: restart mesos master\n  sudo: yes\n  service:\n    name: mesos-master\n    state: restarted\n\n- name: restart mesos slave\n  sudo: yes\n  service:\n    name: mesos-slave\n    state: restarted\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "90724e9e0c0b8d2dfb84af5eddd64dc9ada0abcb", "filename": "playbooks/services.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Configure DHCP'\n  hosts: dhcp_servers\n  roles:\n  - role: dhcp\n  tags: \n  - configure_dhcp\n\n- name: 'Configure DNS (internal)'\n  hosts: dns_servers_internal\n  roles:\n  - role: config-dns-server\n  tags:\n  - configure_dns_internal\n\n- name: 'Configure DNS (external)'\n  hosts: dns_servers_external\n  roles:\n  - role: config-dns-server\n  tags:\n  - configure_dns_external\n\n- name: 'Configure NTP / Chrony'\n  hosts: ntp_servers\n  roles:\n  - role: config-chrony\n  tags:\n  - configure_chrony\n\n- name: 'Configure IdM'\n  hosts: idm_servers\n  roles:\n  - role: idm\n  tags:\n  - configure_idm\n\n- name: 'Configure Satellite'\n  hosts: satellite_servers\n  roles:\n  - role: config-satellite\n  tags:\n  - configure_satellite\n\n- name: 'Configure www hosts'\n  hosts: www_servers\n  roles:\n  - role: config-httpd\n  tags:\n  - configure_www_hosts\n\n- name: 'Configure REPO hosts'\n  hosts: repo_servers\n  roles:\n  - role: config-software-src\n  - role: config-repo-server\n  tags:\n  - configure_repo_hosts\n\n- name: 'Configure PXE hosts'\n  hosts: pxe_servers\n  roles:\n  - role: config-pxe\n  tags:\n  - configure_pxe_hosts\n\n- name: 'Configure OpenVPN'\n  hosts: openvpn_servers\n  roles:\n  - role: config-openvpn\n  tags:\n  - configure_openvpn\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "bb3ba7a7b4c2df57058b5588ee8f8999be718496", "filename": "tasks/keys/apk-key.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: APK OSs) Download NGINX Signing Key\"\n  get_url:\n    url: https://nginx.org/keys/nginx_signing.rsa.pub\n    dest: /etc/apk/keys/nginx_signing.rsa.pub\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "0b5394b3ba992ff1441ca1061646896fcfc60d03", "filename": "playbooks/minishift-remote/README.md", "repository": "redhat-cop/infra-ansible", "decoded_content": "# Minishift Remote playbook\n\nThis playbook can be executed against an existing host or used to provision a new machine to be utilized as a remote target for Minishift.\n\n\n## Prerequisites\n\nOne of the two options:\n\n* A running host with docker installed and a user who can elevate to root access\n* IaaS that allows for provisioning through these playbooks\n\n## Example run\n\nAn example inventory can be found in the [inventory/minishift-remote](../../inventory/minishift-remote) directory. \n\n```\n> ansible-playbook -i ../../inventory/minishift-remote main.yml\n```\n\n\n## Inventory Options\n\n| Name | Description | Default|\n|---|---|---|\n|provision_infrastructure|Whether to provision infrastructure|`True`|\n|hosting_infrastructure|IaaS infrastructure used to host Minishift| `openstack`| \n|rhsm_register|Register RHEL machine if utilized| `False` |\n|docker_install|Install and configure Docker on remote machine| `true`|\n|install_prerequisites|Install dependencies used by Minishift | 80, 443, 2376, 4001 |\n\nAdditional options can also be found in the [minishift-remote](../../roles/minishift-remote) role to further tailor the execution."}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "5cfa986a22782542fb0f1be7cea8beee72c37d8d", "filename": "tasks/create_repo_yum_proxy_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_yum_proxy\n    args: \"{{ _nexus_repos_yum_defaults|combine(item) }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "14d115e72a68596440a6cf6ecf1783584f031dfc", "filename": "roles/network/templates/named/bind9.service", "repository": "iiab/iiab", "decoded_content": "[Unit]\nDescription=BIND Domain Name Server\nDocumentation=man:named(8)\nAfter=network.target\n\n[Service]\nEnvironmentFile=-/etc/sysconfig/named\nExecStart=/usr/sbin/named -f -u bind $OPTIONS\nExecReload=/usr/sbin/rndc reload\nExecStop=/usr/sbin/rndc stop\n\n[Install]\nWantedBy=multi-user.target\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "f68aa8e3adcd68b9fc7c976dce257bd45f53da7a", "filename": "playbooks/roles/bb0-openstack/tests/test.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "---\n- hosts: localhost\n  remote_user: root\n  roles:\n    - provisioning_openstack"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "d67cbde4d7729588934df443d37a359fc2c983dc", "filename": "playbooks/ubuntu.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- name: Ubuntu | Install prerequisites\n  raw: sleep 10 && sudo apt-get update -qq && sudo apt-get install -qq -y python2.7\n\n- name: Ubuntu | Configure defaults\n  raw: sudo update-alternatives --install /usr/bin/python python /usr/bin/python2.7 1\n  tags:\n    - update-alternatives\n"}, {"commit_sha": "e91a55152358e890a05cf849abc7d58b8badecc2", "sha": "12a9ea2e925e4503674405d44366c405524193e8", "filename": "tasks/perm.yml", "repository": "fubarhouse/ansible-role-golang", "decoded_content": "---\n\n- name: \"Go-Lang | Set codebase permissions\"\n  file:\n    path: \"{{ GOROOT }}\"\n    state: directory\n    mode: \"{{ mode_codebase }}\"\n    recurse: no\n  changed_when: false\n\n- name: \"Go-Lang | Set workspace permissions\"\n  file:\n    path: \"{{ GOPATH }}/{{ item }}\"\n    state: directory\n    mode: \"{{ mode_workspace }}\"\n    recurse: no\n  with_items:\n  - src\n  - pkg\n  - bin\n  changed_when: false"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "d07a671d708ccba6110d1c58fb63c9cdada6b927", "filename": "roles/network/templates/named/named.blackhole", "repository": "iiab/iiab", "decoded_content": "$TTL    604800\n@       IN      SOA     . root.localhost. (\n                              1         ; Serial\n                         604800         ; Refresh\n                          86400         ; Retry\n                        2419200         ; Expire\n                         604800 )       ; Negative Cache TTL\n\n\tIN\tNS\t.\n.\tIN\tA\t{{ lan_ip }}\n*.\tIN\tA\t{{ lan_ip }}\n\n"}, {"commit_sha": "e91a55152358e890a05cf849abc7d58b8badecc2", "sha": "df5e6617a067fc974c3b877eed3c79f43f630240", "filename": "tasks/install-bootstrap.yml", "repository": "fubarhouse/ansible-role-golang", "decoded_content": "---\n\n- name: \"Go-Lang | Ensure bootstrap directory is writable\"\n  file:\n    path: \"{{ GOROOT_BOOTSTRAP }}\"\n    state: directory\n    owner: \"{{ fubarhouse_user }}\"\n    mode: 0755\n\n- name: \"Go-Lang | Get bootstrap distribution\"\n  git:\n    repo: \"https://github.com/golang/go.git\"\n    dest: \"{{ GOROOT_BOOTSTRAP }}\"\n    version: \"release-branch.go1.4\"\n    clone: yes\n    update: no\n\n- name: \"Go-Lang | Building Bootstrapper\"\n  shell: \"cd {{ GOROOT_BOOTSTRAP }}/src && ./{{ go_build_script }}\"\n  environment:\n    GOROOT_BOOTSTRAP: \"{{ GOROOT_BOOTSTRAP }}\""}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "cdeaccc3047905b4e092f283bbb224f1f8fe29de", "filename": "tasks/section_06_level1_05.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 6.5.2 Configure Network Time Protocol (restrict4) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='restrict -4 default kod nomodify notrap nopeer noquery'\n        regexp='^restrict -4 default'\n        state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.2\n\n  - name: 6.5.3 Configure Network Time Protocol (restrict6) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='restrict -6 default kod nomodify notrap nopeer noquery'\n        regexp='^restrict -6 default'\n        state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.3\n\n  - name: 6.5.4 Configure Network Time Protocol (server check) (NTP) (Scored)\n    command: 'grep \"^server\" /etc/ntp.conf'\n    register: ntp_server_rc\n    changed_when: False\n    always_run: True\n    ignore_errors: True\n    tags:\n      - section6\n      - section6.5\n      - section6.5.4\n\n  - name: 6.5.4 Configure Network Time Protocol (server add) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='server 0.fr.pool.ntp.org'\n        state=present\n    when: ntp_server_rc.rc == 1\n    tags:\n      - section6\n      - section6.5\n      - section6.5.4\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "9ffba24fe3f384431a004ef97033a2fa54b2644d", "filename": "roles/osp/packstack-install/tasks/packstack-install-prep.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Include prereq\"\n  import_tasks: prereq.yml\n\n- name: \"Initialize variables\"\n  set_fact:\n    config: []\n\n- name: \"Get the list of hosts part of this OSP cluster\"\n  set_fact:\n    cluster_hosts: \"{{ cluster_hosts | default(groups[group_names[0]]) | intersect(groups[item]) }}\"\n  with_items:\n  - \"{{ group_names }}\"\n\n- name: \"Build OSP fact: Compute(nova) Host(s)\"\n  set_fact:\n    compute_hosts: \"{{ compute_hosts|default([]) }} + [ '{{ hostvars[item].ansible_host }}' ]\"\n  with_items:\n  - \"{{ cluster_hosts }}\"\n  when:\n  - \"'nova' in hostvars[item].osp_roles.split(',')\"\n\n- name: \"Build OSP fact: Network(neutron) Host(s)\"\n  set_fact:\n    network_hosts: \"{{ network_hosts|default([]) }} + [ '{{ hostvars[item].ansible_host }}' ]\"\n  with_items:\n  - \"{{ cluster_hosts }}\"\n  when:\n  - \"'neutron' in hostvars[item].osp_roles.split(',')\"\n\n- name: \"Set OSP fact: Build Config Dictionary\"\n  set_fact:\n    config:\n      compute: \"{{ compute_hosts|join(',') }}\"\n      network: \"{{ network_hosts|join(',') }}\"\n\n- name: \"Set OSP fact: Build Config Dictionary\"\n  set_fact:\n    config: \"{{ config | combine( { item.1: hostvars[item.0].ansible_host } ) }}\"\n  with_nested:\n  - \"{{ cluster_hosts }}\"\n  - [ 'controller', 'cinder', 'amqp', 'mariadb', 'mongodb', 'redis' ]\n  when:\n  - \"item[1] in hostvars[item.0].osp_roles.split(',')\"\n\n- name: \"Set answer-file fact\"\n  set_fact:\n    answer_file: \"answer-file-{{ ansible_date_time.date }}-{{ ansible_date_time.time }}\"\n\n- name: \"Generate the Initial answer file\"\n  command: \"packstack --gen-answer-file={{ answer_file }}\"\n\n- name: \"Populate the yes/no choices in the answer file\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^{{ item.key }}'\n    line: '{{ item.key }}={{ item.value }}'\n  with_dict: \"{{ osp_install_choices }}\"\n\n- name: \"Populate the answer file with OSP host values\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^{{ item.answer_key }}='\n    line: '{{ item.answer_key }}={{ config[item.config_key] }}'\n  with_items:\n  - { config_key: 'amqp', answer_key: 'CONFIG_AMQP_HOST' }\n  - { config_key: 'compute', answer_key: 'CONFIG_COMPUTE_HOSTS' }\n  - { config_key: 'controller', answer_key: 'CONFIG_CONTROLLER_HOST' }\n  - { config_key: 'mariadb', answer_key: 'CONFIG_MARIADB_HOST' }\n  - { config_key: 'mongodb', answer_key: 'CONFIG_MONGODB_HOST' }\n  - { config_key: 'network', answer_key: 'CONFIG_NETWORK_HOSTS' }\n  - { config_key: 'redis', answer_key: 'CONFIG_REDIS_HOST' }\n\n- name: \"Update SSL_CERT Subject CN\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_SSL_CERT_SUBJECT_CN='\n    line: 'CONFIG_SSL_CERT_SUBJECT_CN={{ osp_public_fqdn }}'\n\n- name: \"Update SSL_CERT Subject MAIL\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_SSL_CERT_SUBJECT_MAIL='\n    line: 'CONFIG_SSL_CERT_SUBJECT_MAIL=admin@{{ osp_public_fqdn }}'\n\n- name: \"Replace PW placeholders\"\n  replace:\n    path: \"{{ answer_file }}\"\n    regexp: 'PW_PLACEHOLDER'\n    replace: '{{ pw_placeholder_replacement }}'\n\n- name: \"Update MariaDB Password\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_MARIADB_PW='\n    line: 'CONFIG_MARIADB_PW={{ mariadb_passwd }}'\n\n- name: \"Update Keystone DB Password\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_KEYSTONE_DB_PW='\n    line: 'CONFIG_KEYSTONE_DB_PW={{ keystone_db_password }}'\n\n- name: \"Update Keystone Admin Password\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_KEYSTONE_ADMIN_PW='\n    line: 'CONFIG_KEYSTONE_ADMIN_PW={{ keystone_admin_password }}'\n\n- name: \"Update the default password\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_DEFAULT_PASSWORD='\n    line: 'CONFIG_DEFAULT_PASSWORD={{ default_password }}'\n\n- name: \"Update to NOT create cinder volumes\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_CINDER_VOLUMES_CREATE='\n    line: 'CONFIG_CINDER_VOLUMES_CREATE=n'\n\n- name: \"Allow for SSH migration of instances\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_NOVA_COMPUTE_MIGRATE_PROTOCOL='\n    line: 'CONFIG_NOVA_COMPUTE_MIGRATE_PROTOCOL=ssh'\n\n- name: \"Set Neutron L3 External Bridge to 'provider'\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_NEUTRON_L3_EXT_BRIDGE='\n    line: 'CONFIG_NEUTRON_L3_EXT_BRIDGE=provider'\n\n- name: \"Set Neutron ML2 Type Drivers\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_NEUTRON_ML2_TYPE_DRIVERS='\n    line: 'CONFIG_NEUTRON_ML2_TYPE_DRIVERS={{ neutron_ml2_type_drivers }}'\n\n- name: \"Set Neutron ML2 VLAN Ranges\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_NEUTRON_ML2_VLAN_RANGES='\n    line: 'CONFIG_NEUTRON_ML2_VLAN_RANGES={{ neutron_vlan_ranges }}'\n\n- name: \"Set OVS Bridge Interfaces\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_NEUTRON_OVS_BRIDGE_IFACES='\n    line: 'CONFIG_NEUTRON_OVS_BRIDGE_IFACES={{ neutron_ovs_bridge_ifaces }}'\n\n- name: \"Set OVS Tunnel Interface\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_NEUTRON_OVS_TUNNEL_IF='\n    line: 'CONFIG_NEUTRON_OVS_TUNNEL_IF={{ neutron_ovs_tunnel_if }}'\n\n- name: \"Set OVS Bridge Mappings\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_NEUTRON_OVS_BRIDGE_MAPPINGS='\n    line: 'CONFIG_NEUTRON_OVS_BRIDGE_MAPPINGS={{ neutron_ovs_bridge_mappings }}'\n\n- name: \"Set OVS Bridges Compute\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_NEUTRON_OVS_BRIDGES_COMPUTE='\n    line: 'CONFIG_NEUTRON_OVS_BRIDGES_COMPUTE={{ neutron_ovs_bridges_compute }}'\n\n- name: \"Set NTP servers\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_NTP_SERVERS='\n    line: 'CONFIG_NTP_SERVERS={{ ntp_servers }}'\n\n- name: \"Do not provision demo usage and testing\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_PROVISION_DEMO='\n    line: 'CONFIG_PROVISION_DEMO=n'\n\n- name: \"Enable SSL for Horizon (dashboard)\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_HORIZON_SSL='\n    line: 'CONFIG_HORIZON_SSL=y'\n\n- name: \"Disable self-signed certs\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_SSL_CACERT_SELFSIGN='\n    line: 'CONFIG_SSL_CACERT_SELFSIGN=n'\n\n- name: \"Set the cert directory\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_SSL_CERT_DIR='\n    line: 'CONFIG_SSL_CERT_DIR={{ ssl_cert_directory }}'\n\n- name: \"Set the SSL CA cert\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_SSL_CACERT_FILE='\n    line: 'CONFIG_SSL_CACERT_FILE={{ ssl_cacert_file }}'\n\n- name: \"Set the SSL CA Cert key file\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_SSL_CACERT_KEY_FILE='\n    line: 'CONFIG_SSL_CACERT_KEY_FILE={{ ssl_host_key_file }}'\n\n- name: \"Set the VNC SSL cert\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_VNC_SSL_CERT='\n    line: 'CONFIG_VNC_SSL_CERT={{ ssl_host_cert_file }}'\n\n- name: \"Set the VNC SSL key file\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_VNC_SSL_KEY='\n    line: 'CONFIG_VNC_SSL_KEY={{ ssl_host_key_file }}'\n\n- name: \"Set the Horizon CA cert\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_HORIZON_SSL_CACERT='\n    line: 'CONFIG_HORIZON_SSL_CACERT={{ ssl_cacert_file }}'\n\n- name: \"Set the Horizon SSL cert\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_HORIZON_SSL_CERT='\n    line: 'CONFIG_HORIZON_SSL_CERT={{ ssl_host_cert_file }}'\n\n- name: \"Set the Horizon SSL key file\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_HORIZON_SSL_KEY='\n    line: 'CONFIG_HORIZON_SSL_KEY={{ ssl_host_key_file }}'\n\n- name: \"Provision Cinder related settings\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_CINDER_{{ item.key|upper }}='\n    line: 'CONFIG_CINDER_{{ item.key|upper }}={{ item.value }}'\n  with_dict: \"{{ cinder }}\"\n\n- name: \"Configure keystone identity backend\"\n  lineinfile:\n    path: \"{{ answer_file }}\"\n    regexp: '^CONFIG_KEYSTONE_IDENTITY_BACKEND='\n    line: 'CONFIG_KEYSTONE_IDENTITY_BACKEND={{ keystone_identity_backend }}'\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "805f1c1737c68741643f0d5980e0de081fbdc074", "filename": "roles/config-clair/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Validate Quay Address Provided\n  fail:\n    msg: \"Quay Address Must Be Provided!\"\n  when: quay_enterprise_address is undefined or quay_enterprise_address|trim == \"\"\n\n- name: Set Clair Address\n  set_fact:\n    clair_address: \"http://{{ hostvars[inventory_hostname]['ansible_eth0']['ipv4']['address'] }}\"\n  when: clair_address is undefined or clair_address|trim == \"\"\n\n- name: Configure Configuration Directory\n  file:\n    state: directory\n    owner: root\n    group: root\n    mode: g+rw\n    path: \"{{ clair_config_dir }}\"\n  \n- name: Configure Trusted SSL\n  block:\n    - name: Check if Trusted SSL file exists\n      become: false\n      stat:\n        path: \"{{ clair_ssl_trust_src_file  }}\"\n      register: trusted_ssl_exists\n      changed_when: False\n      delegate_to: localhost\n    \n    - name: Fail if SSL source file does not exist\n      fail:\n        msg: \"Could not locate SSL trust certificate\"\n      when: trusted_ssl_exists.stat.exists == false\n  \n    - name: Copy SSL Certificate\n      copy:\n        src: \"{{ clair_ssl_trust_src_file }}\"\n        dest: \"{{ clair_ssl_trust_host_file }}\"\n        owner: root\n        group: root\n        mode: g+rw\n      notify: Restart Clair Service\n  when: clair_ssl_trust_configure|bool\n\n- name: Setup Clair configuration file\n  template:\n    src: config.yaml.j2\n    dest: \"{{ clair_config_dir }}/config.yaml\"\n    owner: root\n    group: root\n    mode: g+rw\n  notify: Restart Clair Service\n\n\n- name: Configure systemd environment files\n  template:\n    src: \"{{ clair_name }}.j2\"\n    dest: \"{{ systemd_environmentfile_dir}}/{{ clair_name }}\"\n  notify: \"Restart Clair Service\"\n\n- name: Configure systemd unit files\n  template:\n    src: \"{{ clair_service }}.j2\"\n    dest: \"{{ systemd_service_dir}}/{{ clair_service }}\"\n  notify: \"Restart Clair Service\"\n\n- name: Include firewall tasks\n  include_tasks: firewall.yml"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "ab1f565a6fda17de0a7be3a483fcc778f6cea355", "filename": "roles/moodle-1.9/moodle/templates/moodle-xs.service.in", "repository": "iiab/iiab", "decoded_content": "[Unit]\nDescription=Moodle Course Management OLPC edition\nAfter={{ apache_service }}.service\n\n[Service]\nType=oneshot\n{% if is_debuntu %}\nExecStart=/etc/init.d/moodle-xs-init start\n{% else $}\nExecStart=/usr/libexec/moodle-xs-init start\n{% endif %}\n\n[Install]\nWantedBy=multi-user.target\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "8c355b9a48642e5b576ba8117359e954232bbf99", "filename": "roles/moodle-1.9/moodle/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "---\n- name: Install moodle required packages\n  package: name={{ item }}\n           state=present\n  with_items:\n    - moodle-xs\n    - python-psycopg2\n  tags:\n    - download\n\n- name: Remove stock moodle conf\n  file: path='/etc/{{ apache_config_dir }}/moodle.conf'\n        state=absent\n\n- name: Configure moodle\n  template: backup=yes\n            src={{ item.src }}\n            dest={{ item.dest }}\n            owner=root\n            group=root\n            mode={{ item.mode }}\n  with_items:\n    - src: '020-iiab-moodle.conf.j2'\n      dest: '/etc/{{ apache_config_dir }}/020-iiab-moodle.conf'\n      mode: '0655'\n    - src: 'moodle-xs.service.j2'\n      dest: '/etc/systemd/system/moodle-xs.service'\n      mode: '0655'\n    - src: 'moodle-xs-init'\n      dest: '/usr/libexec/moodle-xs-init'\n      mode: '0755'\n\n- name: Stop postgresql\n  service: name=postgresql\n           state=stopped\n\n- name: Start postgresql-iiab\n  service: name=postgresql-iiab\n           state=started\n\n- name: Create db user\n  postgresql_user: name=apache\n                   password=apache\n                   role_attr_flags=NOSUPERUSER,NOCREATEROLE,NOCREATEDB\n                   state=present\n  become: yes\n  become_user: postgres\n\n- name: Create database\n  postgresql_db: name=moodle-xs\n                 encoding=utf8\n                 owner=apache\n                 template=template0\n                 state=present\n  sudo: yes\n  sudo_user: postgres\n\n- name: Execute moodle startup script\n  command: /usr/libexec/moodle-xs-init start\n\n- name: Restart postgresql-iiab\n  service: name=postgresql-iiab\n           state=restarted\n\n- name: Restart httpd\n  service: name={{ apache_service }}\n           state=restarted\n\n- name: Enable moodle service\n  service: name=moodle-xs\n           enabled=yes\n           state=started\n\n- name: fetch the administrative password for moodle\n  shell: cat /etc/moodle/adminpw\n  register: moodlepw\n\n- name: add moodle to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=moodle\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: Moodle\n    - option: description\n      value: '\"Access the Moodle learning management system.\"'\n    - option: path\n      value: /moodle\n    - option: enabled\n      value: \"{{ moodle_enabled }}\"\n    - option: adminpw\n      value: \"{{ moodlepw.stdout }}\"\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "46e5b079ecc8b18ee501acb3206a5d3c63a5a033", "filename": "tasks/create_repo_gitlfs_hosted_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_gitlfs_hosted\n    args: \"{{ _nexus_repos_gitlfs_defaults|combine(item) }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "c25dae0aaca64fd84bc382b0fba1f2b7fff20b7f", "filename": "playbooks/update-dns-records.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Update DNS records'\n  hosts: dns-records-manage-host\n  roles:\n  - role: dns/manage-dns-records\n  tags:\n  - update_dns_records\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "679f3176dda438a414ba3f60266c33552e200b26", "filename": "playbooks/update-dns-records.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Update DNS records'\n  hosts: localhost\n  roles:\n  - role: dns\n  tags:\n  - update_dns_records\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "faba929a430584fd1f952eba0947285dc89e3516", "filename": "playbooks/vm.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Create VM on infra virtual hosts'\n  hosts: infra_virt_hosts\n  roles:\n  - role: virt-install\n  tags:\n  - provision_infra_vms\n  \n- name: 'Check that the VM(s) are alive'\n  hosts: infra_vms\n  gather_facts: no\n  tasks:\n  - name: 'Wait for VM(s) to come alive'\n    local_action: wait_for\n    args: \n      host: \"{{ ansible_host }}\"\n      port: 22\n      delay: 30\n      timeout: 300\n  tags:\n  - vm_health_check\n\n- name: 'Subscribe the VMs to RHSM'\n  hosts: infra_vms\n  vars:\n    rhsm_username: \"{{ hostvars['localhost'].rhsm_username|default(omit) }}\"\n    rhsm_password: \"{{ hostvars['localhost'].rhsm_password|default(omit) }}\"\n  roles:\n  - role: rhsm\n  tags:\n  - configure_rhsm\n\n- name: 'Make sure the VM is running the latest'\n  hosts: infra_vms\n  roles:\n  - role: update-host\n  tags:\n  - update_host\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "b6176537738b34c2d36d7a67a0dd9d02a48b18cf", "filename": "roles/network/templates/named/dns-jail.conf", "repository": "iiab/iiab", "decoded_content": "ErrorDocument 404 \"/\"\n\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "a78978cf3132bde5f6aae5545524b18910178180", "filename": "tasks/plus/install-plus.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- import_tasks: setup-license.yml\n\n- import_tasks: setup-debian.yml\n  when: ansible_os_family == \"Debian\"\n\n- import_tasks: setup-redhat.yml\n  when: ansible_os_family == \"RedHat\"\n\n- import_tasks: setup-suse.yml\n  when: ansible_os_family == \"Suse\"\n\n- import_tasks: setup-freebsd.yml\n  when: ansible_os_family == \"FreeBSD\"\n\n- import_tasks: setup-alpine.yml\n  when: ansible_os_family == \"Alpine\"\n\n- name: \"(Install: All OSs) Install NGINX Plus\"\n  package:\n    name: \"nginx-plus{{ nginx_version | default('') }}\"\n    state: present\n  notify: \"(Handler: All OSs) Start NGINX\"\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "16985eb8f59f9faa8a941bda7eedf6b92148488e", "filename": "roles/ferm/handlers/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: restart ferm\n  service: name=ferm state=restarted\n  when: ferm_enabled"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "fb5bba9851872a0dc2758594e555a02bbd2a139b", "filename": "roles/rollback/tasks/prior-release.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Get list position of current symlinked release\n  shell: \"ls releases | grep -n $(basename $(readlink current)) | cut -f1 -d:\"\n  args:\n    chdir: \"{{ project_root }}\"\n  register: current_release_position\n\n- name: Fail if current release is the oldest available release\n  fail:\n    msg: \"Currently symlinked to earliest available release. Cannot rollback. You may manually specify a different release using --extra-vars='release=12345678901234'.\"\n  when: current_release_position.stdout_lines[0] == \"1\"\n\n- name: Collect list of releases\n  command: ls releases\n  args:\n    chdir: \"{{ project_root }}\"\n  register: releases\n\n- name: Create new_release_path variable\n  set_fact:\n    new_release_path: \"{{ project_root }}/releases/{{ releases.stdout_lines[(current_release_position.stdout_lines[0] | int - 2)] }}\"\n"}, {"commit_sha": "beb41b82405655aa385bb8297bf49ada1a4eb14c", "sha": "3898ce0279b607c6ebcbd117d3f7b68908ad6786", "filename": "tasks/Win32NT/system.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: 'Perform {{ java_binary_type }} install'\n  include_tasks: '{{ install_task }}'\n  with_first_found:\n    - 'install/{{ java_distribution }}_{{ java_binary_type }}.yml'\n    - 'install/{{ java_binary_type }}.yml'\n  loop_control:\n    loop_var: install_task\n\n- name: Find java_folder\n  win_find:\n    paths: '{{ java_path }}'\n    recurse: false\n    file_type: directory\n    patterns: '{{ java_folder }}'\n    use_regex: true\n  register: java_dir\n\n- name: Set actual java directory\n  set_fact:\n    java_act_path: \"{{ java_dir.files | map(attribute='path') | list | last }}\"\n\n- name: Set java environment variable\n  win_environment:\n    name: JAVA_HOME\n    state: present\n    value: '{{ java_act_path }}'\n    level: machine\n\n- name: Ensure that 'JAVA_HOME\\bin' present in 'Path' variable\n  win_path:\n    elements: '{{ java_act_path }}\\bin'\n    state: present\n    scope: machine\n"}, {"commit_sha": "c33f3410e002f9d8506f0725f56b7d7afa1c5f74", "sha": "edd38c59225d4f7b898d2b3568cb37aff618c357", "filename": "tasks/packages-RedHat.yml", "repository": "jloh/nagios-nrpe-server", "decoded_content": "---\n# Nagios NRPE Server for RedHat based OS's\n# The EPEL repo is required for this package\n- name: Install Nagios NRPE Server [RedHat]\n  yum: name=nrpe state=present\n\n# Nagios Plugins since they aren't installed as part of the package above\n- name: Install Nagios NRPE Plugins [RedHat]\n  yum: name=nagios-plugins-all state=present\n  notify: restart nagios-nrpe-server\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "f2b91216e1df27975704ec7c6a40758b7f690390", "filename": "roles/config-routes/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Notify about Network reload\"\n  debug:\n    msg: \"Networking Static Routes altered - Network reload needed.\" \n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "f69bccfcbb02ddebe59d8cb0629bea382a13d05a", "filename": "roles/nfs-server/tasks/configure_lvm.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Set VG name\"\n  set_fact:\n    nfs_vg_name: \"{{ nfs_vg_name | default(default_nfs_vg_name) }}\"\n\n- name: \"Set LV name\"\n  set_fact:\n    nfs_lv_name: \"{{ nfs_lv_name | default(default_nfs_lv_name) }}\"\n\n- name: \"Set NFS share basename\"\n  set_fact:\n    nfs_share_basedir: \"{{ nfs_share_basedir | default(default_nfs_share_basedir) }}\"\n\n- name: \"Setup and create PV & VG\"\n  lvg:\n    vg: \"{{ nfs_vg_name }}\"\n    pvs: \"{{ nfs_storage_device }}\"\n    force: yes\n\n- name: \"Setup LV\"\n  lvol: \n    vg: \"{{ nfs_vg_name }}\"\n    lv: \"{{ nfs_lv_name }}\"\n    force: yes\n    size: \"100%VG\"\n\n- name: \"Create file system on share\"\n  filesystem:\n    fstype: xfs\n    dev: \"/dev/mapper/{{ nfs_vg_name }}-{{ nfs_lv_name }}\"\n\n- name: \"Ensure the base dir for NFS shares exists\" \n  file:\n    path: \"{{ nfs_share_basedir }}\"\n    state: directory\n\n- name: \"Mount NFS base dir\"\n  mount:\n    src: \"/dev/mapper/{{ nfs_vg_name }}-{{ nfs_lv_name }}\" \n    path: \"{{ nfs_share_basedir }}\"\n    fstype: xfs \n    state: mounted\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "b810d7201ee61553d868578425ac38d24ffd45ad", "filename": "roles/fail2ban/README.md", "repository": "roots/trellis", "decoded_content": "## What is ansible-fail2ban?\n\nIt is an [ansible](http://www.ansible.com/home) role to install and configure fail2ban.\n\n### What problem does it solve and why is it useful?\n\nSecurity is important and fail2ban is an excellent tool to harden your server with minimal or even no configuration.\n\n## Role variables\n\nBelow is a list of default values along with a description of what they do.\n\n```\n# Which log level should it be output as?\n# 1 = ERROR, 2 = WARN, 3 = INFO, 4 = DEBUG\nfail2ban_loglevel: 3\n\n# Where should log outputs be sent to?\n# SYSLOG, STDERR, STDOUT, file\nfail2ban_logtarget: /var/log/fail2ban.log\n\n# Where should the socket be created?\nfail2ban_socket: /var/run/fail2ban/fail2ban.sock\n\n# Which IP address, CIDR mark or DNS host should be ignored?\nfail2ban_ignoreip: 127.0.0.1/8\n\n# How long in seconds should the ban last for?\nfail2ban_bantime: 600\n\n# How many times can they try before getting banned?\nfail2ban_maxretry: 6\n\n# How should the file changes be detected?\n# gamin, polling, auto\nfail2ban_backend: polling\n\n# Where should e-mail reports be sent to?\nfail2ban_destemail: root@localhost\n\n# How should the ban be applied?\n# iptables, iptables-new, iptables-multiport, shorewall, etc.\nfail2ban_banaction: iptables-multiport\n\n# What e-mail action should be used?\n# sendmail or mail\nfail2ban_mta: sendmail\n\n# What should the default protocol be?\nfail2ban_protocol: tcp\n\n# Which chain would the JUMPs be added into iptables-*?\nfail2ban_chain: INPUT\n\n# What should the default ban action be?\n# action_, action_mw, action_mwl\nfail2ban_action: action_\n\n# What services should fail2ban monitor?\n# You can define fail2ban_services as an empty string to not monitor anything.\n# You can define multiple services as a standard yaml list.\nfail2ban_services:\n    # The name of the service\n    # REQUIRED.\n  - name: ssh\n\n    # Is it enabled?\n    # OPTIONAL: Defaults to \"true\" (must be a string).\n    enabled: \"true\"\n\n    # What port does the service use?\n    # Separate multiple ports with a comma, no spaces.\n    # REQUIRED.\n    port: ssh\n\n    # What protocol does the service use?\n    # OPTIONAL: Defaults to the protocol listed above.\n    protocol: tcp\n\n    # What filter should it use?\n    # REQUIRED.\n    filter: sshd\n\n    # Which log path should it monitor?\n    # REQUIRED.\n    logpath: /var/log/auth.log\n\n    # How many times can they try before getting banned?\n    # OPTIONAL: Defaults to the maxretry listed above.\n    maxretry: 6\n\n    # What should the default ban action be?\n    # OPTIONAL: Defaults to the action listed above.\n    action: action_\n\n    # How should the ban be applied?\n    # OPTIONAL: Defaults to the banaction listed above.\n    banaction: iptables-multiport\n```\n\n## Example playbook\n\nLet's say you want to edit a few values, you can do this by opening `group_vars/all` and then add the following:\n\n```\nfail2ban_services:\n  - name: ssh\n    port: ssh\n    filter: sshd\n    logpath: /var/log/auth.log\n  - name: postfix\n    port: smtp,ssmtp\n    filter: postfix\n    logpath: /var/log/mail.log\n```\n\n## Attribution\n\nMany thanks to [nickjj](https://github.com/nickjj/) for creating the [original version](https://github.com/nickjj/ansible-fail2ban/) of this role.\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "d8c4472ca1b65cea039252e137ff3b4ab5d3a555", "filename": "playbooks/roles", "repository": "redhat-cop/infra-ansible", "decoded_content": "../roles"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "40825e9a0214068afaa70ee18933e3940feb913a", "filename": "roles/config-idm-server/tasks/configure_idm.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: 'Configure initial IdM setup'\n  command: > \n    ipa-server-install -U \n      --hostname=\"{{ idm_master_hostname | default(ansible_fqdn) }}\"\n      --domain=\"{{ idm_domain }}\"\n      --realm=\"{{ idm_realm }}\"\n      --ds-password=\"{{ idm_dm_password }}\"\n      --admin-password=\"{{ idm_admin_password }}\"\n  ignore_errors: true\n  when:\n  - idm_src is not defined \n\n- name: 'Add IdM client for replica'\n  command: > \n    ipa-client-install -U\n      --domain=\"{{ idm_domain }}\"\n      --server=\"{{ idm_src }}\"\n      --principal=\"{{ idm_principal }}\"\n      --password=\"{{ idm_admin_password }}\"\n      --force-join\n  when:\n  - idm_src is defined \n\n- name: 'Install and Configure IdM replica'\n  command: > \n    ipa-replica-install -U \n      --principal=\"{{ idm_principal }}\" \n      --admin-password=\"{{ idm_admin_password }}\"\n  ignore_errors: true\n  when:\n  - idm_src is defined \n\n- name: 'Ensure IdM is running at boot'\n  service:\n    name: ipa\n    enabled: yes\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a32e89ffceda299a55f478ed58d4a333ddb3a859", "filename": "roles/user-management/manage-atlassian-users/tasks/create_atlassian_groups.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Create Group\n  uri:\n    url: '{{ atlassian.url }}/rest/api/2/group'\n    method: POST\n    status_code: [201, 400]\n    user: '{{ atlassian.username }}'\n    password: '{{ atlassian.password }}'\n    force_basic_auth: yes\n    body_format: json\n    body: \"{'name': '{{ group }}' }\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "b5bdd80aad13dc5224d26409369d3d2e52d18849", "filename": "roles/schooltool/templates/schooltool.conf", "repository": "iiab/iiab", "decoded_content": "ProxyPass /schooltool http://127.0.0.1:7080/++vh++http:schoolserver.lan:80/schooltool/++/\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "b19fe708a5628615d1e401d786258db80a759188", "filename": "roles/user-management/manage-local-user-password/test/playbook.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Add a test user\"\n  hosts: all\n  tasks:\n  - user:\n      name: \"{{ user_name }}\"\n      comment: \"Test User\"\n    when:\n      - user_name != \"root\"\n\n# Test the role to update the password\n- name: \"Update {{ user_name }} password\"\n  hosts: all\n  roles:\n    - role: manage-local-user-password\n\n# Test the password access by running a remote command on machine\n#\n\n- name: \"Test password update\" \n  hosts: all\n  tasks:\n\n  - name: \"Test password for {{ user_name }} on {{ ansible_host }}\"\n    raw: \"sshpass -p \\\"{{ clear_text_password }}\\\" ssh {{ user_name }}@{{ansible_host }} /bin/true\"\n    delegate_to: localhost\n    become: False\n    register: result\n    changed_when: False\n    failed_when:\n      result.rc != 0\n"}, {"commit_sha": "f958689395b3fc98cacf0c605ed7b8b4b19718da", "sha": "01cde1a59ed5ffb8123cfd4aebfb909745f75ad7", "filename": "tasks/generate_secret_key.yml", "repository": "lae/ansible-role-netbox", "decoded_content": "---\n- name: Generate a SECRET_KEY for NetBox if unspecified\n  shell: \"{{ netbox_current_path }}/netbox/generate_secret_key.py | tr -d $'\\n' > {{ netbox_shared_path }}/generated_secret_key\"\n  args:\n    creates: \"{{ netbox_shared_path }}/generated_secret_key\"\n\n- name: Load saved SECRET_KEY\n  slurp:\n    src: \"{{ netbox_shared_path }}/generated_secret_key\"\n  register: __netbox_secret_key_file\n\n- name: Set netbox_config.SECRET_KEY to generated SECRET_KEY\n  set_fact:\n    netbox_config: \"{{ netbox_config | combine({'SECRET_KEY': __netbox_secret_key_file['content'] | b64decode}) }}\"\n"}, {"commit_sha": "79e29502fb4e0ff1c30c0b5396bfa1b48fb84a8e", "sha": "0657fc1dc99a0d51fcaab3031127ac775e0b8aaa", "filename": "tasks/core.yml", "repository": "Oefenweb/ansible-wordpress", "decoded_content": "# tasks file for wordpress, core\n---\n- name: check download\n  shell: \"ls {{ item.path }} | grep -q 'wp-'\"\n  register: check_download\n  failed_when: False\n  changed_when: False\n  with_items: wordpress_installs\n  tags: [configuration, wordpress, wordpress-core, wordpress-is-downloaded]\n\n- name: download\n  shell: \"wp-cli --allow-root --no-color --path='{{ item.item.path }}' core download\"\n  with_items: check_download.results\n  when: item.rc != 0\n  tags: [configuration, wordpress, wordpress-core, wordpress-downloaded]\n\n- name: configure\n  shell: \"wp-cli --allow-root --no-color --path='{{ item.path }}' core config --dbname='{{ item.dbname }}' --dbuser='{{ item.dbuser }}' --dbpass='{{ item.dbpass }}' --dbhost='{{ item.dbhost | default('localhost') }}'\"\n  args:\n    creates: \"{{ item.path }}/wp-config.php\"\n  with_items: wordpress_installs\n  tags: [configuration, wordpress, wordpress-core, wordpress-configure]\n\n- name: identify installation\n  shell: \"wp-cli --allow-root --no-color --path='{{ item.path }}' core is-installed\"\n  register: check_installation\n  failed_when: False\n  changed_when: False\n  with_items: wordpress_installs\n  tags: [configuration, wordpress, wordpress-core, wordpress-is-installed]\n\n- name: install\n  shell: \"wp-cli --allow-root --no-color --path='{{ item.item.path }}' core install --url='{{ item.item.url }}' --title='{{ item.item.title }}' --admin_name='{{ item.item.admin_name | default('admin') }}' --admin_email='{{ item.item.admin_email }}' --admin_password='{{ item.item.admin_password }}'\"\n  with_items: check_installation.results\n  when: item.rc != 0\n  tags: [configuration, wordpress, wordpress-core, wordpress-install]\n\n- name: check install\n  shell: \"wp-cli --allow-root --no-color --path='{{ item.path }}' core is-installed\"\n  changed_when: False\n  with_items: wordpress_installs\n  tags: [configuration, wordpress, wordpress-core, wordpress-install-check]\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "186328b4bd988acb79e3dff693036166d9bd0c31", "filename": "playbooks/inventory/all-in-one.ini", "repository": "rocknsm/rock", "decoded_content": "# file: all-in-one\n\n[rock]\nsimplerockbuild.simplerock.lan ansible_hostname=127.0.0.1 ansible_connection=local\n\n[sensors:children]\nrock\n\n[datapipe:children]\nrock\n"}, {"commit_sha": "481f7ad18dc225973e1d676d33e58c49cbbfe986", "sha": "f0c9dd5f4efd528e5cf4901baaa7d4fd898c841e", "filename": "meta/main.yml", "repository": "openwisp/ansible-openwisp2", "decoded_content": "---\n\ndependencies:\n  - src: https://github.com/nemesisdesign/Stouts.postfix\n    version: origin/develop\n    name: Stouts.postfix\n    postfix_smtp_sasl_auth_enable: \"{{ postfix_smtp_sasl_auth_enable_override | default(false) }}\"\n\ngalaxy_info:\n  author: Federico Capoano\n  company: Cineca\n  description: Official role to install and upgrade openwisp2 controller\n  license: BSD\n  min_ansible_version: 2.5\n  issue_tracker_url: https://github.com/openwisp/ansible-openwisp2/issues\n  platforms:\n  - name: Debian\n    versions:\n    - wheezy\n    - jessie\n    - stretch\n  - name: Ubuntu\n    versions:\n    - trusty\n    - xenial\n  - name: Fedora\n    versions:\n    - 25\n  - name: EL\n    versions:\n    - 7\n  galaxy_tags:\n    - system\n    - networking\n"}, {"commit_sha": "9662c15ce2e4260fac5cc2bfdf5aaaaf0a2191dd", "sha": "22c0add3c498db7b4ae54b4d408c48a1b95f73aa", "filename": "tasks/section_05_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 5.1.1 Ensure NIS is not installed (Scored)\n    apt: name=nis state=absent purge=yes\n    tags:\n    - section5\n    - section5.1\n    - section5.1.1\n\n  - name: 5.1.2 Ensure rsh, rlogin, rexec, talk, telnet, chargen, daytime, echo, discard, time is not enabled (stat inetd) (Scored)\n    stat: path=/etc/inetd.conf\n    register: inetd_path\n    tags:\n    - section5\n    - section5.1\n    - section5.1.2\n\n  - name: 5.1.2 Ensure rsh, rlogin, rexec, talk, telnet, chargen, daytime, echo, discard, time is not enabled (Scored)\n    lineinfile: >\n        dest=/etc/inetd.conf\n        regexp='^({{ item }}.*)'\n        line='#\\1'\n        state=present\n        backrefs=yes\n        backup=yes\n    with_items:\n        - shell\n        - login\n        - exec\n        - talk\n        - ntalk\n        - telnet\n        - chargen\n        - daytime\n        - echo\n        - discard\n        - time\n    when: inetd_path.stat.exists == True\n    tags:\n    - section5\n    - section5.1\n    - section5.1.2\n\n  - name: 5.1.3.1 Ensure rsh client is not installed (Scored)\n    apt: name=rsh-client state=absent purge=yes\n    tags:\n    - section5\n    - section5.1\n    - section5.1.3\n    - section5.1.3.1\n\n  - name: 5.1.3.2 Ensure rsh client is not installed (Scored)\n    apt: name=rsh-redone-client state=absent purge=yes\n    tags:\n    - section5\n    - section5.1\n    - section5.1.3\n    - section5.1.3.2\n\n  - name: 5.1.5 Ensure talk client is not installed (Scored)\n    apt: name=talk state=absent purge=yes\n    tags:\n    - section5\n    - section5.1\n    - section5.1.5\n\n  - name: 5.1.8 Ensure xinetd is not enabled (stat xinetd) (Scored)\n    stat: path=/etc/init/xinetd.conf\n    register: xinetd_path\n    tags:\n    - section5\n    - section5.1\n    - section5.1.8\n\n  - name: 5.1.8 Ensure xinetd is not enabled (Scored)\n    lineinfile: >\n        dest=/etc/init/xinetd.conf\n        regexp='start on runlevel'\n        state=present\n        line='#start on runlevel [2345]'\n    when: xinetd_path.stat.exists == True\n    tags:\n    - section5\n    - section5.1\n    - section5.1.8\n"}, {"commit_sha": "045ff4bb9f4720739632aac2951fbf2798a99c8c", "sha": "567614cd625074435415aaadf7319e4f57b20c47", "filename": "roles/vpn/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: Gather Facts\n  setup:\n\n- name: Enable IPv6\n  set_fact:\n    ipv6_support: true\n  when: ansible_default_ipv6.gateway is defined\n\n- name: Generate password for the CA key\n  shell: >\n    < /dev/urandom tr -dc _A-Z-a-z-0-9 | head -c${1:-12};echo;\n  register: CA_password\n\n- set_fact:\n    easyrsa_p12_export_password: \"{{ p12_export_password|default((ansible_date_time.iso8601_basic|sha1|to_uuid).split('-')[0]) }}\"\n    easyrsa_CA_password: \"{{ CA_password.stdout }}\"\n    IP_subject_alt_name: \"{{ IP_subject_alt_name }}\"\n\n- name: Change the algorithm to RSA\n  set_fact:\n    algo_params: \"rsa:2048\"\n  when: Win10_Enabled is defined and Win10_Enabled == \"Y\"\n\n- name: Install StrongSwan\n  apt: name=strongswan state=latest update_cache=yes install_recommends=yes\n\n- name: Enforcing ipsec with apparmor\n  shell: aa-enforce \"{{ item }}\"\n  when: apparmor_enabled is defined and apparmor_enabled == true\n  with_items:\n    - /usr/lib/ipsec/charon\n    - /usr/lib/ipsec/lookip\n    - /usr/lib/ipsec/stroke\n  notify:\n    - restart apparmor\n  tags: ['apparmor']\n\n- name: Enable services\n  service: name={{ item }} enabled=yes\n  with_items:\n    - apparmor\n    - strongswan\n    - netfilter-persistent\n\n- name: Configure iptables so IPSec traffic can traverse the tunnel\n  iptables: table=nat chain=POSTROUTING source=\"{{ vpn_network }}\" jump=MASQUERADE\n  when: (security_enabled is not defined) or\n        (security_enabled is defined and security_enabled != \"y\")\n  notify:\n    - save iptables\n\n- name: Configure ip6tables so IPSec traffic can traverse the tunnel\n  iptables: ip_version=ipv6 table=nat chain=POSTROUTING source=\"{{ vpn_network_ipv6 }}\" jump=MASQUERADE\n  when: ((security_enabled is not defined) or (security_enabled is defined and security_enabled != \"y\")) and\n        (ipv6_support is defined and ipv6_support == true)\n  notify:\n    - save iptables\n\n- name: Ensure that the strongswan group exist\n  group: name=strongswan state=present\n\n- name: Ensure that the strongswan user exist\n  user: name=strongswan group=strongswan state=present\n\n- name: Ensure that the strongswan service directory exist\n  file: path=/etc/systemd/system/strongswan.service.d/ state=directory mode=0755  owner=root group=root\n\n- name: Setup the cgroup limitations for the ipsec daemon\n  template: src=100-CustomLimitations.conf.j2 dest=/etc/systemd/system/strongswan.service.d/100-CustomLimitations.conf\n  notify:\n    - daemon-reload\n    - restart strongswan\n\n- meta: flush_handlers\n\n- name: Setup the strongswan.conf file from our template\n  template: src=strongswan.conf.j2 dest=/etc/strongswan.conf owner=root group=root mode=0644\n  notify:\n    - restart strongswan\n\n- name: Setup the ipsec.conf file from our template\n  template: src=ipsec.conf.j2 dest=/etc/ipsec.conf owner=root group=root mode=0644\n  notify:\n    - restart strongswan\n\n- name: Setup the ipsec.secrets file\n  template: src=ipsec.secrets.j2 dest=/etc/ipsec.secrets owner=strongswan group=root mode=0600\n  notify:\n    - restart strongswan\n\n- name: Get loaded plugins\n  shell: >\n    find /etc/strongswan.d/charon/ -type f -name '*.conf' -printf '%f\\n' | cut -f1 -d.\n  register: strongswan_plugins\n\n- name: Disable unneeded plugins\n  lineinfile: dest=\"/etc/strongswan.d/charon/{{ item }}.conf\" regexp='.*load.*' line='load = no' state=present\n  notify:\n    - restart strongswan\n  when: item not in strongswan_enabled_plugins\n  with_items: \"{{ strongswan_plugins.stdout_lines }}\"\n\n- name: Ensure that required plugins are enabled\n  lineinfile: dest=\"/etc/strongswan.d/charon/{{ item }}.conf\" regexp='.*load.*' line='load = yes' state=present\n  notify:\n    - restart strongswan\n  when: item in strongswan_enabled_plugins\n  with_items: \"{{ strongswan_plugins.stdout_lines }}\"\n\n- name: Ensure the pki directory is not exist\n  local_action:\n    module: file\n    dest: configs/{{ IP_subject_alt_name }}/pki\n    state: absent\n  become: no\n  when: easyrsa_reinit_existent == True\n\n- name: Ensure the pki directories are exist\n  local_action:\n    module: file\n    dest: \"configs/{{ IP_subject_alt_name }}/pki/{{ item }}\"\n    state: directory\n    recurse: yes\n  become: no\n  with_items:\n    - ecparams\n    - certs\n    - crl\n    - newcerts\n    - private\n    - reqs\n\n- name: Ensure the files are exist\n  local_action:\n    module: file\n    dest: \"configs/{{ IP_subject_alt_name }}/pki/{{ item }}\"\n    state: touch\n  become: no\n  with_items:\n    - \".rnd\"\n    - \"private/.rnd\"\n    - \"index.txt\"\n    - \"index.txt.attr\"\n    - \"serial\"\n\n- name: Generate the openssl server configs\n  local_action:\n    module: template\n    src: openssl.cnf.j2\n    dest: \"configs/{{ IP_subject_alt_name }}/pki/openssl.cnf\"\n  become: no\n\n- name: Build the CA pair\n  local_action: >\n    shell openssl ecparam -name prime256v1 -out ecparams/prime256v1.pem &&\n      openssl req -utf8 -new -newkey {{ algo_params | default('ec:ecparams/prime256v1.pem') }} -config openssl.cnf -keyout private/cakey.pem -out cacert.pem -x509 -days 3650 -batch -passout pass:\"{{ easyrsa_CA_password }}\" &&\n      touch {{ IP_subject_alt_name }}_ca_generated\n  become: no\n  args:\n    chdir: \"configs/{{ IP_subject_alt_name }}/pki/\"\n    creates: \"{{ IP_subject_alt_name }}_ca_generated\"\n  environment:\n    subjectAltName: \"DNS:{{ IP_subject_alt_name }},IP:{{ IP_subject_alt_name }}\"\n\n- name: Copy the CA certificate\n  local_action:\n    module: copy\n    src: \"configs/{{ IP_subject_alt_name }}/pki/cacert.pem\"\n    dest: \"configs/{{ IP_subject_alt_name }}/cacert.pem\"\n    mode: 0600\n  become: no\n\n- name: Generate the serial number\n  local_action: >\n    shell echo 01 > serial &&\n      touch serial_generated\n  become: no\n  args:\n    chdir: \"configs/{{ IP_subject_alt_name }}/pki/\"\n    creates: serial_generated\n\n- name: Build the server pair\n  local_action: >\n    shell openssl req -utf8 -new -newkey {{ algo_params | default('ec:ecparams/prime256v1.pem') }} -config openssl.cnf -keyout private/{{ IP_subject_alt_name }}.key -out reqs/{{ IP_subject_alt_name }}.req -nodes -passin pass:\"{{ easyrsa_CA_password }}\" -subj \"/CN={{ IP_subject_alt_name }}\" -batch &&\n    openssl ca -utf8 -in reqs/{{ IP_subject_alt_name }}.req -out certs/{{ IP_subject_alt_name }}.crt -config openssl.cnf -days 3650 -batch -passin pass:\"{{ easyrsa_CA_password }}\" -subj \"/CN={{ IP_subject_alt_name }}\" &&\n    touch certs/{{ IP_subject_alt_name }}_crt_generated\n  become: no\n  args:\n    chdir: \"configs/{{ IP_subject_alt_name }}/pki/\"\n    creates: certs/{{ IP_subject_alt_name }}_crt_generated\n  environment:\n    subjectAltName: \"DNS:{{ IP_subject_alt_name }},IP:{{ IP_subject_alt_name }}\"\n\n- name: Build the client's pair\n  local_action: >\n   shell openssl req -utf8 -new -newkey {{ algo_params | default('ec:ecparams/prime256v1.pem') }} -config openssl.cnf -keyout private/{{ item }}.key -out reqs/{{ item }}.req -nodes -passin pass:\"{{ easyrsa_CA_password }}\" -subj \"/CN={{ item }}\" -batch &&\n      openssl ca -utf8 -in reqs/{{ item }}.req -out certs/{{ item }}.crt -config openssl.cnf -days 3650 -batch -passin pass:\"{{ easyrsa_CA_password }}\" -subj \"/CN={{ item }}\" &&\n      touch certs/{{ item }}_crt_generated\n  become: no\n  args:\n    chdir: \"configs/{{ IP_subject_alt_name }}/pki/\"\n    creates: certs/{{ item }}_crt_generated\n  environment:\n    subjectAltName: \"DNS:{{ item }}\"\n  with_items: \"{{ users }}\"\n\n- name: Build the client's p12\n  local_action: >\n    shell openssl pkcs12 -in certs/{{ item }}.crt -inkey private/{{ item }}.key -export -name {{ item }} -out private/{{ item }}.p12 -certfile cacert.pem -passout pass:\"{{ easyrsa_p12_export_password }}\"\n  become: no\n  args:\n    chdir: \"configs/{{ IP_subject_alt_name }}/pki/\"\n  with_items: \"{{ users }}\"\n\n- name: Copy the p12 certificates\n  local_action:\n    module: copy\n    src: \"configs/{{ IP_subject_alt_name }}/pki/private/{{ item }}.p12\"\n    dest: \"configs/{{ IP_subject_alt_name }}/{{ item }}.p12\"\n    mode: 0600\n  become: no\n  with_items:\n    - \"{{ users }}\"\n\n- name: Copy the CA cert to the strongswan directory\n  copy: src='configs/{{ IP_subject_alt_name }}/pki/cacert.pem' dest=/etc/ipsec.d/cacerts/ca.crt owner=strongswan group=root mode=0600\n  notify:\n    - restart strongswan\n\n- name: Copy the server cert to the strongswan directory\n  copy: src='configs/{{ IP_subject_alt_name }}/pki/certs/{{ IP_subject_alt_name }}.crt' dest=/etc/ipsec.d/certs/{{ IP_subject_alt_name }}.crt owner=strongswan group=root mode=0600\n  notify:\n    - restart strongswan\n\n- name: Copy the server key to the strongswan directory\n  copy: src='configs/{{ IP_subject_alt_name }}/pki/private/{{ IP_subject_alt_name }}.key' dest=/etc/ipsec.d/private/{{ IP_subject_alt_name }}.key owner=strongswan group=root mode=0600\n  notify:\n    - restart strongswan\n\n- name: Register p12 PayloadContent\n  local_action: >\n    shell cat private/{{ item }}.p12 | base64\n  register:  PayloadContent\n  become: no\n  args:\n    chdir: \"configs/{{ IP_subject_alt_name }}/pki/\"\n  with_items: \"{{ users }}\"\n\n- name: Set facts for mobileconfigs\n  set_fact:\n    proxy_enabled: false\n    PayloadContentCA: \"{{ lookup('file' , 'configs/{{ IP_subject_alt_name }}/pki/cacert.pem')|b64encode }}\"\n\n- name: Build the mobileconfigs\n  local_action:\n    module: template\n    src: mobileconfig.j2\n    dest: configs/{{ IP_subject_alt_name }}/{{ item.0 }}.mobileconfig\n    mode: 0600\n  become: no\n  with_together:\n    - \"{{ users }}\"\n    - \"{{ PayloadContent.results }}\"\n  no_log: True\n\n- name: Build the strongswan app android config\n  local_action:\n    module: template\n    src: sswan.j2\n    dest: configs/{{ IP_subject_alt_name }}/{{ item.0 }}.sswan\n    mode: 0600\n  become: no\n  with_together:\n    - \"{{ users }}\"\n    - \"{{ PayloadContent.results }}\"\n  no_log: True\n\n- name: Build the client ipsec config file\n  local_action:\n    module: template\n    src: client_ipsec.conf.j2\n    dest: configs/{{ IP_subject_alt_name }}/ipsec_{{ item }}.conf\n    mode: 0600\n  become: no\n  with_items:\n    - \"{{ users }}\"\n\n- name: Build the client ipsec secret file\n  local_action:\n    module: template\n    src: client_ipsec.secrets.j2\n    dest: configs/{{ IP_subject_alt_name }}/ipsec_{{ item }}.secrets\n    mode: 0600\n  become: no\n  with_items:\n    - \"{{ users }}\"\n\n- name: Build the windows client powershell script\n  local_action:\n    module: template\n    src: client_windows.ps1.j2\n    dest: configs/{{ IP_subject_alt_name }}/windows_{{ item }}.ps1\n    mode: 0600\n  become: no\n  when: Win10_Enabled is defined and Win10_Enabled == \"Y\"\n  with_items: \"{{ users }}\"\n\n- name: Restrict permissions for the remote private directories\n  file: path=\"{{ item }}\" state=directory mode=0700  owner=strongswan group=root\n  with_items:\n    - /etc/ipsec.d/private\n\n- name: Restrict permissions for the local private directories\n  local_action:\n    module: file\n    path: \"{{ item }}\"\n    state: directory\n    mode: 0700\n  become: no\n  with_items:\n    - configs/{{ IP_subject_alt_name }}\n\n- include: iptables.yml\n  tags: iptables\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "cbf6672ba05d96cc088a81363d2f9b7a0d248750", "filename": "archive/roles/cicd-common/tasks/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- name: Setting CICD Common Facts\n  set_fact:\n    cicd_storage_disk_volume: \"{{ cicd_storage_disk_volume | default(default_cicd_storage_disk_volume) }}\"\n    cicd_openstack_security_groups: \"{{ cicd_openstack_security_groups | default(default_cicd_openstack_security_groups) }}\"\n    cicd_openstack_flavor_name: \"{{ cicd_openstack_flavor_name | default(default_cicd_openstack_flavor_name) }}\"\n    cicd_openstack_image_name: \"{{ cicd_openstack_image_name | default(default_cicd_openstack_image_name) }}\"\n    cicd_openstack_storage_size: \"{{ cicd_openstack_storage_size | default(default_cicd_openstack_storage_size) }}\"\n    cicd_instance_count: \"{{ cicd_instance_count | default(default_cicd_instance_count) }}\"\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "3d94eaedf779dbb399d5628fbc994e736433b72f", "filename": "tasks/create_repo_rubygems_group_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_rubygems_group\n    args: \"{{ _nexus_repos_rubygems_defaults|combine(item) }}\""}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "c8e609069b7df676fce73442c0064ef5d954e81a", "filename": "tasks/httpd_reverse_proxy_config.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n\n- name: Copy {{ httpd_package_name }} vhost\n  template:\n    src: \"nexus-vhost.conf\"\n    dest: \"{{ httpd_config_dir }}\"\n  notify:\n    - httpd-service-reload\n    - wait-for-httpd\n\n- name: Copy SSL certificate file\n  copy:\n    src: \"{{ httpd_ssl_certificate_file }}\"\n    dest: \"{{ certificate_file_dest }}\"\n    mode: 0600\n  when: httpd_copy_ssl_files\n  notify:\n    - httpd-service-reload\n    - wait-for-httpd\n\n- name: Copy SSL certificate key file\n  copy:\n    src: \"{{ httpd_ssl_certificate_key_file }}\"\n    dest: \"{{ certificate_key_dest }}\"\n    mode: 0600\n  when: httpd_copy_ssl_files\n  notify:\n    - httpd-service-reload\n    - wait-for-httpd\n\n- name: Setsebool httpd_can_network_connect\n  seboolean:\n    name: httpd_can_network_connect\n    persistent: yes\n    state: yes\n  when: ansible_selinux.status is defined and ansible_selinux.status == \"enabled\"\n\n- meta: flush_handlers\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "9bfa345ddf55829c174d613c07cbc18f7cc4f32c", "filename": "roles/config-postgresql/tasks/install_containerized.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Generate Random DB Username\n  set_fact:\n    postgresql_username: \"{{ lookup('password', '/dev/null length=5 chars=ascii_letters') | lower }}\"\n  when: postgresql_username is undefined and postgresql_username|trim == \"\"\n\n- name: Generate Random DB Password\n  set_fact:\n    postgresql_password: \"{{ lookup('password', '/dev/null length=10 chars=ascii_letters,digits,hexdigits') }}\"\n  when: postgresql_password is undefined and postgresql_password|trim == \"\"\n\n- name: Generate Random DB Admin Username\n  set_fact:\n    postgresql_admin_user: \"{{ lookup('password', '/dev/null length=5 chars=ascii_letters') | lower }}\"\n  when: postgresql_admin_user is undefined and postgresql_admin_user|trim == \"\"\n\n- name: Generate Random Admin DB Password\n  set_fact:\n    postgresql_admin_password: \"{{ lookup('password', '/dev/null length=10 chars=ascii_letters,digits,hexdigits') }}\"\n  when: postgresql_admin_password is undefined and postgresql_admin_password|trim == \"\"\n\n- name: Configure Storage Directory\n  file:\n    state: directory\n    owner: root\n    group: root\n    mode: g+rw\n    path: \"{{ postgresql_storage_dir }}\"\n  notify: \"Restart PostgreSQL Service\"\n\n- name: Configure systemd environment files\n  template:\n    src: \"postgresql.j2\"\n    dest: \"{{ systemd_environmentfile_dir}}/{{ postgresql_name }}\"\n  notify: \"Restart PostgreSQL Service\"\n\n- name: Configure systemd unit files\n  template:\n    src: \"postgresql.service.j2\"\n    dest: \"{{ systemd_service_dir}}/{{ postgresql_service }}\"\n  notify: \"Restart PostgreSQL Service\"\n\n- name: Include firewall tasks\n  include_tasks: firewall.yml\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "e5e888fe7fdcb48946d8041bc37743cffa5a4766", "filename": "roles/user-management/manage-local-user-ssh-authkeys/test/playbook.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Add a test user\"\n  hosts: all\n  tasks:\n  - user:\n      name: \"{{ user_name }}\"\n      comment: \"Test User\"\n    when:\n      - user_name != \"root\"\n\n# Test the role to update the access keys\n- name: \"Update {{ user_name }} access\"\n  hosts: all\n  roles:\n    - role: manage-local-user-ssh-authkeys\n\n# Test the SSH Key access by running a remote command on machine\n#\n\n- name: \"Testing authorized ssh keyfile\" \n  hosts: all\n  tasks:\n  - name: \"Test authorized key for {{ user_name }} on {{ ansible_host }}\"\n    raw: \"ssh -v -i id_rsa_user1 {{ user_name }}@{{ ansible_host }} /bin/true\"\n    delegate_to: localhost\n    register: result\n    become: False\n    changed_when: False\n    failed_when:\n      result.rc != 0\n\n"}, {"commit_sha": "481f7ad18dc225973e1d676d33e58c49cbbfe986", "sha": "dc1feef91d06894cca0d74e869320556ef8460bd", "filename": "tasks/apt.yml", "repository": "openwisp/ansible-openwisp2", "decoded_content": "- name: Update APT package cache\n  apt: update_cache=yes\n  changed_when: false\n\n- name: Install system packages\n  apt:\n    name:\n      - sudo\n      - software-properties-common\n      - build-essential\n      - supervisor\n      - nginx\n      - openssl\n      - libssl-dev\n      - libffi-dev\n      - python-dev\n      - redis-server\n    state: latest\n  notify:\n    - reload systemd\n    - start redis-server\n\n# On the newer versions of redis, by default redis\n# binds to localhost on ipv6 address which wouldn't\n# let the service start if the server doesn't have\n# ipv6 enabled. Hence, we set redis to listen on ipv4\n- name: set redis to listen on ipv4\n  notify: start redis-server\n  lineinfile:\n    path: /etc/redis/redis.conf\n    regexp: '^bind 127\\.0\\.0\\.1 ::1'\n    line: 'bind 127.0.0.1'\n    backrefs: yes\n\n- name: Install spatialite\n  when: openwisp2_database.engine == \"django.contrib.gis.db.backends.spatialite\"\n  apt:\n    name:\n      - sqlite3\n      - gdal-bin\n      - libproj-dev\n      - libgeos-dev\n      - libspatialite-dev\n    state: latest\n  notify: reload systemd\n\n- name: Install mod-spatialite (may fail on older linux distros)\n  when: openwisp2_database.engine == \"django.contrib.gis.db.backends.spatialite\"\n  ignore_errors: yes\n  apt: name=libsqlite3-mod-spatialite state=latest\n\n# fixes issue described in https://docs.ansible.com/ansible/become.html#becoming-an-unprivileged-user\n- name: Install acl if acting as non-root user\n  apt: name=acl state=latest\n  when: ansible_user is not defined or ansible_user != 'root'\n\n- name: ensure supervisor is started\n  service: name=supervisor state=started\n\n- name: Install python2 packages\n  when: openwisp2_python in [\"python2.7\", \"python2\"]\n  apt:\n    name:\n      - python-pip\n      - python-dev\n      - python-virtualenv\n    state: latest\n\n- name: Install python3 packages\n  when: openwisp2_python == \"python3\"\n  apt:\n    name:\n      - python3\n      - python3-pip\n      - python3-dev\n      - python-virtualenv\n    state: latest\n\n- name: Install python3-pyparsing\n  when: ansible_distribution == \"Debian\" and ansible_distribution_version == \"9.0\"\n  apt:\n    name:\n      - python3-pyparsing\n    state: latest\n\n- name: Install python wheel (optional, allowed to fail)\n  ignore_errors: yes\n  apt:\n    name:\n      - python-wheel\n      - python3-wheel\n    state: latest\n\n- name: Install python3-virtualenv\n  ignore_errors: yes\n  when: ansible_distribution != 'Ubuntu'\n  apt:\n    name:\n      - python3-virtualenv\n    state: latest\n\n- name: Install ntp\n  when: openwisp2_install_ntp\n  apt:\n    name: ntp\n    state: latest\n"}, {"commit_sha": "2a05a5032ce341d6a1d918453164c59ea2922f58", "sha": "264d336e9de967f130595f7cbff86b02e653a1a0", "filename": "roles/dns/tasks/main.yml", "repository": "CSCfi/fgci-ansible", "decoded_content": "---\n- name: Deploy a clean /etc/resolv.conf\n  template: src=resolv.conf.j2 dest=/etc/resolv.conf\n  tags:\n    - dns\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "f27e3fde719698d02ffcea03ec7ff4599f12bc9e", "filename": "tasks/setup-repository-Fedora.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Ensure python and deps for Ansible modules\n  become: true\n  raw: dnf install -y python2 python2-dnf libselinux-python\n  changed_when: false\n  when:\n    - docker_network_access\n\n- name: Include tasks from setup of repositories for CentOS\n  include_tasks: setup-repository-CentOS.yml"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "693400c542cff20815c3ffcb9e561eb00abf7d03", "filename": "roles/network/tasks/hosts.yml", "repository": "iiab/iiab", "decoded_content": "#TODO: Use vars instead of hardcoded values\n- name: Configure short hostname in /etc/hosts\n  lineinfile: dest=/etc/hosts\n              regexp='^127\\.0\\.0\\.1'\n              line='127.0.0.1            localhost.localdomain   localhost  box {{ iiab_hostname }}'\n              owner=root\n              group=root\n              mode=0644\n\n- name: Remove fqdn in /etc/hosts without LAN\n  lineinfile: dest=/etc/hosts\n              regexp='^172\\.18\\.96\\.1'\n              state=absent\n  when: iiab_lan_iface == \"none\" and not installing\n\n- name: Configure fqdn in /etc/hosts with LAN\n  lineinfile: dest=/etc/hosts\n              regexp='^172\\.18\\.96\\.1'\n              line='172.18.96.1            {{ iiab_hostname }}.{{ iiab_domain }} {{ iiab_hostname }} box'\n              state=present\n  when: iiab_lan_iface != \"none\" and not installing\n\n- name: Configure fqdn in /etc/hosts appliance mode\n  lineinfile: dest=/etc/hosts\n              regexp='^127\\.0\\.0\\.1'\n              line='127.0.0.1            localhost.localdomain localhost {{ iiab_hostname }}.{{ iiab_domain }} {{ iiab_hostname }} box '\n              owner=root\n              group=root\n              mode=0644\n  when: iiab_lan_iface == \"none\" and not installing\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "eb12c1ef8bed5e7f0785f266b357ea424f5f114a", "filename": "roles/user-management/manage-user-passwd/test/changepasswd.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n# These tests covers testing password change of an individual user\n\n- name: \"TEST 1: Change user's IdM Passwd when both set, provded changed\"\n  hosts: ipa\n\n  vars_files:\n    - vars/passwdfile1.json\n\n  vars:\n    ipa_admin_user: admin\n    ipa_admin_password: test123\n    ipa_host: idm.example.com \n  \n  roles:\n    - manage-user-passwd\n\n- name: \"TEST 2: Change user's IdM Passwd is not set and generate set, random, changed\"\n  hosts: ipa\n\n  vars_files:\n    - vars/passwdfile2.json\n\n  vars:\n    ipa_admin_user: admin\n    ipa_admin_password: test123\n    ipa_host: idm.example.com \n\n  roles:\n    - manage-user-passwd\n\n- name: \"TEST 3: Change user's IdM password: when neither is set: skipped\"\n  hosts: ipa\n\n  vars_files:\n    - vars/passwdfile3.json\n\n  vars:\n    ipa_admin_user: admin\n    ipa_admin_password: test123\n    ipa_host: idm.example.com \n\n  roles:\n    - manage-user-passwd\n\n- name: \"TEST 4:Change user's IdM password: missing generate field, no passwd: skipped \"\n  hosts: ipa\n\n  vars_files:\n    - vars/passwdfile4.json\n\n  vars:\n    ipa_admin_user: admin\n    ipa_admin_password: test123\n    ipa_host: idm.example.com \n\n  roles:\n    - manage-user-passwd\n\n- name: \"TEST 5:Change user's IdM password: missing generate=False, valid passwd: changed\"\n  hosts: ipa\n\n  vars_files:\n    - vars/passwdfile5.json\n\n  vars:\n    ipa_admin_user: admin\n    ipa_admin_password: test123\n    ipa_host: idm.example.com \n\n  roles:\n    - manage-user-passwd\n\n- name: \"TEST 6: Change user's IdM password: with list\"\n  hosts: ipa\n\n  vars_files:\n    - vars/passwordall.json\n\n  vars:\n    ipa_admin_user: admin\n    ipa_admin_password: test123\n    ipa_host: idm.example.com \n\n  roles:\n    - manage-user-passwd\n\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "d801d5ab81109abe0807da8f19e936d83eaf64b8", "filename": "tasks/section_04.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - include: section_04_level1.yml\n    tags:\n      - section04\n      - level1\n\n  - include: section_04_level2.yml\n    tags:\n      - section04\n      - level2\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "1b39744e994ae9bff0ddd700f27ed3a862dd295e", "filename": "playbooks/templates/filebeat.yml.j2", "repository": "rocknsm/rock", "decoded_content": "#=========================== Filebeat prospectors =============================\n\nfilebeat.prospectors:\n- input_type: log\n  paths:\n    - {{ rock_data_dir }}/suricata/eve.json\n  json.keys_under_root: true\n  fields:\n    kafka_topic: suricata-raw\n  fields_under_root: true\n- input_type: log\n  paths:\n    - {{ rock_data_dir }}/fsf/rockout.log\n  json.keys_under_root: true\n  fields:\n    kafka_topic: fsf-raw\n  fields_under_root: true\nprocessors:\n - decode_json_fields:\n     fields: [\"message\",\"Scan Time\", \"Filename\", \"objects\", \"Source\", \"meta\", \"Alert\" ,\"Summary\"]\n     process_array: true\n     max_depth: 10\n\n#================================ General =====================================\n\n# The name of the shipper that publishes the network data. It can be used to group\n# all the transactions sent by a single shipper in the web interface.\n#name:\n\n# The tags of the shipper are included in their own field with each\n# transaction published.\n#tags: [\"service-X\", \"web-tier\"]\n\n# Optional fields that you can specify to add additional information to the\n# output.\n#fields:\n#  env: staging\n\n#================================ Outputs =====================================\n\n# Configure what outputs to use when sending the data collected by the beat.\n# Multiple outputs may be used.\n\noutput.kafka:\n  hosts: [\"localhost:9092\"]\n\n  topic: '%{[kafka_topic]}'\n  required_acks: 1\n  compression: gzip\n  max_message_bytes: 1000000\n\n#================================ Logging =====================================\n\n# Sets log level. The default log level is info.\n# Available log levels are: critical, error, warning, info, debug\n#logging.level: debug\n\n# At debug level, you can selectively enable logging only for some components.\n# To enable all selectors use [\"*\"]. Examples of other selectors are \"beat\",\n# \"publish\", \"service\".\n#logging.selectors: [\"*\"]\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "fc7d9e4a9afe4c900a7f786ac20b396266abcf2b", "filename": "roles/config-hostname/tasks/set-hostname.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Setting Default Hostname if new one is not supplied\n  set_fact:\n    hostname: \"{{ hostname | default(inventory_hostname_short) }}\"\n\n- name: Setting Hostname Related Facts\n  set_fact:\n    hostname: \"{{ hostname }}.{{ dns_domain }}\"\n  when:\n  - dns_domain is defined\n  - dns_domain|trim != ''\n\n- name: Setting hostname (FQDN)\n  hostname:\n    name: \"{{ hostname }}\"\n\n- name: Check for cloud.cfg\n  stat:\n    path: \"/etc/cloud/cloud.cfg\"\n  register: cloud_cfg\n\n- name: Prevent cloud-init updates of hostname/fqdn (if applicable)\n  lineinfile:\n    dest: /etc/cloud/cloud.cfg\n    state: present\n    regexp: \"{{ item.regexp }}\"\n    line: \"{{ item.line }}\"\n  with_items:\n  - { regexp: '^ - set_hostname', line: '# - set_hostname' }\n  - { regexp: '^ - update_hostname', line: '# - update_hostname' }\n  when:\n  - cloud_cfg.stat.exists\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "b701c84e1710ef007fe0e647c10ed75e7c2248ae", "filename": "roles/dnsmasq/defaults/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# defaults file for dnsmasq\ndnsmasq_config_folder: \"/etc/dnsmasq.d\"\ndnsmasq_resolvconf_file: \"{{ dnsmasq_config_folder }}/resolv.conf~\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "f1a7f6297c97bf40927d83b66c65ee23ab388611", "filename": "roles/2-common/templates/udev-reload.service", "repository": "iiab/iiab", "decoded_content": "[Unit]\nDescription=Make sure udev is operating on RW disk\nAfter=network-online.target\n\n[Service]\nExecStart=/bin/systemctl restart systemd-udevd.service\n\n[Install]\nWantedBy=multi-user.target\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "d47394d5e2062fda94b44348f2c0e835ab8a222e", "filename": "playbooks/templates/stenographer-config.j2", "repository": "rocknsm/rock", "decoded_content": "{\n  \"Threads\": [\n    {\n      \"PacketsDirectory\": \"/data/stenographer/{{ item.1 }}/thread0/packets\"\n    , \"IndexDirectory\": \"/data/stenographer/{{ item.1 }}/thread0/index\"\n    }\n  ]\n  , \"StenotypePath\": \"/usr/bin/stenotype\"\n  , \"Interface\": \"{{ item.1 }}\"\n  , \"Port\": {{ 1234 + item.0 }}\n  , \"Host\": \"127.0.0.1\"\n  , \"Flags\": [\"-v\"]\n  , \"CertPath\": \"/etc/stenographer/certs\"\n}\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "032d50b8d2b4684727f928677cbed04360be9489", "filename": "roles/osp/packstack-post/tasks/nova.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Ensure 'dhcp_domain' is unset for nova\"\n  lineinfile:\n    path: \"/etc/nova/nova.conf\"\n    regexp: '^dhcp_domain='\n    line: 'dhcp_domain='\n  notify: 'restart openstack-nova-compute'\n\n- name: \"Set a 'disk_alocation_ratio' to allow for overcommit on the local disk\"\n  lineinfile:\n    path: \"/etc/nova/nova.conf\"\n    regexp: '^disk_allocation_ratio='\n    line: 'disk_allocation_ratio=2.0'\n  notify: 'restart openstack-nova-compute'\n\n- name: \"Workaround for OSP >12 to allow for Nova Migrations\"\n  replace:\n    path: \"/var/lib/nova/.ssh/config\"\n    regexp: '(.*)'\n    replace: '# \\1'\n\n- name: \"Ensure Nova Migration doesn't get blocked by host key checking\"\n  lineinfile:\n    path: \"/var/lib/nova/.ssh/config\"\n    regexp: '^StrictHostKeyChecking '\n    line: 'StrictHostKeyChecking no'\n    create: yes\n    owner: nova\n    mode: 0644\n\n- name: \"Copy SELinux .te file to remote host\"\n  copy:\n    src: \"nova-ssh.te\"\n    dest: \"/tmp/nova-ssh.te\"\n\n- name: \"Build SELinux module (.mod) to allow Nova Migration\"\n  command: checkmodule -M -m /tmp/nova-ssh.te -o /tmp/nova-ssh.mod\n\n- name: \"Build SELinux module (.pp) to allow Nova Migration\"\n  command: semodule_package -m /tmp/nova-ssh.mod -o /tmp/nova-ssh.pp\n\n- name: \"Enable the 'nova' user's shell\"\n  user:\n    name: nova\n    shell: /bin/bash\n\n- name: \"Load SELinux module to allow Nova Migration\"\n  command: semodule -i /tmp/nova-ssh.pp\n  notify:\n  - 'restart openstack-nova-compute'\n  - 'restart libvirtd'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "69d3156843e7052afecabf7398ca6992261825f2", "filename": "roles/osp/packstack-post/tasks/mariadb.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Ensure target directory exists\"\n  file:\n    path: \"/etc/systemd/system/mariadb.service.d\"\n    state: directory\n\n- name: \"Update mariadb/MySQL to handle additional open files\"\n  copy:\n    src: \"mariadb-limits.conf\"\n    dest: \"/etc/systemd/system/mariadb.service.d/limits.conf\"\n  notify:\n  - 'restart mariadb'\n\n- name: \"Perform daemon-reload to ensure the changes are picked up\"\n  command: 'systemctl daemon-reload'\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "a91d851372ffca8a92ee7f12834e511a14049025", "filename": "tasks/Win32NT/fetch/security-fetch/security-winfetch-web.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Download security policy artifact from web\n  win_get_url:\n    url: '{{ java_unlimited_policy_url }}'\n    dest: >-\n      {{ java_download_path }}\\{{ (java_unlimited_policy_url\n        | urlsplit('path')).split('/')[-1] }}\n    force: false\n  register: policy_file_downloaded\n  retries: 3\n  delay: 2\n  until: policy_file_downloaded is succeeded\n\n- name: Downloaded security policy artifact\n  set_fact:\n    security_policy_java_artifact: '{{ policy_file_downloaded.dest }}'\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "8a47c4673c67eb244be2e478d1bd72e6ddd0c316", "filename": "roles/ovirt-collect-logs/tasks/hypervisor.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\n\n- name: Prepare directory structure\n  file:\n    src: \"{{ item }}\"\n    dest: \"{{ ovirt_collect_logs_tmp_dir }}/{{ item }}\"\n    state: directory\n  with_items:\n    - \"etc\"\n\n- name: Register coredump path\n  shell: \"cat /proc/sys/kernel/core_pattern | xargs dirname | head -n 1\"\n  register: coredumpdir\n\n- name: Link vdsm and libvirt logs\n  file:\n    src: \"{{ item.src }}\"\n    dest: \"{{ ovirt_collect_logs_tmp_dir }}/{{ item.dest }}\"\n    state: link\n  with_items:\n    -\n      src: \"/var/log/vdsm\"\n      dest: \"vdsm-logs\"\n    -\n      src: \"/var/log/libvirt\"\n      dest: \"libvirt-logs\"\n    -\n      src: \"/etc/ovirt-vmconsole\"\n      dest: \"etc/ovirt-vmconsole\"\n    -\n      src: \"/etc/vdsm\"\n      dest: \"etc/vdsm\"\n    -\n      src: \"/etc/libvirt\"\n      dest: \"etc/libvirt\"\n    -\n      src: \"/var/log/ovirt-hosted-engine-setup\"\n      dest: \"hosted-engine-setup-logs\"\n    -\n      src: \"/var/log/ovirt-hosted-engine-ha\"\n      dest: \"hosted-engine-logs\"\n    -\n      src: \"{{ coredumpdir }}\"\n      dest: \"coredumps\"\n  ignore_errors: true\n\n- name: Dump mount\n  shell: \"mount &> {{ ovirt_collect_logs_tmp_dir }}/mount.txt\"\n  ignore_errors: true\n\n- name: Dump multipath\n  shell: \"multipath -ll &> {{ ovirt_collect_logs_tmp_dir }}/multipath.txt\"\n  ignore_errors: true\n\n- name: Dump lvm\n  shell: \"(vgs; pvs; lvs) &> {{ ovirt_collect_logs_tmp_dir }}/lvm.txt\"\n  ignore_errors: true\n"}, {"commit_sha": "beb41b82405655aa385bb8297bf49ada1a4eb14c", "sha": "ee4d6746b44114fc557a675a2eeb7182f1d8a34b", "filename": "meta/main.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\ngalaxy_info:\n  role_name: \"java\"\n  author: \"Lean Delivery team <team@lean-delivery.com>\"\n  description: \"Lean Delivery Java install\"\n  company: \"Epam Systems\"\n  license: \"Apache\"\n  min_ansible_version: \"2.7\"\n  issue_tracker_url: \"https://github.com/lean-delivery/ansible-role-java/issues\"\n  platforms:\n    - name: \"Ubuntu\"\n      versions:\n        - \"trusty\"\n        - \"xenial\"\n        - \"bionic\"\n    - name: \"Debian\"\n      versions:\n        - \"stretch\"\n    - name: \"EL\"\n      versions:\n        - \"6\"\n        - \"7\"\n    - name: \"Amazon\"\n      versions:\n        - \"2017.12\"\n        - \"Candidate\"\n    - name: \"Windows\"\n      versions:\n        - \"all\"\n\n  galaxy_tags:\n    - \"development\"\n    - \"system\"\n    - \"packaging\"\n    - \"java\"\n    - \"oracle\"\n    - \"jdk\"\n    - \"openjdk\"\n    - \"sapjvm\"\n    - \"windows\"\n\ndependencies: []\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "88c621245354fecf81a0790b4625b26ef4c4c5f9", "filename": "playbooks/templates/es_cleanup.sh.j2", "repository": "rocknsm/rock", "decoded_content": "#!/bin/bash\n\nindexes=(bro suricata)\nes_uri=\"http://localhost:9200\"\n\n#Clean out old marvel indexes, only keeping the current index.\nfor i in $(curl -sSL ${es_uri}/_stats/indexes\\?pretty\\=1 | grep marvel | grep -Ev 'es-data|kibana' | grep -vF \"$(date +%m.%d)\" | awk '{print $1}' | sed 's/\\\"//g' 2>/dev/null); do\n  curl -sSL -XDELETE ${es_uri}/$i > /dev/null 2>&1\ndone\n\n#Cleanup TopBeats indexes from 5 days ago.\n#curl -sSL -XDELETE \"http://127.0.0.1:9200/topbeat-$(date -d '5 days ago' +%Y.%m.%d)\" 2>&1\n\nfor item in ${indexes[*]}; do\n  #Delete Logstash indexes from 60 days ago.\n  curl -sSL -XDELETE \"${es_uri}/${item}-$(date -d '{{ elastic_delete_interval }} days ago' +%Y.%m.%d)\" 2>&1\n  #Close Logstash indexes from 15 days ago.\n  curl -sSL -XPOST \"${es_uri}/${item}-$(date -d '{{ elastic_close_interval }} days ago' +%Y.%m.%d)/_close\" 2>&1\ndone\n\n#Make sure all indexes have replicas off\ncurl -sSL -XPUT 'localhost:9200/_all/_settings' -d '\n{\n    \"index\" : {\n        \"number_of_replicas\" : 0\n    }\n}' > /dev/null 2>&1\n"}, {"commit_sha": "af1b4f6c5adde980e027a8b8f38684b11ffbfa19", "sha": "a8c329a9ed3dfe4ea9033c126d8225553220b090", "filename": "tasks/asserts.yml", "repository": "cytopia/ansible-role-cloudformation", "decoded_content": "---\n\n- name: assert that cloudformation array has required elements\n  assert:\n    that:\n      - item.stack_name is defined\n      - item.template is defined\n  with_items:\n    - \"{{ cloudformation_stacks }}\"\n\n- name: assert custom set required keys in cloudformation array\n  assert:\n    that:\n      - \"item[0][item[1]] is defined\"\n    msg: \"Stack '{{ item[0].stack_name }}' has no dict key {{ item[1] }}\"\n  with_nested:\n    - \"{{ cloudformation_stacks }}\"\n    - \"{{ cloudformation_required }}\"\n\n- name: assert that cloudformation_diff output is set correctly\n  assert:\n    that:\n      - \"cloudformation_diff_output == 'yaml' or cloudformation_diff_output == 'json'\"\n    msg: \"cloudformation_diff_output must either be 'yaml' or 'json', but not: '{{ cloudformation_diff_output }}'\"\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "dcee602670e4f635ba08fc68a4e761a6ae95d6e4", "filename": "roles/ovirt-engine-setup/tasks/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\n# health page\n- name: check if ovirt-engine running (health page)\n  uri:\n    url: \"http://{{ ansible_fqdn }}/ovirt-engine/services/health\"\n    status_code: 200\n  register: ovirt_engine_status\n  retries: 2\n  delay: 5\n  until: ovirt_engine_status|success\n  ignore_errors: True\n\n# copy default answer file\n- name: copy default answerfile\n  template:\n    src: answerfile_{{ ovirt_engine_version }}_basic.txt.j2\n    dest: /tmp/answerfile.txt\n    mode: 0644\n    owner: root\n    group: root\n  when: \"{{ ovirt_engine_answer_file_path is undefined }}\"\n\n# copy custom answer file\n- name: copy custom answer file\n  template:\n    src: \"{{ ovirt_engine_answer_file_path }}\"\n    dest: /tmp/answerfile.txt\n    mode: 0644\n    owner: root\n    group: root\n  when: \"{{ ovirt_engine_answer_file_path is defined }}\"\n\n- name: run engine-setup with answerfile\n  shell: 'engine-setup --config-append=/tmp/answerfile.txt'\n  when: ovirt_engine_status|failed\n  tags:\n    - skip_ansible_lint\n\n- name: check state of database\n  service:\n    name: postgresql\n    state: running\n  when: (ovirt_engine_dwh_db_host == 'localhost' and ovirt_engine_dwh == True) or ovirt_engine_db_host == 'localhost'\n\n- name: check state of engine\n  service:\n    name: ovirt-engine\n    state: running\n\n- name: restart of ovirt-engine service\n  service:\n    name: ovirt-engine\n    state: restarted\n\n- name: check health status of page\n  uri:\n    url: \"http://{{ ansible_fqdn }}/ovirt-engine/services/health\"\n    status_code: 200\n  register: health_page\n  retries: 12\n  delay: 10\n  until: health_page|success\n\n- name: clean tmp files\n  file:\n    path: '/tmp/answerfile.txt'\n    state: 'absent'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "7ee05f1770af4e3b86b6ac0c3f8f4a62d6cf7065", "filename": "roles/dhcp/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- hosts: dhcp\n  become: yes\n\n  vars_files:\n  -  vars.yml\n\n#  build a DHCP server and configured it\n  pre_tasks:\n  - debug:\n      msg: \"Development Playbook to install a dhcp server and get it running\"\n\n  roles:\n  - dhcp\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "ffceb7bbadf524ff4d44851d5aafb906f1f9e558", "filename": "roles/ovirt-guest-agent/meta/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\ngalaxy_info:\n  author: \"Katerina Koukiou\"\n  description: \"Installs guest agents on VMs\"\n  company: \"Red Hat\"\n  license: \"GPLv3\"\n  min_ansible_version: 1.9\n  platforms:\n  - name: EL\n    versions:\n    - all\n  galaxy_tags:\n    - installer\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "7e55c9f839e15610accea0212aa25f7e873ff102", "filename": "roles/2-common/tasks/udev.yml", "repository": "iiab/iiab", "decoded_content": "- name: Does systemd-udevd.service exist\n  stat: path=\"{{ systemd_location }}/systemd-udevd.service\"\n  register: udev_unit\n\n- name: Copy udevd service to /etc/systemd/system to modify\n  copy: src={{ systemd_location }}/systemd-udevd.service\n        dest=/etc/systemd/system/systemd-udevd.service\n        owner=root\n        group=root\n        mode=0644\n  when: udev_unit.stat.exists is defined and udev_unit.stat.exists\n\n- name: Change MountFlags from slave to shared\n  lineinfile: backup=no\n              dest=/etc/systemd/system/systemd-udevd.service\n              regexp='^MountFlags'\n              line='MountFlags=shared'\n              state=present\n  when: udev_unit.stat.exists is defined and udev_unit.stat.exists\n\n# ubuntu 16.04 comes with ansible 2.0.0.2 -- no systemd module\n- name: Ask systemd to recognize the changes\n  shell: systemctl daemon-reload\n  when: udev_unit.stat.exists is defined and udev_unit.stat.exists\n\n- name: restart so systemd recognizes the changes\n  shell: systemctl restart systemd-udevd.service\n  when: udev_unit.stat.exists is defined and udev_unit.stat.exists\n\n- name: reload systemd-udevd so it has rootfs open read-write\n  template: src=udev-reload.service dest=/etc/systemd/system/\n\n- name: enable the reload service\n  shell: systemctl enable udev-reload.service\n\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "34b453c9a3c82f04899fa623f547da442b6fb20a", "filename": "roles/config-dns-server/tasks/generate_keys.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Get existing key files\n  shell: 'ls -1 K{{ item }}*.key | sed -ne \"s/K\\({{ item }}\\).*.key/\\1/p\"'\n  args: \n    chdir: /var/named/\n  register: key_files\n  ignore_errors: yes\n  with_items:\n  - \"{{ dns_views }}\"\n\n- name: Build list of existing key files\n  set_fact: \n    existing_key_files: \"{{ existing_key_files | default([]) + [ item.stdout ] }}\"\n  with_items:\n  - \"{{ key_files.results }}\"\n\n- name: Generate keys for nsupdate\n  command: >\n    /sbin/dnssec-keygen\n      -a {{ dnssec_keygen_algorithm | default(default_dnssec_keygen_algorithm) }} \n      -b {{ dnssec_keygen_size | default(default_dnssec_keygen_size) }}\n      -n USER\n      -r /dev/urandom \n      -K /var/named {{ item }}\n  with_items:\n  - \"{{ dns_views }}\"\n  when:\n  - item not in existing_key_files \n\n- name: Gather keys for nsupdate\n  shell: \"grep Key: /var/named/K{{ item }}*.private | cut -d ' ' -f 2\"\n  register: nsupdate_keys_captured\n  with_items:\n  - \"{{ dns_views }}\"\n\n# Build the dict with the proper keys, i.e.:\n#    private-view.example.com:\n#      algorithm: HMAC-MD5 \n#      secret: SKqKNdpfk7llKxZ57bbxUnUDobaaJp9t8CjXLJPl+fRI5mPcSBuxTAyvJPa6Y9R7vUg9DwCy/6WTpgLNqnV4Hg==\n#    public-view.example.com:\n#      algorithm: HMAC-MD5 \n#      secret: kVE2bVTgZjrdJipxPhID8BEZmbHD8cExlVPR+zbFpW6la8kL5wpXiwOh8q5AAosXQI5t95UXwq3Inx8QT58duw==\n- name: Set nsupdate_keys fact\n  set_fact:\n    nsupdate_keys: \"{{ nsupdate_keys | default({}) | combine({ item.item : { 'key_algorithm': ( dnssec_keygen_algorithm | default(default_dnssec_keygen_algorithm) ), 'key_secret': item.stdout } }) }}\"\n  with_items: \"{{ nsupdate_keys_captured.results }}\"\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "ae6654a5b1c216aee4eb40dc7379857f1d8c5936", "filename": "tasks/checks/distribution-checks-Debian.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Fail if unsupported Debian version\n  fail:\n    msg: \"Debian 7 (wheezy) or later is required!\"\n  when: _docker_os_dist == \"Debian\" and\n        _docker_os_dist_major_version < '7'\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "8300062335c53d34114d2867f425a8a42dd974ee", "filename": "archive/roles/cicd/tasks/jenkins_install_plugins.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n    \n- name: Validate Jenkins Plugins\n  fail: msg=\"Plugins Not Passed\"\n  failed_when: plugins is not defined\n  tags: jenkins\n  \n- name: Cretate Jenkins Plugin Directory\n  file:\n    path: \"{{ jenkins_plugins_home_dir }}\"\n    group: \"{{ jenkins_group }}\"\n    owner: \"{{ jenkins_user }}\"\n    state: directory\n  tags: jenkins\n\n- name: \"Download Plugins\"\n  get_url:\n      url: \"{{ jenkins_plugins_base_url }}/{{ item.name }}/{{ item.version }}/{{ item.name }}.hpi\"\n      dest: \"{{ jenkins_plugins_home_dir }}/{{item.name}}.{{ (item.pinned is defined and item.pinned == true) | ternary('jpi','hpi') }}\"\n  register: jenkins_download_plugins\n  with_items: plugins\n  tags: jenkins\n  \n- name: \"Change Plugin Permissions\"\n  file:\n    group: \"{{ jenkins_group }}\"\n    owner: \"{{ jenkins_user }}\"\n    state: file\n    path: \"{{ item.dest }}\"\n  with_items: jenkins_download_plugins.results\n  tags: jenkins\n\n\n- name: \"Set Pinned Plugin Markers\"\n  file:\n    group: \"{{ jenkins_group }}\"\n    owner: \"{{ jenkins_user }}\"\n    state: touch\n    path: \"{{ jenkins_plugins_home_dir }}/{{ item.item.name }}.jpi.pinned\"\n  when: item.item.pinned is defined and item.item.pinned == true\n  with_items: jenkins_download_plugins.results\n  tags: jenkins"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "0e39d036a00738df147cff9e42c79342733e9735", "filename": "roles/config-nagios-target/tasks/nrpe_disk.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Ensure the check_disk.cfg file exists\n  file:\n    path: /etc/nrpe.d/check_disk.cfg\n    state: touch\n    mode: 0644\n\n- name: Add the check for the root disk\n  lineinfile:\n    dest: /etc/nrpe.d/check_disk.cfg\n    regexp: '^command.check_root_disk.=.+check_disk .*'\n    line: \"command[check_root_disk]=/usr/lib64/nagios/plugins/check_disk -w 20% -c 10% -p {{ item.device }}\"\n    state: present\n  with_items:\n  - \"{{ ansible_mounts }}\"\n  when: item.mount == '/'\n\n\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "6e356e1bc062a58fe73e4da23d63371ac7bb7059", "filename": "roles/rollback/tasks/user-release.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Check whether user-specified release exists\n  stat:\n    path: \"{{ project_root }}/releases/{{ release }}\"\n  register: specified\n\n- name: Get name of current symlinked release\n  shell: \"basename $(readlink {{ project_current_path }})\"\n  args:\n    chdir: \"{{ project_root }}\"\n  register: current_release\n\n- name: Fail if user-specified release doesn't exist or is already active\n  fail:\n    msg: \"Cannot switch to release {{ release }}. Either it does not exist or it is the active release.\"\n  when: specified.stat.isdir | default(False) == False or current_release.stdout_lines[0] == release\n\n- name: Create new_release_path variable\n  set_fact:\n    new_release_path: \"{{ project_root }}/releases/{{ release }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "48f07f3e567b7e7b1e955e26687cf137c320c1cc", "filename": "roles/schooltool/templates/schooltool.service", "repository": "iiab/iiab", "decoded_content": "[unit]\nDescription=schooltool\nAfter=docker.service\nRequires=docker.service\n\n[Service]\nExecStartPre=-/usr/bin/docker stop tool\nExecStartPre=-/usr/bin/docker rm tool\nExecStart=/usr/bin/docker run -d  --name=tool -p 7080:7080 -v /var/lib/schooltool:/var/lib/schooltool ghunt/schooltool\n#Restart=always\n#RestartSec=10s\nType=notify\nNotifyAccess=all\nTimeoutStartSec=120\nTimeoutStopSec=15\n\n[Install]\nWantedBy=multi-user.target\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "460c2014184a21eaad715cefeb40ad345cbd8ded", "filename": "tasks/Win32NT/system.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Set parse variables based on java distribution\n  include_vars: java_parts.yml\n\n- name: 'Perform {{ java_binary_type }} install'\n  include_tasks: '{{ install_task }}'\n  with_first_found:\n    - 'install/{{ java_distribution }}_{{ java_binary_type }}.yml'\n    - 'install/{{ java_binary_type }}.yml'\n  loop_control:\n    loop_var: install_task\n\n- name: Finalize binary paths\n  include_tasks: finalize_paths.yml\n"}, {"commit_sha": "a9f9815335a6b9c73bed7e3dcd75e14cd973fbb5", "sha": "d37ddc9d5bb88aafef20e21ad2820fcbbfd418f4", "filename": "handlers/main.yml", "repository": "CSCfi/ansible-role-cuda", "decoded_content": "---\n\n- name: ZZ CUDA Restart server\n  command: shutdown -r now \"Reboot triggered by Ansible\"\n  async: 0\n  poll: 0\n  ignore_errors: true\n  when: cuda_packages_installation.changed and cuda_restart_node_on_install == True\n\n- name: ZZ CUDA Wait for server to restart\n  wait_for:\n     host={{ inventory_hostname }}\n     port=22\n     delay=5\n     timeout=300\n  sudo: false\n  when: cuda_restart.changed and cuda_restart_node_on_install == True\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "ea6bb28e04d30bab9c71cb03e62b90845c7f3093", "filename": "playbooks/manage-users/manage-local-user-access.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Update local access for account:{{ user_name }}'\n  hosts: all\n  roles:\n    - role: user-management/manage-local-user-password\n    - role: user-management/manage-local-user-ssh-authkeys\n    - role: manage-sshd-config\n  tags:\n    - manage-local-user-access\n\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "fedfc97eb4b8f91682a3a826e4ec251e3fa1c669", "filename": "roles/wordpress-install/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- include: directories.yml\n  tags: wordpress-install-directories\n\n- name: Create .env file\n  template:\n    src: \"env.j2\"\n    dest: \"/tmp/{{ item.key }}.env\"\n    owner: \"{{ web_user }}\"\n    group: \"{{ web_group }}\"\n  with_dict: \"{{ wordpress_sites }}\"\n\n- name: Copy .env file into web root\n  command: rsync -ac --info=NAME /tmp/{{ item.key }}.env {{ www_root }}/{{ item.key }}/current/.env\n  with_dict: \"{{ wordpress_sites }}\"\n  register: env_file\n  changed_when: env_file.stdout == \"{{ item.key }}.env\"\n\n- name: Install Dependencies with Composer\n  command: composer install\n  args:\n    chdir: \"{{ www_root }}/{{ item.key }}/current/\"\n  register: composer_results\n  with_dict: \"{{ wordpress_sites }}\"\n  changed_when: \"'Nothing to install or update' not in composer_results.stderr\"\n\n- name: Install WP\n  command: wp core install\n           --allow-root\n           --url=\"{{ site_env.wp_home }}\"\n           --title=\"{{ item.value.site_title | default(item.key) }}\"\n           --admin_user=\"{{ item.value.admin_user | default('admin') }}\"\n           --admin_password=\"{{ vault_wordpress_sites[item.key].admin_password }}\"\n           --admin_email=\"{{ item.value.admin_email }}\"\n  args:\n    chdir: \"{{ www_root }}/{{ item.key }}/current/\"\n  register: wp_install_results\n  with_dict: \"{{ wordpress_sites }}\"\n  when: item.value.site_install | default(true) and not item.value.multisite.enabled | default(false)\n  changed_when: \"'WordPress is already installed.' not in wp_install_results.stdout\"\n\n- name: Setup Permalink Structure\n  command: wp rewrite structure {{ item.value.initial_permalink_structure | default(\"/%postname%/\") }}\n           --allow-root\n  args:\n    chdir: \"{{ www_root }}/{{ item.key }}/current/\"\n  with_dict: \"{{ wordpress_sites }}\"\n  when: wp_install_results | changed and not wp_install_results | skipped\n\n- name: Install WP Multisite\n  command: wp core multisite-install\n           --allow-root\n           --url=\"{{ site_env.wp_home }}\"\n           --base=\"{{ item.value.multisite.base_path | default('/') }}\"\n           --subdomains=\"{{ item.value.multisite.subdomains | default('false') }}\"\n           --title=\"{{ item.value.site_title | default(item.key) }}\"\n           --admin_user=\"{{ item.value.admin_user | default('admin') }}\"\n           --admin_password=\"{{ vault_wordpress_sites[item.key].admin_password }}\"\n           --admin_email=\"{{ item.value.admin_email }}\"\n  args:\n    chdir: \"{{ www_root }}/{{ item.key }}/current/\"\n  register: wp_install_results\n  with_dict: \"{{ wordpress_sites }}\"\n  when: item.value.site_install | default(true) and item.value.multisite.enabled | default(false)\n  changed_when: \"'The network already exists.' not in wp_install_results.stdout\"\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "0f7bc7f32302b9e2ed0fe835697ee064d52d5fde", "filename": "roles/dcos_cli/tasks/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "- include: frameworks.yml\n- include: apps.yml\n\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "d373337628b6bc3cbbff5c37b25053d1aaa4ef28", "filename": "roles/ssmtp/defaults/main.yml", "repository": "roots/trellis", "decoded_content": "ssmtp_auth_method: LOGIN\nssmtp_from_override: 'Yes'\nssmtp_start_tls: 'Yes'\nssmtp_tls: 'Yes'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "0ac050f5db9f98b4541ad13cf8ae69a2521e7586", "filename": "roles/config-linux-desktop/config-lxde/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Install, configure and enable LXDE\"\n  include_tasks: \"{{ distro_file }}\"\n  with_first_found:\n  - files:\n    - lxde-{{ ansible_distribution }}.yml\n    skip: true\n  loop_control:\n    loop_var: distro_file\n  when:\n  - lxde_install|default(False)\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "d7b1e862aedad429ccd8a486cf9e01ff065a0ef3", "filename": "roles/config-lvm/tasks/lvm.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Setup and create PV & VG\"\n  lvg:\n    vg: \"{{ item.vg_name }}\"\n    pvs: \"{{ item.storage_device }}\"\n\n- name: \"Setup LV\"\n  lvol: \n    vg: \"{{ item.vg_name }}\"\n    lv: \"{{ item.lv_name }}\"\n    size: \"{{ item.lv_size | default(default_lv_size) }}\"\n\n- name: \"Create file system on share\"\n  filesystem:\n    fstype: \"{{ item.lv_fstype | default(lvm_fstype) }}\"\n    dev: \"/dev/mapper/{{ item.vg_name }}-{{ item.lv_name }}\"\n\n- name: \"Ensure the mount dir exists\" \n  file:\n    path: \"{{ item.mount_path }}\"\n    state: directory\n\n- name: \"Mount LVM to directory\"\n  mount:\n    src: \"/dev/mapper/{{ item.vg_name }}-{{ item.lv_name }}\"\n    path: \"{{ item.mount_path }}\"\n    fstype: \"{{ item.lv_fstype | default(lvm_fstype) }}\"\n    state: mounted\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "504112fb9851d096ae3c265530a9e4c29fe56d32", "filename": "roles/activity-server/README.rst", "repository": "iiab/iiab", "decoded_content": "Serve XO activities from the XS school server\n=============================================\n\nXO laptops can update their activities via HTTP, using specially\nmicroformatted html pages to determine what to download.\n\nThis package imports XO activities from a USB stick and generates the\ncorrect html to serve them, in as many languages as it knows how,\nusing the localisation information from the activity bundles.  Content\nnegotiation between Apache and the laptops decides what html is seen.\n\nThe URL for this index is http://schoolserver/activities/.\n\nA facility exists to add extra descriptive html to the generated\nindexes.\n\nUSB import\n----------\n\nWhen a USB drive is inserted, the server looks for a directory in the\nroot directory called xs-activity-server.  In there it expects to find\nany number of activity bundles, a file called manifest.sha1, and\noptionally a file or files with the suffix \".info\".  Depending on the\nconfiguration of the school server, a file called \"manifest.sha1.sig\"\nmight also be required.\n\nActivity bundles are zip files with the suffix .xo and an internal\nlayout described at http://wiki.laptop.org/go/Activity_bundles.\n\nThe manifest file should contain sha1sums for each activity bundle and\nthe metadata files, as if you had run\n\n  sha1sum *.xo *.info > manifest.sha1\n\nin the directory.\n\nIf full XS security is enabled (by the presence of /etc/xs-security-on\n-- see the xs-tools documentation), then manifest.sha1.sig should\ncontain a detached GPG signature for manifest.sha1, signed by a key\nthat the XS knows.  If the school server lacks the /etc/xs-security-on\nflag, the manifest.sha1.sig file is ignored.\n\nMultiple languages\n------------------\n\nActivities can contain localisation information, which usually\nconsists of a translated activity name.  The localised information is\nfound in the bundle in a directory like:\n\nSomeWonderful.activity/locale/pt-BR/activity.linfo\n\nwhere pt-BR is an RFC1788 language code. If any activity contains an\nactivity.linfo file for a language, then an index is generated.  The\nserver has templates for indexes in some languages (currently Spanish\nand English); for other languages the indexes will be in English\nexcept for the localised names.\n\nThese index files are saved with names like\nactivities/index.html.zh-es.  You can choose to look at them directly\nthat way, or let your browser decide which one is best for you by\nvisiting activities/index.html.\n\nIf some activities lack localised information for a multi-part\nlanguage code, the index will include information that exists for the\ncorresponding single part code, before defaulting to English.  For\nexample, a zh-CN page will include zh localisation if need be.  (This\nmay not always be the best result: bn and bn-IN appear to use\ndifferent scripts).\n\n\nIncluding extra descriptions\n----------------------------\n\nThe optional .info files in the xs-activation-server directory should\nconsist of sections in this format:\n\n  [com.microsoft.Word]\n  description = Write replacement, without distraction of collaboration.\n\n  [some.other.Something]\n  description = another description, all on one line.\n\nIf a section heading (in square brackets) matches the bundle_id or\nservice_name of an activity, the description will be displayed on the\ngenerated html page.  This information is not used by automatic\nupdates, but it might assist children in browsing and manually\ninstalling activities.  Note: there is no clever localisation here.\n\nMultiple versions\n-----------------\n\nOver the course of a server deployment, an activity might be updated\nseveral times.  To preserve disk space, only the 4 most recent\nversions of an activity are kept.  Links to the second, third and\nfourth newest versions are presented in the activities html file, but\nthese do not use the activity microformat and will not be visible to\nautomated updaters.\n\nTo determine which activities are the most recent, the file's modification\ntimes (mtime) are examined. The version number is not considered here.\n\nNote: If you plug in a USB stick with very out-of-date activities they\nwill be deleted as soon as they get on the server.\n\nHTML microformat\n----------------\n\nThe microformat is described at\nhttp://wiki.laptop.org/go/Activity_microformat.\n\nUtility script\n--------------\n\n/usr/bin/xs-check-activities will print statistics about a directory\nof activities to stderr.  Its output is not particularly well\nformatted or explained, but it is there if you want it.\n\nFiles and directories\n---------------------\n\nActivities are stored in /library/xs-activity-server/activities, with\nthe html index being index.html in that directory.  Apache is coaxed\ninto serving this by /etc/httpd/conf.d/xs-activity-server.conf.\n\nBugs\n----\n\nOld versions are only saved if the different versions have different\nfile names.  Most activity bundles have names like 'Maze-4.xo',\n'Maze-5.xo' and so on, but some lack the version number in the file\nname, so the most recently imported version ends up overwriting the\nolder ones.\n\nSource\n------\n\nThis role is based on the xs-activity-server rpm.\n\nhttp://dev.laptop.org/git/users/martin/xs-activity-server/ v0.4 release"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "6d52aec395d3263d58ccc5062c0fa4bdceeaf2f4", "filename": "playbooks/roles/check_docker/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "---\n- name: Prepare install and validate docker\n  hosts: nodes\n  gather_facts: yes\n  vars_files:\n  - \"{{file_env}}\"\n  roles:\n  - check_docker_setup\n  - check_docker_validation\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "057f4a0f8aed5a36d902e7f8d4887d4fef8a9833", "filename": "tasks/unknown-transport.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Warn on unsupported transport\n  debug:\n    msg: |\n      This role does not support '{{ transport }}' transport.\n      Please contact support@lean-delivery.com\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "652c416a91e66958d163fffd422999ecb3f043b7", "filename": "roles/dns/manage-dns-zones-route53/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: dns-servers\n  roles:\n  - role: dns/manage-dns-zones\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "a56cb98c85fbfadbe74a4121fc372f5d32180a68", "filename": "roles/osm/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "osm_install: True\nosm_enabled: False\nosm_path: \"\"\nosm_venv: /usr/local/osm/\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "c0a43088b2e8f61199cf7c4de598e36d01eb9514", "filename": "tasks/create_repo_raw_proxy_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_raw_proxy\n    args: \"{{ _nexus_repos_raw_defaults|combine(item) }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "660c800d320298dac7d556fb87a2f98537beb140", "filename": "roles/1-prep/README.rst", "repository": "iiab/iiab", "decoded_content": "===========\nPrep README\n===========\n\nThis role is a sort on init or startup.  It includes preliminaries like hostname and is where things\nthat are specific to a particular platform, such as the XO, are done before the bulk of the install.\n"}, {"commit_sha": "e91a55152358e890a05cf849abc7d58b8badecc2", "sha": "1cb977893695f2e57995638163bb9b10666d9f1b", "filename": "tasks/install-distro.yml", "repository": "fubarhouse/ansible-role-golang", "decoded_content": "---\n\n- name: \"Go-Lang | Download distribution\"\n  get_url:\n    url: \"{{ go_custom_mirror }}/{{ go_distribution_filename }}.tar.gz\"\n    dest: \"{{ go_temporary_dir }}/{{ go_distribution_filename }}.tar.gz\"\n    validate_certs: no\n\n- name: \"Go-Lang | Empty destination directory\"\n  file:\n    path: \"{{ GOROOT }}\"\n    state: absent\n\n- name: \"Go-Lang | Ensure directory is writable\"\n  file:\n    path: \"{{ GOROOT }}\"\n    state: directory\n    owner: \"{{ fubarhouse_user }}\"\n    mode: 0755\n    recurse: true\n\n- name: \"Go-Lang | Unpack distribution\"\n  unarchive:\n    src: \"{{ go_temporary_dir }}/{{ go_distribution_filename }}.tar.gz\"\n    dest: \"{{ go_temporary_dir }}\"\n    copy: \"no\"\n\n- name: \"Go-Lang | Removing existing installation\"\n  shell: \"rm -rf {{ GOROOT }}/*\"\n\n- name: \"Go-Lang | Moving to installation directory\"\n  shell: \"cp -rf {{ go_temporary_dir }}/go/* {{ GOROOT }}/\"\n\n- name: \"Go-Lang | Remove temporary data\"\n  file:\n    path: \"{{ go_temporary_dir }}/go/\"\n    state: absent"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a0190e66c7152567180a84db90dc9dae1cbc2999", "filename": "roles/dhcp/tasks/prereq.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: 'Pre-Req: Install required packages '\n  package:\n    name: '{{ item }}'\n    state: installed\n  with_items:\n  - firewalld\n  - python-firewall\n  - libsemanage-python\n  - dhcp\n  notify: 'enable and start dhcp services'\n\n- name: 'Start firewalld service'\n  service:\n    name: firewalld\n    enabled: yes\n    state: started\n\n- name: 'Pre-Req: Open Firewall for dhcp use'\n  firewalld:\n    service: \"{{item}}\"\n    permanent: yes\n    state: enabled\n    immediate: yes\n  with_items:\n  - dhcp\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "4ecafae6b40c757d6e92ea23c9a80c38148c1eb9", "filename": "roles/user-management/manage-atlassian-users/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- include_tasks: create_atlassian_groups.yml\n  with_items: \"{{ atlassian.groups }}\"\n  loop_control:\n    loop_var: group\n  when: atlassian.groups|length > 0\n\n- include_tasks: create_atlassian_users.yml\n  with_items: \"{{ atlassian.user }}\"\n  loop_control:\n    loop_var: atlassian_user\n  when: atlassian.user|length > 0\n\n- include_tasks: add_user_to_groups.yml\n  with_items: \"{{ atlassian.user }}\"\n  loop_control:\n    loop_var: atlassian_user\n  when: atlassian.user|length > 0\n\n- include_tasks: delete_atlassian_users.yml\n  with_items: \"{{ atlassian.user }}\"\n  loop_control:\n    loop_var: atlassian_user\n  when: atlassian.user|length > 0\n\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "731f59bf659097dcdf3c23325abec0a73b1e7f4b", "filename": "archive/roles/cicd-common/defaults/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\ndefault_cicd_storage_disk_volume: \"/dev/vdb\"\n\ndefault_cicd_openstack_security_groups: \"CI-CD\"\ndefault_cicd_openstack_flavor_name: \"m1.medium\"\ndefault_cicd_openstack_image_name: \"ose3_1-base\"\ndefault_cicd_openstack_storage_size: 10\ndefault_cicd_instance_count: 1"}, {"commit_sha": "a5a5c4d74b7b0fd14f534dda1f41f903d1a58abf", "sha": "69f30fe2908e149a7f2bac15095f01acf9509f14", "filename": "tasks/iojs.yml", "repository": "fubarhouse/ansible-role-nodejs", "decoded_content": "---\n#\n# IOJS Tasks\n#\n# IOJS is no longer available via NVM, but can be downloaded on the web.\n# IOJS was a NodeJS compatible platform based upon an earlier NodeJS release.\n# IOJS was merged into NodeJS in version 4, and is in every version this role installs.\n#\n\n- name: \"IOJS | Get versions\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  shell: \"/usr/local/bin/ivm ls\"\n  register: iojs_available_versions\n  changed_when: false\n\n- name: \"IOJS | Check for local default install\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  stat:\n    path: \"/usr/local/ivm/versions/{{ node_version }}\"\n  register: fubarhouse_npm_io_install_result\n  changed_when: false\n  failed_when: false\n  when: '\"{{ node_version }}\" in iojs_available_versions.stdout_lines'\n\n- name: \"IOJS | Check for all local installs\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  stat:\n    path: \"/usr/local/ivm/versions/{{ item }}\"\n  register: fubarhouse_npm_io_install_results\n  changed_when: false\n  failed_when: false\n  when: '\"{{ item }}\" in iojs_available_versions.stdout'\n  with_items: \"{{ node_versions }}\"\n\n- name: \"IOJS | Install default\"\n  become: yes\n  become_user: root\n  shell:  \"/usr/local/bin/ivm {{ node_version }}\"\n  when:\n    - fubarhouse_npm_io_install_result is defined\n    - '\"{{ node_version }}\" not in fubarhouse_npm_io_install_results.results'\n    - '\"{{ node_version }}\" in iojs_available_versions.stdout'\n  changed_when: false\n\n- name: \"IOJS | Install all\"\n  become: yes\n  become_user: root\n  shell:  \"/usr/local/bin/ivm {{ item }}\"\n  when: 'iojs_available_versions is defined and \"{{ item }}\" in iojs_available_versions.stdout'\n  with_items:\n   - \"{{ node_versions }}\"\n  changed_when: false\n\n- name: \"IOJS | Unalias default NVM alias\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  shell: \"{{ fubarhouse_npm.nvm_symlink_exec }} unalias default\"\n  changed_when: false\n  failed_when: false\n  when: '\"{{ node_version }}\" in iojs_available_versions.stdout'\n\n- name: \"IOJS | Switch\"\n  become: yes\n  become_user: root\n  file:\n    src: \"/usr/local/ivm/versions/{{ node_version }}/bin/node\"\n    dest: \"/usr/local/bin/iojs\"\n    state: link\n    force: yes\n  when: '\"{{ node_version }}\" in iojs_available_versions.stdout'\n\n- name: \"IOJS | Verify version in use\"\n  shell: \"/usr/local/bin/ivm ls | grep \u03bf | cat\"\n  register: iojs_current_version\n  changed_when: false\n  failed_when: 'iojs_current_version.stdout.find(\"{{ node_version }}\") == -1'\n  when: '\"{{ node_version }}\" in iojs_available_versions.stdout'"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "d3781a822b2de6f8922d069fff1fc0319a918064", "filename": "roles/ansible/tower/config-ansibletower/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: restart-tower\n  service:\n    name:  supervisord\n    state: restarted\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "2aec9e33a6f932755c7b46c680fc92564058f2d9", "filename": "roles/config-mysql/tasks/firewall.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Check if firewalld is installed\n  command: systemctl status firewalld\n  register: firewalld_status\n  failed_when: false\n  changed_when: false\n\n- name: Check if iptables is installed\n  command: systemctl status iptables\n  register: iptables_status\n  failed_when: false\n  changed_when: false\n\n- name: Open port in firewalld\n  firewalld:\n    port: \"{{ mysql_host_port }}/TCP\"\n    permanent: true\n    state: enabled\n  when: firewalld_status.rc == 0\n  notify:\n  - restart firewalld\n\n- name: Ensure iptables is correctly configured\n  lineinfile:\n    insertafter: \".*INPUT -p tcp.*\"\n    state: present\n    dest: /etc/sysconfig/iptables\n    regexp: \"^-A INPUT .* --dport {{ mysql_host_port }} .* ACCEPT\"\n    line: \"-A INPUT -p tcp -m state --state NEW -m tcp --dport {{ mysql_host_port }} -j ACCEPT\"\n  when: iptables_status.rc == 0 and firewalld_status.rc != 0\n  notify:\n  - restart iptables\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "6e550b858e96b5dd5d743b720e9792141e680a24", "filename": "roles/2-common/tasks/net_mods.yml", "repository": "iiab/iiab", "decoded_content": "- name: Disable systemd-networkd.service\n  service: name=systemd-networkd.service\n           enabled=no\n  when: not is_centos\n\n- name: Mask systemd-networkd.service\n  shell: 'systemctl mask systemd-networkd'\n  when: not is_centos\n\n- name: Disable systemd-hostnamed.service\n  service: name=systemd-hostnamed.service\n           enabled=no\n\n- name: Disable dbus-org.freedesktop.hostname1.service\n  service: name=dbus-org.freedesktop.hostname1\n           enabled=no\n\n- name: Mask dbus-org.freedesktop.hostname1.service\n  shell: 'systemctl mask dbus-org.freedesktop.hostname1'\n\n- name: Disable network.service\n  service: name=network\n           enabled=no\n\n- name: Mask network.service\n  shell: 'systemctl mask network.service'\n\n# Network Manager starts this if needed\n- name: Disable wpa_supplicant\n  service: name=wpa_supplicant\n           enabled=no\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "ca3a57a92b6e2c92f1b027d30b5c93b1b4e57bd8", "filename": "roles/ansible/tower/manage-inventories/tasks/process-group.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Load up the inventory (group)\"\n  uri:\n    url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}/api/v2/groups/\"\n    user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n    password: \"{{ ansible_tower.admin_password }}\"\n    force_basic_auth: yes\n    method: POST\n    body: \"{{ lookup('template', 'group.j2') }}\"\n    body_format: 'json'\n    headers:\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n    validate_certs: no\n    status_code: 200,201,400\n\n# Utilize the `rest_get` library routine to ensure REST pagination is handled\n- name: \"Get the updated list of existing groups\"\n  rest_get:\n    host_url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}\"\n    rest_user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n    rest_password: \"{{ ansible_tower.admin_password }}\"\n    api_uri: \"/api/v2/groups/\"\n  register: existing_groups_output\n\n- name: \"Get the group id based on the group name\"\n  set_fact:\n    group_id: \"{{ item.id }}\"\n  when:\n  - item.name|trim == group.name|trim\n  with_items:\n  - \"{{ existing_groups_output.rest_output }}\"\n\n- name: \"Process the inventory group members\"\n  include_tasks: process-group-member.yml\n  with_items:\n  - \"{{ group.hosts }}\"\n  loop_control:\n    loop_var: group_member\n\n- name: \"Clear/Update facts\"\n  set_fact:\n    group_id: ''\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "03af4243588c5cb7719cc8a7e5b631224f6e3136", "filename": "roles/config-satellite/tasks/manifest.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Copy subscription manifest .zip file\"\n  copy:\n    src: \"{{ manifest_file_path | default(default_manifest_file_path) }}\"\n    dest: /root/manifest.zip\n  register: copy_sub\n\n- name: \"Upload manifest if new or updated file provided\"\n  command: > \n    hammer \n      -u \"{{ satellite_username }}\"\n      -p \"{{ satellite_password }}\"\n      subscription upload\n      --file /root/manifest.zip\n      --organization \"{{ satellite_organization }}\"\n  when: copy_sub|changed\n\n\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "496945b806ba59f8c882a941780dbe6b2c544b40", "filename": "tasks/plus/setup-license.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(All OSs) Setup NGINX Plus License\"\n  block:\n\n    - name: \"(All OSs) Create SSL Directory\"\n      file:\n        path: /etc/ssl/nginx\n        state: directory\n\n    - name: \"(All OSs) Copy NGINX Plus Certificate and License Key\"\n      copy:\n        src: \"{{ item }}\"\n        dest: /etc/ssl/nginx\n        decrypt: yes\n      with_items:\n        - \"{{ nginx_license.certificate }}\"\n        - \"{{ nginx_license.key }}\"\n\n  when: ansible_distribution != \"Alpine\"\n\n- name: \"(Alpine Linux) Setup NGINX Plus License\"\n  block:\n\n    - name: \"(Alpine Linux) Create APK Directory\"\n      file:\n        path: /etc/apk\n        state: directory\n\n    - name: \"(Alpine Linux) Copy NGINX Plus Key\"\n      copy:\n        src: \"{{ nginx_license.key }}\"\n        dest: /etc/apk/cert.key\n        decrypt: yes\n\n    - name: \"(Alpine Linux) Copy NGINX Plus Certificate\"\n      copy:\n        src: \"{{ nginx_license.certificate }}\"\n        dest: /etc/apk/cert.pem\n        decrypt: yes\n\n  when: ansible_distribution == \"Alpine\"\n"}, {"commit_sha": "481f7ad18dc225973e1d676d33e58c49cbbfe986", "sha": "8b07a95fc71dce668eda8f88b5df4c67866e4e44", "filename": "tasks/nginx.yml", "repository": "openwisp/ansible-openwisp2", "decoded_content": "- name: create \"{{ openwisp2_path }}/public_html\"\n  file:\n    path: \"{{ openwisp2_path }}/public_html\"\n    state: directory\n\n- name: create \"{{ openwisp2_path }}/ssl\"\n  file:\n    path: \"{{ openwisp2_path }}/ssl\"\n    state: directory\n\n- name: create SSL cert if not exists yet\n  command: >\n    openssl req -new -nodes -x509 -subj \"/C={{ openwisp2_ssl_country }}/ST={{ openwisp2_ssl_state }}/L={{ openwisp2_ssl_locality }}/O={{ openwisp2_ssl_organization }}/CN={{ openwisp2_ssl_common_name }}\" -days 3650 -keyout {{ openwisp2_ssl_key }} -out {{ openwisp2_ssl_cert }} -extensions v3_ca creates={{ openwisp2_ssl_cert }}\n  notify: restart nginx\n\n- name: nginx site available\n  template:\n    src: ../templates/nginx.j2\n    dest: \"/etc/nginx/sites-available/{{ inventory_hostname }}\"\n  notify: restart nginx\n  when: ansible_os_family == 'Debian'\n\n- name: nginx site enabled\n  file:\n    src: \"/etc/nginx/sites-available/{{ inventory_hostname }}\"\n    dest: \"/etc/nginx/sites-enabled/{{ inventory_hostname }}\"\n    state: link\n  notify: restart nginx\n  when: ansible_os_family == 'Debian'\n\n- name: nginx site\n  template:\n    src: ../templates/nginx.j2\n    dest: \"/etc/nginx/conf.d/{{ inventory_hostname }}.conf\"\n  notify: restart nginx\n  when: ansible_os_family == 'RedHat'\n"}, {"commit_sha": "0af3e85a918252d0349ba15721cbedc1e3d80ff1", "sha": "31ed8d0c2d225aca51b6b37aa3ee0500f8cfcd59", "filename": "tasks/nodejs.yml", "repository": "fubarhouse/ansible-role-nodejs", "decoded_content": "---\n# Tasks file for NodeJS\n\n- name: \"NodeJS | Check\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  shell:  \"{{ fubarhouse_npm.nvm_symlink_exec }} ls | cat\"\n  register: installed_nodejs_versions\n  changed_when: false\n\n- name: \"NodeJS | Install default version\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  shell:  \"{{ fubarhouse_npm.nvm_symlink_exec }} install {{ node_version }}\"\n  when: '\"{{ node_version }}\" in nodejs_available_versions.stdout and \"{{ node_version }}\" not in \"{{ node_versions }}\" and \"{{ node_version }}\" not in \"{{ installed_nodejs_versions.stdout }}\"'\n\n- name: \"NodeJS | Install all requested versions\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  shell:  \"{{ fubarhouse_npm.nvm_symlink_exec }} install {{ item }}\"\n  when: '\"{{ item }}\" in nodejs_available_versions.stdout and item not in installed_nodejs_versions.stdout'\n  with_items: \"{{ node_versions }}\"\n\n- name: \"NodeJS | Switching\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  shell:  \"{{ fubarhouse_npm.nvm_symlink_exec }} use {{ node_version }}\"\n  register: fubarhouse_npm_switch\n  changed_when: false\n  when: '\"{{ node_version }}\" in nodejs_available_versions.stdout'\n\n- name: \"NodeJS | Linking\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  shell: \"{{ fubarhouse_npm.nvm_symlink_exec }} alias default {{ node_version }}\"\n  changed_when: false\n  when: '\"{{ node_version }}\" in nodejs_available_versions.stdout'\n\n- name: \"NodeJS | Linking binaries\"\n  file:\n    src: \"{{ fubarhouse_npm.user_dir }}/.nvm/v{{ node_version }}/bin/{{ item }}\"\n    dest: \"/usr/local/bin/{{ item }}\"\n    state: link\n    force: yes\n  with_items:\n    - node\n    - npm\n  when: '\"{{ node_version }}\" in nodejs_available_versions.stdout'\n\n- name: \"NodeJS | Import exports\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  lineinfile:\n    dest: \"{{ fubarhouse_npm.user_dir }}/{{ item.filename }}\"\n    line: \"export PATH=$PATH:$(npm config --global get prefix)/bin\"\n    state: present\n  with_items: \"{{ fubarhouse_npm.shell_profiles }}\"\n  when: '\"{{ node_version }}\" in nodejs_available_versions.stdout'\n\n- name: \"NodeJS | Verify version in use\"\n  shell: \"{{ fubarhouse_npm.nvm_symlink_exec }} ls | grep current | cat\"\n  register: node_current_version\n  changed_when: false\n  failed_when: 'node_current_version.stdout.find(\"{{ node_version }}\") == -1'\n  when: '\"{{ node_version }}\" in nodejs_available_versions.stdout'"}, {"commit_sha": "64cbc6946b7ebc0d9a36f40d77ac86f8e3564499", "sha": "820131214c438519ceba181f2727829f0eb45aa4", "filename": "tasks/compute.yml", "repository": "CSCfi/ansible-role-slurm", "decoded_content": "---\n\n  - name: get munge key for distribution to nodes\n    copy: src=files/munge.key\n          dest=/etc/munge/munge.key\n          owner=munge\n          group=munge\n          mode=0400\n    when: slurm_munge_key_from_nfs == False\n    notify:\n     - restart munge\n\n  - name: copy the munge key from NFS\n    command: cp -v {{ slurm_munge_key_nfs }} /etc/munge/munge.key creates=/etc/munge/munge.key\n    when: slurm_munge_key_from_nfs == True\n    notify:\n     - restart munge\n\n  - name: set permissions on the munge key from NFS\n    file: path=/etc/munge/munge.key mode=0400 owner=munge group=munge\n    when: slurm_munge_key_from_nfs == True\n    notify:\n     - restart munge\n\n  - name: start and enable munge\n    service: name=munge state=started enabled=yes\n    notify:\n     - restart munge\n\n  - name: Make sure /usr/local/libexec/slurm/epilog.d exists\n    file: path=/usr/local/libexec/slurm/epilog.d state=directory owner=root group=root mode=0755 recurse=yes\n\n  - name: Create namespace epilog script\n    template: src=namespace_clean.sh.j2 dest=/usr/local/libexec/slurm/epilog.d/namespace_clean.sh owner=root group=root mode=0755\n\n  - name: disable the slurm init script slurm on el7\n    service: name=slurm enabled=no\n    when: ansible_os_family == \"RedHat\" and ansible_distribution_major_version == \"7\"\n\n  - name: start and enable slurmd\n    service: name={{ slurmd_service }} state=started enabled=yes\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "e0677e73adc313768f10a3f97a8345ea4635e5cd", "filename": "roles/config-dns-server/test/inventory/group_vars/forward-server.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nnamed_config_recursion: 'yes'\nnamed_config_dnssec_enable: 'yes'\nnamed_config_dnssec_validation: 'yes'\nnamed_config_dnssec_lookaside: 'no'\nnamed_config_views:\n- name: my_forward_zone\n  recursion: 'yes'\n  zone:\n  - dns_domain: forward.example.com\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "9a33fe708c26a47d69a840091dda411e7cc32c96", "filename": "roles/dns/manage-dns-zones-route53/tasks/get-zone-records.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Get all hosted zones\n  route53_facts:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    query: hosted_zone\n  register: hosted_zones\n\n- name: Get all records from zones\n  route53_facts:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    query: record_sets\n    hosted_zone_id: \"{{ item.Id | replace('/hostedzone/', '')}}\"\n  with_items:\n    - \"{{ hosted_zones.HostedZones | default({}) }}\"\n  register: zones_records\n  when:\n    - hosted_zones|length > 0\n"}, {"commit_sha": "481f7ad18dc225973e1d676d33e58c49cbbfe986", "sha": "19d7e7542bfdc2c7db5b9758f0580b16dfbfabcb", "filename": "tasks/cron.yml", "repository": "openwisp/ansible-openwisp2", "decoded_content": "---\n\n- name: Install topology update cron\n  when: openwisp2_network_topology\n  become: true\n  cron:\n    name: \"Update toplogies\"\n    day: \"{{ openwisp2_topology_update_frequency.day }}\"\n    hour: \"{{ openwisp2_topology_update_frequency.hour }}\"\n    minute: \"{{ openwisp2_topology_update_frequency.minute }}\"\n    job: \"{{ virtualenv_path }}/bin/python {{ openwisp2_path }}/manage.py update_topology\"\n\n- name: Install topology snapshot save cron\n  when: openwisp2_network_topology\n  become: true\n  cron:\n    name: \"Save snapshots of topologies\"\n    day: \"{{ openwisp2_topology_save_snapshot_frequency.day }}\"\n    hour: \"{{ openwisp2_topology_save_snapshot_frequency.hour }}\"\n    minute: \"{{ openwisp2_topology_save_snapshot_frequency.minute }}\"\n    job: \"{{ virtualenv_path }}/bin/python {{ openwisp2_path }}/manage.py save_snapshot\"\n\n- name: Install clearsessions cronjob\n  become: true\n  cron:\n    name: \"clearsessions cronjob\"\n    day: \"*\"\n    hour: \"04\"\n    minute: \"30\"\n    job: \"{{ virtualenv_path }}/bin/python {{ openwisp2_path }}/manage.py clearsessions\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a3d169f23fcb6326156d922ee50836f94839582c", "filename": "roles/idm-host-cert/tasks/retrieve-ca-cert.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Retrieve the CA cert\"\n  uri: \n    url: \"https://{{ idm_fqdn }}/ipa/session/json\"\n    method: POST\n    body: '{\"method\": \"cert_show\", \"params\":[[\"{{ retrieve_cert_serialnumber|default(1) }}\"],{ \"version\": \"{{ api_version }}\" }],\"id\":0}'\n    body_format: json\n    validate_certs: no\n    return_content: yes\n    headers:\n      Cookie: \"{{ idm_session.set_cookie }}\"\n      referer: \"https://{{ idm_fqdn }}/ipa\"\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n  register: ca_cert\n\n- name: \"Error out if the request returned an error\"\n  fail:\n    msg: \"ERROR: request failed with message: {{ ca_cert.json.error.message }}\"\n  when:\n  - ca_cert.json.error is defined\n  - ca_cert.json.error.message is defined\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "6094a72d47ea15a0b611ea3f4362efa5dcd5b5c2", "filename": "roles/config-container-storage-setup/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "docker_dev: /dev/vdb\ndocker_vg: docker-vol\ndocker_data_size: 95%VG\ndocker_dm_basesize: \"3G\"\ncontainer_root_lv_name: dockerlv\ncontainer_root_lv_mount_path: /var/lib/docker\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "5bd938115643e05b30ae4126c69935aef7b231ca", "filename": "roles/ansible/tower/manage-job-templates/tasks/process-job-template.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Get the inventory id based on the inventory name\"\n  set_fact:\n    inventory_id: \"{{ item.id }}\"\n  when:\n  - item.name|trim == job_template.inventory|trim\n  with_items:\n  - \"{{ existing_inventories_output.rest_output }}\"\n\n- name: \"Get the project id based on the project name\"\n  set_fact:\n    project_id: \"{{ item.id }}\"\n  when:\n  - item.name|trim == job_template.project|trim\n  with_items:\n  - \"{{ existing_projects_output.rest_output }}\"\n\n- name: \"Get the credential id based on the credential name\"\n  set_fact:\n    credential_id: \"{{ item.id }}\"\n  when:\n  - item.name|trim == job_template.credential|trim\n  with_items:\n  - \"{{ existing_credentials_output.rest_output }}\"\n\n- name: \"Load up the job template\"\n  uri:\n    url: https://localhost/api/v2/job_templates/\n    method: POST\n    body: \"{{ lookup('template', 'job-template.j2') }}\"\n    body_format: 'json'\n    headers:\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n    user: admin\n    password: \"{{ tower_admin_password }}\"\n    validate_certs: no\n    status_code: 200,201,400\n\n# Utilize the `rest_get` library routine to ensure REST pagination is handled\n- name: \"Obtain the current roles\"\n  rest_get:\n    host_url: \"{{ tower_url }}\"\n    api_uri: \"/api/v2/roles/\"\n    rest_user: \"{{ tower_admin_username }}\"\n    rest_password: \"{{ tower_admin_password }}\"\n  register: existing_roles_output\n\n- name: \"Assign the Team(s) Permission(s)\"\n  vars:\n    permissions_object: \"teams\"\n    permissions_value: \"{{ team }}\"\n  include_tasks: set-permissions.yml\n  when:\n  - job_template.permissions is defined \n  - job_template.permissions.teams is defined\n  with_items:\n  - \"{{ job_template.permissions.teams }}\"\n  loop_control:\n    loop_var: team\n\n- name: \"Assign the User(s) Permission(s)\"\n  vars:\n    permissions_object: \"users\"\n    permissions_value: \"{{ user }}\"\n  include_tasks: set-permissions.yml\n  when:\n  - job_template.permissions is defined \n  - job_template.permissions.users is defined\n  with_items:\n  - \"{{ job_template.permissions.users }}\"\n  loop_control:\n    loop_var: user\n\n- name: \"Clear/Update facts\"\n  set_fact:\n    inventory_id: ''\n    project_id: ''\n    processed_job_templates: \"{{ processed_job_templates + [ {'name': job_template.name } ] }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "49a566b864c2cb9592f1aa9ab6358be98ef3a69d", "filename": "roles/httpd/files/html/services/power_off.php", "repository": "iiab/iiab", "decoded_content": "<?php\n\necho exec ( \"sudo poweroff\");\n\n?>\n"}, {"commit_sha": "f958689395b3fc98cacf0c605ed7b8b4b19718da", "sha": "947764fc5b0647f11059893932f39df2b3aa6b6f", "filename": "tasks/install_packages_apt.yml", "repository": "lae/ansible-role-netbox", "decoded_content": "---\n- name: Install required packages for selected NetBox configuration\n  apt:\n    name: \"{{ item }}\"\n    state: latest\n    cache_valid_time: 3600\n    update_cache: yes\n  with_items:\n    - \"{{ netbox_python3_packages if (netbox_python == 3) else netbox_python2_packages }}\"\n    - \"{{ netbox_packages }}\"\n    - \"{{ netbox_ldap_packages if netbox_ldap_enabled else [] }}\"\n    - \"{{ 'git' if netbox_git else [] }}\"\n    - \"{{ 'python-psycopg2' if (ansible_python_version | version_compare('3.0.0', '<')) else 'python3-psycopg2' }}\"\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "cd6f969e35c2640626898357735d10ebd98d4ef8", "filename": "playbooks/roles/bb0-openstack/provisioner-image/README.md", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "# STC OpenStack Provisioner\n\n## Build\n\n```\ndocker pull registry.access.redhat.com/rhel7/rhel\ndocker build \\\n    --build-arg RH_ORG_ID=$RHN_ORG_ID \\\n    --build-arg RH_ACTIVATIONKEY=$RHN_ACTIVATIONKEY \\\n    --build-arg RH_POOL_ID=$STC_SUBSCRIPTION_POOL_ID \\\n    -t quay.io/redhat/stc-openstack-provisioner:latest \\\n    .\n\ndocker tag quay.io/redhat/stc-openstack-provisioner:latest quay.io/redhat/stc-openstack-provisioner:$(docker run -ti quay.io/redhat/stc-openstack-provisioner:latest yum info openshift-ansible | grep Version | cut -f2 -d':'|tr -d ' '|tr -d '\\r')\n\ndocker push quay.io/redhat/stc-openstack-provisioner\n\n```\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "e4a6d54b6fc94ca92f3f33a2e80895d9fc872a7d", "filename": "playbooks/provision-bastion/README.md", "repository": "redhat-cop/infra-ansible", "decoded_content": "# Bastion Host / Control Host playbook\n\nThis playbook uses a variety of roles in this repo to setup a bastion host, also some times called a control host. The inventory can be used (per instructions below) to control which software and services get installed on the bastion host.\n\n\n## Prerequisites\nA running instance (VM or cloud image) such as Fedora, CentOS or Red Hat Enterprise Linux. The instance needs to be subscribed (if applicable) and configured with access to the necessary repos (in most cases, the exsisting repos / configuration is sufficient).\n\nIf the IdM / IPA integration is to be used, it is a prerequisites that the environment is set up with automatic client server discovery vis DNS SRV records (consult your sys admin if this is an unfamiliar area).\n\n## Gotcha's\n1. If running in a cloud environment, for example OpenStack, make sure to have the correct ports open in the security groups (e.g.: 5901 for VNC, 22 for SSH, etc.)\n2. When enabling VNC, and you already have a shared home directory, make sure the proper changes are made to the VNC configuration (typically in `~/.vnc` ) to allow for the service to run correctly.\n\n## Example run\nHow to run the playbook may depend on the options selected. However, below is an example execution whereas the password for IPA/IdM integration (with `ipa_client_install` set to `True` in the inventory) is passed in rather than statically set in the inventory. Modify the inventory to your liking in `playbooks/bastion/inventory`, then at the top level of the repository, execute the following command:\n\n```\n> ansible-playbook -i playbooks/bastion/inventory playbooks/bastion/install.yml -e 'ipa_password=<ipa/IdM password>'\n```\n\n**Note:** If your password contains any special characters, e.g.: a '!', it's important to use the single quotes for the passed in value as it otherwise may be interpereted by the shell.\n\n## Inventory Options\n\n**Note:** If you are intending to use the IdM/IPA integration, and are unfamiliar with the IdM/IPA variables below, please consult the IdM/IPA documentation or your sys admin for details.\n\n**Note:** When installing a GUI (i.e.: XFCE, LXDE, Gnome), it's recommended that only one is selected as running multiple is not supported nor tested by this playbook/roles.\n\n| variable | info |\n|:--------:|:----:|\n|main_user|The username this bastion is primerly being enabled for|\n|ipa_client_install|Set to `True` if you'd like to integrate with a backend IPA/IdM service|\n|ipa_domain|If `ipa_client_install` is set to `True`, set this to the existing IdM / IPA domain your environment uses (obtain from sys admin if not known)|\n|ipa_automount_location|If `ipa_client_install` is set to `True`, set the required automount location for home directories (obtain from sys admin if not known)|\n|ipa_username|If `ipa_client_install` is set to `True`, this is the username of an account that has the permission to join this host to the above IPA/IdM domain (obtain from sys admin if not known)|\n|ipa_password|If `ipa_client_install` is set to `True`, this is the password of an account that has the permission to join this host to the above IPA/IdM domain (obtain from sys admin if not known)\n|docker_install|Set to `True` if you'd like to enable docker on this host|\n|docker_username|Set to the desirable user (your username) to be added to the docker group (to allow for docker admin)|\n|docker_compose_install|Set to `True` if you'd like to have docker-compose installed on this host. NOTE: This will auto set docker_install=True (not supported on CentOS)|\n|xfce_install|Set to `True` if you'd like XFCE enabled on this host for a graphical UI (note MATE, XFCE or LXDE often works better than gnome for VNC)|\n|lxde_install|Set to `True` if you'd like LXDE enabled on this host for a graphical UI (note MATE, XFCE or LXDE often works better than gnome for VNC)|\n|gnome_install|Set to `True` if you'd like gnome enabled on this host for a graphical UI|\n|mate_install|Set to `True` if you'd like MATE Desktop enabled on this host for a graphical UI (note MATE, XFCE or LXDE often works better than gnome for VNC)|\n|vnc_server_install|Set to `True` if you'd like to enable a VNC server on this host for graphical access to the host|\n|list_of_packages_to_install|List of additional packages (RPMs) to be installed at the end of the bastion host preparation, e.g.: `['git', 'vim']`|\n|timezone| `Optional` Timezone of the Bastion ie `America/Denver`|\n|ansible_python_interpreter| `Optional` Required to be set to `/usr/bin/python3` when using systems like Fedora 28 where certain packages are dependent on python3|\n|vnc_password| `Optional` Set VNC password to a specific value instead of accepting the default| \n\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "3974dedaf4060386150be9c6844ad76f46abfafa", "filename": "roles/deploy/defaults/main.yml", "repository": "roots/trellis", "decoded_content": "# If you use the \"git\" strategy:\n# - you must set a repository (no default)\nproject_git_repo: \"{{ project.repo }}\"\n# - you can set the git ref to deploy (can be a branch, tag or commit hash)\nproject_version: \"{{ project.branch | default('master') }}\"\n\n# The source_path is used to fetch the tags from git, or synchronise via rsync. This way\n# you do not have to download/sync the entire project on every deploy\nproject_source_path: \"{{ project_root }}/shared/source\"\n\n# There are certain folders you'll want to copy from release to release to speed up deploys.\n# Examples: Composer's `vendor` folder, npm's `node_modules`.\n# These should not be part of project_shared_children since dependencies need to be atomic and tied to a deploy.\nproject_copy_folders:\n  - vendor\n\n# All the templates to process on the remote system on deploy. These could contain config files.\n# `src` and `dest` paths work the same as project_local_files.\nproject_templates:\n  - name: .env config\n    src: roles/deploy/templates/env.j2\n    dest: .env\n\n# The shared_children is a list of all files/folders in your project that need to be linked to a path in \"/shared\".\n# For example a sessions directory or an uploads folder. They are created if they don't exist, with the type\n# specified in the `type` key (file or directory).\n# Example:\n# project_shared_children:\n#   - path: \"app/sessions\"\n#     src: \"sessions\"\n#     mode: \"0755\"\n#     type: \"file\" / \"directory\"  // <- optional, defaults to \"directory\"\nproject_shared_children:\n  - path: web/app/uploads\n    src: uploads\n\n# The project_environment is a list of environment variables that can be used in hooks\n# Example:\n# project_environment:\n#   WP_ENV: \"production\"\nproject_environment:\n  WP_ENV: \"{{ env }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "24b6fe88a0ceb5dfb7a715f2eb3eebd9d26364cb", "filename": "roles/config-linux-desktop/config-xfce/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Install, configure and enable XFCE\"\n  include_tasks: \"{{ distro_file }}\"\n  with_first_found:\n  - files:\n    - xfce-{{ ansible_distribution }}.yml\n    skip: true\n  loop_control:\n    loop_var: distro_file\n  when:\n  - xfce_install|default(False)\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "2f48d68ea8d1e98a21111562713798fd9f7f7313", "filename": "roles/user-management/list-users-by-group/tasks/generate-list-of-users.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Populate list of users\"\n  set_fact:\n    list_of_users: \"{{ list_of_users | default([]) }} + [ {{ item }} ]\"\n  when:\n  - item.user_name in user_group.members\n  with_items:\n  - \"{{ users }}\"\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "3ace0b7c4dbeb3f49b8bfdb29ab734276173a3ca", "filename": "playbooks/provision-idm-server/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_playbook: ../prep.yml\n  when:\n  - rhsm_register|default(False)\n  tags:\n  - 'never'\n  - 'install'\n\n- import_playbook: ../osp/manage-user-network.yml\n  when:\n  - hosting_infrastructure == 'openstack'\n  tags:\n  - 'never'\n  - 'install'\n\n- import_playbook: ../osp/provision-osp-instance.yml\n  when:\n  - hosting_infrastructure == 'openstack'\n  tags:\n  - 'never'\n  - 'install'\n\n- import_playbook: ../rhsm.yml\n  tags:\n  - 'never'\n  - 'install'\n\n- import_playbook: setup-idm-dns.yml\n  tags:\n  - 'never'\n  - 'install'\n\n- hosts: idm-server\n  roles:\n  - role: update-host\n  tags:\n  - 'never'\n  - 'install'\n\n- import_playbook: configure-idm-server.yml\n  tags:\n  - 'always'\n"}, {"commit_sha": "ccab58ae5d697bb64abd86558f79c34161d2fb00", "sha": "2732fb26e03c950a482f3e207f4a3f77601150f6", "filename": "tasks/nexus_install.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n\n- name: Set detection method to fixed if we have a var\n  set_fact:\n    nexus_version_detected_from: fixed\n  when: nexus_version | length > 0\n\n- name: \"Check nexus-latest link stat in {{ nexus_installation_dir }}\"\n  stat:\n    path: \"{{ nexus_installation_dir }}/nexus-latest\"\n  register: nexus_latest_link\n  check_mode: no\n\n- name: Register current running version if any\n  set_fact:\n    nexus_version_running: >-\n      {{\n        nexus_latest_link.stat.lnk_target\n        | regex_replace('^.*/nexus-(\\d*\\.\\d*\\.\\d*-\\d*)', '\\1')\n      }}\n  when:\n    - nexus_latest_link.stat.exists | default(false)\n    - nexus_latest_link.stat.islnk | default(false)\n\n- name: No version given => Version detection\n  block:\n\n    - name: Register nexus_version from currently installed\n      # Note: setting nexus_version here skips the next block task.\n      set_fact:\n        nexus_version: \"{{ nexus_version_running }}\"\n        nexus_version_detected_from: installed\n      when:\n        - nexus_version_running is defined\n        - not (nexus_upgrade | default(false) | bool)\n\n    - name: Call latest nexus uri to get redirection\n      uri:\n        url: \"{{ nexus_download_url }}/latest-unix.tar.gz\"\n        method: CONNECT\n        status_code: 302\n        validate_certs: \"{{ nexus_download_ssl_verify | default(omit) }}\"\n      register: nexus_latest_uri_call\n      # No changes made, we only need the target uri. Safe for check mode and needed for next operations\n      check_mode: no\n\n    - name: Register nexus_version from latest nexus uri redirection\n      set_fact:\n        nexus_version: >-\n          {{\n            nexus_latest_uri_call.location\n            | regex_replace(\"^https://.*nexus-(\\d*\\.\\d*\\.\\d*-\\d*)-unix.tar.gz\", \"\\1\")\n          }}\n        nexus_version_detected_from: latest\n\n  when: nexus_version | length == 0\n\n- name: Print info about detected version to use\n  vars:\n    version_info: |-\n      Used version: {{ nexus_version }}\n      Version detected from: {{ nexus_version_detected_from }}\n      Upgrade allowed: {{ nexus_upgrade | default(false) | bool }}\n      Current running version: {{ nexus_version_running | default('none') }}\n  debug:\n    msg: \"{{ version_info.split('\\n') }}\"\n\n- name: Register nexus package name\n  set_fact:\n    nexus_package: \"nexus-{{ nexus_version }}-unix.tar.gz\"\n\n- name: Download nexus_package\n  get_url:\n    url: \"{{ nexus_download_url }}/{{ nexus_package }}\"\n    dest: \"{{ nexus_download_dir }}/{{ nexus_package }}\"\n    force: no\n    validate_certs: \"{{ nexus_download_ssl_verify | default(omit) }}\"\n  notify:\n    - nexus-service-stop\n\n- name: Ensure Nexus o/s group exists\n  group:\n    name: \"{{ nexus_os_group }}\"\n    state: present\n\n- name: Ensure Nexus o/s user exists\n  user:\n    name: \"{{ nexus_os_user }}\"\n    group: \"{{ nexus_os_group }}\"\n    home: \"{{ nexus_os_user_home_dir }}\"\n    shell: \"/bin/bash\"\n    state: present\n\n- name: Ensure Nexus installation directory exists\n  file:\n    path: \"{{ nexus_installation_dir }}\"\n    state: \"directory\"\n\n- name: Unpack Nexus download\n  unarchive:\n    src: \"{{ nexus_download_dir }}/{{ nexus_package }}\"\n    dest: \"{{ nexus_installation_dir }}\"\n    creates: \"{{ nexus_installation_dir }}/nexus-{{ nexus_version }}\"\n    force: no\n    copy: false\n  notify:\n    - nexus-service-stop\n\n- name: Ensure proper ownership of nexus installation directory\n  file:\n    path: \"{{ nexus_installation_dir }}/nexus-{{ nexus_version }}\"\n    recurse: yes\n    mode: \"u=rwX,g=rX,o=rX\"\n\n- name: Update symlink nexus-latest\n  file:\n    path: \"{{ nexus_installation_dir }}/nexus-latest\"\n    src: \"{{ nexus_installation_dir }}/nexus-{{ nexus_version }}\"\n    owner: \"{{ nexus_os_user }}\"\n    group: \"{{ nexus_os_group }}\"\n    state: link\n    follow: false\n  register: nexus_latest_version\n  notify:\n    - nexus-service-stop\n\n- meta: flush_handlers\n\n- name: Delete unpacked data directory\n  file:\n    path: \"{{ nexus_installation_dir }}/nexus-latest/data\"\n    state: absent\n\n- name: Get path to default settings\n  set_fact:\n    nexus_default_settings_file: \"{{ nexus_installation_dir }}/nexus-latest/etc/org.sonatype.nexus.cfg\"\n  when: nexus_version is version_compare('3.1.0', '<')\n\n- name: Get path to default settings\n  set_fact:\n    nexus_default_settings_file: \"{{ nexus_installation_dir }}/nexus-latest/etc/nexus-default.properties\"\n  when: nexus_version is version_compare('3.1.0', '>=')\n\n- name: Get application settings directories\n  set_fact:\n    nexus_app_dir_settings_dirs:\n      - \"{{ nexus_installation_dir }}/nexus-latest/etc\"\n  when: nexus_version is version_compare('3.1.0', '<')\n\n- name: Get application settings directories\n  set_fact:\n    nexus_app_dir_settings_dirs:\n      - \"{{ nexus_installation_dir }}/nexus-latest/etc\"\n      - \"{{ nexus_installation_dir }}/nexus-latest/etc/karaf\"\n      - \"{{ nexus_installation_dir }}/nexus-latest/etc/jetty\"\n      - \"{{ nexus_installation_dir }}/nexus-latest/etc/fabric\"\n      - \"{{ nexus_installation_dir }}/nexus-latest/etc/logback\"\n      - \"{{ nexus_installation_dir }}/nexus-latest/etc/scripts\"\n  when: nexus_version is version_compare('3.1.0', '>=')\n\n- name: Get rest API endpoint (v < 3.8.0)\n  set_fact:\n    nexus_rest_api_endpoint: \"service/siesta/rest/v1/script\"\n  when: nexus_version is version_compare('3.8.0', '<')\n\n- name: Get rest API endpoint (v >= 3.8.0)\n  set_fact:\n    nexus_rest_api_endpoint: \"service/rest/v1/script\"\n  when: nexus_version is version_compare('3.8.0', '>=')\n\n- name: Get path to database restore dir (v < 3.11.0)\n  set_fact:\n    nexus_db_restore_dir: \"{{ nexus_data_dir }}/backup\"\n  when: nexus_version is version_compare('3.11.0', '<')\n\n- name: Get path to database restore dir (v >= 3.11.0)\n  set_fact:\n    nexus_db_restore_dir: \"{{ nexus_data_dir }}/restore-from-backup\"\n  when: nexus_version is version_compare('3.11.0', '>=')\n\n- name: Allow nexus to create first-time install configuration files in  {{ nexus_installation_dir }}/nexus-latest/etc\n  file:\n    path: \"{{ item }}\"\n    state: \"directory\"\n    owner: \"{{ nexus_os_user }}\"\n    group: \"{{ nexus_os_group }}\"\n    mode: \"0755\"\n    recurse: false\n  with_items: \"{{ nexus_app_dir_settings_dirs }}\"\n  when: nexus_latest_version.changed\n  register: chown_config_first_time\n  tags:\n    # hard to run as a handler for time being\n    - skip_ansible_lint\n\n- name: Create Nexus data directory\n  file:\n    path: \"{{ nexus_data_dir }}\"\n    state: \"directory\"\n    owner: \"{{ nexus_os_user }}\"\n    group: \"{{ nexus_os_group }}\"\n\n- name: Setup Nexus data directory\n  lineinfile:\n    dest: \"{{ nexus_installation_dir }}/nexus-latest/bin/nexus.vmoptions\"\n    regexp: \"^-Dkaraf.data=.*\"\n    line: \"-Dkaraf.data={{ nexus_data_dir }}\"\n  notify:\n    - nexus-service-stop\n\n- name: Setup JVM logfile directory\n  lineinfile:\n    dest: \"{{ nexus_installation_dir }}/nexus-latest/bin/nexus.vmoptions\"\n    regexp: \"^-XX:LogFile=.*\"\n    line: \"-XX:LogFile={{ nexus_data_dir }}/log/jvm.log\"\n  notify:\n    - nexus-service-stop\n\n- name: Setup Nexus default timezone\n  lineinfile:\n    dest: \"{{ nexus_installation_dir }}/nexus-latest/bin/nexus.vmoptions\"\n    regexp: \"^-Duser.timezone=.*\"\n    line: \"-Duser.timezone={{ nexus_timezone }}\"\n  notify:\n    - nexus-service-stop\n\n- name: Setup Nexus JVM min heap size\n  lineinfile:\n    dest: \"{{ nexus_installation_dir }}/nexus-latest/bin/nexus.vmoptions\"\n    regexp: \"^-Xms.*\"\n    line: \"-Xms{{ nexus_min_heap_size }}\"\n  notify: nexus-service-stop\n\n- name: Setup Nexus JVM max heap size\n  lineinfile:\n    dest: \"{{ nexus_installation_dir }}/nexus-latest/bin/nexus.vmoptions\"\n    regexp: \"^-Xmx.*\"\n    line: \"-Xmx{{ nexus_max_heap_size }}\"\n  notify: nexus-service-stop\n\n- name: Setup Nexus JVM max direct memory\n  lineinfile:\n    dest: \"{{ nexus_installation_dir }}/nexus-latest/bin/nexus.vmoptions\"\n    regexp: \"^-XX:MaxDirectMemorySize=.*\"\n    line: \"-XX:MaxDirectMemorySize={{ nexus_max_direct_memory }}\"\n  notify: nexus-service-stop\n\n- name: Stop the admin wizard from running\n  lineinfile:\n    path: \"{{ nexus_default_settings_file }}\"\n    line: \"nexus.onboarding.enabled={{ nexus_onboarding_wizard }}\"\n    create: true\n  when: nexus_version is version_compare('3.17.0', '>=')\n\n- name: Create Nexus tmp directory\n  file:\n    path: \"{{ nexus_tmp_dir }}\"\n    state: \"directory\"\n    owner: \"{{ nexus_os_user }}\"\n    group: \"{{ nexus_os_group }}\"\n\n- name: Create Nexus backup directory\n  file:\n    path: \"{{ nexus_backup_dir }}\"\n    state: \"directory\"\n    owner: \"{{ nexus_os_user }}\"\n    group: \"{{ nexus_os_group }}\"\n  when: nexus_backup_dir_create | bool\n\n- name: Setup Nexus tmp directory\n  lineinfile:\n    dest: \"{{ nexus_installation_dir }}/nexus-latest/bin/nexus.vmoptions\"\n    regexp: \"^-Djava.io.tmpdir=.*\"\n    line: \"-Djava.io.tmpdir={{ nexus_tmp_dir }}\"\n  notify:\n    - nexus-service-stop\n\n- name: Set NEXUS_HOME for the service user\n  lineinfile:\n    dest: \"{{ nexus_os_user_home_dir }}/.bashrc\"\n    regexp: \"^export NEXUS_HOME=.*\"\n    line: \"export NEXUS_HOME={{ nexus_installation_dir }}/nexus-latest\"\n  notify:\n    - nexus-service-stop\n\n- name: Set nexus user\n  lineinfile:\n    dest: \"{{ nexus_installation_dir }}/nexus-latest/bin/nexus.rc\"\n    regexp: \".*run_as_user=.*\"\n    line: \"run_as_user=\\\"{{ nexus_os_user }}\\\"\"\n  notify:\n    - nexus-service-stop\n\n- name: Set nexus port\n  lineinfile:\n    dest: \"{{ nexus_default_settings_file }}\"\n    regexp: \"^application-port=.*\"\n    line: \"application-port={{ nexus_default_port }}\"\n  notify:\n    - nexus-service-stop\n\n- name: Set nexus context path\n  lineinfile:\n    dest: \"{{ nexus_default_settings_file }}\"\n    regexp: \"^nexus-context-path=.*\"\n    line: \"nexus-context-path={{ nexus_default_context_path }}\"\n  notify:\n    - nexus-service-stop\n\n- name: \"Set nexus service listening ip to {{ nexus_application_host }}\"\n  lineinfile:\n    dest: \"{{ nexus_default_settings_file }}\"\n    regexp: \"^application-host=.*\"\n    line: \"application-host={{ nexus_application_host }}\"\n  notify:\n    - nexus-service-stop\n\n- name: Create systemd service configuration\n  template:\n    src: \"nexus.service\"\n    dest: \"/etc/systemd/system\"\n  notify:\n    - systemd-reload\n  when: \"ansible_service_mgr == 'systemd'\"\n\n- name: Create sysv service configuration\n  file:\n    path: \"/etc/init.d/nexus\"\n    src: \"{{ nexus_installation_dir }}/nexus-latest/bin/nexus\"\n    state: link\n  when: \"ansible_service_mgr != 'systemd'\"\n\n- block:\n    - name: \"Deploy backup restore script\"\n      template:\n        src: \"nexus-blob-restore.sh.j2\"\n        dest: \"{{ nexus_script_dir }}/nexus-blob-restore.sh\"\n        mode: 0755\n    - name: \"Symlink backup restore script to /sbin\"\n      file:\n        src: \"{{ nexus_script_dir }}/nexus-blob-restore.sh\"\n        dest: \"/sbin/nexus-blob-restore.sh\"\n        state: link\n  when: nexus_backup_configure | bool\n\n- name: 'Check if data directory is empty (first-time install)'\n  command: \"ls {{ nexus_data_dir }}\"\n  register: nexus_data_dir_contents\n  check_mode: no\n  changed_when: false\n\n- name: Clean cache for upgrade process\n  file:\n    path: \"{{ nexus_data_dir }}/clean_cache\"\n    state: touch\n  when: nexus_latest_version.changed and nexus_data_dir_contents.stdout | length > 0\n  tags:\n    # hard to run as a handler for time being\n    - skip_ansible_lint\n\n- meta: flush_handlers\n\n- name: Enable nexus systemd service and make sure it is started\n  systemd:\n    name: nexus.service\n    enabled: yes\n    state: started\n    no_block: yes\n  notify:\n    - wait-for-nexus\n    - wait-for-nexus-port\n  when: \"ansible_service_mgr == 'systemd'\"\n\n- name: Enable nexus sysv service and make sure it is started\n  service:\n    name: nexus\n    enabled: yes\n    state: started\n  notify:\n    - wait-for-nexus\n    - wait-for-nexus-port\n  when: \"ansible_service_mgr != 'systemd'\"\n\n- meta: flush_handlers\n\n- name: Chown configuration files from {{ nexus_installation_dir }}/nexus-latest/etc back to root\n  file:\n    path: \"{{ nexus_installation_dir }}/nexus-latest/etc\"\n    owner: \"root\"\n    group: \"root\"\n    mode: a=rX,u+w\n    recurse: true\n  when: chown_config_first_time.changed\n  tags:\n    # hard to run as a handler for time being\n    - skip_ansible_lint\n\n- name: Prevent nexus to create any new configuration files in  {{ nexus_installation_dir }}/nexus-latest/etc\n  file:\n    path: \"{{ item }}\"\n    state: \"directory\"\n    owner: \"root\"\n    group: \"root\"\n    mode: \"0755\"\n    recurse: false\n  with_items: \"{{ nexus_app_dir_settings_dirs }}\"\n\n- name: Install plugins from remote source\n  get_url:\n    url: \"{{ item }}\"\n    dest: \"{{ nexus_installation_dir }}/nexus-{{ nexus_version }}/deploy/\"\n  with_items: \"{{ nexus_plugin_urls }}\"\n\n- name: Access scripts API endpoint with defined admin password\n  uri:\n    url: \"{{ nexus_api_scheme }}://{{ nexus_api_hostname }}:{{ nexus_api_port }}\\\n      {{ nexus_api_context_path }}{{ nexus_rest_api_endpoint }}\"\n    method: 'HEAD'\n    user: 'admin'\n    password: \"{{ nexus_admin_password }}\"\n    force_basic_auth: yes\n    status_code: 200, 401\n    validate_certs: \"{{ nexus_api_validate_certs }}\"\n  register: nexus_api_head_with_defined_password\n  check_mode: no\n\n- name: Register defined admin password for next operations\n  set_fact:\n    current_nexus_admin_password: \"{{ nexus_admin_password }}\"\n  when: nexus_api_head_with_defined_password.status == 200\n  no_log: true\n\n- name: Check if admin.password file exists\n  stat:\n    path: \"{{ nexus_data_dir }}/admin.password\"\n  register: admin_password_file\n\n- name: Get generated admin password from file (nexus >= 3.17)\n  when:\n    - admin_password_file.stat.exists\n    - nexus_api_head_with_defined_password.status == 401\n    - nexus_version is version_compare('3.17.0', '>=')\n  block:\n    - name: Slurp content of remote generated password file\n      slurp:\n        src: \"{{ nexus_data_dir }}/admin.password\"\n      register: _slurpedpass\n\n    - name: Set default password from slurped content\n      set_fact:\n        nexus_default_admin_password: \"{{ _slurpedpass.content | b64decode }}\"\n\n- name: Access scripts API endpoint with default admin password\n  uri:\n    url: \"{{ nexus_api_scheme }}://{{ nexus_api_hostname }}:{{ nexus_api_port }}\\\n      {{ nexus_api_context_path }}{{ nexus_rest_api_endpoint }}\"\n    method: 'HEAD'\n    user: 'admin'\n    password: \"{{ nexus_default_admin_password }}\"\n    force_basic_auth: yes\n    status_code: 200, 401\n    validate_certs: \"{{ nexus_api_validate_certs }}\"\n  register: nexus_api_head_with_default_password\n  when: nexus_api_head_with_defined_password.status == 401\n\n- name: Register default admin password for next operations\n  set_fact:\n    current_nexus_admin_password: \"{{ nexus_default_admin_password }}\"\n  when: (nexus_api_head_with_default_password.status | default(false)) == 200\n\n- name: Ensure current Nexus password is known\n  fail:\n    msg: >-\n      Failed to determine current Nexus password\n      (it is neither the default/generated nor the defined password).\n      If you are trying to change nexus_admin_password after first\n      install, please set `-e nexus_default_admin_password=oldPassword`\n      on the ansible-playbook command line.\n      See https://github.com/ansible-ThoTeam/nexus3-oss/blob/master/README.md#change-admin-password-after-first-install\n  when: current_nexus_admin_password is not defined\n\n- name: Force (re-)registration of groovy scripts (purge reference dir)\n  file:\n    path: \"{{ nexus_data_dir }}/groovy-raw-scripts\"\n    state: absent\n  when: nexus_force_groovy_scripts_registration | default(false)\n\n- name: Create directories to hold current groovy scripts for reference\n  file:\n    path: \"{{ item }}\"\n    state: directory\n    owner: root\n    group: root\n  with_items:\n    - \"{{ nexus_data_dir }}/groovy-raw-scripts/current\"\n    - \"{{ nexus_data_dir }}/groovy-raw-scripts/new\"\n\n- name: Archive scripts\n  become: no\n  archive:\n    path: \"{{ role_path }}/files/groovy/*\"\n    dest: \"/tmp/nexus-upload-groovy-scripts.tar.gz\"\n  run_once: true\n  delegate_to: localhost\n\n- name: Upload new scripts\n  unarchive:\n    src: \"/tmp/nexus-upload-groovy-scripts.tar.gz\"\n    dest: \"{{ nexus_data_dir }}/groovy-raw-scripts/new/\"\n\n- block:\n    - name: Sync new scripts to old and get differences\n      shell: >\n        set -o pipefail &&\n        rsync -ric {{ nexus_data_dir }}/groovy-raw-scripts/new/ {{ nexus_data_dir }}/groovy-raw-scripts/current/\n        | cut -d\" \" -f 2 | sed \"s/\\.groovy//g\"\n      register: nexus_groovy_files_changed\n      check_mode: no\n      changed_when: false\n      # simple check on changed files kept on host\n      # skip ansible lint (we don't want to use synchronize module for this)\n      args:\n        warn: false\n        executable: /bin/bash\n  rescue:\n    - name: Fail with information on rsync error\n      fail:\n        msg: >-\n          A task involving running rsync on the host just failed, most probably because rsync is not installed.\n          Please make sure rsync is installed on your host or double check the above error and try again.\n\n- name: Declare new or changed groovy scripts in nexus\n  include_tasks: declare_script_each.yml\n  with_items: \"{{ nexus_groovy_files_changed.stdout_lines }}\"\n\n- name: Change admin password if we are still using default\n  block:\n    - include_tasks: call_script.yml\n      vars:\n        script_name: update_admin_password\n        args:\n          new_password: \"{{ nexus_admin_password }}\"\n\n    - name: Admin password changed\n      set_fact:\n        current_nexus_admin_password: \"{{ nexus_admin_password }}\"\n      no_log: true\n\n    - name: Clear generated password file from install (nexus > 3.17)\n      file:\n        path: \"{{ nexus_data_dir }}/admin.password\"\n        state: absent\n      when: nexus_version is version_compare('3.17.0', '>=')\n\n  when: (nexus_api_head_with_default_password.status | default(false)) == 200\n"}, {"commit_sha": "0183b10864f53eb0cf3405fb2a3a92a07d573349", "sha": "ba9d553ba3951c9c90f4568ce3e811b9002e65bd", "filename": "meta/main.yml", "repository": "angstwad/docker.ubuntu", "decoded_content": "---\ngalaxy_info:\n  author: Paul Durivage\n  description: Docker on Ubuntu greater than 12.04\n  license: Apache v2.0\n  min_ansible_version: 1.2\n  platforms:\n    - name: Ubuntu\n      versions:\n        - precise\n        - raring\n        - saucy\n        - trusty\n  categories:\n    - development\n    - packaging\n    - system\ndependencies: []\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n  \n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "3516ab4a5fc191707ca388abb1c8ff91fa1efc8d", "filename": "playbooks/roles/check_sizing/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- shell: echo 'Currently CPU has {{ ansible_processor_vcpus }} vCPUs and memory is {{ (ansible_memory_mb.real.total / 1024) | round | int }} GBs. Node sizing is {{ node_vcpus }} for vCPUs, and {{ (node_mem / 1024) | round | int }} for memory.'\n  register: status_msg\n- debug: msg=\"{{ status_msg.stdout }}\"\n- fail:\n    msg: \"Not enough CPU cores or memory.\"\n  when: sizing == \"fixed\" and (((ansible_memory_mb.real.total / 1024) | round | int)<((node_mem / 1024) | round | int) or ansible_processor_vcpus<node_vcpus)\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "da8a681d11139e7fa3da2f54b966ba27542b6f0e", "filename": "playbooks/openshift/openstack/dns-records.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n- name: \"Start with a clean list of records\"\n  set_fact:\n    a_records: []\n    named_records: []\n\n- name: \"Set the DNS zone to use\"\n  set_fact:\n    nsupdate_zone: \"{{ nsupdate.zone | default(full_dns_domain) }}\"\n\n- name: \"Generate list of A records\"\n  set_fact:\n    a_records: \"{{ a_records | default([]) +\n                   [{\n                      'type': 'A',\n                      'hostname': (hostvars[item]['ansible_fqdn'] | replace('.' + nsupdate_zone, '')),\n                      'ip': hostvars[item][nsupdate.view + '_v4']\n                   }]\n                 }}\"\n  with_items:\n    - \"{{ groups['cluster_hosts'] }}\"\n\n- name: \"Add wildcard records to the A records for infrahosts\"\n  set_fact:\n    a_records: \"{{ a_records | default([]) +\n                   [{\n                      'type': 'A',\n                      'hostname': '*.' + (openshift_master_default_subdomain | replace('.' + nsupdate_zone, '')),\n                      'ip': hostvars[item][nsupdate.view + '_v4']\n                   }]\n                }}\"\n  when:\n    - openshift_master_default_subdomain is defined\n    - openshift_master_default_subdomain|trim != ''\n  with_items:\n    - \"{{ groups['infra_hosts'] }}\"\n\n- name: \"Set master ip to be used (single master)\"\n  set_fact:\n    master_ip: \"{{ hostvars[groups.masters[0]][nsupdate.view + '_v4'] }}\"\n  run_once: true\n  delegate_to: \"{{ groups['masters'] | first }}\"\n  when:\n    - (groups['masters'] | length == 1)\n\n- name: \"Set master ip to be used (multi master)\"\n  set_fact:\n    master_ip: \"{{ hostvars[groups.lb[0]][nsupdate.view + '_v4'] }}\"\n  run_once: true\n  delegate_to: \"{{ groups['masters'] | first }}\"\n  when:\n    - (groups['masters'] | length > 1)\n\n- name: \"Add public master cluster hostname records to the A records\"\n  set_fact:\n    a_records: \"{{ a_records | default([]) +\n                   [{\n                      'type': 'A',\n                      'hostname': (openshift_master_cluster_public_hostname | replace(nsupdate_zone, ''))[:-1],\n                      'ip': master_ip\n                   }]\n                }}\"\n  when:\n    - openshift_master_cluster_public_hostname is defined\n\n- name: \"Generate the Add section for DNS for all nsupdate servers\"\n  set_fact:\n    named_records: \"{{ named_records | default([]) +\n                       [{\n                          'view': nsupdate.view,\n                          'zone': nsupdate.zone,\n                          'server': item.server,\n                          'key_name': item.key_name,\n                          'key_secret': item.key_secret,\n                          'key_algorithm': (item.key_algorithm | lower),\n                          'entries': a_records\n                       }]\n                    }}\"\n  with_items:\n    - \"{{ nsupdate.server_list }}\"\n\n- name: \"Add to 'dns_records_add' list\"\n  set_fact:\n    dns_records_add: \"{{ dns_records_add | default([]) + named_records }}\"\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "066d9600ce992851f9be8eba5a45db07e496e98d", "filename": "roles/ssh_tunneling/handlers/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: restart ssh\n  service: name=\"{{ ssh_service_name|default('ssh') }}\" state=restarted\n"}, {"commit_sha": "4e46e9eb277bc88f285dbc9dd980193e57f7bf48", "sha": "0ea3f924ee1347e5611d3c715e01e9ffeb78d4e0", "filename": "tasks/setup-repository.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Ensure python and deps for Ansible modules\n  raw: dnf install -y python2 python2-dnf libselinux-python\n  become: true\n  changed_when: false\n  when: _docker_os_dist == \"Fedora\"\n\n- name: Update APT cache\n  apt:\n    update_cache: yes\n  changed_when: false\n  become: true\n  when: _docker_os_dist == \"Ubuntu\" or\n        _docker_os_dist == \"Debian\"\n\n- name: Ensure packages are installed for repository setup\n  package:\n    name: \"{{ item }}\"\n    state: present\n  with_items:\n    - \"{{ docker_repository_related_packages[_docker_os_dist] }}\"\n  become: true\n  when: _docker_os_dist == \"Ubuntu\" or\n        _docker_os_dist == \"Debian\" or\n        _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Add Docker official GPG key\n  apt_key:\n    url: https://download.docker.com/linux/{{ _docker_os_dist|lower }}/gpg\n    state: present\n  become: true\n  when: (_docker_os_dist == \"Ubuntu\" and _docker_os_dist_major_version > '14')\n        or _docker_os_dist == \"Debian\"\n\n- name: Add Docker APT key (alternative for older Ubuntu systems without SNI).\n  shell: \"curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\"\n  args:\n    warn: false\n  become: true\n  changed_when: false\n  when: _docker_os_dist == \"Ubuntu\" and\n        _docker_os_dist_major_version == '14'\n\n- name: Add Docker CE repository (Ubuntu/Debian)\n  apt_repository:\n    repo: deb [arch=amd64] https://download.docker.com/linux/{{ _docker_os_dist|lower }} {{ _docker_os_dist_release }} stable {{ (docker_enable_ce_edge == true) | ternary('edge','') }}\n    state: present\n    filename: 'docker-ce'\n  become: true\n  when: _docker_os_dist == \"Ubuntu\" or\n        _docker_os_dist == \"Debian\"\n\n- name: Add Docker CE repository (Fedora/CentOS/RedHat)\n  get_url:\n    url: \"{{ docker_repository_url[_docker_os_dist] }}\"\n    dest: /etc/yum.repos.d/docker-ce.repo\n    mode: 0644\n  become: true\n  register: docker_repo\n  when: _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"Fedora\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Determine Docker CE Edge repo status (Fedora/CentOS/RedHat)\n  shell: \"{{ docker_cmd_check_edge_repo_status[_docker_os_dist] }}\"\n  args:\n    warn: false\n  ignore_errors: yes\n  changed_when: false\n  register: cmd_docker_ce_edge_enabled\n  when: _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"Fedora\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Set current Docker CE Edge repo status fact (Fedora/CentOS/RedHat)\n  set_fact:\n    _fact_docker_ce_edge_enabled: \"{{ cmd_docker_ce_edge_enabled.stdout == 'enabled = True' }}\"\n  when: _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"Fedora\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Enable/Disable Docker CE Edge Repository (Fedora/CentOS/RedHat)\n  shell: \"{{ docker_cmd_enable_disable_edge_repo[_docker_os_dist] }}\"\n  become: true\n  when: (_docker_os_dist == \"CentOS\" or _docker_os_dist == \"Fedora\" or _docker_os_dist == \"RedHat\") and\n        _fact_docker_ce_edge_enabled != docker_enable_ce_edge\n        \n# disable rt-beta so we don't get a 403 error retrieving repomd.xml\n- name: Check if rhel-7-server-rt-beta-rpms Repository is enabled (RedHat)\n  shell: \"subscription-manager repos --list-enabled | grep rhel-7-server-rt-beta-rpms\"\n  become: true\n  register: cmd_rhel_rt_beta_repo_enabled\n  when: _docker_os_dist == \"RedHat\"\n  changed_when: false\n  failed_when: cmd_rhel_rt_beta_repo_enabled.rc not in [ 0, 1 ]\n\n- name: Disable rhel-7-server-rt-beta-rpms Repository (RedHat)\n  shell: \"subscription-manager repos --disable=rhel-7-server-rt-beta-rpms\"\n  become: true\n  when: _docker_os_dist == \"RedHat\" and cmd_rhel_rt_beta_repo_enabled.rc == 0\n\n# container-selinux package wants this\n- name: Check if rhel-7-server-extras-rpms Repository is enabled (RedHat)\n  shell: \"subscription-manager repos --list-enabled | grep rhel-7-server-extras-rpms\"\n  become: true\n  register: cmd_rhel_extras_repo_enabled\n  when: _docker_os_dist == \"RedHat\"\n  changed_when: false\n  failed_when: cmd_rhel_extras_repo_enabled.rc not in [ 0, 1 ]\n\n- name: Enable rhel-7-server-extras-rpms Repository (RedHat)\n  shell: \"subscription-manager repos --enable=rhel-7-server-extras-rpms\"\n  become: true\n  when: _docker_os_dist == \"RedHat\" and cmd_rhel_extras_repo_enabled.rc == 1\n\n- name: Update repository cache\n  shell: \"{{ docker_cmd_update_repo_cache[_docker_os_dist] }}\"\n  args:\n    warn: false\n  become: true\n  when: docker_repo.changed"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "8edc163c74d47a18ca4e54f1f1b91b807fea100f", "filename": "roles/config-httpd/tasks/prep.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Install required packages'\n  package:\n    name: '{{ item }}'\n    state: installed\n  with_items:\n  - httpd\n  - firewalld\n  - python-firewall\n\n- name: 'Ensure firewalld is running'\n  service:\n    name: firewalld\n    state: started \n    enabled: yes\n\n- name: 'Ensure httpd is running'\n  service:\n    name: httpd\n    state: started \n    enabled: yes\n\n- name: 'Open Firewall for httpd use'\n  firewalld: \n    port: \"{{ item }}\"\n    permanent: yes\n    state: enabled\n    immediate: yes\n  with_items:\n  - 80/tcp\n\n"}, {"commit_sha": "f92ebbef856e59bd4563d4b5b69ee75a95ec89d5", "sha": "6615146b08a7bcaa8b5b06fe4633507911c58c4d", "filename": "roles/openshift-management/tasks/prune-deployments.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- name: Prune Deployments\n  shell: oc adm prune deployments --keep-complete={{ openshift_prune_deployments_complete }}  --keep-failed={{ openshift_prune_deployments_failed }} --keep-younger-than={{ openshift_prune_deployments_keep_younger }} --orphans --confirm\n  environment:\n    KUBECONFIG: \"{{ kubeconfig }}\""}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "fe10fe604abe0e3b5a48e7fed20e1bd16df7137b", "filename": "archive/playbooks/openstack/terminate.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n# Use this to delete all OpenStack instances and their attached volumes matching a specified 'env_id'. \n#\n# Call it as such:\n#\n#            ansible-playbook terminate.yml -e \"env_id=testenv1\"\n\n- hosts: localhost\n  gather_facts: false\n  vars:\n    ansible_ssh_user: cloud-user\n    max_instances: 6\n    min_env_id_length: 8\n    really_really_sure: false\n    dry_run: false\n    force: false\n    prompt: true\n    uuid_regex: \"[[:alnum:]]{8}-[[:alnum:]]{4}-[[:alnum:]]{4}-[[:alnum:]]{4}-[[:alnum:]]{12}\"\n    newline: \"\\n\"\n  tasks:\n\n  - name: \"Set 'env_id' to 'uuid_regex' if override requested\"\n    set_fact:\n      env_id: \"{{ uuid_regex }}\"\n    when:\n      - env_id is not defined or env_id is none or env_id|trim == ''\n      - really_really_sure\n\n  - name: \"Verify environment ID was set\"\n    fail:\n      msg: \"No 'env_id' set, refusing to delete all instances and volumes, please provide a string to match via 'env_id'. Override with 'really_really_sure=true'\"\n    when: \n      - env_id is not defined or env_id is none or env_id|trim == ''\n      - not really_really_sure\n\n  - name: \"Verify environment ID is of sufficient length\"\n    fail:\n      msg: \"'env_id' is too short at only '{{ env_id|length }}' characters, risk of deleting too many instances. Override 'min_env_id_length' or with 'really_really_sure=true'\"\n    when: \n      - env_id|length < min_env_id_length|int\n      - not really_really_sure\n\n  - name: \"Verify connectivity to OpenStack\"\n    command: \"nova credentials\"\n    register: nova_result\n    failed_when: nova_result.rc != 0\n\n  - name: \"Determine number of matching instances\"\n    shell: nova list | grep -v \"ERROR\" | grep -E \"{{ env_id }}\" | awk '{print $2}' | sed ':a;N;$!ba;s/\\n/, /g'\n    register: instances_to_delete\n\n  - debug:\n      var:\n        instances_to_delete\n    when: dry_run\n\n  - name: \"Set instance count fact\"\n    set_fact:\n      instance_count: \"{{ instances_to_delete.stdout.split(', ')|length }}\"\n\n  - name: \"Fix instance count if list is empty\"\n    # Python counts an empty list as length 1, so fixing it if so\n    set_fact:\n      instance_count: 0\n    when:\n      - instances_to_delete.stdout.split(', ').0|trim == ''\n\n  - name: \"Determine if there are matching instances\"\n    fail:\n      msg: \"'{{ env_id }}' does not match any instances.\"\n    when:\n      - instance_count == 0\n      - not really_really_sure\n\n  - name: \"Verify environment ID does not match too many instances\"\n    fail:\n      msg: \"'{{ env_id }}' matches {{ instance_count|int }} instances, risk of deleting too many instances. Override 'max_instances' or with 'really_really_sure=true'\"\n    when: \n      - instance_count|int > max_instances|int\n      - not really_really_sure\n\n  - name: \"Determine instance names to delete\"\n    shell: nova list | grep -v \"ERROR\" | grep -E \"{{ env_id }}\" | awk '{print $4}' | sed ':a;N;$!ba;s/\\n/, /g'\n    register: names_to_delete\n\n  - debug:\n      var:\n        names_to_delete\n    when: dry_run\n\n  - name: \"Query Neutron services\"\n    command: neutron agent-list\n    register: neutron\n    ignore_errors: true\n\n  - name: \"Check for Neutron services - (a failure assumes Legacy Networking (Nova Network)\"\n    set_fact:\n      neutron_in_use: true\n    when: neutron.rc == 0\n\n  # There is a possibility of an instance not having a floating IP thus the extra sed to delete an empty field\n  - name: \"Determine list of public IPs\"\n    shell: nova list | grep -v \"ERROR\" | grep -E \"{{ env_id }}\" | awk '{print $13}' | sed '/|/d' | sed ':a;N;$!ba;s/\\n/, /g'\n    register: ips_to_delete\n\n  - name: \"Set IP count fact\"\n    set_fact:\n      ip_count: \"{{ ips_to_delete.stdout.split(', ')|length }}\"\n\n  - name: \"Fix IP count if list is empty\"\n    # Python counts an empty list as length 1, so fixing it if so\n    set_fact:\n      ip_count: 0\n    when:\n      - ips_to_delete.stdout.split(', ').0|trim == ''\n\n\n  - debug:\n      var:\n        ips_to_delete\n    when: dry_run\n\n  - name: \"Determine list of Neutron Floating IP IDs to delete\"\n    shell: for floatingip in $(echo {{ ips_to_delete.stdout }}  | sed -n 1'p' | tr ',' ' ' | while read ip; do echo ${ip}; done); do neutron floatingip-list | awk \"/${floatingip}/\"'{print $2}'; done | sed ':a;N;$!ba;s/\\n/, /g'\n    register: floatingips_to_delete\n    when: neutron_in_use is defined\n\n  - debug:\n      var:\n        floatingips_to_delete\n    when: dry_run\n\n  # It is possible for a volume to exist but not be attached possibly intentionally to save data, so adding an extra grep to ensure only in-use volumes are deleted. This is because the volume names are set the ID of the instance which is difficult to determine when it is attached or not by looking for an attached ID.\n  - name: \"Determine list of volumes\"\n    shell: for instance in $(echo {{ instances_to_delete.stdout }}  | sed -n 1'p' | tr ',' ' ' | while read id; do echo ${id}; done); do nova volume-list | grep \"in-use\" | awk \"/${instance}/\"'{print $2}'; done | sed ':a;N;$!ba;s/\\n/, /g'\n    register: volumes_to_delete\n\n  - debug:\n      var:\n        volumes_to_delete\n    when: dry_run\n\n  - name: \"Set Volume count fact\"\n    set_fact:\n      volume_count: \"{{ volumes_to_delete.stdout.split(', ')|length }}\"\n\n  - name: \"Fix Volume count if list is empty\"\n    # Python counts an empty list as length 1, so fixing it if so\n    set_fact:\n      volume_count: 0\n    when:\n      - volumes_to_delete.stdout.split(', ').0|trim == ''\n\n  - name: \"Determine images used in instances\"\n    shell: for instance in $(echo {{ instances_to_delete.stdout }}  | sed -n 1'p' | tr ',' ' ' | while read id; do echo ${id}; done); do nova show ${instance} | awk \"/image/\"'{print $4}'; done | sed ':a;N;$!ba;s/\\n/, /g'\n    register: images_to_delete\n\n  - debug:\n      var:\n        images_to_delete\n    when: dry_run\n\n  - name: \"Initialize image fact to first image found\"\n    set_fact:\n      image: \"{{ images_to_delete.stdout.split(', ').0 }}\"\n\n  - name: \"Determine if any instance uses a different image\"\n    set_fact:\n      images_differ: true\n    when: \"'{{ item }}' != image\"\n    with_items: images_to_delete.stdout.split(', ')\n\n  - name: \"Set Neutron Port ID fact\"\n    set_fact:\n      floatingips_to_delete:\n        stdout: \"Neutron not in use\"\n    when: neutron_in_use is undefined\n\n  - name: \"Warn if images are not unique\"\n    pause:\n      prompt: \"{{ newline }}\nWARNING! Images used for matching instances are not unique. It is possible that different users are required for SSH based on the image used. This can lead to some termination tasks such as subscription-manager not being executed successfully. It is recommended that each environment is deleted in batches of matching images.{{ newline }}\nProceed with caution.{{ newline }}{{ newline }}\n[Unique Images]{{':'}} '{{ images_to_delete.stdout.split(', ') | unique | join(', ') }}'{{ newline }}{{ newline }}\nPress ENTER to continue or CTRL+c to cancel\"\n    when:\n      - images_differ is defined\n      - prompt\n\n  - name: \"Build a group containing instance IPs\"\n    add_host:\n      hostname: \"{{ item }}\"\n      ansible_ssh_host: \"{{ item }}\"\n      ansible_ssh_user: \"{{ ansible_ssh_user }}\"\n      groups: instance_ips\n    with_items: \"ips_to_delete.stdout.split(', ')\"\n    when:\n      - item is defined\n      - item is not none\n      - item|trim != ''\n\n  - name: \"Set 'env_id' fact for display purposes if override requested\"\n    set_fact:\n      env_id: \"*\"\n    when:\n      - really_really_sure\n      - env_id == uuid_regex\n\n  - name: \"Pause for confirmation on normal run.\"\n    pause:\n      prompt: \"{{ newline }}\nWARNING! About to delete the following objects matching the environment ID '{{ env_id}}'{{':'}}{{ newline }}\n{{ instance_count|int }} instances, {{ ip_count|int }} IPs and {{ volume_count|int }} attached volumes{{':'}}{{ newline }}{{ newline }}\n[Instance IDs]{{':'}} '{{ instances_to_delete.stdout }}'{{ newline }}{{ newline }}\n[Instance Names]{{':'}} '{{ names_to_delete.stdout }}'{{ newline }}{{ newline }}\n[Instance IPs]{{':'}} '{{ ips_to_delete.stdout }}'{{ newline }}{{ newline }}\n[Floating IP IDs]{{':'}} '{{ floatingips_to_delete.stdout }}'{{ newline }}{{ newline }}\n[Attached Volumes]{{':'}} '{{ volumes_to_delete.stdout }}'{{ newline }}{{ newline }}\n[Unique Images]{{':'}} '{{ images_to_delete.stdout.split(', ') | unique | join(', ') }}'{{ newline }}{{ newline }}\nPress ENTER to delete these or CTRL+c to cancel\"\n    when:\n      - not dry_run\n      - prompt\n\n  - name: \"Pause for confirmation on dry run.\"\n    pause:\n      prompt: \"{{ newline }}\nNOTE{{':'}} A normal run would delete the following objects matching the environment ID '{{ env_id}}'{{':'}}{{ newline}}\n{{ instance_count|int }} instances, {{ ip_count|int }} IPs and {{ volume_count|int }} attached volumes{{':'}}{{ newline }}{{ newline }}\n[Instance IDs]{{':'}} '{{ instances_to_delete.stdout }}'{{ newline }}{{ newline }}\n[Instance Names]{{':'}} '{{ names_to_delete.stdout }}'{{ newline }}{{ newline }}\n[Instance IPs]{{':'}} '{{ ips_to_delete.stdout }}'{{ newline }}{{ newline }}\n[Floating IP IDs]{{':'}} '{{ floatingips_to_delete.stdout }}'{{ newline }}{{ newline }}\n[Attached Volumes]{{':'}} '{{ volumes_to_delete.stdout }}'{{ newline }}{{ newline }}\n[Unique Images]{{':'}} '{{ images_to_delete.stdout.split(', ') | unique | join(', ') }}'{{ newline }}{{ newline }}\nPress ENTER to view tasks that will be skipped or CTRL+c to cancel\"\n    when:\n      - dry_run\n      - prompt\n\n- hosts: instance_ips\n  gather_facts: false\n  vars:\n    ansible_sudo: true\n    dry_run: false\n    unregister: true\n  tasks:\n\n  - debug:\n      var: hostvars[inventory_hostname]\n    when: dry_run\n\n  - name: \"Attempt to unregister from Subscription Manager\"\n    command: \"subscription-manager unregister\"\n    ignore_errors: yes\n    when:\n      - not dry_run\n      - unregister\n\n- hosts: localhost\n  gather_facts: false\n  vars:\n    dry_run: false\n  tasks:\n\n  - name: \"Delete instance\"\n    command: \"nova delete {{ item }}\"\n    ignore_errors: yes\n    with_items: \"instances_to_delete.stdout.split(', ')\"\n    when:\n      - not dry_run\n      - item is defined\n      - item is not none\n      - item|trim != ''\n\n  - name: \"Wait for instance delete and volume detach\"\n    shell: nova volume-list | awk \"/{{ item }}/\"'{ print $4 }'\n    register: volume_check\n    until: volume_check.stdout != \"in-use\"\n    retries: 5\n    delay: 10\n    with_items: \"volumes_to_delete.stdout.split(', ')\"\n    when:\n      - not dry_run\n      - item is defined\n      - item is not none\n      - item|trim != ''\n\n  - name: \"Delete volume\"\n    command: \"nova volume-delete {{ item }}\"\n    ignore_errors: yes\n    with_items: \"volumes_to_delete.stdout.split(', ')\"\n    when:\n      - not dry_run\n      - item is defined\n      - item is not none\n      - item|trim != ''\n\n  - name: \"Release Neutron Floating IP\"\n    command: \"neutron floatingip-delete {{ item }}\"\n    ignore_errors: yes\n    with_items: \"floatingips_to_delete.stdout.split(', ')\"\n    when:\n      - not dry_run\n      - neutron_in_use is defined\n      - item is defined\n      - item is not none\n      - item|trim != ''\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "4f1aacd3f681189af6c8a97679ed4c6b233423ba", "filename": "roles/wordpress-setup/tasks/self-signed-certificate.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Generate self-signed certificates\n  shell: >\n    openssl req -subj \"/CN={{ item.value.site_hosts[0].canonical }}\" -new\n    -newkey rsa:2048 -days 3650 -nodes -x509 -sha256\n    -keyout {{ item.key }}.key -out {{ item.key }}.cert\n  args:\n    chdir: \"{{ nginx_path }}/ssl\"\n    creates: \"{{ item.key }}.*\"\n  with_dict: \"{{ wordpress_sites }}\"\n  when: item.value.ssl.enabled and item.value.ssl.provider | default('manual') == 'self-signed'\n  notify:\n    - reload nginx\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "1024f329ab13a1fe7409e6c18fb357183a3eb2fd", "filename": "tasks/section_10_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 10.1.1 Set Password Expiration Days (Scored)\n    lineinfile: >\n        dest='/etc/login.defs'\n        line='PASS_MAX_DAYS 90'\n        state=present\n        regexp='^PASS_MAX_DAYS'\n    tags:\n      - section10\n      - section10.1\n      - section10.1.1\n\n  - name: 10.1.2 Set Password Change Minimum Number of Days (Scored)\n    lineinfile: >\n        dest='/etc/login.defs'\n        line='PASS_MIN_DAYS 7'\n        regexp='^PASS_MIN_DAYS'\n    tags:\n      - section10\n      - section10.1\n      - section10.1.2\n\n  - name: 10.1.3 Set Password Expiring Warning Days (Scored)\n    lineinfile: >\n        dest='/etc/login.defs'\n        line='PASS_WARN_AGE'\n        regexp='^PASS_WARN_AGE'\n    tags:\n      - section10\n      - section10.1\n      - section10.1.3\n\n  - name: 10.2 Disable System Accounts (check) (Scored)\n    shell: awk -F':' '($1!=\"root\" && $1!=\"sync\" && $1!=\"shutdown\" &&$1!=\"halt\" && $3<500 && $7!=\"/usr/sbin/nologin\" && $7!=\"/bin/false\") {print $1}' /etc/passwd\n    register: awk_etc_passwd\n    changed_when: False\n    tags:\n      - section10\n      - section10.2\n\n  - name: 10.2 Disable System Accounts (Scored)\n    command: /usr/sbin/usermod -s /usr/sbin/nologin {{ item }}\n    with_items: awk_etc_passwd.stdout_lines\n    tags:\n      - section10\n      - section10.2\n\n  - name: 10.3 Set Default Group for root Account (Scored)\n    user: >\n        name=root\n        group=root\n    tags:\n      - section10\n      - section10.3\n\n  - name: 10.4 Set Default umask for Users (Scored)\n    lineinfile: >\n        dest=/etc/login.defs\n        line='UMASK\\t077'\n        regexp='^UMASK'\n        state=present\n    tags:\n      - section10\n      - section10.4\n\n  - name: 10.5 Lock Inactive User Accounts (check) (Scored)\n    command: grep INACTIVE /etc/login.defs\n    changed_when: False\n    failed_when: False\n    always_run: True\n    register: lock_inactive_rc\n    tags:\n      - section10\n      - section10.5\n        \n  - name: 10.5 Lock Inactive User Accounts (Scored)\n    lineinfile: >\n        dest=/etc/login.defs\n        line='INACTIVE=35'\n        state=present\n    when: lock_inactive_rc.rc == 1\n    tags:\n      - section10\n      - section10.5\n\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "3065896d31847159f850dc12da7368122ed9b919", "filename": "playbooks/roles/bb0-openstack/tasks/provisioning.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "---\n# tasks file for provisioning_openstack\n\n# - include_tasks: validate-parameters.yml\n\n# Just for informations: os_loadbalancer, os_listener, os_pool and os_member need Ansible 2.7.\n# And addional packages: python2-urllib3.noarch  python2-chardet.noarch\n# All thoses ansible modules use the openstack octavia lbaas API.\n\n\n\n- name: Create instance\n  os_server:\n    api_timeout: 360 # Because my lab is not so fast\n    state: present\n    auth:\n      auth_url: \"{{ lookup('env','OS_AUTH_URL') }}\"\n      project_name: \"{{ lookup('env','OS_PROJECT_NAME') }}\"\n      username: \"{{ lookup('env','OS_USERNAME') }}\"\n      password: \"{{ lookup('env','OS_PASSWORD') }}\"\n    name: \"{{ inventory_hostname }}\"\n    image: \"{{ iaas_image }}\"\n    flavor: \"{{ iaas_machine_size }}\"\n    auto_ip: \"{{ iaas_public_ip | default(false) }}\"\n    key_name: openshift-stc-key\n    security_groups: \"{{ os_security_groups }}\"\n    network: \"{{ iaas_internal_network }}\"\n    terminate_volume: true\n    boot_from_volume: true\n    userdata: |\n      #cloud-config\n      # set the locale\n      locale: en_US.UTF-8\n      # timezone: set the timezone for this instance\n      timezone: UTC\n      # hostname: {{ inventory_hostname }}\n      # fqdn: {{ inventory_hostname }}\n  register: return\n\n- name: Set some facts\n  set_fact:\n    instance_data: \"{{ return }}\"\n\n# - debug:\n#     var: instance_data\n\n# - debug: var=instance_data.openstack.private_v4\n# - debug: var=instance_data.openstack.public_v4\n\n\n- name: Create container storage disk\n  os_volume:\n    state: present\n    auth:\n      auth_url: \"{{ lookup('env','OS_AUTH_URL') }}\"\n      project_name: \"{{ lookup('env','OS_PROJECT_NAME') }}\"\n      username: \"{{ lookup('env','OS_USERNAME') }}\"\n      password: \"{{ lookup('env','OS_PASSWORD') }}\"\n    size: \"{{ iaas_container_storage_disk }}\"\n    display_name: \"{{ inventory_hostname }}_container_storage_disk\"\n  when: ( iaas_container_storage_disk | int > 0 )\n\n- name: Attach container storage disk to server\n  os_server_volume:\n    state: present\n    auth:\n      auth_url: \"{{ lookup('env','OS_AUTH_URL') }}\"\n      project_name: \"{{ lookup('env','OS_PROJECT_NAME') }}\"\n      username: \"{{ lookup('env','OS_USERNAME') }}\"\n      password: \"{{ lookup('env','OS_PASSWORD') }}\"\n    server: \"{{ inventory_hostname }}\"\n    volume: \"{{ inventory_hostname }}_container_storage_disk\"\n  when: ( iaas_container_storage_disk | int > 0 )\n  register: return\n\n# If I attach a disk to an server, it is important to reset the facts \n#    because to get the device name (/dev/vd?)\n- name: Set some facts\n  set_fact:\n    instance_data: \"{{ return }}\"\n  when: ( return.changed == true )\n\n- name: Create glusterfs disk\n  os_volume:\n    state: present\n    auth:\n      auth_url: \"{{ lookup('env','OS_AUTH_URL') }}\"\n      project_name: \"{{ lookup('env','OS_PROJECT_NAME') }}\"\n      username: \"{{ lookup('env','OS_USERNAME') }}\"\n      password: \"{{ lookup('env','OS_PASSWORD') }}\"\n    size: \"{{ iaas_glusterfs_disk }}\"\n    display_name: \"{{ inventory_hostname }}_glusterfs_disk\"\n  when: ( iaas_glusterfs_disk | int > 0 )\n\n- name: Attach glusterfs disk to server\n  os_server_volume:\n    state: present\n    auth:\n      auth_url: \"{{ lookup('env','OS_AUTH_URL') }}\"\n      project_name: \"{{ lookup('env','OS_PROJECT_NAME') }}\"\n      username: \"{{ lookup('env','OS_USERNAME') }}\"\n      password: \"{{ lookup('env','OS_PASSWORD') }}\"\n    server: \"{{ inventory_hostname }}\"\n    volume: \"{{ inventory_hostname }}_glusterfs_disk\"\n  when: ( iaas_glusterfs_disk | int > 0 )\n  register: return\n\n# If I attach a disk to an server, it is important to reset the facts \n#    because to get the device name (/dev/vd?)\n- name: Set some facts\n  set_fact:\n    instance_data: \"{{ return }}\"\n  when: ( return.changed == true )\n\n# - debug: var=instance_data.openstack.private_v4\n# - debug: var=instance_data.openstack.public_v4\n# - debug: var=instance_data.openstack.volumes\n\n- name: Set _container_storage_disk\n  set_fact:\n    container_storage_disk: \"{{ instance_data.openstack.volumes | selectattr('display_name','equalto',  inventory_hostname + '_container_storage_disk' ) | first }}\"\n  when: ( instance_data.openstack.volumes | selectattr('display_name','equalto', inventory_hostname + '_container_storage_disk' )| list | length > 0 )\n\n- name: Set glusterfs_disk\n  set_fact:\n    glusterfs_disk: \"{{ instance_data.openstack.volumes | selectattr('display_name','equalto', inventory_hostname + '_glusterfs_disk' ) | first }}\"\n  when: ( instance_data.openstack.volumes | selectattr('display_name','equalto', inventory_hostname + '_glusterfs_disk' )| list | length > 0 )\n\n- name: Set ansible_host if public ip is available\n  set_fact:\n    ansible_host: \"{{ instance_data.openstack.public_v4 }}\"\n    ansible_ssh_private_key_file: \"{{ playbook_dir }}/id_rsa\"\n    ansible_user: \"cloud-user\"\n  when: ( instance_data.openstack.public_v4 is defined and instance_data.openstack.public_v4 != \"\" )\n\n- include_tasks: provisioning-dns-{{ dns_provider }}.yml\n\n- include_tasks: provisioning-prepare-bastion.yml\n  when: ( inventory_hostname == 'bastion' ) \n\n- debug: \n    msg: \"Connect to bastion via ssh -i {{ ansible_ssh_private_key_file }} -l {{ ansible_user }} {{ bastion_public_hostname }}\"\n  when: ( inventory_hostname == 'bastion' )"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "9f7c8909eca483da83ebff2090ab5def5aab3b5d", "filename": "roles/osp/admin-image/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Create the image\"\n  os_image:\n    cloud: \"{{ item.cloud | default(osp_default_cloud) | default(omit) }}\"\n    filename: \"{{ item.filename }}\"\n    disk_format: \"{{ item.disk_format | default(omit) }}\"\n    is_public: \"{{ item.is_public | default(omit) }}\"\n    name: \"{{ item.name }}\"\n  with_items:\n  - \"{{ osp_images | default([]) }}\"\n"}, {"commit_sha": "1224adf2811c827a09ff0bf133fbb476901a547d", "sha": "5e3caef9204c63c07f638687fa38ac81774205e4", "filename": "handlers/main.yml", "repository": "nusenu/ansible-relayor", "decoded_content": "---\n- name: stop-and-mask default tor instance\n  become: yes\n  shell: systemctl stop tor@default && systemctl mask tor@default\n  when: ansible_pkg_mgr == 'apt'\n\n- name: restart apparmor\n  become: yes\n  service: name=apparmor state=restarted\n\n- name: systemctl daemon-reload\n  become: yes\n  command: systemctl daemon-reload\n\n- name: re-gather facts\n  setup:\n  when: ansible_pkg_mgr == 'dnf'\n\n- name: disable default tor instance FreeBSD\n  become: yes\n  lineinfile:\n    dest: /etc/rc.conf\n    line: \"tor_disable_default_instance=\\\"YES\\\"\"\n    create: yes\n  when: ansible_system == 'FreeBSD'\n\n# TODO: this reloads all instances on a FreeBSD host even if just one torrc changed\n- name: Ensure Tor instances are reloaded if its torrc changed (FreeBSD)\n  become: yes\n  service:\n    name: tor\n    state: reloaded\n  when: ansible_system == 'FreeBSD'\n\n- name: Ensure Tor instances are reloaded if its torrc changed (Linux)\n  become: yes\n  service:\n    name: \"tor@{{ item.item.0.ipv4 }}_{{ item.item.1.orport }}.service\"\n    state: reloaded\n  with_items: \"{{ instances.results }}\"\n  when: item.changed == True and ansible_system == 'Linux'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "59a01af41e732dc11c04e7b4c2b757be570d9cc3", "filename": "roles/setup-slack/tasks/get_channel_info.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Get channel info\n  uri:\n    url: \"https://slack.com/api/channels.list?token={{ slack_token }}\"\n    method: GET\n    status: [200]\n    return_content: yes\n  register: channel_data\n\n- name: Get group info\n  uri:\n    url: \"https://slack.com/api/groups.list?token={{ slack_token }}\"\n    method: GET\n    status: [200]\n    return_content: yes\n  register: group_data\n\n- name: Update channel mapping\n  with_items: \"{{ channel_data.json.channels }}\"\n  loop_control:\n    loop_var: channel\n  set_fact:\n    channel_mapping: \"{{ channel_mapping|combine({ channel.name: channel.id }) }}\"\n\n- name: Update group mapping\n  with_items: \"{{ group_data.json.groups }}\"\n  loop_control:\n    loop_var: group\n  set_fact:\n    channel_mapping: \"{{ channel_mapping|combine({ group.name: group.id }) }}\"\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "28b42be8eb4dac9a7c91bf9009a3a3c825a1c9f9", "filename": "roles/virt-install/tests/infrahosts.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Create VMs on infra hosts'\n  hosts: infra_hosts\n  roles:\n  - role: virt-install\n  tags:\n  - provision_infra_vms\n  \n- name: 'Check that the VMs are alive'\n  hosts: infra_vms\n  gather_facts: no\n  tasks:\n  - name: 'Wait for VMs to come alive'\n    local_action: wait_for\n      args: \n        host: \"{{ ansible_host }}\"\n        port: 22\n        delay: 30\n        timeout: 300\n  tags:\n  - vm_health_check\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "4e0eb5e94cd2c0d49a7e1d714f0569d0ab770e72", "filename": "roles/network/templates/named/named.ip6.local", "repository": "iiab/iiab", "decoded_content": "$TTL\t86400\n@       IN      SOA     localhost. root.localhost.  (\n                                      1997022700 ; Serial\n                                      28800      ; Refresh\n                                      14400      ; Retry\n                                      3600000    ; Expire\n                                      86400 )    ; Minimum\n       IN      NS      localhost.\n1      IN      PTR     localhost.\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "2b90dd3959d13f3a2854d91dd735b11bb91d08b4", "filename": "tasks/opensource/setup-debian.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: Debian/Ubuntu) Add NGINX Repository\"\n  apt_repository:\n    repo: \"{{ item }}\"\n  with_items:\n    - \"{{ nginx_repository.debian }}\"\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "b5d691868b56db98bde2048b162af52287cade69", "filename": "roles/ferm/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: ensure ferm status is in debconf\n  debconf:\n    name: ferm\n    question: ferm/enable\n    vtype: boolean\n    value: \"{{ ferm_enabled | lower }}\"\n\n- name: ensure ferm is installed\n  apt:\n    pkg: ferm\n    state: latest\n    update_cache: true\n    cache_valid_time: \"{{ apt_cache_valid_time }}\"\n    install_recommends: no\n  notify:\n    - restart ferm\n\n- name: ensure configuration directories exist\n  file:\n    path: \"{{ item }}\"\n    state: directory\n    mode: 0750\n  with_items:\n    - /etc/ferm/ferm.d\n    - /etc/ferm/filter-input.d\n\n- name: ensure firewall is configured\n  template:\n    src: \"{{ item }}.j2\"\n    dest: /{{ item }}\n  with_items:\n    - etc/default/ferm\n    - etc/ferm/ferm.conf\n  notify:\n    - restart ferm\n\n- name: ensure iptables INPUT rules are removed\n  file: state=absent\n        {% if item.filename is defined and item.filename %}\n        path=/etc/ferm/filter-input.d/{{ item.weight | default('50') }}_{{ item.filename }}.conf\n        {% else %}\n        path=/etc/ferm/filter-input.d/{{ item.weight | default('50') }}_{{ item.type }}_{{ item.dport[0] }}.conf\n        {% endif %}\n  with_flattened:\n    - \"{{ ferm_input_list }}\"\n    - \"{{ ferm_input_group_list }}\"\n    - \"{{ ferm_input_host_list }}\"\n  when: ((item.type is defined and item.type) and (item.dport is defined and item.dport)) and\n        (item.delete is defined and item.delete)\n\n- name: ensure iptables INPUT rules are added\n  template: src=etc/ferm/filter-input.d/{{ item.type }}.conf.j2\n            {% if item.filename is defined and item.filename %}\n            dest=/etc/ferm/filter-input.d/{{ item.weight | default('50') }}_{{ item.filename }}.conf\n            {% else %}\n            dest=/etc/ferm/filter-input.d/{{ item.weight | default('50') }}_{{ item.type }}_{{ item.dport[0] }}.conf\n            {% endif %}\n  with_flattened:\n    - \"{{ ferm_input_list }}\"\n    - \"{{ ferm_input_group_list }}\"\n    - \"{{ ferm_input_host_list }}\"\n  when: (item.type is defined and item.type and item.dport is defined and item.dport) and\n        (item.delete is undefined or (item.delete is defined and not item.delete))\n\n- name: ensure iptables rules are enabled\n  command: ferm --slow /etc/ferm/ferm.conf\n  changed_when: false\n  when: ferm_enabled\n\n- name: ensure iptables rules are disabled\n  command: ferm --flush /etc/ferm/ferm.conf\n  changed_when: false\n  when: not ferm_enabled\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "f17552026c999dde4742cdc0e93d6b6050907cda", "filename": "playbooks/update-dns-zones.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Update DNS zones'\n  hosts: dns-zones-manage-host\n  roles:\n  - role: dns/manage-dns-zones-bind\n  - role: dns/manage-dns-zones-route53\n  tags:\n  - update_dns_zones\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "6846aced61c8f72cf2fdfa991f4bfe05ee10aa75", "filename": "roles/config-minishift-remote/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Dependency Check\n  block:\n    - name: Check if Dependencies are installed\n      command: >\n        rpm -q {{ item }}\n      register: dependencies_installed\n      ignore_errors: yes\n      changed_when: false\n      loop: \"{{ minishift_dependencies }}\"\n  \n    - name: Fail if dependencies not installed\n      fail:\n        msg: \"{{ item.item }} is not installed\"\n      when: item.rc != 0\n      loop: \"{{ dependencies_installed.results }}\"\n  when: ansible_os_family == 'RedHat'\n\n# CentOS Fix for Red Hat Registry\n- name: Support Red Hat Registry on CentOS\n  become: yes\n  file:\n    path: /etc/rhsm/ca/redhat-uep.pem\n    state: touch\n  when: ansible_distribution == 'CentOS'\n\n- name: Create docker group\n  become: true\n  group:\n    name: \"{{ docker_group }}\"\n    state: present\n\n- name: Add user to Docker group\n  become: true\n  user:\n   name: \"{{ minishift_remote_user }}\"\n   groups: \"{{ docker_group }}\"\n   append: true\n  notify: Restart Docker\n\n- name: Flush handlers\n  meta: flush_handlers\n\n- name: Check is public key exists\n  stat:\n    path: \"{{ minishift_user_ssh_public_key_file }}\"\n  delegate_to: localhost\n  register: ssh_public_key_result\n\n- name: Fail if public key does not exist\n  fail:\n    msg: Public Key for Minishift user does not exist\n  when: not ssh_public_key_result.stat.exists\n\n- name: Add public SSH key to authorized keys file\n  authorized_key:\n    user: \"{{ minishift_remote_user }}\"\n    state: present\n    key: \"{{ lookup('file', minishift_user_ssh_public_key_file) }}\"\n\n- name: Open Firewall Ports\n  become: true\n  firewalld:\n    port: \"{{ item }}\"\n    permanent: yes\n    state: enabled\n    immediate: yes\n  loop: \"{{ minishift_firewalld_ports }}\"\n\n# Start Minishift\n- include_tasks: minishift_configure_start.yml\n  when: configure_start_minishift|bool"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "a6c182b07e6282124e8b6f1c24bcb0abe79100ba", "filename": "roles/config-postgresql/tasks/firewall.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Check if firewalld is installed\n  command: systemctl status firewalld\n  register: firewalld_status\n  failed_when: false\n  changed_when: false\n\n- name: Check if iptables is installed\n  command: systemctl status iptables\n  register: iptables_status\n  failed_when: false\n  changed_when: false\n\n- name: Open port in firewalld\n  firewalld:\n    port: \"{{ postgresql_port }}/tcp\"\n    permanent: true\n    state: enabled\n  when: firewalld_status.rc == 0\n  notify:\n  - restart firewalld\n\n- name: Ensure iptables is correctly configured\n  lineinfile:\n    insertafter: \"^-A INPUT .* --dport {{ postgresql_port }} .* ACCEPT\"\n    state: present\n    dest: /etc/sysconfig/iptables\n    regexp: \"^-A INPUT .* --dport {{ postgresql_port }} .* ACCEPT\"\n    line: \"-A INPUT -p TCP -m state --state NEW -m TCP --dport {{ postgresql_port }} -j ACCEPT\"\n  when: iptables_status.rc == 0 and firewalld_status.rc != 0\n  notify:\n  - restart iptables\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "0796fd9778618ff837ffa9a47405e3d12bdd6a8c", "filename": "tasks/unit/setup-redhat.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: CentOS/RedHat) Add NGINX Unit Repository\"\n  yum_repository:\n    name: unit\n    baseurl: https://packages.nginx.org/unit/{{ (ansible_distribution == \"RedHat\") | ternary('rhel/', 'centos/') }}$releasever/$basearch/\n    description: NGINX Unit Repository\n    enabled: yes\n    gpgcheck: yes\n  when: ansible_distribution != \"Amazon\"\n\n- name: \"(Install: Amazon Linux) Add NGINX Unit Repository\"\n  yum_repository:\n    name: unit\n    baseurl: https://packages.nginx.org/unit/amzn{{ (ansible_distribution_version == \"2\") | ternary('2', '') }}/$releasever/$basearch/\n    description: NGINX Unit Repository\n    enabled: yes\n    gpgcheck: yes\n  when: ansible_distribution == \"Amazon\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "86ba2c3f22e0e6537cf33ae56c10657587802bc1", "filename": "roles/3-base-server/meta/main.yml", "repository": "iiab/iiab", "decoded_content": "dependencies:\n   - { role: httpd, tags: ['services','httpd','base'] }\n   - { role: iiab-admin, tags: ['services','iiab-admin','base'] }\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "105ae3bedcce0752d1b1df27abc46a97059c9fe6", "filename": "tasks/create_repo_npm_hosted_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_npm_hosted\n    args: \"{{ _nexus_repos_npm_defaults|combine(item) }}\""}, {"commit_sha": "abafe1581c6c78d784cf215b214947675d49eff8", "sha": "9dcd122d997788a0d0a9aea7244f7aee308042ef", "filename": "roles/logging/handlers/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: restart rsyslog\n  service: name=rsyslog state=restarted\n\n- name: restart auditd\n  service: name=auditd state=restarted\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "036f98a30bcafddafd65c65d51d519ba468703a2", "filename": "roles/ssmtp/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Install ssmtp\n  apt:\n    name: ssmtp\n    state: present\n\n- name: ssmtp configuration\n  template:\n    src: ssmtp.conf.j2\n    dest: /etc/ssmtp/ssmtp.conf\n"}, {"commit_sha": "64cbc6946b7ebc0d9a36f40d77ac86f8e3564499", "sha": "01fa24175300127d47aed457a5f16ca2a4042e1b", "filename": "tasks/submit.yml", "repository": "CSCfi/ansible-role-slurm", "decoded_content": "---\n\n  - name: get munge key for distribution to nodes\n    copy: src=files/munge.key\n          dest=/etc/munge/munge.key\n          owner=munge\n          group=munge\n          mode=0400\n    notify:\n     - restart munge\n          \n  - name: start munge\n    service: name=munge state=started enabled=yes\n\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "0f3a2eb8ea71b53d507df6c9f099ab1a8224185b", "filename": "tasks/plus/setup-alpine.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: Alpine Linux) Add NGINX Plus Repository\"\n  lineinfile:\n    path: /etc/apk/repositories\n    insertafter: EOF\n    line: \"https://plus-pkgs.nginx.com/alpine/v{{ ansible_distribution_version | regex_search('^[0-9]+\\\\.[0-9]+') }}/main\"\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "233d96586ca783942b6b08369b69cb73c900dc2e", "filename": "roles/dns/manage-dns-zones/tasks/named/process-zones.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Ensure the view directory exists\n  file:\n    path: \"{{ dns_zone_temp_config_dir }}/{{ view.name }}\"\n    state: directory\n\n- name: Set server config facts\n  set_fact:\n    view_recursion: \"{{ view.named.recursion }}\"\n  when:\n    - view.named is defined\n    - view.named.recursion is defined\n\n- name: Prepare the view pre-zones content\n  vars:\n    view_name: \"{{ view.name }}\"\n    view_recursion: \"{{ view_recursion | default(dns_data.named_global_config.recursion) }}\"\n  template:\n    src: named/view-config-1.j2\n    dest: \"{{ dns_zone_temp_config_dir }}/{{ view.name }}/0001-{{ view.name }}.cfg\"\n    owner: named\n    group: named\n    mode: 0660\n  when:\n    - view.state|default('present') == 'present'\n\n- name: Initialize flags\n  set_fact:\n    processed_zones: False\n\n- include_tasks: process-one-zone.yml\n  with_items:\n    -  \"{{ view.zones }}\"\n  loop_control:\n    loop_var: \"zone\"\n\n- name: Prepare the view post-zones content\n  vars:\n    view_forwarders: \"{{ view.default_forwarders | default(['127.0.0.1']) }}\"\n  template:\n    src: named/view-config-2.j2\n    dest: \"{{ dns_zone_temp_config_dir }}/{{ view.name }}/0003-{{ view.name }}.cfg\"\n    owner: named\n    group: named\n    mode: 0660\n  when:\n    - processed_zones|bool == True\n    - view.state|default('present') == 'present'\n\n- name: Assemble the complete view file\n  assemble:\n    src: \"{{ dns_zone_temp_config_dir }}/{{ view.name }}\"\n    dest: \"{{ dns_zone_temp_config_dir }}/view/{{ view.name }}.cfg\"\n  when:\n    - processed_zones|bool == True\n    - view.state|default('present') == 'present'\n\n- name: Remove temporary view if no zones were processed\n  file:\n    path: \"{{ dns_zone_temp_config_dir }}/{{ view.name }}\"\n    state: absent\n  when:\n    - processed_zones|bool == False\n"}, {"commit_sha": "2f1ed84fec270723a1031cdc2b07b7a76a5a3bda", "sha": "74964eb09d06e31552a1b618cbd0a6e38dea15a6", "filename": "tasks/main.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n# tasks file for ansible-role-docker-ce\n\n- include: main-CentOS.yml\n  when: ansible_distribution == \"CentOS\" and ansible_distribution_major_version > '6'\n\n- include: main-Fedora.yml\n  when: ansible_distribution == \"Fedora\" and ansible_distribution_major_version > '23'\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "d8e4c92f0294b88b8abb4db37cb52d132e834e7e", "filename": "tasks/Linux/security_policy.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: 'Fetch oracle security policy with {{ java_unlimited_policy_transport }} transport'\n  include_tasks: '{{ transport_driver }}'\n  with_first_found:\n    - 'fetch/security-fetch/security-fetch-{{ java_unlimited_policy_transport }}.yml'\n    - 'fetch/unknown-transport.yml'\n  loop_control:\n    loop_var: transport_driver\n  when:\n    - java_unlimited_policy_enabled\n    - java_distribution == 'oracle_java'\n    - java_full_version is version('8.151', '<')\n\n- name: Become block\n  block:\n    - name: Unzip patch file\n      unarchive:\n        src: '{{ security_policy_java_artifact }}'\n        dest: '{{ java_path }}/{{ java_folder }}/jre/lib/security'\n        remote_src: true\n        owner: root\n        group: root\n        mode: 0755\n\n    - name: Apply patch file\n      copy:\n        src: \"{{ java_path }}/{{ java_folder }}/jre/lib/security/\\\n          {{ security_patch_folders[java_major_version|int] }}/{{ policy_item }}\"\n        dest: '{{ java_path }}/{{ java_folder }}/jre/lib/security/'\n        remote_src: true\n        directory_mode: true\n        owner: root\n        group: root\n        mode: 0644\n      loop:\n        - local_policy.jar\n        - US_export_policy.jar\n        - README.txt\n      loop_control:\n        loop_var: policy_item\n  when: java_full_version is version('8.151', '<')\n  become: true\n\n- name: Apply setting\n  replace:\n    path: '{{ java_path }}/{{ java_folder }}/jre/lib/security/java.security'\n    regexp: '#crypto.policy=unlimited'\n    replace: 'crypto.policy=unlimited'\n  when: java_major_version | int < 9\n  become: true\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "4021a1e3bc543caee9562fbc5195f01ca9741632", "filename": "roles/wp-cli/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Install WP-CLI\n  get_url:\n    url: \"{{ wp_cli_phar_url }}\"\n    dest: \"{{ wp_cli_bin_path }}\"\n    mode: 0755\n\n- name: Install WP-CLI tab completions\n  get_url:\n    url: \"{{ wp_cli_completion_url }}\"\n    dest: \"{{ wp_cli_completion_path }}\"\n    mode: 0644\n"}, {"commit_sha": "c33f3410e002f9d8506f0725f56b7d7afa1c5f74", "sha": "89e19bc7c1428de698b5348c56e03edc69645bc9", "filename": "tasks/main.yml", "repository": "jloh/nagios-nrpe-server", "decoded_content": "---\n# Nagios NRPE Server role by Mooash\n\n# Include variables at the start so they're in scope\n- name: Include OS-Specific variables\n  include_vars: \"{{ ansible_os_family }}.yml\"\n\n# Include RedHat specific variables due to x64/x86 differences\n- name: Include RedHat architecture specific variables\n  include_vars: \"{{ ansible_os_family }}-{{ ansible_architecture }}.yml\"\n  when: \"'{{ ansible_os_family }}' == 'RedHat'\"\n\n# Install our needed packages for each specific OS\n- include: \"packages-{{ ansible_os_family }}.yml\"\n\n# Create our config\n- name: Create nrpe.cfg from template\n  template: >\n    src=\"nrpe.cfg.j2\"\n    dest=\"{{ nagios_nrpe_server_dir }}/nrpe.cfg\"\n    owner=root group=root mode=0644\n  notify: restart nagios-nrpe-server\n\n# Create nrpe_ansible.cfg\n- name: Create nrpe_ansible.cfg from template\n  template: >\n    src=\"nrpe_ansible.cfg.j2\"\n    dest=\"{{ nagios_nrpe_server_dir }}/nrpe_ansible.cfg\"\n    owner=root group=root mode=0644\n  notify: restart nagios-nrpe-server\n\n# Sync our plugins\n- name: Install global plugins\n  copy: >\n    src=\"{{ item }}\"\n    dest=\"{{ nagios_nrpe_server_plugins_dir }}/\"\n    owner=root group=root mode=0755\n  with_fileglob:\n    - plugins/global/*\n\n# Install per-server plugins\n- name: Install per-server plugins\n  copy: >\n    src=\"{{ item }}\"\n    dest=\"{{ nagios_nrpe_server_plugins_dir }}/\"\n    owner=root group=root mode=0755\n  with_fileglob:\n    - \"plugins/{{ ansible_fqdn }}/*\"\n\n# Ensure NRPE server is running and will start at boot\n- name: Ensure NRPE server is running\n  service: name=\"{{ nagios_nrpe_server_service }}\" state=started enabled=yes\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "280137e10150a363ae48dedf34d351deede25a63", "filename": "roles/config-vlans/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: 'prereq.yml'\n- import_tasks: 'interfaces.yml'\n\n\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "17b3238062cb9748f788e7aea22bd5161a0b8eae", "filename": "playbooks/roles/bb0-openstack/handlers/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "---\n# handlers file for provisioning_openstack"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "7490dce015861ae02952fceb4985090782ccc06f", "filename": "roles/config-mysql/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nmode: containerized\n\n# Name of the database installation and service\n# (different from actual database name)\nmysql_name: mysql\nmysql_service: \"{{ mysql_name }}.service\"\n\n# Systemd\nsystemd_service_dir: /usr/lib/systemd/system\nsystemd_environmentfile_dir: /etc/sysconfig\n\n# MySQL\nmysql_image: registry.access.redhat.com/rhscl/mysql-57-rhel7:latest\nmysql_storage_dir: /var/lib/mysql\nmysql_container_storage_dir: /var/lib/mysql/data\nmysql_database: sampledb\nmysql_host_port: 3306\nmysql_container_port: 3306\nmysql_root_username: root\n\n# These Values will be randomaly generated if not defined\n#mysql_username: mysql\n#mysql_password: mysql\n#mysql_root_password: mysqlroot"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "e961cc0d2e933c2481b815280a0675a89fca8580", "filename": "playbooks/nagios/setup_nagios.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- name: \"Set up the nagios targets\"\n  hosts: nagios-targets\n  roles:\n  - role: infra-ansible/roles/nagios-target\n    \n- name: \"Set up nagios server\"\n  hosts: nagios-servers\n  roles:\n  - role: infra-ansible/roles/nagios-server\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "33a5388dae47d6190407fd717cf8827b70a72c65", "filename": "roles/2-common/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "\n- include: iiab_ini.yml\n\n# create the directory structure for XSCE\n- include: fl.yml\n\n- include: xo.yml\n  when: xo_model != \"none\" or osbuilder is defined\n\n- include: centos.yml\n  when: ansible_distribution == \"CentOS\"\n\n- include: fedora.yml\n  when: ansible_distribution == \"Fedora\"\n\n# the following installs common packages for both debian and fedora\n- include: packages.yml\n\n- sysctl: name=net.ipv4.ip_forward value=1 state=present\n- sysctl: name=net.ipv4.conf.default.rp_filter value=1 state=present\n- sysctl: name=net.ipv4.conf.default.accept_source_route value=0 state=present\n- sysctl: name=kernel.sysrq value=1 state=present\n- sysctl: name=kernel.core_uses_pid value=1 state=present\n- sysctl: name=net.ipv4.tcp_syncookies value=1 state=present\n- sysctl: name=kernel.shmmax value=268435456 state=present\n# IPv6 disabled\n- sysctl: name=net.ipv6.conf.all.disable_ipv6 value=1 state=present\n- sysctl: name=net.ipv6.conf.default.disable_ipv6 value=1 state=present\n- sysctl: name=net.ipv6.conf.lo.disable_ipv6 value=1 state=present\n\n- name: Set default Timezone\n  shell: ln -sf /usr/share/zoneinfo/{{ iiab_TZ }} /etc/localtime\n  when: iiab_TZ is defined and iiab_TZ != \"\"\n\n- name: Install custom profile file\n  template: dest=/etc/profile.d/zzz_iiab.sh\n            src=zzz_iiab.sh\n            owner=root\n            mode=0644\n            backup=no\n\n- include: net_mods.yml\n  when: not is_debuntu and not is_F18\n\n- include: udev.yml\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "0d247100d57ac2ee720dcf6af9f1d58015ea3acc", "filename": "tasks/configure-RedHat.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n\nhttpd_package_name: \"httpd\"\nhttpd_config_dir: \"/etc/{{ httpd_package_name }}/conf.d\"\ncertificate_file_dest: \"/etc/pki/tls/certs\"\ncertificate_key_dest: \"/etc/pki/tls/private\"\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "7844bd2937142407b5e7a9a5e744eb2c6c261828", "filename": "tasks/create_repo_nuget_group_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_nuget_group\n    args: \"{{ _nexus_repos_nuget_defaults|combine(item) }}\""}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "677d1f9caa2f6a3ea4f0694224993b7674c23fc8", "filename": "tasks/section_11.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - include: section_11_level1.yml\n    tags:\n      - section11\n      - level1\n\n"}, {"commit_sha": "836dc4dd0dacc490044a14c0e39469d162b9449b", "sha": "7d69804247d5aae61cd12459f21b0883d7f9a352", "filename": "tasks/section5.yml", "repository": "florianutz/Ubuntu1604-CIS", "decoded_content": "---\n- name: \"SCORED | 5.1.1 | PATCH | Ensure cron daemon is enabled\"\n  service:\n      name: \"{{ cron_service[ansible_os_family] }}\"\n      enabled: true\n  when:\n      - ubuntu1604cis_rule_5_1_1\n  tags:\n      - level1\n      - scored\n      - patch\n      - cron\n      - rule_5.1.1\n\n- name: \"SCORED | 5.1.2 | PATCH | Ensure permissions on /etc/crontab are configured\"\n  file:\n      dest: /etc/crontab\n      owner: root\n      group: root\n      mode: 0600\n  when:\n      - ubuntu1604cis_rule_5_1_2\n  tags:\n      - level1\n      - scored\n      - patch\n      - cron\n      - rule_5.1.2\n\n- name: \"SCORED | 5.1.3 | PATCH | Ensure permissions on /etc/cron.hourly are configured\"\n  file:\n      dest: /etc/cron.hourly\n      state: directory\n      owner: root\n      group: root\n      mode: 0700\n  when:\n      - ubuntu1604cis_rule_5_1_3\n  tags:\n      - level1\n      - scored\n      - patch\n      - cron\n      - rule_5.1.3\n\n- name: \"SCORED | 5.1.4 | PATCH | Ensure permissions on /etc/cron.daily are configured\"\n  file:\n      dest: /etc/cron.daily\n      state: directory\n      owner: root\n      group: root\n      mode: 0700\n  when:\n      - ubuntu1604cis_rule_5_1_4\n  tags:\n      - level1\n      - scored\n      - patch\n      - cron\n      - rule_5.1.4\n\n- name: \"SCORED | 5.1.5 | PATCH | Ensure permissions on /etc/cron.weekly are configured\"\n  file:\n      dest: /etc/cron.weekly\n      state: directory\n      owner: root\n      group: root\n      mode: 0700\n  when:\n      - ubuntu1604cis_rule_5_1_5\n  tags:\n      - level1\n      - scored\n      - patch\n      - cron\n      - rule_5.1.5\n\n- name: \"SCORED | 5.1.6 | PATCH | Ensure permissions on /etc/cron.monthly are configured\"\n  file:\n      dest: /etc/cron.monthly\n      state: directory\n      owner: root\n      group: root\n      mode: 0700\n  when:\n      - ubuntu1604cis_rule_5_1_6\n  tags:\n      - level1\n      - scored\n      - patch\n      - cron\n      - rule_5.1.6\n\n- name: \"SCORED | 5.1.7 | PATCH | Ensure permissions on /etc/cron.d are configured\"\n  file:\n      dest: /etc/cron.d\n      state: directory\n      owner: root\n      group: root\n      mode: 0700\n  when:\n      - ubuntu1604cis_rule_5_1_7\n  tags:\n      - level1\n      - scored\n      - patch\n      - cron\n      - rule_5.1.7\n\n- name: \"SCORED | 5.1.8 | PATCH | Ensure at/cron is restricted to authorized users\"\n  block:\n      - name: \"SCORED | 5.1.8 | PATCH | Ensure at/cron is restricted to authorized users\"\n        file:\n            dest: /etc/at.deny\n            state: absent\n\n      - name: \"SCORED | 5.1.8 | PATCH | Check if at.allow exists\"\n        stat:\n            path: \"/etc/at.allow\"\n        register: at_allow\n\n      - name: \"SCORED | 5.1.8 | PATCH | Ensure at/cron is restricted to authorized users\"\n        file:\n            dest: /etc/at.allow\n            state: '{{ \"file\" if  at_allow.stat.exists else \"touch\"}}'\n            owner: root\n            group: root\n            mode: 0600\n\n      - name: \"SCORED | 5.1.8 | PATCH | Ensure at/cron is restricted to authorized users\"\n        file:\n            dest: /etc/cron.deny\n            state: absent\n\n      - name: \"SCORED | 5.1.8 | PATCH | Check if cron.allow exists\"\n        stat:\n            path: \"/etc/cron.allow\"\n        register: cron_allow\n\n      - name: \"SCORED | 5.1.8 | PATCH | Ensure at/cron is restricted to authorized users\"\n        file:\n            dest: /etc/cron.allow\n            state: '{{ \"file\" if  cron_allow.stat.exists else \"touch\"}}'\n            owner: root\n            group: root\n            mode: 0600\n  when:\n      - ubuntu1604cis_rule_5_1_8\n  tags:\n      - level1\n      - scored\n      - patch\n      - cron\n      - rule_5.1.8\n\n- name: \"SCORED | 5.2.1 | PATCH | Ensure permissions on /etc/ssh/sshd_config are configured\"\n  file:\n      dest: /etc/ssh/sshd_config\n      state: file\n      owner: root\n      group: root\n      mode: 0600\n  when:\n      - ubuntu1604cis_rule_5_2_1\n  tags:\n      - level1\n      - scored\n      - patch\n      - sshd\n      - rule_5.2.1\n\n- name: \"SCORED | 5.2.2 | PATCH | Ensure SSH Protocol is set to 2\"\n  lineinfile:\n      state: present\n      dest: /etc/ssh/sshd_config\n      regexp: '^Protocol'\n      line: 'Protocol 2'\n  when:\n      - ubuntu1604cis_rule_5_2_2\n  tags:\n      - level1\n      - scored\n      - patch\n      - sshd\n      - rule_5.2.2\n\n- name: \"SCORED | 5.2.3 | PATCH | Ensure SSH LogLevel is set to INFO\"\n  lineinfile:\n      state: present\n      dest: /etc/ssh/sshd_config\n      regexp: '^LogLevel'\n      line: 'LogLevel INFO'\n  when:\n      - ubuntu1604cis_rule_5_2_3\n  tags:\n      - level1\n      - scored\n      - patch\n      - sshd\n      - rule_5.2.3\n\n- name: \"SCORED | 5.2.4 | PATCH | Ensure SSH X11 forwarding is disabled\"\n  lineinfile:\n      state: present\n      dest: /etc/ssh/sshd_config\n      regexp: '^X11Forwarding'\n      line: 'X11Forwarding no'\n  when:\n      - ubuntu1604cis_rule_5_2_4\n  tags:\n      - level1\n      - scored\n      - patch\n      - sshd\n      - rule_5.2.4\n\n- name: \"SCORED | 5.2.5 | PATCH | Ensure SSH MaxAuthTries is set to 4 or less\"\n  lineinfile:\n      state: present\n      dest: /etc/ssh/sshd_config\n      regexp: '^(#)?MaxAuthTries \\d'\n      line: 'MaxAuthTries 4'\n  when:\n      - ubuntu1604cis_rule_5_2_5\n  tags:\n      - level1\n      - scored\n      - patch\n      - sshd\n      - rule_5.2.5\n\n- name: \"SCORED | 5.2.6 | PATCH | Ensure SSH IgnoreRhosts is enabled\"\n  lineinfile:\n      state: present\n      dest: /etc/ssh/sshd_config\n      regexp: '^IgnoreRhosts'\n      line: 'IgnoreRhosts yes'\n  when:\n      - ubuntu1604cis_rule_5_2_6\n  tags:\n      - level1\n      - scored\n      - patch\n      - sshd\n      - rule_5.2.6\n\n- name: \"SCORED | 5.2.7 | PATCH | Ensure SSH HostbasedAuthentication is disabled\"\n  lineinfile:\n      state: present\n      dest: /etc/ssh/sshd_config\n      regexp: '^HostbasedAuthentication'\n      line: 'HostbasedAuthentication no'\n  when:\n      - ubuntu1604cis_rule_5_2_7\n  tags:\n      - level1\n      - scored\n      - patch\n      - sshd\n      - rule_5.2.7\n\n- name: \"SCORED | 5.2.8 | PATCH | Ensure SSH root login is disabled\"\n  lineinfile:\n      state: present\n      dest: /etc/ssh/sshd_config\n      regexp: '^PermitRootLogin'\n      line: 'PermitRootLogin no'\n  when:\n      - ubuntu1604cis_rule_5_2_8\n  tags:\n      - level1\n      - scored\n      - patch\n      - sshd\n      - rule_5.2.8\n\n- name: \"SCORED | 5.2.9 | PATCH | Ensure SSH PermitEmptyPasswords is disabled\"\n  lineinfile:\n      state: present\n      dest: /etc/ssh/sshd_config\n      regexp: '^PermitEmptyPasswords'\n      line: 'PermitEmptyPasswords no'\n  when:\n      - ubuntu1604cis_rule_5_2_9\n  tags:\n      - level1\n      - scored\n      - patch\n      - sshd\n      - rule_5.2.9\n\n- name: \"SCORED | 5.2.10 | PATCH | Ensure SSH PermitUserEnvironment is disabled\"\n  lineinfile:\n      state: present\n      dest: /etc/ssh/sshd_config\n      regexp: '^PermitUserEnvironment'\n      line: 'PermitUserEnvironment no'\n  when:\n      - ubuntu1604cis_rule_5_2_10\n  tags:\n      - level1\n      - scored\n      - patch\n      - sshd\n      - rule_5.2.10\n\n- name: \"SCORED | 5.2.11 | PATCH | Ensure only approved MAC algorithms are used\"\n  lineinfile:\n      state: present\n      dest: /etc/ssh/sshd_config\n      regexp: '^MACs'\n      line: 'MACs hmac-sha2-512-etm@openssh.com,hmac-sha2-256-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-512,hmac-sha2-256,umac-128@openssh.com'\n  when:\n      - ubuntu1604cis_rule_5_2_11\n  tags:\n      - level1\n      - scored\n      - patch\n      - sshd\n      - rule_5.2.11\n\n- name: \"SCORED | 5.2.12 | PATCH | Ensure SSH Idle Timeout Interval is configured\"\n  block:\n      - name: \"SCORED | 5.2.12 | PATCH | Ensure SSH Idle Timeout Interval is configured\"\n        lineinfile:\n            state: present\n            dest: /etc/ssh/sshd_config\n            regexp: '^ClientAliveInterval'\n            line: \"ClientAliveInterval {{ ubuntu1604cis_sshd['clientaliveinterval'] }}\"\n\n      - name: \"SCORED | 5.2.12 | PATCH | Ensure SSH ClientAliveCountMax set to <= 3\"\n        lineinfile:\n            state: present\n            dest: /etc/ssh/sshd_config\n            regexp: '^ClientAliveCountMax'\n            line: \"ClientAliveCountMax {{ ubuntu1604cis_sshd['clientalivecountmax'] }}\"\n  when:\n      - ubuntu1604cis_rule_5_2_12\n  tags:\n      - level1\n      - scored\n      - patch\n      - sshd\n      - rule_5.2.12\n\n- name: \"SCORED | 5.2.13 | PATCH | Ensure SSH LoginGraceTime is set to one minute or less\"\n  lineinfile:\n      state: present\n      dest: /etc/ssh/sshd_config\n      regexp: '^LoginGraceTime'\n      line: \"LoginGraceTime 60\"\n  when:\n      - ubuntu1604cis_rule_5_2_13\n  tags:\n      - level1\n      - scored\n      - patch\n      - sshd\n      - rule_5.2.13\n\n- name: \"SCORED | 5.2.14 | PATCH | Ensure SSH access is limited\"\n  block:\n      - name: \"SCORED | 5.2.14 | PATCH | Ensure SSH access is limited - allowusers\"\n        lineinfile:\n            state: present\n            dest: /etc/ssh/sshd_config\n            regexp: '^AllowUsers'\n            line: \"AllowUsers {{ ubuntu1604cis_sshd['allowusers'] }}\"\n        notify:\n            - restart sshd\n        when:\n            - \"ubuntu1604cis_sshd['allowusers']|default('') != ''\"\n\n      - name: \"SCORED | 5.2.14 | PATCH | Ensure SSH access is limited - allowgroups\"\n        lineinfile:\n            state: present\n            dest: /etc/ssh/sshd_config\n            regexp: '^AllowGroups'\n            line: \"AllowGroups {{ ubuntu1604cis_sshd['allowgroups'] }}\"\n        notify:\n            - restart sshd\n        when:\n            - \"ubuntu1604cis_sshd['allowgroups']|default('') != ''\"\n\n      - name: \"SCORED | 5.2.14 | PATCH | Ensure SSH access is limited - denyusers\"\n        lineinfile:\n            state: present\n            dest: /etc/ssh/sshd_config\n            regexp: '^DenyUsers'\n            line: \"DenyUsers {{ ubuntu1604cis_sshd['denyusers'] }}\"\n        notify:\n            - restart sshd\n        when:\n            - \"ubuntu1604cis_sshd['denyusers']|default('') != ''\"\n\n      - name: \"SCORED | 5.2.14 | PATCH | Ensure SSH access is limited - denygroups\"\n        lineinfile:\n            state: present\n            dest: /etc/ssh/sshd_config\n            regexp: '^DenyGroups'\n            line: \"DenyGroups {{ ubuntu1604cis_sshd['denygroups'] }}\"\n        notify:\n            - restart sshd\n        when:\n            - \"ubuntu1604cis_sshd['denygroups']|default('') != ''\"\n  when:\n      - ubuntu1604cis_rule_5_2_14\n  tags:\n      - level1\n      - scored\n      - patch\n      - sshd\n      - rule_5.2.14\n\n- name: \"SCORED | 5.2.15 | PATCH | Ensure SSH warning banner is configured\"\n  lineinfile:\n      state: present\n      dest: /etc/ssh/sshd_config\n      regexp: '^Banner'\n      line: 'Banner /etc/issue.net'\n  when:\n      - ubuntu1604cis_rule_5_2_15\n  tags:\n      - level1\n      - scored\n      - patch\n      - sshd\n      - rule_5.2.15\n\n- name: \"SCORED | 5.3.1 | PATCH | Ensure password creation requirements are configured\"\n  block:\n      - name: \"SCORED | 5.3.1 | PATCH | Ensure lipam-pwquality is installed\"\n        apt:\n            name: libpam-pwquality\n            state: present\n            install_recommends: false\n\n      - name: \"SCORED | 5.3.1 | PATCH | Ensure password creation requirements are configured\"\n        lineinfile:\n            state: present\n            dest: /etc/security/pwquality.conf\n            regexp: '^{{ item.key }}'\n            line: '{{ item.key }} = {{ item.value }}'\n        with_items:\n            - { key: 'minlen', value: '14' }\n            - { key: 'dcredit', value: '-1' }\n            - { key: 'ucredit', value: '-1' }\n            - { key: 'ocredit', value: '-1' }\n            - { key: 'lcredit', value: '-1' }\n  when:\n      - ubuntu1604cis_rule_5_3_1\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_5.3.1\n\n- name: \"SCORED | 5.3.2 | PATCH | Ensure lockout for failed password attempts is configured\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_5_3_2\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_5.3.2\n      - notimplemented\n\n- name: \"SCORED | 5.3.3 | PATCH | Ensure password reuse is limited\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_5_3_3\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_5.3.3\n      - notimplemented\n\n- name: \"SCORED | 5.3.4 | PATCH | Ensure password hashing algorithm is SHA-512\"\n  command: authconfig --passalgo=sha512 --update\n  changed_when: false\n  failed_when: false\n  when:\n      - ubuntu1604cis_rule_5_3_4\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_5.3.4\n\n- name: \"SCORED | 5.4.1.1 | PATCH | Ensure password expiration is 90 days or less\"\n  lineinfile:\n      state: present\n      dest: /etc/login.defs\n      regexp: '^PASS_MAX_DAYS'\n      line: \"PASS_MAX_DAYS {{ ubuntu1604cis_pass['max_days'] }}\"\n  when:\n      - ubuntu1604cis_rule_5_4_1_1\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_5.4.1.1\n\n- name: \"SCORED | 5.4.1.2 | PATCH | Ensure minimum days between password changes is 7 or more\"\n  lineinfile:\n      state: present\n      dest: /etc/login.defs\n      regexp: '^PASS_MIN_DAYS'\n      line: \"PASS_MIN_DAYS {{ ubuntu1604cis_pass['min_days'] }}\"\n  when:\n      - ubuntu1604cis_rule_5_4_1_2\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_5.4.1.2\n\n- name: \"SCORED | 5.4.1.3 | PATCH | Ensure password expiration warning days is 7 or more\"\n  lineinfile:\n      state: present\n      dest: /etc/login.defs\n      regexp: '^PASS_WARN_AGE'\n      line: \"PASS_WARN_AGE {{ ubuntu1604cis_pass['warn_age'] }}\"\n  when:\n      - ubuntu1604cis_rule_5_4_1_3\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_5.4.1.3\n\n- name: \"SCORED | 5.4.1.4 | PATCH | Ensure inactive password lock is 30 days or less\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_5_4_1_4\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_5.4.1.4\n      - notimplemented\n\n- name: \"SCORED | 5.4.2 | PATCH | Ensure system accounts are non-login\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_5_4_2\n  tags:\n      - level1\n      - patch\n      - rule_5.4.2\n      - notimplemented\n      - scored\n\n- name: \"SCORED | 5.4.3 | PATCH | Ensure default group for the root account is GID 0\"\n  command: usermod -g 0 root\n  changed_when: false\n  failed_when: false\n  when:\n      - ubuntu1604cis_rule_5_4_3\n  tags:\n      - level1\n      - patch\n      - rule_5.4.3\n      - scored\n\n- name: \"SCORED | 5.4.4 | PATCH | Ensure default user umask is 027 or more restrictive\"\n  block:\n\n      - name: \"SCORED | 5.4.4 | PATCH | Check if bashrc exists\"\n        stat:\n            path: \"/etc/bashrc\"\n        register: bashrc_present\n\n      - name: \"SCORED | 5.4.4 | PATCH | Ensure default user umask is 027 or more restrictive - /etc/bashrc\"\n        replace:\n            path: /etc/bashrc\n            regexp: '(^\\s+umask) 002'\n            replace: '\\1 027'\n        when: bashrc_present.stat.exists\n\n      - name: \"SCORED | 5.4.4 | PATCH | Ensure default user umask is 027 or more restrictive - /etc/profile\"\n        replace:\n            path: /etc/profile\n            regexp: '(^\\s+umask) 002'\n            replace: '\\1 027'\n  when:\n      - ubuntu1604cis_rule_5_4_4\n  tags:\n      - level1\n      - patch\n      - rule_5.4.4\n      - scored\n\n- name: \"NOTSCORED | 5.5 | PATCH | Ensure root login is restricted to system console\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_5_5\n  tags:\n      - level1\n      - patch\n      - rule_5.5\n      - notscored\n      - notimplemented\n\n- name: \"SCORED | 5.6 | PATCH | Ensure access to the su command is restricted\"\n  lineinfile:\n      state: present\n      dest: /etc/pam.d/su\n      regexp: '^(#)?auth\\s+required\\s+pam_wheel\\.so'\n      line: \"auth           required        pam_wheel.so use_uid\"\n  when:\n      - ubuntu1604cis_rule_5_6\n  tags:\n      - level1\n      - patch\n      - rule_5.6\n      - scored\n\n- name: \"SCORED | 5.6 | PATCH | Ensure access to the su command is restricted - wheel group contains root\"\n  user:\n      name: root\n      groups: wheel\n  when:\n      - ubuntu1604cis_rule_5_6\n  tags:\n      - level1\n      - patch\n      - rule_5.6\n      - scored\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "3b69c8386b006457e876b2f996f60a17db416e29", "filename": "roles/ansible/tower/config-ansible-tower/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: tower\n  roles:\n  - role: ansible/tower/config-ansible-tower\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "ed175524aaeab04f5f27250e33538cbf0d28249a", "filename": "roles/deploy/tasks/initialize.yml", "repository": "roots/trellis", "decoded_content": "---\n- include: \"{{ deploy_initialize_before | default('../hooks/example.yml') }}\"\n  tags: deploy-initialize-before\n\n- name: Initialize\n  deploy_helper:\n    current_path: \"{{ project_current_path }}\"\n    path: \"{{ project_root }}\"\n    state: present\n\n- include: \"{{ deploy_initialize_after | default('../hooks/example.yml') }}\"\n  tags: deploy-initialize-after\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "93f7bacd0a08310ab5a14c6e8f79c9f19c9fd1cf", "filename": "roles/ajenti/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Install python-pip package\n  package: name=python-pip\n           state=present\n\n- name: Install required libraries\n  package: name={{ item.pkg }}\n           state=present\n  with_items:\n    - pkg: python-imaging\n    - pkg: python-devel\n    - pkg: libxslt-devel\n    - pkg: pyOpenSSL\n    - pkg: python-daemon\n    - pkg: gcc\n\n- name: Install ajenti from our repo\n  pip: name=\"{{ iiab_download_url }}\"/ajenti-0.99.34-patched5.tar.gz\n  when: internet_available \n\n#  notify:\n#    - restart ajenti service\n\n- name: download python-catcher\n  pip: name=python-catcher version=0.1.3\n  when: internet_available \n\n- name: change default port\n  lineinfile: backup=yes\n              dest=/etc/ajenti/config.json\n              state=present\n              backrefs=yes\n              regexp='\"port\":\\s*[0-9]{1,5}'\n              line='\"port\":9990'\n\n- name: exe permission to ajenti\n  file: path=/etc/rc.d/init.d/ajenti\n        mode=0744\n        state=file\n\n- include: ajenti-wondershaper.yml\n  when: 'iiab_lan_iface != \"\"'\n\n# handler doesn't fire\n- name: restart ajenti service\n  service: name=ajenti\n           enabled=yes\n           state=restarted\n  when: ajenti_enabled\n\n- name: Add ajenti to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=ajenti\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: ajenti\n    - option: description\n      value: \"Ajenti is a client server systems administration tool controlled by a web browser\"\n    - option: enabled\n      value: \"{{ ajenti_enabled }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "6fd58ac7156bd395243a46d556dfb0be567e3802", "filename": "roles/config-versionlock/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Test versionlock of some packages\"\n  hosts: all\n  roles:\n  - role: config-versionlock \n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "3d99ba9623c719b9e97b36554886f566359b539c", "filename": "roles/config-minishift-remote/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Restart Docker\n  become: true\n  service:\n    name: docker\n    state: restarted"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "9b08d1705c9e3f39e686323628131b892c623656", "filename": "roles/dokuwiki/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Include the install playbook\n  include: install.yml\n  when: dokuwiki_install\n\n- name: Add dokuwiki to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=dokuwiki\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: dokuwiki\n    - option: description\n      value: '\"DokuWiki is a simple to use and highly versatile Open Source wiki software that does not require a database. \"'\n    - option: installed\n      value: \"{{ dokuwiki_install }}\"\n    - option: enabled\n      value: \"{{ dokuwiki_enabled }}\"\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "5b1eef96698f2936f1da6c44e5b76ee879109bfe", "filename": "roles/dockerbench/meta/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\ngalaxy_info:\n  author: Cam Parry\n  description:\n  company: Capgemini\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (MIT)\n  min_ansible_version: 1.2\n  min_docker_version: 1.6\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: Ubuntu\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n     - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies: []\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "8add78ffd0fe856720f3590a516105318b4a96b1", "filename": "roles/network/tasks/ifcfg_mods.yml", "repository": "iiab/iiab", "decoded_content": "- name: Stop the Access Point Hostapd program\n  service: name=hostapd.service\n           state=stopped\n  when: iiab_wireless_lan_iface != \"none\"\n\n# might need an exclude for F18 here\n- name: Now disconnect bridge slaves\n  shell: nmcli c delete id \"System {{ item|trim }}\"\n  ignore_errors: True\n  when: item|trim != iiab_wireless_lan_iface\n  with_items:\n    - \"{{ ifcfg_slaves.stdout_lines }}\"\n\n# clear all bridge ifcfg files\n- name: Now delete slave bridge ifcfg files\n  shell: rm -f /etc/sysconfig/network-scripts/ifcfg-\"{{ item }}\"\n  when: num_lan_interfaces != \"0\" or iiab_wireless_lan_iface != \"none\"\n  with_items:\n    - \"{{ ifcfg_slaves.stdout_lines }}\"\n\n- name: Now delete original ifcfg files\n  shell: rm -f /etc/sysconfig/network-scripts/ifcfg-\"{{ item }}\"\n  when: num_lan_interfaces == \"1\" and iiab_lan_iface != \"br0\"\n  with_items:\n    - \"{{ discovered_lan_iface }}\"\n\n- name: Stop the LAN/Bridge deleting iiab-LAN\n  shell: nmcli con delete id iiab-LAN\n  ignore_errors: True\n  changed_when: False\n  when: (num_lan_interfaces != \"0\" or iiab_wireless_lan_iface != \"none\")\n\n## vars/ users should set user_wan_iface to avoid messy redetect\n- include: redetect.yml\n  when: discovered_wan_iface == \"none\" and user_wan_iface == \"auto\"\n\n# move gateway if not WAN\n# might have wifi info if wireless is used as uplink.\n- include: edit_ifcfg.yml\n  when: has_wifi_gw == \"none\" and has_ifcfg_gw != \"none\" and has_ifcfg_gw != \"/etc/sysconfig/network-scripts/ifcfg-WAN\"\n\n# create ifcfg-WAN if missing\n# if we get here we have gateway but no ifcfg file\n- include: create_ifcfg.yml\n  when: iiab_wan_iface != \"none\" and not has_WAN and has_ifcfg_gw == \"none\" and xo_model == \"none\" and not iiab_demo_mode\n\n- name: Configuring LAN interface as iiab_lan_iface\n  template: src=network/ifcfg.j2\n            dest=/etc/sysconfig/network-scripts/ifcfg-LAN\n  when: iiab_lan_iface != \"none\"\n\n# can be more than one wired interface\n- name: Wired enslaving ## lan_list_result ## to Bridge\n  template: src=network/ifcfg-slave.j2\n            dest=/etc/sysconfig/network-scripts/ifcfg-{{ item|trim }}\n  when: iiab_lan_iface == \"br0\" and item|trim != iiab_wireless_lan_iface and item|trim != iiab_wan_iface\n  with_items:\n      - \"{{ lan_list_result.stdout_lines }}\"\n\n- name: WiFi enslaving {{ iiab_wireless_lan_iface }} to Bridge\n  template: src=network/wifi-slave.j2\n            dest=/etc/sysconfig/network-scripts/ifcfg-{{ iiab_wireless_lan_iface }}\n  when: iiab_lan_iface == \"br0\" and iiab_wireless_lan_iface != \"none\"\n  tags:\n    - network\n\n- include: enable_wan.yml\n  when: not installing and not iiab_demo_mode\n\n# monitor-connection-files defaults to no with F21, F18-F20 defaults to yes\n- name: Re-read network config files\n  shell: nmcli con reload\n  when: not installing and not no_NM_reload\n\n# test point, we should always have one with any kind of starting point\n# no ifcfg = supply\n# had but not WAN = rename and edit if wired, skip wifi gateway.\n# test point, confirm onboot=no is OK everywhere\n\n- name: Enabling pre-existing ifcfg-WAN file\n  shell: nmcli conn up id iiab-WAN\n  when: has_WAN and iiab_wan_iface != \"none\" and not installing and not iiab_demo_mode\n\n- name: Enabling ifcfg-LAN file\n  shell: nmcli conn up id iiab-LAN\n  ignore_errors: True\n  when: iiab_lan_iface != \"none\" and not installing and not iiab_demo_mode\n\n# we could do the DEVICE name stuff for a cleaner looking nmcli\n- name: Enabling ifcfg slaves\n  shell: nmcli conn up id \"System {{ item|trim }}\"\n  ignore_errors: True\n  when: iiab_lan_iface == \"br0\" and item|trim != iiab_wireless_lan_iface and item|trim != iiab_wan_iface and not iiab_demo_mode\n  with_items:\n      - \"{{ lan_list_result.stdout_lines }}\"\n\n# testpoint confirm with 'nmcli c show' 'brctl show'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "2828f2d58f7296885763b76cb40bb0d59d276e67", "filename": "roles/config-satellite/tasks/prereq.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Install required packages'\n  package:\n    name: '{{ item }}'\n    state: installed\n  with_items:\n  - satellite\n  - firewalld\n  - python-firewall\n\n- name: 'Ensure firewalld is running'\n  service:\n    name: firewalld\n    state: started\n    enabled: yes\n\n- name: 'Open Firewall for Satellite use'\n  firewalld:\n    service: \"{{ item }}\"\n    permanent: yes\n    state: enabled\n    immediate: yes\n  with_items:\n  - http\n  - https \n  - ssh\n\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "f49335b92676307b2917ed8ba5fc14918e277121", "filename": "tasks/Win32NT/fetch/security-fetch/security-winfetch-oracle-fallback.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Download security policy artifact from Oracle OTN\n  win_get_url:\n    url: '{{ fallback_oracle_security_policy_artifacts[java_major_version|int] }}'\n    dest: >-\n      {{ java_download_path }}\\{{ (fallback_oracle_security_policy_artifacts[java_major_version|int]\n        | urlsplit('path')).split('/')[-1] }}\n    headers:\n      Cookie: 'oraclelicense=accept-securebackup-cookie'\n    force: false\n  register: policy_file_downloaded\n  retries: 15\n  delay: 5\n  until: policy_file_downloaded is succeeded\n\n- name: Downloaded security policy artifact\n  set_fact:\n    security_policy_java_artifact: '{{ policy_file_downloaded.dest }}'\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "c081b7be4e5dd7fe132323bb4b5968b7e7a3a806", "filename": "archive/roles/cicd/tasks/maven.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n  \n- name: Install Maven\n  yum: \n    name: maven\n    enablerepo: rhel-7-server-optional-rpms \n    state: present\n  tags: maven\n  \n- name: Copy Maven Settings File\n  copy: \n    src: maven/settings.xml\n    dest: /usr/share/maven/conf/\n  tags: maven"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "f10179dfcc33832dd20bc239c9886885b112d500", "filename": "archive/roles/cicd/tasks/groovy.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n  \n- name: Download Groovy Artifact\n  get_url: \n    url: \"{{ groovy_url }}\"\n    dest: \"{{ groovy_local_archive }}\"\n  tags: groovy\n \n- name: Extract Groovy Artifact\n  unarchive: \n      src: \"{{ groovy_local_archive }}\"\n      dest: \"{{ groovy_base_dir }}\"\n      copy: no \n      creates: \"{{ groovy_install_dir }}\"\n  tags: groovy\n\n- name: Create Groovy Symbolic Link\n  file: \n      src: \"{{ groovy_install_dir }}\"\n      dest: \"{{ groovy_base_dir }}/groovy\"\n      state: link\n  tags: groovy\n\n- name: Add GROOVY_HOME Variable\n  lineinfile: \n    dest: /etc/profile \n    regexp: \"^export GROOVY_HOME=/usr/local/groovy-{{groovy_version}}\"\n    line: \"export GROOVY_HOME=/usr/local/groovy-{{groovy_version}}\"\n  tags: groovy\n  \n- name: Add GROOVY_HOME to PATH\n  lineinfile: \n    dest: /etc/profile\n    regexp: \"^export PATH=$PATH:$GROOVY_HOME/bin\"\n    line: \"export PATH=$PATH:$GROOVY_HOME/bin\"\n  tags: groovy"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "c916439a2c614bb7b4679386a29f9a05dca32833", "filename": "roles/config-nagios-target/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# Ensure all prerequisites are met\n- import_tasks: prerequisites.yml\n\n# Setup and prepare NRPE (Nagios Remote Plugin Executor)\n- import_tasks: nrpe.yml\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "a976221fb85a1a4effd6ace30e9c62adb01f0227", "filename": "playbooks/bb4/templates/config.j2", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "version: 0.1\nlog:\n  level: warn\n  fields:\n    service: registry\nstorage:\n    cache:\n        layerinfo: inmemory\n    filesystem:\n        rootdirectory: /var/lib/registry\nhttp:\n    addr: :{{registry.split(':')[1] }}\n    relativeurls: true\n    secret: {{registry_secret}}\n    tls:\n      certificate: /etc/docker-distribution/registry/cert.cert\n      key: /etc/docker-distribution/registry/cert.key\n      #clientcas: /etc/docker-distribution/registry/ca.cert\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "ade698001c475b94328cdb5f0b34fe82dcf94588", "filename": "roles/ansible/tower/manage-workflow-templates/tests/inventory/group_vars/tower.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nansible_tower:\n  admin_password: \"admin01\"\n  workflow_templates:\n  - name: \"Workflow 1\"\n    description: \"My Workflow 1\"\n    nodes:\n      - unified_job_template:\n          name: \"Job1\"\n        success_nodes:\n          - unified_job_template:\n              name: \"Job2\"\n          - unified_job_template:\n              name: \"Job3\"\n        failure_nodes:\n          - unified_job_template:\n              name: \"Job4\"\n          - unified_job_template:\n              name: \"Job5\"\n    permissions:\n      teams:\n        - name: team1\n          role: Execute\n      users:\n        - name: user1\n          role: Execute\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "e2bf004ec07cbe953c7c386f6848f304ac58f3b2", "filename": "tasks/setup_role_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: setup_role\n    args: \"{{ item }}\"\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "3a8b624ea05aea186008b3d2519e754f1c495dcd", "filename": "tasks/bug-tweaks/bug-centos7-resource-busy.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "- name: Stat /proc/sys/fs/may_detach_mounts (CentOS/RedHat)\n  stat:\n    path: /proc/sys/fs/may_detach_mounts\n  register: _may_detach_mounts\n  check_mode: no\n\n- name: Ensure fs.may_detach_mounts is set to avoid 'Device or resource busy' (CentOS/RedHat)\n  become: true\n  sysctl:\n    name: fs.may_detach_mounts\n    value: \"1\"\n    sysctl_file: /etc/sysctl.d/99-docker.conf\n    reload: yes\n  when:\n    - docker_enable_mount_flag_fix | bool\n    - _may_detach_mounts.stat.exists\n\n- name: Stat /etc/sysctl.d/99-docker.conf (CentOS/RedHat)\n  stat:\n    path: /etc/sysctl.d/99-docker.conf\n  register: _sysctl_docker\n  check_mode: no\n  when:\n    - not docker_enable_mount_flag_fix | bool\n\n- name: Unset fs.may_detach_mounts (CentOS/RedHat)\n  become: true\n  sysctl:\n    name: fs.may_detach_mounts\n    value: \"0\"\n    sysctl_file: /etc/sysctl.d/99-docker.conf\n    reload: yes\n  when:\n    - not docker_enable_mount_flag_fix | bool\n    - _sysctl_docker.stat.exists\n\n# Keep for compatibility reasons of this role. Now everything is in the same file.\n- name: Remove systemd drop-in for Docker Mount Flags slave configuration (CentOS/RedHat)\n  become: true\n  file:\n    path: /etc/systemd/system/docker.service.d/mountflags-slave.conf\n    state: absent\n  notify: restart docker\n\n- name: Set MountFlags option to \"slave\" to prevent \"device busy\" errors on CentOS/RedHat 7.3 kernels (CentOS/RedHat)\n  set_fact:\n    docker_systemd_service_config_tweaks: \"{{ docker_systemd_service_config_tweaks + \\\n      _systemd_service_config_tweaks }}\"\n  vars:\n    _systemd_service_config_tweaks:\n      - 'MountFlags=slave'\n  when:\n    - docker_enable_mount_flag_fix | bool\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "fb08fb607d83fc997ed459fec56a55b2f9ae8a5b", "filename": "tasks/conf/upload-config.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Setup: All NGINX) Ensure NGINX Main Directory Exists\"\n  file:\n    path: \"{{ nginx_main_upload_dest | default('/etc/nginx/') }}\"\n    state: directory\n  when: nginx_main_upload_enable | bool\n\n- name: \"(Setup: All NGINX) Upload NGINX Main Configuration File\"\n  copy:\n    src: \"{{ nginx_main_upload_src | default('conf/nginx.conf') }}\"\n    dest: \"{{ nginx_main_upload_dest | default('/etc/nginx/') }}\"\n    backup: yes\n  when: nginx_main_upload_enable | bool\n  notify: \"(Handler: All OSs) Reload NGINX\"\n\n- name: \"(Setup: All NGINX) Ensure NGINX HTTP Directory Exists\"\n  file:\n    path: \"{{ nginx_http_upload_dest | default('/etc/nginx/conf.d/') }}\"\n    state: directory\n  when: nginx_http_upload_enable | bool\n\n- name: \"(Setup: All NGINX) Upload NGINX HTTP Configuration Files\"\n  copy:\n    src: \"{{ item }}\"\n    dest: \"{{ nginx_http_upload_dest | default('/etc/nginx/conf.d/') }}\"\n    backup: yes\n  with_fileglob: \"{{ nginx_http_upload_src }}\"\n  when: nginx_http_upload_enable | bool\n  notify: \"(Handler: All OSs) Reload NGINX\"\n\n- name: \"(Setup: All NGINX) Ensure NGINX Stream Directory Exists\"\n  file:\n    path: \"{{ nginx_stream_upload_dest | default('/etc/nginx/conf.d/') }}\"\n    state: directory\n  when: nginx_stream_upload_enable | bool\n\n- name: \"(Setup: All NGINX) Upload NGINX Stream Configuration Files\"\n  copy:\n    src: \"{{ item }}\"\n    dest: \"{{ nginx_stream_upload_dest | default('/etc/nginx/conf.d/') }}\"\n    backup: yes\n  with_fileglob: \"{{ nginx_stream_upload_src }}\"\n  when: nginx_stream_upload_enable | bool\n  notify: \"(Handler: All OSs) Reload NGINX\"\n\n- name: \"(Setup: All NGINX) Ensure NGINX HTML Directory Exists\"\n  file:\n    path: \"{{ nginx_html_upload_dest | default('/usr/share/nginx/html') }}\"\n    state: directory\n  when: nginx_html_upload_enable | bool\n\n- name: \"(Setup: All NGINX) Upload NGINX HTML Files\"\n  copy:\n    src: \"{{ item }}\"\n    dest: \"{{ nginx_html_upload_dest | default('/usr/share/nginx/html') }}\"\n    backup: yes\n  with_fileglob: \"{{ nginx_html_upload_src }}\"\n  when: nginx_html_upload_enable | bool\n  notify: \"(Handler: All OSs) Reload NGINX\"\n\n- name: \"(Setup: All NGINX) Ensure SSL Certificate Directory Exists\"\n  file:\n    path: \"{{ nginx_ssl_crt_upload_dest | default('/etc/ssl/certs/') }}\"\n    state: directory\n  when: nginx_ssl_upload_enable | bool\n\n- name: \"(Setup: All NGINX) Ensure SSL Key Directory Exists\"\n  file:\n    path: \"{{ nginx_ssl_key_upload_dest | default('/etc/ssl/private/') }}\"\n    state: directory\n  when: nginx_ssl_upload_enable | bool\n\n- name: \"(Setup: All NGINX) Upload NGINX SSL Certificates\"\n  copy:\n    src: \"{{ item }}\"\n    dest: \"{{ nginx_ssl_crt_upload_dest | default('/etc/ssl/certs/') }}\"\n    mode: 0640\n    decrypt: yes\n    backup: yes\n  with_fileglob: \"{{ nginx_ssl_crt_upload_src }}\"\n  when: nginx_ssl_upload_enable | bool\n\n- name: \"(Setup: All NGINX) Upload NGINX SSL Keys\"\n  copy:\n    src: \"{{ item }}\"\n    dest: \"{{ nginx_ssl_key_upload_dest | default('/etc/ssl/private/') }}\"\n    mode: 0640\n    decrypt: yes\n    backup: yes\n  with_fileglob: \"{{ nginx_ssl_key_upload_src }}\"\n  when: nginx_ssl_upload_enable | bool\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "73438a60f9e784d678b42d2c551d487c2820402f", "filename": "roles/4-server-options/meta/main.yml", "repository": "iiab/iiab", "decoded_content": "dependencies:\n    - { role: sshd, tags: ['services','sshd','base'] }\n    - { role: network, tags: ['services','base','network'] }\n    - { role: postgresql, tags: ['services','postgresql','base'], when: postgresql_install }\n    - { role: authserver,  tags: ['services','authserver','base'], when: authserver_install }\n    - { role: openvpn, tags: ['options','openvpn'], when: openvpn_install }\n    - { role: samba, tags: ['services','samba','options'], when: samba_install }\n    - { role: usb-lib, tags: ['services','usb-lib','options'], when: usb_lib_install }\n    - { role: cups, tags: ['services','cups','options'], when: cups_install }\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "2ffbfa1e81ffee8948778a446f227631b4603e68", "filename": "roles/network/templates/squid/squid.sysconfig", "repository": "iiab/iiab", "decoded_content": "## XS Config override\n##\n## This file has an \".in\" template - for details see\n##  see /usr/share/doc/xs-config-<version>/README \n\n# default squid options\nSQUID_OPTS=\"\"\n\n# Time to wait for Squid to shut down when asked. Should not be necessary\n# most of the time.\nSQUID_SHUTDOWN_TIMEOUT=100\n\n# default squid conf file\nSQUID_CONF=\"/etc/squid/squid-iiab.conf\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "b318c173e39a815eaea6ee1d8b5c82a574df07cc", "filename": "roles/virt-install/tasks/create_vm.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Initialize Facts for VM deployments'\n  set_fact:\n   virt_install_commands: []\n   mounted_iso: {}\n\n- name: 'Gather the list of existing VMs'\n  command: virsh list --name\n  register: existing_vms\n\n- name: 'Compose Command for new VM provisioning'\n  include_tasks: 'virt-install.yml'\n  when:\n  - inventory_hostname == hostvars[vm]['infrahost']\n  - hostvars[vm]['libvirt_name'] not in existing_vms.stdout_lines\n  with_items:\n  - \"{{ groups['infra_vms'] }}\"\n  loop_control:\n    loop_var: vm\n\n- name: \"Call virt-install to create VMs\"\n  shell: \"{{ item }}\"\n  with_items: \"{{ virt_install_commands }}\"\n  register: vm_instances\n  async: 7200\n  poll: 0\n  when: virt_install_commands|length > 0\n\n- name: 'Wait for VMs creation to complete'\n  async_status: \n    jid: \"{{ item.ansible_job_id }}\"\n  register: vm_jobs\n  until: vm_jobs.finished\n  retries: 300\n  with_items: \"{{ vm_instances.results }}\"\n  when: virt_install_commands|length > 0\n\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "d12d6b7e80f21eafbed880441570d5c8afb1d813", "filename": "roles/haproxy-config/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: prereq.yml\n- import_tasks: haproxy-config.yml\n"}, {"commit_sha": "6fada6f2a7515ab18178ae350168c3de147c4dd0", "sha": "af5d141df51b1d56fa75fec5998a146a78054bad", "filename": "handlers/main.yml", "repository": "inkatze/wildfly", "decoded_content": "---\n# handlers file for wildfly\n\n- name: restart wildfly\n  service:\n    name: wildfly\n    state: restarted\n\n- name: change standalone data mode\n  file:\n    path: '{{ wildfly_dir }}/standalone/data'\n    owner: '{{ wildfly_user }}'\n    group: '{{ wildfly_group }}'\n    mode: '0750'\n    recurse: yes\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "06cbca65aa3c3836b3ae6b2bf4de39f3ab49459c", "filename": "roles/user-management/manage-atlassian-users/tasks/create_atlassian_users.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Create User\n  uri:\n    url: '{{ atlassian.url }}/rest/api/2/user'\n    method: POST\n    user: '{{ atlassian.username }}'\n    password: '{{ atlassian.password }}'\n    force_basic_auth: yes\n    status_code: 201\n    body_format: json\n    body: \"{'name': '{{ atlassian_user.email.split(\\\"@\\\") | first }}', \n            'password': '{{ atlassian_user.password }}', \n            'emailAddress': '{{ atlassian_user.email }}', \n            'displayName': '{{ atlassian_user.firstname }} {{ atlassian_user.lastname }}' }\"\n    return_content: yes\n  register: user_data\n  when: \n    - atlassian_user.state|default('present') == 'present'"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "87b1b315af90c8eb674c99a5b1c3a8a2303f760a", "filename": "roles/osm/templates/map.html", "repository": "iiab/iiab", "decoded_content": "<!DOCTYPE html>\n<html>\n    <head>\n        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no\" />\n        <link rel=\"stylesheet\" href=\"lib/leaflet/leaflet.css\" />\n        <link rel=\"stylesheet\" href=\"lib/leaflet/geosearch/l.geosearch.css\" />\n\n        <style type=\"text/css\">\n            body {\n                padding: 0;\n                margin: 0;\n            }\n            html, body, #map {\n                height: 100%;\n            }\n        </style>\n\n        <script type=\"text/javascript\">\n        // Required for Firefox 3.6\n        if (!Function.prototype.bind) {\n          Function.prototype.bind = function (oThis) {\n            if (typeof this !== \"function\") {\n              // closest thing possible to the ECMAScript 5 internal IsCallable function\n              throw new TypeError(\"Function.prototype.bind - what is trying to be bound is not callable\");\n            }\n\n            var aArgs = Array.prototype.slice.call(arguments, 1),\n                fToBind = this,\n                fNOP = function () {},\n                fBound = function () {\n                  return fToBind.apply(this instanceof fNOP && oThis\n                                         ? this\n                                         : oThis,\n                                       aArgs.concat(Array.prototype.slice.call(arguments)));\n                };\n\n            fNOP.prototype = this.prototype;\n            fBound.prototype = new fNOP();\n\n            return fBound;\n          };\n        }\n        </script>\n\n        <script src=\"lib/jquery-1.9.0.js\"></script>\n        <script src=\"lib/leaflet/leaflet.js\"></script>\n        <script src=\"lib/leaflet/geosearch/l.control.geosearch.js\"></script>\n        <script src=\"lib/leaflet/geosearch/l.geosearch.provider.iiab.js\"></script>\n\n        <script type=\"text/javascript\">\n            $(function () {\n                var map = L.map('map'); /*.setView([51.505, -0.09], 14);*/\n                L.tileLayer('/iiab/maps/tile/{z}/{x}/{y}.png', {\n                    attribution: 'Map data &copy; <a href=\"http://openstreetmap.org\">OpenStreetMap</a> contributors, <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">CC-BY-SA</a>',\n                    maxZoom: 15\n                }).addTo(map);\n\n                var geoOptions = {\n                    provider: new L.GeoSearch.Provider.iiab(),\n                    searchLabel: \"Search by City Name...\",\n                    notFoundMessage: \"No matches found\",\n                    zoomLevel: 8,\n                    maxMarkers: 10,\n                    maxResultCount: 15,\n                    enableAutocomplete: true,\n                    enableButtons: true\n                };\n                new L.Control.GeoSearch(geoOptions).addTo(map);\n\n                map.fitWorld().setZoom(3);  // default world view\n                //map.locate({setView: true, maxZoom: 15});\n            });\n        </script>\n    </head>\n    <body>\n        <div id=\"map\"></div>\n\n    </body>\n</html>\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "3fb0ab1b666b26e9f74250d4cdeddd82d88a47e0", "filename": "playbooks/subscribe-host.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# Example run (localhost needed to source username/password with \"prep.yml\") \n# > ansible-playbook -i <inventory> subscribe-host.yml -l \"myhosts,localhost\" \n\n- import_playbook: \"prep.yml\"\n- import_playbook: \"rhsm.yml\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "3672ce2385dbf7d06d0ff5c873ca8a2a3eb7dc86", "filename": "playbooks/provision-satellite-server/README.md", "repository": "redhat-cop/infra-ansible", "decoded_content": "# Satellite Server Playbook\n\nThis playbook directory has the playbook(s) necessary to manage your Satellite server(s).\n\n## Prerequisites\n\nOne of the two:\n- a set of running instance(s)\n- a IaaS that allow for provisioning through these playbooks\n\n\n## Example\n\n### Inventory\n\nPlease see the **sample** inventory in the inventory area:\n\n- [satellite-server](../../inventory/satellite-server/README.md)\n\nYou will need to modify this sample inventory to fit your desired configuration.\n\n### Playbook execution\n\nDepending on how this is being hosted, the initial may need the `tags='install'` set to ensure all necessary software is installed:\n\n```bash\n> ansible-playbook -i inventory main.yml --tags='install'\n```\n\nAny consecutive runs can be done without the 'install' tag to speed up execution:\n```bash\n> ansible-playbook -i inventory main.yml\n```\n\nLicense\n-------\n\nApache License 2.0\n\n\nAuthor Information\n------------------\n\nRed Hat Community of Practice & staff of the Red Hat Open Innovation Labs.\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "78c487ec8514120759c55e24da8f8ae28ac3749e", "filename": "roles/weave/vars/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# vars file for weave\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "1c821320d6b581ca5eb7aa537541cb1513736e7a", "filename": "roles/sshd/defaults/main.yml", "repository": "roots/trellis", "decoded_content": "---\nsshd_port: 22\nsshd_listen_address: 0.0.0.0\nsshd_protocol: 2\nsshd_host_rsa_key: /etc/ssh/ssh_host_rsa_key\nsshd_host_dsa_key: /etc/ssh/ssh_host_dsa_key\nsshd_host_ecdsa_key: /etc/ssh/ssh_host_ecdsa_key\nsshd_use_privilege_separation: true\nsshd_key_regeneration_interval: 3600\nsshd_server_key_bits: 768\nsshd_syslog_facility: AUTH\nsshd_log_level: INFO\nsshd_login_grace_time: 120\nsshd_permit_root_login: true\nsshd_strict_modes: true\nsshd_rsa_authentication: true\nsshd_pubkey_authentication: true\nsshd_authorized_keys_file: \"%h/.ssh/authorized_keys\"\nsshd_ignore_rhosts: true\nsshd_rhosts_rsa_authentication: false\nsshd_host_based_authentication: false\nsshd_ignore_user_known_hosts: false\nsshd_permit_empty_passwords: false\nsshd_challenge_response_authentication: false\nsshd_password_authentication: false\nsshd_gss_api_authentication: false\nsshd_gss_api_cleanup_credentials: true\nsshd_x11_forwarding: true\nsshd_x11_display_offset: 10\nsshd_print_motd: false\nsshd_print_last_log: true\nsshd_tcp_keep_alive: true\nsshd_max_startups: 10:30:100\nsshd_banner: none\nsshd_accept_env: LANG LC_*\nsshd_subsystem: sftp /usr/lib/openssh/sftp-server\nsshd_use_pam: true\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "053a471b6806f28c6be2853139a478b9f2c0db65", "filename": "roles/config-hostname/tasks/main.yaml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- block:\n  - import_tasks: prep.yml\n  - import_tasks: set-hostname.yml\n  become: True\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "c704e1cc4f6227fb3d60cfcc4deefe369dcfaea9", "filename": "playbooks/provision-nfs-server/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- import_playbook: ../prep.yml\n  when:\n  - rhsm_register|default(False)\n  tags:\n  - 'never'\n  - 'install'\n\n- import_playbook: ../osp/manage-user-network.yml\n  when:\n  - hosting_infrastructure == 'openstack'\n  tags:\n  - 'never'\n  - 'install'\n\n- import_playbook: ../osp/provision-osp-instance.yml\n  when:\n  - hosting_infrastructure == 'openstack'\n  tags:\n  - 'never'\n  - 'install'\n\n- import_playbook: ../rhsm.yml\n  tags:\n  - 'never'\n  - 'install'\n\n- import_playbook: nfs-server.yml\n  tags:\n  - 'always'\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "43d64bc66005ca64dd42badf7e70aac76879f4ea", "filename": "tasks/admin_password_setup.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: update_admin_password\n    args:\n      new_password: \"{{ nexus_admin_password }}\"\n\n- name: Admin password changed\n  set_fact:\n    current_nexus_admin_password: \"{{ nexus_admin_password }}\"\n  no_log: true"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "f4ba5e8f1f4bae31d5f9bd2f19fbd4bd15059746", "filename": "roles/config-ipa-client/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Configure the host for IPA/IdM use'\n  hosts: all\n  roles:\n  - role: config-ipa-client\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "e11ff2ade241f86f101252abb1c443a7d778cf3f", "filename": "roles/letsencrypt/tasks/nginx.yml", "repository": "roots/trellis", "decoded_content": "- name: Check for existing certificates\n  stat:\n    path: \"{{ letsencrypt_certs_dir }}/{{ item.key }}.cert\"\n  register: letsencrypt_existing_certs\n  when: site_uses_letsencrypt\n  with_dict: \"{{ wordpress_sites }}\"\n\n- name: Create Nginx sites for challenges\n  template:\n    src: nginx-challenge-site.conf.j2\n    dest: \"{{ nginx_path }}/sites-available/letsencrypt-{{ item.item.key }}.conf\"\n  when: not item | skipped and not item.stat.exists\n  with_items: \"{{ letsencrypt_existing_certs.results }}\"\n\n- name: Enable Nginx site\n  file:\n    src: \"{{ nginx_path }}/sites-available/letsencrypt-{{ item.item.key }}.conf\"\n    dest: \"{{ nginx_path }}/sites-enabled/letsencrypt-{{ item.item.key }}.conf\"\n    state: link\n  when: not item | skipped and not item.stat.exists\n  with_items: \"{{ letsencrypt_existing_certs.results }}\"\n\n- name: Trigger nginx reload\n  service:\n    name: nginx\n    state: reloaded\n  changed_when: false\n\n- name: Create test Acme Challenge file\n  shell: touch {{ acme_tiny_challenges_directory }}/ping.txt\n  args:\n    creates: \"{{ acme_tiny_challenges_directory }}/ping.txt\"\n    warn: false\n\n- name: Test Acme Challenges\n  test_challenges:\n    hosts: \"{{ item.value.site_hosts | reverse_www(enabled=item.value.www_redirect | default(true)) }}\"\n  register: letsencrypt_test_challenges\n  ignore_errors: true\n  when: site_uses_letsencrypt\n  with_dict: \"{{ wordpress_sites }}\"\n\n- name: Notify of challenge failures\n  fail:\n    msg: >\n      Could not access the challenge file for the hosts/domains: {{ item.failed_hosts | join(', ') }}.\n      Let's Encrypt requires every domain/host be publicly accessible.\n      Make sure that a valid DNS record exists for {{ item.failed_hosts | join(', ') }} and that they point to this server's IP.\n      If you don't want these domains in your SSL certificate, then remove them from `site_hosts`.\n      See https://roots.io/trellis/docs/ssl for more details.\n  when: not item | skipped and letsencrypt_test_challenges | failed\n  with_items: \"{{ letsencrypt_test_challenges.results }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "4ecf02929c80bba3c53026102c0e98bc4b52435f", "filename": "playbooks/provision-ansible-tower/README.md", "repository": "redhat-cop/infra-ansible", "decoded_content": "# Ansible Tower Provisioning playbook\n\nThis playbooks runs through the steps to provision a VM, set it up (subscriptions, updates, etc.), and install Ansible Tower.\nCurrently it is configured to provision OpenStack resources, but other providers can easily be added.\n\n## Prerequisites\nAccess to an Ansible Tower software and license.\n\nOne of the two:\n- a set of running instance(s)\n- a IaaS that allow for provisioning through these playbooks\n\n\n## Example\n\n### Inventory\n\nPlease see the **sample** inventory in the inventory area:\n\n- [ansible-tower](../../inventory/ansible-tower/README.md)\n\nYou will need to modify this sample inventory to fit your desired configuration.\n\n### Playbook execution\n\nDepending on how this is being hosted, the initial may need the `tags='install'` set to ensure all necessary software is installed:\n\n```bash\n> ansible-playbook -i inventory main.yml --tags='install'\n```\n\nAny consecutive runs can be done without the 'install' tag to speed up execution:\n```bash\n> ansible-playbook -i inventory main.yml\n```\n\nLicense\n-------\n\nApache License 2.0\n\n\nAuthor Information\n------------------\n\nRed Hat Community of Practice & staff of the Red Hat Open Innovation Labs.\n"}, {"commit_sha": "045ff4bb9f4720739632aac2951fbf2798a99c8c", "sha": "2251f847582a6b940012e2d38b79a2d25d1791e2", "filename": "roles/cloud-digitalocean/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: Set the DigitalOcean Access Token fact\n  set_fact:\n    do_token: \"{{ do_access_token | default(lookup('env','DO_API_TOKEN')) }}\"\n    public_key: \"{{ lookup('file', '{{ SSH_keys.public }}') }}\"\n\n- block:\n    - name: \"Delete the existing Algo SSH keys\"\n      digital_ocean:\n        state: absent\n        command: ssh\n        api_token: \"{{ do_token }}\"\n        name: \"{{ SSH_keys.comment }}\"\n      register: ssh_keys\n      until: ssh_keys.changed != true\n      retries: 10\n      delay: 1\n\n  rescue:\n    - name: Collect the fail error\n      digital_ocean:\n        state: absent\n        command: ssh\n        api_token: \"{{ do_token }}\"\n        name: \"{{ SSH_keys.comment }}\"\n      register: ssh_keys\n      ignore_errors: yes\n\n    - debug: var=ssh_keys\n\n    - fail:\n        msg: \"Please, ensure that your API token is not read-only.\"\n\n- name: \"Upload the SSH key\"\n  digital_ocean:\n    state: present\n    command: ssh\n    ssh_pub_key: \"{{ public_key }}\"\n    api_token: \"{{ do_token }}\"\n    name: \"{{ SSH_keys.comment }}\"\n  register: do_ssh_key\n\n- name: \"Creating a droplet...\"\n  digital_ocean:\n    state: present\n    command: droplet\n    name: \"{{ do_server_name }}\"\n    region_id: \"{{ do_region }}\"\n    size_id: \"512mb\"\n    image_id: \"ubuntu-16-04-x64\"\n    ssh_key_ids: \"{{ do_ssh_key.ssh_key.id }}\"\n    unique_name: yes\n    api_token: \"{{ do_token }}\"\n    ipv6: yes\n  register: do\n\n- name: Add the droplet to an inventory group\n  add_host:\n    name: \"{{ do.droplet.ip_address }}\"\n    groups: vpn-host\n    ansible_ssh_user: root\n    ansible_python_interpreter: \"/usr/bin/python2.7\"\n    ansible_ssh_private_key_file: \"{{ SSH_keys.private }}\"\n    do_access_token: \"{{ do_token }}\"\n    do_droplet_id: \"{{ do.droplet.id }}\"\n    cloud_provider: digitalocean\n    ipv6_support: true\n\n- set_fact:\n    cloud_instance_ip: \"{{ do.droplet.ip_address }}\"\n\n- name: Tag the groplet\n  digital_ocean_tag:\n    name: \"Environment:Algo\"\n    resource_id: \"{{ do.droplet.id }}\"\n    api_token: \"{{ do_token }}\"\n    state: present\n\n- name: Get droplets\n  uri:\n    url: \"https://api.digitalocean.com/v2/droplets?tag_name=Environment:Algo\"\n    method: GET\n    status_code: 200\n    headers:\n      Content-Type: \"application/json\"\n      Authorization: \"Bearer {{ do_token }}\"\n  register: do_droplets\n\n- name: Ensure the group digitalocean exists in the dynamic inventory file\n  lineinfile:\n    state: present\n    dest: configs/inventory.dynamic\n    line: '[digitalocean]'\n\n- name: Populate the dynamic inventory\n  lineinfile:\n    state: present\n    dest: configs/inventory.dynamic\n    insertafter: '\\[digitalocean\\]'\n    regexp: \"^{{ item.networks.v4[0].ip_address }}.*\"\n    line: \"{{ item.networks.v4[0].ip_address }}\"\n  with_items:\n    - \"{{ do_droplets.json.droplets }}\"\n"}, {"commit_sha": "7c574f3b148b4df43177a5c0fc398ce4bea6ae3e", "sha": "d0651906cf94512689969285f75823ece8b36049", "filename": "meta/main.yml", "repository": "zzet/ansible-rbenv-role", "decoded_content": "---\ngalaxy_info:\n  author: \"Andrew Kumanyaev\"\n  description: rbenv\n  company: Undev\n  license: MIT\n  min_ansible_version: 1.7.1\n  version: 0.2\n\n  platforms:\n    - name: EL\n      versions:\n       # - 5\n       - 6\n       # - 7\n    - name: Ubuntu\n      versions:\n        # - lucid    # 10.04 ## package is named git-core 10.04... also geerlingguy.git doesn't support 10.04 either\n        - precise  # 12.04\n        - saucy    # 13.10\n        - trusty   # 14.04\n        # - utopic   # 14.10\n  categories:\n    - development\n    - system\n\ndependencies: []\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "ab632736e6b8a9fd221408fc3bb316b184326e1e", "filename": "roles/php/defaults/main.yml", "repository": "roots/trellis", "decoded_content": "disable_default_pool: true\nmemcached_sessions: false\n\nphp_error_reporting: 'E_ALL & ~E_DEPRECATED & ~E_STRICT'\nphp_display_errors: 'Off'\nphp_display_startup_errors: 'Off'\nphp_max_execution_time: 120\nphp_max_input_time: 300\nphp_max_input_vars: 1000\nphp_memory_limit: 96M\nphp_mysqlnd_collect_memory_statistics: 'Off'\nphp_post_max_size: 25M\nphp_sendmail_path: /usr/sbin/ssmtp -t\nphp_session_save_path: /tmp\nphp_upload_max_filesize: 25M\nphp_track_errors: 'Off'\nphp_default_timezone: '{{ default_timezone }}'\n\nphp_opcache_enable: 1\nphp_opcache_enable_cli: 1\nphp_opcache_fast_shutdown: 1\nphp_opcache_interned_strings_buffer: 8\nphp_opcache_max_accelerated_files: 4000\nphp_opcache_memory_consumption: 128\nphp_opcache_revalidate_freq: 60\n\nphp_xdebug_remote_enable: \"false\"\nphp_xdebug_remote_connect_back: \"false\"\nphp_xdebug_remote_host: localhost\nphp_xdebug_remote_port: \"9000\"\nphp_xdebug_remote_log: /tmp/xdebug.log\nphp_xdebug_idekey: XDEBUG\nphp_max_nesting_level: 200\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "1e585705b0997bb08ea630b9834beefecd31302a", "filename": "roles/keepalived/tasks/prereq.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Install required packages'\n  package:\n    name: '{{ item }}'\n    state: installed\n  with_items:\n  - keepalived\n  - libsemanage-python\n  notify: 'start and enable keepalived services'\n\n\n- name: 'Allow bind to the VIP'\n  lineinfile: \n    path: /etc/sysctl.d/50-keepalived.conf\n    regexp: '^net.ipv4.ip_nonlocal_bind.*'\n    line: 'net.ipv4.ip_nonlocal_bind=1'\n    create: yes\n    state: present\n    owner: root\n    group: root\n    mode: 0644\n  notify: 'reload sysctl'\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "993d34b4c070b987fda91669ab99f1607fbe18e1", "filename": "roles/user-management/manage-atlassian-users/tasks/create_atlassian_users.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Create User\n  uri:\n    url: '{{ atlassian_url }}/rest/api/2/user'\n    method: POST\n    user: '{{ atlassian_username }}'\n    password: '{{ atlassian_password }}'\n    force_basic_auth: yes\n    status_code: 201\n    body_format: json\n    body: \"{'name': '{{ atlassian_user.email.split(\\'@\\') | first }}', 'password': '{{ atlassian_user.password }}', 'emailAddress': '{{ atlassian_user.email }}', 'displayName': '{{ atlassian_user.firstname }} {{ atlassian_user.lastname }}' }\"\n    return_content: yes\n  register: user_data\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "5cc14a2c7060d2dc147ab9a06fe377828216c25b", "filename": "roles/ovirt-engine-backup/meta/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\ngalaxy_info:\n  author: \"Petr Kubica\"\n  description: \"oVirt backup role\"\n  company: \"Red Hat\"\n  license: \"GPLv3\"\n  min_ansible_version: 1.9\n  platforms:\n  - name: EL\n    versions:\n    - all\n  galaxy_tags:\n    - installer\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "3c1d73b02c4297b1088488450f497c49345bf2f9", "filename": "playbooks/templates/hosts-v3.11.j2", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "# Create an OSEv3 group that contains the masters and nodes groups\n[OSEv3:children]\nmasters\nnodes\netcd\n{% if lb is defined %}\nlb\n{% endif %}\n{% if bastion is defined %}\nbastion\n{% endif %}\n{% if cns is defined %}\nglusterfs\n{% endif %}\n\n# Set variables common for all OSEv3 hosts\n[OSEv3:vars]\nansible_ssh_user={{ssh_user}}\nansible_become={% if ssh_user == \"root\" %}no{% else %}yes{% endif %}\n\n# https://github.com/openshift/openshift-ansible/blob/master/DEPLOYMENT_TYPES.md\ndeployment_type=openshift-enterprise\noreg_url=registry.redhat.io/openshift3/ose-${component}:${version}\n{% if registry_token_user is defined and registry_token is defined %}\noreg_auth_user={{registry_token_user}}\noreg_auth_password={{registry_token}}\n{% else %}\n# Please set:\n# oreg_auth_user=...\n# oreg_auth_password=.....\n{% endif %}\ncontainerized=false\n\n# Skip env validation\nopenshift_disable_check=disk_availability,memory_availability\n\n# Configure usage of openshift_clock role.\nopenshift_clock_enabled=true\n\n# Set upgrade restart mode for full system restarts\nopenshift_rolling_restart_mode=system\n\n# Enable cockpit\nosm_use_cockpit=false\nosm_cockpit_plugins=['cockpit-kubernetes', 'cockpit-pcp', 'setroubleshoot-server']\n\n# Docker / Registry Configuration\nopenshift_docker_disable_push_dockerhub=True\nopenshift_docker_options=\"--log-driver=journald --log-level=warn --ipv6=false\"\nopenshift_docker_insecure_registries=docker-registry.default.svc,docker-registry.default.svc.cluster.local\n\n# Native high availability cluster method with optional load balancer.\n\nopenshift_master_cluster_method=native\nopenshift_master_cluster_hostname={{api_dns}}\nopenshift_master_cluster_public_hostname={{api_dns}}\nopenshift_master_api_port=8443\nopenshift_master_console_port=8443\n\n\n# Configure nodeIP in the node config\n# This is needed in cases where node traffic is desired to go over an\n# interface other than the default network interface.\n\n# Configure the multi-tenant SDN plugin (default is 'redhat/openshift-ovs-subnet')\nos_sdn_network_plugin_name=redhat/openshift-ovs-multitenant\n\n# Configure SDN cluster network and kubernetes service CIDR blocks. These\n# network blocks should be private and should not conflict with network blocks\n# in your infrastructure that pods may require access to. Can not be changed\n# after deployment.\nosm_cluster_network_cidr=10.1.0.0/16\nopenshift_portal_net=172.30.0.0/16\nosm_host_subnet_length=8\n\n#Proxy\n{% if proxy_http is defined %}\nopenshift_http_proxy={% if proxy_username is defined %}{{proxy_username}}{% if proxy_password is defined %}:{{proxy_password}}{% endif %}@{% endif %}{{proxy_http}}\n{% endif %}\n{% if proxy_https is defined %}\nopenshift_https_proxy={% if proxy_username is defined %}{{proxy_username}}{% if proxy_password is defined %}:{{proxy_password}}{% endif %}@{% endif %}{{proxy_https}}\n{% endif %}\n{% if proxy_no is defined %}\nopenshift_no_proxy='{{proxy_no}}'\n{% endif %}\nopenshift_generate_no_proxy_hosts=true\n\n# htpasswd auth\nopenshift_master_identity_providers=[{'name': 'htpasswd_auth', 'login': 'true', 'challenge': 'true', 'kind': 'HTPasswdPasswordIdentityProvider'}]\n\n# Provide local certificate paths which will be deployed to masters\nopenshift_master_overwrite_named_certificates=true\n\n# Install the openshift examples\nopenshift_install_examples=true\nopenshift_examples_modify_imagestreams=true\n\n# default subdomain to use for exposed routes\nopenshift_master_default_subdomain={{ apps_dns | replace(\"*.\",\"\")  }}\n\n# Openshift Registry Options\nopenshift_hosted_registry_storage_kind=glusterfs\nopenshift_hosted_registry_replicas=1\n\n#OCS\nopenshift_storage_glusterfs_namespace=ocs\nopenshift_storage_glusterfs_name=ocs\nopenshift_storage_glusterfs_wipe=True\nopenshift_storage_glusterfs_storageclass=true\nopenshift_storage_glusterfs_storageclass_default=true\n\n# Fix for: https://access.redhat.com/solutions/3949971\nopenshift_storage_glusterfs_image=registry.redhat.io/rhgs3/rhgs-server-rhel7:{{ocs_version_tag}}\nopenshift_storage_glusterfs_block_image=registry.redhat.io/rhgs3/rhgs-gluster-block-prov-rhel7:{{ocs_version_tag}}\nopenshift_storage_glusterfs_heketi_image=registry.redhat.io/rhgs3/rhgs-volmanager-rhel7:{{ocs_version_tag}}\n\n\nopenshift_storage_glusterfs_block_deploy=True\nopenshift_storage_glusterfs_block_host_vol_create=true\nopenshift_storage_glusterfs_block_host_vol_size=50\nopenshift_storage_glusterfs_block_storageclass=true\n\n# Metrics deployment\nopenshift_metrics_install_metrics={{ true if install_metrics == 'y' else false }}\nopenshift_metrics_hawkular_hostname=metrics.{{ apps_dns | replace(\"*.\",\"\")}}\nopenshift_metrics_cassandra_replicas=1\nopenshift_metrics_cassandra_limits_memory=2Gi\nopenshift_metrics_hawkular_replicas=1\nopenshift_metrics_duration=5\nopenshift_metrics_cassandra_pvc_size=5Gi\nopenshift_metrics_cassandra_storage_type=dynamic\nopenshift_metrics_cassandra_pvc_storage_class_name=glusterfs-ocs-block\n\n# Logging deployment\nopenshift_logging_install_logging={{ true if install_logging == 'y' else false }}\nopenshift_logging_kibana_hostname=logging.{{ apps_dns | replace(\"*.\",\"\")  }}\nopenshift_logging_use_ops=false\nopenshift_logging_public_master_url=https://{{api_dns}}:8443\nopenshift_logging_curator_default_days=7\nopenshift_logging_es_pvc_size=10Gi\nopenshift_logging_es_pvc_dynamic=true\nopenshift_logging_es_pvc_storage_class_name=glusterfs-ocs-block\nopenshift_logging_es_memory_limit=8Gi\nopenshift_logging_kibana_nodeselector={\"node-role.kubernetes.io/infra\": \"true\"}\nopenshift_logging_curator_nodeselector={\"node-role.kubernetes.io/infra\": \"true\"}\nopenshift_logging_es_nodeselector={\"node-role.kubernetes.io/infra\": \"true\"}\n\n# Prometheus\nopenshift_cluster_monitoring_operator_install=true\nopenshift_cluster_monitoring_operator_prometheus_storage_enabled=true\nopenshift_cluster_monitoring_operator_alertmanager_storage_enabled=true\nopenshift_cluster_monitoring_operator_prometheus_storage_capacity=5Gi\nopenshift_cluster_monitoring_operator_node_selector={\"node-role.kubernetes.io/infra\":\"true\"}\n\n# Service brokers\n\n#openshift_service_catalog_image_version=latest\n#ansible_service_broker_local_registry_whitelist=['.*-apb$']\n#openshift_template_service_broker_namespaces=['openshift']\n\n# Operator Lifecycle Manager\n# openshift_enable_olm=true\n# openshift_additional_registry_credentials=[{'host':'registry.connect.redhat.com','user':'your_user','password':'your_pwd','test_image':'mongodb/enterprise-operator:0.3.2'}]\n\n\n\n\n[masters]\n{% for master in masters %}\n{{master}}\n{% endfor %}\n\n[etcd]\n{% for master in masters %}\n{{master}}\n{% endfor %}\n\n{% if lb is defined %}\n[lb]\n{{lb}}\n{% endif %}\n\n{% if cns is defined %}\n[glusterfs]\n{% for cns_node in cns %}\n{{cns_node}} glusterfs_ip={{ cns_hosts[loop.index0] }} glusterfs_devices='[\"/dev/{{ocs_disk}}\"]'\n{% endfor %}\n{% endif %}\n\n\n[nodes]\n{% for master in masters %}\n{{master}} openshift_node_group_name='{% if infranodes is defined %}node-config-master{% endif %}{% if infranodes is not defined %}node-config-master-infra{% endif %}'\n{% endfor %}\n\n{% if infranodes is defined %}\n{% for infra_node in infranodes %}\n{{infra_node}} openshift_node_group_name='node-config-infra'\n{% endfor %}\n{% endif %}\n\n{% for node in nodes %}\n{{node}} openshift_node_group_name='node-config-compute'\n{% endfor %}\n\n{% if bastion is defined %}\n[bastion]\n{{bastion}}\n{% endif %}\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "e2d969eb3bd70c5c993666acf645dbc1a8f49800", "filename": "roles/manage-confluence-space/tests/playbook.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Test Confluence Role\n  hosts: confluence\n  vars_files:\n  - vars/vars_atlassian\n  roles:\n  - manage-confluence-space\n"}, {"commit_sha": "a94f9ce4fa32273fd0fad7492d36db4101423cc3", "sha": "defb54fb0fd7975e8d05b0e6eda0ed3ccb4ebb1f", "filename": "tasks/setup-audit.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Ensure auditd is installed\n  become: true\n  package:\n    name: auditd\n    state: present\n  when: docker_enable_audit and (_docker_os_dist == \"Ubuntu\" or _docker_os_dist == \"Debian\")\n\n- name: Copy Docker audit rules\n  become: yes\n  copy:\n    src: files/etc/audit/rules.d/docker.rules\n    dest: /etc/audit/rules.d/docker.rules\n  notify: restart auditd\n  when: docker_enable_audit\n\n- name: Ensure Docker audit rules are removed\n  become: yes\n  file:\n    path: /etc/audit/rules.d/docker.rules\n    state: absent\n  notify: restart auditd\n  when: not docker_enable_audit\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "3554059adca4924e6a200a03c0e0183660116c91", "filename": "roles/config-nagios-target/tasks/enable-repos.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Enable the 'rhel-7-server-optional-rpms' repo\n  command: \"/usr/bin/subscription-manager repos --enable={{ item }}\"\n  with_items:\n  - rhel-7-server-optional-rpms \n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "5a16047ee86384bb87133a7d05de9fe60b101d60", "filename": "roles/dns/manage-dns-zones-bind/tasks/keys.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Setup Domain Keys configuration\n  vars:\n    named_views: \"{{ dns_data.views }}\"\n  template:\n    src: domain-keys.j2\n    dest: /etc/named/named.conf.domain-keys\n    owner: \"{{ bind_user }}\"\n    group: \"{{ bind_group }}\"\n    mode: 0660\n  notify: restart named\n\n- import_tasks: generate_keys.yml\n  run_once: true\n  delegate_to: \"{{ ansible_play_hosts | first }}\"\n\n- name: Setup key files for nsupdate\n  template:\n    src: domain-key.j2\n    dest: /var/named/{{ item.item.name }}.key\n    owner: \"{{ bind_user }}\"\n    group: \"{{ bind_group }}\"\n    mode: 0660\n  with_items:\n    - \"{{ hostvars[ansible_play_hosts | first].nsupdate_keys_captured.results }}\"\n  notify: restart named\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "edb8275433caa3e3404acd40a88ab2125eb81fdf", "filename": "roles/phpmyadmin/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "phpmyadmin_install: True\nphpmyadmin_enabled: False\n"}, {"commit_sha": "7032aee7df1c2c6e96795067285efa3b2a6de32e", "sha": "c57ea67cd90f1b410fc256d4dee0e98441eed518", "filename": "roles/docker/defaults/main.yml", "repository": "openshift/openshift-ansible-contrib", "decoded_content": "---\ndefault_docker_storage_block_device: \"/dev/vdb\"\ndefault_docker_storage_volume_group: \"docker_vg\"\n"}, {"commit_sha": "473bab1042b717eb6a6641b7240516af4dbae4d8", "sha": "d48a4d4d269a632faa3516f798d3fb1af7103ace", "filename": "tasks/cleanup.yml", "repository": "fubarhouse/ansible-role-golang", "decoded_content": "---\n\n- name: \"Go-Lang | Removing GOROOT\"\n  file:\n    path: \"{{ GOROOT }}\"\n    state: absent\n  failed_when: false\n\n- name: \"Go-Lang | Removing GOBOOTSTRAP\"\n  file:\n    path: \"{{ GOROOT_BOOTSTRAP }}\"\n    state: absent\n  when:\n   - GOROOT_BOOTSTRAP is defined\n   - install_go_bootstrap|bool == true\n  failed_when: false\n\n- name: \"Go-Lang | Define shell exports to cleanup\"\n  set_fact:\n    shell_exports:\n    - regex: \"export GOROOT={{ GOROOT }}\"\n      lineinfile: \"export GOROOT={{ GOROOT }}\"\n    - regex: \"export GOPATH={{ GOPATH }}/bin\"\n      lineinfile: \"export GOPATH={{ GOPATH }}/bin\"\n    - regex: \"export PATH=$PATH:{{ GOPATH }}/bin\"\n      lineinfile: \"export PATH=$PATH:{{ GOPATH }}/bin\"\n  when: shell_exports is not defined\n\n- name: \"Go-Lang | Ensure shell profiles are clean\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  lineinfile:\n    dest: \"{{ fubarhouse_user_dir }}/{{ item[0] }}\"\n    regexp: \"{{ item[1].regex }}\"\n    line: \"{{ item[1].lineinfile }}\"\n    state: absent\n  with_nested:\n  - \"{{ shell_profiles }}\"\n  - \"{{ shell_exports_static }}\"\n  ignore_errors: yes\n  when: shell_exports is defined\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "3b0c55d8f20afdbed4b0b6ebab822912a0cfe0d2", "filename": "roles/network/tasks/squid.yml", "repository": "iiab/iiab", "decoded_content": "- name: Install squid packages\n  package: name={{ item }}\n           state=present\n  with_items:\n    - \"{{ proxy }}\"\n    - cadaver\n  tags:\n    - download\n\n- name: Create the squid user\n  user: name={{ proxy_user }}\n        createhome=False\n        shell=/bin/false\n\n- name: Copy init script and config file\n  template: src={{ item.src }}\n            dest={{ item.dest }}\n            owner={{ item.owner }}\n            group={{ item.group }}\n            mode={{ item.mode }}\n  with_items:\n    - src: 'squid/squid.sysconfig'\n      dest: '/etc/sysconfig/squid'\n      owner: 'root'\n      group: 'root'\n      mode: '0755'\n    - src: 'squid/sites.whitelist.txt'\n      dest: '/etc/{{ proxy }}/sites.whitelist.txt'\n      owner: '{{ proxy_user }}'\n      group: '{{ proxy_user }}'\n      mode: '0644'\n    - src: 'squid/allowregex.rules'\n      dest: '/etc/{{ proxy }}/allowregex.rules'\n      owner: '{{ proxy_user }}'\n      group: '{{ proxy_user }}'\n      mode: '0644'\n    - src: 'squid/denyregex.rules'\n      dest: '/etc/{{ proxy }}/denyregex.rules'\n      owner: '{{ proxy_user }}'\n      group: '{{ proxy_user }}'\n      mode: '0644'\n    - src: 'squid/dstaddress.rules'\n      dest: '/etc/{{ proxy }}/dstaddress.rules'\n      owner: '{{ proxy_user }}'\n      group: '{{ proxy_user }}'\n      mode: '0644'\n    - src: 'squid/iiab-httpcache.j2'\n      dest: '/usr/bin/iiab-httpcache'\n      owner: 'root'\n      group: 'root'\n      mode: '0755'\n\n- name: Create squid cache directory\n  file: path=/library/cache\n        owner={{ proxy_user }}\n        group={{ proxy_user }}\n        mode=0750\n        state=directory\n\n- name: Create squid log directory\n  file: path=/var/log/{{ proxy }}\n        owner={{ proxy_user }}\n        group={{ proxy_user }}\n        mode=0750\n        state=directory\n\n- include: dansguardian.yml\n  when: dansguardian_install\n\n- name: Stop Squid\n  service: name={{ proxy }}\n           state=stopped\n  ignore_errors: yes\n  when: not installing\n\n- name: Add squid to service list\n  ini_file: dest='{{ service_filelist }}'\n            section={{ proxy }}\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: squid\n    - option: description\n      value: '\"Squid caches web pages the first time they are accessed, and pulls them from the cache thereafter\"'\n    - option: enabled\n      value: \"{{ squid_enabled }}\"\n\n- name: Add dansguardian to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=dansguardian\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: dansguardian\n    - option: description\n      value: '\"Dansguardian searches web content for sexual references and denies access when found\"'\n    - option: enabled\n      value: \"{{ dansguardian_enabled }}\"\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "32838ad94901e927f0a06e2ee43edbc3ab3e9608", "filename": "roles/registrator/meta/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\ngalaxy_info:\n  author: Alberto Garcia\n  description:\n  company: Capgemini\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (MIT)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  - name: Ubuntu\n    versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n     - trusty\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  categories:\n  - cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  - system\n  #- web\ndependencies: []\n  # List your role dependencies here, one per line. Only\n  # dependencies available via galaxy should be listed here.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n"}, {"commit_sha": "045ff4bb9f4720739632aac2951fbf2798a99c8c", "sha": "c195b13d3658a38e8d7c495c9dba5d3e4dd72286", "filename": "playbooks/common.yml", "repository": "trailofbits/algo", "decoded_content": "- name: Install prerequisites\n  raw: sleep 10 && sudo apt-get update -qq && sudo apt-get install -qq -y python2.7\n\n- name: Configure defaults\n  raw: sudo update-alternatives --install /usr/bin/python python /usr/bin/python2.7 1\n  tags:\n    - update-alternatives\n\n- name: Ensure the algo ssh key exist on the server\n  authorized_key:\n    user: \"{{ ansible_ssh_user }}\"\n    state: present\n    key: \"{{ lookup('file', '{{ SSH_keys.public }}') }}\"\n  tags: [ 'always' ]\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "bcd7a8c41e82944ea70603b615f4bf0bffba8108", "filename": "roles/kalite/templates/kalite.conf", "repository": "iiab/iiab", "decoded_content": "<VirtualHost *:80>\n        RewriteEngine on\n\n\tRewriteRule \"^/kalite(.*)\"  \"http://127.0.0.1:8008$1\"\n\n        AddOutputFilterByType SUBSTITUTE text/html\n\tSubstitute \"s|/management/|/kalite/management/|i\"\n\tSubstitute \"s|/coachreports/|/kalite/coachreports/|i\"\n\tSubstitute \"s|/static/|/kalite/static/|i\"\n\tSubstitute \"s|/update/|/kalite/update/|i\"\n\tSubstitute \"s|/_generated/|/kalite/_generated/|i\"\n\tSubstitute \"s|/securesync/|/kalite/securesync/|i\"\n\tSubstitute \"s|/api/|/kalite/api/|i\"\n\tSubstitute \"s|/content/|/kalite/content/|i\"\n\n</VirtualHost>\n"}, {"commit_sha": "35c4af9fd84d7a7e6bc093adc944b352e68d6ff1", "sha": "216eaa495d8af4dfe0ec808c9f6df3093bb0f22a", "filename": "handlers/main.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n# handlers file for ansible-role-docker-ce\n\n- name: restart docker\n  service:\n    name: docker\n    state: restarted\n  become: true\n\n# Workaround because systemd cannot be used: https://github.com/ansible/ansible/issues/22171\n- name: restart auditd\n  shell: service auditd restart\n  args:\n    warn: false\n  become: true\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "a7425708f691a73345558f219456c9e98fa8963e", "filename": "tasks/Linux/fetch/web.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Download artifact from web\n  get_url:\n    url: '{{ transport_web }}'\n    dest: '{{ java_download_path }}'\n  register: file_downloaded\n  retries: 5\n  delay: 2\n  until: file_downloaded is succeeded\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "5d1bc61d4e7da30ad6bd41c088a89eff8d66239c", "filename": "tasks/modules/install-rtmp.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: All OSs) Install NGINX Plus RTMP Module\"\n  package:\n    name: nginx-plus-module-rtmp\n    state: present\n\n- name: \"(Setup: All NGINX) Load NGINX RTMP Module\"\n  lineinfile:\n    path: /etc/nginx/nginx.conf\n    insertbefore: BOF\n    line: load_module modules/ngx_rtmp_module.so;\n  when: not nginx_main_template_enable\n  notify: \"(Handler: All OSs) Reload NGINX\"\n"}, {"commit_sha": "ccab58ae5d697bb64abd86558f79c34161d2fb00", "sha": "8300adcb5fcb716e225169707f9cb00c2fc75b99", "filename": "tasks/create_content_selector_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_content_selector\n    args: \"{{ item }}\"\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "05f4d57a93cb085f1c4fd7b9be72e61b4c3396bc", "filename": "roles/ovirt-engine-backup/tasks/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\n# engine-backup\n- name: run engine-backup\n  shell: 'engine-backup --mode={{ovirt_backup_mode}} --file={{ovirt_backup_archive}} --log={{ovirt_backup_log_file}} --scope={{ovirt_backup_scope}}'\n  tags:\n    - skip_ansible_lint\n  register: ovirt_backup_status\n\n# download backup file to ansible-client node\n- name: download engine backup file\n  fetch:\n    src: \"{{ovirt_backup_archive}}\"\n    dest: \"{{ovirt_backup_archive}}\"\n  when: ovirt_backup_status|succeeded\n\n# download log file to ansible-client node\n- name: download log file\n  fetch:\n    src: \"{{ovirt_log_file}}\"\n    dest: \"{{ovirt_log_file}}\"\n  when: ovirt_backup_status|failed\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "06a01b61fb2813208755f3e9447ee112234b2d8e", "filename": "roles/letsencrypt/templates/renew-certs.py", "repository": "roots/trellis", "decoded_content": "#!/usr/bin/env python\n\nimport os\nimport sys\nimport time\n\nfrom subprocess import CalledProcessError, check_output, STDOUT\n\ncerts_dir = '{{ letsencrypt_certs_dir }}'\nfailed = False\nsites = {{ wordpress_sites }}\nsites = (k for k, v in sites.items() if 'ssl' in v and v['ssl'].get('enabled', False) and v['ssl'].get('provider', 'manual') == 'letsencrypt')\n\nfor site in sites:\n    cert_path = os.path.join(certs_dir, site + '.cert')\n    bundled_cert_path = os.path.join(certs_dir, site + '-bundled.cert')\n\n    if os.access(cert_path, os.F_OK):\n        stat = os.stat(cert_path)\n        print 'Certificate file ' + cert_path + ' already exists'\n\n        if time.time() - stat.st_mtime < {{ letsencrypt_min_renewal_age }} * 86400:\n            print '  The certificate is younger than {{ letsencrypt_min_renewal_age }} days. Not creating a new certificate.\\n'\n            continue\n\n    print 'Generating certificate for ' + site\n\n    cmd = ('/usr/bin/env python {{ acme_tiny_software_directory }}/acme_tiny.py '\n           '--ca {{ letsencrypt_ca }} '\n           '--account-key {{ letsencrypt_account_key }} '\n           '--csr {{ acme_tiny_data_directory }}/csrs/{0}.csr '\n           '--acme-dir {{ acme_tiny_challenges_directory }}'\n           ).format(site)\n\n    try:\n        cert = check_output(cmd, stderr=STDOUT, shell=True)\n    except CalledProcessError as e:\n        failed = True\n        print 'Error while generating certificate for ' + site\n        print e.output\n    else:\n        with open(cert_path, 'w') as cert_file:\n            cert_file.write(cert)\n\n        with open('{{ letsencrypt_intermediate_cert_path }}') as intermediate_cert_file:\n            intermediate_cert = intermediate_cert_file.read()\n\n        with open(bundled_cert_path, 'w') as bundled_file:\n            bundled_file.write(''.join([cert, intermediate_cert]))\n\n        print 'Created certificate for ' + site\n\nif failed:\n    sys.exit(1)\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "0656f4a5f47a08599d45fa695e19d67676464c1e", "filename": "roles/haproxy/defaults/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# defaults file for haproxy\nhaproxy_image: asteris/haproxy-consul\nhaproxy_image_tag: latest\n\n# Set the domain that haproxy uses to match URLs to internal apps.\n# For example, if all your apps will be\n#    app1.example.com, app2.example.com, etc.  set this to 'example.com'\nhaproxy_domain: example.com\n\nhaproxy_rebuild_container: False\n\nconsul_template_dir: /mnt/consul-template.d\nconsul_template_loglevel: debug\nconsul_backend: consul.service.consul:8500\nconsul_template_version: 0.10.0\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "d2a1e4ee51e6d8bc3cdca7a595c598fc09e1b4f8", "filename": "roles/monit/templates/squid", "repository": "iiab/iiab", "decoded_content": "check process squid with pidfile /var/run/squid.pid\n   start program = \"/sbin/service squid start\" \n   stop program = \"/sbin/service squid stop\" \n   if cpu > 60% for 3 cycles then restart\n   if totalmem > 200.0 MB for 3 cycles then restart \n   if failed host localhost port 3130 type tcp then restart\n   if 3  restarts within 5 cycles then timeout\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "12b04a119f58fb81863345bf21cf8e1b3cc56853", "filename": "tasks/section_07_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 7.1.1 Disable IP Forwarding (Scored)\n    sysctl: >\n      name=net.ipv4.ip_forward\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.1\n\n  - name: 7.1.2.1 Disable Send Packet Redirects (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.2\n      - section7.1.2.1\n\n  - name: 7.1.2.2 Disable Send Packet Redirects (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.2\n      - section7.1.2.2\n\n  - name: 7.2.1.1 Disable Source Routed Packet Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.accept_source_route\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.1\n      - section7.2.1.1\n\n  - name: 7.2.1.2 Disable Source Routed Packet Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.accept_source_route\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.1\n      - section7.2.1.2\n\n  - name: 7.2.2.1 Disable ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.2\n      - section7.2.2.1\n\n  - name: 7.2.2.2 Disable ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.2\n      - section7.2.2.2\n\n  - name: 7.2.3.1 Disable Secure ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.secure_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.3\n      - section7.2.3.1\n\n  - name: 7.2.3.2 Disable Secure ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.secure_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.3\n      - section7.2.3.2\n\n  - name: 7.2.4.1 Log Suspicious Packets (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.log_martians\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.4\n      - section7.2.4.1\n\n  - name: 7.2.4.2 Log Suspicious Packets (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.log_martians\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.4\n      - section7.2.4.2\n\n  - name: 7.2.5 Enable Ignore Broadcast Requests (Scored)\n    sysctl: >\n      name=net.ipv4.icmp_echo_ignore_broadcasts\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.5\n\n  - name: 7.2.6 Enable Bad Error Message Protection (Scored)\n    sysctl: >\n      name=net.ipv4.icmp_ignore_bogus_error_responses\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.6\n\n  - name: 7.2.7.1 Enable RFC-recommended Source Route Validation (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.rp_filter\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.7\n      - section7.2.7.1\n\n  - name: 7.2.7.2 Enable RFC-recommended Source Route Validation (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.rp_filter\n      value=1\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.7\n      - section7.2.7.2\n\n  - name: 7.2.8 Enable TCP SYN Cookies (Scored)\n    sysctl: >\n      name=net.ipv4.tcp_syncookies\n      value=1\n      state=present\n    when: enable_tcp_syncookies\n    tags:\n      - section7\n      - section7.2\n      - section7.2.8\n\n  - name: 7.3.1.1 Disable IPv6 Router Advertisements (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.all.accept_ra\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.1\n      - section7.3.1.1\n\n  - name: 7.3.1.2 Disable IPv6 Router Advertisements (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.default.accept_ra\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.1\n      - section7.3.1.2\n\n  - name: 7.3.2.1 Disable IPv6 Redirect Acceptance (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.all.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.2\n      - section7.3.2.1\n\n  - name: 7.3.2.2 Disable IPv6 Redirect Acceptance (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.default.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.2\n      - section7.3.2.2\n\n  - name: 7.3.3 Disable IPv6 (Not Scored)\n    sysctl: >\n      name={{ item }}\n      value=1\n      state=present\n    with_items:\n      - net.ipv6.conf.all.disable_ipv6\n      - net.ipv6.conf.default.disable_ipv6\n      - net.ipv6.conf.lo.disable_ipv6\n    when: disable_ipv6 == True\n    tags:\n      - section7\n      - section7.3\n      - section7.3.3\n\n  - name: 7.4.1 Install TCP Wrappers (Scored)\n    apt: name=tcpd state=present\n    tags:\n      - section7\n      - section7.4\n      - section7.4.1\n\n  - name: 7.4.2 Create /etc/hosts.allow (Not Scored)\n    debug: msg=\"*** Verify /etc/hosts.allow ***\"\n    tags:\n      - section7\n      - section7.4\n      - section7.4.2\n\n  - name: 7.4.3 Verify Permissions on /etc/hosts.allow (Scored)\n    file: >\n        path=/etc/hosts.allow\n        owner=root\n        group=root\n        mode=0644\n    tags:\n      - section7\n      - section7.4\n      - section7.4.3\n\n  - name: 7.4.4 Create /etc/hosts.deny (Not Scored)\n    debug: msg='*** Verify /etc/hosts.deny ***'\n    tags:\n      - section7\n      - section7.4\n      - section7.4.4\n\n  - name: 7.4.5 Verify Permissions on /etc/hosts.deny (Scored)\n    file: >\n        path=/etc/hosts.deny\n        owner=root\n        group=root\n        mode=0644\n    tags:\n      - section7\n      - section7.4\n      - section7.4.5\n\n  - name: 7.5.0 Create the file \"cis.conf\" under modprobe.d if doesn't exist (Not Scored)\n    copy:\n        dest: /etc/modprobe.d/CIS.conf\n        content: \"\"\n        force: no\n    tags:\n      - section7\n      - section7.5\n\n  - name: 7.5.0 Check the presence of the file \"cis.conf\" under modprobe.d (Not Scored)\n    stat: >\n        path=/etc/modprobe.d/CIS.conf\n    register: cis_conf_file\n    tags:\n      - section7\n      - section7.5\n\n\n  - name: 7.5.1-4 Disable DCCP, SCTP, RDS, TIPC (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install {{ item }} /bin/true'\n        state=present\n    when: cis_conf_file.stat.exists\n    with_items:\n        - dccp\n        - sctp\n        - rds\n        - tipc\n    tags:\n      - section7\n      - section7.5\n      - section7.5.1\n      - section7.5.2\n      - section7.5.3\n      - section7.5.4\n\n  - name: 7.6 Deactivate Wireless Interfaces (Not Scored)\n    shell: 'lspci -k | grep -i wifi'\n    changed_when: False\n    register: lspci_wifi\n    failed_when: lspci_wifi.rc == 0\n    tags:\n      - section7\n      - section7.6\n\n  - name: 7.7 Ensure Firewall is active (install) (Scored)\n    apt: >\n        name=ufw\n        state=present\n    when: activate_ufw\n    tags:\n      - section7\n      - section7.7\n\n  - name: 7.7 Ensure Firewall is active (Scored)\n    service: >\n        name=ufw\n        state=started\n    when: activate_ufw\n    tags:\n      - section7\n      - section7.7\n"}, {"commit_sha": "3848dbe33432b38a7e7ebad0da63826355cf1b4c", "sha": "9dc575c6bcabe355bda06a00ce175d0b02f88d73", "filename": "tasks/configure.yml", "repository": "geerlingguy/ansible-role-solr", "decoded_content": "---\n- name: Remove existing SOLR_HEAP configuration.\n  lineinfile:\n    dest: \"{{ solr_config_file }}\"\n    regexp: \"^SOLR_HEAP\"\n    state: absent\n  notify: restart solr\n\n- name: Apply Solr memory configuration changes.\n  lineinfile:\n    dest: \"{{ solr_config_file }}\"\n    regexp: \"{{ item.regexp }}\"\n    line: \"{{ item.line }}\"\n    state: present\n  with_items:\n    - regexp: \"^.?SOLR_JAVA_MEM=\"\n      line: 'SOLR_JAVA_MEM=\"-Xms{{ solr_xms }} -Xmx{{ solr_xmx }}\"'\n    - regexp: \"^SOLR_PORT=\"\n      line: 'SOLR_PORT=\"{{ solr_port }}\"'\n  notify: restart solr"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "ac125b67a0b01c695f6f431aa65e4c337ccf0fac", "filename": "roles/postgresql/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Install postgresql packages\n  package: name={{ item }}\n           state=present\n  with_items:\n    - postgresql\n  tags:\n    - download\n\n- name: Install postgresql for debian\n  package: name=postgresql-client\n  when: is_debuntu\n  tags:\n    - download\n\n- name: Install postgresql for fedora\n  package: name=postgresql-server\n  when: not is_debuntu\n  tags:\n    - download\n\n- name: Create postgresql-iiab systemd service\n  template: src=postgresql-iiab.service\n            dest=/etc/systemd/system/postgresql-iiab.service\n            owner=root\n            group=root\n            mode=0644\n\n- name: Create postgres data directory\n  file: path=/library/pgsql-iiab\n        owner=postgres\n        group=postgres\n        mode=0700\n        state=directory\n\n- name: make sure that the en_US locale is enabled\n  lineinfile: dest=/etc/locale.gen\n              line=\"{{ postgresql_locale }} UTF-8\"\n  when: is_debuntu\n\n- name: generate the selected locales\n  command: /usr/sbin/locale-gen\n  when: is_debuntu\n\n- name: Initialize the postgres db\n  command:  su - postgres -c \"/usr/lib/postgresql/{{ postgresql_version }}/bin/initdb -E 'UTF-8' --locale={{ postgresql_locale }}  -D /library/pgsql-iiab\"\n            creates=/library/pgsql-iiab/pg_hba.conf\n  when: is_debian\n\n- name: Initialize the postgres db\n  command:  su - postgres -c \"/usr/lib/postgresql/9.5/bin/initdb -E 'UTF-8' --locale={{ postgresql_locale }}  -D /library/pgsql-iiab\"\n            creates=/library/pgsql-iiab/pg_hba.conf\n  when: is_ubuntu\n\n- name: Initialize the postgres db\n  command:  su - postgres -c \"/usr/bin/initdb -E 'UTF-8' --lc-collate={{ postgresql_locale }} --lc-ctype={{ postgresql_locale }}  -D /library/pgsql-iiab\"\n            creates=/library/pgsql-iiab/pg_hba.conf\n  when: not is_debuntu\n\n- name: Configure postgres\n  template: backup=yes\n            src=postgresql.conf.j2\n            dest=/library/pgsql-iiab/postgresql.conf\n            owner=postgres\n            group=postgres\n            mode=0640\n\n- name: Stop and disable stock postgresql service\n  service: name=postgresql\n           state=stopped\n           enabled=no\n\n- name: Start and enable postgresql-iiab service\n  service: name=postgresql-iiab\n           state=started\n           enabled=yes\n  when: postgresql_enabled\n\n- name: Add postgresql to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=postgresql\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: postgresql\n    - option: description\n      value: '\"PostgreSQL is a powerful, open source object-relational database system.\"'\n    - option: installed\n      value: \"{{ postgresql_install }}\"\n    - option: enabled\n      value: \"{{ postgresql_enabled }}\"\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "c405c07cde00dc8ecdecee0aa2c238f812fa2b49", "filename": "tasks/delete_blobstore_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: delete_blobstore\n    args: \"{{ item }}\""}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "53e4cf92bc1a3603e266561ef941367cf5505240", "filename": "roles/idm-host-cert/tasks/write-certs-to-file.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Set certificate fact\"\n  set_fact:\n    certificate: \"{{ host_cert.json.result.result.certificate }}\"\n\n- name: \"Write the Host Specific Certificate to a file\"\n  template:\n    src: cert.j2\n    dest: \"{{ target_host_cert_file }}\"\n  when:\n  - target_host_cert_file is defined\n  - target_host_cert_file|trim != ''\n\n- name: \"Write the Certificate key to a file\"\n  copy:\n    content: \"{{ csr_content.key }}\"\n    dest: \"{{ target_host_key_file }}\"\n  when:\n  - target_host_key_file is defined\n  - target_host_key_file|trim != ''\n\n- name: \"Set certificate fact\"\n  set_fact:\n    certificate: \"{{ ca_cert.json.result.result.certificate }}\"\n\n- name: \"Write the CA Certificate to a file\"\n  template:\n    src: cert.j2\n    dest: \"{{ target_ca_cert_file }}\"\n  when:\n  - target_ca_cert_file is defined\n  - target_ca_cert_file|trim != ''\n\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "4856a97ccad74bdab9624b18a470220b401d2e22", "filename": "roles/vpn/tasks/ubuntu.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- set_fact:\n    strongswan_additional_plugins: []\n\n- name: Ubuntu | Install strongSwan\n  apt: name=strongswan state=latest update_cache=yes install_recommends=yes\n\n- name: Ubuntu | Enforcing ipsec with apparmor\n  shell: aa-enforce \"{{ item }}\"\n  when: apparmor_enabled is defined and apparmor_enabled == true\n  with_items:\n    - /usr/lib/ipsec/charon\n    - /usr/lib/ipsec/lookip\n    - /usr/lib/ipsec/stroke\n  notify:\n    - restart apparmor\n  tags: ['apparmor']\n\n- name: Ubuntu | Enable services\n  service: name={{ item }} enabled=yes\n  with_items:\n    - apparmor\n    - strongswan\n    - netfilter-persistent\n\n- name: Ubuntu | Ensure that the strongswan service directory exist\n  file: path=/etc/systemd/system/strongswan.service.d/ state=directory mode=0755  owner=root group=root\n\n- name: Ubuntu | Setup the cgroup limitations for the ipsec daemon\n  template: src=100-CustomLimitations.conf.j2 dest=/etc/systemd/system/strongswan.service.d/100-CustomLimitations.conf\n  notify:\n    - daemon-reload\n    - restart strongswan\n\n- include: iptables.yml\n  tags: iptables\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "5cb02ea1d96bf4ac4a39a572e29e4dd9e8649dda", "filename": "roles/ansible/tower/config-ansible-tower/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: restart-tower\n  service:\n    name: supervisord\n    state: restarted\n  become: True\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "31802eed3fa0a8ab46f20e08074fe5ce4e19d0b8", "filename": "roles/wordpress-install/tasks/directories.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Create web root of sites\n  file:\n    path: \"{{ www_root }}/{{ item.key }}/current/web\"\n    owner: \"{{ web_user }}\"\n    group: \"{{ web_group }}\"\n    mode: 0755\n    state: directory\n  with_dict: \"{{ wordpress_sites }}\"\n\n- name: Create shared folder of sites\n  file:\n    path: \"{{ www_root }}/{{ item.key }}/shared\"\n    owner: \"{{ web_user }}\"\n    group: \"{{ web_group }}\"\n    mode: 0755\n    state: directory\n  with_dict: \"{{ wordpress_sites }}\"\n\n- name: Change site owner to user\n  file:\n    path: \"{{ www_root }}/{{ item.key }}\"\n    owner: \"{{ web_user }}\"\n    group: \"{{ web_group }}\"\n    state: directory\n    recurse: yes\n  with_dict: \"{{ wordpress_sites }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "026e5bf3f01c743e087cd93ac3145380fca870a8", "filename": "roles/config-hostname/tests/inventory/group_vars/my-host.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nhostname: \"cool\"\ndns_domain: \"hostname.com\"\n\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "006479d78a56ce2f77e09eac5e164cb160f06902", "filename": "roles/vpn/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: Gather Facts\n  setup:\n\n- name: Enable IPv6\n  set_fact:\n    ipv6_support: true\n  when: ansible_default_ipv6.gateway is defined\n\n- name: Generate password for the CA key\n  shell: >\n    openssl rand -hex 16\n  register: CA_password\n\n- set_fact:\n    easyrsa_p12_export_password: \"{{ p12_export_password|default((ansible_date_time.iso8601_basic|sha1|to_uuid).split('-')[0]) }}\"\n    easyrsa_CA_password: \"{{ CA_password.stdout }}\"\n    IP_subject_alt_name: \"{{ IP_subject_alt_name }}\"\n\n- name: Change the algorithm to RSA\n  set_fact:\n    algo_params: \"rsa:2048\"\n  when: Win10_Enabled is defined and Win10_Enabled == \"Y\"\n\n- name: Ensure that the strongswan group exist\n  group: name=strongswan state=present\n\n- name: Ensure that the strongswan user exist\n  user: name=strongswan group=strongswan state=present\n\n- include: ubuntu.yml\n  when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'\n\n- include: freebsd.yml\n  when: ansible_distribution == 'FreeBSD'\n\n- name: Install strongSwan\n  package: name=strongswan state=present\n\n- include: ipec_configuration.yml\n- include: openssl.yml\n- include: distribute_keys.yml\n- include: client_configs.yml\n\n- meta: flush_handlers\n\n- name: strongSwan started\n  service: name=strongswan state=started\n"}, {"commit_sha": "2f1ed84fec270723a1031cdc2b07b7a76a5a3bda", "sha": "2c307c60a332af536d304b4059175c10570610dc", "filename": "tasks/main-Generic.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n# tasks file for ansible-role-docker-ce\n\n- name: Determine Docker version\n  command: bash -c \"docker version | grep Version | awk '{print $2}'\"\n  ignore_errors: yes\n  changed_when: false\n  register: cmd_docker_version\n\n- name: Set fact if old Docker installation shall be removed\n  set_fact:\n    remove_old_docker: \"{{docker_remove_pre_ce | bool }} == true and {{ cmd_docker_version.stdout_lines[0] | search('-ce') }} == false\"\n  when: cmd_docker_version.stdout_lines is defined and cmd_docker_version.stdout_lines[0] is defined\n\n- name: Check if Docker is running\n  command: systemctl status docker\n  ignore_errors: yes\n  changed_when: false\n  register: service_docker_status\n  when: remove_old_docker | default(false) | bool == true\n  become: true\n\n- name: Stop Docker service\n  service:\n    name: docker\n    state: stopped\n  when: \"service_docker_status.rc | default(1) == 0\"\n\n- name: Remove old Docker installation before Docker CE\n  package:\n    name: \"{{ item }}\"\n    state: absent\n  become: true\n  when: remove_old_docker|default(false) | bool == true\n  with_items:\n    - docker\n    - docker-common\n    - container-selinux\n    - docker-selinux\n    - docker-engine\n\n- name: Ensure docker-ce is the latest version\n  package:\n    name: docker-ce\n    state: latest\n  become: true\n  notify: restart docker\n\n- name: Ensure /etc/docker directory exists\n  file:\n    path: /etc/docker\n    state: directory\n    mode: 0755\n  become: true\n\n- name: Configure Docker daemon (file)\n  copy:\n    src: \"{{ docker_daemon_config_file }}\"\n    dest: /etc/docker/daemon.json\n  become: true\n  notify: restart docker\n  when: docker_daemon_config_file is defined\n\n- name: Configure Docker daemon (variables)\n  copy:\n    content: \"{{ docker_daemon_config | to_nice_json }}\"\n    dest: /etc/docker/daemon.json\n  become: true\n  notify: restart docker\n  when: docker_daemon_config_file is not defined and \n        docker_daemon_config is defined\n\n- name: Enable and start Docker service\n  service:\n    name: docker\n    state: started\n    enabled: true\n  become: true\n\n"}, {"commit_sha": "49010188a985bfe713552eb8980cfa0d7a888daf", "sha": "51794268e8cb15727515a0236c7419821b0aacb8", "filename": "roles/openshift-replicas-ready/defaults/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\ntarget_namespace: ''\ndelay: 10\nretries: 30"}, {"commit_sha": "64cbc6946b7ebc0d9a36f40d77ac86f8e3564499", "sha": "2d69959c48104bad70d73a8fd726c86fd67ef112", "filename": "tasks/dbd.yml", "repository": "CSCfi/ansible-role-slurm", "decoded_content": "---\n  - name: slurm_mysql_password variable must be set\n    assert:\n      that: \"slurm_mysql_password is defined\"\n\n####\n\n  - name: install slurmdbd specific packages\n    package: \"name={{item}} state=present\"\n    register: reg_install_slurm_packages\n    with_items: \"{{ slurmdbd_packages }}\"\n    when: ansible_os_family == \"RedHat\"\n\n  - name: start and enable mariadb/mysql\n    service: name={{ slurm_sql_service }} state=started enabled=yes\n    when: ansible_os_family == \"RedHat\"\n\n  - name: restart mariadb/mysql after install\n    service: name={{ slurm_sql_service }} state=restarted\n    when: reg_install_slurm_packages.changed\n\n  - name: wait for mysql in port 3306 to start\n    wait_for: port=3306 delay=10 timeout=60\n\n  - name: Set root sql user password\n    # If .my.cnf already exists, this will cause an mysql-root-password update.\n    # check_implicit_admin means it tries without password first\n    mysql_user:\n      name: root\n      password: \"{{ DB_root_password}}\"\n      check_implicit_admin: true\n      host: \"{{ item }}\"\n    with_items:\n       - \"::1\"\n       - \"127.0.0.1\"\n       - \"localhost\"\n    when: slurm_manage_mysql_security\n    \n  - name: template .my.cnf\n    template:\n     src: \".my.cnf.j2\"\n     dest: \"/root/.my.cnf\"\n     owner: root\n     group: root\n     mode: 0600\n    when: slurm_manage_mysql_security\n\n  - name: delete anonymous sql server user for localhost\n    mysql_user: user=\"\" state=absent\n    when: slurm_manage_mysql_security\n\n  - name: remove the mysql test database\n    mysql_db: db=test state=absent\n    when: slurm_manage_mysql_security\n\n  - name: create slurm acct db\n    mysql_db: name=slurm_acct_db state=present\n    when: slurm_manage_mysql_security\n\n  - name: create slurm sql user\n    mysql_user: \n     name: slurm \n     state: present \n     password: \"{{ slurm_mysql_password }}\"\n    register: mysqlslurmuser\n    ignore_errors: yes\n    tags: debug\n\n  - name: print mysqlslurmuser\n    debug: var=mysqlslurmuser verbosity=1\n    tags: debug\n    changed_when: False\n\n  - name: ensure slurm sql user has a password and privileges if it does not exist or if it was just added\n    mysql_user: \n     name: slurm\n     password: \"{{ slurm_mysql_password\u00a0}}\"\n     priv: \"slurm_acct_db.*:ALL\"\n     state: present \n     update_password: always\n    when: mysqlslurmuser|failed or mysqlslurmuser|changed\n\n  - name: template in slurmdbd.conf\n    template: \n     src: slurmdbd.conf.j2 \n     dest: /etc/slurm/slurmdbd.conf \n     owner: root \n     mode: 0640 \n     backup: yes\n    notify:\n      - restart slurmdbd\n\n  - name: template in dump-all-databases.sh\n    template: src=dump-all-databases.sh.j2 dest=/usr/local/sbin/dump-all-databases.sh owner=root mode=0750 backup=no\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "7326d96705e982cda9b5c0662c69616910d42ade", "filename": "roles/awstats/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- include: install.yml\n  when: awstats_install\n\n- name: Add awstats to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=awstats\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: awstats\n    - option: description\n      value: '\"Awstats is Advanced Web Statistics package written in perl which generates static or dynamic html summaries based upon web server logs\"'\n    - option: installed\n      value: \"{{ awstats_install }}\"\n    - option: enabled\n      value: \"{{ awstats_enabled }}\"\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "372ed8c23454af038000b4731432a6e4ccc5a3aa", "filename": "roles/dns/manage-dns-zones/tasks/named/keys.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Setup Domain Keys configuration\n  vars:\n    named_views: \"{{ dns_data.views }}\"\n  template:\n    src: named/domain-keys.j2\n    dest: /etc/named/named.conf.domain-keys\n    owner: named\n    group: named\n    mode: 0660\n  notify: restart named\n\n- import_tasks: generate_keys.yml\n  run_once: true\n  delegate_to: \"{{ ansible_play_hosts | first }}\"\n\n- name: Setup key files for nsupdate\n  template:\n    src: named/domain-key.j2\n    dest: /var/named/{{ item.item }}.key\n    owner: named\n    group: named\n    mode: 0660\n  with_items:\n    - \"{{ hostvars[ansible_play_hosts | first].nsupdate_keys_captured.results }}\"\n  notify: restart named\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "ec570c25c4e083bdcabd5f9cca71e08a601177da", "filename": "playbooks/templates/rock_config.yml.j2", "repository": "rocknsm/rock", "decoded_content": "---\n# These are all the current variables that could affect\n# the configuration of ROCKNSM. Take care when modifying\n# these. The defaults should be used unless you really\n# know what you are doing!\n\n# interfaces that should be configured for sensor applications\nrock_monifs:\n  {% for item in rock_monifs %}\n  - {{ item }}\n  {% endfor %}\n\n# Secifies the hostname of the sensor\nrock_hostname: {{ rock_hostname }}\n# the FQDN\nrock_fqdn: {{ rock_fqdn }}\n# the number of CPUs that bro will use\nbro_cpu: {{ bro_cpu }}\n# name of elasticsearch cluster\nes_cluster_name: {{ es_cluster_name }}\n# name of node in elasticsearch cluster\nes_node_name: {{ es_node_name }}\n# how much memory to use for elasticsearch\nes_mem: {{ es_mem }}\n# (optional) personal configured key for pulled pork to pull latest sigs from snort.org\npulled_pork_oinkcode: {{ pulled_pork_oinkcode }}\n\n########## Offline/Enterprise Network Options ##############\n\n# configure if this system may reach out to the internet\n# (configured repos below) during configuration\nrock_online_install: {{ rock_online_install }}\n# (online) the URL for the EPEL repo mirror\nepel_baseurl: {{ epel_baseurl }}\n# (online) the URL for the EPEL GPG key\nepel_gpgurl: {{ epel_gpgurl }}\n# (online) the URL for the elastic repo mirror\nelastic_baseurl: {{ elastic_baseurl }}\n# (online) the URL for the elastic GPG key\nelastic_gpgurl: {{ elastic_gpgurl }}\n# (online) the URL for the rocknsm repo mirror\nrocknsm_baseurl: {{ rocknsm_baseurl }}\n# (online) the URL for the rocknsm GPG key\nrocknsm_gpgurl: {{ rocknsm_gpgurl }}\n\n# (offline) the filesytem path for a local repo if doing an \"offline\" install\nrocknsm_local_baseurl: {{ rocknsm_local_baseurl }}\n\n# the git repo from which to checkout rocknsm customization scripts for bro\nbro_rockscripts_repo: {{ bro_rockscripts_repo }}\n\n# the git repo from which pulled pork should be installed\npulled_pork_repo: {{ pulled_pork_repo }}\n\n#### Retention Configuration ####\nelastic_close_interval: {{ elastic_close_interval }}\nelastic_delete_interval: {{ elastic_delete_interval }}\nkafka_retention: {{ kafka_retention }}\nsuricata_retention: {{ suricata_retention }}\nbro_log_retention: {{ bro_log_retention }}\nbro_stats_retention: {{ bro_stats_retention }}\n\n### Advanced Feature Selection ######\n# Don't flip these unless you know what you're doing\nwith_stenographer: {{ with_stenographer }}\nwith_bro: {{ with_bro }}\nwith_suricata: {{ with_suricata }}\nwith_snort: {{ with_snort }}\nwith_pulledpork: {{ with_pulledpork }}\nwith_logstash: {{ with_logstash }}\nwith_elasticsearch: {{ with_elasticsearch }}\nwith_kibana: {{ with_kibana }}\nwith_zookeeper: {{ with_zookeeper }}\nwith_kafka: {{ with_kafka }}\nwith_nginx: {{ with_nginx }}\nwith_fsf: {{ with_fsf }}\n\n# Specify if a service is enabled on startup\nenable_stenographer: {{ enable_stenographer }}\nenable_bro: {{ enable_bro }}\nenable_suricata: {{ enable_suricata }}\nenable_snort: {{ enable_snort }}\nenable_pulledpork: {{ enable_pulledpork }}\nenable_logstash: {{ enable_logstash }}\nenable_elasticsearch: {{ enable_elasticsearch }}\nenable_kibana: {{ enable_kibana }}\nenable_zookeeper: {{ enable_zookeeper }}\nenable_kafka: {{ enable_kafka }}\nenable_nginx: {{ enable_nginx }}\nenable_fsf: {{ enable_fsf }}\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "f421a24af4ec2621d2856842ec477aab5fe5453f", "filename": "tasks/Linux/fetch/openjdk-fallback.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: 'Fetch root page {{ openjdk_root_page }}'\n  uri:\n    url: '{{ openjdk_root_page }}'\n    return_content: true\n  register: root_page\n\n- name: Find GA release version\n  set_fact:\n    java_major_version: >-\n      {{ root_page['content']\n        | regex_findall('Ready for use:.*>JDK ([\\d]+)<')\n        | first\n      }}\n\n- name: Out java_major_version\n  debug:\n    var: java_major_version\n\n- name: Fetch GA release page\n  uri:\n    url: '{{ openjdk_root_page }}/{{ java_major_version }}/'\n    return_content: true\n  register: ga_release_page\n\n- name: Find release url\n  set_fact:\n    release_url: >-\n      {{ ga_release_page['content']\n        | regex_findall('(https://download[\\.\\w]+/java/GA/jdk'\n          + java_major_version|string + '[.\\d]*/[\\d\\w]+/'\n          + '[.\\d]+/GPL/openjdk-'\n          + java_major_version|string + '[\\d._]+linux-x64_bin[\\w\\d.]+)')\n      }}\n\n- name: Exit if OpenJDK version is not General-Availability Release\n  fail:\n    msg: 'OpenJDK version {{ java_major_version }} not GA Release'\n  when: release_url[1] is not defined\n\n- name: 'Get artifact checksum {{ release_url[1] }}'\n  uri:\n    url: '{{ release_url[1] }}'\n    return_content: true\n  register: artifact_checksum\n\n- name: 'Download artifact from {{ release_url[0] }}'\n  get_url:\n    url: '{{ release_url[0] }}'\n    dest: '{{ java_download_path }}'\n    checksum: 'sha256:{{ artifact_checksum.content }}'\n  register: file_downloaded\n  retries: 20\n  delay: 5\n  until: file_downloaded is succeeded\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "2aa063bb353e89c5f6ba558f790fc20fee1bd874", "filename": "examples/playbooks/cleanup_engine.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\n# example playbook for cleanup engines\n# use with cleanup_engine.inv\n- hosts: engine\n  remote_user: root\n  roles:\n    - {role: ovirt-engine-cleanup}\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "459480c05a1f6608bf799d24b1473559dbcf9512", "filename": "playbooks/bb4/templates/squid.j2", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "acl mynetwork src {{proxy_cidr}}\n\nhttp_access allow mynetwork\n\n#defaults\nacl localnet src 10.0.0.0/8\nacl localnet src 172.16.0.0/12\nacl localnet src 192.168.0.0/16\nacl localnet src fc00::/7\nacl localnet src fe80::/10\nacl SSL_ports port 443\nacl Safe_ports port 80\nacl Safe_ports port 21\nacl Safe_ports port 443\nacl Safe_ports port 70\nacl Safe_ports port 210\nacl Safe_ports port 1025-65535\nacl Safe_ports port 280\nacl Safe_ports port 488\nacl Safe_ports port 591\nacl Safe_ports port 777\nacl CONNECT method CONNECT\nhttp_access allow manager localhost\nhttp_access deny manager\nhttp_access deny !Safe_ports\nhttp_access deny CONNECT !SSL_ports\nhttp_access allow localnet\nhttp_access allow localhost\nhttp_access deny all\nhttp_port 3128\ncoredump_dir /var/spool/squid2\nrefresh_pattern ^ftp:       1440    20% 10080\nrefresh_pattern ^gopher:    1440    0%  1440\nrefresh_pattern -i (/cgi-bin/|\\?) 0 0%  0\nrefresh_pattern .       0   20% 4320\n\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "45461aa09a5b5838dedd0f5fbdede713a7526bb7", "filename": "roles/ovirt-engine-remote-db/tasks/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\n# main file for remote DB task\n# based on https://fedoraproject.org/wiki/PostgreSQL\n\n- name: check PostgreSQL service\n  service:\n    name: postgresql\n    state: running\n  register: postgresql_status\n  ignore_errors: True\n\n# install libselinux-python on machine - selinux policy\n- name: install libselinux-python for ansible\n  yum:\n    name: libselinux-python\n    state: \"present\"\n  when: postgresql_status|failed\n\n# for semanage utility\n- name: install policycoreutils-python for changing selinux port\n  yum:\n    name: policycoreutils-python\n    state: \"present\"\n  when: postgresql_status|failed\n\n- name: yum install PostgreSQL\n  yum:\n    name: \"postgresql-server\"\n    state: installed\n    update_cache: yes\n  when: postgresql_status|failed\n\n- name: run PostgreSQL initdb\n  become_user: postgres\n  become: yes\n  shell: '/usr/bin/initdb -D /var/lib/pgsql/data'\n  when: postgresql_status|failed\n  tags:\n    - skip_ansible_lint\n\n- name: start PostgreSQL service\n  service:\n    name: postgresql\n    state: started\n    enabled: yes\n\n# allow access engine database access from outside\n- name: update pg_hba.conf -> host ovirt_engine_db_name ovirt_engine_db_user 0.0.0.0/0 md5\n  lineinfile:\n    dest: '/var/lib/pgsql/data/pg_hba.conf'\n    insertafter: EOF\n    line: \"host {{ovirt_engine_db_name}} {{ovirt_engine_db_user}} 0.0.0.0/0 md5\"\n  when: ovirt_engine_remote_db == True\n\n# allow access dwh database access from outside\n- name: update pg_hba.conf -> host ovirt_engine_db_dwh_name ovirt_engine_db_dwh_user 0.0.0.0/0 md5\n  lineinfile:\n    dest: '/var/lib/pgsql/data/pg_hba.conf'\n    insertafter: EOF\n    line: \"host {{ovirt_engine_dwh_db_name}} {{ovirt_engine_dwh_db_user}} 0.0.0.0/0 md5\"\n  when: ovirt_engine_dwh_remote_db == True\n\n# listen on specific address\n- name: update postgresql.conf -> listen_addresses='*'\n  lineinfile:\n    dest: '/var/lib/pgsql/data/postgresql.conf'\n    insertafter: EOF\n    line: \"listen_addresses='{{ovirt_engine_remote_db_listen_address}}'\"\n  when: postgresql_status|failed\n\n# listen on specific port\n- name: update postgresql.conf -> port number\n  lineinfile:\n    dest: '/var/lib/pgsql/data/postgresql.conf'\n    insertafter: EOF\n    line: \"port={{ovirt_engine_remote_db_port}}\"\n  when: postgresql_status|failed and ovirt_engine_remote_db_port != 5432\n\n# postgresql.conf: (el7)\n# Note: In RHEL/Fedora installations, you can't set the port number here;\n#   adjust it in the service file instead.\n#   /usr/lib/systemd/system/postgresql.service\n#    - Environment=PGPORT=5432\n- name: update postgresql.conf -> port number in service file (Fedora & RHEL)\n  lineinfile:\n    dest: '/usr/lib/systemd/system/postgresql.service'\n    backrefs: yes\n    regexp: \"Environment=PGPORT=5432\"\n    line: \"Environment=PGPORT={{ovirt_engine_remote_db_port}}\"\n  register: port_update\n  when: postgresql_status|failed and ovirt_engine_remote_db_port != 5432\n  ignore_errors: True\n\n# daemon reload - service file was changed\n- name: systemctl daemon-reload (el7)\n  shell: 'systemctl daemon-reload'\n  when: postgresql_status|failed and ovirt_engine_remote_db_port != 5432 and port_update|success\n  tags:\n    - skip_ansible_lint\n\n# el6 use only service (systemctl not present)\n- name: update postgresql.conf -> port number in service file (el6)\n  lineinfile:\n    dest: '/etc/init.d/postgresql'\n    backrefs: yes\n    regexp: \"PGPORT=5432\"\n    line: \"PGPORT={{ovirt_engine_remote_db_port}}\"\n  when: postgresql_status|failed and ovirt_engine_remote_db_port != 5432 and port_update|failed\n  ignore_errors: True\n\n# allow selinux for postgresql non-standard port\n- name: allow selinux for non-standard port\n  shell: 'semanage port -a -t postgresql_port_t -p tcp {{ovirt_engine_remote_db_port}}'\n  when: postgresql_status|failed and ovirt_engine_remote_db_port != 5432\n  ignore_errors: True\n  tags:\n    - skip_ansible_lint\n\n# first check of PostgreSQL - if fail, setup\n- name: PostgreSQL reload configuration\n  service:\n    name: postgresql\n    state: restarted\n\n- name: check iptables service\n  service:\n    name: iptables\n    state: running\n  register: iptables_status\n  when: postgresql_status|failed\n  ignore_errors: True\n\n- name: open port for PostgreSQL in iptables\n  shell: \"iptables -I INPUT -p tcp -m state --state NEW -m tcp --dport {{ovirt_engine_remote_db_port}} -j ACCEPT\"\n  when: postgresql_status|failed and not iptables_status|failed\n  tags:\n    - skip_ansible_lint\n\n- name: save iptables rules\n  shell: \"/sbin/iptables-save\"\n  when: postgresql_status|failed and not iptables_status|failed\n  tags:\n    - skip_ansible_lint\n\n- name: check firewalld service\n  service:\n    name: firewalld\n    state: running\n  register: firewalld_status\n  when: postgresql_status|failed\n  ignore_errors: True\n\n- name: open port for PostgreSQL in firewalld\n  firewalld:\n    port: \"{{ovirt_engine_remote_db_port|int}}/tcp\"\n    permanent: True\n    state: enabled\n  when: postgresql_status|failed and not firewalld_status|failed\n\n- name: reload firewalld\n  shell: \"firewall-cmd --reload\"\n  when: postgresql_status|failed and not firewalld_status|failed\n  tags:\n    - skip_ansible_lint\n\n- name: creating directory for sql scripts in /tmp/ansible-sql\n  file:\n    path: /tmp/ansible-sql\n    state: directory\n\n- name: copy SQL scripts\n  template:\n    src: \"{{item}}.j2\"\n    dest: \"/tmp/ansible-sql/{{item}}\"\n    mode: 0644\n    owner: postgres\n    group: postgres\n  with_items:\n    - \"ovirt-engine-db-create.sql\"\n    - \"ovirt-engine-db-user-create.sql\"\n    - \"ovirt-engine-dwh-db-create.sql\"\n    - \"ovirt-engine-dwh-db-user-create.sql\"\n\n- name: create engine DB and user\n  become_user: postgres\n  become: yes\n  command: psql -p {{ovirt_engine_remote_db_port}} -a -f /tmp/ansible-sql/'{{item}}'\n  with_items:\n    - \"ovirt-engine-db-user-create.sql\"\n    - \"ovirt-engine-db-create.sql\"\n  when: ovirt_engine_remote_db == True\n\n- name: create engine DWH DB and user\n  become_user: postgres\n  become: yes\n  command: psql -p {{ovirt_engine_remote_db_port}} -a -f /tmp/ansible-sql/'{{item}}'\n  with_items:\n    - \"ovirt-engine-dwh-db-user-create.sql\"\n    - \"ovirt-engine-dwh-db-create.sql\"\n  when: ovirt_engine_dwh_remote_db == True\n\n- name: check PostgreSQL service\n  service:\n    name: postgresql\n    state: started\n    enabled: yes\n\n- name: clean tmp files\n  file:\n    path: '/tmp/ansible-sql'\n    state: 'absent'\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "95ddcbec74759cd60523a6bcd9f6ea1a7987a44d", "filename": "roles/common/defaults/main.yml", "repository": "roots/trellis", "decoded_content": "ansible_requirements:\n  - version: 2.0.2.0\n    operator: '>='\n  - version: 2.1.0.0\n    operator: '!='\n\ndefault_timezone: Etc/UTC\n"}, {"commit_sha": "4e46e9eb277bc88f285dbc9dd980193e57f7bf48", "sha": "4aa7b46327618eb5ca7d70b6f6bc13a878a08dd7", "filename": "tasks/configure-non-systemd.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "- name: Setup Docker environment file {{ docker_envs_dir[_docker_os_dist] }}/docker\n  template:\n    src: docker-envs.j2\n    dest: \"{{ docker_envs_dir[_docker_os_dist] }}/docker\"\n  become: yes\n  notify: restart docker\n  vars:\n    docker_opts: \"{{ docker_daemon_opts }}\""}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "5c9ccc09f75ba26bdb024b3d279956a7695ac525", "filename": "playbooks/files/nm-issue-update", "repository": "rocknsm/rock", "decoded_content": "#!/bin/bash\n# 90-issue-update\n# Description: Updates /etc/issue using template /etc/issue.in and\n#              values from system at time of interface up\n\nIF=$1\nSTATUS=$2\n\nfunction update_issue() {\n  . /etc/os-release\n  OS_RELEASE=\"${NAME} ${VERSION}\";\n  IP_ADDR=$(ip route get 255.255.255.255 | awk '{print $6 \" (\"$4\")\"; exit}')\n  cat /etc/issue.in | sed \"s/{{OS_RELEASE}}/${OS_RELEASE}/;s/{{IP_ADDR}}/${IP_ADDR}/\" > /etc/issue\n\n  # Reset gettys where a user is not logged in\n  GETTYS=$(systemctl list-units | grep \"getty@\" | grep -vE \"$(who | awk '{ print $2 }'|paste -sd'|' )\" | awk '{print $1}'|paste -s)\n  systemctl restart $(GETTYS)\n}\n\nif [ \"$IF\" <> \"lo\" ]\nthen\n  case \"$2\" in\n    up)\n      logger -s \"NM Script up triggered\"\n      update_issue\n      ;;\n    down)\n      logger -s \"NM Script down triggered\"\n      update_issue\n      ;;\n    *)\n      ;;\n  esac\nfi\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "b94daa1eb21d995fbc562661ac93d3062b9fada2", "filename": "tasks/admin_password_setup.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: update_admin_password\n    args:\n      new_password: \"{{ nexus_admin_password }}\"\n\n- name: Admin password changed\n  set_fact:\n    current_nexus_admin_password: \"{{ nexus_admin_password }}\"\n  no_log: true\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "ac953416bc6d93ae8434f79292773445854a392f", "filename": "roles/consul/handlers/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# handlers file for consul\n- name: restart consul\n  service:\n    name: consul\n    state: restarted\n  sudo: yes\n  notify:\n    - wait for consul to listen\n\n- name: wait for consul to listen\n  wait_for:\n    host: \"{{ consul_bind_addr }}\"\n    port: 8500\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "e68d3cfbc1ae0b5c5f4ec21fabbaa43fb4895e52", "filename": "roles/ansible/tower/config-ansible-tower-ldap/tasks/ldap.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- block: # become: True\n\n  - name: \"Upload Cert CA to Ansible Tower (if applicable)\"\n    copy:\n      src: \"{{ ansible_tower.ldap.ca_cert }}\"\n      dest: \"/etc/pki/ca-trust/source/anchors/{{ ansible_tower.ldap.ca_cert | basename }}\"\n    when:\n    - ansible_tower.ldap.ca_cert is defined\n    - ansible_tower.ldap.ca_cert|trim != ''\n    notify:\n    - restart-tower\n    register: ca_uploaded\n\n  - name: \"Update CA trust if a new CA was added\"\n    command: update-ca-trust\n    when:\n    - ca_uploaded is defined\n    - ca_uploaded.changed\n\n  - name: \"Update Ansible Tower LDAP config\"\n    uri:\n      url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}/api/v1/settings/ldap/\"\n      user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      password: \"{{ ansible_tower.admin_password }}\"\n      force_basic_auth: yes\n      method: PUT\n      body: \"{{ lookup('template', 'ldap.j2') }}\"\n      body_format: 'json'\n      headers:\n        Content-Type: \"application/json\"\n        Accept: \"application/json\"\n      validate_certs: no\n    notify:\n    - restart-tower\n\n  - name: \"Force LDAP Sync\"\n    uri:\n      url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}/api/\"\n      user: \"{{ ansible_tower.ldap.bind_dn.split(',') | first | regex_replace('uid=') }}\"\n      password: \"{{ ansible_tower.ldap.bind_password }}\"\n      force_basic_auth: yes\n      method: GET\n      validate_certs: no\n    register: status_output\n    until: status_output.status == 200\n    retries: 6\n    delay: 5\n\n  become: True\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "31b5d0840f67ba22065eaf34184c7666c9a3cd22", "filename": "tasks/create_repo_pypi_proxy_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_pypi_proxy\n    args: \"{{ _nexus_repos_pypi_defaults|combine(item) }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "ff1d43f3ad7f46254a69892dff6733675b187af3", "filename": "playbooks/osp/inventory/openstack.py", "repository": "redhat-cop/infra-ansible", "decoded_content": "../../../files/openstack.py"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "16eb4adc4c062e3a89c32a60a0424497cfa9b46d", "filename": "examples/playbooks/install_engine.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\n# example playbook for installing engines\n# use with examples/inventory/install_engine.inv\n- hosts: engine\n  remote_user: root\n  roles:\n    - {role: ovirt-common}\n    - {role: ovirt-engine-install-packages}\n    - {role: ovirt-engine-setup}\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "6f87be40064542ba48c20eab76c41701429ba913", "filename": "roles/config-postgresql/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Install Containerized PostgreSQL\n  include_tasks: install_containerized.yml\n  when: mode == \"containerized\"\n\n- name: Flush Handlers (Postgresql)\n  meta: flush_handlers\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "db727359b0736026ea3fbd6046834d7f21d4209d", "filename": "roles/ovirt-engine-config/handlers/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\n# oVirt engine restart is required if configuration changed\n- name: restart of ovirt-engine service\n  service:\n    name: ovirt-engine\n    state: restarted\n\n- name: check health status of page\n  uri:\n    url: \"http://localhost/ovirt-engine/services/health\"\n    status_code: 200\n  register: health_page\n  retries: 12\n  delay: 10\n  until: health_page|success\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "4c1a002ea81a4c8b89de4f7fbfbd4678236fef19", "filename": "playbooks/files/logstash-kafka-suricata.conf", "repository": "rocknsm/rock", "decoded_content": "input {\n  kafka {\n    topics => [\"suricata-raw\"]\n    add_field => { \"[@metadata][stage]\" => \"suricataraw_kafka\" }\n    # Set this to one per kafka partition to scale up\n    #consumer_threads => 4\n    group_id => \"suricata_logstash\"\n    bootstrap_servers => \"127.0.0.1:9092\"\n    codec => json\n    auto_offset_reset => \"earliest\"\n  }\n}\n\nfilter {\n  if \"_jsonparsefailure\" in [tags] {\n    drop { }\n  }\n\n  # Remove kafka_topic field\n  mutate {\n    remove_field => [ \"kafka_topic\" ]\n  }\n\n  if [@metadata][stage] == \"suricataraw_kafka\" {\n\n    # Set the timestamp\n    date { match => [ \"timestamp\", \"ISO8601\" ] }\n    }    \n}\n\noutput {\n  if [@metadata][stage] == \"suricataraw_kafka\" {\n    kafka {\n     codec => json\n     topic_id => \"suricata-clean\"\n     bootstrap_servers => \"127.0.0.1:9092\"\n    }\n\n    elasticsearch {\n      hosts => [\"127.0.0.1\"]\n      index => \"suricata-%{+YYYY.MM.dd}\"\n      manage_template => false\n      document_type => \"%{event_type}\"\n    }\n  }\n}\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "ac7cc02fe22fa6e072cdc445281a6201ad450c59", "filename": "tasks/Win32NT/install/zulu_tarball.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Check that the java_folder exists\n  win_stat:\n    path: '{{ java_path }}\\{{ java_folder }}\\bin'\n  register: java_folder_bin\n\n- name: Install java from tarball\n  block:\n  - name: Mkdir for java installation\n    win_file:\n      path: '{{ java_path }}\\{{ java_folder }}'\n      state: directory\n\n  - name: Create temporary directory\n    win_tempfile:\n      state: directory\n    register: temp_dir_path\n\n  - name: Unarchive to temporary directory\n    win_unzip:\n      src: '{{ java_artifact }}'\n      dest: '{{ temp_dir_path }}'\n\n  - name: Find java_folder in temp\n    win_find:\n      paths: '{{ temp_dir_path }}'\n      recurse: false\n      file_type: directory\n    register: java_temp_folder\n\n  - name: Copy from temporary directory\n    win_copy:\n      src: '{{ java_temp_folder.files | map(attribute=\"path\") | list | last }}\\'\n      dest: '{{ java_path }}\\{{ java_folder }}'\n      remote_src: true\n  when: not java_folder_bin.stat.exists | bool\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "00f20e0f5b09245c54f19ffa6a73226c45013455", "filename": "playbooks/minishift-remote/prerequisites.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Install firewalld\n  package:\n    name: firewalld\n    state: latest\n\n- name: Enable and Start firewalld\n  service:\n    name: firewalld\n    enabled: yes\n    state: started\n\n- name: Configure Docker\n  include_role:\n    name: \"{{ docker_item }}\"\n  loop:\n    - config-container-storage-setup\n    - config-docker\n  loop_control:\n    loop_var: docker_item\n  when: (docker_install | bool) | default(false)"}, {"commit_sha": "96adc61e360141bb718b75d48c387b3680a8471b", "sha": "bd6e3ef84f074c04cfe4be5befd4859e63151a45", "filename": "tasks/main.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Set distribution facts\n  set_fact:\n    _docker_os_dist: \"{{ ansible_distribution }}\"\n    _docker_os_dist_release: \"{{ ansible_distribution_release }}\"\n    _docker_os_dist_major_version: \"{{ ansible_distribution_major_version }}\"\n    _docker_os_dist_check: yes\n  tags: [\"install\", \"configure\"]\n\n- name: Reinterpret distribution facts for Linux Mint 18\n  set_fact:\n    _docker_os_dist: \"Ubuntu\"\n    _docker_os_dist_release: \"xenial\"\n    _docker_os_dist_major_version: \"16\"\n  when:\n    _docker_os_dist == \"Linux Mint\" and\n    _docker_os_dist_major_version == \"18\"\n  tags: [\"install\", \"configure\"]\n\n# https://wiki.ubuntu.com/SystemdForUpstartUsers\n# Important! systemd is only fully supported in Ubuntu 15.04 and later releases\n- name: Determine usage of systemd\n  shell: \"ps -p1 | grep systemd 1>/dev/null && echo systemd || echo upstart\"\n  become: true\n  changed_when: no\n  register: _determine_systemd_usage\n\n- name: Set fact to indicate systemd is not used\n  set_fact:\n    _docker_systemd_used: \"{{ _determine_systemd_usage is defined and _determine_systemd_usage.stdout == 'systemd' }}\"\n\n- name: Compatibility and distribution checks\n  include_tasks: checks.yml\n  tags: [\"install\", \"configure\"]\n\n- name: Setup Docker package repositories\n  include_tasks: setup-repository.yml\n  tags: [\"install\"]\n\n- name: Remove Docker versions before Docker CE\n  include_tasks: remove-pre-docker-ce.yml\n  when: docker_remove_pre_ce | bool\n  tags: [\"install\"]\n\n- name: Install Docker\n  include_tasks: install-docker.yml\n  tags: [\"install\"]\n\n- name: Configure audit logging\n  include_tasks: setup-audit.yml\n  tags: [\"configure\"]\n\n- name: Apply workarounds for bugs and/or tweaks\n  include_tasks: bug-tweaks.yml\n  tags: [\"configure\"]\n\n- name: Configure systemd service\n  include_tasks: configure-systemd.yml\n  when: _docker_systemd_used | bool\n  tags: [\"configure\"]\n\n- name: Configure non-systemd service\n  include_tasks: configure-non-systemd.yml\n  when: _docker_systemd_used | bool == false\n  tags: [\"configure\"]\n\n- name: Configure Docker\n  include_tasks: configure-docker.yml\n  tags: [\"configure\"]\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "a0fc192d72cf9ef286c3b9f84db10b31eb152f3d", "filename": "tasks/section_07.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - include: section_07_level1.yml\n    tags:\n      - section07\n      - level1\n\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "120d1dc0053598c52e92249ef75b8639fbf0a126", "filename": "roles/vpn/defaults/main.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\nstrongswan_enabled_plugins:\n  - aes\n  - gcm\n  - hmac\n  - kernel-netlink\n  - nonce\n  - openssl\n  - pem\n  - pgp\n  - pkcs12\n  - pkcs7\n  - pkcs8\n  - pubkey\n  - random\n  - revocation\n  - sha2\n  - socket-default\n  - stroke\n  - x509\n\nciphers:\n  defaults:\n    ike: aes128gcm16-prfsha512-ecp256!\n    esp: aes128gcm16-ecp256!\n  compat:\n    ike: aes128gcm16-prfsha512-ecp256,aes128-sha2_512-prfsha512-ecp256,aes128-sha2_512-prfsha512-modp2048!\n    esp: aes128gcm16-ecp256,aes128-sha2_512-ecp256,aes128-sha2_512-prfsha512-modp2048!\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "13a04cbfb81bbff451a36d0550e7f94edd9e92ad", "filename": "roles/sugar-stats/tasks/statistics-consolidation.yml", "repository": "iiab/iiab", "decoded_content": "- name: Install python-pip package\n  package: name=python-pip\n           state=present\n\n- name: Install statistics-consolidation with pip\n  pip: name=stats-consolidation version=2.1.2\n  when: internet_available\n\n- name: Install required libraries\n  package: name={{ item }}\n           state=present\n  with_items:\n    - rrdtool-python\n    - python-sqlalchemy\n    - python-psycopg2\n\n- name: Enable postgresl access by md5 method\n  lineinfile: backup=yes\n              dest=/library/pgsql-iiab/pg_hba.conf\n              regexp=\"^host\\s+statsconso\"\n              line=\"host     statsconso     statsconso     samehost     md5\"\n              state=present\n              insertafter=\"^# IPv4 local connections\"\n              owner=postgres\n              group=postgres\n\n- name: Restart postgresql service\n  service: name=postgresql-iiab\n           state=restarted\n\n- name: Create postgres user\n  postgresql_user: user=statsconso password=statsconso\n  become: yes\n  become_user: postgres\n\n- name: Create postgres database\n  postgresql_db: db=statsconso owner=statsconso\n  sudo: yes\n  sudo_user: postgres\n\n- name: Install conf file\n  template: backup=yes\n            src=statistics-consolidation/stats-consolidation.conf\n            dest=/etc/stats-consolidation.conf\n            owner=root\n            group=root\n            mode=0644\n\n- name: Create log directory\n  file: path=/var/log/statistics-consolidation\n        state=directory\n        group=sugar-stats\n        owner=sugar-stats\n        mode=0755\n\n- name: Enable logrotate\n  template: backup=yes\n            src=statistics-consolidation/stats-consolidation.logrotate\n            dest=/etc/logrotate.d/stats-consolidation\n            group=root\n            owner=root\n            mode=0644\n\n- name: Install cron file\n  template: backup=yes\n            src=statistics-consolidation/stats-consolidation.cron\n            dest=/etc/cron.d/stats-consolidation\n            owner=root\n            group=root\n            mode=0644\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "aaae48663a9c3287dc198ac196ebcf478c263691", "filename": "playbooks/ansible/tower/README.md", "repository": "redhat-cop/infra-ansible", "decoded_content": "# Ansible Tower Playbooks\n\nThis playbook directory has the playbook(s) necessary to manage your Ansible Tower.\n\n## Prerequisites\n\nCurrently, the playbook(s) in here do not manage the instances (a.k.a.: VMs) themselves, so you need to ensure you already have running instances (and subscribed if applicable) before running these playbook(s) with a valid inventory.\n\n## Example\n\n### Inventory\n\nPlease see the inventory in the respective role for more details:\n\n- [tower](../../../roles/ansible/tower/README.md)\n\n\n### Playbook execution\n\nInitial run needs the `tags='install,all'` set to ensure all necessary software is installed:\n\n```bash\n> ansible-playbook -i inventory configure-ansible-tower.yml --tags='install,all'\n```\n\nAny consecutive runs can be done without the tags to speed up execution:\n```bash\n> ansible-playbook -i inventory configure-ansible-tower.yml\n```\n\n\nLicense\n-------\n\nApache License 2.0\n\n\nAuthor Information\n------------------\n\nRed Hat Community of Practice & staff of the Red Hat Open Innovation Labs.\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "79cbd2976f4ccdbe58989e676fdfbc40d82a3d87", "filename": "roles/schooltool/meta/main.yml", "repository": "iiab/iiab", "decoded_content": "---\ndependencies:\n    - { role: docker }\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "77b86c3aff5471a37de8dc507b12d4a9a02c11ff", "filename": "roles/rachel/templates/footer.html", "repository": "iiab/iiab", "decoded_content": "\n<!-- START FOOTER -->\n\n<div style=\"clear: left;\"></div>\n</li>\n</ul>\n</div>\n\n\n<p/>\n\n\n<div style=\"clear: both;\"></div>\n</div>\n\n<div id=\"haut\">\n\t\t<ul class=\"menuhaut\" >\n\t\t\t<li><a href=\"{{ rachel_url }}/index.html\">HOME</a></li>\n\t\t\t<li><a href=\"{{ rachel_url }}/about.html\">ABOUT</a></li>\n\t\t</ul>\n\t\t<div id=\"footer_right\">RACHEL - SEP 2013 Version</div>\n\n</div>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n\n</body>\n</html>\n\n"}, {"commit_sha": "b7c6bfe0369646ca69beeb3dfe07e8218d61c940", "sha": "b3ceff3e4b7741ba9c65dbd28c511a134b14e54e", "filename": "tasks/apt.yml", "repository": "dev-sec/ansible-os-hardening", "decoded_content": "---\n- name: remove deprecated or insecure packages | package-01 - package-09\n  apt:\n    name: '{{ item }}'\n    state: 'absent'\n  with_items:\n    - '{{ os_security_packages_list }}'\n  when: 'os_security_packages_clean'\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "cf0a1550102d6f81c1a89c8d3ab7cada764c1dfb", "filename": "playbooks/lb-vms.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Generate the HAproxy configuration'\n  hosts: lb_mgmt\n  vars: \n    haproxy_temp_file: '/tmp/haproxy.cfg'\n  roles:\n  - role: haproxy-config\n\n- name: 'Configure the LB hosts'\n  hosts: lb_vms\n  become: True\n  vars: \n    haproxy_temp_file: '/tmp/haproxy.cfg'\n  roles:\n  - role: keepalived\n  - role: haproxy\n  \n- name: 'Clean-Up'\n  hosts: lb_mgmt\n  tasks: \n  - name: 'Remove tmp file' \n    file:\n      path: '/tmp/haproxy.cfg'\n      state: absent  \n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "34ade9650f383f273a793bd03e9188824e1f520e", "filename": "roles/config-docker-compose/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Make sure dependencies are met\"\n  vars: \n    docker_install: True\n  include_role:\n    name: config-docker\n  when:\n  - docker_compose_install|default(False)\n\n- name: \"Install, configure and enable Docker-compose\"\n  import_tasks: docker-compose.yml\n  when:\n  - docker_compose_install|default(False)\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "db625270140b73d90f2da1d7be4a9cadabbd34c1", "filename": "roles/config-quay-enterprise/tasks/firewall.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Check if firewalld is installed\n  command: systemctl status firewalld\n  register: firewalld_status\n  failed_when: false\n  changed_when: false\n\n- name: Check if iptables is installed\n  command: systemctl status iptables\n  register: iptables_status\n  failed_when: false\n  changed_when: false\n\n- name: Open port in firewalld\n  firewalld:\n    port: \"{{ item }}/tcp\"\n    permanent: true\n    state: enabled\n  when: firewalld_status.rc == 0\n  with_items:\n    - \"{{ quay_host_http_port }}\"\n    - \"{{ quay_host_https_port }}\"\n  notify:\n  - restart firewalld\n\n- name: Ensure iptables is correctly configured\n  lineinfile:\n    insertafter: \"^-A INPUT .* --dport {{ item }} .* ACCEPT\"\n    state: present\n    dest: /etc/sysconfig/iptables\n    regexp: \"^-A INPUT .* --dport {{ item }} .* ACCEPT\"\n    line: \"-A INPUT -p TCP -m state --state NEW -m TCP --dport {{ item }} -j ACCEPT\"\n  with_items:\n    - \"{{ quay_host_http_port }}\"\n    - \"{{ quay_host_https_port }}\"\n  when: iptables_status.rc == 0 and firewalld_status.rc != 0\n  notify:\n  - restart iptables\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "32c5ffa4a22c502a0a1a714e65846029eafdb43e", "filename": "roles/config-openvpn/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: prep.yml\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "2e8ee3c777c72b5cfd6d861522f26cac83cdc118", "filename": "roles/config-httpd/tasks/seed.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Seed web server with content'\n  copy:\n    src: \"{{ httpd_seed_dir }}\"\n    dest: \"{{ html_document_root | default(default_document_root) }}\"\n  when:\n  - httpd_seed_dir is defined\n  - httpd_seed_dir|trim != \"\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "da2b29330e7e4d42cb2cf9a8af99d72654b2c755", "filename": "roles/network/templates/squid/sites.whitelist.txt", "repository": "iiab/iiab", "decoded_content": "# the leading dot matches anything preceeding\n# don't remove the .lan line\n# change this to your domain if necessary\n.{{ iiab_domain }}\n.laptop.org\n.olpcMAP.net\n.mapmeld.appspot.com\n.googlecode.com\n.googleapis.com\n.translate.google.com\n.gstatic.com\n.unleashkids.org\n.iiab.io.org\n.hopeforhaitischildren.org\n.lenouvelliste.com\n.voanouvel.com\n.bing.com\n.microsofttranslator.com\n.sugarlabs.org\n"}, {"commit_sha": "b7c6bfe0369646ca69beeb3dfe07e8218d61c940", "sha": "ce95ea3e10dfa5c17e78e5ba5a833291a88aef48", "filename": "tasks/pam.yml", "repository": "dev-sec/ansible-os-hardening", "decoded_content": "---\n- name: update pam on Debian systems\n  command: 'pam-auth-update --package'\n  when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'\n  changed_when: False\n  environment:\n    DEBIAN_FRONTEND: noninteractive\n\n- name: remove pam ccreds on Debian systems\n  apt:\n    name: '{{ os_packages_pam_ccreds }}'\n    state: 'absent'\n  when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'\n\n- name: remove pam ccreds on Redhat systems\n  yum:\n    name: '{{ os_packages_pam_ccreds }}'\n    state: 'absent'\n  when: ansible_os_family == 'RedHat'\n\n- name: remove pam_cracklib, because it does not play nice with passwdqc\n  apt:\n    name: '{{ os_packages_pam_cracklib }}'\n    state: 'absent'\n  when: (ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu') and os_auth_pam_passwdqc_enable\n\n- name: install the package for strong password checking\n  apt:\n    name: '{{ os_packages_pam_passwdqc }}'\n    state: 'present'\n    update_cache: 'yes'\n  when: (ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu') and os_auth_pam_passwdqc_enable\n\n- name: configure passwdqc\n  template:\n    src: 'pam_passwdqc.j2'\n    dest: '{{ passwdqc_path }}'\n    mode: '0640'\n    owner: 'root'\n    group: 'root'\n  when: (ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu') and os_auth_pam_passwdqc_enable\n\n- name: remove passwdqc\n  apt:\n    name: '{{ os_packages_pam_passwdqc }}'\n    state: 'absent'\n  when: (ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu') and not os_auth_pam_passwdqc_enable\n\n- name: install tally2\n  apt:\n    name: 'libpam-modules'\n    state: 'present'\n  when: (ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu') and not os_auth_pam_passwdqc_enable and os_auth_retries > 0\n\n- name: configure tally2\n  template:\n    src: 'pam_tally2.j2'\n    dest: '{{ tally2_path }}'\n    mode: '0640'\n    owner: 'root'\n    group: 'root'\n  when: (ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu') and not os_auth_pam_passwdqc_enable and os_auth_retries > 0\n\n- name: delete tally2 when retries is 0\n  file:\n    path: '{{ tally2_path }}'\n    state: 'absent'\n  when: (ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu') and not os_auth_pam_passwdqc_enable and os_auth_retries == 0\n\n- name: remove pam_cracklib, because it does not play nice with passwdqc\n  yum:\n    name: '{{ os_packages_pam_cracklib }}'\n    state: 'absent'\n  when: ((ansible_os_family == 'RedHat' and ansible_distribution_version < '7') or ansible_distribution == 'Amazon') and os_auth_pam_passwdqc_enable\n\n- name: install the package for strong password checking\n  yum:\n    name: '{{ os_packages_pam_passwdqc }}'\n    state: 'present'\n  when: ((ansible_os_family == 'RedHat' and ansible_distribution_version < '7') or ansible_distribution == 'Amazon') and os_auth_pam_passwdqc_enable\n\n- name: remove passwdqc\n  yum:\n    name: '{{ os_packages_pam_passwdqc }}'\n    state: 'absent'\n  when: ansible_os_family == 'RedHat' and not os_auth_pam_passwdqc_enable\n\n- name: configure passwdqc and tally via central system-auth confic\n  template:\n    src: 'rhel_system_auth.j2'\n    dest: '/etc/pam.d/system-auth-ac'\n    mode: '0640'\n    owner: 'root'\n    group: 'root'\n\n- name: NSA 2.3.3.5 Upgrade Password Hashing Algorithm to SHA-512\n  template:\n    src: 'rhel_libuser.conf.j2'\n    dest: '/etc/libuser.conf'\n    mode: '0640'\n    owner: 'root'\n    group: 'root'\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "d64038473437f1ed08189396ec04e65845069ca7", "filename": "roles/cadvisor/defaults/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# defaults file for cadvisor\ncadvisor_enabled: true\ncadvisor_version: 'latest'\ncadvisor_restart_policy: 'always'\ncadvisor_net: 'bridge'\ncadvisor_hostname: \"{{ ansible_ssh_host }}\"\ncadvisor_image: \"google/cadvisor:{{ cadvisor_version }}\"\ncadvisor_consul_dir: /etc/consul.d\ncadvisor_consul_service_id: \"{{ ansible_hostname }}:cadvisor:8080\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "7205f0f3847261c2bf93e1d60d14320ba2704473", "filename": "roles/config-nagios-target/tasks/prerequisites.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# Ensure the correct repos and software packages are installed\n#- import_tasks: enable-repos.yml\n#- import_tasks: install-epel.yml\n#- import_tasks: install-nagios.yml\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "fac41f0d63df59144b828fe442c313706d740419", "filename": "roles/activity-server/files/lang_templates/en/page", "repository": "iiab/iiab", "decoded_content": "<html>\n<body>\n<h1 id=\"olpc-activity-group-name\">Locally available activities</h1>\n<p id=\"olpc-activity-group-desc\">These activities are stored on the school server.</p>\n%(activities)s\n</body>\n</html>\n"}, {"commit_sha": "e91a55152358e890a05cf849abc7d58b8badecc2", "sha": "88f891af98bee79f6f0d68f052247a064c2debd6", "filename": "tasks/tasks-RedHat.yml", "repository": "fubarhouse/ansible-role-golang", "decoded_content": "---\n\n- name: \"Go-Lang | Install dependencies\"\n  dnf:\n    name: \"{{ item }}\"\n    state: installed\n  with_items:\n    - curl\n    - gcc\n    - git\n    - findutils\n    - make\n    - rsync\n    - tar\n\n- name: \"Go-Lang | Define GOARCH\"\n  set_fact:\n    GOARCH: \"amd64\"\n  when: GOARCH is not defined\n\n- name: \"Go-Lang | Define GOOS\"\n  set_fact:\n    GOOS: \"linux\"\n  when: GOOS is not defined"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "e21bccaf0efee2c631340ff7bb6c0bed12e19de8", "filename": "roles/deploy/tasks/finalize.yml", "repository": "roots/trellis", "decoded_content": "---\n- include: \"{{ deploy_finalize_before | default('../hooks/example.yml') }}\"\n  tags: deploy-finalize-before\n\n- name: Finalize the deploy\n  deploy_helper:\n    current_path: \"{{ project_current_path }}\"\n    path: \"{{ project_root }}\"\n    release: \"{{ deploy_helper.new_release }}\"\n    state: finalize\n\n- include: \"{{ deploy_finalize_after | default('../hooks/example.yml') }}\"\n  tags: deploy-finalize-after\n\n- debug:\n    msg: \"{{ project_version }}@{{ git_clone.after | truncate(7, True, '') }} deployed as release {{ deploy_helper.new_release }}\"\n"}, {"commit_sha": "a94f9ce4fa32273fd0fad7492d36db4101423cc3", "sha": "407838bdfb01178a2d0c4a744395d3446214526d", "filename": "tasks/configure-systemd.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "- name: Combine all systemd service configuration options\n  set_fact:\n    _systemd_service_config: \"{{ docker_systemd_service_config_tweaks + docker_systemd_service_config }}\"\n\n- name: Ensure /etc/systemd/system/docker.service.d directory exists\n  become: true\n  file:\n    path: /etc/systemd/system/docker.service.d\n    state: directory\n    mode: 0755\n\n- name: Setup default Docker drop-in to enable use of environment file\n  become: true\n  template:\n    src: drop-ins/default.conf.j2\n    dest: /etc/systemd/system/docker.service.d/default.conf\n  notify: restart docker\n  register: _systemd_docker_dropin\n  vars:\n    systemd_envs_dir: \"{{ docker_envs_dir[_docker_os_dist] }}\"\n    systemd_service_conf: \"{{ _systemd_service_config }}\"\n\n- name: Combine Docker daemon environment variable configuration\n  set_fact:\n    docker_service_envs: \"{{ docker_service_envs | combine(_docker_service_opts) | combine(docker_daemon_envs) }}\"\n  vars:\n    _docker_service_opts:\n      DOCKER_OPTS: \"{{ docker_daemon_opts }}\"\n\n- name: Setup Docker environment file {{ docker_envs_dir[_docker_os_dist] }}/docker-envs\n  become: true\n  template:\n    src: docker-envs.j2\n    dest: \"{{ docker_envs_dir[_docker_os_dist] }}/docker-envs\"\n  notify: restart docker\n  vars:\n    docker_envs: \"{{ docker_service_envs }}\"\n\n- name: Force daemon reload of systemd\n  become: true\n  systemd:\n    daemon_reload: yes\n  notify: restart docker\n  when: _systemd_docker_dropin|changed"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "2d902a0adb4ea85ccdd6462a222ae28126f3f18d", "filename": "tasks/create_repo_npm_group_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_npm_group\n    args: \"{{ _nexus_repos_npm_defaults|combine(item) }}\""}, {"commit_sha": "473bab1042b717eb6a6641b7240516af4dbae4d8", "sha": "4d64cf03556b528214d44c1e3eb110a4ba39be7d", "filename": "tasks/go-get.yml", "repository": "fubarhouse/ansible-role-golang", "decoded_content": "---\n\n- name: \"Go-Lang | Define list of package directories\"\n  set_fact:\n    go_package_locations:\n    - \"{{ GOPATH }}/bin\"\n    - \"{{ GOPATH }}/pkg\"\n    - \"{{ GOPATH }}/src\"\n  when: go_reget|bool == true\n\n- name: \"Go-Lang | Remove installed workspace packages\"\n  become: yes\n  become_user: \"root\"\n  file:\n    path: \"{{ item }}\"\n    state: absent\n  with_items: \"{{ go_package_locations }}\"\n  ignore_errors: yes\n  when:\n    - go_reget|bool == true\n    - go_package_locations is defined\n\n- name: \"Go-Lang | Run get commands\"\n  shell: \"{{ GOPATH }}/go get -u {{ item.url }}\"\n  environment:\n    GOPATH: \"{{ GOPATH }}\"\n    GOROOT: \"{{ GOROOT }}\"\n  with_items: \"{{ go_get }}\"\n  changed_when: false\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "5b1fc3be1793400e829bd010905f797a1b663f2d", "filename": "playbooks/notifications/email-notify-list-of-users.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Send HTML e-mail message (based on MD) to a list of users\"\n  hosts: mail-host\n  gather_facts: no\n  tasks:\n  - include_vars:\n      file: \"{{ email_content_file }}\"\n  - include_role:\n      name: notifications/md-to-html\n    vars:\n      markdown_content: \"{{ body }}\"\n  - set_fact:\n      mail: \"{{ mail | combine({ 'subject': title, 'body': md_to_html.html_body_message }) }}\"\n  - set_fact:\n      list_of_mail_to: \"{{ list_of_mail_to | default([]) }} + [ '{{ item.email }}' ]\"\n    with_items:\n    - \"{{ list_of_users }}\"\n  - include_role:\n      name: notifications/send-email\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "d02165f10797c2e7e8b37de687aeae4ba02ba0a3", "filename": "roles/wordpress/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "wordpress_download_base_url: https://wordpress.org\nwordpress_src: latest.tar.gz\nwp_db_name: iiab_wp\nwp_db_user: iiab_wp\nwp_db_user_password: changeme\nwordpress_install: True\nwordpress_enabled: True\nwp_install_path: /library\nwp_abs_path: /library/wordpress\nwp_url: /wordpress\nwp_full_url: \"http://{{ iiab_hostname }}{{ wp_url }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "e8d2e4ec21288a7b8018820416b8e5abbeaafacb", "filename": "roles/config-lvm/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- include_tasks: prep.yml\n\n- include_tasks: lvm.yml\n  with_items:\n  - \"{{ lvm_entries | default([]) }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "560774ff3c9635de287fdd68036df80a9495c009", "filename": "roles/sshd/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Disable root login with password\n  lineinfile: dest=/etc/ssh/sshd_config\n              regexp='^PermitRootLogin'\n              line='PermitRootLogin without-password'\n              state=present\n#TODO: use handler to reload ssh\n\n- name: Enable sshd\n  service: name={{ sshd_service }}\n           enabled=yes\n           state=started\n  when: sshd_enabled\n\n- name: Disable sshd\n  service: name={{ sshd_service }}\n           enabled=no\n           state=stopped\n  when: not sshd_enabled\n"}, {"commit_sha": "8c72df4ecfaa4188202ab0872f4500384ffe5233", "sha": "579fed84a6115e618d4203884aa090befc707725", "filename": "tasks/remove-pre-docker-ce.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Determine Docker version\n  command: bash -c \"docker version | grep Version | awk '{print $2}'\"\n  ignore_errors: yes\n  changed_when: false\n  register: _cmd_docker_version\n\n- name: Set fact if old Docker installation shall be removed\n  set_fact:\n    _remove_old_docker: \"{{ docker_remove_pre_ce | bool }} == true and {{ _cmd_docker_version.stdout_lines[0] | search('-ce') }} == false\"\n  when: _cmd_docker_version.stdout_lines is defined and _cmd_docker_version.stdout_lines[0] is defined\n\n- name: Check if Docker is running\n  become: true\n  command: systemctl status docker\n  ignore_errors: yes\n  changed_when: false\n  register: _service_docker_status\n  when: _remove_old_docker | default(False) | bool == true\n\n- name: Stop Docker service\n  service:\n    name: docker\n    state: stopped\n  when: \"_service_docker_status.rc | default(1) == 0\"\n\n- name: Remove old Docker installation before Docker CE\n  become: true\n  package:\n    name: \"{{ item }}\"\n    state: absent\n  when: _remove_old_docker | default(False) | bool\n  with_items:\n    - \"{{ docker_old_packages[_docker_os_dist] }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "acbbbad8a28c834cc2676f1104630ae051290791", "filename": "roles/install-mongodb/tasks/install_mongodb.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: 'Add mongodb repo 3.0 and up'\n  yum_repository:\n    name: \"mongodb-org-{{ mongodb_ver }}\"\n    description: \"MongoDB Repository\"\n    baseurl: https://repo.mongodb.org/yum/{{ os_family }}/{{ os_ver }}/mongodb-org/{{ mongodb_ver }}/x86_64/\n    gpgcheck: yes\n    enabled: yes\n    gpgkey: https://www.mongodb.org/static/pgp/server-{{ mongodb_ver }}.asc\n    file: mongodb-org-{{ mongodb_ver }}\n  when: mongodb_ver|float() >= 3.0\n\n- name: 'Add mongodb repo before 3.0'\n  yum_repository:\n    name: \"mongodb-org-{{ mongodb_ver }}\"\n    description: \"MongoDB {{ mongodb_ver }} Repository\"\n    baseurl: http://downloads-distro.mongodb.org/repo/{{ os_family }}/os/x86_64/\n    gpgcheck: no\n    enabled: yes\n    file: mongodb-org-{{ mongodb_ver }}\n  when: mongodb_ver|float() < 3.0\n\n- name: 'Install mongodb-org'\n  package:\n    name: mongodb-org\n    state: latest\n"}, {"commit_sha": "54430da1067241aa5fcd13a3e02c676a762a7db3", "sha": "fad21fcffbcad3a843ddb81b0ea7ee626482cf78", "filename": "meta/main.yml", "repository": "geerlingguy/ansible-role-php-xdebug", "decoded_content": "---\ndependencies:\n  - { role: geerlingguy.php }\n\ngalaxy_info:\n  author: geerlingguy\n  description: PHP XDebug for Linux\n  company: \"Midwestern Mac, LLC\"\n  license: \"license (BSD, MIT)\"\n  min_ansible_version: 1.4\n  platforms:\n  - name: EL\n    versions:\n    - all\n  - name: GenericUNIX\n    versions:\n    - all\n  - name: Fedora\n    versions:\n    - all\n  - name: opensuse\n    versions:\n    - all\n  - name: GenericBSD\n    versions:\n    - all\n  - name: FreeBSD\n    versions:\n    - all\n  - name: Ubuntu\n    versions:\n    - all\n  - name: SLES\n    versions:\n    - all\n  - name: GenericLinux\n    versions:\n    - all\n  - name: Debian\n    versions:\n    - all\n  categories:\n    - development\n    - web\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "b512af6156611f081efc920b6b96b6e9360ca677", "filename": "roles/common/tasks/ubuntu.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- name: Install software updates\n  apt: update_cache=yes upgrade=dist\n  tags:\n    - cloud\n\n- name: Check if reboot is required\n  shell: >\n    if [[ -e /var/run/reboot-required ]]; then echo \"required\"; else echo \"no\"; fi\n  args:\n    executable: /bin/bash\n  register: reboot_required\n  tags:\n    - cloud\n\n- name: Reboot\n  shell: sleep 2 && shutdown -r now \"Ansible updates triggered\"\n  async: 1\n  poll: 0\n  when: reboot_required is defined and reboot_required.stdout == 'required'\n  ignore_errors: true\n  tags:\n    - cloud\n\n- name: Wait until SSH becomes ready...\n  local_action:\n    module: wait_for\n    port: 22\n    host: \"{{ inventory_hostname }}\"\n    search_regex: OpenSSH\n    delay: 10\n    timeout: 320\n  when: reboot_required is defined and reboot_required.stdout == 'required'\n  become: false\n  tags:\n    - cloud\n\n- name: Disable MOTD on login and SSHD\n  replace: dest=\"{{ item.file }}\" regexp=\"{{ item.regexp }}\" replace=\"{{ item.line }}\"\n  with_items:\n    - { regexp: '^session.*optional.*pam_motd.so.*', line: '# MOTD DISABLED', file: '/etc/pam.d/login' }\n    - { regexp: '^session.*optional.*pam_motd.so.*', line: '# MOTD DISABLED', file: '/etc/pam.d/sshd' }\n  tags:\n    - cloud\n\n- name: Loopback for services configured\n  template: src=10-loopback-services.cfg.j2 dest=/etc/network/interfaces.d/10-loopback-services.cfg\n  notify:\n    - restart loopback\n  tags:\n    - always\n\n- name: Loopback included into the network config\n  lineinfile: dest=/etc/network/interfaces line='source /etc/network/interfaces.d/10-loopback-services.cfg' state=present\n  notify:\n    - restart loopback\n  tags:\n    - always\n\n- meta: flush_handlers\n  tags:\n    - always\n\n- name: Check apparmor support\n  shell: apparmor_status\n  ignore_errors: yes\n  register: apparmor_status\n\n- set_fact:\n    apparmor_enabled: true\n  when: '\"profiles are in enforce mode\" in apparmor_status.stdout'\n\n- set_fact:\n    tools:\n      - git\n      - screen\n      - apparmor-utils\n      - uuid-runtime\n      - coreutils\n      - sendmail\n      - iptables-persistent\n      - cgroup-tools\n      - openssl\n    sysctl:\n      - item: net.ipv4.ip_forward\n        value: 1\n      - item: net.ipv4.conf.all.forwarding\n        value: 1\n      - item: net.ipv6.conf.all.forwarding\n        value: 1\n  tags:\n    - always\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "3fd18396b048c5faf91f0430663d903f8b763461", "filename": "playbooks/roles/check_docker_setup/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- name: Ensure docker installed\n  yum:\n    name: docker\n    state: latest\n- name: Ensure docker proxy settings\n  lineinfile:\n    dest: /etc/sysconfig/docker\n    state: present\n    line: \"{{item[0]}}={{ item[1] }}\"\n  with_together:\n  - ['HTTP_PROXY', 'HTTPS_PROXY', 'NO_PROXY']\n  - [\"{{proxy_http}}\", \"{{proxy_https}}\", \"{{proxy_no}}\"]\n  when: proxy_username is not defined and proxy_http is defined\n- name: Ensure docker proxy settings with username and password\n  lineinfile:\n    dest: /etc/sysconfig/docker\n    state: present\n    line: \"{{item[0]}}=http://{{ proxy_username }}:{{ proxy_password }}@{{ item[1] }}\"\n  with_together:\n  - ['HTTP_PROXY', 'HTTPS_PROXY', 'NO_PROXY']\n  - [\"{{proxy_http}}\", \"{{proxy_https}}\", \"{{proxy_no}}\"]\n  when: proxy_username is defined and proxy_http is defined\n- name: Detect Docker storage configuration status\n  command: grep -q overlay2 /etc/sysconfig/docker-storage\n  register: docker_storage_test\n  changed_when: false\n  failed_when: false\n- name: Create docker storage configuration\n  template:\n    src: templates/docker-storage-setup.j2\n    dest: /etc/sysconfig/docker-storage-setup\n  when: docker_storage_test.rc != 0\n\n- name: Apply Docker storage configuration changes\n  command: docker-storage-setup\n  when: docker_storage_test.rc != 0\n\n- name: Fail if Docker version is < {{docker_version}}\n  fail:\n    msg: 'docker_version must be >= 1.12, yours is set to {{ docker_version }}.'\n  when: docker_version is version_compare('1.12', '<')\n\n\n- name: Enable and start docker\n  service:\n    name: docker\n    enabled: yes\n    state: started\n"}, {"commit_sha": "0c050ee7f22968afdb69da3b859869efea2bfffa", "sha": "743b9b7022c188af22f6173ea9dcde892bfbe1bf", "filename": "tasks/main.yml", "repository": "geerlingguy/ansible-role-solr", "decoded_content": "---\n- include: user.yml\n  when: solr_create_user\n\n- name: Set solr_filename for Solr 4+.\n  set_fact:\n    solr_filename: \"solr-{{ solr_version }}\"\n  when: \"solr_version.split('.')[0] >= '4'\"\n\n- name: Set solr_filename for Solr 3.x.\n  set_fact:\n    solr_filename: \"apache-solr-{{ solr_version }}\"\n  when: \"solr_version.split('.')[0] == '3'\"\n\n- name: Check if Solr has been installed already.\n  stat:\n    path: \"{{ solr_install_path }}\"\n  register: solr_install_path_status\n\n- name: Download Solr.\n  get_url:\n    url: \"{{ solr_mirror }}/lucene/solr/{{ solr_version }}/{{ solr_filename }}.tgz\"\n    dest: \"{{ solr_workspace }}/{{ solr_filename }}.tgz\"\n    force: no\n  when: solr_install_path_status.stat.isdir is not defined\n  register: solr_download_status\n\n- name: Expand Solr.\n  unarchive:\n    src: \"{{ solr_workspace }}/{{ solr_filename }}.tgz\"\n    dest: \"{{ solr_workspace }}\"\n    copy: no\n  when: solr_download_status.changed\n\n# Install Solr < 5.\n- include: install-pre5.yml\n  when: \"solr_version.split('.')[0] < '5'\"\n\n# Install Solr 5+.\n- include: install.yml\n  when: \"solr_version.split('.')[0] >= '5'\"\n\n- name: Ensure solr is started and enabled on boot if configured.\n  service:\n    name: \"{{ solr_service_name }}\"\n    state: \"{{ solr_service_state }}\"\n    enabled: yes\n  when: solr_service_manage\n\n# Configure solr.\n- include: configure.yml\n  when: \"solr_version.split('.')[0] >= '5'\"\n\n# Create cores, if any are configured.\n- include: cores.yml\n  when: \"solr_cores and solr_version.split('.')[0] >= '5'\"\n\n- include: trim-fat.yml\n  static: no\n"}, {"commit_sha": "a5a5c4d74b7b0fd14f534dda1f41f903d1a58abf", "sha": "cc28372c21fc35712df3fafeef6c43f984313be4", "filename": "tasks/main.yml", "repository": "fubarhouse/ansible-role-nodejs", "decoded_content": "---\n# Main tasks file for fubarhouse.nodejs\n\n- name: \"Define user variable for ssh use\"\n  set_fact:\n    fubarhouse_user: \"{{ ansible_ssh_user }}\"\n  when: ansible_ssh_user is defined and fubarhouse_user is undefined\n\n- name: \"Define user variable for non-ssh use\"\n  set_fact:\n    fubarhouse_user: \"{{ ansible_user_id }}\"\n  when: ansible_ssh_user is not defined and fubarhouse_user is undefined\n\n- name: \"Define OS-specific variables\"\n  include_vars: \"config-{{ ansible_os_family }}.yml\"\n  when: fubarhouse_npm is not defined\n\n- include: nvm.yml\n  when: install_nvm\n\n- include: ivm.yml\n  when:\n    - install_ivm == true\n    - '\"{{ ansible_os_family }}\" != \"Darwin\"'\n\n- include: nodejs.yml\n  when: install_nodejs == true\n\n- include: iojs.yml\n  when:\n    - install_iojs == true\n    - '\"{{ ansible_os_family }}\" != \"Darwin\"'\n\n- include: npm.yml\n  when: install_npm == true"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "e31821759067fd56cb8c2d641d9e57534ecf8f89", "filename": "playbooks/osp/inventory/group_vars/all.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nansible_user: fedora\nansible_become: True\n\nosp_volumes:\n- name: \"vol1\"\n  display_description: \"Volume 1\"\n  display_name: \"Vol1\"\n  size: 1\n- name: \"vol2\"\n  display_description: \"Volume 2\"\n  display_name: \"Vol2\"\n  size: 2\n\nosp_security_groups:\n- name: \"multi-sec-group\"\n  description: \"My Multi-Port Sec Group\"\n  rules:\n  - protocol: tcp\n    port_range_min: 22\n    port_range_max: 22\n    direction: ingress\n    remote_ip_prefix: 0.0.0.0/0 \n  - protocol: tcp\n    port_range_min: 80\n    port_range_max: 80\n    direction: ingress\n    remote_ip_prefix: 0.0.0.0/0 \n- name: \"icmp-sec-group\"\n  description: \"ICMP Security Group\"\n  rules:\n  - protocol: icmp\n    direction: ingress\n    remote_ip_prefix: 0.0.0.0/0 \n\nosp_instances:\n- name: \"fedora1\"\n  meta:\n    group: osp_instances\n  image: \"Fedora-Cloud-Base-26-1.5.x86_64\"\n  key_name: \"my-keypair\"\n  flavor: \"m1.medium\"\n  network: \"my-network\"\n  security_groups:\n  - multi-sec-group\n  - icmp-sec-group\n  volumes:\n  - vol1\n  - vol2\n\n\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "29423e64c7d3ba5b6d79d94ffe90c24381dd410f", "filename": "roles/rhsm/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Install Satellite certificate (if applicable)\"\n  command: \"rpm -Uh --force http://{{ rhsm_server_hostname }}/pub/katello-ca-consumer-latest.noarch.rpm\"\n  when:\n  - rhsm_server_hostname is defined\n  - rhsm_server_hostname|trim != ''\n\n- name: 'Register system using Red Hat Subscription Manager'\n  redhat_subscription:\n    state: present\n    username: \"{{ rhsm_username | default(omit) }}\"\n    password: \"{{ rhsm_password | default(omit) }}\"\n    pool: \"{{ rhsm_pool | default(omit) }}\"\n    server_hostname: \"{{ rhsm_server_hostname | default(omit) }}\"\n    activationkey: \"{{ rhsm_activationkey | default(omit) }}\"\n    org_id: \"{{ rhsm_org_id | default(omit) }}\"\n\n- name: \"Obtain currently enabled repos\"\n  shell: 'subscription-manager repos --list-enabled | sed -ne \"s/^Repo ID:[^a-zA-Z0-9]*\\(.*\\)/\\1/p\"'\n  register: enabled_repos\n\n- name: \"Disable repositories that should not be enabled\"\n  shell: \"subscription-manager repos --disable={{ item }}\"\n  with_items: \n  - \"{{ enabled_repos.stdout_lines | difference(rhsm_repos) }}\"\n\n- name: \"Enable specified repositories not already enabled\"\n  command: \"subscription-manager repos --enable={{ item }}\"\n  with_items:\n  - \"{{ rhsm_repos | difference(enabled_repos.stdout_lines) }}\"\n\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "aeb19aff80ab35b2f96c988c40576875d3981797", "filename": "tasks/Linux/fetch/security-fetch/security-fetch-s3.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Download security policy artifact from s3\n  aws_s3:\n    bucket: '{{ java_unlimited_policy_transport_s3_bucket }}'\n    object: '{{ java_unlimited_policy_transport_s3_path }}'\n    dest: \"{{ java_download_path }}/\\\n      {{ java_unlimited_policy_transport_s3_path|basename }}\"\n    aws_access_key: '{{ transport_s3_aws_access_key }}'\n    aws_secret_key: '{{ transport_s3_aws_secret_key }}'\n    mode: get\n    overwrite: different\n  retries: 5\n  delay: 2\n\n- name: Downloaded security policy artifact\n  set_fact:\n    security_policy_java_artifact: >\n      {{ java_download_path }}/{{ java_unlimited_policy_transport_s3_path\n                             | basename }}\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "1ceeed92c8d4be4c808fb5dd2db86c9aadd4c744", "filename": "roles/ansible/prep-for-ansible/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Force gather facts - an error is normal\"\n  setup:\n  check_mode: no\n  ignore_errors: True\n  register: facts\n\n- name: \"Install python2 and dnf stuff to allow for Ansible operation\"\n  raw: dnf -y install python-dnf libselinux-python\n  when:\n  - facts|failed\n\n\n"}, {"commit_sha": "9662c15ce2e4260fac5cc2bfdf5aaaaf0a2191dd", "sha": "3cb27bb876cbdae833dc06aad9307aefb9fb04ef", "filename": "tasks/section_09_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 9.1.1.1 Check that cron conf file exists (check) (Scored)\n    stat: path=/etc/init/cron.conf\n    register: cron_conf_stat\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.1\n\n  - name: 9.1.1.2 Enable cron Daemon (Scored)\n    lineinfile: >\n        dest='/etc/init/cron.conf'\n        line='start on runlevel [2345]'\n        state=present\n    when: not cron_conf_stat.stat.exists\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.2\n\n  - name: 9.1.2 Set User/Group Owner and Permission on /etc/crontab (Scored)\n    file: path='/etc/crontab' owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.2\n\n  - name: 9.1.3 Set User/Group Owner and Permission on /etc/cron.hourly (Scored)\n    file: path=/etc/cron.hourly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.3\n\n  - name: 9.1.4 Set User/Group Owner and Permission on /etc/cron.daily (Scored)\n    file: path=/etc/cron.daily owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.4\n\n  - name: 9.1.5 Set User/Group Owner and Permission on /etc/cron.weekly(Scored)\n    file: path=/etc/cron.weekly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.5\n\n  - name: 9.1.6 Set User/Group Owner and Permission on /etc/cron.monthly(Scored)\n    file: path=/etc/cron.monthly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.6\n\n  - name: 9.1.7 Set User/Group Owner and Permission on /etc/cron.d (Scored)\n    file: path=/etc/cron.d owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.7\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (Scored)\n    file: path={{ item }} state=absent\n    with_items:\n        - /etc/cron.deny\n        - /etc/at.deny\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n  \n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    stat: path=/etc/cron.allow\n    register: cron_allow_path\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    shell: touch /etc/cron.allow\n    when: cron_allow_path.stat.exists == False\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (Scored)\n    file: path=/etc/cron.allow owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    stat: path=/etc/at.allow\n    register: at_allow_path\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    shell: touch /etc/at.allow\n    when: at_allow_path.stat.exists == False\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (Scored)\n    file: path=/etc/at.allow owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n \n  - name: 9.2.1 Set Password Creation Requirement Parameters Usingpam_cracklib (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password'\n        regexp=\"pam_cracklib.so\"\n        line=\"password required pam_cracklib.so retry=3 minlen=14 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.1\n\n#Note for section 9.2.2:\n#If a user has been locked out because they have reached the maximum consecutive failure count \n#defined by denied= in the pam_tally2.so module, the user can be unlocked by issuing the command\n#/sbin/pam_tally2 -u username --reset\n#This command sets the failed count to 0, effectively unlocking the user\n  - name: 9.2.2 Set Lockout for Failed Password Attempts (Not Scored)\n    lineinfile: >\n        dest='/etc/pam.d/login' \n        regexp='pam_tally2'\n        line=\"auth required pam_tally2.so onerr=fail audit silent deny=5 unlock_time=900\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.2\n\n  - name: 9.2.3 Limit Password Reuse (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password' \n        regexp='remember=5'\n        line=\"password sufficient pam_unix.so remember=5\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.3\n\n  - name: 9.3 Check if ssh is installed (check)\n    stat: path='/etc/ssh/sshd_config'\n    register: ssh_config_file\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n\n  - name: 9.3.1 Set SSH Protocol to 2 (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config' \n        regexp='^Protocol'\n        state=present\n        line='Protocol 2'\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n  - name: 9.3.2 Set LogLevel to INFO (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config' \n        regexp='^LogLevel'\n        state=present\n        line='LogLevel INFO'\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.2\n\n  - name: 9.3.3 Set Permissions on /etc/ssh/sshd_config (Scored)\n    file: path='/etc/ssh/sshd_config' owner=root group=root mode=600\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.3\n\n#Regroups sections 9.3.4 9.3.7 9.3.8 9.3.9 9.3.10\n  - name: 9.3.{4,7,8,9,10} Disable some SSH options (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^{{ item }}'\n        line='{{ item }} no'\n        state=present\n    with_items: \n      - X11Forwarding\n      - HostbasedAuthentication\n      - PermitRootLogin\n      - PermitEmptyPasswords\n      - PermitUserEnvironment\n    tags:\n      - section9\n      - section9.3\n      - section9.3.4\n      - section9.3.7\n      - section9.3.8\n      - section9.3.9\n      - section9.3.10\n\n  - name: 9.3.5 Set SSH MaxAuthTries to 4 or Less (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^MaxAuthTries'\n        line='MaxAuthTries 4'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.5\n\n  - name: 9.3.6 Set SSH IgnoreRhosts to Yes (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^IgnoreRhosts'\n        line='IgnoreRhosts yes'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.6\n\n  - name: 9.3.11 Use Only Approved Cipher in Counter Mode (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Ciphers'\n        line='Ciphers aes128-ctr,aes192-ctr,aes256-ctr'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.11\n\n  - name: 9.3.12.1 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveInterval'\n        line='ClientAliveInterval 300'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.1\n\n  - name: 9.3.12.2 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveCountMax'\n        line='ClientAliveCountMax 0'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.2\n\n  - name: 9.3.13.1 Limit Access via SSH (Scored)\n    shell: grep AllowUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.1\n\n  - name: 9.3.13.2 Limit Access via SSH (Scored)\n    shell: grep AllowGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.2\n\n  - name: 9.3.13.3 Limit Access via SSH (Scored)\n    shell: grep DenyUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.3\n\n  - name: 9.3.13.4 Limit Access via SSH (Scored)\n    shell: grep DenyGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.4\n\n  - name: 9.3.14 Set SSH Banner (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Banner'\n        line='Banner /etc/issue.net'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.14\n\n  - name: 9.3.14 Set SSH Banner File (Scored)\n    lineinfile: >\n        dest=/etc/ssh/sshd_config\n        line='Authorized uses only. All activity may be monitored and reported.'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.14\n\n  - name: 9.4 Restrict root Login to System Console (Not Scored)\n    stat: path=/etc/securetty\n    register: securetty_file\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.4 Restrict root Login to System Console (Not Scored)\n    debug: msg='*** Check /etc/securetty for console allowed for root access ***'\n    when: securetty_file.stat.exists == True\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.5.1 Restrict Access to the su Command (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/su'\n        line='auth            required        pam_wheel.so use_uid'\n        state=present\n    tags:\n      - section9\n      - section9.5\n      - section9.5.1\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "57e54fc41e7ab04cf45c18e84d28c2255c7c95c9", "filename": "roles/letsencrypt/defaults/main.yml", "repository": "roots/trellis", "decoded_content": "sites_using_letsencrypt: \"[{% for name, site in wordpress_sites.iteritems() if site.ssl.enabled and site.ssl.provider | default('manual') == 'letsencrypt' %}'{{ name }}',{% endfor %}]\"\nletsencrypt_enabled: \"{{ sites_using_letsencrypt | count > 0 }}\"\nsite_uses_letsencrypt: \"{{ item.value.ssl is defined and item.value.ssl.enabled | default(false) and item.value.ssl.provider | default('manual') == 'letsencrypt' }}\"\n\nacme_tiny_repo: 'https://github.com/diafygi/acme-tiny.git'\nacme_tiny_commit: '69a457269a6392ac31b629b4e103e8ea7dd282c9'\n\nacme_tiny_software_directory: /usr/local/letsencrypt\nacme_tiny_data_directory: /var/lib/letsencrypt\nacme_tiny_challenges_directory: \"{{ www_root }}/letsencrypt\"\n\n# Path to the local file containing the account key to copy to the server.\n# Secure this file using Git-crypt for example.\n# Leave this blank to generate a new account key that will need to be registered manually with Letsencrypt.org\n#letsencrypt_account_key_source_file: /my/account.key\n\n# Content of the account key to copy to the server.\n# Secure this key using Ansible Vault for example.\n# Leave this blank to generate a new account key that will need to be registered manually with Letsencrypt.org\n#letsencrypt_account_key_source_content: |\n#  -----BEGIN RSA PRIVATE KEY-----\n#  MIIJKAJBBBKCaGEA63J7t9dqyua5+Q+P6M3iHtLEKpF/AZcZNBHr1F2Oo8+Hfyvl\n#  KWXliiWjUORxDxI1c56Rw2VCIExnFjWJAdSLv6/XaQWo2T7U28bkKbAlCF9=\n#  -----END RSA PRIVATE KEY-----\n\nletsencrypt_ca: 'https://acme-v01.api.letsencrypt.org'\n\nletsencrypt_account_key: '{{ acme_tiny_data_directory }}/account.key'\n\nletsencrypt_intermediate_cert_path: /etc/ssl/certs/lets-encrypt-x3-cross-signed.pem\nletsencrypt_intermediate_cert_url: 'https://letsencrypt.org/certs/lets-encrypt-x3-cross-signed.pem'\nletsencrypt_intermediate_cert_sha256sum: 'e446c5e9dbef9d09ac9f7027c034602492437a05ff6c40011d7235fca639c79a'\n\nletsencrypt_keys_dir: \"{{ nginx_ssl_path }}/letsencrypt\"\nletsencrypt_certs_dir: \"{{ nginx_ssl_path }}/letsencrypt\"\n\n# the minimum age (in days) after which a certificate will be renewed\nletsencrypt_min_renewal_age: 60\n\n# the days of a month the cronjob should be run. Make sure to run it rather often, three times per month is a pretty\n# good value. It does not harm to run it often, as it will only regenerate certificates that have passed a certain age\n# (60 days by default).\nletsencrypt_cronjob_daysofmonth: 1,11,21\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "8e314abcc68eee1f847c254dea115c63b9db872c", "filename": "roles/user-management/manage-atlassian-users/tasks/delete_atlassian_users.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Delete User \n  uri:\n    url: '{{ atlassian.url }}/rest/api/2/user?username={{ atlassian_user.firstname }}'\n    method: DELETE\n    user: '{{ atlassian.username }}'\n    password: '{{ atlassian.password }}'\n    force_basic_auth: yes\n    status_code: 204\n    body_format: json\n  register: result\n  when:\n    - atlassian_user.state is defined\n    - atlassian_user.state == \"absent\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "113f0465520d4e1ead4cd01cfa466906180f95f3", "filename": "roles/awstats/templates/apache.conf", "repository": "iiab/iiab", "decoded_content": "# This provides worldwide access to everything below the directory\n# Security concerns:\n#  * Raw log processing data is accessible too for everyone\n#  * The directory is by default writable by the httpd daemon, so if\n#    any PHP, CGI or other script can be tricked into copying or\n#    symlinking stuff here, you have a looking glass into your server,\n#    and if stuff can be uploaded to here, you have a public warez site!\nScriptAlias /awstats /usr/lib/cgi-bin\n<Directory /usr/share/awstats>\n    Options +ExecCGI -MultiViews +SymLinksIfOwnerMatch\n    AllowOverride None\n    DirectoryIndex /cgi-bin/awstats.pl\n    require all granted\n</Directory>\n\n# This provides worldwide access to everything below the directory\n# Security concerns: none known\n<Directory /usr/share/awstats/icon>\n\tOptions None\n\tAllowOverride None\n        require all granted\n</Directory>\n\n# This provides worldwide access to everything below the directory\n# Security concerns: none known\n<Directory /usr/share/java/awstats>\n\tOptions FollowSymLinks\n\tAllowOverride None\n        require all granted\n</Directory>\n\n# This provides worldwide access to everything in the directory\n# Security concerns: none known\nAlias /awstats-icon/ /usr/share/awstats/icon/\n\n# This provides worldwide access to everything in the directory\n# Security concerns: none known\nAlias /awstatsclasses/ /usr/share/java/awstats/\n\n# This (hopefully) enables _all_ CGI scripts in the default directory\n# Security concerns: Are you sure _all_ CGI scripts are safe?\nScriptAlias /cgi-bin/ /usr/lib/cgi-bin/\n<Directory /usr/lib/cgi-bin>\n  Options +ExecCGI\n  SetHandler cgi-script\n  require all granted \n</Directory>\n"}, {"commit_sha": "0c050ee7f22968afdb69da3b859869efea2bfffa", "sha": "26b5f7a77dd6b81e72d726195e04ca0b2cb4d812", "filename": "tasks/configure.yml", "repository": "geerlingguy/ansible-role-solr", "decoded_content": "---\n- name: Remove existing SOLR_HEAP configuration.\n  lineinfile:\n    dest: \"{{ solr_config_file }}\"\n    regexp: \"^SOLR_HEAP\"\n    state: absent\n  notify: restart solr\n\n- name: Apply Solr configuration changes.\n  lineinfile:\n    dest: \"{{ solr_config_file }}\"\n    regexp: \"{{ item.regexp }}\"\n    line: \"{{ item.line }}\"\n    state: present\n  with_items:\n    - regexp: \"^.?SOLR_JAVA_MEM=\"\n      line: 'SOLR_JAVA_MEM=\"-Xms{{ solr_xms }} -Xmx{{ solr_xmx }}\"'\n    - regexp: \"^SOLR_PORT=\"\n      line: 'SOLR_PORT=\"{{ solr_port }}\"'\n    - regexp: \"^.?SOLR_TIMEZONE=\"\n      line: 'SOLR_TIMEZONE=\"{{ solr_timezone }}\"'\n  notify: restart solr"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "d77cdd9aa936d60a777cc33fb19be20d1b487c79", "filename": "roles/osm/templates/defaults.ini", "repository": "iiab/iiab", "decoded_content": ";; Configuration file for Internet-in-a-Box\n;;\n;; You should NOT edit this file if you are only\n;; making changes for your local machine.  \n;;\n;; Instead create a local.ini file which will automatically\n;; be loaded AFTER this file loads, and can be used to \n;; override any settings in this file.  Do NOT check your local.ini\n;; into the repository, it is for your personal use only.\n;;\n;; Variable \"interpolation\" can be used to incorporate\n;; values from previous assignments within a setting value.\n;;\n;; For example,\n;; b = BAAAH\n;; a = a%(b)sc\n;;\n;; will result in the value of 'a' being 'aBAAHc'.  Note the 's'\n;; following the parenthesis is NECESSARY (to denote a string?)\n;;\n;; [DEFAULT] is a special section.  Any settings there\n;; will automatically appear in all other sections.  [DEFAULT]\n; Location of our dataset\n[DEFAULT]\nknowledge_dir = /library/knowledge\nprocessed_dir = %(knowledge_dir)s/processed\nmodules_dir = %(knowledge_dir)s/modules\ndata_dir = %(knowledge_dir)s/data\n\n; If search_for_knowledge_dir is true, then\n; the system will search all mounted volumes\n; for a \"knowledge/\" directory if the path\n; specified in knowledge_dir does not exist.\nsearch_for_knowledge_dir = False\n\n; Machine architecture.  This is set by the \n; application at run-time.\narch = unset\nbin_dir = %(knowledge_dir)s/sys/bin-%(arch)s\n\n[WEBAPP]\nport = 25000\ninterface = 0.0.0.0\nbase_prefix = /iiab/\nuse_x_sendfile = False\n\n[ZIM]\nurl = /iiab/zim\nwikipedia_zim_dir = %(modules_dir)s/wikipedia-zim\nwikipedia_index_dir = %(modules_dir)s/wikipedia-index\nkiwix_library_file = %(wikipedia_zim_dir)s/library.xml\nold_kiwix_library_file = %(modules_dir)s/wikipedia-kiwix/library.xml\n\n[GUTENBERG]\ngutenberg_dir = %(modules_dir)s/gutenberg\ngutenberg_mirror = %(modules_dir)s/gutenberg-mirror\nhtmlz_dir = %(modules_dir)s/gutenberg-htmlz\nhtmlz_images_dir = %(modules_dir)s/gutenberg-htmlz-images\nepub_dir = %(modules_dir)s/gutenberg-epub\nepub_images_dir = %(modules_dir)s/gutenberg-epub-images\nsqlalchemy_echo = True\nsqlalchemy_database_uri = %(gutenberg_dir)s/gutenberg.db\nindex_dir = %(gutenberg_dir)s/whoosh/gutenberg_index\nroot_dir = %(gutenberg_mirror)s/\n\n[VIDEO]\nkhanacademy_dir = %(modules_dir)s/khanacademy\nkhan_webm_dir = %(khanacademy_dir)s/webm\nkhan_h264_dir = %(khanacademy_dir)s/h264\nkhan_cache_file = /tmp/khan_cache.json\n; Where we make easy 0/1/2/3 sym links for all videos\n; so they can be served directly by the front end web server\nsymlink_dir = %(khanacademy_dir)s/khanlinks\n; This is static content, so it can change based on web server config\nvideo_url = /iiab/video/khanvideo\n\n[OSM]\nopenstreetmap_dir = %(modules_dir)s/openstreetmap\nosm_search_dir = %(modules_dir)s/geonames_index\n\n[SOFTWARE]\nsoftware_dir = %(modules_dir)s/ubuntu/12.04/mirror/archive.ubuntu.com/ubuntu\nsoftware_url = /iiab/software\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "f9415e33ab491ddec5468f1dab30f1a44c5d2b97", "filename": "tasks/create_repo_rubygems_proxy_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_rubygems_proxy\n    args: \"{{ _nexus_repos_rubygems_defaults|combine(item) }}\""}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "156a1c135cbe53205ef2a8b9bf9c23b77257382c", "filename": "archive/roles/registry/tasks/main.yaml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- name: Setting Registry Facts\n  set_fact:\n    template_registry_domain_name: \"{{ registry_domain_name | default(default_domain_name) }}\"\n    certificate_path: \"{{ default_certificate_path }}\"\n    certificate_subject: \"{{ registry_certificate_subject | default(default_certificate_subject) }}\"\n    nginx_repo_url: \"{{ registry_nginx_repo_url | default(default_nginx_repo_url) }}\"\n    auth_layer: \"{{ registry_auth_layer | default(default_auth_layer) }}\"\n\n- name: Install Registry\n  action: \"{{ ansible_pkg_mgr }} name=docker-distribution state=latest\"\n\n- name: Enable & Start Registry\n  service: name=docker-distribution enabled=yes state=started\n\n- name: Install firewalld\n  action: \"{{ ansible_pkg_mgr }} name=firewalld state=latest\"\n\n#- name: Install firewall-cmd\n#  yum: name=firewall-cmd state=latest\n\n- name: Enable Firewalld\n  service: name=firewalld enabled=yes state=started\n\n- name: Open Firewall for Registry\n  firewalld: port=5000/tcp permanent=yes state=enabled immediate=yes zone=public\n  when: not auth_layer | bool\n\n- name: Lay Down Registry Config\n  template: src=\"{{role_path}}/templates/nginx.j2\" dest=\"/etc/docker-distribution/registry/config.xml\"\n  notify: restart docker registry\n\n- name: Add Auth Layer\n  include: \"{{role_path}}/tasks/auth_layer_nginx.yaml\"\n  when: registry_auth_layer | default(false) | bool\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "150a679118e706bd392a5853172c3fa88ea1bf54", "filename": "roles/dns/manage-dns-zones/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n###############################################################################\n# common defaults\nttl: 300\n\n\n###############################################################################\n# defaults for named\nnamed_processing: False\ndefault_dnssec_keygen_size: 256\ndefault_dnssec_keygen_algorithm: HMAC-SHA256\n\n\n###############################################################################\n# defaults for Route53\nroute53_processing: False\naws_access_key: \"{{ lookup('env','AWS_ACCESS_KEY_ID') }}\"\naws_secret_key: \"{{ lookup('env','AWS_SECRET_ACCESS_KEY') }}\"\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "3f1ede4fc7d8049eb99ebf157524686650086270", "filename": "playbooks/roles/check_packages_nodes/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- name: Install packages\n  yum:\n    name: \"{{item}}\"\n    state: latest\n  with_items:\n  - \"{{packages}}\"\n- name: Update packages\n  yum:\n    name: '*'\n    state: latest\n- name: Shutdown\n  shell: sleep 2 && shutdown -r now \"Reboot triggered by Ansible\"\n  async: 1\n  poll: 0\n  ignore_errors: true\n- name: Wait for host to come back up\n  local_action:\n    module: wait_for\n    host: \"{{ inventory_hostname }}\"\n    port: 22\n    delay: 5\n    timeout: 300\n- name: Update packages\n  command: yum update -y\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "5d1f5d656423707012bfe55f0385ecafd9ab2081", "filename": "roles/dns/manage-dns-records/tasks/route53/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- include_tasks: process-records.yml\n  with_subelements:\n    - \"{{ dns_data.views }}\"\n    - zones\n  loop_control:\n    loop_var: dns\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "03e8fb8721c564fd1a596b4b6d7f3404ec6201be", "filename": "roles/owncloud/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "# we need to install the rpm in order to get the dependencies\n# but we only need to do this the first time\n\n- name: add a repo def for ubuntu\n  template: dest=/etc/apt/sources.list.d/\n            src=owncloud.list\n  when: is_ubuntu\n\n- name: See if the owncloud startup page exists\n  stat: path={{ owncloud_prefix }}/owncloud/index.php\n  register: owncloud_page\n\n- name: Install owncloud package\n  package: name={{ item }}\n           state=present\n  with_items:\n      - curl\n      - owncloud\n  when: owncloud_page.stat.exists is defined and not owncloud_page.stat.exists\n\n- name: Remove owncloud package\n  package: name=owncloud\n           state=absent\n  when: owncloud_page.stat.exists is defined and not owncloud_page.stat.exists\n\n- name: remove config files for package\n  file: src=/etc/apache2/conf-available/owncloud.conf\n        dest=/etc/apache2/conf-enabled/owncloud.conf\n        state=absent\n\n- name: remove config files for package\n  file: path=/etc/apache2/conf-available/owncloud.conf\n        state=absent\n\n#- name: Remove /etc/owncloud to avoid confusion as we use the config in {{ owncloud_prefix }}/config/\n#  file: path=/etc/owncloud\n#        state=absent\n\n# but we use the tar file to get the latest version\n\n- name: Get the owncloud software\n  get_url: url={{ iiab_download_url }}/{{ owncloud_src_file }}  dest={{ downloads_dir }}/{{ owncloud_src_file }}\n  when: internet_available\n  async: 300\n  poll: 5\n\n- name: Copy it to permanent location /opt\n  unarchive: src={{ downloads_dir }}/{{ owncloud_src_file }}\n             dest={{ owncloud_prefix }}\n             creates={{ owncloud_prefix }}/owncloud/version.php\n  when: not is_F18\n\n# ansible 1.4.1 does not have \"creates\"\n- name: Copy it to permanent location /opt\n  unarchive: src={{ downloads_dir }}/{{ owncloud_src_file }}\n             dest={{ owncloud_prefix }}\n  when: is_F18\n\n- name: in Centos, the following config dir is symlink to /etc/owncloud\n  file: path=/etc/owncloud\n        state=directory\n\n- name: Add autoconfig file\n  template: src=autoconfig.php.j2\n            dest={{ owncloud_prefix }}/owncloud/config/autoconfig.php\n            owner={{ apache_user }}\n            group=apache\n            mode=0640\n\n- name: Make apache owner\n  file: path={{ owncloud_prefix }}/owncloud\n        owner={{ apache_user }}\n        group=apache\n        recurse=yes\n        state=directory\n\n- name: Create data directory library\n  file: path={{ item }}\n        mode=0750\n        owner={{ apache_user }}\n        group=apache\n        state=directory\n  with_items:\n    - \"{{ owncloud_data_dir }}\"\n\n- name: Create a mysql database for owncloud\n  mysql_db: name={{ owncloud_dbname }}\n  when: mysql_enabled and owncloud_enabled\n\n- name: Create a user to access the owncloud database\n  mysql_user: name={{ owncloud_dbuser }} host={{ item }} password={{ owncloud_dbpassword }} priv={{ owncloud_dbname }}.*:ALL,GRANT\n  with_items:\n        - \"{{ owncloud_dbhost }}\"\n        - 127.0.0.1\n        - ::1\n        - localhost\n  when: mysql_enabled and owncloud_enabled\n\n- name: Restart apache, so it picks up the new aliases\n  service: name={{ apache_service }} state=restarted\n  when: not owncloud_enabled\n\n# Enable owncloud by copying template to httpd config\n\n- include: owncloud_enabled.yml\n  when: owncloud_enabled\n\n- name: Add owncloud to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=owncloud\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: owncloud\n    - option: description\n      value: '\"OwnCloud is a local server-based facility for sharing files, photos, contacts, calendars, etc.\"'\n    - option: path\n      value: \"{{ owncloud_prefix }}/owncloud\"\n    - option: source\n      value: \"{{ owncloud_src_file }}\"\n    - option: enabled\n      value: \"{{ owncloud_enabled }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "08511e6381e9fc1c295475f77761723fab76494a", "filename": "roles/dns/manage-dns-records/tasks/nsupdate/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- include_tasks: nsupdate-server.yml\n  with_subelements:\n    - \"{{ dns_data.views }}\"\n    - zones\n  loop_control:\n    loop_var: dns\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "14d71dfee90aa243bbd7637e7ba18045f4dc7535", "filename": "roles/manage-jira/tasks/create_permission_scheme.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Create Jira Permission Scheme\n  uri:\n    url: \"{{ jira_url }}/rest/api/2/permissionscheme\"\n    method: POST\n    user: \"{{ jira_username }}\"\n    password: \"{{ jira_password }}\"\n    return_content: yes\n    force_basic_auth: yes\n    body_format: json\n    header:\n      - Accept: 'application/json'\n      - Content-Type: 'application/json'\n    body: \"{{ lookup('template','permissionScheme.json.j2') }}\"\n    status_code: 201\n  register: permissionScheme\n\n- name: Set fact for Permission Scheme ID\n  set_fact:\n    PermissionScheme: \"{{ permissionScheme.json.id }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "4021764e9f66d4360d3b518dcda48e167ef387d1", "filename": "roles/samba/handlers/main.yml", "repository": "iiab/iiab", "decoded_content": "---\n- name: restart {{ smb_service }}\n  command: service {{ smb_service }} restart\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "548a4ad8a3da58a7faf2862ced20f4b3e8ec1858", "filename": "tasks/Win32NT/install/adoptopenjdk_tarball.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Check that the java_folder exists\n  win_stat:\n    path: '{{ java_path }}\\{{ java_folder }}/bin'\n  register: java_folder_bin\n\n- name: Install java from tarball\n  block:\n  - name: Mkdir for java installation\n    win_file:\n      path: '{{ java_path }}\\{{ java_folder }}'\n      state: directory\n\n  - name: Create temporary directory\n    win_tempfile:\n      state: directory\n    register: temp_dir_path\n\n  - name: Unarchive to temporary directory\n    win_unzip:\n      src: '{{ java_artifact }}'\n      dest: '{{ temp_dir_path }}'\n\n  - name: Find java_folder in temp\n    win_find:\n      paths: '{{ temp_dir_path }}'\n      recurse: false\n      file_type: directory\n    register: java_temp_folder\n\n  - name: Copy from temporary directory\n    win_copy:\n      src: '{{ java_temp_folder.files | map(attribute=\"path\") | list | last }}\\'\n      dest: '{{ java_path }}\\{{ java_folder }}'\n      remote_src: true\n  when: not java_folder_bin.stat.exists\n"}, {"commit_sha": "abafe1581c6c78d784cf215b214947675d49eff8", "sha": "ae4fbab7187d8b5b3d4afb277c7f858649d4cfb9", "filename": "roles/cloud-ec2/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: Locate official Ubuntu 16.04 AMI for region\n  ec2_ami_find:\n    aws_access_key: \"{{ aws_access_key | default(lookup('env','AWS_ACCESS_KEY_ID'))}}\"\n    aws_secret_key: \"{{ aws_secret_key | default(lookup('env','AWS_SECRET_ACCESS_KEY'))}}\"\n    name: \"ubuntu/images/hvm-ssd/ubuntu-xenial-16.04-amd64-server-*\"\n    owner:  099720109477\n    sort: creationDate\n    sort_order: descending\n    sort_end: 1\n    region: \"{{ region }}\"\n  register: ami_search\n\n- set_fact:\n    ami_image: \"{{ ami_search.results[0].ami_id }}\"\n\n- name: Add ssh public key\n  ec2_key:\n    aws_access_key: \"{{ aws_access_key | default(lookup('env','AWS_ACCESS_KEY_ID'))}}\"\n    aws_secret_key: \"{{ aws_secret_key | default(lookup('env','AWS_SECRET_ACCESS_KEY'))}}\"\n    name: VPNKEY\n    region: \"{{ region }}\"\n    key_material: \"{{ item }}\"\n  with_file: \"{{ ssh_public_key }}\"\n  register: keypair\n\n- name: Configure EC2 security group\n  ec2_group:\n    aws_access_key: \"{{ aws_access_key | default(lookup('env','AWS_ACCESS_KEY_ID'))}}\"\n    aws_secret_key: \"{{ aws_secret_key | default(lookup('env','AWS_SECRET_ACCESS_KEY'))}}\"\n    name: vpn-secgroup\n    description: Security group for VPN servers\n    region: \"{{ region }}\"\n    rules:\n      - proto: udp\n        from_port: 4500\n        to_port: 4500\n        cidr_ip: 0.0.0.0/0\n      - proto: udp\n        from_port: 500\n        to_port: 500\n        cidr_ip: 0.0.0.0/0\n      - proto: tcp\n        from_port: 22\n        to_port: 22\n        cidr_ip: 0.0.0.0/0\n    rules_egress:\n      - proto: all\n        from_port: 0-65535\n        to_port: 0-65535\n        cidr_ip: 0.0.0.0/0\n\n- name: Launch instance\n  ec2:\n    aws_access_key: \"{{ aws_access_key | default(lookup('env','AWS_ACCESS_KEY_ID'))}}\"\n    aws_secret_key: \"{{ aws_secret_key | default(lookup('env','AWS_SECRET_ACCESS_KEY'))}}\"\n    keypair: \"VPNKEY\"\n    group: vpn-secgroup\n    instance_type: t2.nano\n    image: \"{{ ami_image }}\"\n    wait: true\n    region: \"{{ region }}\"\n    instance_tags:\n      name: \"{{ aws_server_name }}\"\n  register: ec2\n\n- name: Add new instance to host group\n  add_host:\n    hostname: \"{{ item.public_ip }}\"\n    groupname: vpn-host\n    ansible_ssh_user: ubuntu\n    ansible_python_interpreter: \"/usr/bin/python2.7\"\n    easyrsa_p12_export_password: \"{{ easyrsa_p12_export_password }}\"\n    cloud_provider: ec2\n    ipv6_support: no\n  with_items: \"{{ ec2.instances }}\"\n\n- name: Wait for SSH to become available\n  local_action: \"wait_for port=22 host={{ item.public_dns_name }} timeout=320\"\n  with_items: \"{{ ec2.instances }}\"\n  become: false\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "b04a143ca4747648ae1795a909c716a32e693a04", "filename": "roles/sshd/handlers/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: restart ssh\n  service: name=ssh state=restarted"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "796623e8c959281cdeafc74bb02f16836823caa6", "filename": "roles/dokuwiki/tasks/install.yml", "repository": "iiab/iiab", "decoded_content": "- name: Get the Dokuwiki software\n  get_url: url=\"{{ iiab_download_url }}/{{ dokuwiki_version }}.tgz\"  dest={{ downloads_dir }}/\n  when: internet_available\n\n- name: Copy it to permanent location /library\n  unarchive: src={{ downloads_dir }}/{{ dokuwiki_version }}.tgz  dest=/library creates=/library/{{ dokuwiki_version }}/VERSION\n\n- name: Symlink /library/dokuwiki* to /library/dokuwiki\n  shell: if [ ! -d /library/dokuwiki ]; then ln -sf /library/{{ dokuwiki_version }} /library/dokuwiki; fi\n\n- name: Install config file for dokuwiki in Apache\n  template: src=dokuwiki.conf.j2 dest=/etc/{{ apache_config_dir }}/dokuwiki.conf\n  when: dokuwiki_enabled\n\n- name: enable the dokuwiki\n  file: path=/etc/apache2/sites-enabled/dokuwiki.conf\n        src=/etc/apache2/sites-available/dokuwiki.conf\n        state=link\n  when: dokuwiki_enabled and is_debuntu\n\n- name: disable the dokuwiki\n  file: path=/etc/apache2/sites-enabled/dokuwiki.conf\n        state=absent\n  when: not dokuwiki_enabled and is_debuntu\n\n\n- name: Change permissions on engine directory so apache can write\n  file: path=/library/{{ dokuwiki_version }} owner={{ apache_user }} mode=0755 state=directory recurse=yes\n\n- name: Restart apache, so it picks up the new aliases\n  service: name={{ apache_service }} state=restarted\n"}, {"commit_sha": "a5a5c4d74b7b0fd14f534dda1f41f903d1a58abf", "sha": "906324d4b3aa287478680d32743f78bf1eb9b4d2", "filename": "tasks/ivm.yml", "repository": "fubarhouse/ansible-role-nodejs", "decoded_content": "---\n\n- name: \"IVM | Ensure folder requirements are met\"\n  become: yes\n  become_user: root\n  file:\n    path: /usr/local/ivm\n    state: directory\n    mode: 0777\n    owner: root\n\n- name: \"IVM | Clone/Update\"\n  become: yes\n  become_user: \"{{ fubarhouse_user }}\"\n  git:\n    repo: \"{{ ivm_repo }}\"\n    dest: \"{{ fubarhouse_npm.user_dir }}/.ivm\"\n    clone: yes\n    update: yes\n    force: yes\n    version: master\n    recursive: false\n  changed_when: false\n\n- name: \"IVM | Linking\"\n  become: yes\n  become_user: root\n  file:\n    src: \"{{ fubarhouse_npm.user_dir }}/.ivm/bin/ivm\"\n    dest: \"/usr/local/bin/ivm\"\n    state: link\n    force: yes\n  changed_when: false\n\n- name: \"IVM | Ensure shell profiles are configured\"\n  become: yes\n  become_user: \"root\"\n  lineinfile:\n    dest: \"{{ fubarhouse_npm.user_dir }}/{{ item.filename }}\"\n    regexp: 'export NVM_IOJS_ORG_MIRROR=https://iojs.org/dist'\n    line:  'export NVM_IOJS_ORG_MIRROR=https://iojs.org/dist;'\n    state: present\n  with_items:\n    - \"{{ fubarhouse_npm.shell_profiles }}\"\n  ignore_errors: yes"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "dd399244f11b02f8ef064b5c3d93e18b2aaa9501", "filename": "roles/config-nagios-target/tasks/nrpe_nfs.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Copy in additional Nagios service plugin\n  copy: \n    src: plugins/check_service.sh\n    dest: /usr/lib64/nagios/plugins/check_service.sh\n    owner: root\n    group: root\n    mode: 0755\n\n- name: Copy nrpe.d NFS configuration files\n  copy: \n    src: nrpe.d/check_nfs.cfg\n    dest: /etc/nrpe.d/check_nfs.cfg\n    owner: root\n    group: root\n    mode: 0644\n\n"}, {"commit_sha": "e91a55152358e890a05cf849abc7d58b8badecc2", "sha": "26e2cea4d0b57252bc12fb3846144bd10993f07d", "filename": "tasks/tasks-Darwin.yml", "repository": "fubarhouse/ansible-role-golang", "decoded_content": "---\n\n- name: \"Go-Lang | Define GOARCH\"\n  set_fact:\n    GOARCH: \"amd64\"\n  when: GOARCH is not defined\n\n- name: \"Go-Lang | Define GOOS\"\n  set_fact:\n    GOOS: \"darwin\"\n  when: GOOS is not defined"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "6444c7dd4ed1c306b3f4976ce0a7b03dbdd1d0b3", "filename": "tasks/checks/distribution-checks-Fedora.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Fail if unsupported Fedora version\n  fail:\n    msg: \"Fedora 24 or later is required!\"\n  when: _docker_os_dist == \"Fedora\" and\n        _docker_os_dist_major_version < '24'\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "152419f7c5cbcba9a459fa5e1c5b984fb202e07e", "filename": "tasks/create_repo_maven_hosted_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_maven_hosted\n    args: \"{{ _nexus_repos_maven_defaults|combine(item) }}\""}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "282caa6c224daa029362bbc4d05215b279bd4c98", "filename": "tasks/create_repo_npm_proxy_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_npm_proxy\n    args: \"{{ _nexus_repos_npm_defaults|combine(item) }}\""}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "e896b660944daf12f17513f66948f560e7610ec5", "filename": "roles/config-pxe/tasks/prep.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Install required packages'\n  package:\n    name: '{{ item }}'\n    state: installed\n  with_items:\n  - tftp-server\n  - syslinux\n  - firewalld\n  - python-firewall\n\n- name: 'Ensure firewalld is running'\n  service:\n    name: firewalld\n    state: started \n    enabled: yes\n\n- name: 'Ensure tftp-server is running'\n  service:\n    name: tftp\n    state: started \n    enabled: yes\n\n- name: 'Open Firewall for PXE/TFTP use'\n  firewalld: \n    port: \"{{ item }}\"\n    permanent: yes\n    state: enabled\n    immediate: yes\n  with_items:\n  - 69/udp\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "b1b1465236995360b2ff3a9f9bf5c8efff6e90a3", "filename": "roles/kiwix/templates/iiab-make-kiwix-lib.py", "repository": "iiab/iiab", "decoded_content": "#!/usr/bin/python\n\n\"\"\"\n\n   Creates library.xml file for kiwix from contents of /zims/content and index\n\n   Author: Tim Moody <tim(at)timmoody(dot)com>\n   Contributors: Jerry Vonau <jvonau3(at)gmail.com>\n\n\"\"\"\n\nimport os, sys, syslog\nimport pwd, grp\nimport time\nfrom datetime import date, datetime\nimport json\nimport yaml\nimport re\nimport subprocess\nimport shlex\nimport ConfigParser\nIIAB_PATH='/etc/iiab'\nif not IIAB_PATH in sys.path:\n   sys.path.append(IIAB_PATH)\nfrom iiab_env import get_iiab_env\n\n# Config Files\niiab_config_file = \"{{ iiab_config_file }}\"\n\n# Variables that should be read from config file\n# All of these variables will be read from config files and recomputed in init()\niiab_zim_path = \"{{ iiab_zim_path }}\"\nkiwix_library_xml = \"{{ kiwix_library_xml }}\"\n\niiab_base_path = \"{{ iiab_base }}\"\nkiwix_manage = iiab_base_path + \"/kiwix/bin/kiwix-manage\"\ndoc_root = get_iiab_env('WWWROOT')\nzim_version_idx = doc_root + \"/common/assets/zim_version_idx.json\"\nzim_versions = {}\nold_zim_map = {\"bad.zim\" : \"unparseable name\"}\n\ndef main():\n    \"\"\"Server routine\"\"\"\n\n    init()\n\n    # remove existing file\n    try:\n        os.remove(kiwix_library_xml)\n    except OSError:\n        pass\n\n    # add each file in /library/zims/content with corresponding index\n    # only add a single .zim for each .zimxx file\n\n    files_processed = {}\n    content = iiab_zim_path + \"/content/\"\n    index = iiab_zim_path + \"/index/\"\n\n    flist = os.listdir(content)\n    flist.sort()\n    for filename in flist:\n        zimpos = filename.find(\".zim\")\n        if zimpos != -1:\n            filename = filename[:zimpos]\n            if filename not in files_processed:\n                files_processed[filename] = True\n                zimname = content + filename + \".zim\"\n                zimidx = index + filename + \".zim.idx\"\n                command = kiwix_manage + \" \" + kiwix_library_xml + \" add \" + zimname\n                if os.path.isdir (zimidx): # only declare index if exists (could be embedded)\n                    command += \" -i \" + zimidx\n                #print command\n                args = shlex.split(command)\n                try:\n                    outp = subprocess.check_output(args)\n\n                    # create map of generic zim name to actual, assumes pattern of <name>_<yyyy-mm>\n                    # all current files follow this pattern, but some older ones, no longer in the catalog, do not\n\n                    if filename in old_zim_map: # handle old names that don't parse\n                        wiki_name = old_zim_map[filename]\n                    else:\n                        ulpos = filename.rfind(\"_\")\n                        # but gutenberg don't - future maybe put in old_zim_map (en and fr, but instance dates may change)\n                        if \"gutenberg_\" in filename:\n                            ulpos = filename[:ulpos].rfind(\"_\")\n                        wiki_name = filename[:ulpos]\n\n                    zim_versions[wiki_name] = filename # if there are multiples, last should win\n\n                except: #skip things that don't work\n                    print 'skipping ' + filename\n                    pass\n\n    with open(zim_version_idx, 'w') as fp:\n        json.dump(zim_versions, fp)\n\n    sys.exit()\n\ndef init():\n\n    global iiab_base_path\n    global iiab_zim_path\n    global kiwix_library_xml\n    global kiwix_manage\n\n    config = ConfigParser.SafeConfigParser()\n    config.read(iiab_config_file)\n    iiab_base_path = config.get('location','iiab_base')\n    iiab_zim_path = config.get('kiwix-serve','iiab_zim_path')\n    kiwix_library_xml = config.get('kiwix-serve','kiwix_library_xml')\n    kiwix_manage = iiab_base_path + \"/kiwix/bin/kiwix-manage\"\n\n# Now start the application\n\nif __name__ == \"__main__\":\n\n    # Run the main routine\n    main()\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "700fc1270e6882f0236c02d8506f08a311af1555", "filename": "roles/5-xo-services/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: XO Services Installed\n  command: echo XO Services Installed\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "24cb7e844943863241fa6fe614e66365fde35f9e", "filename": "roles/2-common/tasks/packages.yml", "repository": "iiab/iiab", "decoded_content": "- name: install yum deps for arm!!!\n  shell: dnf install -y python-urlgrabber pyxattr yum-metadata-parser\n  when: ansible_distribution == \"Fedora\" and ansible_machine == \"armv7l\" and ansible_distribution_version|int >= 22\n\n- name: install yum from Fedora 23 for arm!!!\n  shell: dnf install -y https://kojipkgs.fedoraproject.org//packages/yum/3.4.3/506.fc23/noarch/yum-3.4.3-506.fc23.noarch.rpm python-dnf\n  when: ansible_distribution == \"Fedora\" and ansible_machine == \"armv7l\" and ansible_distribution_version|int >= 22\n\n- name: install yum if it has been dropped from our distribution -- Fedora 22 uses dnf!!!\n  shell: dnf install -y yum\n  when: ansible_distribution == \"Fedora\" and ansible_distribution_version|int >= 22 and ansible_machine != \"armv7l\"\n\n- name: get the createrepo program\n  package: name=createrepo\n           state=present\n  when: is_redhat\n\n- name: Create local repo\n  shell: createrepo {{ yum_packages_dir }}\n  when: is_redhat\n\n- name: Install local repo file.\n  template: dest=/etc/yum.repos.d/iiab-local.repo\n            src=local.repo\n            owner=root\n            mode=0644\n  when: is_redhat\n\n- name: Install yum packages\n  package: name={{ item }}\n           state=present\n  with_items:\n   - yum-utils\n   - createrepo\n   - wpa_supplicant\n   - linux-firmware\n   - syslog\n   - xml-common\n  when: is_redhat\n\n- name: Download usbmount -- not in debian-9\n  command: wget {{ iiab_download_url }}/usbmount_0.0.14.1_all.deb -P {{ downloads_dir }}\n  when: is_debian_9\n\n- name: Install usbmount for debian-9\n  command: apt install -y {{ downloads_dir }}/usbmount_0.0.14.1_all.deb\n  when: is_debian_9\n\n- name: Install packages for Debian\n  package: name={{ item }}\n           state=present\n  with_items:\n    - inetutils-syslogd\n    - wpasupplicant\n  when: is_debuntu\n\n- name: Install common packages\n  package: name={{ item }}\n           state=present\n  with_items:\n   - acpid\n   - mlocate\n   - rsync\n   - htop\n   - etckeeper\n   - python-passlib\n   - usbmount\n   - net-tools\n   - openssh-server\n   - sudo\n   - logrotate\n   - make\n   - tar\n   - unzip\n   - bzip2\n   - i2c-tools\n   - bridge-utils\n   - usbutils\n   - hostapd\n   - wget\n   - openssl   #FC 18 does not supply, but pear requires\n   - gawk\n   - curl\n   - pandoc\n   - lynx\n\n#- name: Install pip as a commonly required package management system\n#  command: curl https://bootstrap.pypa.io/get-pip.py -o {{ downloads_dir }}/get-pip.py\n\n#- name: Run the install script for pip\n#  command: python {{ downloads_dir }}/get-pip.py\n\n- name: Install Common python packages\n  package: name={{ item }}\n           state=present\n  with_items:\n   - python-pip\n   - python-setuptools\n   - python-virtualenv\n\n- name: Update common packages (not debian\n  package: name={{ item }}\n           state=latest\n  with_items:\n   - NetworkManager\n   - glibc # CVE-2015-7547\n   - bash\n   - iptables\n  when: is_redhat\n\n- name: Update common packages  (debian)\n  package: name={{ item }}\n           state=latest\n  with_items:\n   - libc6\n   - bash\n   - iptables\n  when: is_debuntu\n\n# instructions state to start with a fully updated system before starting, stop using\n# ansible as a crutch for developers not following the directions and taking short-cuts\n\n#- name: If version of Network manager has changed, subsequent nmcli commands will fail,restart now\n#  service: name=NetworkManager\n#           state=restarted\n#  when: not installing\n# the above should use a handler - all reboots should wait until all\n# mods are preformed\n\n- name: Install optional exFAT packages for CentOS\n  shell: yum --enablerepo=li-nux-ro install exfat-utils fuse-exfat\n  when: exFAT_enabled == \"True\" and ansible_distribution == \"CentOS\"\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "4c480d0f5d3890413d41ede6891bacf32d07fe4f", "filename": "tasks/create_repo_pypi_proxy_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_pypi_proxy\n    args: \"{{ _nexus_repos_pypi_defaults|combine(item) }}\""}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "74ae9e11fbf3438d53767bd8ae0a7dc424fe3b0b", "filename": "roles/9-local-addons/meta/main.yml", "repository": "iiab/iiab", "decoded_content": "# Add your role to this list and then uncomment dependencies.  Adding a tag is handy for testing.\n#dependencies:\n"}, {"commit_sha": "51dcdf691a7801895b569a5a927e30030d8feb70", "sha": "8c03638344ecdd2753792b206bcfbede32eb6e91", "filename": "tasks/linux_service.yml", "repository": "nusenu/ansible-relayor", "decoded_content": "---\n\n# Linux/systemd section (uses service module)\n# ===========================================\n \n- name: Ensure Tor instances are reloaded if its torrc changed (Linux/systemd)\n  become: yes\n  service: name=tor@{{ item.item[0] }}_{{ item.item.1.orport }}.service state=reloaded\n  with_items: instances.results\n  when: item.changed == True\n  tags:\n   - debian\n   - centos\n   - fedora\n   - reconfigure\n\n- name: Ensure Tor instances are enabled and started (Linux/systemd)\n  become: yes\n  service: name=tor@{{ item[0] }}_{{ item.1.orport }}.service enabled=yes state=started\n  with_nested:\n   - tor_ips\n   - tor_ports\n  tags:\n   - debian\n   - centos\n   - fedora\n"}, {"commit_sha": "f958689395b3fc98cacf0c605ed7b8b4b19718da", "sha": "b374dc7e04e00be0cacbdfba8ec3dff7214b9c0e", "filename": "tasks/install_via_stable.yml", "repository": "lae/ansible-role-netbox", "decoded_content": "---\n- name: Download and extract stable NetBox release\n  unarchive:\n    src: \"{{ netbox_stable_uri }}\"\n    dest: \"{{ netbox_releases_path }}\"\n    creates: \"{{ netbox_stable_path }}\"\n    remote_src: True\n  notify:\n    - reload netbox.service\n\n- name: Symlink stable release to current NetBox directory\n  file:\n    src: \"{{ netbox_stable_path }}\"\n    dest: \"{{ netbox_current_path }}\"\n    state: link\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "6d6ba89960ce053ff206a37dbbe229c38fd3356d", "filename": "roles/load-balancers/manage-haproxy/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ntemp_new_file: '/etc/haproxy/haproxy.cfg.new'\nlb_https_backends: {}\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "eadac0d2820a785a3b667d97dcca77ef83cd7a7a", "filename": "roles/mongodb/templates/mongodb", "repository": "iiab/iiab", "decoded_content": "OPTIONS=' -f /etc/mongod.conf '\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "fdc1ae5a2af1fd4c5a248c9d656f8c690bf982c9", "filename": "tasks/unit/setup-freebsd.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: FreeBSD) Fetch Ports\"\n  command: portsnap fetch --interactive\n  args:\n    creates: /var/db/portsnap/INDEX\n\n- name: \"(Install: FreeBSD) Extract Ports\"\n  command: portsnap extract\n  args:\n    creates: /usr/ports\n"}, {"commit_sha": "ccab58ae5d697bb64abd86558f79c34161d2fb00", "sha": "84a9a6985642810b91445ab5309c78597a7f8468", "filename": "tasks/requirements_and_deprecated.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n# This file contains all requirements and deprecation checks\n# that can be run before the role starts.\n\n# @requirement: jmespath module must be installe on ansible host\n# @version: 2.4.0\n- name: Check presence of jmespath python module on ansible host\n  block:\n    - name: Try to use jmespath on a test var\n      set_fact:\n        voidvar: \"{{ [] | json_query('[]') }}\"\n  rescue:\n    - name: Print message about jmespath\n      vars:\n        error_msg: |-\n          Since version 2.4.0, this role uses the  json_query filter which requires\n          the presense of the python module jmespath on the host running ansible.\n          Please install jmespath (i.e. pip install jmespath) on your ansible host.\n      debug:\n        msg: \"{{ error_msg.split('\\n') }}\"\n\n    - name: fail\n      fail:\n        msg: \"Install jmespath. See debug message above\"\n\n# @deprecated: nexus_package must not exists\n# @version: 2.2.0\n- name: Broken compatibility => nexus_package is now dynamically calculated\n  fail:\n    msg: >-\n      You have set the variable nexus_package in your playbook.\n      Starting from version 2.2.0 of this role, this is not compatible\n      with the new nexus latest version detection feature and is not\n      supported anymore. Please use the nexus_version variable only.\n  when: nexus_package is defined\n\n# @deprecated: purge was refactored to nexus_purge\n# @version: 2.2.3\n- name: Broken compatibility => purge var moved to nexus_purge\n  fail:\n    msg: >-\n      You have set the purge variable to reset nexus.\n      Starting from version 2.2.3 of this role, this variable\n      has been renamed nexus_purge. Please fix the var name accordingly\n      on you command line call.\n  when: purge is defined\n\n# @deprecated: public_hostname was renamed to nexus_public_hostname\n# @version: 2.3.0\n- name: Variable refactoring - public_hostname is now nexus_public_hostname\n  fail:\n    msg: >-\n      Version 2.3.0 of this role introduced a variable name change: public_hostname was renamed to\n      nexus_public_hostname. We have detected that public_hostname is set in your vars ({{ public_hostname }})\n      and is different from nexus_public_hostname which still has its default value ({{ nexus_public_hostname }}).\n      Fix this by setting a correct value for nexus_public_hostname and remove public_hostname if\n      possible.\n  when: >-\n    public_hosname | default('') | length > 0\n    and\n    public_hostname != nexus_public_hostname\n    and\n    nexus_public_hostname == 'nexus.vm'\n\n# @deprecated: remote_url is the variable to configure a proxy repo. proxy_url is not supported\n# anymore to configure docker proxy repos\n# @version: 2.4.0\n- name: \"Coding standard: proxy_url is not supported anymore for docker proxy repos\"\n  fail:\n    msg: >-\n      proxy_url used to be the variable to configure docker proxy repositories in nexus3-oss role. Since version 2.3.0,\n      all repository configuration use the same standard var remote_url. Please review your configurations\n      in nexus_repos_docker_proxy and rename the variable accordingly.\n  when: >-\n    nexus_repos_docker_proxy\n    | json_query('[?proxy_url]')\n    | list\n    | length > 0\n\n# @requirement: new internal var _nexus_repos_global_List must be undefined\n# @version: 2.4.0\n- name: \"Make sure our internal var for repos is unset\"\n  when: _nexus_repos_global_list is defined\n  block:\n    - name: Print debug message about our internal var\n      vars:\n        error_msg: |-\n          _nexus_repos_global_list is set somewhere in your playbook/inventory.\n          This is an internal var that must be unset when the role starts executing.\n          Please unset _nexus_repos_global_list from your playbook/inventory\n      debug:\n        msg: \"{{ error_msg.split('\\n') }}\"\n\n    - name: Fail as we cannot run correctly with internal var set\n      fail:\n        msg: \"Unset _nexus_repos_global_list. See debug message above\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "c093d4b36b49b877f4ec06f77930e79923f88b7e", "filename": "playbooks/identity.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Configure IdM/IPA'\n  hosts: idm-clients\n  roles:\n  - role: config-ipa-client\n  tags: \n  - configure_idm_client\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "7d94ed328611a568fcec0e401ce5e009148304f9", "filename": "playbooks/subscription-unregister.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "#!/usr/bin/env ansible-playbook\n---\n- hosts: all\n  gather_facts: false\n  become: true\n  tasks:\n    - name: Unregister host \n      redhat_subscription:\n        state: absent\n\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "71ed52e0cc65c4a6f7b0588ee6e17ce3e906c1f4", "filename": "tasks/configure-docker/configure-docker-plugins.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "- name: Fetch Docker daemon status\n  become: true\n  service:\n    name: docker\n  register: _docker_status\n\n- name: Start Docker daemon\n  become: yes\n  service:\n    name: docker\n    state: started\n  when:\n    - _docker_status.status is defined\n    - _docker_status.status.SubState is defined\n    - _docker_status.status.SubState != \"running\"\n\n- name: Wait for Docker daemon to started\n  become: true\n  shell: docker info\n  register: _docker_info\n  until: _docker_info.rc == 0\n  retries: 10\n  changed_when: false\n  tags:\n    - skip_ansible_lint\n\n- name: Install Docker plugins\n  become: true\n  shell: \"(docker plugin install --grant-all-permissions --alias {{ item.alias | default(item.name) }} {{ item.name }} \\\n    && echo 'installed') || echo 'nop'\"\n  with_items: \"{{ docker_plugins }}\"\n  register: _docker_plugin_install\n  changed_when: _docker_plugin_install.stdout_lines | last == 'installed'\n  when:\n    - docker_network_access\n\n- name: Reset list of authorization plugins\n  set_fact:\n    _authz_plugins: []\n\n- name: Create list of authorization plugins\n  set_fact:\n    _authz_plugins: \"{{ _authz_plugins + [item.alias | default(item.name)] }}\"\n  with_items: \"{{ docker_plugins }}\"\n  when:\n    - item.type == 'authz'\n\n- name: Update Docker daemon configuration with authorization plugins\n  set_fact:\n    docker_daemon_config: \"{{ docker_daemon_config | combine(_updated_item, recursive=true) }}\"\n  vars:\n    _updated_item: \"{ 'authorization-plugins': {{ _authz_plugins | list }} }\"\n\n- name: Update Docker daemon (variables)\n  become: true\n  copy:\n    content: \"{{ docker_daemon_config | to_nice_json }}\"\n    dest: /etc/docker/daemon.json\n  notify: restart docker\n  when:\n    - docker_daemon_config_file is not defined\n    - docker_daemon_config is defined\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "fe0d216383832c3ec933ebb2d9892721a738f0e1", "filename": "archive/roles/registry/handlers/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n- name: reload systemd\n  command: systemctl daemon-reload\n\n- name: restart docker registry\n  service:\n    name: docker-distribution\n    state: restarted\n\n- name: reload nginx\n  service:\n    name: nginx\n    state: reloaded\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "667004055f41b7b0767433972f9973b0403d5d37", "filename": "playbooks/roles/check_docker_validation/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- name: Pull some basic docker images\n  docker_image:\n    name: \"{{item}}:{{docker_prepull_tag}}\"\n  with_items:\n  - \"{{docker_prepull}}\"\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "cb04d52b3526c189f98e0100b1758489ecaf7a09", "filename": "playbooks/files/rock_status", "repository": "rocknsm/rock", "decoded_content": "#!/usr/bin/bats\n\nexport ZOOKEEPER_HOST=127.0.0.1\nexport ZOOKEEPER_PORT=2181\nexport MON_IFS=$(cat /opt/bro/etc/node.cfg | grep interface | \\\n\tsed 's/interface=//; s/.*:://' | sort | uniq | paste -sd \" \" -)\n\nfunction feature_enabled() {\n  if grep -qiE \"^with_$1: (true|yes)\" /etc/rocknsm/config.yml; then\n    grep -qiE \"^enable_$1: (true|yes)\" /etc/rocknsm/config.yml;\n    return $?\n  else\n    return 1\n  fi\n}\n\n#----------------------------------------------------------------------------\n#                               INTERFACE\n#----------------------------------------------------------------------------\n\n@test \"Check each monitor interface is live\" {\n  local timeout_sec=5\n  local timeout_pkt=5\n  local results=()\n\n  # Timeout after 5 seconds or 5 packets\n  for interface in $MON_IFS; do\n    packets_1=$(ethtool -S ${interface} | awk '/rx_packets/ {print $2}')\n    sleep ${timeout_sec}\n    packets_2=$(ethtool -S ${interface} | awk '/rx_packets/ {print $2}')\n    packets=$(echo `expr ${packets_2} - ${packets_1}`)\n    echo \"${interface} had ${packets} packets in ${timeout_sec} secs.\"\n    [ $packets -gt 0 ]\n  done\n}\n\n@test \"Check for interface errors\" {\n  for interface in $MON_IFS; do\n    count=$(ethtool -S ${interface} | awk '/error/ && $2 > 0' | wc -l )\n    echo \"${interface} had ${count} error types.\"\n    echo \">> Check \\`ethtool -S ${interface} | awk '/error/' \\`  << \"\n    [ $count -eq 0 ]\n  done\n}\n\n@test \"Check monitor interface for tx packets\" {\n  for interface in $MON_IFS; do\n    pkts=$(ethtool -S ${interface} | awk '/tx_packets/ {print $2}')\n    echo \"WARNING: Monitor interface ${interface} has sent ${pkts} packets\".\n    [ $pkts -eq 0 ]\n  done\n}\n\n#----------------------------------------------------------------------------\n#                               BRO\n#----------------------------------------------------------------------------\nif feature_enabled bro; then\n\n@test \"Check that broctl is running\" {\n  # This will fail if a worker is crashed as well\n  sudo /opt/bro/bin/broctl status\n}\n\n@test \"Check for bro-detected packet loss\" {\n  local notice_log='/data/bro/logs/current/notice.log'\n  if [ ! -f \"${notice_log}\"]; then\n    skip \"No notice.log to check for packet loss errors.\"\n  fi\n\n  capture_cnt=$(cat ${notice_log} | grep 'CaptureLoss::Too_Much_Loss'|wc -l)\n  drop_cnt=$(cat ${notice_log} | grep 'PacketFilter::Dropped_Packets'|wc -l)\n\n  if [ $capture_cnt > 0 ]; then\n    if [ $drop_cnt > 0 ]; then\n      echo \"Sensor is dropping packets before Bro can process them.\"\n      [ $drop_cnt -eq 0 ]\n    else\n      echo \"Packets are being dropped prior to sensor receiving them.\"\n      [ $capture_cnt -eq 0 ]\n    fi\n  fi\n}\n\nfi\n#----------------------------------------------------------------------------\n#                               SURICATA\n#----------------------------------------------------------------------------\nif feature_enabled suricata; then\n\n@test \"Check that suricata is running\" {\n  systemctl status suricata\n}\n\nfi\n#----------------------------------------------------------------------------\n#                                SNORT\n#----------------------------------------------------------------------------\nif feature_enabled snort; then\n\n@test \"Check that snort is running\" {\n  systemctl status snortd\n}\n\nfi\n#----------------------------------------------------------------------------\n##                               FSF\n##----------------------------------------------------------------------------\n\n@test \"Check that FSF is running\" {\nif feature_enabled fsf; then\n  systemctl status fsf\nfi\n}\n\n#----------------------------------------------------------------------------\n#                               ZOOKEEPER\n#----------------------------------------------------------------------------\nif feature_enabled zookeeper; then\n\n@test \"Check that zookeeper is running\" {\n  systemctl status zookeeper\n}\n\n@test \"Check that zookeeper is listening\" {\n  ss -lnt | grep ${ZOOKEEPER_PORT}\n}\n\n@test \"Check that client can connect to zookeeper\" {\n  echo \"\u0004\" | ncat  ${ZOOKEEPER_HOST} ${ZOOKEEPER_PORT}\n}\n\nfi\n#----------------------------------------------------------------------------\n#                               KAFKA\n#----------------------------------------------------------------------------\nif feature_enabled kafka; then\n\n@test \"Check that kafka is running\" {\n  systemctl status kafka\n}\n\n@test \"Check that kafka is connected to zookeeper\" {\n  kafka_pid=$(systemctl show -p MainPID kafka.service | cut -d= -f2)\n  echo \"kafka_pid: ${kafka_pid}\"\n  kafka_socket=$(sudo ss -ntp | grep \"${kafka_pid}\" | \\\n\tgrep \"${ZOOKEEPER_PORT}\" | awk '{ print $4 }'| sed 's/::ffff://g')\n  echo \"Kafka socket: ${kafka_socket}\"\n  kafka_conns=$(echo \"cons\" | ncat ${ZOOKEEPER_HOST} ${ZOOKEEPER_PORT} | \\\n\tgrep \"${kafka_socket}\" )\n  echo -e \"Kafka Connections: \\n ${kafka_conns}\"\n  conn_count=$(echo ${kafka_conns} | wc -l )\n  echo \"Number of Kafka Conns: ${conn_count}\"\n  # It's possible this might need to be -ge\n  [ ${conn_count} -eq 1 ]\n}\n\nfi\n\n#----------------------------------------------------------------------------\n#                               LOGSTASH\n#----------------------------------------------------------------------------\n\nif feature_enabled logstash; then\n\n@test \"Check that logstash is running\" {\n  systemctl status logstash\n}\n\nfi\n#----------------------------------------------------------------------------\n#                               ELASTICSEARCH\n#----------------------------------------------------------------------------\n\nif feature_enabled elasticsearch; then\n\n@test \"Check that elasticsearch is running\" {\n  systemctl status elasticsearch\n}\n\n@test \"Check that elasticsearch is green\" {\n  result=$(curl -s http://localhost:9200/_cluster/health | jq '.status')\n  [ \"${result}\" == \"\\\"green\\\"\" ]\n}\n\nfi\n#----------------------------------------------------------------------------\n#                               KIBANA\n#----------------------------------------------------------------------------\n\nif feature_enabled kibana; then\n\n@test \"Check that kibana is running\" {\n  systemctl status kibana\n}\n\nfi\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a863bd055e01c1cf31c130ae48fc002bb67ba5e2", "filename": "roles/config-chrony/tasks/prereq.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Install required packages'\n  package:\n    name: '{{ item }}'\n    state: installed\n  with_items:\n  - chrony\n  - firewalld\n  - python-firewall\n\n- name: 'Start firewalld'\n  service:\n    name: firewalld\n    state: started\n    enabled: yes\n\n- name: 'Open Firewall for NTP/Chrony use'\n  firewalld:\n    service: \"{{ item }}\"\n    permanent: yes\n    state: enabled\n    immediate: yes\n  with_items:\n  - ntp\n\n\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "7c8c3f1b1b22ec2bd1a3b105a41c848f471b6d21", "filename": "tasks/create_repo_docker_group_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_docker_group\n    args: \"{{ _nexus_repos_docker_defaults|combine(item) }}\"\n"}, {"commit_sha": "d25113e8fab871b2ead95ca976c5a43e4759ea26", "sha": "069fdccd88032ff4a1b1dc975533d8f15d5a3fcf", "filename": "meta/main.yml", "repository": "UnderGreen/ansible-role-mongodb", "decoded_content": "---\n\ndependencies: []\n\ngalaxy_info:\n  author: Sergei Antipov\n  company: 2GIS\n  description: Manage MongoDB (MMS) with authentication and replica sets\n  license: GPLv2\n  platforms:\n  - name: Ubuntu\n    versions:\n    - trusty\n  - name: Debian\n    versions:\n    - wheezy\n    - jessie\n  categories:\n  - database\n  - database:nosql\n"}, {"commit_sha": "abafe1581c6c78d784cf215b214947675d49eff8", "sha": "f5951a4543e6a814e8bd92c0408888120e2fd5ac", "filename": "roles/vpn/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: Gather Facts\n  setup:\n\n- name: Install StrongSwan\n  apt: name=strongswan state=latest update_cache=yes\n\n- name: Enforcing ipsec with apparmor\n  shell: aa-enforce \"{{ item }}\"\n  with_items:\n    - /usr/lib/ipsec/charon\n    - /usr/lib/ipsec/lookip\n    - /usr/lib/ipsec/stroke\n  notify:\n    - restart apparmor\n\n- name: Enable services\n  service: name={{ item }} enabled=yes\n  with_items:\n    - apparmor\n    - strongswan\n    - netfilter-persistent\n\n- name: Configure iptables so IPSec traffic can traverse the tunnel\n  iptables: table=nat chain=POSTROUTING source=\"{{ vpn_network }}\" jump=MASQUERADE\n  when: (security_enabled is not defined) or\n        (security_enabled is defined and security_enabled != \"y\")\n  notify:\n    - save iptables\n\n- name: Configure ip6tables so IPSec traffic can traverse the tunnel\n  iptables: ip_version=ipv6 table=nat chain=POSTROUTING source=\"{{ vpn_network_ipv6 }}\" jump=MASQUERADE\n  when: (security_enabled is not defined) or\n        (security_enabled is defined and security_enabled != \"y\")\n  notify:\n    - save iptables\n\n- name: Ensure that the strongswan group exist\n  group: name=strongswan state=present\n\n- name: Ensure that the strongswan user exist\n  user: name=strongswan group=strongswan state=present\n\n- name: Ensure that the strongswan service directory exist\n  file: path=/etc/systemd/system/strongswan.service.d/ state=directory mode=0755  owner=root group=root\n\n- name: Setup the cgroup limitations for the ipsec daemon\n  template: src=100-CustomLimitations.conf.j2 dest=/etc/systemd/system/strongswan.service.d/100-CustomLimitations.conf\n  notify:\n    - daemon-reload\n    - restart strongswan\n\n- meta: flush_handlers\n\n- name: Setup the strongswan.conf file from our template\n  template: src=strongswan.conf.j2 dest=/etc/strongswan.conf owner=root group=root mode=0644\n  notify:\n    - restart strongswan\n\n- name: Setup the ipsec.conf file from our template\n  template: src=ipsec.conf.j2 dest=/etc/ipsec.conf owner=root group=root mode=0644\n  notify:\n    - restart strongswan\n\n- name: Setup the ipsec.secrets file\n  template: src=ipsec.secrets.j2 dest=/etc/ipsec.secrets owner=strongswan group=root mode=0600\n  notify:\n    - restart strongswan\n\n- name: Get loaded plugins\n  shell: >\n    find /etc/strongswan.d/charon/ -type f -name '*.conf' -printf '%f\\n' | cut -f1 -d.\n  register: strongswan_plugins\n\n- name: Disable unneeded plugins\n  lineinfile: dest=\"/etc/strongswan.d/charon/{{ item }}.conf\" regexp='.*load.*' line='load = no' state=present\n  notify:\n    - restart strongswan\n  when: item not in strongswan_enabled_plugins\n  with_items: \"{{ strongswan_plugins.stdout_lines }}\"\n\n- name: Ensure that required plugins are enabled\n  lineinfile: dest=\"/etc/strongswan.d/charon/{{ item }}.conf\" regexp='.*load.*' line='load = yes' state=present\n  notify:\n    - restart strongswan\n  when: item in strongswan_enabled_plugins\n  with_items: \"{{ strongswan_plugins.stdout_lines }}\"\n\n- name: Fetch easy-rsa-ipsec from git\n  git: repo=git://github.com/ValdikSS/easy-rsa-ipsec.git version=ed4de10d7ce0726357fb1bb4729f8eb440c06e2b dest=\"{{ easyrsa_dir }}\"\n\n- name: Setup the vars file from our template\n  template: src=easy-rsa.vars.j2 dest={{ easyrsa_dir }}/easyrsa3/vars\n\n- name: Ensure the pki directory is not exist\n  file: dest={{ easyrsa_dir }}/easyrsa3/pki state=absent\n  when: easyrsa_reinit_existent == True\n\n- name: Build the pki enviroments\n  shell: >\n    ./easyrsa init-pki &&\n    touch '{{ easyrsa_dir }}/easyrsa3/pki/pki_initialized'\n  args:\n    chdir: '{{ easyrsa_dir }}/easyrsa3/'\n    creates: '{{ easyrsa_dir }}/easyrsa3/pki/pki_initialized'\n\n- name: Build the CA pair\n  shell: >\n    ./easyrsa build-ca nopass &&\n    touch {{ easyrsa_dir }}/easyrsa3/pki/ca_initialized\n  args:\n    chdir: '{{ easyrsa_dir }}/easyrsa3/'\n    creates: '{{ easyrsa_dir }}/easyrsa3/pki/ca_initialized'\n  notify:\n    - restart strongswan\n\n- name: Build the server pair\n  shell: >\n    ./easyrsa --subject-alt-name='DNS:{{ IP_subject_alt_name }},IP:{{ IP_subject_alt_name }}' build-server-full {{ IP_subject_alt_name }} nopass &&\n    touch '{{ easyrsa_dir }}/easyrsa3/pki/server_initialized'\n  args:\n    chdir: '{{ easyrsa_dir }}/easyrsa3/'\n    creates: '{{ easyrsa_dir }}/easyrsa3/pki/server_initialized'\n  notify:\n    - restart strongswan\n\n- name: Build the client's pair\n  shell: >\n    ./easyrsa build-client-full {{ item }} nopass &&\n    touch '{{ easyrsa_dir }}/easyrsa3/pki/{{ item }}_initialized'\n  args:\n    chdir: '{{ easyrsa_dir }}/easyrsa3/'\n    creates: '{{ easyrsa_dir }}/easyrsa3/pki/{{ item }}_initialized'\n  with_items: \"{{ users }}\"\n\n- name: Build the client's p12\n  shell: >\n    openssl pkcs12 -in {{ easyrsa_dir }}/easyrsa3//pki/issued/{{ item }}.crt -inkey {{ easyrsa_dir }}/easyrsa3//pki/private/{{ item }}.key -export -name {{ item }} -out /{{ easyrsa_dir }}/easyrsa3//pki/private/{{ item }}.p12 -certfile {{ easyrsa_dir }}/easyrsa3//pki/ca.crt -passout pass:{{ easyrsa_p12_export_password }} &&\n    touch '{{ easyrsa_dir }}/easyrsa3/pki/{{ item }}_p12_initialized'\n  args:\n    chdir: '{{ easyrsa_dir }}/easyrsa3/'\n    creates: '{{ easyrsa_dir }}/easyrsa3/pki/{{ item }}_p12_initialized'\n  with_items: \"{{ users }}\"\n\n- name: Copy the CA cert to the strongswan directory\n  copy: remote_src=True src='{{ easyrsa_dir }}/easyrsa3/pki/ca.crt' dest=/etc/ipsec.d/cacerts/ca.crt owner=strongswan group=root mode=0600\n  notify:\n    - restart strongswan\n\n- name: Copy the server cert to the strongswan directory\n  copy: remote_src=True src='{{ easyrsa_dir }}/easyrsa3/pki/issued/{{ IP_subject_alt_name }}.crt' dest=/etc/ipsec.d/certs/{{ IP_subject_alt_name }}.crt owner=strongswan group=root mode=0600\n  notify:\n    - restart strongswan\n\n- name: Copy the server key to the strongswan directory\n  copy: remote_src=True src='{{ easyrsa_dir }}/easyrsa3/pki/private/{{ IP_subject_alt_name }}.key' dest=/etc/ipsec.d/private/{{ IP_subject_alt_name }}.key owner=strongswan group=root mode=0600\n  notify:\n    - restart strongswan\n\n- name: Register p12 PayloadContent\n  shell: >\n    cat /{{ easyrsa_dir }}/easyrsa3//pki/private/{{ item }}.p12 | base64\n  register:  PayloadContent\n  with_items: \"{{ users }}\"\n\n- name: Register CA PayloadContent\n  shell: >\n    cat /{{ easyrsa_dir }}/easyrsa3/pki/ca.crt | base64\n  register:  PayloadContentCA\n\n- name: Set facts for mobileconfigs\n  set_fact:\n    proxy_enabled: false\n\n- name: Build the mobileconfigs\n  template: src=mobileconfig.j2 dest=/{{ easyrsa_dir }}/easyrsa3//pki/private/{{ item.0 }}.mobileconfig mode=0600\n  with_together:\n    - \"{{ users }}\"\n    - \"{{ PayloadContent.results }}\"\n  no_log: True\n\n- name: Build the client ipsec config file\n  template: src=client_ipsec.conf.j2 dest=/{{ easyrsa_dir }}/easyrsa3//pki/private/ipsec_{{ item }}.conf mode=0600\n  with_items:\n    - \"{{ users }}\"\n\n- name: Build the client ipsec secret file\n  template: src=client_ipsec.secrets.j2 dest=/{{ easyrsa_dir }}/easyrsa3//pki/private/ipsec_{{ item }}.secrets mode=0600\n  with_items:\n    - \"{{ users }}\"\n\n- name: Fetch users P12\n  fetch: src=/{{ easyrsa_dir }}/easyrsa3//pki/private/{{ item }}.p12 dest=configs/{{ IP_subject_alt_name }}_{{ item }}.p12 flat=yes\n  with_items: \"{{ users }}\"\n\n- name: Fetch users mobileconfig\n  fetch: src=/{{ easyrsa_dir }}/easyrsa3//pki/private/{{ item }}.mobileconfig dest=configs/{{ IP_subject_alt_name }}_{{ item }}.mobileconfig flat=yes\n  with_items: \"{{ users }}\"\n\n- name: Fetch users certificates\n  fetch: src=/{{ easyrsa_dir }}/easyrsa3//pki/issued/{{ item }}.crt dest=configs/{{ IP_subject_alt_name }}_{{ item }}.crt flat=yes\n  with_items: \"{{ users }}\"\n\n- name: Fetch users keys\n  fetch: src=/{{ easyrsa_dir }}/easyrsa3//pki/private/{{ item }}.key dest=configs/{{ IP_subject_alt_name }}_{{ item }}.key flat=yes\n  with_items: \"{{ users }}\"\n\n- name: Fetch users ipsec configs\n  fetch: src=/{{ easyrsa_dir }}/easyrsa3//pki/private/ipsec_{{ item }}.conf dest=configs/{{ IP_subject_alt_name }}_{{ item }}_ipsec.conf flat=yes\n  with_items: \"{{ users }}\"\n\n- name: Fetch users ipsec secrets\n  fetch: src=/{{ easyrsa_dir }}/easyrsa3//pki/private/ipsec_{{ item }}.secrets dest=configs/{{ IP_subject_alt_name }}_{{ item }}_ipsec.secrets flat=yes\n  with_items: \"{{ users }}\"\n\n- name: Build the windows client powershell script\n  template: src=client_windows.ps1.j2 dest=/{{ easyrsa_dir }}/easyrsa3//pki/private/windows_{{ item }}.ps1 mode=0600\n  when: Win10_Enabled is defined and Win10_Enabled == \"Y\"\n  with_items: \"{{ users }}\"\n\n- name: Fetch users windows scripts\n  fetch: src=/{{ easyrsa_dir }}/easyrsa3//pki/private/windows_{{ item }}.ps1 dest=configs/{{ IP_subject_alt_name }}_{{ item }}_windows.ps1 flat=yes\n  when: Win10_Enabled is defined and Win10_Enabled == \"Y\"\n  with_items: \"{{ users }}\"\n\n- name: Restrict permissions\n  file: path=\"{{ item }}\" state=directory mode=0700  owner=strongswan group=root\n  with_items:\n    - /etc/ipsec.d/private\n\n- name: Fetch server CA certificate\n  fetch: src=/{{ easyrsa_dir }}/easyrsa3/pki/ca.crt dest=configs/{{ IP_subject_alt_name }}_ca.crt flat=yes\n\n- include: iptables.yml\n  tags: iptables\n"}, {"commit_sha": "481f7ad18dc225973e1d676d33e58c49cbbfe986", "sha": "07938e4602b8ac9bcb6897475a9c23b0c23c1a34", "filename": "tasks/pip.yml", "repository": "openwisp/ansible-openwisp2", "decoded_content": "- name: Set openwisp2_python_packages\n  set_fact:\n    openwisp2_python_packages: []\n\n- name: Set custom package list\n  set_fact:\n    openwisp2_python_packages: \"{{ openwisp2_python_packages  + [item] }}\"\n  with_items:\n    - \"{{ openwisp2_controller_pip }}\"\n    - \"{{ openwisp2_users_pip }}\"\n    - \"{{ openwisp2_django_netjsonconfig_pip }}\"\n    - \"{{ openwisp2_django_x509_pip }}\"\n    - \"{{ openwisp2_django_loci_pip }}\"\n    - \"{{ openwisp2_netjsonconfig_pip }}\"\n  when: item != false\n\n- name: Add network_topology to custom package list if set and enabled\n  set_fact: openwisp2_python_packages:\"{{ openwisp2_python_packages + [item] }}\"\n  with_items:\n    - \"{{ openwisp2_django_netjsongraph_pip }}\"\n    - \"{{ openwisp2_network_topology_pip }}\"\n  when: item != false and openwisp2_network_topology\n\n- name: Update pip & related tools\n  pip:\n    name:\n      - pip\n      - setuptools\n      - wheel\n    state: latest\n    virtualenv: \"{{ virtualenv_path }}\"\n    virtualenv_python: \"{{ openwisp2_python }}\"\n    virtualenv_site_packages: yes\n\n- name: Install openwisp2 controller and its dependencies\n  pip:\n    name:\n      - openwisp-controller\n      - asgi_redis\n      - service_identity\n    state: latest\n    virtualenv: \"{{ virtualenv_path }}\"\n    virtualenv_python: \"{{ openwisp2_python }}\"\n    virtualenv_site_packages: yes\n  notify: reload supervisor\n\n- name: Install django-redis\n  pip:\n    name: \"django-redis>=4.9.0\"\n    state: present\n    virtualenv: \"{{ virtualenv_path }}\"\n    virtualenv_python: \"{{ openwisp2_python }}\"\n    virtualenv_site_packages: yes\n  notify: reload supervisor\n\n- name: Install openwisp2 network topology and its dependencies\n  when: openwisp2_network_topology\n  pip:\n    name:\n      - openwisp-network-topology\n    state: latest\n    virtualenv: \"{{ virtualenv_path }}\"\n    virtualenv_python: \"{{ openwisp2_python }}\"\n    virtualenv_site_packages: yes\n  notify: reload supervisor\n\n- name: Install custom OpenWISP 2 Python packages\n  pip:\n    name: \"{{ item }}\"\n    state: latest\n    virtualenv: \"{{ virtualenv_path }}\"\n    virtualenv_python: \"{{ openwisp2_python }}\"\n    virtualenv_site_packages: yes\n  with_items: \"{{ openwisp2_python_packages }}\"\n  notify: reload supervisor\n\n- name: Install extra python packages\n  pip:\n    name: \"{{ item }}\"\n    state: latest\n    virtualenv: \"{{ virtualenv_path }}\"\n    virtualenv_python: \"{{ openwisp2_python }}\"\n    virtualenv_site_packages: yes\n  with_items: \"{{ openwisp2_extra_python_packages }}\"\n  notify: reload supervisor\n\n- name: Install uwsgi\n  pip:\n    name:\n      - uwsgi\n    state: latest\n    virtualenv: \"{{ virtualenv_path }}\"\n    virtualenv_python: \"{{ openwisp2_python }}\"\n    virtualenv_site_packages: yes\n\n  notify: reload supervisor\n\n- name: Install psycopg2\n  when: openwisp2_database.engine in [\"django.db.backends.postgresql\", \"django.contrib.gis.db.backends.postgis\"]\n  pip:\n    name: psycopg2\n    state: latest\n    virtualenv: \"{{ virtualenv_path }}\"\n    virtualenv_python: \"{{ openwisp2_python }}\"\n    virtualenv_site_packages: yes\n  notify: reload supervisor\n\n- name: Install MySQL-python\n  when: openwisp2_database.engine in [\"django.db.backends.mysql\", \"django.contrib.gis.db.backends.mysql\"]\n  pip:\n    name: MySQL-python\n    state: latest\n    virtualenv: \"{{ virtualenv_path }}\"\n    virtualenv_python: \"{{ openwisp2_python }}\"\n    virtualenv_site_packages: yes\n  notify: reload supervisor\n\n- name: Install raven (sentry client)\n  when: openwisp2_sentry.get('dsn') != False\n  pip:\n    name: raven\n    state: latest\n    virtualenv: \"{{ virtualenv_path }}\"\n    virtualenv_python: \"{{ openwisp2_python }}\"\n    virtualenv_site_packages: yes\n  notify: reload supervisor\n"}, {"commit_sha": "abafe1581c6c78d784cf215b214947675d49eff8", "sha": "467de88b469145b5d3d274942716008bbc8eb46a", "filename": "roles/logging/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "# Auditd\n\n- name: Auditd installed\n  apt: name=auditd state=latest\n\n- name: Auditd rules configured\n  template: src=audit.rules.j2 dest=/etc/audit/audit.rules\n  notify:\n    - restart auditd\n\n- name: Auditd configured\n  template: src=auditd.conf.j2 dest=/etc/audit/auditd.conf\n  notify:\n    - restart auditd\n\n- name: Enable services\n  service: name=auditd enabled=yes\n\n# Rsyslog\n\n- name: Rsyslog installed\n  apt: name=rsyslog state=latest\n\n- name: Rsyslog configured\n  template: src=rsyslog.conf.j2 dest=/etc/rsyslog.conf\n  notify:\n    - restart rsyslog\n\n- name: Rsyslog CIS configured\n  template: src=CIS.conf.j2 dest=/etc/rsyslog.d/CIS.conf owner=root group=root mode=0644\n  notify:\n    - restart rsyslog\n\n- name: Enable services\n  service: name=rsyslog enabled=yes\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "91a909b1c6101ea353d4b92d006da93308eb090a", "filename": "playbooks/roles/check_storage/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- shell: |\n    if [[ $(df -T / | tail -n 1 | awk '{print $2}') == \"btrfs\" ]]; then\n      btrfs fi usage --kbytes / | awk '/^.*Free / {print $3}'| sed 's/\\..*//'\n    else\n      df -BK / | tail -n 1 | awk '/^[^Filesystem]/ {print $4}' | sed 's/K//'\n    fi\n  changed_when: false\n  register: root_space_available\n- name: Set root disk facts\n  set_fact:\n    root_space_available_bytes: \"{{ ( root_space_available.stdout | int) * 1024 | int }}\"\n- name: Set root disk in bytes\n  set_fact:\n    disk_free_space_bytes: \"{{ ((disk_free_space | int) * 1024**3) | int }}\"\n- name: Set root disk size in GB\n  set_fact:\n    root_gb_available: \"{{ ((root_space_available_bytes | int ) / 1024**3) | round(2, 'floor') }}\"\n- name: Fail if there is not enough space available in /\n  assert:\n    that: |\n      (root_space_available_bytes | int) >= (disk_free_space_bytes | int)\n    msg: \"There is no enough root space available on this node, required {{disk_free_space}} available {{root_gb_available}}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "648ebaf5e73989cb415be4326757627af49570ff", "filename": "roles/dns/manage-dns-zones-route53/tasks/loop-zones.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Loop over all zones\n  include_tasks: loop-records.yml\n  with_items:\n    - \"{{ zones_records.results }}\"\n  loop_control:\n    loop_var: r53_zone\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "27b0666c55f05d27ab4e764be4f84f7321388d13", "filename": "roles/config-satellite/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ndefault_manifest_file_path: manifest.zip\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "54d1836d517d422f85c0d8adfb33573e81c6bbb7", "filename": "playbooks/bb4/redhat-registry-mirror.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- name: Setup disconnected installation\n  hosts: bastion\n  gather_facts: no\n  vars_files:\n  - ../vars/bb4.yml\n  - ../group_vars/all\n  tasks:\n  - name: Install required packages\n    yum:\n      name: \"{{item}}\"\n      state: present\n    with_items: \"{{registry_packages}}\"\n  - name: Configure Docker Registry\n    template:\n      src: templates/config.j2\n      dest: \"{{registry_path}}/{{registry_conf}}\"\n  - name: Generate Registry certificates\n    shell: openssl req -x509 -newkey rsa:4096 -nodes -sha256 -days 3650 -keyout cert.key -out cert.cert -subj \"/CN={{registry.split(':')[0]}}\"\n    args:\n      chdir: \"{{registry_path}}\"\n    register: cert_gen\n  - name: Create Registry dir in /etc/docker/certs.d/\n    file:\n      path:  \"/etc/docker/certs.d/{{registry.split(':')[0]}}\"\n      state: directory\n      mode: 0755\n  - name: Create a symlink inside /etc/docker/certs.d/ for generate certs\n    file:\n      src: \"{{registry_path}}/cert.cert\"\n      dest: \"/etc/docker/certs.d/{{registry.split(':')[0]}}/cert.crt\"\n      state: link\n  - name: Start and enable Docker Registry\n    shell: systemctl enable docker-distribution && systemctl start docker-distribution\n    register: registry_stat\n  - name: Create script to sync images\n    template:\n      src: templates/local-registry-setup-v2.j2\n      dest: /tmp/local-registry-setup-v2\n      mode: 0755\n  - name: Sync images\n    shell: /tmp/local-registry-setup-v2 > /tmp/sync\n    register: sync\n\n\n \n\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "4546928cdb815f68f638b5e6ed9d0271d4049455", "filename": "roles/weave/tasks/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n\n- name: upload weave template service\n  template:\n    src: weave.conf.j2\n    dest: \"/etc/init/weave.conf\"\n    mode: 0755\n  sudo: yes\n  tags:\n    - weave\n\n- name: ensure weave service is running.\n  sudo: yes\n  service:\n    name: weave\n    state: started\n    enabled: yes\n\n- name: wait for weave socket to be ready.\n  wait_for:\n    port: 6783\n    delay: 10\n\n- name: download weave scope\n  get_url:\n    url: \"{{ weave_scope_url }}\"\n    dest: \"{{ weave_scope_dest }}\"\n    mode: 0755\n    validate_certs: no\n  environment: proxy_env\n  when: weave_scope_enabled\n  tags:\n    - weave\n\n- name: upload weave scope template service\n  template:\n    src: scope.conf.j2\n    dest: \"/etc/init/weavescope.conf\"\n    mode: 0755\n  sudo: yes\n  when: weave_scope_enabled\n  tags:\n    - weave\n\n# Flush handlers so we restart the Docker process here with the weave network\n# enabled and containers correctly start in the weave network.\n- meta: flush_handlers\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "045fe455eef232d4c88c5335be2790eda0135591", "filename": "roles/cloud-ec2/defaults/main.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\nec2_vpc_nets:\n  cidr_block: 172.16.0.0/16\n  subnet_cidr: 172.16.254.0/23\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "f767271010d3aa85de82f52309640341f2453e21", "filename": "roles/config-iscsi-client/tests/host_vars/node-2.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\niscsi_initiatorname: iqn.1994-05.com.example:node-2\n\ndisk_mapping:\n- lun: 0\n  vg: vg0\n  lv: lv0\n  mount_path: /mnt/vg0-lv0\n"}, {"commit_sha": "c33f3410e002f9d8506f0725f56b7d7afa1c5f74", "sha": "b153e53bfc45074c4a81300c68494fa4f52d4b17", "filename": "tasks/packages-Debian.yml", "repository": "jloh/nagios-nrpe-server", "decoded_content": "---\n# Update apt-cache for Debian based OS's\n- name: Update apt cache [Debian]\n  apt: update_cache=yes\n\n# Nagios NRPE Server for Debian based OS's\n- name: Install Nagios NRPE Server [Debian]\n  apt: name=nagios-nrpe-server state=present\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "252894b663c4fd54cf9a931e4d8dd3e2ba58dfb5", "filename": "roles/cloud-azure/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- set_fact:\n    resource_group: \"Algo_{{ region }}\"\n    secret: \"{{ azure_secret | default(lookup('env','AZURE_SECRET'), true) }}\"\n    tenant: \"{{ azure_tenant | default(lookup('env','AZURE_TENANT'), true) }}\"\n    client_id: \"{{ azure_client_id | default(lookup('env','AZURE_CLIENT_ID'), true) }}\"\n    subscription_id: \"{{ azure_subscription_id | default(lookup('env','AZURE_SUBSCRIPTION_ID'), true) }}\"\n\n- name: Create a resource group\n  azure_rm_resourcegroup:\n    secret: \"{{ secret }}\"\n    tenant: \"{{ tenant }}\"\n    client_id: \"{{ client_id }}\"\n    subscription_id: \"{{ subscription_id }}\"\n    name: \"{{ resource_group }}\"\n    location: \"{{ region }}\"\n    tags:\n      Environment: Algo\n\n- name: Create a virtual network\n  azure_rm_virtualnetwork:\n    secret: \"{{ secret }}\"\n    tenant: \"{{ tenant }}\"\n    client_id: \"{{ client_id }}\"\n    subscription_id: \"{{ subscription_id }}\"\n    resource_group: \"{{ resource_group }}\"\n    name: algo_net\n    address_prefixes: \"10.10.0.0/16\"\n    tags:\n      Environment: Algo\n\n- name: Create a security group\n  azure_rm_securitygroup:\n    secret: \"{{ secret }}\"\n    tenant: \"{{ tenant }}\"\n    client_id: \"{{ client_id }}\"\n    subscription_id: \"{{ subscription_id }}\"\n    resource_group: \"{{ resource_group }}\"\n    name: AlgoSecGroup\n    purge_rules: yes\n    rules:\n      - name: AllowSSH\n        protocol: Tcp\n        destination_port_range: 22\n        access: Allow\n        priority: 100\n        direction: Inbound\n      - name: AllowIPSEC500\n        protocol: Udp\n        destination_port_range: 500\n        access: Allow\n        priority: 110\n        direction: Inbound\n      - name: AllowIPSEC4500\n        protocol: Udp\n        destination_port_range: 4500\n        access: Allow\n        priority: 120\n        direction: Inbound\n\n- name: Create a subnet\n  azure_rm_subnet:\n    secret: \"{{ secret }}\"\n    tenant: \"{{ tenant }}\"\n    client_id: \"{{ client_id }}\"\n    subscription_id: \"{{ subscription_id }}\"\n    resource_group: \"{{ resource_group }}\"\n    name: algo_subnet\n    address_prefix: \"10.10.0.0/24\"\n    virtual_network: algo_net\n    security_group_name: AlgoSecGroup\n    tags:\n      Environment: Algo\n\n- name: Create an instance\n  azure_rm_virtualmachine:\n    secret: \"{{ secret }}\"\n    tenant: \"{{ tenant }}\"\n    client_id: \"{{ client_id }}\"\n    subscription_id: \"{{ subscription_id }}\"\n    resource_group: \"{{ resource_group }}\"\n    admin_username: ubuntu\n    virtual_network: algo_net\n    name: \"{{ azure_server_name }}\"\n    ssh_password_enabled: false\n    vm_size: \"{{ cloud_providers.azure.size }}\"\n    tags:\n      Environment: Algo\n    ssh_public_keys:\n      - { path: \"/home/ubuntu/.ssh/authorized_keys\", key_data: \"{{ lookup('file', '{{ SSH_keys.public }}') }}\" }\n    image:\n      offer: UbuntuServer\n      publisher: Canonical\n      sku: '16.04-LTS'\n      version: latest\n  register: azure_rm_virtualmachine\n\n  # To-do: Add error handling - if vm_size requested is not available, can we fall back to another, ideally with a prompt?\n\n- set_fact:\n    ip_address: \"{{ azure_rm_virtualmachine.ansible_facts.azure_vm.properties.networkProfile.networkInterfaces[0].properties.ipConfigurations[0].properties.publicIPAddress.properties.ipAddress }}\"\n    networkinterface_name: \"{{ azure_rm_virtualmachine.ansible_facts.azure_vm.properties.networkProfile.networkInterfaces[0].name }}\"\n\n- name: Ensure the network interface includes all required parameters\n  azure_rm_networkinterface:\n    secret: \"{{ secret }}\"\n    tenant: \"{{ tenant }}\"\n    client_id: \"{{ client_id }}\"\n    subscription_id: \"{{ subscription_id }}\"\n    name: \"{{ networkinterface_name }}\"\n    resource_group: \"{{ resource_group }}\"\n    virtual_network_name: algo_net\n    subnet_name: algo_subnet\n    security_group_name: AlgoSecGroup\n\n- name: Add the instance to an inventory group\n  add_host:\n    name: \"{{ ip_address }}\"\n    groups: vpn-host\n    ansible_ssh_user: ubuntu\n    ansible_python_interpreter: \"/usr/bin/python2.7\"\n    ansible_ssh_private_key_file: \"{{ SSH_keys.private }}\"\n    cloud_provider: azure\n    ipv6_support: no\n\n- set_fact:\n    cloud_instance_ip: \"{{ ip_address }}\"\n\n- name: Ensure the group azure exists in the dynamic inventory file\n  lineinfile:\n    state: present\n    dest: configs/inventory.dynamic\n    line: '[azure]'\n\n- name: Populate the dynamic inventory\n  lineinfile:\n    state: present\n    dest: configs/inventory.dynamic\n    insertafter: '\\[azure\\]'\n    regexp: \"^{{ cloud_instance_ip }}.*\"\n    line: \"{{ cloud_instance_ip }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "dbccf9375b7b4b08038bdab0d23a102eb111df4d", "filename": "roles/ansible/tower/config-ansible-tower-ldap/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: restart-tower\n  service:\n    name:  supervisord\n    state: restarted\n  become: True\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "1f1de192470bc39496f4676565f96d2758c1e5b4", "filename": "tasks/section_12.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - include: section_12_level1.yml\n    tags:\n      - section12\n      - level1\n\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "2272403cbb2628b4fe9e918c9ffe8f399cbed7b5", "filename": "roles/common/handlers/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: restart rsyslog\n  service: name=rsyslog state=restarted\n\n- name: restart ipfw\n  service: name=ipfw state=restarted\n\n- name: flush routing cache\n  shell: echo 1 > /proc/sys/net/ipv4/route/flush\n\n- name: restart loopback\n  shell: ifdown lo:100 && ifup lo:100\n\n- name: restart loopback bsd\n  shell: >\n    ifconfig lo100 destroy || true &&\n    ifconfig lo100 create &&\n    ifconfig lo100 inet {{ local_service_ip }} netmask 255.255.255.255 &&\n    ifconfig lo100 inet6 FCAA::1/64; echo $?\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "135fdaa4b469df3302c000b1682ae35f7458c3e2", "filename": "roles/manage-aws-infra/tasks/update-cns-nodes.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n- name: \"Set facts needed for CNS deployment\"\n  set_fact:\n    \n\n"}, {"commit_sha": "4eeee9eb934aff6fd8af0b32e75128c884379f1d", "sha": "90d9f7692f1dda2eae403b43fdb0170e912d89b3", "filename": "meta/main.yml", "repository": "geerlingguy/ansible-role-solr", "decoded_content": "---\ndependencies: []\n\ngalaxy_info:\n  author: geerlingguy\n  description: Apache Solr for Linux.\n  company: \"Midwestern Mac, LLC\"\n  license: \"license (BSD, MIT)\"\n  min_ansible_version: 1.8\n  platforms:\n    - name: EL\n      versions:\n      - 6\n      - 7\n    - name: Debian\n      versions:\n      - all\n    - name: Ubuntu\n      versions:\n      - all\n  galaxy_tags:\n    - development\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "45b3998a181551dd87ca694f58812b0aca998d28", "filename": "tasks/Linux/fetch/security-fetch/security-fetch-web.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Download security policy artifact from web\n  get_url:\n    url: '{{ java_unlimited_policy_url }}'\n    dest: '{{ java_download_path }}'\n  register: policy_file_downloaded\n  retries: 3\n  delay: 2\n  until: policy_file_downloaded is succeeded\n\n- name: Downloaded security policy artifact\n  set_fact:\n    security_policy_java_artifact: '{{ policy_file_downloaded.dest }}'\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "659f7590ea845e832b975e28e4e29483be1b1091", "filename": "roles/network/templates/gateway/check-LAN", "repository": "iiab/iiab", "decoded_content": "#!/bin/bash\nrun_detect(){\n    logger \"check-LAN: running reconfig\"\n    cd /opt/schoolserver/iiab\n    /opt/schoolserver/iiab/runtags network > /dev/null\n    logger \"check-LAN: completed reconfig\"\n    exit 0\n}\n\nexit_clean(){\n    logger \"check-LAN: completed - nothing to do\"\n    exit 0\n}\n\nlogger \"check-LAN: startup\"\n\nif [ -f /etc/sysconfig/xs_lan_device ]; then\n    LAN_DEVICE=`cat /etc/sysconfig/xs_lan_device`\n    if [ \"x$LAN_DEVICE\" = \"x\" ]; then\n        logger \"check-LAN: no lan expected\"\n        exit_clean\n    else\n        if [ \"$LAN_DEVICE\" = \"br0\" ]; then\n            SLAVES=`egrep -rn BRIDGE=br0 /etc/sysconfig/network-scripts/ifcfg-* \\\n            | gawk -F'[-:]' '{print $3}'`\n            SLAVE_COUNT=`egrep -rn BRIDGE=br0 /etc/sysconfig/network-scripts/ifcfg-* \\\n            | wc | awk '{print $1}'`\n\n            logger \"check-LAN: looking for $SLAVE_COUNT slaves\"\n\n            while [ \"$SLAVE_COUNT\" > 1 ]; do \n                TEST_SLAVE=`brctl show | tail -n $[ $SLAVE_COUNT - 1 ] | awk '{print $1}'`\n                if [ \"x$TEST_SLAVE\" = \"x\" ]; then\n                    logger \"check-LAN: blank slave for number $SLAVE_COUNT\"\n                    run_detect\n                else\n                    logger \"check-LAN: slave number $SLAVE_COUNT $TEST_SLAVE present\"\n                fi\n                SLAVE_COUNT=\"$[ $SLAVE_COUNT - 1 ]\"\n                if [ \"$SLAVE_COUNT\" = 1 ]; then\n                    TEST_SLAVE=`brctl show | grep br0 | awk '{print $4}'`\n                    if [ \"x$TEST_SLAVE\" = \"x\" ]; then\n                        logger \"check-LAN: single blank slave for number $SLAVE_COUNT\"\n                        run_detect\n                    else\n                        logger \"check-LAN: single slave number $SLAVE_COUNT $TEST_SLAVE present\"\n                        exit_clean\n                    fi\n                fi\n            done\n        fi\n        LAN_IF=`ip -o addr | grep 172.18 | awk '{print $2}'`\n        if [ \"$LAN_IF\" = \"$LAN_DEVICE\" ]; then\n            logger \"check-LAN: expected LAN matched $LAN_DEVICE\"\n            exit_clean\n        fi\n    fi\nelse\n    logger \"check-LAN: unconfigured\"\n    exit_clean\nfi\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "3e87b366eac8521f6180e46117ec75862635922e", "filename": "playbooks/files/nginx.conf", "repository": "rocknsm/rock", "decoded_content": "# For more information on configuration, see:\n#   * Official English Documentation: http://nginx.org/en/docs/\n#   * Official Russian Documentation: http://nginx.org/ru/docs/\n\nuser nginx;\nworker_processes auto;\nerror_log /var/log/nginx/error.log;\npid /run/nginx.pid;\n\n# Load dynamic modules. See /usr/share/nginx/README.dynamic.\ninclude /usr/share/nginx/modules/*.conf;\n\nevents {\n    worker_connections 1024;\n}\n\nhttp {\n    log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                      '$status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n    access_log  /var/log/nginx/access.log  main;\n\n    sendfile            on;\n    tcp_nopush          on;\n    tcp_nodelay         on;\n    keepalive_timeout   65;\n    types_hash_max_size 2048;\n\n    include             /etc/nginx/mime.types;\n    default_type        application/octet-stream;\n\n    # Load modular configuration files from the /etc/nginx/conf.d directory.\n    # See http://nginx.org/en/docs/ngx_core_module.html#include\n    # for more information.\n    include /etc/nginx/conf.d/*.conf;\n}\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "744d902f07b4b1ef52aa56632f92bdb395dbe0a0", "filename": "roles/activity-server/files/www.0/index.html.fr", "repository": "iiab/iiab", "decoded_content": "<!DOCTYPE html>\n<META http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n<body>\n<h1 id=\"olpc-activity-group-name\">Activit\u00e9s disponibles localement</h1>\n<p id=\"olpc-activity-group-desc\">Ces activit\u00e9s sont stock\u00e9es sur le serveur de l\u2019\u00e9cole.</p>\n<div class=\"olpc-activity-info\">\nIl n'y a pas d'activit\u00e9s. Ins\u00e9rez une cl\u00e9 USB avec des activit\u00e9s sur pour ajouter.\n</div>\n\n</body>\n</html>\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "c4e4498b61a4b8b7b63ac423785c2780e0197c8b", "filename": "tasks/opensource/install-oss-bsd.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: FreeBSD) Update ports\"\n  block:\n\n    - name: \"(Install: FreeBSD) Fetch Ports\"\n      command: portsnap fetch --interactive\n      args:\n        creates: /var/db/portsnap/INDEX\n\n    - name: \"(Install: FreeBSD) Extract Ports\"\n      command: portsnap extract\n      args:\n        creates: /usr/ports\n\n  when:\n    - ansible_system == 'FreeBSD'\n    - nginx_bsd_update_ports\n\n- name: \"(Install: FreeBSD)\"\n  block:\n\n    - name: \"(Install: FreeBSD) Install NGINX package\"\n      pkgng:\n        name: \"www/nginx{{ nginx_version | default('') }}\"\n        state: present\n      when: nginx_bsd_install_packages\n      notify: \"(Handler: All OSs) Start NGINX\"\n\n    - name: \"(Install: FreeBSD) Install NGINX port\"\n      portinstall:\n        name: \"www/nginx{{ nginx_version | default('') }}\"\n        use_packages: \"{{ nginx_bsd_portinstall_use_packages | default(omit) }}\"\n        state: present\n      when: not nginx_bsd_install_packages\n      notify: \"(Handler: All OSs) Start NGINX\"\n\n  when: ansible_system == 'FreeBSD'\n\n- name: \"(Install: OpenBSD)\"\n  block:\n\n    - name: \"(Install: OpenBSD) Install NGINX package\"\n      openbsd_pkg:\n        name: \"nginx{{ nginx_version | default('') }}\"\n        build: false\n        state: present\n      when: nginx_bsd_install_packages\n      notify: \"(Handler: All OSs) Start NGINX\"\n\n    - name: \"(Install: OpenBSD) Install NGINX port\"\n      openbsd_pkg:\n        name: \"nginx{{ nginx_version | default('') }}\"\n        build: true\n        state: present\n      when: not nginx_bsd_install_packages\n      notify: \"(Handler: All OSs) Start NGINX\"\n\n  when: ansible_system == 'OpenBSD'\n\n- name: \"(Install: NetBSD)\"\n  block:\n\n    - name: \"(Install: NetBSD) Install NGINX package\"\n      command: \"pkg_add www/nginx{{ nginx_version | default('') }}\"\n      when: nginx_bsd_install_packages\n      notify: \"(Handler: All OSs) Start NGINX\"\n\n    - name: \"(Install: NetBSD) Install NGINX port\"\n      fail:\n        msg: \"{{ ansible_system }} Install NGINX port not implemented.\"\n      when: not nginx_bsd_install_packages\n\n  when: ansible_system == 'NetBSD'\n\n- name: \"(Install: DragonFlyBSD)\"\n  block:\n\n    - name: \"(Install: DragonFlyBSD) Install NGINX package\"\n      command: \"pkg install www/nginx{{ nginx_version | default('') }}\"\n      when: nginx_bsd_install_packages\n      notify: \"(Handler: All OSs) Start NGINX\"\n\n    - name: \"(Install: DragonFlyBSD) Install NGINX port\"\n      fail:\n        msg: \"{{ ansible_system }} Install NGINX port not implemented.\"\n      when: not nginx_bsd_install_packages\n\n  when: ansible_system == 'DragonFlyBSD'\n\n- name: \"(Install: HardenedBSD)\"\n  block:\n\n    - name: \"(Install: HardenedBSD) Install NGINX package\"\n      command: \"pkg install www/nginx{{ nginx_version | default('') }}\"\n      when: nginx_bsd_install_packages\n      notify: \"(Handler: All OSs) Start NGINX\"\n\n    - name: \"(Install: HardenedBSD) Install NGINX port\"\n      fail:\n        msg: \"{{ ansible_system }} Install NGINX port not implemented.\"\n      when: not nginx_bsd_install_packages\n\n  when: ansible_system == 'HardenedBSD'\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "9ee638d9b64d36bd2fe268eaf5221b1bc479f68f", "filename": "archive/roles/openstack-create/tasks/security_groups.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- name: \"Create Security Groups if required\"\n  os_security_group:\n    name: \"{{ item.name }}\"\n    state: present\n  with_items: \"{{ security_groups }}\"\n  when: neutron_in_use\n\n- name: \"Create SSH Rule in matching Security Group if required\"\n  os_security_group_rule:\n    security_group: \"{{ item.0.name }}\"\n    protocol: \"{{ item.1.protocol }}\"\n    port_range_min: \"{{ item.1.from_port }}\"\n    port_range_max: \"{{ item.1.to_port }}\"\n    remote_ip_prefix: \"{{ item.1.cidr }}\"\n  when:\n    - item.1.name is defined\n    - item.1.protocol is defined\n    - item.1.from_port is defined\n    - item.1.to_port is defined\n    - item.1.cidr is defined\n    - neutron_in_use\n  with_subelements:\n    - \"{{ security_groups }}\"\n    - rules\n\n# Build a comma-separated list of security groups defined in the array\n# Initialize list variable so previous runs are not concatenated\n- set_fact:\n    security_groups_list: \"\"\n\n- name: \"Build a list of Security Groups\"\n  set_fact:\n    security_groups_list: \"{{ [item.name,security_groups_list | default('')] | join(',') }}\"\n  with_items: \"{{ security_groups }}\"\n\n# This is an optional task as it cleans up the string variable, otherwise the way it is constructed would result in an extra comma at the end as such 'group1,group2,\" and this can be passed to the nova_compute module just fine but this extra step just cleans it up\n- set_fact:\n    security_groups_list: \"{{ security_groups_list | regex_replace('^(.*),$', '\\\\1') }}\"\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "e7433589139778ea2f35175a0a2316d5b0264fee", "filename": "roles/config-lvm/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nlvm_fstype: \"xfs\"\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "721472d64b008cd88ea32a8d1d95df8f4128d3f6", "filename": "roles/consul/defaults/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# defaults file for consul\nconsul_dc: dc1\nconsul_servers_group: consul_servers\nconsul_advertise: \"{{ ansible_ssh_host }}\"\nconsul_bind_addr: \"{{ ansible_default_ipv4.address }}\"\nconsul_retry_join: \"{% for host in groups[consul_servers_group] %}\\\"{{ hostvars[host].ansible_default_ipv4.address }}\\\"{% if not loop.last %}, {% endif %}{% endfor %}\"\nconsul_bootstrap_expect: \"{{ groups[consul_servers_group] | length }}\"\nconsul_client_addr: \"0.0.0.0\"\nconsul_atlas_join: false\nconsul_node_name: \"{{ ansible_hostname }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "c1b14169ee06efc370b3e1ce8becd46c40d3d25a", "filename": "roles/user-management/manage-idm-users/tasks/configure_user.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "--- \n  - name: Create IPA user\n    ipa_user:\n      ipa_host: \"{{ ipa_host | default(ansible_host)}}\"\n      ipa_user: \"{{ ipa_admin_user }}\"\n      ipa_pass: \"{{ ipa_admin_password }}\"\n      validate_certs: \"{{ ipa_validate_certs | default(False) }}\"\n      givenname: \"{{ item.first_name | trim }}\"\n      sn: \"{{ item.last_name | trim }}\"\n      name: \"{{ item.user_name | trim }}\"\n      mail: \"{{ item.email | default('') }}\"\n      state: \"{{ item.state | default('present') }}\"\n# The addition of expiration date is a request that will be submitted upstream\n#      krbprincipalexpiration: \"{{ item.expiration_date | default('') }}\"\n    with_items: \"{{ users }}\"\n    register: idm_user_list\n\n  - name: \"Clear users before re-building list with additional data\"\n    set_fact: \n       users: []\n\n  - name: \"Create password generation dataset\"\n    set_fact: \n       users: \"{{ users + [idm_data.item | combine(idm_data | set_user_flags) ] }}\"\n    with_items: \"{{ idm_user_list.results }}\"\n    loop_control:\n      loop_var: idm_data\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "8e3cfd51faa931ecb191c0413937bef488884f68", "filename": "playbooks/manage-users/manage-users.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: \"Manage local users\"\n  import_playbook: manage-local-user-access.yml\n\n- name: \"Manage IDM users\"\n  import_playbook: manage-idm-users.yml\n\n- name: \"Manage Atlassian users\"\n  import_playbook: manage-atlassian-users.yml\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "c31a75a01accdb8a24043c2c18b00686c6f4d4c6", "filename": "playbooks/manage-users/manage-idm-users.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Import user data from {{ csv_doc_file_name }} and create IDM users\"\n  hosts: identity-hosts\n  gather_facts: no\n  roles:\n    - user-management/populate-users\n    - user-management/manage-idm-users\n    - user-management/manage-user-passwd\n\n- name: \"Notify users\"\n  import_playbook: ../notifications/email-notify-users.yml\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "a69c43e42286785ffaaf8625de447fe55a8b35fa", "filename": "tasks/conf/setup-status.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Setup: NGINX Open Source) Enable NGINX Open Source Status\"\n  blockinfile:\n    path: \"{{ nginx_status_location }}\"\n    create: yes\n    block: |\n      server {\n          listen 127.0.0.1:{{ nginx_status_port | default('80') }};\n          location /nginx_status {\n              stub_status on;\n              allow 127.0.0.1;\n              deny all;\n          }\n      }\n  when: nginx_type == \"opensource\"\n  notify: \"(Handler: All OSs) Reload NGINX\"\n\n- name: \"(Setup: NGINX Plus) Enable NGINX Plus Status\"\n  blockinfile:\n    path: \"{{ nginx_status_location }}\"\n    create: yes\n    block: |\n      server {\n          listen 127.0.0.1:{{ nginx_status_port | default('80') }};\n          location /status {\n              status;\n              allow 127.0.0.1;\n              deny all;\n          }\n      }\n  when: nginx_type == \"plus\"\n  notify: \"(Handler: All OSs) Reload NGINX\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a6000f41477b04367a50b643953e22e6542a6ae1", "filename": "roles/config-postgresql/tasks/firewall.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Check if firewalld is installed\n  command: systemctl status firewalld\n  register: firewalld_status\n  failed_when: false\n  changed_when: false\n\n- name: Check if iptables is installed\n  command: systemctl status iptables\n  register: iptables_status\n  failed_when: false\n  changed_when: false\n\n- name: Open port in firewalld\n  firewalld:\n    port: \"{{ postgresql_host_port }}/tcp\"\n    permanent: true\n    state: enabled\n  when: firewalld_status.rc == 0\n  notify:\n  - restart firewalld\n\n- name: Open iptables Postgresql firewall port for future sessions\n  lineinfile:\n    insertbefore: \"-A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT\"\n    state: present\n    dest: /etc/sysconfig/iptables\n    regexp: \"^-A INPUT .* --dport {{ postgresql_host_port }} .* ACCEPT\"\n    line: \"-A INPUT -p tcp -m state --state NEW -m tcp --dport {{ postgresql_host_port }} -j ACCEPT\"\n  when: iptables_status.rc == 0 and firewalld_status.rc != 0\n  # notify:\n  # - restart iptables\n\n- name: Open iptables Postgresql firewall port for current session\n  iptables:\n    action: insert\n    protocol: tcp\n    destination_port: \"{{ postgresql_host_port }}\"\n    state: present\n    chain: INPUT\n    jump: ACCEPT\n  when: iptables_status.rc == 0 and firewalld_status.rc != 0\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "3ca4f302e134343195b84d40002b8f5a604755ea", "filename": "roles/dhcp/tests/vars.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# vars file for dhcp-config\ndhcp_host_entries:\n- host: test1\n  fqdn: test1.example.com\n  hw_addr: e0:07:1b:ec:fd:ec\n  ip_addr: 192.168.10.123\n\n- host: test2\n  fqdn: test2.example.com\n  hw_addr: e0:07:1b:fd:a5:70\n  ip_addr: 192.168.11.124\n\n\n#\n# Define the subnet entries\n#\ndhcp_subnet_entries:\n- subnet: 192.168.11.0\n  range: 192.168.11.50 192.168.11.99\n  subnet_mask: 255.255.255.0\n  router: 192.168.11.1\n  broadcast: 192.168.11.255\n  dns: 8.8.8.8, 8.8.4.4\n  domain_search: example.com \n  domain_name: example.com\n  next_server: 192.168.11.33\n\n- subnet: 192.168.12.0\n  range: 192.168.12.50 192.168.12.99\n  subnet_mask: 255.255.255.0\n  router: 192.168.12.1\n  broadcast: 192.168.12.255\n  dns: 8.8.8.8, 8.8.4.4\n  domain_search: example.com \n  domain_name: example.com\n  next_server: 192.168.12.33\n\n- subnet: 192.168.100.0\n  range: 192.168.100.50 192.168.100.99\n  subnet_mask: 255.255.255.0\n  router: 192.168.100.1\n  broadcast: 192.168.100.255\n  dns: 8.8.8.8, 8.8.4.4\n  domain_search: example.com \n  domain_name: example.com\n  next_server: 192.168.100.33\n\ndhcp_group_entries:\n- group:\n  title: '# Test group 1'\n  hosts:\n  - desc: '# Blade #1 - interface \"ens1f0\"'\n    name: node1\n    hw_addr: 00:0a:f7:57:e1:f0\n    ip_addr: 192.168.11.121\n    fqdn: node1.example.com\n\n  - desc: '# Blade #2 - interface \"ens1f0\"'\n    name: node2\n    hw_addr: 00:0a:f7:57:dd:80\n    ip_addr: 192.168.11.122\n    fqdn: node4.example.com\n\n- group: \n  title: '#Test group 2 '\n  hosts:\n  - desc: '# Blade #3 - interface \"ens1f0\"'\n    name: node3\n    hw_addr: 00:0a:f7:57:dd:80\n    ip_addr: 192.168.11.123\n    fqdn: node5.example.com\n\n  - desc: '# Blade #4 - interface \"ens1f0\"'\n    name: node4\n    hw_addr: 00:0a:f7:57:de:54\n    ip_addr: 192.168.11.124\n    fqdn: node6.example.com\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "fe440ec11df5b1703627152c3b1299167ae13597", "filename": "playbooks/roles/check_networking/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- name: check is net.ipv4.ip_forward turned on\n  command: sysctl -b net.ipv4.ip_forward\n  register: ip_forward_check\n- name: show error\n  debug:\n    msg: \"net.ipv4.ip_forward is 0 forcing it to 1\"\n  when: ip_forward_check.stdout == 0\n- name: force net.ipv4.ip_forward to 1\n  sysctl:\n    name: net.ipv4.ip_forward\n    value: 1\n    sysctl_set: yes\n    state: present\n    reload: yes\n  when: ip_forward_check.stdout == 0\n\n- name: Check state of firewalld\n  systemd: name=firewalld\n  register: firewalld_check\n\n- name: Fail when firewalld is active\n  fail:\n    msg: \"firewalld is active, but iptables is required\"\n  when: \"firewalld_check.status.ActiveState == 'active'\"\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "0c64ea40cb8897d3a2d2a46dcdb097e62e7a26bc", "filename": "tasks/Win32NT/system_chocolatey.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: 'Perform {{ java_binary_type }} install'\n  include_tasks: '{{ install_task }}'\n  with_first_found:\n    - 'install/{{ java_distribution }}_{{ java_binary_type }}.yml'\n    - 'install/{{ java_binary_type }}.yml'\n  loop_control:\n    loop_var: install_task\n\n- name: Finalize binary paths\n  include_tasks: finalize_paths.yml\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "9585e2adaf32df67c5ba712dec8be880a860d1dc", "filename": "roles/ejabberd_xs/templates/ejabberd-xs.init", "repository": "iiab/iiab", "decoded_content": "#!/bin/bash\n#\n# ejabberd    Start and stop ejabberd.\n\n# chkconfig: - 40 60\n# description: ejabberd\n# processname: ejabberd\n# pidfile: /var/run/ejabberd/ejabberd.pid\n\n### BEGIN INIT INFO\n# Provides: ejabberd\n# Required-Start: network\n# Required-Stop: network\n# Default-Start:\n# Default-Stop: 0 1 6\n# Short-Description: Start and stop ejabberd\n# Description: A distributed, fault-tolerant Jabber/XMPP server\n### END INIT INFO\n\n. /etc/rc.d/init.d/functions\n\nif [ -r /etc/sysconfig/ejabberd-xs ]; then\n\t. /etc/sysconfig/ejabberd-xs\nfi\n\nif [ ! \"$CONFIG_FILE\" ]; then\n\tCONFIG_FILE=/etc/ejabberd/ejabberd.cfg\nfi\n\n# /var/run is tmpfs in fc18, so need to create every time\nmkdir -p /var/run/ejabberd\nchown ejabberd:ejabberd /var/run/ejabberd\n\n# avoid using consolehelper, call ejabberdctl directly\nprogctl=/usr/sbin/ejabberdctl\n\nSYS_DOMAIN_FILE=/etc/sysconfig/xs_domain_name\nOUR_DOMAIN_FILE=/etc/sysconfig/ejabberd_domain_name\n\ncheck_domain_configured() {\n    if [ ! -e /etc/sysconfig/xs_domain_name ]; then\n\techo \"Domain not configured yet\" > /dev/stderr\n\texit 1;\n    fi\n\n    domain=`cat \"$SYS_DOMAIN_FILE\" `\n    if [ \"$domain\" == \"random.xs.laptop.org\" ]; then\n\techo \"Domain not configured yet\" > /dev/stderr\n\texit 1;\n    fi\n\n    #hostname=`hostname -f`\n    hostname=`hostname `\n    if [ \"$hostname\" == \"localhost.localdomain\" ]; then\n         echo \"Domain not configured yet\" > /dev/stderr\n    fi\n\n#    if [ \"$hostname\" != \"schoolserver.$domain\" ]; then\n#         echo \"Domain changed -- restart to enable ejabberd\" > /dev/stderr\n#    fi\n\n    short_host=`hostname -s`\n    node_name=`cat $OUR_DOMAIN_FILE`\n\n#    if [ ! -e \"$OUR_DOMAIN_FILE\" ] || ! cmp \"$SYS_DOMAIN_FILE\" \"$OUR_DOMAIN_FILE\" ; then\n    if [ ! -e \"$OUR_DOMAIN_FILE\" ] ; then\n\tupdate_domain\n    fi\n}\n\nupdate_domain() {\n\n    BACKUP_SUFFIX=old\n\n    if [ -e $CONFIG_FILE ]; then\n\tcp $CONFIG_FILE $CONFIG_FILE.$BACKUP_SUFFIX || exit 1\n    fi\n\n    new_name=$short_host.$domain\n\n    #(sed -e s/@@BASEDNSNAME2@@/$new_name/ $CONFIG_FILE.in > $CONFIG_FILE.tmp ) && mv $CONFIG_FILE.tmp $CONFIG_FILE || exit 1\n\n    # If we are changing the domain, we must clear the DB.\n    if [ -e /var/lib/ejabberd/online_src_created ] ; then\n\trm -f /var/lib/ejabberd/online_src_created\n    fi\n    if [ -d /var/lib/ejabberd/spool/ ]; then\n\trm -f /var/lib/ejabberd/spool/*\n    fi\n\n    # Mark as done -\n    # cp \"$SYS_DOMAIN_FILE\" \"$OUR_DOMAIN_FILE\"\n    echo \"$domain\" > \"$OUR_DOMAIN_FILE\"\n}\n\nsetup_online_srg() {\n\n    if [ -e /var/lib/ejabberd/online_src_created ]; then\n\treturn 0\n    fi;\n\n    # give ejabberd a bit of time to startup on XO-1 HW :-)\n    sleep 10;\n\n    short_host=`hostname -s`\n    domain=`cat \"$SYS_DOMAIN_FILE\"`\n\n    # Note: grep -q exits as soon as the match is found, which ejabberdctl\n    # doesn't like. So we send the output to /dev/null instead - more\n    # portable too.\n    #\n    # ejabberdctl should handle SIGPIPE without messing up, but that's\n    # a minor problem anyway.\n    #\n    if ! ejabberdctl srg_list \"$short_host.$domain\" | grep '^Online$' > /dev/null ; then\n\t# ejabberdctl doesn't like spaces in the description field.\n\t# backslashes work - but escaping is better left alone for now :-)\n\tejabberdctl srg_create Online \"$short_host.$domain\" \\\n\t    Online \"Created_by_ejabberd_init\" Online\n\t[ $? -eq 0 ] || return 1\n    fi\n\n    if ! ejabberdctl srg_get_info Online \"$short_host.$domain\" | grep '^online_users: true$' > /dev/null ; then\n\tejabberdctl srg_user_add '@online@' \"$short_host.$domain\" \\\n\t    Online \"$short_host.$domain\"\n\t[ $? -eq 0 ] || return 1\n    fi\n\n    # mark success\n    touch /var/lib/ejabberd/online_src_created\n}\n\nis_running() {\n\t/sbin/runuser -s /bin/bash - ejabberd -c \"$progctl status\" &>/dev/null\n}\n\nstart() {\n        echo -n $\"Starting ejabberd: \"\n\t#if [ \"$ULIMIT_MAX_FILES\" ]; then\n\t#\tulimit -n $ULIMIT_MAX_FILES\n\t#fi\n\n\tcheck_domain_configured\n\n\t# check whether ejabberd was already started\n\tif is_running; then\n\t\techo -n \"already running\" && warning && echo\n\t\treturn 0\n\tfi\n\n\tdaemon --user=ejabberd $progctl start\t--config $CONFIG_FILE \\\n\t\t\t\t--ctl-config /etc/ejabberd/ejabberdctl.cfg \\\n\t\t\t\t--logs \"/var/log/ejabberd\" \\\n\t\t\t\t--spool \"/var/lib/ejabberd/spool\" \\\n\t\t\t\t2>/dev/null\n        RETVAL=$?\n        [ $RETVAL -eq 0 ] && touch /var/lock/subsys/ejabberd\n        echo\n\n\t# it takes some time to actually start necessary nodes\n\tsleep 5\n\n\t# Ignore the return val of setup_online_srg\n\t# ==> startup even if the SRG setup had errors.\n    set +e;\n    setup_online_srg\n\n        return $RETVAL\n}\n\nstop() {\n        # Stop daemons.\n        echo -n \"Shutting down ejabberd: \"\n\n\t# check whether ejabberd was already stopped\n\tif ! is_running; then\n\t\techo -n \"already stopped\" && warning && echo\n\t\treturn 0\n\tfi\n\n\tdaemon $progctl stop 2>/dev/null\n        RETVAL=$?\n        [ $RETVAL -eq 0 ] && rm -f /var/lock/subsys/ejabberd\n        echo\n\n\t# it takes some time to actually stop necessary nodes\n\tsleep 5\n\n        return $RETVAL\n}\n\nrestart() {\n        stop\n\tsleep 5\n        start\n}\n\n# See how we were called.\ncase \"$1\" in\n  start)\n        start\n        ;;\n  stop)\n        stop\n        ;;\n  restart|force-reload)\n        restart\n        ;;\n  condrestart|try-restart)\n        [ -f /var/lock/subsys/ejabberd ] && restart || :\n        ;;\n  status)\n\t$progctl status\n        ;;\n  *)\n        echo \"Usage: ejabberd {start|stop|restart|force-reload|condrestart|try-restart|status}\"\n        exit 2\nesac\n\nexit $RETVAL\n\n\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "a5a392bcea4a4615867317d8304608d815f0f5ad", "filename": "tasks/create_repo_raw_hosted_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_raw_hosted\n    args: \"{{ _nexus_repos_raw_defaults|combine(item) }}\""}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "2fe3a5559c1c79c835b67370ebd7cac82a9620ba", "filename": "roles/8-mgmt-tools/meta/main.yml", "repository": "iiab/iiab", "decoded_content": "dependencies:\n#   - { role: sugar-stats, tags: ['olpc','sugar-stats','tools'], when: sugar_stats_install and ansible_distribution != \"CentOS\" }\n#   - { role: ajenti, tags: ['services','ajenti','tools'], when: ajenti_install }\n   - { role: munin, tags: ['services','munin','tools'], when: munin_install }\n   - { role: monit, tags: ['services','monit','tools'], when: monit_install }\n   - { role: vnstat, tags: ['services','vnstat','tools'], when: vnstat_install }\n#   - { role: xovis, tags: ['services','xovis','tools'], when: xovis_install and ansible_distribution != \"CentOS\" }\n   - { role: phpmyadmin, tags: ['services','phpmyadmin','tools'], when: phpmyadmin_install }\n   - { role: awstats, tags: ['services','awstats','tools'], when: awstats_install }\n   - { role: teamviewer, tags: ['services','teamviewer','tools'], when: teamviewer_install }\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "08f7d837e68f0bf8b8f42b48d22f6efcde33d2ab", "filename": "playbooks/manage-users/add-users.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Import user data from {{ csv_doc_file_name }} and create users\"\n  hosts: identity-hosts\n  gather_facts: no\n  roles:\n    - user-management/populate-users\n    - user-management/manage-users\n    - user-management/manage-user-passwd\n\n- name: \"Notify users\"\n  import_playbook: ../notifications/email-notify-users.yml\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "c34ec67b1c88fe815ce437cbb2ba2ac5b42ca90b", "filename": "tasks/create_repo_gitlfs_hosted_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_gitlfs_hosted\n    args: \"{{ _nexus_repos_gitlfs_defaults|combine(item) }}\"\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "38eeeb75d3a75383f4495788d601b8d2a9ce3d8b", "filename": "tasks/checks/distribution-checks-Ubuntu.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Fail if unsupported Ubuntu version\n  fail:\n    msg: \"Ubuntu 14 or later is required!\"\n  when: _docker_os_dist == \"Ubuntu\" and\n        _docker_os_dist_major_version < '14'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "6c35c739af5cea9321ffc6741ec0fcd6c2985a1e", "filename": "roles/config-pxe/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: pxe-server\n  roles:\n  - config-pxe \n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "4bbad5ec755bdd3fd31d35a55cc14fcc2b4e4d79", "filename": "playbooks/bb4/templates/local-registry-setup-v2.j2", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "#!/bin/sh\n\nOSE_VERS={{ocp_version}}\nREG_VERS=2\nUPSTREAM=registry.access.redhat.com\nREGISTRY={{registry}}\n# https://bugzilla.redhat.com/show_bug.cgi?id=1481130\nUSE_SKOPEO=yes\nSKOPEO_DEST_VERIFY=false\n\n# Add/remove XXX to variable names to disable/enable syncing of the images\nose_images=\"\n  openshift3/ose-deployer\n  openshift3/ose-docker-builder\n  openshift3/ose-docker-registry\n  openshift3/ose-haproxy-router\n  openshift3/ose-pod\n  openshift3/ose-sti-builder\n\n  openshift3/registry-console\n\n  openshift3/logging-auth-proxy\n  openshift3/oauth-proxy\n  openshift3/logging-curator\n  openshift3/logging-elasticsearch\n  openshift3/logging-fluentd\n  openshift3/logging-kibana\n{% if '%0.2f'| format(ocp_version|float) == '3.10' %}\n  openshift3/metrics-cassandra\n  openshift3/metrics-hawkular-metrics\n  openshift3/metrics-heapster\n{% endif %}\n\n  openshift3/prometheus\n  openshift3/prometheus-alert-buffer\n  openshift3/prometheus-alertmanager\n  openshift3/prometheus-node-exporter\n\n  openshift3/ose-service-catalog\n  openshift3/ose-ansible-service-broker\n  openshift3/mediawiki-apb\n  openshift3/postgresql-apb\n\n  openshift3/registry-console\n\"\n\nose_images_cont=\"\n  rhel7/cockpit\n  rhel7/etcd\n  openshift3/ose\n  openshift3/node\n  openshift3/openvswitch\n\"\n\nXXXose_images_opt=\"\n  openshift3/ose-egress-router\n  openshift3/ose-keepalived-ipfailover\n\n  openshift3/image-inspector\n\"\n\nxpaas_images=\"\n  redhat-openjdk-18/openjdk18-openshift\n  jboss-webserver-3/webserver30-tomcat8-openshift\n  jboss-eap-7/eap70-openshift\n  redhat-sso-7/sso70-openshift\n  rhscl/postgresql-95-rhel7\n\"\n\ncns_images=\"\n  rhgs3/rhgs-server-rhel7\n  rhgs3/rhgs-volmanager-rhel7\n  rhgs3/rhgs-gluster-block-prov-rhel7\n  rhgs3/rhgs-s3-server-rhel7\n\"\n\njenkins_images=\"\n  openshift3/jenkins-2-rhel7\n  openshift3/jenkins-slave-base-rhel7\n  openshift3/jenkins-slave-maven-rhel7\n  openshift3/jenkins-slave-nodejs-rhel7\n\"\n\n# Configure Docker if needed\n[ \"$USE_SKOPEO\" != \"yes\" ] && (rpm -q docker > /dev/null 2>&1 || yum install -y docker)\nif [ \"$USE_SKOPEO\" != \"yes\" ] && ! grep -q \"add-registry $REGISTRY\" /etc/sysconfig/docker; then\n  systemctl stop docker\n  sed -i -e 's,--log-driver=,--log-level=warn --log-driver=,' /etc/sysconfig/docker\n  sed -i -e 's,--log-level=,--max-concurrent-downloads=10 --log-level=,' /etc/sysconfig/docker\n  sed -i -e 's,--log-level=,--max-concurrent-uploads=10 --log-level=,' /etc/sysconfig/docker\n  sed -i -e 's,^ADD_REGISTRY=,#ADD_REGISTRY=,' /etc/sysconfig/docker\n  sed -i -e 's,^BLOCKED_REGISTRY=,#BLOCKED_REGISTRY=,' /etc/sysconfig/docker\n  sed -i -e 's,^INSECURE_REGISTRY=,#INSECURE_REGISTRY=,' /etc/sysconfig/docker\n  cat <<EOF>> /etc/sysconfig/docker\nADD_REGISTRY='--add-registry $REGISTRY --add-registry $UPSTREAM'\nBLOCK_REGISTRY='--block-registry all'\nEOF\n  if [ $REG_VERS -eq 1 ]; then\n    echo INSECURE_REGISTRY=\\'--insecure-registry $REGISTRY\\' >> /etc/sysconfig/docker\n  fi\n  systemctl enable docker\nfi\n[ \"$USE_SKOPEO\" != \"yes\" ] && systemctl start docker\n\n# Pull/copy\nfor img in $ose_images $ose_images_cont $ose_images_opt $cns_images; do\n  avail=\"$(curl -s https://$UPSTREAM/v1/repositories/$img/tags | grep -Po '\"v?'${OSE_VERS/\\./\\\\.}'.*?\"' | tr -d '\"' | sort -V)\"\n  # rhel7/etcd has its own versioning\n  if [ \"$img\" = \"rhel7/etcd\" -o \"$img\" = \"rhgs3/rhgs-server-rhel7\" -o \"$img\" = \"rhgs3/rhgs-volmanager-rhel7\" -o \"$img\" = \"rhgs3/rhgs-gluster-block-prov-rhel7\" -o \"$img\" = \"rhgs3/rhgs-s3-server-rhel7\" ]; then\n    [ \"$USE_SKOPEO\" != \"yes\" ] && docker pull $UPSTREAM/$img\n    [ \"$USE_SKOPEO\"  = \"yes\" ] && echo Copying $img... && skopeo copy --dest-tls-verify=$SKOPEO_DEST_VERIFY --dest-cert-dir=/etc/docker-distribution/registry docker://$UPSTREAM/$img docker://$REGISTRY/$img\n  fi\n  [ -n \"$avail\" ] || continue\n  # Get latest images with and without v in the tag / patch level\n  tags=\"\"\n  tags=\"$tags $(printf %s\\\\n $avail | grep v${OSE_VERS}$)\"\n  tags=\"$tags $(printf %s\\\\n $avail | grep ^v | tail -n 1)\"\n  tags=\"$tags $(printf %s\\\\n $avail | grep -v ^v | tail -n 1)\"\n  tags=\"$tags $(printf %s\\\\n $avail | grep ^v | grep -v -- - | tail -n 1)\"\n  tags=\"$tags $(printf %s\\\\n $avail | grep -v ^v | grep -v -- - | tail -n 1)\"\n  tags=\"$(echo $tags | tr ' ' '\\n' | sort -u)\"\n  for tag in $tags; do\n    if [ \"$USE_SKOPEO\" != \"yes\" ]; then\n      docker pull $UPSTREAM/$img:$tag || exit 1\n    else\n      echo Copying $img:$tag...\n      skopeo copy --dest-tls-verify=$SKOPEO_DEST_VERIFY --dest-cert-dir=/etc/docker-distribution/registry docker://$UPSTREAM/$img:$tag docker://$REGISTRY/$img:$tag || exit 1\n    fi\n  done\ndone\n\nfor img in $xpaas_images $jenkins_images; do\n  # Latest only\n  if [ \"$USE_SKOPEO\" != \"yes\" ]; then\n    docker pull $UPSTREAM/$img || exit 2\n  else\n    echo Copying $img...\n    skopeo copy --dest-tls-verify=$SKOPEO_DEST_VERIFY --dest-cert-dir=/etc/docker-distribution/registry docker://$UPSTREAM/$img docker://$REGISTRY/$img || exit 2\n  fi\ndone\n\n# Push\nif [ \"$USE_SKOPEO\" != \"yes\" ]; then\n  images=\"$(docker images)\"\n  for img in $ose_images $ose_images_cont $ose_images_opt $xpaas_images $jenkins_images; do\n    for tag in $(printf %s\\\\n \"$images\" | awk '/'$UPSTREAM\\\\/${img/\\//\\\\/}' / {print $2}'); do\n      [ \"$tag\" = \"<none>\" ] && continue\n      docker tag $UPSTREAM/$img:$tag $REGISTRY/$img:$tag || exit 3\n      docker push $REGISTRY/$img:$tag || exit 4\n      docker rmi $REGISTRY/$img:$tag || exit 5\n    done\n  done\nfi\n\n# Garbage collect\n/usr/bin/registry garbage-collect /etc/docker-distribution/registry/config.yml\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "68e45f989ef842e6e52988cfeb339939d563a84b", "filename": "archive/roles/secure-registry/meta/main.yaml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n dependencies:\n   - { role: openshift_common }\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "7ca305eac11ada5d99000fb55aa1c0f9feec7057", "filename": "roles/2-common/README.rst", "repository": "iiab/iiab", "decoded_content": "=============\nCommon README\n=============\n\nThis role aggregates roles containing packages and a few other tasks that are common to all platforms\nand are required before creating a functioning server.\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "8a3b6a67a5e3ce966f20077a342a83fa07949b50", "filename": "roles/user-management/list-users-by-group/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Find users part of group and generate list of users\"\n  include_tasks: generate-list-of-users.yml\n  when:\n  - user_group.name == target_group\n  with_items:\n  - \"{{ user_groups }}\"\n  loop_control:\n    loop_var: user_group\n\n"}, {"commit_sha": "d7fbb1f61d1191166152acc249d0e910859619ca", "sha": "fdd5fdbabd232c84896f0363d9a310bdbc4a2c83", "filename": "tasks/remove-pre-docker-ce.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Determine Docker version\n  command: bash -c \"docker version | grep Version | awk '{print $2}'\"\n  ignore_errors: yes\n  changed_when: false\n  register: cmd_docker_version\n\n- name: Set fact if old Docker installation shall be removed\n  set_fact:\n    remove_old_docker: \"{{ docker_remove_pre_ce | bool }} == true and {{ cmd_docker_version.stdout_lines[0] | search('-ce') }} == false\"\n  when: cmd_docker_version.stdout_lines is defined and cmd_docker_version.stdout_lines[0] is defined\n\n- name: Check if Docker is running\n  become: true\n  command: systemctl status docker\n  ignore_errors: yes\n  changed_when: false\n  register: service_docker_status\n  when: remove_old_docker | default(false) | bool == true\n\n- name: Stop Docker service\n  service:\n    name: docker\n    state: stopped\n  when: \"service_docker_status.rc | default(1) == 0\"\n\n- name: Remove old Docker installation before Docker CE\n  become: true\n  package:\n    name: \"{{ item }}\"\n    state: absent\n  when: remove_old_docker|default(false) | bool == true\n  with_items:\n    - \"{{ docker_old_packages[_docker_os_dist] }}\"\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "1e505fc306dc4b9f411fa34652095eb3ab0fc6a1", "filename": "tasks/create_repo_rubygems_group_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_rubygems_group\n    args: \"{{ _nexus_repos_rubygems_defaults|combine(item) }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "292d6c5ba4f901b14cc526a52ddff7421456d39b", "filename": "roles/ansible/tower/manage-credentials/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- block: # when ansible_tower.credentials is defined\n\n  - name: \"Set default values\"\n    set_fact:\n      processed_credentials: []\n      existing_organizations_output: []\n      existing_credentials_output: []\n      existing_credential_types_output: []\n\n  # Utilize the `rest_get` library routine to ensure REST pagination is handled\n  - name: \"Get the existing organizations\"\n    rest_get:\n      host_url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}\"\n      rest_user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      rest_password: \"{{ ansible_tower.admin_password }}\"\n      api_uri: \"/api/v2/organizations/\"\n    register: existing_organizations_output\n\n  # Utilize the `rest_get` library routine to ensure REST pagination is handled\n  - name: \"Get the existing credentials\"\n    rest_get:\n      host_url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}\"\n      rest_user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      rest_password: \"{{ ansible_tower.admin_password }}\"\n      api_uri: \"/api/v2/credentials/\"\n    register: existing_credentials_output\n\n  # Utilize the `rest_get` library routine to ensure REST pagination is handled\n  - name: \"Get the existing credential types\"\n    rest_get:\n      host_url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}\"\n      rest_user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      rest_password: \"{{ ansible_tower.admin_password }}\"\n      api_uri: \"/api/v2/credential_types/\"\n    register: existing_credential_types_output\n\n  - name: \"Process the inventory credentials\"\n    include_tasks: process-credential.yml\n    with_items:\n    - \"{{ ansible_tower.credentials }}\"\n    loop_control:\n      loop_var: credential\n\n  - name: \"Elminate the credentials that should not be present\"\n    uri:\n      url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}/api/v2/credentials/{{ item.id }}/\"\n      user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      password: \"{{ ansible_tower.admin_password }}\"\n      force_basic_auth: yes\n      method: DELETE\n      validate_certs: no\n      status_code: 200,204\n    with_items:\n    - \"{{ existing_credentials_output.rest_output | get_remaining_items(processed_credentials, 'name', 'name')}}\"\n\n  when:\n  - ansible_tower.credentials is defined\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "5d50bf41be22f10d422e06f283c7a0e653135b33", "filename": "playbooks/roles/bb0-openstack/meta/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "galaxy_info:\n  author: your name\n  description: your description\n  company: your company (optional)\n\n  # If the issue tracker for your role is not on github, uncomment the\n  # next line and provide a value\n  # issue_tracker_url: http://example.com/issue/tracker\n\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (GPLv2, CC-BY, etc)\n\n  min_ansible_version: 2.4\n\n  # If this a Container Enabled role, provide the minimum Ansible Container version.\n  # min_ansible_container_version:\n\n  # Optionally specify the branch Galaxy will use when accessing the GitHub\n  # repo for this role. During role install, if no tags are available,\n  # Galaxy will use this branch. During import Galaxy will access files on\n  # this branch. If Travis integration is configured, only notifications for this\n  # branch will be accepted. Otherwise, in all cases, the repo's default branch\n  # (usually master) will be used.\n  #github_branch:\n\n  #\n  # Provide a list of supported platforms, and for each platform a list of versions.\n  # If you don't wish to enumerate all versions for a particular platform, use 'all'.\n  # To view available platforms and versions (or releases), visit:\n  # https://galaxy.ansible.com/api/v1/platforms/\n  #\n  # platforms:\n  # - name: Fedora\n  #   versions:\n  #   - all\n  #   - 25\n  # - name: SomePlatform\n  #   versions:\n  #   - all\n  #   - 1.0\n  #   - 7\n  #   - 99.99\n\n  galaxy_tags: []\n    # List tags for your role here, one per line. A tag is a keyword that describes\n    # and categorizes the role. Users find roles by searching for tags. Be sure to\n    # remove the '[]' above, if you add tags to this list.\n    #\n    # NOTE: A tag is limited to a single word comprised of alphanumeric characters.\n    #       Maximum 20 tags per role.\n\ndependencies: []\n  # List your role dependencies here, one per line. Be sure to remove the '[]' above,\n  # if you add dependencies to this list."}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "36b740b72a42c0d26a0fc8723cdda3c688f99952", "filename": "meta/main.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\ngalaxy_info:\n  role_name: \"java\"\n  author: \"Lean Delivery team <team@lean-delivery.com>\"\n  description: \"Lean Delivery Java install\"\n  company: \"Epam Systems\"\n  license: \"Apache\"\n  min_ansible_version: \"2.7\"\n  issue_tracker_url: \"https://github.com/lean-delivery/ansible-role-java/issues\"\n  platforms:\n    - name: \"Ubuntu\"\n      versions:\n        - \"xenial\"\n        - \"bionic\"\n    - name: \"Debian\"\n      versions:\n        - \"stretch\"\n    - name: \"EL\"\n      versions:\n        - \"6\"\n        - \"7\"\n        - \"8\"\n    - name: \"Amazon\"\n      versions:\n        - \"2017.12\"\n        - \"Candidate\"\n    - name: \"Windows\"\n      versions:\n        - \"2016\"\n        - \"2019\"\n\n  galaxy_tags:\n    - \"development\"\n    - \"system\"\n    - \"packaging\"\n    - \"java\"\n    - \"oracle\"\n    - \"jdk\"\n    - \"jre\"\n    - \"openjdk\"\n    - \"adoptopenjdk\"\n    - \"sapmachine\"\n    - \"zulu\"\n    - \"sapjvm\"\n    - \"windows\"\n\ndependencies: []\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "122f356655499f0041a012622c42284ea551d652", "filename": "roles/network/templates/named/named.rfc1912.zones", "repository": "iiab/iiab", "decoded_content": "// named.rfc1912.zones:\n//\n// Provided by Red Hat caching-nameserver package \n//\n// ISC BIND named zone configuration for zones recommended by\n// RFC 1912 section 4.1 : localhost TLDs and address zones\n// \n// See /usr/share/doc/bind*/sample/ for example named configuration files.\n//\nzone \"localdomain\" IN {\n\ttype master;\n\tfile \"localdomain.zone\";\n\tallow-update { none; };\n};\n\nzone \"localhost\" IN {\n\ttype master;\n\tfile \"localhost.zone\";\n\tallow-update { none; };\n};\n\nzone \"0.0.127.in-addr.arpa\" IN {\n\ttype master;\n\tfile \"named.local\";\n\tallow-update { none; };\n};\n\nzone \"0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.ip6.arpa\" IN {\n        type master;\n\tfile \"named.ip6.local\";\n\tallow-update { none; };\n};\n\nzone \"255.in-addr.arpa\" IN {\n\ttype master;\n\tfile \"named.broadcast\";\n\tallow-update { none; };\n};\n\nzone \"0.in-addr.arpa\" IN {\n\ttype master;\n\tfile \"named.zero\";\n\tallow-update { none; };\n};\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a42fb3ddc5939231a417815303c87c5a58d0c3b8", "filename": "roles/user-management/manage-atlassian-users/tasks/add_user_to_groups.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Add user to groups\n  uri:\n    url: \"{{ atlassian.url }}/rest/api/2/group/user?groupname={{ item | urlencode }}\"\n    method: POST\n    user: '{{ atlassian.username }}'\n    password: '{{ atlassian.password }}'\n    force_basic_auth: yes\n    status_code: [201, 400]\n    body_format: json\n    body: \"{ 'name': '{{ atlassian_user.email.split(\\\"@\\\") | first }}' }\"\n    return_content: yes\n  with_items: '{{ atlassian_user.groups }}'\n  when: atlassian_user.groups|length > 0\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "b46c33e48b4bf1480d66d65ed5a009702a5c6eee", "filename": "roles/dns/test/inventory/group_vars/all.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ndns_records_rm:\n- view: private\n  zone: first.example.com\n  server: \"192.168.48.26\"\n  key_name: \"private-first.example.com\"\n  key_secret: \"EhZfRtlHgy7xTIi2LeVSGsBj99Sb8IGB6K30ovg13dE=\"\n  key_algorithm: \"hmac-sha256\"\n  entries:\n  - type: A\n    hostname: master\n    ip: 172.16.10.19\ndns_records_add:\n- view: private\n  zone: first.example.com\n  server: \"192.168.48.26\"\n  key_name: \"private-first.example.com\"\n  key_secret: \"EhZfRtlHgy7xTIi2LeVSGsBj99Sb8IGB6K30ovg13dE=\"\n  key_algorithm: \"hmac-sha256\"\n  entries:\n  - type: A\n    hostname: master\n    ip: 172.16.10.20\n  - type: A\n    hostname: node1\n    ip: 172.16.10.20\n  - type: A\n    hostname: node2\n    ip: 172.16.10.21\n  - type: A\n    hostname: node3\n    ip: 172.16.10.22\n- view: private\n  zone: second.example.com\n  server: \"192.168.48.26\"\n  key_name: \"private-second.example.com\"\n  key_secret: \"+UYdpSzdQyZ20V9/2Ud9RjHFz9Pouqn4aXP3V9X/gq4=\"\n  key_algorithm: \"hmac-sha256\"\n  entries:\n  - type: A\n    hostname: master\n    ip: 172.17.10.20\n  - type: A\n    hostname: node1\n    ip: 172.17.10.20\n  - type: A \n    hostname: node2\n    ip: 172.17.10.21\n- view: public\n  zone: first.example.com\n  server: \"192.168.48.26\"\n  key_name: \"public-first.example.com\"\n  key_secret: \"5RZv5wMtKS/fZtjtc2bXS2s6L5+cXN2x53jSkEtwNjk=\"\n  key_algorithm: \"hmac-sha256\"\n  entries:\n  - type: A \n    hostname: master\n    ip: 10.9.77.20\n  - type: A \n    hostname: node1\n    ip: 10.9.77.20\n  - type: A\n    hostname: node2\n    ip: 10.9.77.21\n  - type: A\n    hostname: node3\n    ip: 10.9.77.22\n- view: public\n  zone: second.example.com\n  server: \"192.168.48.26\"\n  key_name: \"public-second.example.com\"\n  key_secret: \"7VKvn5iZ64l+s42XT/hllJSxS6CjE3369tOy85vkBk4=\"\n  key_algorithm: \"hmac-sha256\"\n  entries:\n  - type: A\n    hostname: master\n    ip: 10.8.88.20\n  - type: A\n    hostname: node1\n    ip: 10.8.88.20\n  - type: A\n    hostname: node2\n    ip: 10.8.88.21\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "eda7d133fcbc791fb9664af112fbd73206f1fed7", "filename": "tasks/setup_user_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: setup_user\n    args: \"{{ item }}\""}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "55c9335734299dea93c2833215648a958e1f5fa4", "filename": "tasks/create_repo_nuget_group_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_nuget_group\n    args: \"{{ _nexus_repos_nuget_defaults|combine(item) }}\"\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "100c2d82d5a351ff02f16a0880bc5f40d741e7d7", "filename": "roles/ansible/tower/manage-inventories/tasks/process-group.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Load up the inventory (group)\"\n  uri:\n    url: https://localhost/api/v2/groups/\n    method: POST\n    body: \"{{ lookup('template', 'group.j2') }}\"\n    body_format: 'json'\n    headers:\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n    user: admin\n    password: \"{{ tower_admin_password }}\"\n    validate_certs: no\n    status_code: 200,201,400\n\n# Utilize the `rest_get` library routine to ensure REST pagination is handled\n- name: \"Get the updated list of existing groups\"\n  rest_get:\n    host_url: \"{{ tower_url }}\"\n    api_uri: \"/api/v2/groups/\"\n    rest_user: \"{{ tower_admin_username }}\"\n    rest_password: \"{{ tower_admin_password }}\"\n  register: existing_groups_output\n\n- name: \"Get the group id based on the group name\"\n  set_fact:\n    group_id: \"{{ item.id }}\"\n  when:\n  - item.name|trim == group.name|trim\n  with_items:\n  - \"{{ existing_groups_output.rest_output }}\"\n\n- name: \"Process the inventory group members\"\n  include_tasks: process-group-member.yml\n  with_items:\n  - \"{{ group.hosts }}\"\n  loop_control:\n    loop_var: group_member\n\n- name: \"Clear/Update facts\"\n  set_fact:\n    group_id: ''\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "ea1d2fd5c45571fb95974a1fc0ff98d854ffe32c", "filename": "roles/kalite/tasks/install.yml", "repository": "iiab/iiab", "decoded_content": "# This is for an OS other than Fedora 18\n\n- name: Install missing packages required for kalite startup\n  package: name={{ item }}\n           state=present\n  with_items:\n    - python-virtualenv\n\n- name: Grab the requirements file\n  get_url: url={{ kalite_requirements }} dest={{ pip_packages_dir }}/kalite.txt\n  when: internet_available\n\n- name: Install ka-lite dependencies with pip\n  pip: requirements={{ pip_packages_dir }}/kalite.txt\n       virtualenv={{ kalite_venv }}\n       virtualenv_site_packages=no\n       extra_args=\"--no-cache-dir\"\n#       extra_args=\"--no-cache-dir\"\n#       extra_args=\"--disable-pip-version-check\"\n  when: internet_available and is_debuntu\n\n- name: Install ka-lite with pip\n  pip: name=ka-lite-static\n       version={{ kalite_version }}\n       virtualenv={{ kalite_venv }}\n       virtualenv_site_packages=no\n       extra_args=\"--no-cache-dir\"\n#       extra_args=\"--no-cache-dir\"\n#       extra_args=\"--disable-pip-version-check\"\n  when: internet_available and is_debuntu\n\n- name: Install ka-lite dependencies with pip\n  pip: requirements={{ pip_packages_dir }}/kalite.txt\n       virtualenv={{ kalite_venv }}\n       virtualenv_site_packages=no\n#       extra_args=\"--no-cache-dir\"\n#       extra_args=\"--disable-pip-version-check\"\n  when: internet_available and not is_debuntu\n\n- name: Install ka-lite with pip\n  pip: name=ka-lite-static\n       version={{ kalite_version }}\n       virtualenv={{ kalite_venv }}\n       virtualenv_site_packages=no\n#       extra_args=\"--no-cache-dir\"\n#       extra_args=\"--disable-pip-version-check\"\n  when: internet_available and not is_debuntu\n\n- name: Default is to have cronserve started with kalite\n  set_fact:\n     job_scheduler_stanza: \"\"\n\n- name: Add --skip-job-scheduler to start if cronserve not enabled\n  set_fact:\n     job_scheduler_stanza: \"--skip-job-scheduler \"\n  when: not kalite_cron_enabled\n\n- name: Create kalite service(s) and support scripts\n  template: backup=no\n            src={{ item.src }}\n            dest={{ item.dest }}\n            owner=root\n            group=root\n            mode={{ item.mode }}\n  with_items:\n    - { src: 'kalite-serve.service.j2', dest: '/etc/systemd/system/kalite-serve.service', mode: '0644'}\n    - { src: 'kalite.sh.j2', dest: '/etc/profile.d/kalite.sh', mode: '0644'}\n    - { src: 'kalite.conf', dest: '/etc/{{ apache_config_dir }}', mode: '0644'}\n\n- name: Create symlink to kalite bin file in path\n  file: path=/usr/bin/kalite\n        src={{ kalite_venv }}/bin/kalite\n        state=link\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "8adf5d58307caf1e5fdfc31a2418d43ab6f91947", "filename": "playbooks/provision-dns-server/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_playbook: ../prep.yml\n  tags:\n  - 'never'\n  - 'install'\n\n- import_playbook: ../osp/manage-user-network.yml\n  when:\n  - hosting_infrastructure == 'openstack'\n  tags:\n  - 'never'\n  - 'install'\n\n- import_playbook: ../osp/provision-osp-instance.yml\n  when:\n  - hosting_infrastructure == 'openstack'\n  tags:\n  - 'never'\n  - 'install'\n\n- import_playbook: ../rhsm.yml\n  tags:\n  - 'never'\n  - 'install'\n\n- hosts: dns-server\n  roles:\n  - role: update-host\n  tags:\n  - 'never'\n  - 'install'\n\n- import_playbook: configure-dns-server.yml\n  tags:\n  - 'always'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "4d5bc0fe549946f072d4a4f94f2eaf5e41d063d4", "filename": "roles/config-vlans/tests/inventory/group_vars/infra_hosts.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nvlans:\n- device: tenant.vlan11\n  physdev: eth0\n  vlan_id: 11\n- device: tenant.vlan12\n  physdev: eth0\n  vlan_id: 12\n- device: tenant.vlan13\n  physdev: eth0\n  vlan_id: 13\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "1fd6100a916740175d4ba6ef31a93f4cae2942cc", "filename": "roles/user-management/manage-atlassian-users/tasks/create_atlassian_users.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Create User\n  uri:\n    url: '{{ atlassian.url }}/rest/api/2/user'\n    method: POST\n    user: '{{ atlassian.username }}'\n    password: '{{ atlassian.password }}'\n    force_basic_auth: yes\n    status_code: 201\n    body_format: json\n    body:\n      name: \"{ atlassian_user.email.split(\\\"@\\\") | first }}\"\n      emailAddress: \"{{ atlassian_user.email }}\"\n      displayName: \"{{ atlassian_user.firstname }} {{ atlassian_user.lastname }}\"\n      notification: true\n    return_content: yes\n  register: user_data\n  when: \n    - atlassian_user.state|default('present') == 'present'"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "eff0aac9b1c721a1ff0a2a9eeaf6c204978e87ad", "filename": "tasks/delete_repo_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: delete_repo\n    args:\n      name: \"{{ item }}\"\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "3f14dc1576ebd935ac9e8ac56a15e069ba4ea700", "filename": "roles/consul/vars/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# vars file for consul\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "61abe61a5c6e074bf329ed12d4336f7c82f40cff", "filename": "roles/cups/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "# administer this service by browsing to localhost:631\n- name: get the CUPS package installed\n  package: name={{ item }}\n           state=present\n  with_items:\n    - cups\n  when: cups_install\n  tags:\n    - download\n\n- name: Put our own config file in place, to permit local lan admin\n  template: dest=/etc/cups/cupsd.conf\n            src=cupsd.conf\n\n- name: Put an apache2 config file in place\n  template: dest=/etc/{{ apache_config_dir }}/\n            src=cups.conf\n\n- name: Create the link for sites-enabled\n  file: src=/etc/apache2/sites-available/cups.conf\n        dest=/etc/apache2/sites-enabled/cups.conf\n        state=link\n  when: cups_enabled and is_debuntu\n\n- name: Enable services for cups\n  service: name={{ item }}\n           state=started\n           enabled=yes\n  with_items:\n    - cups\n    - cups-browsed\n  when: cups_enabled and not is_F18\n\n- name: Enable services for cups for xo's\n  service: name=cups\n           state=started\n           enabled=yes\n  when: cups_enabled and is_F18\n\n- name: Permit headless admin of CUPS -- only works when cups daemon is running\n  shell: \"cupsctl --remote-admin\"\n  when: cups_enabled\n\n- name: Disable services for cups\n  service: name={{ item }}\n          state=stopped\n          enabled=no\n  with_items:\n    - cups\n    - cups-browsed\n  when: not cups_enabled and not is_F18\n\n- name: Disable services for cups for xo's\n  service: name=cups\n           state=stopped\n           enabled=no\n  when: not cups_enabled and is_F18\n\n- name: add cups to service list\n  ini_file: dest={{ service_filelist }}\n            section=cups\n            option={{ item.option }}\n            value={{ item.value }}\n  with_items:\n    - option: name\n      value: '\"Common UNIX Printing System (CUPS)\"'\n    - option: description\n      value: '\"CUPS  is a modular printing system  which allows a computer to act as a print server. A computer running CUPS is a host that can accept print jobs from client computers, process them, and send them to the appropriate printer.\"'\n    - option: installed\n      value: \"{{ cups_install }}\"\n    - option: enabled\n      value: \"{{ cups_enabled }}\"\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "8f427cd221c0cfacbff14db93927fea12cc1ed3e", "filename": "playbooks/openshift-management.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n- hosts: openshift\n  roles:\n    - openshift-management\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "aed7576318b2a6e8e76e0fe6c7a729602c147dc4", "filename": "roles/security/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: Install tools\n  apt: name=\"{{ item }}\" state=latest\n  with_items:\n    - unattended-upgrades\n\n- name: Configure unattended-upgrades\n  template: src=50unattended-upgrades.j2 dest=/etc/apt/apt.conf.d/50unattended-upgrades owner=root group=root mode=0644\n\n- name: Periodic upgrades configured\n  template: src=10periodic.j2 dest=/etc/apt/apt.conf.d/10periodic owner=root group=root mode=0644\n\n- name: Find directories for minimizing access\n  stat:\n    path: \"{{ item }}\"\n  register: minimize_access_directories\n  with_items:\n    - '/usr/local/sbin'\n    - '/usr/local/bin'\n    - '/usr/sbin'\n    - '/usr/bin'\n    - '/sbin'\n    - '/bin'\n\n- name: Minimize access\n  file: path='{{ item.stat.path }}' mode='go-w' recurse=yes\n  when: item.stat.isdir\n  with_items: \"{{ minimize_access_directories.results }}\"\n  no_log: True\n\n- name: Change shadow ownership to root and mode to 0600\n  file: dest='/etc/shadow' owner=root group=root mode=0600\n\n- name: change su-binary to only be accessible to user and group root\n  file: dest='/bin/su' owner=root group=root mode=0750\n\n- name: Collect Use of privileged commands\n  shell: >\n    /usr/bin/find {/usr/local/sbin,/usr/local/bin,/sbin,/bin,/usr/sbin,/usr/bin} -xdev \\( -perm -4000 -o -perm -2000 \\) -type f | awk '{print \"-a always,exit -F path=\" $1 \" -F perm=x -F auid>=500 -F auid!=4294967295 -k privileged\" }'\n  args:\n    executable: /bin/bash\n  register: privileged_programs\n\n# Core dumps\n\n- name: Restrict core dumps (with PAM)\n  lineinfile: dest=/etc/security/limits.conf line=\"* hard core 0\" state=present\n\n- name: Restrict core dumps (with sysctl)\n  sysctl: name=fs.suid_dumpable value=0 ignoreerrors=yes sysctl_set=yes reload=yes state=present\n\n# Kernel fixes\n\n- name: Disable Source Routed Packet Acceptance\n  sysctl: name=\"{{item}}\" value=0 ignoreerrors=yes sysctl_set=yes reload=yes state=present\n  with_items:\n    - net.ipv4.conf.all.accept_source_route\n    - net.ipv4.conf.default.accept_source_route\n  notify:\n    - flush routing cache\n\n- name: Disable ICMP Redirect Acceptance\n  sysctl: name=\"{{item}}\" value=0 ignoreerrors=yes sysctl_set=yes reload=yes state=present\n  with_items:\n    - net.ipv4.conf.all.accept_redirects\n    - net.ipv4.conf.default.accept_redirects\n\n- name: Disable Secure ICMP Redirect Acceptance\n  sysctl: name=\"{{item}}\" value=0 ignoreerrors=yes sysctl_set=yes reload=yes state=present\n  with_items:\n    - net.ipv4.conf.all.secure_redirects\n    - net.ipv4.conf.default.secure_redirects\n  notify:\n    - flush routing cache\n\n- name: Enable Bad Error Message Protection\n  sysctl: name=net.ipv4.icmp_ignore_bogus_error_responses value=1 ignoreerrors=yes sysctl_set=yes reload=yes state=present\n  notify:\n    - flush routing cache\n\n- name: Enable RFC-recommended Source Route Validation\n  sysctl: name=\"{{item}}\" value=1 ignoreerrors=yes sysctl_set=yes reload=yes state=present\n  with_items:\n    - net.ipv4.conf.all.rp_filter\n    - net.ipv4.conf.default.rp_filter\n  notify:\n    - flush routing cache\n\n- name: Do not send ICMP redirects (we are not a router)\n  sysctl: name=net.ipv4.conf.all.send_redirects value=0\n\n- name: SSH config\n  template: src=sshd_config.j2 dest=/etc/ssh/sshd_config owner=root group=root mode=0644\n  notify:\n    - restart ssh\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "f4c1787b63ea4b57d0e9b6165b38a08f82d29171", "filename": "playbooks/manage-users/manage-atlassian-users.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Create Atlassian Users\n  hosts: localhost\n  tasks:    \n    - import_role:\n        name: user-management/manage-atlassian-users\n    when:\n     - atlassian is defined\n     - atlassian.user is defined\n  no_log: true\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "257aa8bdda8085d984ac4b40590a691d8b72f311", "filename": "roles/ansible/tower/manage-inventories/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Set default values\"\n  set_fact:\n    processed_inventories: []\n    existing_organizations_output: []\n\n# Utilize the `rest_get` library routine to ensure REST pagination is handled\n- name: \"Get the existing organizations\"\n  rest_get:\n    host_url: \"{{ tower_url }}\"\n    api_uri: \"/api/v2/organizations/\"\n    rest_user: \"{{ tower_admin_username }}\"\n    rest_password: \"{{ tower_admin_password }}\"\n  register: existing_organizations_output\n\n- name: \"Process the inventory entries\"\n  include_tasks: process-inventory.yml\n  with_items:\n  - \"{{ ansible_tower_inventories }}\"\n  loop_control:\n    loop_var: inventory\n\n- name: \"Elminate the inventories that should not be present\"\n  uri:\n    url: https://localhost/api/v2/inventories/{{ item.id }}/\n    method: DELETE\n    user: admin\n    password: \"{{ tower_admin_password }}\"\n    validate_certs: no\n    status_code: 200,202,204\n  with_items:\n  - \"{{ existing_inventories_output.rest_output | get_remaining_items(processed_inventories, 'name', 'name')}}\"\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "5a5a190af8073fa9acadf7f81cb055493e544d80", "filename": "roles/docker/handlers/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# handlers file for docker\n- name: restart docker\n  service:\n   name: docker\n   state: restarted\n  sudo: yes\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "a592b98c11cfb8e935dae812e3c76f8a1cc869bc", "filename": "roles/deploy/defaults/main.yml", "repository": "roots/trellis", "decoded_content": "# If you use the \"git\" strategy:\n# - you must set a repository (no default)\nproject_git_repo: \"{{ project.repo }}\"\n# - you can set the git ref to deploy (can be a branch, tag or commit hash)\nproject_version: \"{{ project.branch | default('master') }}\"\n\n# The source_path is used to fetch the tags from git, or synchronise via rsync. This way\n# you do not have to download/sync the entire project on every deploy\nproject_source_path: \"{{ project_root }}/shared/source\"\n\n# There are certain folders you'll want to copy from release to release to speed up deploys.\n# Examples: Composer's `vendor` folder, npm's `node_modules`.\n# These should not be part of project_shared_children since dependencies need to be atomic and tied to a deploy.\nproject_copy_folders:\n  - vendor\n\n# All the templates to process on the remote system on deploy. These could contain config files.\n# `src` and `dest` paths work the same as project_local_files.\nproject_templates:\n  - name: .env config\n    src: roles/deploy/templates/env.j2\n    dest: .env\n\n# The shared_children is a list of all files/folders in your project that need to be linked to a path in \"/shared\".\n# For example a sessions directory or an uploads folder. They are created if they don't exist, with the type\n# specified in the `type` key (file or directory).\n# Example:\n# project_shared_children:\n#   - path: \"app/sessions\"\n#     src: \"sessions\"\n#     mode: \"0755\"\n#     type: \"file\" / \"directory\"  // <- optional, defaults to \"directory\"\nproject_shared_children:\n  - path: web/app/uploads\n    src: uploads\n\n# The project_environment is a list of environment variables that can be used in hooks\n# Example:\n# project_environment:\n#   WP_ENV: \"production\"\nproject_environment:\n  WP_ENV: \"{{ env }}\"\n\n# The project_current_path is the symlink used for the latest or active deployment\n# - default is 'current'\nproject_current_path: \"{{ project.current_path | default('current') }}\"\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "dccd25969aa58c2d00194da85f720514422807a4", "filename": "roles/notifications/send-email/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Create the 'To:' list of addresses\"\n  set_fact:\n    mail:\n      to: \"{{ list_of_mail_to | join(', ') }}, {{ mail.to | default('') }}\"\n  when:\n    - list_of_mail_to is defined\n\n- name: \"Create the 'CC:' list of addresses\"\n  set_fact:\n    mail:\n      cc: \"{{ list_of_mail_cc | join(', ') }}, {{ mail.cc | default('') }}\"\n  when:\n    - list_of_mail_cc is defined\n\n- name: \"Create the 'BCC:' list of addresses\"\n  set_fact:\n    mail:\n      bcc: \"{{ list_of_mail_bcc | join(', ') }}, {{ mail.bcc | default('') }}\"\n  when:\n    - list_of_mail_bcc is defined\n\n- name: \"Send out e-mail content to users\"\n  mail:\n    subject: \"{{ mail.subject }}\"\n    body: \"{{ mail.body | default(omit) }}\"\n    host: \"{{ mail.host | default(omit) }}\"\n    port: \"{{ mail.port | default (omit) }}\"\n    username: \"{{ mail.username | default(omit) }}\"\n    password: \"{{ mail.password | default(omit) }}\"\n    to: \"{{ mail.to | default(omit) }}\"\n    cc: \"{{ mail.cc | default(omit) }}\"\n    bcc: \"{{ mail.bcc | default(omit) }}\"\n    from: \"{{ mail.from | default(omit)}}\"\n    headers: \"{{ mail.header | default(omit)}}\"\n    secure: \"{{ mail.secure | default(omit) }}\"\n    subtype: \"{{ mail.subtype | default(omit) }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "61bcc7684474b03422f9ef84169e0dce53d349bb", "filename": "roles/idm-host-cert/tasks/register-host.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Register host\"\n  uri: \n    url: \"https://{{ idm_fqdn }}/ipa/session/json\"\n    method: POST\n    body: '{\"method\":\"host_add\",\"params\":[[\"{{ host_name }}\"],{\"force\": {{ host_force_add }}, \"description\": \"{{ host_description }}\", \"version\": \"{{ api_version }}\" }],\"id\":0}'\n    body_format: json\n    validate_certs: no\n    headers:\n      Cookie: \"{{ idm_session.set_cookie }}\"\n      referer: \"https://{{ idm_fqdn }}/ipa\"\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n  register: reg_host\n\n- name: \"Error out if the request returned an error\"\n  fail:\n    msg: \"ERROR: request failed with message: {{ reg_host.json.error.message }}\"\n  when:\n  - reg_host.json.error is defined\n  - reg_host.json.error.message is defined\n  - reg_host.json.error.name != \"DuplicateEntry\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "f0f3578bcf1fd6f002cb1c1f411fbdac8e987658", "filename": "roles/config-quay-builder/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# Base Configurations\nquay_builder_name: quay-builder\nquay_builder_service: \"{{ quay_builder_name }}.service\"\n\n#Systemd\nsystemd_service_dir: /usr/lib/systemd/system\nsystemd_environmentfile_dir: /etc/sysconfig\n\n# Quay Builder\nquay_builder_image: quay.io/coreos/quay-builder:v2.9.3\nquay_builder_config_dir: /var/lib/quay-builder/config\nquay_builder_ssl_trust_configure: False\nquay_builder_ssl_trust_src_file: /tmp/quay-builder-ssl-trust.crt\nquay_builder_ssl_trust_host_file: \"{{ quay_builder_config_dir }}/ca.crt\"\nquay_builder_ssl_trust_container_file: /usr/local/share/ca-certificates/rootCA.pem\n\n# Container Credentials\ncontainer_credentials_file: /root/.docker/config.json\ncontainer_credentials_file_content: {}\nquay_registry_server: quay.io\nquay_registry_auth:\nquay_registry_email:\n\n# Quay\nquay_enterprise_hostname: \"\""}, {"commit_sha": "f958689395b3fc98cacf0c605ed7b8b4b19718da", "sha": "510833bba0849e99d035a8cbdb01b1c0ddac5a88", "filename": "meta/main.yml", "repository": "lae/ansible-role-netbox", "decoded_content": "galaxy_info:\n  author: Musee Ullah\n  description: Installs and configures NetBox, a DCIM suite, in a production setting.\n  license: MIT\n  min_ansible_version: 2.1\n  platforms:\n    - name: Ubuntu\n      versions:\n        - xenial\n        - yakkety\n        - zesty\n        - artful\n    - name: Debian\n      versions:\n        - stretch\n        - jessie\n        - sid\n    - name: EL\n      versions:\n        - 7\n  galaxy_tags:\n    - dcim\n    - ipam\n    - inventory-management\n    - web\ndependencies: []\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "f29f2c0f2cd49d20bf5264d6bdfedca20b5a0a2c", "filename": "roles/schooltool/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "# the defaults on this image are user:manager, password:schooltool\n- name: Get the schooltool container if it is missing\n  docker: image=ghunt/schooltool:latest\n          ports=7080:7080\n          state=present\n          pull=missing\n  when: schooltool_install and docker_install and internet_available \n\n\n- name: Configure schooltool to run in docker container under systemd\n  template: backup=yes\n            src={{ item.src }}\n            dest={{ item.dest }}\n            owner=root\n            group=root\n            mode={{ item.mode }}\n  with_items:\n    -  dest: '/etc/systemd/system/schooltool.service'\n       src: 'schooltool.service'\n       mode: '0644'\n    -  dest: '/etc/{{ apache_config_dir }}/schooltool.conf'\n       src:  'schooltool.conf'\n       mode: '0644'\n\n# create a schooltool user who can have limited capability\n- name: Make a user for schooltool\n  user: name=schooltool\n        shell=/sbin/nologin\n        createhome=no\n\n# create the permanent storage directory, and give world write access\n# -- will eventually change the docker container to give itself write access and demote itself\n- name: create Permanent Storage for persistent schooltool data\n  file: path=/var/lib/schooltool\n        state=directory\n        owner=schooltool\n        mode=0777\n\n#Experience teaches that enabling schooltool is more likely to succeed after docker restart\n- name: Restart docker\n  service: name=docker\n           state=restarted\n           enabled=yes\n  when: schooltool_enabled\n\n- name: Enable schooltool\n  service: name=schooltool\n           state=started\n           enabled=yes\n  when: schooltool_enabled\n\n- name: Disable schooltool\n  service: name=schooltool\n           state=stopped\n           enabled=no\n  when: not schooltool_enabled\n\n- name: add schooltool to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=schooltool\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: Schooltool\n    - option: description\n      value: '\"SchoolTool is an open source, web based student information system designed for schools in the developing world, with strong support for translation, localization and automated deployment and updates.\"'\n    - option: enabled\n      value: \"{{ schooltool_enabled }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "ac6ca1be8d1094c2dc6095993397571be7169c4d", "filename": "roles/nfs-server/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Reload NFS\"\n  command: exportfs -a\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "da134fc75b6535abc3aedb8d496b6fc1cb5d4ecd", "filename": "roles/osp/packstack-post/tasks/keystone.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Configure the keystone parameters to allow for multiple domains\"\n  ini_file:\n    path: \"/etc/keystone/keystone.conf\"\n    section: \"identity\"\n    option: \"{{ item.key }}\"\n    value: \"{{ item.value }}\"\n  with_items:\n  - { key: 'domain_specific_drivers_enabled', value: 'true' }\n  - { key: 'domain_config_dir', value: '/etc/keystone/domains' }\n  notify: 'restart keystone'\n\n- name: \"Configure the openstack-dashboard parameters to allow for multiple domains\"\n  lineinfile:\n    path: \"/etc/openstack-dashboard/local_settings\"\n    regexp: '^{{ item.key }} ='\n    line: '{{ item.key }} = {{ item.value }}'\n  with_items:\n  - { key: 'OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT', value: 'True' }\n  - { key: 'OPENSTACK_KEYSTONE_DEFAULT_DOMAIN', value: '\"default\"' }\n  notify: 'restart keystone'\n\n- name: \"Ensure target domain directory exists\"\n  file:\n    path: \"/etc/keystone/domains/\"\n    state: directory\n\n- name: \"Set SELinux boolean\"\n  seboolean:\n    name: authlogin_nsswitch_use_ldap\n    state: yes\n    persistent: yes\n\n- name: \"Setup LDAP domain configuration\"\n  template:\n    src: keystone_ldap.j2\n    dest: \"/etc/keystone/domains/keystone.{{ item.domain }}.conf\"\n  notify: 'restart keystone'\n  with_items:\n  - \"{{ keystone_ldap }}\"\n\n- name: \"Create temporary file for keystone rc variables\"\n  tempfile:\n    state: file\n    prefix: keystonerc\n  register: keystonerc_file\n  notify:\n  - \"remove temporary keystone rc file\"\n\n- name: \"Source the admin keystonerc file\"\n  shell: \"source {{ admin_keystonerc_file }}; env | grep '^OS_' > {{ keystonerc_file.path }}\"\n\n- name: \"Retrive the sourced rc content file\"\n  fetch:\n    src: \"{{ keystonerc_file.path }}\"\n    dest: \"{{ keystonerc_file.path }}\"\n    flat: yes\n  notify:\n  - \"remove local temporary keystone rc file\"\n\n- name: \"Ensure target directory for 'clouds.cfg' exists\"\n  file:\n    path: \"{{ clouds_yaml_file | dirname }}\"\n    state: directory\n\n- name: \"Configure the 'clouds.cfg' file for admin\"\n  template:\n    src: clouds_yaml.j2\n    dest: \"{{ clouds_yaml_file }}\"\n\n- name: \"Restart keystone (httpd) to apply config\"\n  service:\n    name: httpd\n    state: restarted\n\n- name: \"Wait a bit for keystone to catch up\"\n  pause:\n    seconds: 10\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "2ee6f9fa7515d7b97d6d6c3a887726d0c2cef140", "filename": "playbooks/roles/check_connectivity/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- name: cURL proxy whitelisted sites\n  shell: \"curl -s http://{{item}} -o /dev/null\"\n  with_items: \"{{proxy_whitelist}}\"\n  register: connectivity\n  changed_when: false\n- name: Check download speed\n  shell: \"curl -s https://raw.githubusercontent.com/sivel/speedtest-cli/master/speedtest.py | python - | grep Download | awk '{print $2}'\"\n  register: bandwidth\n  changed_when: false\n- set_fact:\n    download_speed: \"{{bandwidth.stdout}}\"\n- debug:\n    msg: \"Download speed is {{download_speed}}\"\n  failed_when: \"(download_speed | int) < bandwidth_limit\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "e66b3055c3fd988e6ca9f40758d2d97df0a1d91d", "filename": "roles/monit/templates/monitrc", "repository": "iiab/iiab", "decoded_content": "###############################################################################\n## Monit control file\n###############################################################################\n##\n## Comments begin with a '#' and extend through the end of the line. Keywords\n## are case insensitive. All path's MUST BE FULLY QUALIFIED, starting with '/'.\n##\n## Below you will find examples of some frequently used statements. For \n## information about the control file and a complete list of statements and \n## options, please have a look in the Monit manual.\n##\n##\n###############################################################################\n## Global section\n###############################################################################\n##\n## Start Monit in the background (run as a daemon):\n#\nset daemon  300              # check services at 5-minute intervals\n   with start delay 240    # optional: delay the first check by 4-minutes (by \n#                           # default Monit check immediately after Monit start)\n#\n#\n## Set syslog logging with the 'daemon' facility. If the FACILITY option is\n## omitted, Monit will use 'user' facility by default. If you want to log to \n## a standalone log file instead, specify the full path to the log file\n#\n# set logfile syslog facility log_daemon                       \n#\n#\n## Set the location of the Monit id file which stores the unique id for the\n## Monit instance. The id is generated and stored on first Monit start. By \n## default the file is placed in $HOME/.monit.id.\n#\n# set idfile /var/.monit.id\n#\n## Set the location of the Monit state file which saves monitoring states\n## on each cycle. By default the file is placed in $HOME/.monit.state. If\n## the state file is stored on a persistent filesystem, Monit will recover\n## the monitoring state across reboots. If it is on temporary filesystem, the\n## state will be lost on reboot which may be convenient in some situations.\n#\n# set statefile /var/.monit.state\n#\n## Set the list of mail servers for alert delivery. Multiple servers may be \n## specified using a comma separator. If the first mail server fails, Monit \n# will use the second mail server in the list and so on. By default Monit uses \n# port 25 - it is possible to override this with the PORT option.\n#\n# set mailserver mail.bar.baz,               # primary mailserver\n#                backup.bar.baz port 10025,  # backup mailserver on port 10025\n#                localhost                   # fallback relay\n#\n#\n## By default Monit will drop alert events if no mail servers are available. \n## If you want to keep the alerts for later delivery retry, you can use the \n## EVENTQUEUE statement. The base directory where undelivered alerts will be \n## stored is specified by the BASEDIR option. You can limit the maximal queue\n## size using the SLOTS option (if omitted, the queue is limited by space \n## available in the back end filesystem).\n#\n# set eventqueue\n#     basedir /var/monit  # set the base directory where events will be stored\n#     slots 100           # optionally limit the queue size\n#\n#\n## Send status and events to M/Monit (for more informations about M/Monit \n## see http://mmonit.com/). By default Monit registers credentials with \n## M/Monit so M/Monit can smoothly communicate back to Monit and you don't\n## have to register Monit credentials manually in M/Monit. It is possible to\n## disable credential registration using the commented out option below. \n## Though, if safety is a concern we recommend instead using https when\n## communicating with M/Monit and send credentials encrypted.\n#\n# set mmonit http://monit:monit@192.168.1.10:8080/collector\n#     # and register without credentials     # Don't register credentials\n#\n#\n## Monit by default uses the following alert mail format:\n##\n## --8<--\n## From: monit@$HOST                         # sender\n## Subject: monit alert --  $EVENT $SERVICE  # subject\n##\n## $EVENT Service $SERVICE                   #\n##                                           #\n## \tDate:        $DATE                   #\n## \tAction:      $ACTION                 #\n## \tHost:        $HOST                   # body\n## \tDescription: $DESCRIPTION            #\n##                                           #\n## Your faithful employee,                   #\n## Monit                                     #\n## --8<--\n##\n## You can override this message format or parts of it, such as subject\n## or sender using the MAIL-FORMAT statement. Macros such as $DATE, etc.\n## are expanded at runtime. For example, to override the sender, use:\n#\n# set mail-format { from: monit@foo.bar }\n#\n#\n## You can set alert recipients whom will receive alerts if/when a \n## service defined in this file has errors. Alerts may be restricted on \n## events by using a filter as in the second example below. \n#\n# set alert sysadm@foo.bar                       # receive all alerts\n# set alert manager@foo.bar only on { timeout }  # receive just service-\n#                                                # timeout alert\n#\n#\n## Monit has an embedded web server which can be used to view status of \n## services monitored and manage services from a web interface. See the\n## Monit Wiki if you want to enable SSL for the web server. \n#\nset httpd port 2812 and\n    use address localhost  # only accept connection from localhost\n    allow localhost        # allow localhost to connect to the server and\n    allow admin:monit      # require user 'admin' with password 'monit'\n    allow @monit           # allow users of group 'monit' to connect (rw)\n    allow @users readonly  # allow users of group 'users' to connect readonly\n\n###############################################################################\n## Services\n###############################################################################\n##\n## Check general system resources such as load average, cpu and memory\n## usage. Each test specifies a resource, conditions and the action to be\n## performed should a test fail.\n#\n#  check system myhost.mydomain.tld\n#    if loadavg (1min) > 4 then alert\n#    if loadavg (5min) > 2 then alert\n#    if memory usage > 75% then alert\n#    if swap usage > 25% then alert\n#    if cpu usage (user) > 70% then alert\n#    if cpu usage (system) > 30% then alert\n#    if cpu usage (wait) > 20% then alert\n#\n#    \n## Check if a file exists, checksum, permissions, uid and gid. In addition\n## to alert recipients in the global section, customized alert can be sent to \n## additional recipients by specifying a local alert handler. The service may \n## be grouped using the GROUP option. More than one group can be specified by\n## repeating the 'group name' statement.\n#    \n#  check file apache_bin with path /usr/local/apache/bin/httpd\n#    if failed checksum and \n#       expect the sum 8f7f419955cefa0b33a2ba316cba3659 then unmonitor\n#    if failed permission 755 then unmonitor\n#    if failed uid root then unmonitor\n#    if failed gid root then unmonitor\n#    alert security@foo.bar on {\n#           checksum, permission, uid, gid, unmonitor\n#        } with the mail-format { subject: Alarm! }\n#    group server\n#\n#    \n## Check that a process is running, in this case Apache, and that it respond\n## to HTTP and HTTPS requests. Check its resource usage such as cpu and memory,\n## and number of children. If the process is not running, Monit will restart \n## it by default. In case the service is restarted very often and the \n## problem remains, it is possible to disable monitoring using the TIMEOUT\n## statement. This service depends on another service (apache_bin) which\n## is defined above.\n#    \n#  check process apache with pidfile /usr/local/apache/logs/httpd.pid\n#    start program = \"/etc/init.d/httpd start\" with timeout 60 seconds\n#    stop program  = \"/etc/init.d/httpd stop\"\n#    if cpu > 60% for 2 cycles then alert\n#    if cpu > 80% for 5 cycles then restart\n#    if totalmem > 200.0 MB for 5 cycles then restart\n#    if children > 250 then restart\n#    if loadavg(5min) greater than 10 for 8 cycles then stop\n#    if failed host www.tildeslash.com port 80 protocol http \n#       and request \"/somefile.html\"\n#       then restart\n#    if failed port 443 type tcpssl protocol http\n#       with timeout 15 seconds\n#       then restart\n#    if 3 restarts within 5 cycles then timeout\n#    depends on apache_bin\n#    group server\n#    \n#    \n## Check filesystem permissions, uid, gid, space and inode usage. Other services,\n## such as databases, may depend on this resource and an automatically graceful\n## stop may be cascaded to them before the filesystem will become full and data\n## lost.\n#\n#  check filesystem datafs with path /dev/sdb1\n#    start program  = \"/bin/mount /data\"\n#    stop program  = \"/bin/umount /data\"\n#    if failed permission 660 then unmonitor\n#    if failed uid root then unmonitor\n#    if failed gid disk then unmonitor\n#    if space usage > 80% for 5 times within 15 cycles then alert\n#    if space usage > 99% then stop\n#    if inode usage > 30000 then alert\n#    if inode usage > 99% then stop\n#    group server\n#\n#\n## Check a file's timestamp. In this example, we test if a file is older \n## than 15 minutes and assume something is wrong if its not updated. Also,\n## if the file size exceed a given limit, execute a script\n#\n#  check file database with path /data/mydatabase.db\n#    if failed permission 700 then alert\n#    if failed uid data then alert\n#    if failed gid data then alert\n#    if timestamp > 15 minutes then alert\n#    if size > 100 MB then exec \"/my/cleanup/script\" as uid dba and gid dba\n#\n#\n## Check directory permission, uid and gid.  An event is triggered if the \n## directory does not belong to the user with uid 0 and gid 0.  In addition, \n## the permissions have to match the octal description of 755 (see chmod(1)).\n#\n#  check directory bin with path /bin\n#    if failed permission 755 then unmonitor\n#    if failed uid 0 then unmonitor\n#    if failed gid 0 then unmonitor\n#\n#\n## Check a remote host availability by issuing a ping test and check the \n## content of a response from a web server. Up to three pings are sent and \n## connection to a port and an application level network check is performed.\n#\n#  check host myserver with address 192.168.1.1\n#    if failed icmp type echo count 3 with timeout 3 seconds then alert\n#    if failed port 3306 protocol mysql with timeout 15 seconds then alert\n#    if failed url http://user:password@www.foo.bar:8080/?querystring\n#       and content == 'action=\"j_security_check\"'\n#       then alert\n#\n#\n###############################################################################\n## Includes\n###############################################################################\n##\n## It is possible to include additional configuration parts from other files or\n## directories.\n#\ninclude /etc/monit.d/*\n#\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "f485a1f5ac25ce895645b7f4d0b4c518aade37e2", "filename": "roles/network/templates/wondershaper/wondershaper.service", "repository": "iiab/iiab", "decoded_content": "[Unit]\nDescription=Bandwidth shaper/Network rate limiter\nAfter=network.target\nWants=network.target\n\n[Service]\nType=oneshot\nRemainAfterExit=yes\nEnvironmentFile=/etc/conf.d/wondershaper.conf\nExecStart=/usr/bin/wondershaper -a $IFACE -d $DSPEED -u $USPEED\nExecStop=/usr/bin/wondershaper -c -a $IFACE\n\n[Install]\nWantedBy=multi-user.target\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "230314c5efbd3b3214e184f6a5f59084388ac773", "filename": "playbooks/provision-satellite-server/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_playbook: ../prep.yml\n  tags:\n  - 'never'\n  - 'install'\n\n- import_playbook: ../osp/manage-user-network.yml\n  when:\n  - hosting_infrastructure == 'openstack'\n  tags:\n  - 'never'\n  - 'install'\n\n- import_playbook: ../osp/provision-osp-instance.yml\n  when:\n  - hosting_infrastructure == 'openstack'\n  tags:\n  - 'never'\n  - 'install'\n\n- import_playbook: ../rhsm.yml\n  tags:\n  - 'never'\n  - 'install'\n\n- hosts: satellite-server\n  roles:\n  - role: update-host\n  tags:\n  - 'never'\n  - 'install'\n\n- import_playbook: configure-satellite-server.yml\n  tags:\n  - 'always'\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "b215621b0d6660bb699373bdb247c05a1dbe7fc9", "filename": "roles/5-xo-services/README.rst", "repository": "iiab/iiab", "decoded_content": "==================\nXO Services README\n==================\n\nThis role is a place to aggregate roles that provide XO specific services.\n\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "0a802f1b6ab4b743d9a2505049ec2d4558a32ea2", "filename": "tasks/create_repo_bower_group_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_bower_group\n    args: \"{{ _nexus_repos_bower_defaults|combine(item) }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "8d5e6e25518f52cb44d805a3189e3dfd1811c9c5", "filename": "roles/osp/admin-network/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: localhost\n  roles:\n  - osp-admin-network\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "76c984c3a3f0bf2bb1cdb9f28621eb2ac0ac594f", "filename": "roles/iiab-admin/files/dummy_authorized_keys", "repository": "iiab/iiab", "decoded_content": "# Put your authorized keys here\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "522f97fe26f77bba69c6db4df7664c7b7bb0404a", "filename": "roles/httpd/tasks/home-page.yml", "repository": "iiab/iiab", "decoded_content": "- name: Create home directory\n  file: path={{ doc_root }}/home\n        mode=0755\n        owner={{ apache_user }}\n        group={{ apache_user }}\n        state=directory\n\n- name: Install admin home page into apache2\n  template: src=iiab-home-page.conf\n             dest=/etc/{{ apache_config_dir }}/iiab-home-page.conf\n\n- name: Enable the home page\n  file: src=/etc/{{ apache_config_dir }}/iiab-home-page.conf\n        dest=/etc/apache2/sites-enabled/iiab-home-page.conf\n        state=link\n  when: is_debuntu\n"}, {"commit_sha": "836dc4dd0dacc490044a14c0e39469d162b9449b", "sha": "e64664f894a5f4cef833ffdce707e9e1b9bae7eb", "filename": "tasks/section6.yml", "repository": "florianutz/Ubuntu1604-CIS", "decoded_content": "---\n- name: \"NOTSCORED | 6.1.1 | PATCH | Audit system file permissions\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_6_1_1\n  tags:\n      - level2\n      - notscored\n      - patch\n      - rule_6.1.1\n      - notimplemented\n\n- name: \"SCORED | 6.1.2 | PATCH | Ensure permissions on /etc/passwd are configured\"\n  file:\n      dest: /etc/passwd\n      owner: root\n      group: root\n      mode: 0644\n  when:\n      - ubuntu1604cis_rule_6_1_2\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.1.2\n\n- name: \"SCORED | 6.1.3 | PATCH | Ensure permissions on /etc/shadow are configured\"\n  file:\n      dest: /etc/shadow\n      owner: root\n      group: root\n      mode: 0000\n  when:\n      - ubuntu1604cis_rule_6_1_3\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.1.3\n\n- name: \"SCORED | 6.1.4 | PATCH | Ensure permissions on /etc/group are configured\"\n  file:\n      dest: /etc/group\n      owner: root\n      group: root\n      mode: 0644\n  when:\n      - ubuntu1604cis_rule_6_1_4\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.1.4\n\n- name: \"SCORED | 6.1.5 | PATCH | Ensure permissions on /etc/gshadow are configured\"\n  file:\n      dest: /etc/gshadow\n      owner: root\n      group: root\n      mode: 0000\n  when:\n      - ubuntu1604cis_rule_6_1_5\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.1.5\n\n- name: \"SCORED | 6.1.6 | PATCH | Ensure permissions on /etc/passwd- are configured\"\n  file:\n      dest: /etc/passwd-\n      owner: root\n      group: root\n      mode: 0600\n  when:\n      - ubuntu1604cis_rule_6_1_6\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.1.6\n\n- name: \"SCORED | 6.1.7 | PATCH | Ensure permissions on /etc/shadow- are configured\"\n  file:\n      dest: /etc/shadow-\n      owner: root\n      group: root\n      mode: 0000\n  when:\n      - ubuntu1604cis_rule_6_1_7\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.1.7\n\n- name: \"SCORED | 6.1.8 | PATCH | Ensure permissions on /etc/group- are configured\"\n  file:\n      dest: /etc/group-\n      owner: root\n      group: root\n      mode: 0600\n  when:\n      - ubuntu1604cis_rule_6_1_8\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.1.8\n\n- name: \"SCORED | 6.1.9 | PATCH | Ensure permissions on /etc/gshadow- are configured\"\n  file:\n      dest: /etc/gshadow-\n      owner: root\n      group: root\n      mode: 0600\n  when:\n      - ubuntu1604cis_rule_6_1_9\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.1.9\n\n- name: \"SCORED | 6.1.10 | PATCH | Ensure no world writable files exist\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_6_1_10\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.1.10\n      - notimplemented\n\n- name: \"SCORED | 6.1.11 | PATCH | Ensure no unowned files or directories exist\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_6_1_11\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.1.11\n      - notimplemented\n\n- name: \"SCORED | 6.1.12 | PATCH | Ensure no ungrouped files or directories exist\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_6_1_12\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.1.12\n      - notimplemented\n\n- name: \"NOTSCORED | 6.1.13 | PATCH | Audit SUID executables\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_6_1_13\n  tags:\n      - level1\n      - notscored\n      - patch\n      - rule_6.1.13\n      - notimplemented\n\n- name: \"NOTSCORED | 6.1.14 | PATCH | Audit SGID executables\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_6_1_14\n  tags:\n      - level1\n      - notscored\n      - patch\n      - rule_6.1.14\n      - notimplemented\n\n- name: \"SCORED | 6.2.1 | PATCH | Ensure password fields are not empty\"\n  command: passwd -l {{ item }}\n  changed_when: false\n  failed_when: false\n  with_items: \"{{ empty_password_accounts.stdout_lines }}\"\n  when:\n      - empty_password_accounts.rc\n      - ubuntu1604cis_rule_6_2_1\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.2.1\n\n- name: \"SCORED | 6.2.2 | PATCH | Ensure no legacy '+' entries exist in /etc/passwd\"\n  command: sed -i '/^+/ d' /etc/passwd\n  changed_when: false\n  failed_when: false\n  when:\n      - ubuntu1604cis_rule_6_2_2\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.2.2\n\n- name: \"SCORED | 6.2.3 | PATCH | Ensure no legacy '+' entries exist in /etc/shadow\"\n  command: sed -i '/^+/ d' /etc/shadow\n  changed_when: false\n  failed_when: false\n  when:\n      - ubuntu1604cis_rule_6_2_3\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.2.3\n\n- name: \"SCORED | 6.2.4 | PATCH | Ensure no legacy '+' entries exist in /etc/group\"\n  command: sed -i '/^+/ d' /etc/group\n  changed_when: false\n  failed_when: false\n  when:\n      - ubuntu1604cis_rule_6_2_4\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.2.4\n\n- name: \"SCORED | 6.2.5 | PATCH | Ensure root is the only UID 0 account\"\n  command: passwd -l {{ item }}\n  changed_when: false\n  failed_when: false\n  with_items: \"{{ uid_zero_accounts_except_root.stdout_lines }}\"\n  when:\n      - uid_zero_accounts_except_root.rc\n      - ubuntu1604cis_rule_6_2_5\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.2.5\n\n- name: \"SCORED | 6.2.6 | PATCH | Ensure root PATH Integrity\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_6_2_6\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.2.6\n      - notimplemented\n\n- name: \"SCORED | 6.2.6 | PATCH | Ensure root PATH Integrity\"\n  shell: |\n    sudopath=($(grep secure_path /etc/sudoers | cut -f2 -d= |cut -f2 -d\\\"))\n    IFS=:\n    for i in ${sudopath[*]}\n    do\n      if [ -d \"$i\" ]\n        then newsudopath+=($i)\n      fi\n     done\n    echo \"${newsudopath[*]}\"\n  args:\n      executable: /bin/bash\n  register: fixsudo\n  changed_when: false\n  check_mode: false\n  when:\n      - ubuntu1604cis_rule_6_2_6\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.2.6\n\n- name: \"SCORED | 6.2.6 | PATCH | Ensure root PATH Integrity\"\n  lineinfile:\n      dest: /etc/sudoers\n      regexp: \"(.*secure_path=).*\"\n      line: '\\1\"{{ fixsudo.stdout_lines[0] }}\"'\n      backrefs: true\n  when:\n      - fixsudo.stdout_lines[0] != \"\"\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.2.6\n\n- name: \"SCORED | 6.2.7 | PATCH | Ensure all users' home directories exist\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_6_2_7\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.2.7\n      - notimplemented\n\n- name: \"SCORED | 6.2.8 | PATCH | Ensure users' home directories permissions are 750 or more restrictive\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_6_2_8\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.2.8\n      - notimplemented\n\n- name: \"SCORED | 6.2.9 | PATCH | Ensure users own their home directories\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_6_2_9\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.2.9\n      - notimplemented\n\n- name: \"SCORED | 6.2.10 | PATCH | Ensure users' dot files are not group or world writable\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_6_2_10\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.2.10\n      - notimplemented\n\n- name: \"SCORED | 6.2.11 | PATCH | Ensure no users have .forward files\"\n  file:\n      state: absent\n      dest: \"~{{ item }}/.forward\"\n  with_items: \"{{ users.stdout_lines }}\"\n  when:\n      - ubuntu1604cis_rule_6_2_11\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.2.11\n\n- name: \"SCORED | 6.2.12 | PATCH | Ensure no users have .netrc files\"\n  file:\n      state: absent\n      dest: \"~{{ item }}/.netrc\"\n  with_items: \"{{ users.stdout_lines }}\"\n  when:\n      - ubuntu1604cis_rule_6_2_12\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.2.12\n\n- name: \"SCORED | 6.2.14 | PATCH | Ensure no users have .rhosts files\"\n  file:\n      state: absent\n      dest: \"~{{ item }}/.rhosts\"\n  with_items: \"{{ users.stdout_lines }}\"\n  when:\n      - ubuntu1604cis_rule_6_2_14\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.2.14\n\n- name: \"SCORED | 6.2.15 | PATCH | Ensure all groups in /etc/passwd exist in /etc/group\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_6_2_15\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.2.15\n      - notimplemented\n\n- name: \"SCORED | 6.2.16 | PATCH | Ensure no duplicate UIDs exist\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_6_2_16\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.2.16\n      - notimplemented\n\n- name: \"SCORED | 6.2.17 | PATCH | Ensure no duplicate GIDs exist\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_6_2_17\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.2.17\n      - notimplemented\n\n- name: \"SCORED | 6.2.18 | PATCH | Ensure no duplicate user names exist\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_6_2_18\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.2.18\n      - notimplemented\n\n- name: \"SCORED | 6.2.19 | PATCH | Ensure no duplicate group names exist\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_6_2_19\n  tags:\n      - level1\n      - scored\n      - patch\n      - rule_6.2.19\n      - notimplemented\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "79614686f00bcd737955e73f1dab73df05159806", "filename": "roles/kalite/tasks/enable.yml", "repository": "iiab/iiab", "decoded_content": "# By the time we get here we should have ka-lite of some version\n# And the systemd unit files should be defined\n\n- name: Enable kalite server\n  service: name=kalite-serve\n           enabled=yes\n           state=started\n\n- name: Disable kalite server\n  service: name=kalite-serve\n           enabled=no\n           state=stopped\n  when: not kalite_enabled\n\n# Since Fedora 18 we don't have a separate unit fiile for kalite-cron\n\n- name: Disable kalite cron server F18\n  service: name=kalite-cron\n           enabled=no\n           state=stopped\n  when: not kalite_cron_enabled and is_F18\n\n- name: Enable kalite cron server F18\n  service: name=kalite-cron\n           enabled=yes\n           state=started\n  when: kalite_cron_enabled and is_F18\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "5ced7e6e42e16bd8f751eb5501d9781edd0ccf8f", "filename": "roles/config-redis/tasks/firewall.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Check if firewalld is installed\n  command: systemctl status firewalld\n  register: firewalld_status\n  failed_when: false\n  changed_when: false\n\n- name: Check if iptables is installed\n  command: systemctl status iptables\n  register: iptables_status\n  failed_when: false\n  changed_when: false\n\n- name: Open port in firewalld\n  firewalld:\n    port: \"{{ redis_host_port }}/tcp\"\n    permanent: true\n    state: enabled\n  when: firewalld_status.rc == 0\n  notify:\n  - restart firewalld\n\n- name: Ensure iptables is correctly configured\n  lineinfile:\n    insertafter: \"^-A INPUT .* --dport {{ redis_host_port }} .* ACCEPT\"\n    state: present\n    dest: /etc/sysconfig/iptables\n    regexp: \"^-A INPUT .* --dport {{ redis_port }} .* ACCEPT\"\n    line: \"-A INPUT -p TCP -m state --state NEW -m TCP --dport {{ redis_port }} -j ACCEPT\"\n  when: iptables_status.rc == 0 and firewalld_status.rc != 0\n  notify:\n  - restart iptables\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "d5e818f325191f456eff2c6f083dd0ffbac95e11", "filename": "roles/dns/manage-dns-records/tasks/nsupdate/nsupdate-server.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- include_tasks: process-records.yml\n  with_items:\n    - \"{{ dns.1.nsupdate }}\"\n  when:\n    - dns.1.nsupdate is defined\n  loop_control:\n    loop_var: nsupdate\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "be2c937d34edaabbf4a3102d273db1441b1a0fda", "filename": "roles/install-mongodb/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: 'Check if mongodb is installed'\n  command: which mongod\n  register: mongod_check\n  ignore_errors: yes\n\n- name: 'Install mongodb if not installed'\n  include_tasks: 'install_mongodb.yml'\n  when: mongod_check != '/usr/bin/mongod'\n\n- name: 'Start MongoDB'\n  service:\n    name: mongod\n    state: started\n\n- name: 'Check if pip is installed'\n  command: which pip\n  register: pip_check\n  ignore_errors: yes\n\n- name: 'Install pip if not installed'\n  command: easy_install pip\n  when: pip_check != '/usr/bin/pip'\n\n- name: 'Install pymongo'\n  command: pip install pymongo\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "b6a7b28714bc3cfad933fc9c2fb2a1bcab0b340c", "filename": "roles/dns/manage-dns-zones-bind/tasks/generate_keys.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Build a list of view/zone items\n  set_fact:\n    dns_views: \"{{ dns_views | default([]) + [ { 'name': item.0.name + '-' + item.1.dns_domain } ] }}\"\n  with_subelements:\n    - \"{{ dns_data.views }}\"\n    - zones\n\n- name: Get existing key files\n  shell: 'ls -1 K{{ item.name }}*.key | sed -ne \"s/K\\({{ item.name }}\\).*.key/\\1/p\"'\n  args:\n    chdir: /var/named/\n  register: key_files\n  ignore_errors: yes\n  with_items:\n    - \"{{ dns_views }}\"\n\n- name: Build list of existing key files\n  set_fact:\n    existing_key_files: \"{{ existing_key_files | default([]) + [ item.stdout ] }}\"\n  with_items:\n    - \"{{ key_files.results }}\"\n\n- name: Generate keys for nsupdate\n  command: >\n    /sbin/dnssec-keygen\n      -a {{ default_dnssec_keygen_algorithm }}\n      -b {{ default_dnssec_keygen_size }}\n      -n USER\n      -r /dev/urandom\n      -K /var/named {{ item.name }}\n  with_items:\n    - \"{{ dns_views }}\"\n  when:\n    - item not in existing_key_files\n\n- name: Gather keys for nsupdate\n  shell: \"grep Key: /var/named/K{{ item.name }}*.private | cut -d ' ' -f 2\"\n  register: nsupdate_keys_captured\n  with_items:\n    - \"{{ dns_views }}\"\n\n- name: Move .private and .key files to the 'archive' \n  block:\n  - file:\n      path: \"/var/named/key-archive\"\n      state: directory\n  - shell: \"mv /var/named/K{{ item.name }}*.{private,key} /var/named/key-archive/\"\n    with_items:\n      - \"{{ dns_views }}\"\n\n# Build the dict with the proper keys, i.e.:\n#    private-view.example.com:\n#      algorithm: HMAC-MD5\n#      secret: SKqKNdpfk7llKxZ57bbxUnUDobaaJp9t8CjXLJPl+fRI5mPcSBuxTAyvJPa6Y9R7vUg9DwCy/6WTpgLNqnV4Hg==\n#    public-view.example.com:\n#      algorithm: HMAC-MD5\n#      secret: kVE2bVTgZjrdJipxPhID8BEZmbHD8cExlVPR+zbFpW6la8kL5wpXiwOh8q5AAosXQI5t95UXwq3Inx8QT58duw==\n- name: Set nsupdate_keys fact\n  set_fact:\n    nsupdate_keys: \"{{ nsupdate_keys | default({}) | combine({ item.item.name : { 'key_algorithm': ( dnssec_keygen_algorithm | default(default_dnssec_keygen_algorithm) ), 'key_secret': item.stdout } }) }}\"\n  with_items: \"{{ nsupdate_keys_captured.results }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "32607d7387e653b5642e64a47319b0817a6ec2ca", "filename": "roles/2-common/tasks/iiab_ini.yml", "repository": "iiab/iiab", "decoded_content": "# workaround for fact that auto create does not work on ini_file\n- name: Create iiab config file\n  file: dest='{{ iiab_config_file }}'\n        state=touch\n\n- name: Add location section to config file\n  ini_file: dest='{{ iiab_config_file }}'\n            section=location\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: 'iiab_base'\n      value: '{{ iiab_base }}'\n    - option: 'iiab_dir'\n      value: '{{ iiab_dir }}'\n\n- name: add version section\n  ini_file: dest='{{ iiab_config_file }}'\n            section=version\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: 'distribution'\n      value: '{{ ansible_distribution }}'\n    - option: 'arch'\n      value: '{{ ansible_architecture }}'\n    - option: 'iiab_branch'\n      value: '{{ ansible_local[\"local_facts\"][\"iiab_branch\"] }}'\n    - option: 'iiab_commit'\n      value: '{{ ansible_local[\"local_facts\"][\"iiab_commit\"] }}'\n    - option: 'install_date'\n      value: '{{ ansible_date_time[\"iso8601\"] }}'\n    - option: 'install_xo'\n      value: '{{ xo_model }}'\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "3ac1dc9d8e4c09041c6ec0a6ecc86dd1eed1ca5f", "filename": "roles/monit/templates/ejabberd", "repository": "iiab/iiab", "decoded_content": "check process ejabberd with pidfile /var/run/ejabberd/ejabberd.pid\n   start program = \"/usr/libexec/ejabberd-xs start && sleep 10\" \n   stop program = \"/usr/libexec/ejabberd-xs stop && sleep 10\" \n   if cpu > 60% for 2 cycles then restart\n   if totalmem > 200.0 MB for 3 cycles then restart \n   if failed host localhost port 5222 type tcp then restart\n   if 3 restarts within 5 cycles then timeout\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "254fce0b3612df4bf15dc0563d02a4d81df54747", "filename": "roles/1-prep/templates/iiab-testing.repo", "repository": "iiab/iiab", "decoded_content": "[iiab-testing]\nname=iiab-testing\nfailovermethod=priority\nbaseurl=http://download.iiab.io/repos/xsce/testing\nenabled=1\nmetadata_expire=1d\ngpgcheck=0\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "c777b149bfcd0876cca5a3e9d1628256f7139908", "filename": "roles/network/templates/squid/allowregex.rules", "repository": "iiab/iiab", "decoded_content": "# put regular expressions that match desired urls \nbing.com/translator\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "1140ca9478535ed68f79a0333f6076541e10f455", "filename": "roles/idmgr/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Install idmgr packages\n  package: name={{ item }}\n           state=present\n  with_items:\n   - ds-backup-server\n   - idmgr\n   - xinetd\n   - xs-rsync\n   - incron\n  tags:\n    - download\n\n- name: Configure idmgr\n  template: backup=yes\n            src={{ item.src }}\n            dest={{ item.dest }}\n            owner=root\n            group=root\n            mode={{ item.mode }}\n  with_items:\n    - { src: 'idmgr', dest: '/etc/idmgr.conf', mode: '0644' }\n    - { src: 'idmgr.service.j2', dest: '/etc/systemd/system/idmgr.service', mode: '0644'}\n\n- name: Configure ds-backup\n  command: /etc/sysconfig/olpc-scripts/setup.d/ds-backup\n           creates=/etc/incron.d/ds-backup.conf\n\n- name: Configure idmgr sqlite db\n  command: /etc/sysconfig/olpc-scripts/setup.d/idmgr\n           creates=/home/idmgr/identity.db\n\n- name: Configure xs-rsync\n  command: /etc/sysconfig/olpc-scripts/setup.d/xs-rsync\n           creates=/etc/xinetd.d/xs-rsyncd\n\n- name: Copy idmgr init script\n  command: /bin/cp /etc/init.d/idmgr /usr/libexec/idmgr.init\n           creates=/usr/libexec/idmgr.init\n\n- name: Enable idmgr service\n  service: name={{ item }}\n           enabled=yes\n           state=started\n  with_items:\n    - idmgr\n    - xinetd\n  when: xo_services_enabled\n\n- name: Disable idmgr service\n  service: name={{ item }}\n           enabled=no\n           state=stopped\n  with_items:\n    - idmgr\n    - xinetd\n  when: not xo_services_enabled\n\n#idmgr needs an extra step\n- name: Enable ejabberd service\n  file: src=/etc/systemd/system/idmgr.service\n        dest=/etc/systemd/system/multi-user.target.wants/idmgr.service\n        owner=root\n        group=root\n        state=link\n\n- name: Configure rssh rsync permissions to allow OLPC Backup clients\n  lineinfile: backup=yes\n              dest=/etc/rssh.conf\n             state=present\n             regexp='^#allowrsync'\n             insertafter='^#allowrsync'\n             line=allowrsync\n\n- name: Configure rssh sftp permissions for backup restore clients\n  lineinfile: backup=yes\n              dest=/etc/rssh.conf\n             state=present\n             regexp='^#allowsftp'\n             insertafter='^#allowsftp'\n             line=allowsftp\n\n- name: Add idmgr to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=idmgr\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: idmgr\n    - option: description\n      value: '\"Idmgr is an automatic identity manager for XO clients which enables automatic backup\"'\n    - option: enabled\n      value: \"{{ xo_services_enabled }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "273b8454a8f041552555d52ceda34f3698ff4f84", "filename": "roles/dhcp/tasks/dhcpconfig.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n  - name: \"generate a random local directory in /tmp\"\n    tempfile:\n      path: '{{ dhcp_config_temp_dir }}'\n      state: directory\n      prefix: dhcp\n    register: dhcp_config_dir\n    notify: dhcp-config cleanup temp\n\n  - name: 'Add Read/Execute permissions on directory'\n    file:\n      path: '{{ dhcp_config_dir.path }}'\n      mode: 0755\n      state: directory\n\n  - name: \"Generate local dhcpd.conf file\"\n    template:\n      src: dhcp_conf.j2\n      dest: '{{ dhcp_config_dir.path }}/{{ dhcp_config_temp_file }}'\n    notify: dhcp-config cleanup temp\n\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "de3691e0b810ef0e06385881560bac3c3d434cf4", "filename": "playbooks/openshift/openstack/post-provision.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n# Assign hostnames\n- hosts: cluster_hosts\n  pre_tasks:\n    - import_tasks: ../prep-inventory.yml\n  roles:\n    - role: openshift-ansible-contrib/roles/hostnames\n\n# Build and process DNS Records\n- hosts: localhost\n  pre_tasks:\n    - import_tasks: ../prep-inventory.yml\n    - import_tasks: dns.yml\n  roles:\n    - role: infra-ansible/roles/dns\n\n# provision cinder volume\n- import_playbook: cinder-registry.yml\n  when:\n    - openshift_hosted_registry_storage_kind is defined\n    - openshift_hosted_registry_storage_kind == \"openstack\"\n    - openshift_hosted_registry_storage_openstack_volumeID is not defined\n  \n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "17bba197ecaa9e116a9bb35a2de29e38c72e13d7", "filename": "tasks/create_repo_maven_hosted_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_maven_hosted\n    args: \"{{ _nexus_repos_maven_defaults|combine(item) }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "2880c831929bdf8b1b788ee2fc79faa464a938e1", "filename": "roles/config-lvm/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nlvm_fstype: \"xfs\"\ndefault_lv_size: \"100%VG\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "8b0a9102e6d5a7f40d4ac33c828159582412c4dc", "filename": "roles/osp/packstack-post/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'restart mariadb'\n  service:\n    name: 'mariadb'\n    state: restarted\n\n- name: 'restart rabbitmq-server'\n  service:\n    name: 'rabbitmq-server'\n    state: restarted\n\n- name: 'restart openstack-nova-compute'\n  service:\n    name: 'openstack-nova-compute'\n    state: restarted\n\n- name: 'restart libvirtd'\n  service:\n    name: 'libvirtd'\n    state: restarted\n\n- name: 'restart iptables'\n  service:\n    name: 'iptables'\n    state: restarted\n\n- name: 'restart keystone'\n  service:\n    name: 'httpd'\n    state: restarted\n\n- name: 'restart openstack-cinder-api'\n  service:\n    name: 'openstack-cinder-api'\n    state: restarted\n\n- name: 'restart openstack-cinder-backup'\n  service:\n    name: 'openstack-cinder-backup'\n    state: restarted\n\n- name: 'restart openstack-cinder-scheduler'\n  service:\n    name: 'openstack-cinder-scheduler'\n    state: restarted\n\n- name: 'restart openstack-cinder-volume'\n  service:\n    name: 'openstack-cinder-volume'\n    state: restarted\n\n- name: \"remove temporary keystone rc file\"\n  file:\n    path: \"{{ keystonerc_file.path }}\"\n    state: absent\n\n- name: \"remove local temporary keystone rc file\"\n  file:\n    path: \"{{ keystonerc_file.path }}\"\n    state: absent\n  delegate_to: localhost\n\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "c7b7e40338c588175511f401d3b6fc3383186e70", "filename": "playbooks/ansible/tower/manage-tower-content.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: tower\n  roles:\n  - role: ansible/tower/manage-projects\n  - role: ansible/tower/manage-credentials\n  - role: ansible/tower/manage-inventories\n  - role: ansible/tower/manage-job-templates\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "6725ddecb21705530dd9c7bd694f8ffc63f95349", "filename": "roles/activity-server/files/lang_templates/fr/activity", "repository": "iiab/iiab", "decoded_content": "<div class=\"olpc-activity-info\">\n<h2>%(name)s</h2>\n%(description)s\n<ul>\n <li>Identifiant: <span class=\"olpc-activity-id\">%(bundle_id)s</span></li>\n <li>Version: <span class=\"olpc-activity-version\">%(activity_version)s</span></li>\n <li>URL: <span class=\"olpc-activity-url\"><a href=\"%(bundle_url)s\">%(bundle_url)s</a></span></li>\n <li style=\"display: %(show_older_versions)s\">Anciennes versions: %(older_versions)s</li>\n</ul>\n</div>\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "9117b3795fa83a9fcbfff293bef4234dea94df1e", "filename": "roles/config-mysql/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Install Containerized MySQL\n  include_tasks: install_containerized.yml\n  when: mode == \"containerized\"\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "4093fe866a1aace2a169d0d9c4e60edf5d46c711", "filename": "tasks/unit/install-unit.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- import_tasks: setup-debian.yml\n  when: ansible_os_family == \"Debian\"\n\n- import_tasks: setup-redhat.yml\n  when: ansible_os_family == \"RedHat\"\n\n- import_tasks: setup-freebsd.yml\n  when: ansible_os_family == \"FreeBSD\"\n\n- name: \"(Install: Debian/Ubuntu/CentOS/RedHat) Install NGINX Unit\"\n  package:\n    name: unit\n    state: present\n  when: ansible_os_family != \"FreeBSD\"\n  notify: \"(Handler: Debian/Ubuntu/CentOS/RedHat) Start NGINX Unit\"\n\n- name: \"(Install: FreeBSD) Install NGINX Unit\"\n  portinstall:\n    name: unit\n    state: present\n  when: ansible_os_family == \"FreeBSD\"\n  notify: \"(Handler: FreeBSD) Start NGINX Unit\"\n\n- import_tasks: install-modules.yml\n  when: nginx_unit_modules is defined and nginx_unit_modules\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "b7371c0074b7d44d01e382640a41dad7bcdbe0a6", "filename": "roles/config-chrony/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: \"prereq.yml\"\n- import_tasks: \"chrony.yml\"\n\n"}, {"commit_sha": "c0bf4b7577771e6d9cd9f162e7588a1a8f8e302e", "sha": "506fde4436d1a9fdca43dec042d52a27e12f4d5a", "filename": "tasks/trim-fat.yml", "repository": "geerlingguy/ansible-role-solr", "decoded_content": "---\n- name: Remove the downloaded Solr archive.\n  file:\n    path: \"{{ item }}\"\n    state: absent\n  with_items:\n    - \"{{ solr_workspace }}/{{ solr_filename }}.tgz\"\n    - \"{{ solr_workspace }}/{{ solr_filename }}\"\n\n- name: Remove extra cruft, if configured.\n  file:\n    path: \"{{ item }}\"\n    state: absent\n  with_items:\n    - \"{{ solr_install_path }}/docs\"\n    - \"{{ solr_install_path }}/example\"\n  when: solr_remove_cruft\n"}, {"commit_sha": "7032aee7df1c2c6e96795067285efa3b2a6de32e", "sha": "7083873550e60cb3878b0882101381b16c5ded90", "filename": "roles/docker/tasks/main.yml", "repository": "openshift/openshift-ansible-contrib", "decoded_content": "---\n- name: \"Setting Docker Facts\"\n  set_fact:\n    docker_storage_block_device: \"{{ docker_storage_block_device | default(default_docker_storage_block_device) }}\"\n    docker_storage_volume_group: \"{{ docker_storage_volume_group | default(default_docker_storage_volume_group) }}\"\n\n- name: \"Install Docker\"\n  yum:\n    name: docker\n    state: latest\n  notify:\n    - enable docker\n\n- name: \"Confige Docker\"\n  lineinfile:\n    dest: /etc/sysconfig/docker\n    regexp: '^OPTIONS=.*$'\n    line: \"^OPTIONS='--selinux-enabled --insecure-registry 172.30.0.0/16'\"\n\n- name: \"Check for existing Docker Storage device\"\n  command: pvs\n  register: pvs\n\n- name: \"Set Docker Storage fact if already configured\"\n  set_fact:\n    docker_storage_setup: true\n  when: pvs.stdout | search('{{ docker_storage_block_device }}.*{{ docker_storage_volume_group }}')\n\n- name: \"Configure Docker Storage Setup\"\n  template:\n    src: docker-storage-setup.j2\n    dest: /etc/sysconfig/docker-storage-setup\n  when: docker_storage_setup is undefined\n\n# - name: \"Run Docker Storage Setup\"\n#   command: docker-storage-setup\n#   when: docker_storage_setup is undefined\n#   notify:\n#   - restart docker\n#\n# - name: \"Extend the Volume Group for Docker Storage\"\n#   command: lvextend -l 90%VG /dev/{{ docker_storage_volume_group }}/docker-pool\n#   when: docker_storage_setup is undefined\n#   notify:\n#   - restart docker\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "b15a4ec08ca9acf43dcaa363afb1e8d4107f06b8", "filename": "roles/dns/config-dns-server-bind/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\npackage_state: present\n\ndns_server_type: 'master'\n\nnamed_config_recursion: yes\n\nnamed_config_views: []\nnamed_config_allow_query: []\nnamed_config_allow_transfer: []\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "215ba70c3276cd50f5d8e91c85e16608a6afe761", "filename": "roles/user-management/populate-users/test/playbook.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Import identities information from CSV file \n  hosts: identity\n\n  roles: \n    - populate-users\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "0118bc466f818ce5d4e47b8620fd827b653745fb", "filename": "archive/roles/cicd/defaults/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\ncicd_block_device: \"/dev/vdb\"\njava_keystore_password: \"changeit\"\njava_certs: \"\"\ncicd_temp_dir: \"/tmp/cicd-setup\"\n\ngroovy_version: \"2.4.4\"\ngroovy_url: \"http://dl.bintray.com/groovy/maven/apache-groovy-binary-{{groovy_version}}.zip\"\ngroovy_local_archive: \"{{cicd_temp_dir}}/apache-groovy-binary-{{groovy_version}}.zip\"\ngroovy_base_dir: \"/usr/local\"\ngroovy_install_dir: \"{{groovy_base_dir}}/groovy-{{groovy_version}}\"\n\nnexus_version: \"2.12.0-01\"\nnexus_url: \"https://sonatype-download.global.ssl.fastly.net/nexus/oss/nexus-{{nexus_version}}-bundle.tar.gz\"\nnexus_local_archive: \"{{cicd_temp_dir}}/nexus-{{                                                               nexus_version}}-bundle.tar.gz\"\nnexus_base_dir: \"/usr/local\"\nnexus_install_dir: \"{{nexus_base_dir}}/nexus-{{nexus_version}}\"\nnexus_home_dir: \"{{ nexus_base_dir }}/nexus\"\nnexus_pid_dir: \"/var/run/nexus\"\nnexus_sonatype_work_dir: \"{{nexus_base_dir}}/sonatype-work\"\nnexus_user: \"nexus\"\nnexus_group: \"nexus\"\n\njenkins_repo_url: \"http://pkg.jenkins-ci.org/redhat-stable/jenkins.repo\"\njenkins_repo_key_url: \"https://jenkins-ci.org/redhat/jenkins-ci.org.key\"\njenkins_home_dir: \"/var/lib/jenkins\"\njenkins_authz_xml: '<authorizationStrategy class=\"hudson.security.AuthorizationStrategy$Unsecured\"/><securityRealm class=\"hudson.security.SecurityRealm$None\"/>'\njenkins_plugins_base_url: \"https://updates.jenkins-ci.org/download/plugins\"\njenkins_plugins_home_dir: \"{{ jenkins_home_dir }}/plugins\"\njenkins_user: \"jenkins\"\njenkins_group: \"jenkins\""}, {"commit_sha": "51dcdf691a7801895b569a5a927e30030d8feb70", "sha": "15ae2bd7e4e3f8b8028e6b2339f0ba7062a3aaeb", "filename": "tasks/rpm_install.yml", "repository": "nusenu/ansible-relayor", "decoded_content": "---\n\n- name: Setup RPM specific variables (set_fact)\n  set_fact:\n    tor_user: toranon\n    tor_ConfDir: /etc/tor\n    tor_RunAsDaemon: 0\n  tags:\n   - reconfigure\n   - renewkey\n\n- name: Ensure tor package is installed (dnf)\n  become: yes\n  dnf: name=tor,libselinux-python,libsemanage-python state=present\n  when: ansible_pkg_mgr == 'dnf'\n  notify: re-gather facts\n\n# re-gathering facts after installing libselinux-python on F23\n# is a workaround for https://github.com/ansible/ansible-modules-core/issues/2432\n- meta: flush_handlers\n\n- name: Ensure EPEL repo is installed (yum)\n  become: yes\n  yum: name=epel-release\n  when: ansible_pkg_mgr == 'yum'\n\n- name: Ensure tor package is installed (yum)\n  become: yes\n  yum: name=tor,libsemanage-python state=present\n  when: ansible_pkg_mgr == 'yum'\n\n- name: Ensure SELinux boolean (tor_can_network_relay) is set appropriately (Fedora)\n  become: yes\n  seboolean: name=tor_can_network_relay state=yes persistent=yes\n  when: ansible_selinux.status == 'enabled'\n\n"}, {"commit_sha": "f26e6a5f816bc8f8672d0b80aa761ae8c459d30a", "sha": "5bd2184ff46fa9d2539dc5af526f83e080b3b17b", "filename": "tasks/setup-repository.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Ensure python and deps for Ansible modules\n  raw: dnf install -y python2 python2-dnf libselinux-python\n  become: true\n  changed_when: false\n  when: _docker_os_dist == \"Fedora\"\n\n- name: Update APT cache\n  apt:\n    update_cache: yes\n  become: true\n  when: _docker_os_dist == \"Ubuntu\" or\n        _docker_os_dist == \"Debian\"\n\n- name: Ensure packages are installed for repository setup\n  package:\n    name: \"{{ item }}\"\n    state: present\n  with_items:\n    - \"{{ docker_repository_related_packages[_docker_os_dist] }}\"\n  become: true\n  when: _docker_os_dist == \"Ubuntu\" or\n        _docker_os_dist == \"Debian\" or\n        _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Add Docker\u2019s official GPG key\n  apt_key:\n    url: https://download.docker.com/linux/{{ _docker_os_dist|lower }}/gpg\n    state: present\n  become: true\n  when: (_docker_os_dist == \"Ubuntu\" and _docker_os_dist_major_version > '14')\n        or _docker_os_dist == \"Debian\"\n\n- name: Add Docker APT key (alternative for older Ubuntu systems without SNI).\n  shell: \"curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\"\n  args:\n    warn: false\n  become: true\n  when: _docker_os_dist == \"Ubuntu\" and\n        _docker_os_dist_major_version == '14'\n\n- name: Add Docker CE repository (Ubuntu/Debian)\n  apt_repository:\n    repo: deb [arch=amd64] https://download.docker.com/linux/{{ _docker_os_dist|lower }} {{ _docker_os_dist_release }} stable {{ (docker_enable_ce_edge == true) | ternary('edge','') }}\n    state: present\n    filename: 'docker-ce'\n  become: true\n  when: _docker_os_dist == \"Ubuntu\" or\n        _docker_os_dist == \"Debian\"\n\n- name: Add Docker CE repository (Fedora/CentOS/RedHat)\n  get_url:\n    url: \"{{ docker_repository_url[_docker_os_dist] }}\"\n    dest: /etc/yum.repos.d/docker-ce.repo\n    mode: 0644\n  become: true\n  register: docker_repo\n  when: _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"Fedora\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Determine Docker CE Edge repo status (Fedora/CentOS/RedHat)\n  shell: \"{{ docker_cmd_check_edge_repo_status[_docker_os_dist] }}\"\n  args:\n    warn: false\n  ignore_errors: yes\n  changed_when: false\n  register: cmd_docker_ce_edge_enabled\n  when: _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"Fedora\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Set current Docker CE Edge repo status fact (Fedora/CentOS/RedHat)\n  set_fact:\n    _fact_docker_ce_edge_enabled: \"{{ cmd_docker_ce_edge_enabled.stdout == 'enabled = True' }}\"\n  when: _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"Fedora\" or\n        _docker_os_dist == \"RedHat\"\n\n- name: Enable/Disable Docker CE Edge Repository (Fedora/CentOS/RedHat)\n  shell: \"{{ docker_cmd_enable_disable_edge_repo[_docker_os_dist] }}\"\n  become: true\n  when: (_docker_os_dist == \"CentOS\" or _docker_os_dist == \"Fedora\" or _docker_os_dist == \"RedHat\") and\n        _fact_docker_ce_edge_enabled != docker_enable_ce_edge\n        \n# disable rt-beta so we don't get a 403 error retrieving repomd.xml\n- name: Check if rhel-7-server-rt-beta-rpms Repository is enabled (RedHat)\n  shell: \"subscription-manager repos --list-enabled | grep rhel-7-server-rt-beta-rpms\"\n  become: true\n  register: cmd_rhel_rt_beta_repo_enabled\n  when: _docker_os_dist == \"RedHat\"\n  changed_when: false\n  failed_when: cmd_rhel_rt_beta_repo_enabled.rc not in [ 0, 1 ]\n\n- name: Disable rhel-7-server-rt-beta-rpms Repository (RedHat)\n  shell: \"subscription-manager repos --disable=rhel-7-server-rt-beta-rpms\"\n  become: true\n  when: _docker_os_dist == \"RedHat\" and cmd_rhel_rt_beta_repo_enabled.rc == 0\n\n# container-selinux package wants this\n- name: Check if rhel-7-server-extras-rpms Repository is enabled (RedHat)\n  shell: \"subscription-manager repos --list-enabled | grep rhel-7-server-extras-rpms\"\n  become: true\n  register: cmd_rhel_extras_repo_enabled\n  when: _docker_os_dist == \"RedHat\"\n  changed_when: false\n  failed_when: cmd_rhel_extras_repo_enabled.rc not in [ 0, 1 ]\n\n- name: Enable rhel-7-server-extras-rpms Repository (RedHat)\n  shell: \"subscription-manager repos --enable=rhel-7-server-extras-rpms\"\n  become: true\n  when: _docker_os_dist == \"RedHat\" and cmd_rhel_extras_repo_enabled.rc == 1\n\n- name: Update repository cache\n  shell: \"{{ docker_cmd_update_repo_cache[_docker_os_dist] }}\"\n  args:\n    warn: false\n  become: true\n  when: docker_repo.changed"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "bb74cc840b224ae0779bb61605e2f1aa58a43e5b", "filename": "roles/config-idm-server/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n# handlers file for idm"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "64f98d33b6959aa52bf4efa0873653f7b1bed98d", "filename": "roles/config-versionlock/tasks/versionlock.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Add version locks for specified packages\"\n  shell: >\n    {{ ansible_pkg_mgr }} versionlock {{ item }}\n  with_items:\n    - \"{{ versionlock_packages }}\"\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "be721cc5ca8821a905f6e80f5ba39c6f090cff52", "filename": "roles/config-idm-server/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: idm-server\n  become: yes\n  roles:\n  - config-idm-server\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "2fb88344023f1930b72c95ea9ef0fa31ea62c114", "filename": "roles/ajenti/handlers/main.yml", "repository": "iiab/iiab", "decoded_content": "---\n- name: restart ajenti service\n  service: name=ajenti\n           enabled=yes\n           state=restarted\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "1ea80f447da048ad27f1bc3fd674fee2d81a0c4b", "filename": "roles/openvpn/templates/xscenet.conf", "repository": "iiab/iiab", "decoded_content": "#########################################\n# Sample client-side OpenVPN config file\n# for connecting to multi-client server.\n#\n# Adapted from http://openvpn.sourceforge.net/20notes.html\n#\n# The server can be pinged at {{ openvpn_server_virtual_ip }}\n#\n\nport {{ openvpn_server_port }}\ndev tun\nremote {{ vpn_presence }}\n\n# TLS parms\n\ntls-client\nca keys/ca.crt\ncert keys/client1.crt\nkey keys/client1.key\n\n# This parm is required for connecting\n# to a multi-client server.  It tells\n# the client to accept options which\n# the server pushes to us.\npull\n\n# Scripts can be used to do various\n# things (change nameservers, for\n# example.\nscript-security 2\nup scripts/announce\ndown scripts/silence\nlog /var/log/openvpn.log\n\nverb 3\ncomp-lzo yes\nkeepalive 5 30\n"}, {"commit_sha": "9662c15ce2e4260fac5cc2bfdf5aaaaf0a2191dd", "sha": "f2addede9fef134507b37ba1f3b153d3b05da88c", "filename": "tasks/section_06_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 6.1 Ensure the X Window system is not installed (Scored)\n    apt: name=xserver-xorg-core* purge=yes state=absent\n    tags:\n      - section6\n      - section6.1\n\n  - name: 6.2 Ensure Avahi Server is not enabled (check) (Scored)\n    stat: path='/etc/init/avahi-daemon.conf'\n    register: avahi_stat\n    tags:\n      - section6\n      - section6.2\n\n  - name: 6.2 Ensure Avahi Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on (filesystem'\n        state=present\n        regexp='start on (filesystem'\n        dest=/etc/init/.conf\n    when: avahi_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.2\n\n  - name: 6.3 Ensure print server is not enabled (check) (Not Scored)\n    stat: path='/etc/init/cups.conf'\n    register: cups_stat\n    tags:\n      - section6\n      - section6.3\n\n  - name: 6.3 Ensure print server is not enabled (Not Scored)\n    lineinfile: >\n        line='#start on (filesystem'\n        state=present\n        regexp='start on (filesystem'\n        dest=/etc/init/cups.conf\n    when: cups_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.3\n\n  - name: 6.4.1 Ensure DHCP Server is not enabled (check) (Scored)\n    stat: path='/etc/init/isc-dhcp-server.conf'\n    register: dhcp_stat\n    tags:\n      - section6\n      - section6.4\n      - section6.4.1\n\n  - name: 6.4.1 Ensure DHCP Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n        dest=/etc/init/isc-dhcp-server.conf\n    when: dhcp_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.4\n      - section6.4.1\n\n  - name: 6.4.2 Ensure DHCP Server is not enabled (check) (Scored)\n    stat: path='/etc/init/isc-dhcp-server6.conf'\n    register: dhcp6_stat\n    tags:\n      - section6\n      - section6.4\n      - section6.4.2\n\n  - name: 6.4.2 Ensure DHCP Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n        dest=/etc/init/isc-dhcp-server6.conf\n    when: dhcp6_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.4\n      - section6.4.2\n\n  - name: 6.5.1 Configure Network Time Protocol (install) (NTP) (Scored)\n    apt: name=ntp state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.1\n\n  - name: 6.5.2 Configure Network Time Protocol (restrict4) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='restrict -4 default kod nomodify notrap nopeer noquery'\n        regexp='^restrict -4 default'\n        state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.2\n\n  - name: 6.5.3 Configure Network Time Protocol (restrict6) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='restrict -6 default kod nomodify notrap nopeer noquery'\n        regexp='^restrict -6 default'\n        state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.3\n\n  - name: 6.5.4 Configure Network Time Protocol (server check) (NTP) (Scored)\n    command: 'grep \"^server\" /etc/ntp.conf'\n    register: ntp_server_rc\n    changed_when: False\n    always_run: True\n    tags:\n      - section6\n      - section6.5\n      - section6.5.4\n\n  - name: 6.5.4 Configure Network Time Protocol (server add) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='server 0.fr.pool.ntp.org'\n        state=present\n    when: ntp_server_rc.rc == 1\n    tags:\n      - section6\n      - section6.5\n      - section6.5.4\n\n  - name: 6.6 Ensure LDAP is not enabled (Not Scored)\n    apt: name=slapd purge=yes state=absent\n    tags:\n      - section6\n      - section6.6\n\n  - name: 6.7.1 Ensure NFS and RPC are not enabled (stat) (Not Scored)\n    stat: path=/etc/init/rpcbind-boot.conf\n    register: nfs_rpc_rc\n    tags:\n      - section6\n      - section6.7\n      - section6.7.1\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (Not Scored)\n    lineinfile: >\n        dest=/etc/init/rpcbind-boot.conf\n        line='#start on virtual-filesystems and net-device-up IFACE=lo'\n        state=present\n        regexp='start on virtual-filesystems and net'\n    when: nfs_rpc_rc.stat.exists == True\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (check) (Not Scored)\n    command: dpkg -S nfs-kernel-server\n    changed_when: False\n    failed_when: False\n    register: nfs_present\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (rc.d) (Not Scored)\n    service: >\n        name=nfs-kernel-server\n        enabled=no\n    when: nfs_present.rc == 0\n    register: nfs_service_result\n    failed_when: \"nfs_service_result|failed and 'service not found' not in nfs_service_result.msg\"\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.8-14 Ensure DNS,FTP,HTTP,IMAP,POP,Samba,Proxy,SNMP Servers are not enabled (Not Scored)\n    service: >\n        name={{ item }}\n        enabled=no\n    with_items:\n      - bind9\n      - vsftpd\n      - apache2\n      - dovecot\n      - smbd\n      - squid3\n      - snmpd\n    failed_when: False\n    tags:\n      - section6\n      - section6.8\n      - section6.9\n      - section6.10\n      - section6.11\n      - section6.12\n      - section6.13\n      - section6.14\n\n  - name: 6.15 Configure Mail Transfer Agent for Local-Only Mode (stat) (Scored)\n    stat: path=/etc/postfix/main.cf\n    register: postfix_main_cf\n    tags:\n      - section6\n      - section6.15\n\n  - name: 6.15 Configure Mail Transfer Agent for Local-Only Mode (Scored)\n    lineinfile: >\n        dest=/etc/postfix/main.cf\n        line='inet_interfaces = localhost'\n        state=present\n    when: postfix_main_cf.stat.exists == True\n    tags:\n      - section6\n      - section6.15\n\n  - name: 6.16 Ensure rsync service is not enabled (stat) (Scored)\n    stat: path=/etc/default/rsync\n    register: default_rsync\n    tags:\n      - section6\n      - section6.16\n\n  - name: 6.16 Ensure rsync service is not enabled (Scored)\n    lineinfile: >\n        dest='/etc/default/rsync'\n        regexp='^RSYNC_ENABLE'\n        line='RSYNC_ENABLE=false'\n    when: default_rsync.stat.exists == True\n    tags:\n      - section6\n      - section6.16\n\n  - name: 6.17 Ensure Biosdevname is not enabled (Scored)\n    apt: name=biosdevname purge=yes state=absent\n    tags:\n      - section6\n      - section6.17\n"}, {"commit_sha": "a94f9ce4fa32273fd0fad7492d36db4101423cc3", "sha": "c5753354cf99dd58c4ae46fa9c76e4eed51170c6", "filename": "tasks/main.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Set distribution facts\n  set_fact:\n    _docker_os_dist: \"{{ ansible_distribution }}\"\n    _docker_os_dist_release: \"{{ ansible_distribution_release }}\"\n    _docker_os_dist_major_version: \"{{ ansible_distribution_major_version }}\"\n    _docker_os_dist_check: yes\n  tags: [\"install\", \"configure\"]\n\n- name: Reinterpret distribution facts for Linux Mint 18\n  set_fact:\n    _docker_os_dist: \"Ubuntu\"\n    _docker_os_dist_release: \"xenial\"\n    _docker_os_dist_major_version: \"16\"\n  when:\n    _docker_os_dist == \"Linux Mint\" and\n    _docker_os_dist_major_version == \"18\"\n  tags: [\"install\", \"configure\"]\n\n# https://wiki.ubuntu.com/SystemdForUpstartUsers\n# Important! systemd is only fully supported in Ubuntu 15.04 and later releases\n- name: Determine usage of systemd\n  become: true\n  shell: \"ps -p1 | grep systemd 1>/dev/null && echo systemd || echo upstart\"\n  changed_when: no\n  register: _determine_systemd_usage\n\n- name: Set fact to indicate systemd is not used\n  set_fact:\n    _docker_systemd_used: \"{{ _determine_systemd_usage is defined and _determine_systemd_usage.stdout == 'systemd' }}\"\n\n- name: Temporary handling of deprecated variable docker_enable_ce_edge (#54)\n  set_fact:\n    docker_channel: edge\n  when:\n    - docker_enable_ce_edge is defined\n    - docker_enable_ce_edge == true\n\n- name: Compatibility and distribution checks\n  include_tasks: checks.yml\n  tags: [\"install\", \"configure\"]\n\n- name: Setup Docker package repositories\n  include_tasks: setup-repository.yml\n  tags: [\"install\"]\n\n- name: Remove Docker versions before Docker CE\n  include_tasks: remove-pre-docker-ce.yml\n  when: docker_remove_pre_ce | bool\n  tags: [\"install\"]\n\n- name: Install Docker\n  include_tasks: install-docker.yml\n  tags: [\"install\"]\n\n- name: Configure audit logging\n  include_tasks: setup-audit.yml\n  tags: [\"configure\"]\n\n- name: Apply workarounds for bugs and/or tweaks\n  include_tasks: bug-tweaks.yml\n  tags: [\"configure\"]\n\n- name: Configure systemd service\n  include_tasks: configure-systemd.yml\n  when: _docker_systemd_used | bool\n  tags: [\"configure\"]\n\n- name: Configure non-systemd service\n  include_tasks: configure-non-systemd.yml\n  when: _docker_systemd_used | bool == false\n  tags: [\"configure\"]\n\n- name: Configure Docker\n  include_tasks: configure-docker.yml\n  tags: [\"configure\"]\n\n- name: Postinstall tasks\n  include_tasks: postinstall.yml\n  tags: [\"install\"]"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "4f1fcf1b8f309a90bce547cec73bc29784a01e70", "filename": "roles/iiab-admin/templates/lxde_ssh_warn.sh", "repository": "iiab/iiab", "decoded_content": "#!/bin/bash\n# credit to the folks at raspberry pi foundatioon\ncheck_hash ()\n{\n   if ! id -u iiab-admin > /dev/null 2>&1 ; then return 0 ; fi\n   if grep -q \"^PasswordAuthentication\\s*no\" /etc/ssh/sshd_config ; then return 0 ; fi\n   test -x /usr/bin/mkpasswd || return 0\n   SHADOW=\"$(sudo -n grep -E '^iiab-admin:' /etc/shadow 2>/dev/null)\"\n   test -n \"${SHADOW}\" || return 0\n   if echo $SHADOW | grep -q \"iiab-admin:!\" ; then return 0 ; fi\n   SHADOW_PW=$(echo $SHADOW | cut -d: -f2)\n   if [ \"$SHADOW_PW\" != \"\\$6\\$iiab51\\$D.IrrEeLBYIuJkGDmi27pZUGOwPFp98qpl3hxMwWV4hXigFGmdSvy3s/j7tn6OnyTTLmlV7SsN0lCUAFzxSop.\" ]; then return 0 ; fi\n\n   if echo \"${SHADOW}\" | grep -q \"${HASH}\"; then\n\tzenity --warning --text=\"SSH is enabled and the default password for the 'iiab-admin' user has not been changed.\\nThis is a security risk - please go to the iiab-console and use utilities-> change password   to set a new password.\"\n   fi\n}\n\nif service ssh status | grep -q running; then\n\tcheck_hash\nfi\nunset check_hash\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "f572e0376f5edbed4a81f162948900b1d69d2ba5", "filename": "roles/2-common/templates/iiab-centos.repo", "repository": "iiab/iiab", "decoded_content": "[iiab-centos]\nname=iiab-centos\nfailovermethod=priority\nbaseurl=http://download.iiab.io/repos/centos\nenabled=1\nmetadata_expire=1d\ngpgcheck=0\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "0abf5927604a6174b68ee0e4ac11f134a203b91a", "filename": "roles/letsencrypt/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "- include: setup.yml\n- include: nginx.yml\n- include: certificates.yml\n\n- name: Install cronjob for key generation\n  cron:\n    cron_file: letsencrypt-certificate-renewal\n    name: letsencrypt certificate renewal\n    user: root\n    job: cd {{ acme_tiny_data_directory }} && ./renew-certs.py\n    day: \"{{ letsencrypt_cronjob_daysofmonth }}\"\n    hour: 4\n    minute: 30\n    state: present\n"}, {"commit_sha": "b7c6bfe0369646ca69beeb3dfe07e8218d61c940", "sha": "2f4000f71b6066dfb4b3a7bf7a4fc327e86dddad", "filename": "tasks/yum.yml", "repository": "dev-sec/ansible-os-hardening", "decoded_content": "---\n- name: remove unused repositories\n  file:\n    name: '/etc/yum.repos.d/{{ item }}.repo'\n    state: 'absent'\n  with_items:\n    - 'CentOS-Debuginfo'\n    - 'CentOS-Media'\n    - 'CentOS-Vault'\n  when: os_security_packages_clean\n\n- name: get yum-repository-files\n  shell: 'find /etc/yum.repos.d/ -type f -name *.repo'\n  changed_when: False\n  register: yum_repos\n\n- name: check if rhnplugin.conf exists\n  stat:\n    path: '/etc/yum/pluginconf.d/rhnplugin.conf'\n  register: rhnplugin_file\n\n  # for the 'default([])' see here:\n  # https://github.com/dev-sec/ansible-os-hardening/issues/99 and\n  # https://stackoverflow.com/questions/37067827/ansible-deprecation-warning-for-undefined-variable-despite-when-clause\n- name: activate gpg-check for yum-repos\n  replace:\n    dest: '{{ item }}'\n    regexp: '^\\s*gpgcheck: 0'\n    replace: 'gpgcheck: 1'\n  with_flattened:\n    - '/etc/yum.conf'\n    - '{{ yum_repos.stdout_lines| default([]) }}'\n\n- name: activate gpg-check for yum rhn if it exists\n  replace:\n    dest: '/etc/yum/pluginconf.d/rhnplugin.conf'\n    regexp: '^\\s*gpgcheck: 0'\n    replace: 'gpgcheck: 1'\n  when: rhnplugin_file.stat.exists\n\n- name: remove deprecated or insecure packages | package-01 - package-09\n  yum:\n    name: '{{ item }}'\n    state: 'absent'\n  with_items:\n    - '{{ os_security_packages_list }}'\n  when: os_security_packages_clean\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "5849dcbe3afc3994a15438779ec86b13802977b8", "filename": "roles/osp/packstack-install/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'restart mariadb'\n  service:\n    name: 'mariadb'\n    state: restarted\n\n- name: 'restart openstack-nova-compute'\n  service:\n    name: 'openstack-nova-compute'\n    state: restarted\n\n- name: 'restart libvirtd'\n  service:\n    name: 'libvirtd'\n    state: restarted\n\n- name: 'restart iptables'\n  service:\n    name: 'iptables'\n    state: restarted\n\n- name: 'restart keystone'\n  service:\n    name: 'httpd'\n    state: restarted\n\n- name: 'restart openstack-cinder-api'\n  service:\n    name: 'openstack-cinder-api'\n    state: restarted\n\n- name: 'restart openstack-cinder-backup'\n  service:\n    name: 'openstack-cinder-backup'\n    state: restarted\n\n- name: 'restart openstack-cinder-scheduler'\n  service:\n    name: 'openstack-cinder-scheduler'\n    state: restarted\n\n- name: 'restart openstack-cinder-volume'\n  service:\n    name: 'openstack-cinder-volume'\n    state: restarted\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "5501299f24fd600076d296da33911f831f17070f", "filename": "roles/ansible/tower/manage-job-templates/tests/inventory/group_vars/tower.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nansible_tower:\n  admin_password: \"admin01\"\n  job_templates:\n  - name: \"Job 1\"\n    description: \"My Job 1\"\n    inventory: \"Inventory1\"\n    project: \"Project1\"\n    playbook: \"playbooks/prep.yml\"\n    credential: \"Cred1\"\n    extra_vars: \"---\\\\nhello: world\\\\n\"\n    ask_variables_on_launch: true\n    permissions:\n      teams:\n      - name: team1\n        role: Execute\n      users:\n      - name: user1\n        role: Execute\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "7842cfcf0789aa0d4b8cf9103d7379624ceb82b4", "filename": "roles/openvpn/templates/announcer", "repository": "iiab/iiab", "decoded_content": "#!/bin/bash -x\n# small daemon to identify this machine to the openvpn server\n\nHANDLE=\nUUID=\nsource /etc/iiab/iiab.env\nif [ -z \"$HANDLE\" ]; then\n   HANDLE=`cat /etc/iiab/iiab.ini | gawk \\\n\t'{ if((toupper($1) == \"HANDLE\") && ($2 == \"=\")) { print $3;}}'`\nfi\nif [ -z \"$HANDLE\" ]; then\n   if [ -f /etc/iiab/handle ]; then\n   HANDLE=`cat /etc/iiab/handle`\n   fi\nfi\nif [ -f /etc/iiab/uuid ]; then\n   UUID=`cat /etc/iiab/uuid`\nfi\n# start the daemon which will serve the handle on demand\nsource /etc/init.d/functions\nSERVER=/usr/bin/ncat\nPID_FILE=/var/run/openvpn/announce.pid\nHANDLE=${HANDLE// /_}\n{% if is_debuntu %}\nID=`printf \"HANDLE = %s|UUID = %s|\" $HANDLE $UUID`\n$SERVER -l -k -p1705 --exec \"/bin/echo $ID\" &\n{% else %}\ndaemon --pidfile=${PID_FILE} $SERVER \"-l -k -p1705 --exec \\\"/usr/bin/echo $(printf 'HANDLE = %s|UUID = %s' $HANDLE $UUID)\\\"\" &\n{% endif %}\n"}, {"commit_sha": "af1b4f6c5adde980e027a8b8f38684b11ffbfa19", "sha": "28ea31cd347783c0534dd2a233871225af1d3980", "filename": "tasks/run.yml", "repository": "cytopia/ansible-role-cloudformation", "decoded_content": "---\n\n###\n### Set a sane name for the rendered file\n###\n- name: register a sane template name\n  set_fact:\n    cloudformation_file_name: \"{{ cloudformation.template | basename }}-{{ cloudformation.stack_name }}.yml\"\n  check_mode: False\n\n\n###\n### Render cloudformation jinja2 template into the build directory\n###\n- name: ensure cloudformation template is rendered\n  template:\n    src: \"{{ cloudformation.template }}\"\n    dest: \"{{ cloudformation_build_dir_path }}/{{ cloudformation_file_name }}\"\n    mode: 0644\n    force: True\n  changed_when: False\n  check_mode: False\n\n\n###\n### Diff rendered cloudformation template (check mode only)\n###\n- name: diff cloudformation template parameters\n  cloudformation_diff:\n    ignore_hidden_params: True\n    ignore_final_newline: False\n    output_format: \"{{ cloudformation_diff_output }}\"\n    output_choice: parameter\n    stack_name: \"{{ cloudformation.stack_name }}\"\n    template: \"{{ cloudformation_build_dir_path }}/{{ cloudformation_file_name }}\"\n    template_tags: \"{{ cloudformation.tags | default(omit) }}\"\n    template_parameters: \"{{ cloudformation.template_parameters | default(omit) }}\"\n    aws_access_key: \"{{ cloudformation.aws_access_key | default(cloudformation_defaults.aws_access_key | default(omit)) }}\"\n    aws_secret_key: \"{{ cloudformation.aws_secret_key | default(cloudformation_defaults.aws_secret_key | default(omit)) }}\"\n    security_token: \"{{ cloudformation.security_token | default(cloudformation_defaults.security_token | default(omit)) }}\"\n    profile: \"{{ cloudformation.profile | default(cloudformation_defaults.profile | default(omit)) }}\"\n    region: \"{{ cloudformation.region | default(cloudformation_defaults.region | default(omit)) }}\"\n  when: not cloudformation_generate_only and cloudformation_run_diff\n  check_mode: False\n\n- name: diff cloudformation template file\n  cloudformation_diff:\n    ignore_hidden_params: True\n    ignore_final_newline: False\n    output_format: \"{{ cloudformation_diff_output }}\"\n    output_choice: template\n    stack_name: \"{{ cloudformation.stack_name }}\"\n    template: \"{{ cloudformation_build_dir_path }}/{{ cloudformation_file_name }}\"\n    template_tags: \"{{ cloudformation.tags | default(omit) }}\"\n    template_parameters: \"{{ cloudformation.template_parameters | default(omit) }}\"\n    aws_access_key: \"{{ cloudformation.aws_access_key | default(cloudformation_defaults.aws_access_key | default(omit)) }}\"\n    aws_secret_key: \"{{ cloudformation.aws_secret_key | default(cloudformation_defaults.aws_secret_key | default(omit)) }}\"\n    security_token: \"{{ cloudformation.security_token | default(cloudformation_defaults.security_token | default(omit)) }}\"\n    profile: \"{{ cloudformation.profile | default(cloudformation_defaults.profile | default(omit)) }}\"\n    region: \"{{ cloudformation.region | default(cloudformation_defaults.region | default(omit)) }}\"\n  when: not cloudformation_generate_only and cloudformation_run_diff\n  check_mode: False\n\n\n###\n### Run rendered cloudformation template\n###\n- name: ensure cloudformation stack is present\n  cloudformation:\n    stack_name: \"{{ cloudformation.stack_name }}\"\n    state: present\n    template: \"{{ cloudformation_build_dir_path }}/{{ cloudformation_file_name }}\"\n\n    aws_access_key: \"{{ cloudformation.aws_access_key | default(cloudformation_defaults.aws_access_key | default(omit)) }}\"\n    aws_secret_key: \"{{ cloudformation.aws_secret_key | default(cloudformation_defaults.aws_secret_key | default(omit)) }}\"\n    security_token: \"{{ cloudformation.security_token | default(cloudformation_defaults.security_token | default(omit)) }}\"\n    profile: \"{{ cloudformation.profile | default(cloudformation_defaults.profile | default(omit)) }}\"\n    region: \"{{ cloudformation.region | default(cloudformation_defaults.region | default(omit)) }}\"\n    notification_arns: \"{{ cloudformation.notification_arns | default(cloudformation_defaults.notification_arns | default(omit)) }}\"\n    template_parameters: \"{{ cloudformation.template_parameters | default(omit) }}\"\n    tags: \"{{ cloudformation.tags | default(omit) }}\"\n  when: not cloudformation_generate_only\n"}, {"commit_sha": "c0bf4b7577771e6d9cd9f162e7588a1a8f8e302e", "sha": "13c49e157aaa9d82f7a4e2650f711584d356d9e7", "filename": "tasks/install-pre5.yml", "repository": "geerlingguy/ansible-role-solr", "decoded_content": "---\n# Install Solr.\n- name: Check if Solr is already installed.\n  stat: \"path={{ solr_install_path }}/dist/{{ solr_filename }}.war\"\n  register: solr_war_file\n\n- name: Copy Solr into place.\n  command: \"cp -r {{ solr_workspace }}/{{ solr_filename }} {{ solr_install_path }}\"\n  when: not solr_war_file.stat.exists\n\n- name: Ensure Solr install files are owned by the solr_user.\n  file:\n    path: \"{{ solr_install_path }}\"\n    owner: \"{{ solr_user }}\"\n    group: \"{{ solr_user }}\"\n    recurse: yes\n  when: not solr_war_file.stat.exists\n\n# Set up solr_home.\n- name: Check if solr_home is already set up.\n  stat: \"path={{ solr_home }}/solr.xml\"\n  register: solr_example\n\n- name: Ensure solr_home directory exists.\n  file:\n    path: \"{{ solr_home }}\"\n    state: directory\n    owner: \"{{ solr_user }}\"\n    group: \"{{ solr_user }}\"\n    mode: 0755\n  when: not solr_example.stat.exists\n\n- name: Copy Solr example into solr_home.\n  shell: \"cp -r {{ solr_install_path }}/example/solr/* {{ solr_home }}\"\n  when: not solr_example.stat.exists\n\n- name: Fix the example solrconfig.xml file.\n  replace:\n    dest: \"{{ solr_home }}/collection1/conf/solrconfig.xml\"\n    regexp: ^.+solr\\.install\\.dir.+$\n    replace: \"\"\n  when: \"not solr_example.stat.exists and solr_version.split('.')[0] == '4'\"\n\n- name: Ensure Solr home files are owned by the solr_user.\n  file:\n    path: \"{{ solr_home }}\"\n    owner: \"{{ solr_user }}\"\n    group: \"{{ solr_user }}\"\n    recurse: yes\n  when: not solr_example.stat.exists\n\n# Set up Solr init script.\n- name: Ensure log file is created and has proper permissions.\n  file:\n    path: \"/var/log/solr.log\"\n    state: touch\n    owner: \"{{ solr_user }}\"\n    group: root\n    mode: 0664\n  changed_when: false\n\n- name: Copy solr init script into place.\n  template:\n    src: \"solr-init-{{ ansible_os_family }}-pre5.j2\"\n    dest: \"/etc/init.d/{{ solr_service_name }}\"\n    mode: 0755\n\n- name: Ensure daemon is installed (Debian).\n  apt: name=daemon state=installed\n  when: ansible_os_family == \"Debian\"\n\n- name: Copy solr systemd unit file into place (for systemd systems).\n  template:\n    src: solr.unit.j2\n    dest: /etc/systemd/system/solr.service\n    owner: root\n    group: root\n    mode: 0755\n  when: >\n    (ansible_distribution == 'Ubuntu' and ansible_distribution_version == '16.04') or\n    (ansible_distribution == 'Debian' and ansible_distribution_version|int >= 8) or\n    (ansible_distribution == 'CentOS' and ansible_distribution_major_version >= 7) or\n    (ansible_distribution == 'Fedora')\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "8d696f5e4a5321826fa77b20e0b2b67b29d1e820", "filename": "roles/awstats/templates/apache-awstats.conf", "repository": "iiab/iiab", "decoded_content": "#\n# Content of this file, with correct values, can be automatically added to\n# your Apache server by using the AWStats configure.pl tool.\n#\n\n\n# If using Windows and Perl ActiveStat, this is to enable Perl script as CGI.\n#ScriptInterpreterSource registry\n\n\n#\n# Directives to add to your Apache conf file to allow use of AWStats as a CGI.\n# Note that path \"/usr/share/awstats/\" must reflect your AWStats install path.\n#\nAlias /awstatsclasses \"/usr/share/awstats/wwwroot/classes/\"\nAlias /awstatscss \"/usr/share/awstats/wwwroot/css/\"\nAlias /awstatsicons \"/usr/share/awstats/wwwroot/icon/\"\nScriptAlias /awstats/ \"/usr/share/awstats/wwwroot/cgi-bin/\"\nScriptAlias /awstats \"/usr/share/awstats/wwwroot/\"\n\n\n#\n# This is to permit URL access to scripts/files in AWStats directory.\n#\n<Directory \"/usr/share/awstats/wwwroot\">\n    Options +ExecCGI -MultiViews +SymLinksIfOwnerMatch\n    AllowOverride None\n    DirectoryIndex awstats.pl\n        AuthType Basic\n        AuthName \"Admin Console\"\n        AuthBasicProvider external\n        AuthExternal pwauth\n        require valid-user\n</Directory>\n# Additional Perl modules\n<IfModule mod_env.c>\n    SetEnv PERL5LIB /usr/share/awstats/lib:/usr/share/awstats/plugins\n</IfModule>\n\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "261fd40a1c28396631c44c7da755ce451a89dacf", "filename": "tasks/section_03_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n#sections 3.3 and 3.4 have to happen before as the latter overwrite 3.1 and 3.2\n\n  - name: 3.0 Check for /boot/grub/grub.cfg file (Not Scored)\n    stat: path=/boot/grub/grub.cfg\n    register: grub_cfg_file\n    tags:\n      - section3\n\n  - name: 3.3.1.1 Set Boot Loader Superuser (check) (Scored)\n    command: grep \"^set superusers\" /boot/grub/grub.cfg\n    register: boot_superusers\n    when: grub_cfg_file.stat.exists == True\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section3\n      - section3.3\n      - section3.3.1\n      - section3.3.1.1\n\n  - name: 3.3.1.2 Set Boot Loader Superuser (Scored)\n    lineinfile: >\n        dest='/etc/grub.d/40_custom'\n        regexp='^set superusers'\n        line='set superusers=\"root\"'\n        state=present\n        create=yes\n    when: grub_cfg_file.stat.exists == True and boot_superusers.rc == 1\n    tags:\n      - section3\n      - section3.3\n      - section3.3.1\n      - section3.3.1.2\n\n  - name: 3.3.2.1 Set Boot Loader Password (check) (Scored)\n    command: grep \"^password\" /boot/grub/grub.cfg\n    register: boot_password\n    when: grub_cfg_file.stat.exists == True\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section3\n      - section3.3\n      - section3.3.2\n      - section3.3.2.1\n\n  - name: 3.3.2.2 Set Boot Loader Password (Scored)\n    lineinfile: >\n        dest='/etc/grub.d/40_custom'\n        regexp='^password'\n        line=\"password_pbkdf2 root {{root_password_grub}}\"\n        state=present\n    when: grub_cfg_file.stat.exists == True and boot_password.rc == 1\n    tags:\n      - section3\n      - section3.3\n      - section3.3.2\n      - section3.3.2.2\n\n  - name: 3.3.3 Disable password protection booting (Scored)\n    lineinfile: >\n        dest='/etc/grub.d/10_linux'\n        create=yes\n        regexp='^CLASS='\n        line='CLASS=\"--class gnu-linux --class gnu --class os --unrestricted\"'\n        state=present\n    tags:\n      - section3\n      - section3.3\n      - section3.3.3\n\n\n  - name: 3.3.4 Update Grub configuration (Scored)\n    command: update-grub\n    when: grub_cfg_file.stat.exists == True and (boot_superusers.rc == 1 or boot_password.rc == 1)\n    tags:\n      - section3\n      - section3.3\n      - section3.3.4\n\n\n  - name: 3.4.1 Require Authentication for Single-User Mode (check) (Scored)\n    shell: 'grep \"^root:[*\\!]:\" /etc/shadow'\n    register: root_password_set\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section3\n      - section3.4\n      - section3.4.1\n\n  - name: 3.4.2 Require Authentication for Single-User Mode (Scored)\n    user: name=root state=present password='{{ root_password }}'\n    when: root_password_set.rc == 1\n    tags:\n      - section3\n      - section3.4\n      - section3.4.2\n\n  - name: 3.1 Set User/Group Owner on bootloader config (Scored)\n    file: path=/boot/grub/grub.cfg owner=root group=root\n    when: grub_cfg_file.stat.exists == True\n    tags:\n      - section3\n      - section3.1\n\n  - name: 3.2 Set Permissions on bootloader config (Scored)\n    file: path=/boot/grub/grub.cfg mode=\"o-rwx,g-rwx\"\n    when: grub_cfg_file.stat.exists == True\n    become: yes\n    tags:\n      - section3\n      - section3.2\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "0271190cf909c51198555b6b44bf03a042256155", "filename": "roles/mongodb/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Install mongodb required packages\n  package: name={{ item }}\n           state=present\n  with_items:\n    - mongodb-server\n    - mongodb\n  when: internet_available\n  tags:\n    - download\n\n- name: create the data directory for mongodb\n  file: state=directory\n        path={{ item.path }}\n        owner=mongodb\n  with_items:\n     - { path: '/var/run/mongodb' }\n     - { path: '/library/dbdata/mongodb' }\n     - { path: '/var/log/mongodb' }\n\n- name: Create systemd files\n  template: src={{ item.src }}\n            dest={{ item.dest }}\n            owner=root\n            group=root\n            mode=0644\n  with_items:\n     - { src: 'mongodb.service' , dest: '/etc/systemd/system/' }\n     - { src: 'mongodb' , dest: '/etc/sysconfig/'}\n     - { src: 'mongod.conf' , dest: '/etc/mongod.conf'}\n     - { src: 'mongod.conf' , dest: '/etc/mongodb.conf'}\n\n- name: enable services\n  service: name={{ item.name }}\n           enabled=yes\n           state=restarted\n  with_items:\n      - { name: mongodb }\n  when: mongodb_enabled\n\n- name: disable services\n  service: name={{ item.name }}\n           enabled=no\n           state=stopped\n  with_items:\n      - { name: mongodb }\n  when: not mongodb_enabled\n\n# See https://github.com/iiab/iiab/issues/254 for other attempts to eliminate\n# these 256MB files. Brute Force Idea: rm /var/lib/mongodb/journal/prealloc.*\n- name: find /var/lib/mongodb/prealloc.* files to delete\n  find:\n    paths: /var/lib/mongodb/journal\n    patterns: prealloc.*\n  register: files_to_delete\n\n- name: delete prealloc files\n  file:\n    path: \"{{ item.path }}\"\n    state: absent\n  with_items: \"{{ files_to_delete.files }}\"\n\n- name: add mongodb to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=mongodb\n            option='{{ item.option }}'\n            value='\"{{ item.value }}\"'\n  with_items:\n       - option: name\n         value: MongoDB\n       - option: description\n         value: '\"MongoDB is an open-source document database that provides high performance, high availability, and automatic scaling.\"'\n       - option: enabled\n         value: \"{{ mongodb_enabled }}\"\n"}, {"commit_sha": "f3dd45a61b08de1b3351140cc442a705cb2fad82", "sha": "402404e3f88ff086997de81a606372598401ad90", "filename": "tasks/main.yml", "repository": "geerlingguy/ansible-role-security", "decoded_content": "---\n- name: Include OS-specific variables.\n  include_vars: \"{{ ansible_os_family }}.yml\"\n\n# Fail2Ban\n- include_tasks: fail2ban-RedHat.yml\n  when:\n    - ansible_os_family == 'RedHat'\n    - security_fail2ban_enabled | bool\n\n- include_tasks: fail2ban-Debian.yml\n  when:\n    - ansible_os_family == 'Debian'\n    - security_fail2ban_enabled | bool\n\n- name: Ensure fail2ban is running and enabled on boot.\n  service: name=fail2ban state=started enabled=yes\n  when: security_fail2ban_enabled | bool\n\n# SSH\n- include_tasks: ssh.yml\n\n# Autoupdate\n- include_tasks: autoupdate-RedHat.yml\n  when:\n    - ansible_os_family == 'RedHat'\n    - security_autoupdate_enabled | bool\n\n- include_tasks: autoupdate-Debian.yml\n  when:\n    - ansible_os_family == 'Debian'\n    - security_autoupdate_enabled | bool\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "b864f94a27ecb2969b1be76fbe57907312d3eaa7", "filename": "playbooks/templates/nginx-rock.conf.j2", "repository": "rocknsm/rock", "decoded_content": "server {\n    listen 443 ssl;\n\n    server_name {{ rock_hostname }};\n    server_name _;\n\n    ssl on;\n    ssl_certificate     /etc/pki/bundle.crt;\n    ssl_certificate_key /etc/pki/bundle.key;\n    ssl_protocols       TLSv1 TLSv1.1 TLSv1.2;\n    #ssl_ciphers         HIGH:!aNULL:!MD5;\n    ssl_ciphers 'ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA';\n    ssl_prefer_server_ciphers on;\n    ssl_dhparam\t\t/etc/pki/dh2048.pem;\n\n    auth_basic \"Restricted Access\";\n    auth_basic_user_file /etc/nginx/htpasswd.users;\n\n    location / {\n        proxy_pass http://localhost:5601;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection 'upgrade';\n        proxy_set_header Host $host;\n        proxy_cache_bypass $http_upgrade;\n    }\n}\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "93080cdaea917573cd5a5b6c59862ab3d82d4b9a", "filename": "roles/dns/manage-dns-zones/tasks/named/generate_keys.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Build a list of view/zone items\n  set_fact:\n    dns_views: \"{{ dns_views | default([]) + [ item.0.name + '-' + item.1.dns_domain ] }}\"\n  with_subelements:\n    - \"{{ dns_data.views }}\"\n    - zones\n\n- name: Get existing key files\n  shell: 'ls -1 K{{ item }}*.key | sed -ne \"s/K\\({{ item }}\\).*.key/\\1/p\"'\n  args:\n    chdir: /var/named/\n  register: key_files\n  ignore_errors: yes\n  with_items:\n    - \"{{ dns_views }}\"\n\n- name: Build list of existing key files\n  set_fact:\n    existing_key_files: \"{{ existing_key_files | default([]) + [ item.stdout ] }}\"\n  with_items:\n    - \"{{ key_files.results }}\"\n\n- name: Generate keys for nsupdate\n  command: >\n    /sbin/dnssec-keygen\n      -a {{ dnssec_keygen_algorithm | default(default_dnssec_keygen_algorithm) }}\n      -b {{ dnssec_keygen_size | default(default_dnssec_keygen_size) }}\n      -n USER\n      -r /dev/urandom\n      -K /var/named {{ item }}\n  with_items:\n    - \"{{ dns_views }}\"\n  when:\n    - item not in existing_key_files\n\n- name: Gather keys for nsupdate\n  shell: \"grep Key: /var/named/K{{ item }}*.private | cut -d ' ' -f 2\"\n  register: nsupdate_keys_captured\n  with_items:\n    - \"{{ dns_views }}\"\n\n# Build the dict with the proper keys, i.e.:\n#    private-view.example.com:\n#      algorithm: HMAC-MD5\n#      secret: SKqKNdpfk7llKxZ57bbxUnUDobaaJp9t8CjXLJPl+fRI5mPcSBuxTAyvJPa6Y9R7vUg9DwCy/6WTpgLNqnV4Hg==\n#    public-view.example.com:\n#      algorithm: HMAC-MD5\n#      secret: kVE2bVTgZjrdJipxPhID8BEZmbHD8cExlVPR+zbFpW6la8kL5wpXiwOh8q5AAosXQI5t95UXwq3Inx8QT58duw==\n- name: Set nsupdate_keys fact\n  set_fact:\n    nsupdate_keys: \"{{ nsupdate_keys | default({}) | combine({ item.item : { 'key_algorithm': ( dnssec_keygen_algorithm | default(default_dnssec_keygen_algorithm) ), 'key_secret': item.stdout } }) }}\"\n  with_items: \"{{ nsupdate_keys_captured.results }}\"\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "77dd9d7f9d3a73f8ffbb0cea7fbb773ba39fd269", "filename": "tasks/create_repo_maven_group_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include: call_script.yml\n  vars:\n    script_name: create_repo_maven_group\n    args: \"{{ _nexus_repos_maven_defaults|combine(item) }}\""}, {"commit_sha": "045ff4bb9f4720739632aac2951fbf2798a99c8c", "sha": "bf5893194142110fa71036825ef4c3a70eaaa192", "filename": "roles/dns_adblocking/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: Gather Facts\n  setup:\n\n- name: Dnsmasq installed\n  apt: name=dnsmasq state=latest\n\n- name: Dnsmasq profile for apparmor configured\n  template: src=usr.sbin.dnsmasq.j2 dest=/etc/apparmor.d/usr.sbin.dnsmasq owner=root group=root mode=0600\n  when: apparmor_enabled is defined and apparmor_enabled == true\n  notify:\n    - restart dnsmasq\n\n- name: The dnsmasq directory created\n  file: dest=/var/lib/dnsmasq state=directory mode=0755 owner=dnsmasq group=nogroup\n\n- name: Enforce the dnsmasq AppArmor policy\n  shell: aa-enforce usr.sbin.dnsmasq\n  when: apparmor_enabled is defined and apparmor_enabled == true\n  tags: ['apparmor']\n\n- name: Ensure that the dnsmasq service directory exist\n  file: path=/etc/systemd/system/dnsmasq.service.d/ state=directory mode=0755  owner=root group=root\n\n- name: Setup the cgroup limitations for the ipsec daemon\n  template: src=100-CustomLimitations.conf.j2 dest=/etc/systemd/system/dnsmasq.service.d/100-CustomLimitations.conf\n  notify:\n    - daemon-reload\n    - restart dnsmasq\n\n- meta: flush_handlers\n\n- name: Dnsmasq configured\n  template: src=dnsmasq.conf.j2 dest=/etc/dnsmasq.conf\n  notify:\n    - restart dnsmasq\n\n- name: Adblock script created\n  template: src=adblock.sh dest=/opt/adblock.sh owner=root group=root mode=0755\n\n- name: Adblock script added to cron\n  cron:\n    name: Adblock hosts update\n    minute: 10\n    hour: 2\n    job: /opt/adblock.sh\n    user: dnsmasq\n\n- name: Update adblock hosts\n  shell: >\n    /opt/adblock.sh\n  become: true\n  become_user: dnsmasq\n\n- name: Dnsmasq enabled and started\n  service: name=dnsmasq state=started enabled=yes\n\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "99bd89446804cce3b7c8341f960cb66544afeb9e", "filename": "roles/common/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Validate Ansible version\n  fail:\n    msg: |\n      Your Ansible version is {{ ansible_version.full | default('unknown') }}.\n      Please install a version of Ansible that meets these requirements:\n      {% for item in ansible_requirements %}\n        {{ item.operator }} {{ item.version }}\n      {% endfor %}\n  when: ansible_version is not defined or false in [{% for item in ansible_requirements %}{{ ansible_version.full | version_compare(item.version, item.operator) }},{% endfor %}]\n  run_once: true\n\n- name: Validate format of site_hosts\n  fail:\n    msg: \"{{ lookup('template', 'site_hosts.j2') }}\"\n  with_dict: \"{{ wordpress_sites }}\"\n  when: item.value.site_hosts | rejectattr('canonical', 'defined') | list | count\n  tags: [letsencrypt, wordpress]\n\n- name: Validate Ubuntu version\n  debug:\n    msg: |\n      Trellis is built for Ubuntu 16.04 Xenial as of https://github.com/roots/trellis/pull/626\n\n      Your Ubuntu version is {{ ansible_distribution_version }} {{ ansible_distribution_release }}\n\n      We recommend you re-create your server to get the best experience.\n\n      Note: both of these methods will delete all your existing data. It's up to you to backup what's needed and restore it.\n\n      Development via Vagrant: `vagrant destroy && vagrant up`\n\n      Staging/Production: Create a new server with Ubuntu 16.04 and provision\n  when: ansible_distribution_release == 'trusty'\n  run_once: true\n\n- name: Update Apt\n  apt:\n    update_cache: yes\n\n- name: Checking essentials\n  apt:\n    name: \"{{ item }}\"\n    state: present\n  with_items:\n  - python-software-properties\n  - python-pycurl\n  - build-essential\n  - python-mysqldb\n  - curl\n  - git-core\n  - dbus\n\n- name: Validate timezone variable\n  stat:\n    path: /usr/share/zoneinfo/{{ default_timezone }}\n  register: timezone_path\n  changed_when: false\n\n- name: Explain timezone error\n  fail:\n    msg: \"{{ default_timezone }} is not a valid timezone. For a list of valid timezones, check https://php.net/manual/en/timezones.php\"\n  when: not timezone_path.stat.exists\n\n- name: Get current timezone\n  command: cat /etc/timezone\n  register: current_timezone\n  changed_when: false\n\n- name: Set timezone\n  command: timedatectl set-timezone {{ default_timezone }}\n  when: current_timezone.stdout != default_timezone\n"}, {"commit_sha": "1224adf2811c827a09ff0bf133fbb476901a547d", "sha": "28b4bf010226a17e035b8c5a9775c8a8dfc6b8b3", "filename": "tasks/openbsd_prepare.yml", "repository": "nusenu/ansible-relayor", "decoded_content": "---\n\n- name: Gather current system-wide file descriptor limits (OpenBSD)\n  shell: \"sysctl kern.maxfiles|cut -d= -f2\"\n  register: currentlimits\n\n- name: Ensure system-wide runtime file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  command: \"sysctl kern.maxfiles=20000\"\n  when: currentlimits.stdout|int < 20000\n\n- name: Ensure system-wide persistent file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  lineinfile:\n    dest: /etc/sysctl.conf\n    regexp: ^kern.maxfiles\n    line: \"kern.maxfiles=20000\"\n    create: yes\n  when: currentlimits.stdout|int < 20000\n\n# We rise openfiles limits for every tor instance separately.\n# An instance is identified by its rc.d file name.\n- name: Ensure Tor process file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  lineinfile:\n    dest: /etc/login.conf\n    line: \"tor{{ item.0.ipv4| replace('.','_') }}_{{ item.1.orport }}::openfiles-max=13500::tc=daemon:\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "967693af2b1fbcad312af34f2e69519e9f4f8247", "filename": "roles/config-iscsi-client/tasks/iscsi-config.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Ensure the iSCSI initiatorname is set correctly\"\n  lineinfile:\n    path: /etc/iscsi/initiatorname.iscsi\n    regexp: '^InitiatorName='\n    line: 'InitiatorName={{ iscsi_initiatorname }}'\n    create: yes\n    owner: root\n    group: root\n    mode: 0644\n    state: present\n\n- name: \"Ensure the iSCSI service is running (and restarted)\"\n  service:\n    name: iscsid\n    state: restarted\n\n- name: \"Discover and Login to the available iSCSI targets\"\n  open_iscsi:\n    portal: '{{ iscsi_target }}'\n    login: yes\n    discover: yes\n    auto_node_startup: yes\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "22cd3c5f6761aacd57d2609577cf7ed3cf39602e", "filename": "roles/ansible/tower/manage-projects/tasks/process-project.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Get the org id based on the org name\"\n  set_fact:\n    org_id: \"{{ item.id }}\"\n  when:\n  - item.name|trim == project.organization|trim\n  with_items:\n  - \"{{ existing_organizations_output.rest_output }}\"\n\n- name: \"Load up the project\"\n  uri:\n    url: https://localhost/api/v2/projects/\n    method: POST\n    body: \"{{ lookup('template', 'project.j2') }}\"\n    body_format: 'json'\n    headers:\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n    user: admin\n    password: \"{{ tower_admin_password }}\"\n    validate_certs: no\n    status_code: 200,201,400\n  register: project_output\n\n- name: \"Clear/Update facts\"\n  set_fact:\n    org_id: ''\n    processed_projects: \"{{ processed_projects + [ { 'name': project.name } ] }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "c6dd75ebf1696169bb6f44d81fc218f47167e526", "filename": "playbooks/manage-jira/manage-jira.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- hosts: jira\n  roles:\n    - manage-jira\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "6c1c579e73a438e4ecf19ea23c0e373e8640cb27", "filename": "roles/dhcp/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n# handlers file for dhcp-config\n- name: 'dhcp-config cleanup temp'\n  delegate_to: localhost\n  file:\n    path: '{{ dhcp_config_dir.path }}'\n    state: absent\n\n- name: 'cleanup dhcp tmp file'\n  file:\n    path: '{{ dhcp_config_temp_loc }}'\n    state: absent\n\n- name: 'reload dhcp'\n  service:\n    name: '{{ item }}'\n    state: restarted\n  with_items:\n  - dhcpd\n  when: \n  - dhcp_service_enabled|default(True)\n\n- name: 'enable and start dhcp services'\n  service:\n    name: '{{ item }}'\n    enabled: yes\n    state: started\n  with_items:\n  - dhcpd\n  when: \n  - dhcp_service_enabled|default(True) \n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "231b3a5673a98ee8eeced4122d9d5afe64a338d7", "filename": "playbooks/openshift/install.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n- import_playbook: \"{{ openshift_ansible_path | default('../../roles/openshift-ansible') }}/playbooks/byo/config.yml\"\n"}, {"commit_sha": "0c050ee7f22968afdb69da3b859869efea2bfffa", "sha": "63c2979fd0fd9618aff115f62da37c34ad8c8b51", "filename": "meta/container.yml", "repository": "geerlingguy/ansible-role-solr", "decoded_content": "# See: https://github.com/geerlingguy/solr-container\nsolr:\n  from: \"debian:9\"\n  ports:\n    - \"8983:8983\"\n  command: [\"/opt/solr/bin/solr\", \"start\", \"-f\", \"-force\"]\n  roles:\n    - geerlingguy.java\n    - geerlingguy.solr\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "947e4646c3744ae0e2e135de7f812dfb57477103", "filename": "roles/config-repo-server/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- include_role:\n    name: config-httpd\n\n- import_tasks: mount-iso.yml\n\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "6ebb4267f982f00bfd0bdb91982ceb1fce0e363c", "filename": "roles/mariadb/defaults/main.yml", "repository": "roots/trellis", "decoded_content": "keyserver_fingerprint: \"0xcbcb082a1bb943db\"\nmirror: nyc2.mirrors.digitalocean.com\nversion: \"10.0\"\nbinary_logging_disabled: true\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "abd59e0a7a118c1a9872f7453f88a609d73ce6a5", "filename": "playbooks/openshift/provision-instances.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n# Provision Openstack Instances\n- import_playbook: openstack/provision.yml\n  when: hosting_infrastructure == \"openstack\"\n\n# Provision Openstack Instances\n- import_playbook: aws/provision.yml\n  when: hosting_infrastructure == \"aws\"\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "cc87984a790101bf764904982ad10f3a1ddad4b4", "filename": "roles/ovirt-engine-setup/defaults/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\novirt_engine_dwh: True\novirt_engine_type: 'ovirt-engine'\novirt_engine_version: '4.1'\novirt_engine_admin_password: '123456'\n\novirt_engine_db_host: 'localhost'\novirt_engine_db_port: 5432\novirt_engine_db_name: 'engine'\novirt_engine_db_user: 'engine'\novirt_engine_db_password: 'AqbXg4dpkbcVRZwPbY8WOR'\n\novirt_engine_dwh_db_host: 'localhost'\novirt_engine_dwh_db_port: 5432\novirt_engine_dwh_db_name: 'ovirt_engine_history'\novirt_engine_dwh_db_user: 'ovirt_engine_history'\novirt_engine_dwh_db_password: '37xmBKECANQGm0z3SfylMp'\n\novirt_engine_configure_iso_domain: false\novirt_engine_iso_domain_path: '/var/lib/exports/iso'\novirt_engine_iso_domain_name: 'ISO_DOMAIN'\novirt_engine_iso_domain_acl: '0.0.0.0/0.0.0.0(rw)'\n\novirt_engine_firewall_manager: 'firewalld'\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "81800958af84f562e49b02e1f3d3ccaf23bdfa26", "filename": "roles/marathon/vars/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# vars file for marathon\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "8f6714fe2fc4a463753e82c37958de6dbe11277e", "filename": "playbooks/files/stenographer@.service", "repository": "rocknsm/rock", "decoded_content": "# Copyright 2014 Google Inc. All rights reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n# stenographer - full packet to disk capture\n#\n# stenographer is a simple, fast method of writing live packets to disk,\n# then requesting those packets after-the-fact for post-hoc analysis.\n\n[Unit]\nDescription=packet capture to disk\nAfter=network.target\nPartOf=stenographer.service\nReloadPropagatedFrom=stenographer.service\n\n[Service]\nUser=stenographer\nGroup=stenographer\nSyslogIdentifier=stenographer\nLimitFSIZE=4294967296\nLimitNOFILE=1000000\nExecStart=/usr/bin/stenographer -config /etc/stenographer/config.%i\nExecStopPost=/bin/pkill -9 stenotype\n\n[Install]\nWantedBy=stenographer.service\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "e1d5af288f14d93dd45772e6127db8807e6c3a70", "filename": "playbooks/roles/check_cleanup/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- name: Stop nc from listening\n  shell: \"pkill -f 'nc -l'\"\n  ignore_errors: true\n- name: Ensure nc absent\n  yum:\n    name: nc\n    state: absent\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "ad03902b984d9e0cbf6d12479da9006124779350", "filename": "roles/ovirt-collect-logs/tasks/dwh.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\n- name: Link DWH logs\n  file:\n    src: \"{{ item.src }}\"\n    dest: \"{{ ovirt_collect_logs_tmp_dir }}/{{ item.dest }}\"\n    state: link\n  with_items:\n    - { src: \"/var/log/ovirt-engine-dwh\", dest: \"ovirt-engine-dwh-logs\" }\n    - { src: \"/var/lib/ovirt-engine-dwh\", dest: \"ovirt-engine-dwh-data\" }\n    - { src: \"/etc/ovirt-engine-dwh\", dest: \"ovirt-engine-dwh-etc\" }\n  ignore_errors: true\n\n- name: Dump DWH database\n  shell: \"su - postgres -c 'pg_dump ovirt_engine_history > {{ ovirt_collect_logs_tmp_dir }}/dwh_db.sql'\"\n  ignore_errors: true\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "9421a919ca979b46d8bcc1a0f96f24fc7bb0329e", "filename": "roles/teamviewer/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Teamviewer exclude ARM and debian family\n  set_fact:\n    teamviewer_install: False\n    teamviewer_enabled: \"unavailable\"\n  when: ansible_architecture == \"armv7l\" or not is_redhat\n\n- name: Install Teamviewer if intel\n  include: install.yml\n  when: teamviewer_install\n\n- name: Add teamviewer to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=teamviewer\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: teamviewer\n    - option: description\n      value: '\"TeamViewer - the All-In-One Software for Remote Support and Online Meetings\"'\n    - option: installed\n      value: \"{{ teamviewer_install }}\"\n    - option: enabled\n      value: \"{{ teamviewer_enabled }}\"\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "c15065e1a7ee01e1c1e567bd2d3b8e0465dd6964", "filename": "playbooks/roles/bb0-openstack/tasks/provisioning-pre-once.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "---\n\n- name: \"{{ playbook_dir }}\"\n  command: \"ssh-keygen -t rsa -f {{ playbook_dir }}/id_rsa -P ''\"\n  args:\n    creates: \"{{ playbook_dir }}/id_rsa\"\n\n- name: Add ssh\n  os_keypair:\n    auth:\n      auth_url: \"{{ lookup('env','OS_AUTH_URL') }}\"\n      project_name: \"{{ lookup('env','OS_PROJECT_NAME') }}\"\n      username: \"{{ lookup('env','OS_USERNAME') }}\"\n      password: \"{{ lookup('env','OS_PASSWORD') }}\"\n    state: present\n    public_key_file: \"{{ playbook_dir }}/id_rsa.pub\"\n    name: openshift-stc-key\n\n- name: \"Create security groups\"\n  os_security_group:\n    name: \"{{item.name}}\"\n    description: \"secgroup {{ item.name }} - managed by ansible\"\n    auth:\n      auth_url: \"{{ lookup('env','OS_AUTH_URL') }}\"\n      project_name: \"{{ lookup('env','OS_PROJECT_NAME') }}\"\n      username: \"{{ lookup('env','OS_USERNAME') }}\"\n      password: \"{{ lookup('env','OS_PASSWORD') }}\"\n  with_items:\n     - \"{{ os_sec_groups }}\"\n\n- name: \"Create security group rules\"\n  os_security_group_rule:\n    auth:\n      auth_url: \"{{ lookup('env','OS_AUTH_URL') }}\"\n      project_name: \"{{ lookup('env','OS_PROJECT_NAME') }}\"\n      username: \"{{ lookup('env','OS_USERNAME') }}\"\n      password: \"{{ lookup('env','OS_PASSWORD') }}\"\n    security_group: \"{{ item.0.name }}\"\n    protocol: \"{{ item.1.proto }}\"\n    port_range_min: \"{{ item.1.port }}\"\n    port_range_max: \"{{ item.1.port }}\"\n    remote_ip_prefix: 0.0.0.0/0\n  with_subelements:\n    - \"{{ os_sec_groups }}\"\n    - rules\n\n\n# - stat: path=ose_host_key\n#   register: st\n\n# - os_keypair:\n#     auth:\n#       auth_url: \"{{ lookup('env','OS_AUTH_URL') }}\"\n#       project_name: \"{{ lookup('env','OS_PROJECT_NAME') }}\"\n#       username: \"{{ lookup('env','OS_USERNAME') }}\"\n#       password: \"{{ lookup('env','OS_PASSWORD') }}\"\n#     state: absent\n#     name: ose_host_key\n#   when: st.stat.exists == False\n\n# - os_keypair:\n#     auth:\n#       auth_url: \"{{ lookup('env','OS_AUTH_URL') }}\"\n#       project_name: \"{{ lookup('env','OS_PROJECT_NAME') }}\"\n#       username: \"{{ lookup('env','OS_USERNAME') }}\"\n#       password: \"{{ lookup('env','OS_PASSWORD') }}\"\n#     name: ose_host_key\n#   register: return\n#   when: st.stat.exists == False\n# - name: Save private key to {{inventory_dir}}\n#   copy:\n#     content: \"{{return.key.private_key}}\"\n#     dest: \"{{inventory_dir}}/{{return.key.name}}\"\n#     mode: 0600\n#   when: st.stat.exists == False\n\n# - name: Save public key to {{inventory_dir}}\n#   copy:\n#     content: \"{{return.key.public_key}}\"\n#     dest: \"{{inventory_dir}}/{{return.key.name}}.pub\"\n#   when: st.stat.exists == False\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "71af080a73ac6e4469a4777d18f6992f194bb21c", "filename": "roles/1-prep/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "# use these as a tag a release at a point in time\niiab_base_ver: 6.4\ngui_version: 2\n\n# These entries should never be changed in this file.\n# These are defaults for boolean routines, \nfirst_run: False\ninstalling: False\nNUC6_firmware_needed: False\nexFAT_enabled: False\nno_NM_reload: False\nhas_WAN: False\nwireless_lan_present: False\nstrict_networking: False\niiab_demo_mode: False\ngw_active: False\ngui_static_wan: False\ninternet_available: False\nis_F18: False\nis_F20: False\nis_F21: False\nis_F22: False\nis_F23: False\nis_F24: False\n\n# Set default for discovered hardware\ndriver_name: nl80211\nrpi_model: none\nis_rpi: False\nxo_model: none\nrtc_id: ds3231\n\n# Set defaults for discovery process as strings\nwifi1: \"not found-1\"\nwifi2: \"not found-2\"\ndiscovered_wan_iface: \"none\"\ndiscovered_lan_iface: \"none\"\ndiscovered_wireless_iface: \"none\"\niiab_wireless_lan_iface: \"none\"\niiab_lan_iface: \"none\"\niiab_wan_iface: \"none\"\ndevice_gw: \"none\"\nhas_ifcfg_gw: \"none\"\nhas_wifi_gw: \"none\"\nap_device: \"none\"\ndevice_gw2: \"\"\n\ngui_port: 80\n\n# must keep roles/iiab-admin/defaults/main.yml sync'd\nadmin_console_path: \"{{ iiab_base }}/admin_console\"\ncmdsrv_path: \"{{ iiab_base }}/iiab_cmdsrv\"\niiab_cmdsrv_dbname : \"iiab_cmdsrv.0.2.db\"\nwifi_id: none\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "1b82f23b8cb9a7e1c88bd2e9815981811d3bcb71", "filename": "roles/mongodb/templates/mongod.conf", "repository": "iiab/iiab", "decoded_content": "##\n### Basic Defaults\n##\n\n# Comma separated list of ip addresses to listen on (all local ips by default)\nbind_ip = 127.0.0.1\n\n# Specify port number (27017 by default)\nport = 27018\n\n# Fork server process (false by default)\nfork = true\n\n# Full path to pidfile (if not set, no pidfile is created)\npidfilepath = /var/run/mongodb/mongod.pid\n\n# Log file to send write to instead of stdout - has to be a file, not directory\nlogpath = /var/log/mongodb/mongod.log\n\n# Alternative directory for UNIX domain sockets (defaults to /tmp)\nunixSocketPrefix = /var/run/mongodb\n\n# Directory for datafiles (defaults to /data/db/)\ndbpath = /library/dbdata/mongodb\n\n# Enable/Disable journaling (journaling is on by default for 64 bit)\n#journal = true\n#nojournal = true\n\n\n\n##\n### General options\n##\n\n# Be more verbose (include multiple times for more verbosity e.g. -vvvvv) (v by default)\n#verbose = v\n\n# Max number of simultaneous connections (1000000 by default)\n#maxConns = 1000000              \n\n# Log to system's syslog facility instead of file or stdout (false by default)\n#syslog = true\n\n# Syslog facility used for monogdb syslog message (user by defautl)\n#syslogFacility = user\n\n# Append to logpath instead of over-writing (false by default)\n#logappend = true\n\n# Desired format for timestamps in log messages (One of ctime, iso8601-utc or iso8601-local) (iso8601-local by default)\n#timeStampFormat = arg  \n\n# Private key for cluster authentication\n#keyFile = arg\n\n# Set a configurable parameter\n#setParameter = arg\n\n# Enable http interface (false by default)\n#httpinterface = true\n\n# Authentication mode used for cluster authentication. Alternatives are (keyFile|sendKeyFile|sendX509|x509) (keyFile by default)\n#clusterAuthMode = arg\n\n# Disable listening on unix sockets (false by default)\n#nounixsocket = true\n\n# Run with/without security (without by default)\n#auth = true\n#noauth = true\n\n# Enable IPv6 support (disabled by default)\n#ipv6 = true\n\n# Allow JSONP access via http (has security implications) (false by default)\n#jsonp = true\n\n# Turn on simple rest api (false by default)\n#rest = true\n\n# Value of slow for profile and console log (100 by default)\n#slowms = 100\n\n# 0=off 1=slow, 2=all (0 by default)\n#profile = 0\n\n# Periodically show cpu and iowait utilization (false by default)\n#cpu = true\n\n# Print some diagnostic system information (false by default)\n#sysinfo = true\n\n# Each database will be stored in a separate directory (false by default)\n#directoryperdb = true\n\n# Don't retry any index builds that were interrupted by shutdown (false by default)\n#noIndexBuildRetry = true\n\n# Disable data file preallocation - will often hurt performance (false by default)\nnoprealloc = true\n\n# .ns file size (in MB) for new databases (16 MB by default)\n#nssize = 16\n\n# Limits each database to a certain number of files (8 default)\n#quota\n\n# Number of files allowed per db, implies --quota (8 by default)\n#quotaFiles = 8\n\n# Use a smaller default file size (false by default)\nsmallfiles = true\n\n# Seconds between disk syncs (0=never, but not recommended) (60 by default)\n#syncdelay = 60\n\n# Upgrade db if needed (false by default)\n#upgrade = true\n\n# Run repair on all dbs (false by default)\n#repair = true\n\n# Root directory for repair files (defaults to dbpath)\n#repairpath = arg\n\n# Disable scripting engine (false by default)\n#noscripting = true\n\n# Do not allow table scans (false by default)\n#notablescan = true\n\n# Journal diagnostic options (0 by default)\n#journalOptions = 0\n\n# How often to group/batch commit (ms) (100 or 30 by default)\n#journalCommitInterval = 100 \n\n\n\n##\n### Replication options\n##\n\n# Size to use (in MB) for replication op log (default 5% of disk space - i.e. large is good)\n#oplogSize = arg\n\n\n\n##\n### Master/slave options (old; use replica sets instead)\n##\n\n# Master mode\n#master = true\n\n# Slave mode\n#slave = true\n\n# When slave: specify master as <server:port>\n#source = arg\n\n# When slave: specify a single database to replicate\n#only = arg\n\n# Specify delay (in seconds) to be used when applying master ops to slave\n#slavedelay = arg\n\n# Automatically resync if slave data is stale\n#autoresync = true\n\n\n\n##\n### Replica set options\n##\n\n# Arg is <setname>[/<optionalseedhostlist>]\n#replSet = arg\n\n# Specify index prefetching behavior (if secondary) [none|_id_only|all] (all by default)\n#replIndexPrefetch = all\n\n\n\n##\n### Sharding options\n##\n\n# Declare this is a config db of a cluster (default port 27019; default dir /data/configdb) (false by default)\n#configsvr = true\n\n# Declare this is a shard db of a cluster (default port 27018)  (false by default)\n#shardsvr = true\n\n\n\n##\n### SSL options\n##\n\n# Use ssl on configured ports\n#sslOnNormalPorts = true\n\n# Set the SSL operation mode (disabled|allowSSL|preferSSL|requireSSL)\n# sslMode = arg\n\n# PEM file for ssl\n#sslPEMKeyFile = arg\n\n# PEM file password\n#sslPEMKeyPassword = arg\n\n# Key file for internal SSL authentication\n#sslClusterFile = arg\n\n# Internal authentication key file password\n#sslClusterPassword = arg\n\n# Certificate Authority file for SSL\n#sslCAFile = arg\n\n# Certificate Revocation List file for SSL\n#sslCRLFile = arg\n\n# Allow client to connect without presenting a certificate\n#sslWeakCertificateValidation = true\n\n# Allow server certificates to provide non-matching hostnames\n#sslAllowInvalidHostnames = true\n\n# Allow connections to servers with invalid certificates\n#sslAllowInvalidCertificates = true\n\n# Activate FIPS 140-2 mode at startup\n#sslFIPSMode = true\n\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "c802b6f2115904b2092f404aa9f3e86b260f1c5d", "filename": "meta/main.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\ngalaxy_info:\n  role_name: nginx\n  author: Alessandro Fael Garcia\n  description: Official Ansible role for NGINX\n  company: NGINX, Inc.\n\n  license: Apache License, Version 2.0\n\n  min_ansible_version: 2.4.0.0\n\n  platforms:\n    - name: Alpine\n      versions:\n        - all\n    - name: Amazon\n      versions:\n        - Candidate\n    - name: Debian\n      versions:\n        - jessie\n        - stretch\n        - buster\n    - name: EL\n      versions:\n        - 6\n        - 7\n    - name: FreeBSD\n      versions:\n        - 11.2\n        - 12.0\n    - name: Ubuntu\n      versions:\n        - xenial\n        - bionic\n    - name: SLES\n      versions:\n        - 12\n        - 15\n\n  galaxy_tags:\n    - nginx\n    - oss\n    - plus\n    - amplify\n    - controller\n    - unit\n    - web\n    - server\n    - development\n\ndependencies: []\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "7ec2b8458ab7be6df39dcc57dae5e92087c46aa1", "filename": "roles/ansible/tower/manage-inventories/tasks/process-host.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Load up the inventory (host)\"\n  uri:\n    url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}/api/v2/hosts/\"\n    user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n    password: \"{{ ansible_tower.admin_password }}\"\n    force_basic_auth: yes\n    method: POST\n    body: \"{{ lookup('template', 'host.j2') }}\"\n    body_format: 'json'\n    headers:\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n    validate_certs: no\n    status_code: 200,201,400\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "7401b1d5107476603dd21d166992f30038e13871", "filename": "roles/osp/admin-network/tests/inventory/group_vars/all.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nosp_networks:\n- name: \"my-network\"\n  description: \"My Network\"\n\nosp_subnets:\n- name: \"my-subnet\"\n  network_name: \"my-network\"\n  cidr: \"192.168.10.0/24\"\n  gateway_ip: \"192.168.10.1\"\n  allocation_pool_start: \"192.168.10.2\"\n  allocation_pool_end: \"192.168.10.254\"\n  dns_nameservers:\n  - \"192.168.1.11\"\n  - \"192.168.1.12\"\n\nosp_routers:\n- name: \"my-router\"\n  external_gateway: \"external\"\n  subnet: \"my-subnet\"\n"}, {"commit_sha": "7032aee7df1c2c6e96795067285efa3b2a6de32e", "sha": "5391ac1ffa3fe47af70afe50dd45b547abdf7cc7", "filename": "roles/dns-server/defaults/main.yml", "repository": "openshift/openshift-ansible-contrib", "decoded_content": "---\nnamed_config_views: []\nnamed_config_allow_query: []\nnamed_config_allow_transfer: []\n"}, {"commit_sha": "0c050ee7f22968afdb69da3b859869efea2bfffa", "sha": "8c899a30c36d076c5295997531ec4340f3a0842d", "filename": "tasks/user.yml", "repository": "geerlingguy/ansible-role-solr", "decoded_content": "---\n- name: Ensure solr_user group exists.\n  group: \"name={{ solr_user }} state=present\"\n\n- name: Ensure solr_user exists.\n  user:\n    name: \"{{ solr_user }}\"\n    state: present\n    group: \"{{ solr_user }}\"\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "252375d025a9d0addad6bc2336288021ba6b2862", "filename": "roles/ansible/tower/manage-inventories/tasks/process-host.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Load up the inventory (host)\"\n  uri:\n    url: https://localhost/api/v2/hosts/\n    method: POST\n    body: \"{{ lookup('template', 'host.j2') }}\"\n    body_format: 'json'\n    headers:\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n    user: admin\n    password: \"{{ tower_admin_password }}\"\n    validate_certs: no\n    status_code: 200,201,400\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "c208d11b188b8c0ade72e246541c0eb7f433ebf6", "filename": "roles/cfme-ocp-provider/tasks/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n- name: Fail if Required Parameters Not Provided\n  fail:\n    msg: \"Required Parameters have Not Been Provided\"\n  when: (cfme_host | trim == \"\") or (cfme_host is none) or (cfme_host is undefined) or (cfme_username | trim == \"\") or (cfme_username is none) or (cfme_username is undefined) or (cfme_password | trim == \"\") or (cfme_password is none) or (cfme_password is undefined)\n\n- name: Retrieve Default Service Account Token\n  command: >\n    oc serviceaccounts get-token -n {{ default_token_sa_namespace }} {{ default_token_sa_name }}\n  ignore_errors: True\n  register: default_management_token\n  \n- name: Set Default OpenShift Token if Not Provided\n  set_fact:\n    ocp_token: \"{{ default_management_token.stdout }}\"\n  when: default_management_token.rc == 0 and ((ocp_token | trim == \"\") or (ocp_token is none) or (ocp_token is undefined))\n    \n- name: Set Default Hawkular Token if Not Provided\n  set_fact:\n    hawkular_token: \"{{ default_management_token.stdout }}\"\n  when: default_management_token.rc == 0 and ((hawkular_token | trim == \"\") or (hawkular_token is none) or (hawkular_token is undefined))\n\n- name: Query Existing Providers\n  uri:\n    url: https://{{ cfme_host }}/api/providers\n    method: GET\n    user: \"{{ cfme_username }}\"\n    password: \"{{ cfme_password }}\"\n    force_basic_auth: true\n    validate_certs: false\n    status_code: 200\n  register: providers_result\n\n- name: Query Details From Each Provider\n  include_tasks: query_provider.yml\n  vars:    \n    provider_url: \"{{ item }}\"\n  with_items : \"{{ providers_result.json.resources | default([]) }}\"\n  when: providers_result is defined\n\n- name: Create Container Provider\n  uri:\n    url: https://{{ cfme_host }}/api/providers\n    method: POST\n    body: \"{{ lookup('template', '{{role_path}}/templates/container_provider_rest.j2') }}\"\n    user: \"{{ cfme_username }}\"\n    password: \"{{ cfme_password }}\"\n    force_basic_auth: true\n    validate_certs: false\n    status_code: 200\n    body_format: json\n  register: container_provider_result\n  when: ocp_provider_found is not defined or ocp_provider_found != True\n\n- name: Update Container Provider\n  uri:\n    url: https://{{ cfme_host }}/api/providers/{{ ocp_provider_id }}\n    method: POST\n    body: \"{{ lookup('template', '{{role_path}}/templates/container_provider_rest.j2') }}\"\n    user: \"{{ cfme_username }}\"\n    password: \"{{ cfme_password }}\"\n    force_basic_auth: true\n    validate_certs: false\n    status_code: 200\n    body_format: json\n  when: ocp_provider_found is defined and ocp_provider_found == True\n\n- name: Set Provider ID for New Provider\n  set_fact:\n    ocp_provider_id: \"{{ container_provider_result.json.results[0].id }}\"\n  when: ocp_provider_id is not defined\n\n- name: Refresh Container Provider\n  uri:\n    url: https://{{ cfme_host }}/api/providers/{{ ocp_provider_id }}\n    method: POST\n    body: \"{\\\"action\\\" : \\\"refresh\\\"}\"\n    user: \"{{ cfme_username }}\"\n    password: \"{{ cfme_password }}\"\n    force_basic_auth: true\n    validate_certs: false\n    status_code: 200\n    body_format: json\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "86713e1b3144daeb147da2a72e62fb199f3fec89", "filename": "playbooks/osp/inventory/hosts", "repository": "redhat-cop/infra-ansible", "decoded_content": "\n\n[osp_instances]\n\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "33039e02f5a10ea3718d1aee9c978714c6d3b194", "filename": "roles/osm/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Install IIAB required packages\n  package: name={{ item }}\n           state=present\n  with_items:\n    - gcc\n    - python-dev\n    - liblzma-dev\n    - libapache2-mod-wsgi\n    - libapache2-mod-xsendfile\n  when: is_debuntu\n\n- name: Install IIAB required packages\n  package: name={{ item }}\n           state=present\n  with_items:\n    - python-pip\n    - gcc\n    - python-devel\n    - xz-devel\n    - mod_wsgi\n    - mod_xsendfile\n  when: not is_debuntu\n\n# IIAB wants a specific version do that first\n- name: Install Whoosh 2.6\n  pip: name=whoosh\n       virtualenv={{ osm_venv }}\n       virtualenv_site_packages=no\n       version=2.6\n       extra_args=\"--no-cache-dir\"\n  when: internet_available and is_debuntu\n\n- name: Install IIAB with dependencies\n  pip: name={{ item }}\n       virtualenv={{ osm_venv }}\n       virtualenv_site_packages=no\n       extra_args=\"--no-cache-dir\"\n  with_items:\n    - MarkupSafe\n    - pytz\n    - Internet-in-a-Box\n  when: internet_available and is_debuntu\n\n# IIAB wants a specific version do that first\n- name: Install Whoosh 2.6\n  pip: name=whoosh\n       virtualenv={{ osm_venv }}\n       virtualenv_site_packages=no\n       version=2.6\n#       extra_args=\"--no-cache-dir\"\n  when: internet_available and not is_debuntu\n\n- name: Install IIAB with dependencies\n  pip: name={{ item }}\n       virtualenv={{ osm_venv }}\n       virtualenv_site_packages=no\n#       extra_args=\"--no-cache-dir\"\n  with_items:\n    - MarkupSafe\n    - pytz\n    - Internet-in-a-Box\n  when: internet_available and not is_debuntu\n\n- name: Set osm_path\n  set_fact:\n     osm_path: \"{{ osm_venv }}/{{ python_path }}/iiab\"\n  when: osm_enabled and is_redhat\n\n- name: Set osm_path\n  set_fact:\n     osm_path: \"{{ osm_venv }}/lib/python2.7/site-packages/iiab\"\n  when: osm_enabled and is_debuntu\n\n- name: All - Copy IIAB config file\n  template: backup=no\n            src=osm.conf.j2\n            dest=/etc/{{ apache_config_dir }}/osm.conf\n            owner=root\n            group=root\n            mode=0644\n  when: osm_enabled\n\n- name: Debuntu - Create a link from sites-enabled to sites-available\n  file: src=/etc/{{ apache_config_dir }}/osm.conf\n        dest=/etc/apache2/sites-enabled/osm.conf\n        state=link\n  when: osm_enabled and is_debuntu\n\n- name: Debuntu - Remove the link from sites-enabled to sites-available\n  file: dest=/etc/apache2/sites-enabled/osm.conf\n        state=absent\n  when: not osm_enabled and is_debuntu\n\n- name: Redhat - Remove the osm.conf\n  file: dest=/{{ apache_config_dir }}/osm.conf\n        state=absent\n  when: not osm_enabled and is_redhat\n\n- name: All - Remove link to cgi\n  file: dest={{ doc_root }}/osm.wsgi\n        state=absent\n  when: not osm_enabled\n\n- name: All - Create link to cgi\n  file: src={{ osm_venv }}/bin/iiab.wsgi\n        dest={{ doc_root }}/osm.wsgi\n        owner=root\n        group=root\n        state=link\n  when: osm_enabled\n\n- name: Create the knowledge data set folders\n  file: path=/library/knowledge/modules\n        state=directory\n        owner={{ apache_user }}\n        group={{ apache_user }}\n\n# the following was brought into OSM playbook from iiab-factory osm-fix script\n- name: Copy the files\n  template: src={{ item.src }} dest={{ item.dest }}\n  with_items:\n     - { src: 'defaults.ini', dest: \"{{ osm_path }}/\" }\n     - { src: 'etc.iiab.conf', dest: '/etc/iiab.conf' }\n     - { src: 'map_search.py', dest: \"{{ osm_path }}/map_search.py\" }\n     - { src: 'map.html', dest: \"{{ osm_path }}/static/map.html\" }\n     - { src: 'l.control.geosearch.js', dest: \"{{ osm_path }}/static/lib/leaflet/geosearch/l.control.geosearch.js\" }\n     - { src: '{{ osm_path }}/static/map.html', dest: \"{{ osm_path }}/static/index.html\" }\n  when: osm_enabled\n\n- name: Restart httpd service\n  service: name={{ apache_service }}\n           state=restarted\n\n- name: add osm to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=osm\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: Internet-in-a-Box\n    - option: description\n      value: '\"The Internet-in-a-Box is a small, inexpensive device which provides essential Internet resources without any Internet connection. It provides a local copy of half a terabyte of the world\u2019s Free information.\"'\n    - option: path\n      value: /osm\n    - option: enabled\n      value: \"{{ osm_enabled }}\"\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "1f43d85a40aed0e5dd3f72c351ebe995c2af5ffb", "filename": "playbooks/roles/check_ntp/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "---\n- name: Determine if chrony is installed\n  command: rpm -q chrony\n  failed_when: false\n  register: chrony_installed\n\n- name: Determine if ntp is installed\n  command: rpm -q ntp\n  failed_when: false\n  register: ntp_installed\n\n- name: Install chrony package\n  package:\n    name: chrony\n    state: present\n  when: chrony_installed.rc != 0 and ntp_installed.rc != 0\n\n- name: Create chrony conf\n  template:\n    src: templates/chrony.j2\n    dest: /etc/chrony.conf\n    mode: 0644\n  notify: Restart chrony\n  when: ntp_installed.rc != 0 and ntp_servers is defined and (ntp_servers|length > 0)\n\n- name: Create ntp conf\n  template:\n    src: templates/ntp.j2\n    dest: /etc/ntp.conf\n    mode: 0644\n  notify: Restart ntp\n  when: chrony_installed.rc != 0 and ntp_servers is defined and (ntp_servers|length > 0)\n \n- name: Start and enable chronyd/ntpd\n  command: timedatectl set-ntp true\n\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "8ddd1003d91a5a476930e7e907f80ca278369e5c", "filename": "roles/sshd/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: ensure ssh server is installed\n  apt:\n    pkg: openssh-server\n    state: latest\n    update_cache: true\n    cache_valid_time: \"{{ apt_cache_valid_time }}\"\n  notify:\n    - restart ssh\n\n- name: ensure sshd is configured\n  template:\n    src: sshd_config.j2\n    dest: /etc/ssh/sshd_config\n  notify:\n    - restart ssh\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "db4e2580ba9554929aa41924e0d1ecf2b4a57b76", "filename": "roles/serverspec/tasks/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# tasks file for serverspec\n\n- name: upload serverspecs\n  synchronize:\n    src: ../../../tests\n    dest: \"{{ serverspec_tests_path }}\"\n    recursive: yes\n    delete: yes\n  when: serverspec_run_tests and serverspec_install_bundler and serverspec_upload_folder\n  tags:\n    - serverspec\n\n- name: upload marathon runtime serverspecs\n  template:\n    src: marathon_runtime_spec.rb.j2\n    dest: \"{{ serverspec_tests_path }}/tests/spec/marathon/marathon_runtime_spec.rb\"\n    mode: 0755\n  sudo: yes\n  when: serverspec_run_tests and serverspec_upload_folder\n  tags:\n    - serverspec\n\n- name: install bundler\n  sudo: yes\n  command: gem install bundler --no-ri --no-rdoc\n  args:\n    creates: /usr/local/bin/bundler\n  when: serverspec_run_tests and serverspec_install_bundler\n  tags:\n    - serverspec\n\n- name: install bundle files\n  sudo: yes\n  command: bundle install --path vendor\n  args:\n    chdir: \"{{ serverspec_tests_path }}/tests\"\n    creates: \"{{ serverspec_tests_path }}/tests/vendor\"\n  when: serverspec_run_tests\n  tags:\n    - serverspec\n\n- name: run serverspec tests\n  sudo: yes\n  command: \"bundle exec rake serverspec:{{ test_role }}\"\n  args:\n    chdir: \"{{ serverspec_tests_path }}/tests\"\n  when: test_role is defined and serverspec_run_tests\n  tags:\n    - serverspec\n"}, {"commit_sha": "0c050ee7f22968afdb69da3b859869efea2bfffa", "sha": "1efd5a4c2bd873db8ab2f2e61b7847462fbcaad5", "filename": "tasks/install.yml", "repository": "geerlingguy/ansible-role-solr", "decoded_content": "---\n- name: Ensure dependencies are installed.\n  package: name={{ item }} state=present\n  with_items:\n    - lsof\n    - acl\n    - sudo\n\n- name: Run Solr installation script.\n  shell: >\n    {{ solr_workspace }}/{{ solr_filename }}/bin/install_solr_service.sh\n    {{ solr_workspace }}/{{ solr_filename }}.tgz\n    -i {{ solr_install_dir }}\n    -d {{ solr_home }}\n    -u {{ solr_user }}\n    -s {{ solr_service_name }}\n    -p {{ solr_port }}\n    creates={{ solr_install_path }}/bin/solr\n  register: solr_install_script_result\n\n# Workaround for bug https://github.com/ansible/ansible-modules-core/issues/915.\n- name: Ensure solr is stopped (RHEL 7 workaround).\n  command: service {{ solr_service_name }} stop\n  when: >\n    (ansible_os_family == 'RedHat')\n    and (ansible_distribution_version.split(\".\")[0] == '7')\n    and (solr_install_script_result.changed)\n  failed_when: false\n\n- name: Run systemd daemon_reload (RHEL 7 workaround).\n  systemd:\n    name: solr\n    daemon_reload: yes\n  when: >\n    (ansible_os_family == 'RedHat')\n    and (ansible_distribution_version.split(\".\")[0] == '7')\n    and (solr_install_script_result.changed)\n"}, {"commit_sha": "ccab58ae5d697bb64abd86558f79c34161d2fb00", "sha": "33c40088f1cf7b8fcdfa92e4fc1264a28bfdf577", "filename": "tasks/call_script.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- block:\n    - name: Calling Groovy script {{ script_name }}\n      uri:\n        url: \"{{ nexus_api_scheme }}://{{ nexus_api_hostname }}:{{ nexus_api_port }}\\\n          {{ nexus_api_context_path }}{{ nexus_rest_api_endpoint }}/{{ script_name }}/run\"\n        user: 'admin'\n        password: \"{{ current_nexus_admin_password }}\"\n        headers:\n          Content-Type: \"text/plain\"\n        method: POST\n        force_basic_auth: yes\n        validate_certs: \"{{ nexus_api_validate_certs }}\"\n        body: \"{{ args | to_json }}\"\n      register: script_run\n      failed_when: script_run | nexus_groovy_error | bool\n      changed_when: script_run | nexus_groovy_changed | bool\n\n    - name: Details about runned script if verbose mode is on\n      debug:\n        msg: \"{{ script_run | nexus_groovy_details }}\"\n        verbosity: 1\n      when: not ansible_check_mode\n\n  rescue:\n\n    - when: script_run | nexus_groovy_details == 'Global script failure'\n      block:\n\n        - name: Debug script result for global fail\n          debug:\n            var: script_run\n\n        - name: Global script failure at nexus level\n          fail:\n            msg: >-\n              Running the script {{ script_name }} failed at nexus level.\n              See the above debug output\n\n\n    - name: Debug script result for failed script actions\n      debug:\n        msg: \"{{ script_run | nexus_groovy_details }}\"\n\n    - name: Script action failure\n      fail:\n        msg: >-\n          The script {{ script_name }} returned at least one of its\n          actions has failed. See the degug message above for details\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "b64617915c512acf09b65bdf1fcc198f2919da9d", "filename": "playbooks/manage-lb/lb-vms.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Generate and activate the HAproxy configuration'\n  hosts: lb_vms\n  tasks:\n  - import_role:\n      name: load-balancers/manage-haproxy\n      tasks_from: install\n    tags:\n    - 'never'\n    - 'install'\n  - import_role:\n      name: load-balancers/manage-haproxy\n      tasks_from: generate-config\n    tags:\n    - 'always'\n  - import_role:\n      name: load-balancers/manage-haproxy\n      tasks_from: activate-config\n    tags:\n    - 'always'\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "1aec28557d0a0197dfaa5d6cf32886b7dda99337", "filename": "playbooks/provision-bastion/README.md", "repository": "redhat-cop/infra-ansible", "decoded_content": "# Bastion Host / Control Host playbook\n\nThis playbook uses a variety of roles in this repo to setup a bastion host, also some times called a control host. The inventory can be used (per instructions below) to control which software and services get installed on the bastion host.\n\n\n## Prerequisites\nA running instance (VM or cloud image) such as Fedora, CentOS or Red Hat Enterprise Linux. The instance needs to be subscribed (if applicable) and configured with access to the necessary repos (in most cases, the exsisting repos / configuration is sufficient).\n\nIf the IdM / IPA integration is to be used, it is a prerequisites that the environment is set up with automatic client server discovery vis DNS SRV records (consult your sys admin if this is an unfamiliar area).\n\n## Gotcha's\n1. If running in a cloud environment, for example OpenStack, make sure to have the correct ports open in the security groups (e.g.: 5901 for VNC, 22 for SSH, etc.)\n2. When enabling VNC, and you already have a shared home directory, make sure the proper changes are made to the VNC configuration (typically in `~/.vnc` ) to allow for the service to run correctly.\n\n## Example run\nHow to run the playbook may depend on the options selected. However, below is an example execution whereas the password for IPA/IdM integration (with `ipa_client_install` set to `True` in the inventory) is passed in rather than statically set in the inventory. Modify the inventory to your liking in `playbooks/bastion/inventory`, then at the top level of the repository, execute the following command:\n\n```\n> ansible-playbook -i playbooks/bastion/inventory playbooks/bastion/install.yml -e 'ipa_password=<ipa/IdM password>'\n```\n\n**Note:** If your password contains any special characters, e.g.: a '!', it's important to use the single quotes for the passed in value as it otherwise may be interpereted by the shell.\n\n## Inventory Options\n\n**Note:** If you are intending to use the IdM/IPA integration, and are unfamiliar with the IdM/IPA variables below, please consult the IdM/IPA documentation or your sys admin for details.\n\n**Note:** When installing a GUI (i.e.: XFCE, LXDE, Gnome), it's recommended that only one is selected as running multiple is not supported nor tested by this playbook/roles.\n\n| variable | info |\n|:--------:|:----:|\n|main_user|The username this bastion is primerly being enabled for|\n|ipa_client_install|Set to `True` if you'd like to integrate with a backend IPA/IdM service|\n|ipa_domain|If `ipa_client_install` is set to `True`, set this to the existing IdM / IPA domain your environment uses (obtain from sys admin if not known)|\n|ipa_automount_location|If `ipa_client_install` is set to `True`, set the required automount location for home directories (obtain from sys admin if not known)|\n|ipa_username|If `ipa_client_install` is set to `True`, this is the username of an account that has the permission to join this host to the above IPA/IdM domain (obtain from sys admin if not known)|\n|ipa_password|If `ipa_client_install` is set to `True`, this is the password of an account that has the permission to join this host to the above IPA/IdM domain (obtain from sys admin if not known)\n|docker_install|Set to `True` if you'd like to enable docker on this host|\n|docker_username|Set to the desirable user (your username) to be added to the docker group (to allow for docker admin)|\n|docker_compose_install|Set to `True` if you'd like to have docker-compose installed on this host. NOTE: This will auto set docker_install=True (not supported on CentOS)|\n|xfce_install|Set to `True` if you'd like XFCE enabled on this host for a graphical UI (note MATE, XFCE or LXDE often works better than gnome for VNC)|\n|lxde_install|Set to `True` if you'd like LXDE enabled on this host for a graphical UI (note MATE, XFCE or LXDE often works better than gnome for VNC)|\n|gnome_install|Set to `True` if you'd like gnome enabled on this host for a graphical UI|\n|mate_install|Set to `True` if you'd like MATE Desktop enabled on this host for a graphical UI (note MATE, XFCE or LXDE often works better than gnome for VNC)|\n|vnc_server_install|Set to `True` if you'd like to enable a VNC server on this host for graphical access to the host|\n|list_of_packages_to_install|List of additional packages (RPMs) to be installed at the end of the bastion host preparation, e.g.: `['git', 'vim']`|\n|timezone| `Optional` Timezone of the Bastion ie `America/Denver`|\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "527c77cabe5f72219f6819d6430890b79d5d1ba4", "filename": "roles/openvpn/templates/iiab-remote-off", "repository": "iiab/iiab", "decoded_content": "#!/bin/bash\n# script to turn on openvpn\n\n# do nothing if it is not installed\nwhich openvpn\nif [ $? -ne 0 ]; then\n   echo Cannot find the openvpn program.\n   exit 1\nfi\nsystemctl disable openvpn@xscenet.service\nsystemctl stop openvpn@xscenet.service\n\nsleep 5\nps -e|grep vpn\nif [ $? -eq 0 ]; then\n  echo Openvpn failed to stop.\nelse\n  echo Successfully stopped and disabled Openvpn\nfi\n"}, {"commit_sha": "4e46e9eb277bc88f285dbc9dd980193e57f7bf48", "sha": "9c22ecb304a45f42d737174813ff5be24545a258", "filename": "tasks/configure-docker.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Ensure /etc/docker directory exists\n  file:\n    path: /etc/docker\n    state: directory\n    mode: 0755\n  become: true\n\n- name: Configure Docker daemon (file)\n  copy:\n    src: \"{{ docker_daemon_config_file }}\"\n    dest: /etc/docker/daemon.json\n  become: true\n  notify: restart docker\n  when: docker_daemon_config_file is defined\n\n- name: Configure Docker daemon (variables)\n  copy:\n    content: \"{{ docker_daemon_config | to_nice_json }}\"\n    dest: /etc/docker/daemon.json\n  become: true\n  notify: restart docker\n  when: docker_daemon_config_file is not defined and\n        docker_daemon_config is defined\n\n- name: Ensure Docker default user namespace is defined in subuid and subgid\n  lineinfile:\n    path: \"{{ item }}\"\n    regexp: '^dockremap'\n    line: 'dockremap:500000:65536'\n  become: yes\n  with_items:\n    - /etc/subuid\n    - /etc/subgid\n  when: (_docker_os_dist == \"CentOS\" or _docker_os_dist == \"RedHat\") and\n        ((docker_daemon_config is defined and\n        docker_daemon_config['userns-remap'] is defined and\n        docker_daemon_config['userns-remap'] == 'default') or\n        docker_bug_usermod|bool == true)\n\n- name: Ensure thin-provisioning-tools is installed when devicemapper is used (Ubuntu)\n  package:\n    name: thin-provisioning-tools\n    state: present\n  become: yes\n  when: (_docker_os_dist == \"Ubuntu\" or _docker_os_dist == \"Debian\") and\n        docker_daemon_config['storage-driver'] is defined and\n        docker_daemon_config['storage-driver'] == 'devicemapper'\n\n- name: Enable Docker service\n  service:\n    name: docker\n    enabled: yes\n  notify: restart docker\n  register: docker_service\n  become: yes\n\n- name: Trigger start/restart of Docker\n  service:\n    name: docker\n  notify: restart docker\n  changed_when: docker_service.status.SubState != \"running\"\n  when: docker_service.status is defined\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "4c282ec715be022b129930c87ad0f41bffb6bffb", "filename": "roles/ansible/tower/manage-credentials/tests/inventory/group_vars/tower.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ntower_admin_password: \"admin01\"\n\nansible_tower:\n  credentials:\n  - name: \"Cred1\"\n    description: \"My Credential 1\"\n    organization: \"Default\"\n    credential_type: \"Machine\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "fb26bce8237bace944e31c81d5485f73aa699d89", "filename": "roles/ansible/tower/manage-inventories/tests/inventory/group_vars/tower.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nansible_tower:\n  admin_password: \"admin01\"\n  inventories:\n  - name: \"Inventory1\"\n    description: \"My Hosts\"\n    organization: \"Default\"\n    variables: \"---\"\n    hosts:\n    - name: \"localhost\"\n      description: \"\"\n      variables: \"---\\\\nansible_connection: local\"\n    groups:\n    - name: \"seed_hosts\"\n      hosts:\n      - name: \"localhost\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "003be4ec1c8ff3a731c1722ff16f8194389a0f91", "filename": "roles/config-pxe/tasks/pxe.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Ensure necessary directories exists\"\n  file:\n    path: \"{{ item }}\"\n    state: directory\n  with_items:\n  - \"{{ tftpserver_root_dir }}/pxelinux\"\n  - \"{{ tftpserver_root_dir }}/pxelinux.cfg\"\n\n- name: \"Copy in necessary PXE files for regular BIOS use\"\n  copy: \n    src: \"{{ item }}\"\n    dest:  \"{{ tftpserver_root_dir }}/{{ item | basename }}\"\n    remote_src: True\n  with_items:\n  - \"/usr/share/syslinux/pxelinux.0\"\n  - \"/usr/share/syslinux/memdisk\"\n  - \"/usr/share/syslinux/vesamenu.c32\"\n  - \"/usr/share/syslinux/menu.c32\"\n\n# Note: the Ansible 'copy' module doesn't support resursive copy of remote src directories as-is, hence the 'command'\n- name: \"Copy in necessary PXE files for UEFI use\"\n  shell: \"cp -r {{ uefi_source }}/* {{ tftpserver_root_dir }}/pxelinux\"\n\n- name: \"Workaround for buggy UEFI requiring lowercase\"\n  copy: \n    src: \"{{ tftpserver_root_dir }}/pxelinux/BOOTX64.EFI\"\n    dest: \"{{ tftpserver_root_dir }}/pxelinux/bootx64.efi\"\n    remote_src: True\n\n- name: \"Ensure the hosted OS directories exists\"\n  file:\n    path: \"{{ tftpserver_root_dir }}/{{ item.destination }}\"\n    state: directory\n  with_items:\n  - \"{{ pxe_entries }}\"\n\n# Note: the Ansible 'copy' module doesn't support resursive copy of directories as-is, hence the 'command'\n- name: \"Copy in the necessary files for the hosted OS directories\"\n  shell: \"cp -r {{ item.source }}/* {{ tftpserver_root_dir }}/{{ item.destination }}\"\n  with_items:\n  - \"{{ pxe_entries }}\"\n\n- name: \"Populate the pxelinux.cfg default file\"\n  template:\n    src: pxelinux_cfg.j2\n    dest: \"{{ tftpserver_root_dir }}/pxelinux.cfg/default\"\n\n- name: \"Populate the grub.cfg (UEFI) default file\"\n  template:\n    src: pxelinux_uefi.j2\n    dest: \"{{ tftpserver_root_dir }}/pxelinux/grub.cfg\"\n\n- name: \"Generate target specific UEFI grub.cfg file\"\n  include_tasks: pxe-target.yml\n  loop_control:\n    loop_var: target_entry\n  with_items:\n  - \"{{ pxe_targets }}\"\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "a2b8584d7a19b30de63dc462bfa8284ceb7c277b", "filename": "tasks/opensource/install-oss.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: OSS Linux)\"\n  import_tasks: install-oss-linux.yml\n  when: ansible_os_family in nginx_linux_families\n\n- name: \"(Install: OSS BSD)\"\n  import_tasks: install-oss-bsd.yml\n  when: ansible_system in nginx_bsd_systems\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "da2841598f7c95a73b4dd7b12d11d2fb0bb0e486", "filename": "roles/network/templates/named/named", "repository": "iiab/iiab", "decoded_content": "#!/bin/sh -e\n#  This file is called when the domain name is changed, to change any\n#  named configuration files affected.\n#\n#  The first argument is the new domain name,\n\n#  Copyright 2008, One Laptop per Child\n#  Authors: John Watlington, Martin Langhoff\n#  License: GPLv2\n\n#  This is the name of the service (for stopping and restarting)\nSERVICE_NAME={{ dns_service }}\n\n#  This is a list of files related to this service which will have\n#  the domain name globally replaced inside them\nCONFIG_LIST=\"/etc/named-iiab.conf /var/named-iiab/school.internal.zone.in-addr.db /var/named-iiab/school.internal.zone.in-addr.db  /var/named-iiab/school.internal.zone.16.in-addr.db /var/named-iiab/school.internal.zone.32.in-addr.db /var/named-iiab/school.internal.zone.48.in-addr.db\"\n\n#  This is the suffix which original versions of modified files will have\nBACKUP_SUFFIX=old\n\nnew_name=$1\n\nfor config in $CONFIG_LIST;\ndo\n    if [ -e $config.in ]; then\n\tif [ -e $config ]; then\n\t    mv $config $config.$BACKUP_SUFFIX\n\tfi\n\tsed -e s/@@BASEDNSNAME@@/$new_name/ $config.in > $config ;\n    else\n\techo WARNING: Skipped $config - template file is missing!\n    fi\ndone\n\n# Since for the community edition, we don't really expect all modules to be present\n#   Just exit, and expect the user to do a restart\n\nexit 0\n\n\n\n"}, {"commit_sha": "e91a55152358e890a05cf849abc7d58b8badecc2", "sha": "c30f9d78c54e197526019ab38f9495de2febd3ef", "filename": "tasks/cleanup.yml", "repository": "fubarhouse/ansible-role-golang", "decoded_content": "---\n\n- name: \"Go-Lang | Removing GOROOT\"\n  file:\n    path: \"{{ GOROOT }}\"\n    state: absent\n  failed_when: false\n\n- name: \"Go-Lang | Removing GOBOOTSTRAP\"\n  file:\n    path: \"{{ GOROOT_BOOTSTRAP }}\"\n    state: absent\n  when:\n   - GOROOT_BOOTSTRAP is defined\n   - install_go_bootstrap|bool == true\n  failed_when: false\n\n- name: \"Go-Lang | Define shell exports\"\n  set_fact:\n    shell_exports:\n      - regex: \"export GOROOT\"\n        lineinfile: \"export GOROOT={{ GOROOT }}\"\n      - regex: \"export GOPATH\"\n        lineinfile: \"export GOPATH={{ GOPATH }}\"\n      - regex: \"PATH:{{ GOROOT }}/bin\"\n        lineinfile: \"export $PATH:{{ GOROOT }}/bin\"\n      - regex: \"PATH:{{ GOPATH }}\"\n        lineinfile: \"export $PATH=$PATH:{{ GOPATH }}\"\n      - regex: \"PATH:{{ GOPATH }}/bin\"\n        lineinfile: \"export $PATH=$PATH:{{ GOPATH }}/bin\"\n  when: shell_exports is not defined\n\n- name: \"Go-Lang | Detect configured shell profiles\"\n  stat:\n    path: \"{{ fubarhouse_user_dir }}/{{ item }}\"\n  changed_when: false\n  failed_when: false\n  with_items: \"{{ shell_profiles }}\"\n  register: stat_shell_profiles\n  when:\n  - shell_profiles is defined\n  - stat_shell_profiles is not defined\n\n- name: \"Go-Lang | Ensure shell profiles are clean\"\n  lineinfile:\n    dest: \"{{ item[0].stat.path }}\"\n    regexp: \"{{ item[1].regex }}\"\n    line: \"{{ item[1].lineinfile }}\"\n    state: absent\n  with_nested:\n  - \"{{ stat_shell_profiles.results }}\"\n  - \"{{ shell_exports }}\"\n  when:\n  - shell_profiles is defined\n  - shell_exports is defined\n  - item[0].stat.exists|bool == true\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "df1b7d21e03fac750e40fdf48a96267b733f3c8e", "filename": "playbooks/roles/check_packages_bastion/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- name: Install packages\n  yum:\n    name: \"{{item}}\"\n    state: latest\n  with_items:\n  - \"{{ packages }}\"\n  - \"{{ packages_jumphost }}\"\n- name: update bastion packages\n  yum:\n    name: '*'\n    state: latest\n"}, {"commit_sha": "481f7ad18dc225973e1d676d33e58c49cbbfe986", "sha": "7a6eb0524e3d3e843b26c43f8b8a3f45fa9c2b9f", "filename": "tasks/variables-spatialite.yml", "repository": "openwisp/ansible-openwisp2", "decoded_content": "- name: Set spatialite_path for Fedora\n  set_fact:\n    openwisp2_spatialite_path: \"mod_spatialite\"\n  when: ansible_distribution == 'Fedora'\n\n- name: Set spatialite_path (Ubuntu >= 18.04 or Debian >= 10)\n  set_fact:\n    openwisp2_spatialite_path: \"mod_spatialite.so\"\n  when: >\n    (ansible_distribution == 'Ubuntu' \n    and ansible_distribution_version is version_compare('18.04', 'ge')) \n    or (ansible_distribution == 'Debian' and \n    ansible_distribution_version is version_compare('10', 'ge'))\n\n- name: Set spatialite_path (Ubuntu >= 16.04 or Debian >= 9)\n  set_fact:\n    openwisp2_spatialite_path: \"mod_spatialite\"\n  when: >\n    (ansible_distribution == 'Ubuntu'\n    and ansible_distribution_version is version_compare('16.04', 'ge'))\n    or (ansible_distribution == 'Debian'\n    and ansible_distribution_version is version_compare('9', 'ge'))\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "7f0c988fa72abfbdee04b4957b2d10685658a73e", "filename": "roles/dns/manage-dns-zones-bind/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: determine-action.yml\n\n- block:\n    - import_tasks: prereq.yml\n    - import_tasks: process-views.yml\n    - import_tasks: keys.yml\n    - import_tasks: print_keys.yml\n  when:\n  - named_processing|bool == True\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "9b78c918fc809e1e14a485ece767e6d1b00bd208", "filename": "roles/osp/admin-network/tasks/manage-routers.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Set up router(s)\"\n  os_router:\n    cloud: \"{{ item.cloud | default(osp_default_cloud) | default(omit) }}\"\n    project: \"{{ item.project | default(omit) }}\"\n    state: \"{{ item.state | default(osp_resource_state) | default('present') }}\"\n    name: \"{{ item.name }}\"\n    network: \"{{ item.external_gateway }}\"\n    interfaces:\n    - \"{{ item.subnet }}\"\n  with_items:\n  - \"{{ osp_routers | default([]) }}\"\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "f0abc92939fedbe475d2e469ec352d17c8edb017", "filename": "roles/common/handlers/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: restart memcached\n  service:\n    name: memcached\n    state: restarted\n\n- name: reload php-fpm\n  service:\n    name: php7.0-fpm\n    state: reloaded\n\n- name: reload nginx\n  service:\n    name: nginx\n    state: reloaded\n"}, {"commit_sha": "2a05a5032ce341d6a1d918453164c59ea2922f58", "sha": "86fc701e43ef158e053126cd4fa9fff3ed4ffcf4", "filename": "roles/provision_vm/templates/virt-install.sh", "repository": "CSCfi/fgci-ansible", "decoded_content": "#!/bin/bash\n\nif [ ! -f /etc/libvirt/qemu/{{ inventory_hostname.split('.').0 }}.xml ]; then\n\nvirt-install \\\n  --name {{\u00a0inventory_hostname.split('.').0 }} \\\n  --os-variant rhel7 \\\n  --cpu host-model \\\n  --vcpus {{ vcpus }} \\\n  --ram {{ ram }} \\\n{% for disk in disks %}\n  --disk pool={{ disk.pool }},cache=writethrough,device=disk,bus=virtio,size={{ disk.size }},format=raw \\\n{% endfor %}\n{% for bridge in bridges %}\n  --network bridge={{ bridge }},model=virtio \\\n{% endfor %}\n  --connect qemu:///system \\\n  --location {{ location }} \\\n  --graphics=vnc,keymap=\"fi\" \\\n  --wait 20 \\\n  --initrd-inject '{{ kickstart_tempdir }}/{{ inventory_hostname.split('.').0 }}.ks' \\\n  --extra-args 'ks=file:/{{ inventory_hostname.split('.').0 }}.ks console=ttyS0,115200n8' \\\n  --console pty,target_type=serial\nfi\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "4445d480aab6a9856bd09e0734249b789c540eeb", "filename": "roles/config-dns-server/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ndns_server_type: 'master'\n\ndefault_dnssec_keygen_size: 256\ndefault_dnssec_keygen_algorithm: HMAC-SHA256\n\nnamed_config_recursion: yes\n\nnamed_config_views: []\nnamed_config_allow_query: []\nnamed_config_allow_transfer: []\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "1b859cd2134b9a6627cd0d7e35887e6be15bd23f", "filename": "roles/config-ipa-client/tasks/move-local-user-home.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Move local user's home directory to allow for automount\"\n  block:\n  - name: \"Create temporary account used to move the main account home dir\"\n    user:\n      name: \"{{ temporary_username }}\"\n      groups: wheel\n  - name: \"Ensure new local home dir base path exists\"\n    file:\n      path: \"{{ new_local_home_dir }}\"\n      state: directory\n  - name: \"Ensure new local home .ssh dir exists\"\n    file:\n      path: \"/home/{{ temporary_username }}/.ssh\"\n      state: directory\n      mode: 0700\n      owner: \"{{ temporary_username }}\"\n      group: \"{{ temporary_username }}\"\n  - name: \"Copy over SSH key from the ansible_user\"\n    copy:\n      src: \"/home/{{ ansible_user }}/.ssh/authorized_keys\"\n      dest: \"/home/{{ temporary_username }}/.ssh/authorized_keys\"\n      mode: 0600\n      owner: \"{{ temporary_username }}\"\n      group: \"{{ temporary_username }}\"\n      remote_src: True\n  - name: \"Ensure SUDO access for temporary user\"\n    lineinfile:\n      path: /etc/sudoers.d/10-local-user\n      regexp: \"^{{ temporary_username }}\"\n      line: \"{{ temporary_username }} ALL=(ALL) NOPASSWD:ALL\"\n      create: yes\n  - name: \"Override the ansible_user now that a temporary user is enabled\"\n    set_fact:\n      old_ansible_user: \"{{ ansible_user }}\"\n      ansible_user: \"{{ temporary_username }}\"\n  - name: \"Wait for the previous user to finish up\"\n    shell: \"ps -eo uname | grep '{{ old_ansible_user }}'\"\n    register: cmdoutput\n    until: cmdoutput.rc == 1\n    retries: 60\n    delay: 2\n    failed_when: False\n    changed_when: False\n  - name: \"Move local sudo user home dir\"\n    user:\n      name: \"{{ old_ansible_user }}\"\n      move_home: yes\n      home: \"{{ new_local_home_dir }}/{{ old_ansible_user }}\"\n  - name: \"Switch back to the main sudo user\"\n    set_fact:\n      ansible_user: \"{{ old_ansible_user }}\"\n  - name: \"Wait for the previous user to finish up\"\n    shell: \"ps -eo uname | grep '{{ temporary_username }}'\"\n    register: cmdoutput\n    until: cmdoutput.rc == 1\n    retries: 60\n    delay: 2\n    failed_when: false\n    changed_when: false\n  - name: \"Remove the temporary user\"\n    user:\n      name: \"{{ temporary_username }}\"\n      state: absent\n  - name: \"Remove the sudo access for the temporary user\"\n    file:\n      path: /etc/sudoers.d/10-local-user\n      state: absent\n  when:\n  - move_local_user_home|bool == True\n"}, {"commit_sha": "c33f3410e002f9d8506f0725f56b7d7afa1c5f74", "sha": "dd72b0b12925aaf0625355947553eac750364e2b", "filename": "tasks/packages-Archlinux.yml", "repository": "jloh/nagios-nrpe-server", "decoded_content": "---\n# Update pacman cache for Arch Linux based OS's\n- name: Update pacman cache [Arch Linux]\n  pacman: update_cache=yes\n\n# Nagios NRPE Server for Arch Linux based OS's\n- name: Install Nagios NRPE Server [Arch Linux]\n  pacman: name=nrpe state=present\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "3ee7078ed3e0e933a6508c4f194fc74c71d6b6de", "filename": "handlers/main.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- name: systemd-reload\n  systemd:\n    daemon-reload: yes\n    name: nexus.service\n\n- name: nexus-service-restart\n  systemd:\n    name: nexus.service\n    state: restarted\n\n- name: nexus-service-stop\n  systemd:\n    name: nexus.service\n    state: stopped\n  when: nexus_systemd_service_file.stat.exists\n\n- name: wait-for-nexus\n  wait_for:\n    path: \"{{ nexus_data_dir }}/log/nexus.log\"\n    search_regex: \"Started Sonatype Nexus OSS .*\"\n    timeout: 1800\n\n- name: wait-for-nexus-port\n  wait_for:\n    port: \"{{ nexus_default_port }}\"\n    delay: 5\n\n- name: httpd-service-reload\n  systemd:\n    name: \"{{ httpd_package_name }}.service\"\n    state: reloaded\n    enabled: yes\n\n- name: wait-for-httpd\n  wait_for:\n    port: 443\n    delay: 5\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "4e835898a3a694339941f30875c415134c54f864", "filename": "roles/dcos_cli/meta/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\ngalaxy_info:\n  author: Alberto Lamela\n  description:\n  company: Capgemini\n  # If the issue tracker for your role is not on github, uncomment the\n  # next line and provide a value\n  # issue_tracker_url: http://example.com/issue/tracker\n  # Some suggested licenses:\n  # - BSD (default)\n  # - MIT\n  # - GPLv2\n  # - GPLv3\n  # - Apache\n  # - CC-BY\n  license: license (GPLv2, CC-BY, etc)\n  min_ansible_version: 1.2\n  #\n  # Below are all platforms currently available. Just uncomment\n  # the ones that apply to your role. If you don't see your\n  # platform on this list, let us know and we'll get it added!\n  #\n  #platforms:\n  #- name: EL\n  #  versions:\n  #  - all\n  #  - 5\n  #  - 6\n  #  - 7\n  #- name: GenericUNIX\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Fedora\n  #  versions:\n  #  - all\n  #  - 16\n  #  - 17\n  #  - 18\n  #  - 19\n  #  - 20\n  #  - 21\n  #  - 22\n  #- name: SmartOS\n  #  versions:\n  #  - all\n  #  - any\n  #- name: opensuse\n  #  versions:\n  #  - all\n  #  - 12.1\n  #  - 12.2\n  #  - 12.3\n  #  - 13.1\n  #  - 13.2\n  #- name: Amazon\n  #  versions:\n  #  - all\n  #  - 2013.03\n  #  - 2013.09\n  #- name: GenericBSD\n  #  versions:\n  #  - all\n  #  - any\n  #- name: FreeBSD\n  #  versions:\n  #  - all\n  #  - 8.0\n  #  - 8.1\n  #  - 8.2\n  #  - 8.3\n  #  - 8.4\n  #  - 9.0\n  #  - 9.1\n  #  - 9.1\n  #  - 9.2\n  #- name: Ubuntu\n  #  versions:\n  #  - all\n  #  - lucid\n  #  - maverick\n  #  - natty\n  #  - oneiric\n  #  - precise\n  #  - quantal\n  #  - raring\n  #  - saucy\n  #  - trusty\n  #  - utopic\n  #  - vivid\n  #- name: SLES\n  #  versions:\n  #  - all\n  #  - 10SP3\n  #  - 10SP4\n  #  - 11\n  #  - 11SP1\n  #  - 11SP2\n  #  - 11SP3\n  #- name: GenericLinux\n  #  versions:\n  #  - all\n  #  - any\n  #- name: Debian\n  #  versions:\n  #  - all\n  #  - etch\n  #  - jessie\n  #  - lenny\n  #  - squeeze\n  #  - wheezy\n  #\n  # Below are all categories currently available. Just as with\n  # the platforms above, uncomment those that apply to your role.\n  #\n  #categories:\n  #- cloud\n  #- cloud:ec2\n  #- cloud:gce\n  #- cloud:rax\n  #- clustering\n  #- database\n  #- database:nosql\n  #- database:sql\n  #- development\n  #- monitoring\n  #- networking\n  #- packaging\n  #- system\n  #- web\ndependencies: []\n  # List your role dependencies here, one per line.\n  # Be sure to remove the '[]' above if you add dependencies\n  # to this list.\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "2b8e6bac1e04a9cd674dd1d6d4a28882823c5289", "filename": "roles/network/tasks/computed_services.yml", "repository": "iiab/iiab", "decoded_content": "- name: No LAN configured - Appliance mode\n  set_fact:\n    dansguardian_enabled: False\n    squid_enabled: False\n    named_enabled: True\n    dhcpd_enabled: False\n    wondershaper_enabled: False\n    iiab_network_mode: \"Appliance\"\n  when: iiab_lan_iface == \"none\" or user_lan_iface == \"none\"\n\n- name: LAN configured - LanController mode\n  set_fact:\n    named_enabled: True\n    dhcpd_enabled: True\n    dansguardian_enabled: False\n    squid_enabled: False\n    wondershaper_enabled: False\n    iiab_network_mode: \"LanController\"\n  when: iiab_lan_iface != \"\" and iiab_wan_iface == \"none\"\n\n- name: LAN configured - Gateway mode\n  set_fact:\n    named_enabled: True\n    dhcpd_enabled: True\n    iiab_network_mode: \"Gateway\"\n  when: 'iiab_lan_iface != \"none\" and iiab_wan_iface != \"none\"'\n\n- name: Add location section to config file\n  ini_file: dest='{{ iiab_config_file }}'\n            section=network\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n  - option: 'iiab_network_mode_applied'\n    value: '{{ iiab_network_mode }}'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "ce5f2c959a2aae3ba42145646a419ddfaf37870f", "filename": "roles/config-ipa-client/tasks/ipa.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Check if service has already been started - if so skip\"\n  command: \"systemctl status sssd\"\n  register: sssd_status\n  failed_when: False\n  changed_when: False\n\n- name: \"Check if sssd.conf has already been configured - if so skip\"\n  stat:\n    path: /etc/sssd/sssd.conf\n  register: stat_result\n  failed_when: False\n  changed_when: False\n\n- name: \"Check if sssd has already been correctly configured - if so skip\"\n  shell: \"awk /^.domain.{{ ipa_domain }}.$/ /etc/sssd/sssd.conf\"\n  register: check_conf\n  failed_when: False\n  changed_when: False\n\n- name: \"Configure IPA/IdM Integration if not already enabled and correctly configured\"\n  import_tasks: ipa-install.yml\n  when:\n  - (sssd_status.rc != 0 or stat_result.stat.exists == false or check_conf.stdout == \"\")\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "8d3deed965ccaada5f2130d29725e62db7dd9e03", "filename": "roles/user-management/manage-users/tasks/add_user_to_group.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n  - name: \"Add Members to Group {{ this_group.name }}\"\n    ipa_group:\n      ipa_host: \"{{ ipa_host | default(ansible_host)}}\"\n      ipa_user: \"{{ ipa_admin_user }}\"\n      ipa_pass: \"{{ ipa_admin_password }}\"\n      validate_certs: \"{{ ipa_validate_certs | default(True) }}\"\n      name: \"{{ this_group.name }}\"\n      user: \"{{ this_group.members | default('[]') }}\"\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "d43dc4b8aa7f636094cc142e41980d33aa01b222", "filename": "tasks/create_repo_npm_hosted_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_npm_hosted\n    args: \"{{ _nexus_repos_npm_defaults|combine(item) }}\"\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "6d399362cfebd51fde7bf2cbc398d1d4a65c0d8b", "filename": "tasks/section_02.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - include: section_02_level1.yml\n    tags:\n      - section02\n      - level1\n\n  - include: section_02_level2.yml\n    tags:\n      - section02\n      - level2"}, {"commit_sha": "d25113e8fab871b2ead95ca976c5a43e4759ea26", "sha": "b9cce2c09be17389157b60db11fba911e2b47ffc", "filename": "tasks/install.deb.yml", "repository": "UnderGreen/ansible-role-mongodb", "decoded_content": "---\n\n- include_vars: \"{{ansible_distribution}}.yml\"\n\n- name: Check if systemd is present\n  stat: path=/bin/systemd\n  register: systemd\n\n- name: Add systemd configuration if present\n  copy: src=mongodb.service dest=/lib/systemd/system/mongodb.service owner=root group=root mode=0640\n  when: systemd.stat.exists == true\n\n- name: Add symlink for systemd\n  file: src=/lib/systemd/system/mongodb.service dest=/etc/systemd/system/multi-user.target.wants/mongodb.service state=link\n  when: systemd.stat.exists == true\n  notify: reload systemd\n\n- meta: flush_handlers\n  when: systemd.stat.exists == true\n\n- name: Add APT key\n  apt_key: url=http://docs.mongodb.org/10gen-gpg-key.asc id=7F0CEB10\n  when: '\"mongodb-org\" in mongodb_package'\n\n- name: Add APT repository\n  apt_repository: repo=\"{{mongodb_repository}}\" update_cache=yes\n  when: '\"mongodb-org\" in mongodb_package'\n\n- name: Install MongoDB package\n  apt: pkg={{mongodb_package}} state=present\n\n- name: reload systemd\n  shell: systemctl daemon-reload\n  changed_when: false\n  when: systemd.stat.exists == true\n\n- name: Install additional packages\n  apt: pkg={{item}}\n  with_items: mongodb_additional_packages\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "22497cadb480023e0ee738deb8489c1520e3e250", "filename": "roles/config-timezone/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: set timezone to {{ timezone }}\n  timezone:\n    name: \"{{ timezone }}\"\n  when:\n  - timezone is defined\n  - timezone | trim != \"\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "8351a1348192da26f86ed52d0e6eee152bd9cd58", "filename": "roles/config-minishift-remote/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ndocker_group: docker\nminishift_dependencies:\n  - docker\n  - firewalld\nminishift_remote_user: \"{{ ansible_user }}\"\nminishift_user_ssh_public_key_file: \"{{ ansible_ssh_private_key_file | default('~/.ssh/id_rsa') }}.pub\"\nminishift_firewalld_ports:\n  - \"80/tcp\"\n  - \"443/tcp\"\n  - \"2376/tcp\"\n  - \"4001/tcp\"\n\ndownload_minishift: True\nconfigure_start_minishift: True\n\nminishift_install_dir: /usr/local/bin\nminishift_tmp_dir: /tmp\nminishift_host_ip: \"{{ ansible_eth0.ipv4.address }}\"\nminishift_binary_location_escalation: False\n\n\n# Location of the Minishift binary if not retrieving from GitHub\nminishift_url:\n\n# Extra arguments to Minishift start command\nminishift_extra_start_args: \"\"\n      "}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "93a1aeca8c8741dc71bb8430f4f4e7a9d4aaeed3", "filename": "roles/wordpress-setup/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- include: database.yml\n  tags: wordpress-setup-database\n- include: self-signed-certificate.yml\n  tags: wordpress-setup-self-signed-certificate\n\n- name: Create web root\n  file:\n    path: \"{{ www_root }}\"\n    owner: \"{{ web_user }}\"\n    group: \"{{ web_group }}\"\n    mode: 0755\n    state: directory\n  with_dict: \"{{ wordpress_sites }}\"\n\n- name: Create logs folder of sites\n  file:\n    path: \"{{ www_root }}/{{ item.key }}/logs\"\n    owner: \"{{ web_user }}\"\n    group: \"{{ web_group }}\"\n    mode: 0755\n    state: directory\n  with_dict: \"{{ wordpress_sites }}\"\n\n- include: nginx.yml\n  tags: wordpress-setup-nginx\n\n- name: Setup WP system cron\n  cron:\n    name: \"{{ item.key }} WordPress cron\"\n    minute: \"*/15\"\n    user: \"{{ web_user }}\"\n    job: \"cd {{ www_root }}/{{ item.key }}/{{ item.value.current_path | default('current') }} && wp cron event run --due-now\"\n    cron_file: \"wordpress-{{ item.key | replace('.', '_') }}\"\n  with_dict: \"{{ wordpress_sites }}\"\n  when: site_env.disable_wp_cron and not item.value.multisite.enabled | default(false)\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "b39d4b729e039ae2fcd82d7880607d43f9b937e6", "filename": "roles/iiab-admin/README.rst", "repository": "iiab/iiab", "decoded_content": "=================\nXSCE Admin README\n=================\n\nThis role is home to a number of administrative playbooks.  Those implemented are:\n\nAdd Administrative User\n-----------------------\n\n* Add the iiab-admin user and password\n* N.B. to create password hash use python -c 'import crypt; print crypt.crypt(\"<plaintext>\", \"$6$<salt>\")'\n* Make a sudoer\n* Add /root/.ssh and dummy authorized_keys file as placeholder\n* Force password for sudoers\n\nAdd Packages for Remote Access\n------------------------------\n\n* screen\n* lynx\n\nAdmin Console\n-------------\n\nHas been moved to a separate git repo"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "2d4fcdff61c5bf4702148e317211f99d55b5860b", "filename": "roles/wordpress-setup/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- include: database.yml\n  tags: wordpress-setup-database\n- include: self-signed-certificate.yml\n  tags: wordpress-setup-self-signed-certificate\n\n- name: Create web root\n  file:\n    path: \"{{ www_root }}\"\n    owner: \"{{ web_user }}\"\n    group: \"{{ web_group }}\"\n    mode: 0755\n    state: directory\n  with_dict: \"{{ wordpress_sites }}\"\n\n- name: Create logs folder of sites\n  file:\n    path: \"{{ www_root }}/{{ item.key }}/logs\"\n    owner: \"{{ web_user }}\"\n    group: \"{{ web_group }}\"\n    mode: 0755\n    state: directory\n  with_dict: \"{{ wordpress_sites }}\"\n\n- include: nginx.yml\n  tags: wordpress-setup-nginx\n\n- name: Setup WP system cron\n  cron:\n    name: \"{{ item.key }} WordPress cron\"\n    minute: \"*/15\"\n    user: \"{{ web_user }}\"\n    job: \"curl -k -s {{ site_env.wp_siteurl }}/wp-cron.php > /dev/null 2>&1\"\n    cron_file: \"wordpress-{{ item.key | replace('.', '_') }}\"\n  with_dict: \"{{ wordpress_sites }}\"\n  when: site_env.disable_wp_cron and not item.value.multisite.enabled | default(false)\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "84785efbab4cb3c2c884c02e8cffddcee42b237e", "filename": "archive/roles/openstack-create/tasks/create-volume.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n- name: \"Create {{ instance_type }} Attached Storage\"\n  shell: \"nova volume-create --display-name {{ item.openstack.name + '-volume' }} {{ storage_volume_size }} |  awk '/ id / {print $4}'\"\n  register: created_volumes\n  failed_when: created_volumes.rc != 0\n  with_items: \"{{ openstack_machines.results }}\"\n\n\n- name: \"Validate {{ instance_type }} Attached Storage\"\n  shell: \"nova volume-show {{ item.stdout }} | grep -cE \\\"status.*available\\\"\"\n  register: validate_volumes\n  changed_when: false\n  until: validate_volumes.stdout == \"1\"\n  retries: 20\n  delay: 5\n  with_items: \"{{ created_volumes.results }}\"\n  \n\n- name: \"Attach {{ instance_type }} Storage\"\n  command: \"nova volume-attach {{ item.1.id }} {{ item.0.stdout }} {{ storage_disk_volume }}\"\n  with_together:\n    - \"{{ created_volumes.results }}\"\n    - \"{{ openstack_machines.results }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "e5d36a050b7258fd3c26af2b0864428debbf524a", "filename": "roles/virt-install/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Unmount install ISO'\n  mount:\n    path: \"{{ mounted_iso[item] }}\"\n    state: absent\n  with_items:\n  - \"{{ mounted_iso.keys() }}\"\n\n- name: 'Remove authorized_keys'\n  file: \n    path: \"{{ default_http_dir }}/{{ virtinstall_authorized_keys | basename }}\"\n    state: absent\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "313ae15c0876824f2c8a853c1a0dc99c5802a421", "filename": "roles/mongodb/templates/mongodb.service", "repository": "iiab/iiab", "decoded_content": "[Unit]\nDescription=High-performance, schema-free document-oriented database\nAfter=syslog.target network.target\n \n[Service]\nType=forking\nUser=mongodb\nGroup=mongodb\nPIDFile=/var/run/mongodb/mongod.pid\nEnvironmentFile=/etc/sysconfig/mongodb \nExecStart=/usr/bin/mongod -f /etc/mongod.conf\n \n[Install]\nWantedBy=multi-user.target\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "4bc7670cc1897529c280bd234034944b43bf0361", "filename": "roles/kiwix/README.rst", "repository": "iiab/iiab", "decoded_content": "============\nKIWIX README\n============\n\nKiwix is a set of Zim File readers from http://www.kiwix.org/wiki/Main_Page\nWe are using the kiwix-serve and kiwix-manage executables to setup and\nrender wikipedia and other web sources in zim format.\n\nLocations\n---------\n\n- The ZIM files are expected to be in /library/zims/content\n- The ZIM index files are expected to be in directories under /library/zims/index\n- The URL is /kiwix\n\nThe library.xml file can be recalculated by running iiab-make-kiwix-lib.\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "3988aee0678971dc06c0acd93cf5b36e7ef1f3d1", "filename": "roles/update-host/tasks/wait-for-host.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Set the host to wait for\"\n  set_fact:\n    update_host: \"{{ (hostvars[inventory_hostname]['ansible_host'] is defined) |\n                      ternary(hostvars[inventory_hostname]['ansible_host'],\n                              hostvars[inventory_hostname]['ansible_ssh_host']) }}\"\n\n- name: \"Waiting for server to come back\"\n  local_action: wait_for\n  args:\n    host: \"{{ update_host }}\"\n    port: 22\n    delay: 15\n    timeout: 300\n    state: started\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "aeb1bb57ed9ae179105b20496b6a545ac542d112", "filename": "roles/ovirt-common/defaults/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\novirt_engine_type: 'ovirt-engine'\novirt_repo_file: []\novirt_repo: []\n"}, {"commit_sha": "96adc61e360141bb718b75d48c387b3680a8471b", "sha": "b63cf087883540084d0ad8a1775b8e36a457d439", "filename": "tasks/checks.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- include_tasks: distribution-checks.yml\n  when:\n    _docker_os_dist_check | bool\n\n- include_tasks: compatibility-checks.yml\n"}, {"commit_sha": "0c050ee7f22968afdb69da3b859869efea2bfffa", "sha": "b2b3e1fcd1e0ba45fb6d9229eadd013171ffe35c", "filename": "tasks/install-pre5.yml", "repository": "geerlingguy/ansible-role-solr", "decoded_content": "---\n# Install Solr.\n- name: Check if Solr is already installed.\n  stat: \"path={{ solr_install_path }}/dist/{{ solr_filename }}.war\"\n  register: solr_war_file\n\n- name: Copy Solr into place.\n  command: \"cp -r {{ solr_workspace }}/{{ solr_filename }} {{ solr_install_path }}\"\n  when: not solr_war_file.stat.exists\n\n- name: Ensure Solr install files are owned by the solr_user.\n  file:\n    path: \"{{ solr_install_path }}\"\n    owner: \"{{ solr_user }}\"\n    group: \"{{ solr_user }}\"\n    recurse: yes\n  when: not solr_war_file.stat.exists\n\n# Set up solr_home.\n- name: Check if solr_home is already set up.\n  stat: \"path={{ solr_home }}/solr.xml\"\n  register: solr_example\n\n- name: Ensure solr_home directory exists.\n  file:\n    path: \"{{ solr_home }}\"\n    state: directory\n    owner: \"{{ solr_user }}\"\n    group: \"{{ solr_user }}\"\n    mode: 0755\n  when: not solr_example.stat.exists\n\n- name: Copy Solr example into solr_home.\n  shell: \"cp -r {{ solr_install_path }}/example/solr/* {{ solr_home }}\"\n  when: not solr_example.stat.exists\n\n- name: Fix the example solrconfig.xml file.\n  replace:\n    dest: \"{{ solr_home }}/collection1/conf/solrconfig.xml\"\n    regexp: ^.+solr\\.install\\.dir.+$\n    replace: \"\"\n  when: \"not solr_example.stat.exists and solr_version.split('.')[0] == '4'\"\n\n- name: Ensure Solr home files are owned by the solr_user.\n  file:\n    path: \"{{ solr_home }}\"\n    owner: \"{{ solr_user }}\"\n    group: \"{{ solr_user }}\"\n    recurse: yes\n  when: not solr_example.stat.exists\n\n# Set up Solr init script.\n- name: Ensure log file is created and has proper permissions.\n  file:\n    path: \"/var/log/solr.log\"\n    state: touch\n    owner: \"{{ solr_user }}\"\n    group: root\n    mode: 0664\n  changed_when: false\n\n- name: Copy solr init script into place.\n  template:\n    src: \"solr-init-{{ ansible_os_family }}-pre5.j2\"\n    dest: \"/etc/init.d/{{ solr_service_name }}\"\n    mode: 0755\n\n- name: Ensure daemon is installed (Debian).\n  apt: name=daemon state=present\n  when: ansible_os_family == \"Debian\"\n\n- name: Copy solr systemd unit file into place (for systemd systems).\n  template:\n    src: solr.unit.j2\n    dest: /etc/systemd/system/solr.service\n    owner: root\n    group: root\n    mode: 0755\n  when: >\n    (ansible_distribution == 'Ubuntu' and ansible_distribution_version == '16.04') or\n    (ansible_distribution == 'Debian' and ansible_distribution_version|int >= 8) or\n    (ansible_distribution == 'CentOS' and ansible_distribution_major_version|int >= 7) or\n    (ansible_distribution == 'Fedora')\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "627260af5d0143b993729913c384ee4602cf1630", "filename": "roles/ejabberd_xs/templates/ejabberd-xs", "repository": "iiab/iiab", "decoded_content": "## Settings for ejabberd\n\n## Where should ejabberd find its configuration file?\n#\nCONFIG_FILE=/etc/ejabberd/ejabberd-xs.cfg\n\n## ULIMIT_MAX_FILES alters the number of files that ejabberd is\n## allowed to have open at once.  If it is unset the system default\n## (usually 1024) will be used.  ejabberd will want over twice as many\n## open files as it has active connections, so if you have a few\n## hundred or more users you will want to set this.\n#\nULIMIT_MAX_FILES=40000\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "5f40903da64356ae6338827cc29d0c1a14441963", "filename": "roles/openvpn/templates/iiab-remote-on", "repository": "iiab/iiab", "decoded_content": "#!/bin/bash\n# script to turn on openvpn\n\n# do nothing if it is not installed\nwhich openvpn\nif [ $? -ne 0 ]; then\n   echo Cannot find the openvpn program.\n   exit 1\nfi\nsystemctl enable openvpn@xscenet.service\nsystemctl start openvpn@xscenet.service\n\nsleep 5\nping -c 2 10.8.0.1\nif [ $? -eq 0 ]; then\n  echo Openvpn successfully started.\nelse\n  echo Openvpn failed to contact remote server.\nfi\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "9e093fe0909b95788587e3a4977483b28e619762", "filename": "roles/config-dns-server/test/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: dns-servers\n  roles:\n  - role: config-dns-server\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "4876d36f339f7b9e9ce28ce23c8e9e02282c9a35", "filename": "roles/load-balancers/manage-haproxy/tasks/activate-config.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# Use a 'block' to ensure \"become: True\" for all tasks requiring elevated privileges\n- block:\n\n  - name: 'Copy the HAproxy config file to a temp location for validity checking'\n    copy:\n      src: '{{ haproxy_temp_file }}'\n      dest: '{{ temp_new_file }}'\n\n  - name: 'Check the validity'\n    command: 'haproxy -c -f {{ temp_new_file }}'\n    notify: 'remove tmp new file'\n\n  - name: 'Copy and activate the HAproxy config file'\n    copy:\n      src: '{{ haproxy_temp_file }}'\n      dest: '/etc/haproxy/haproxy.cfg'\n      backup: 'yes'\n    notify: 'reload haproxy'\n\n  - name: 'Open Firewall for LB use (TCP only)'\n    firewalld:\n      port: \"{{ fe.lb_host_port }}/tcp\"\n      permanent: yes\n      state: enabled\n      immediate: yes\n    loop_control:\n      loop_var: fe\n    loop: \"{{ lb_config.frontends|flatten(levels=1) }}\"\n\n  - name: 'Tweak SELinux for LB use (TCP only)'\n    seport:\n      ports: \"{{ fe.lb_host_port }}\"\n      proto: tcp\n      setype: http_port_t\n      state: present\n    loop_control:\n      loop_var: fe\n    loop: \"{{ lb_config.frontends|flatten(levels=1) }}\"\n\n  # End of outer block for \"become: True\"\n  become: True\n\n- name: 'Clean-up the temp file'\n  file:\n    path: \"{{ haproxy_temp_file }}\"\n    state: absent\n  when:\n  - (clean_up_temp|default('yes'))|lower == 'yes'\n  delegate_to: localhost\n  run_once: True\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "8964faa18cce732483280962a948f838e675f94a", "filename": "roles/vpn/tasks/freebsd.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- name: FreeBSD / HardenedBSD | Get the existing kernel parameters\n  command: sysctl -b kern.conftxt\n  register: kern_conftxt\n  when: rebuild_kernel is defined and rebuild_kernel == \"true\"\n\n- name: FreeBSD / HardenedBSD | Set the rebuild_needed fact\n  set_fact:\n    rebuild_needed: true\n  when: item not in kern_conftxt.stdout and rebuild_kernel is defined and rebuild_kernel == \"true\"\n  with_items:\n    - \"IPSEC\"\n    - \"IPSEC_NAT_T\"\n    - \"crypto\"\n\n- name: FreeBSD / HardenedBSD | Make the kernel config\n  shell: >\n    sysctl -b kern.conftxt > /tmp/IPSEC\n  when: rebuild_needed is defined and rebuild_needed == true\n\n- name: FreeBSD / HardenedBSD | Ensure the all options are enabled\n  lineinfile:\n    dest: /tmp/IPSEC\n    line: \"{{ item }}\"\n    insertbefore: BOF\n  with_items:\n    - \"options\tIPSEC\"\n    - \"options IPSEC_NAT_T\"\n    - \"device\tcrypto\"\n  when: rebuild_needed is defined and rebuild_needed == true\n\n- name: HardenedBSD | Determine the sources\n  set_fact:\n    sources_repo: https://github.com/HardenedBSD/hardenedBSD.git\n    sources_version: \"hardened/{{ ansible_distribution_release.split('.')[0] }}-stable/master\"\n  when: \"'Hardened' in ansible_distribution_version\"\n\n- name: FreeBSD | Determine the sources\n  set_fact:\n    sources_repo: https://github.com/freebsd/freebsd.git\n    sources_version: \"stable/{{ ansible_distribution_major_version }}\"\n  when: \"'Hardened' not in ansible_distribution_version\"\n\n- name: FreeBSD / HardenedBSD | Increase the git postBuffer size\n  git_config:\n    name: http.postBuffer\n    scope: global\n    value: 1048576000\n\n- block:\n    - name: FreeBSD / HardenedBSD | Fetching the sources...\n      git:\n        repo: \"{{ sources_repo }}\"\n        dest: /usr/krnl_src\n        version: \"{{ sources_version }}\"\n        accept_hostkey: true\n      async: 1000\n      poll: 0\n      register: fetching_sources\n\n    - name: FreeBSD / HardenedBSD | Fetching the sources...\n      async_status: jid={{ fetching_sources.ansible_job_id }}\n      when: rebuild_needed is defined and rebuild_needed == true\n      register: result\n      until: result.finished\n      retries: 600\n      delay: 30\n  rescue:\n    - debug: var=fetching_sources\n\n    - fail:\n        msg: \"Something went wrong. Check the debug output above.\"\n\n- block:\n    - name: FreeBSD / HardenedBSD | The kernel is being built...\n      shell: >\n          mv /tmp/IPSEC /usr/krnl_src/sys/{{ ansible_architecture }}/conf &&\n          make buildkernel KERNCONF=IPSEC &&\n          make installkernel KERNCONF=IPSEC\n      args:\n        chdir: /usr/krnl_src\n        executable: /usr/local/bin/bash\n      when: rebuild_needed is defined and rebuild_needed == true\n      async: 1000\n      poll: 0\n      register: building_kernel\n\n    - name: FreeBSD / HardenedBSD | The kernel is being built...\n      async_status: jid={{ building_kernel.ansible_job_id }}\n      when: rebuild_needed is defined and rebuild_needed == true\n      register: result\n      until: result.finished\n      retries: 600\n      delay: 30\n  rescue:\n    - debug: var=building_kernel\n\n    - fail:\n        msg: \"Something went wrong. Check the debug output above.\"\n\n- name: FreeBSD / HardenedBSD | Reboot\n  shell: >\n    sleep 2 && shutdown -r now\n  args:\n    executable: /usr/local/bin/bash\n  when: rebuild_needed is defined and rebuild_needed == true\n  async: 1\n  poll: 0\n  ignore_errors: true\n\n- name: FreeBSD / HardenedBSD | Enable strongswan\n  lineinfile: dest=/etc/rc.conf regexp=^strongswan_enable= line='strongswan_enable=\"YES\"'\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "5d0918f70d28050c111f03c290b0494e26734d8a", "filename": "roles/ovirt-guest-agent/tasks/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "- name: Install latest {{ ovirt_guest_agent_pkg_prefix }}-guest-agent\n  yum:\n    name: \"{{ item }}\"\n    state: latest\n  with_items:\n    - \"{{ ovirt_guest_agent_pkg_prefix }}-guest-agent\"\n  notify: enable and start {{ ovirt_guest_agent_pkg_prefix }}-guest-agent\n  tags:\n    - skip_ansible_lint\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "206b4da8c114b64a8859725538fc75bb9092dde9", "filename": "roles/dcos_cli/vars/cassandra.yml", "repository": "Capgemini/Apollo", "decoded_content": "dcos_cli_framework_cassandra_enabled: false\ndcos_cli_framework_cassandra_node_count: 1\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "41dad890a6bc3e0f56f1a7f63035362449e779b6", "filename": "tasks/section_13.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - include: section_13_level1.yml\n    tags:\n      - section13\n      - level1\n\n"}, {"commit_sha": "b7c6bfe0369646ca69beeb3dfe07e8218d61c940", "sha": "9f922e2f8fe30377cf75a50b182ad420cda387a4", "filename": "tasks/securetty.yml", "repository": "dev-sec/ansible-os-hardening", "decoded_content": "---\n- name: create securetty\n  template:\n    src: 'securetty.j2'\n    dest: '/etc/securetty'\n    owner: 'root'\n    group: 'root'\n    mode: '0400'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "21e0696a090202f7ffef057d8cc8c6d091508f2b", "filename": "roles/setup-slack/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Initialise channels name to id mapping\n  set_fact:\n    channel_mapping: {}\n\n- name: Create channels\n  include_tasks: create_channels.yml\n  with_items: \"{{ slack_channels }}\"\n  loop_control:\n    loop_var: channel\n\n- name: Invite users\n  include_tasks: invite_users.yml\n  with_items: \"{{ slack_users }}\"\n  loop_control:\n    loop_var: user\n"}, {"commit_sha": "0c050ee7f22968afdb69da3b859869efea2bfffa", "sha": "d7a05210949b18e944e85902b3e13117ed72632f", "filename": "tasks/cores.yml", "repository": "geerlingguy/ansible-role-solr", "decoded_content": "---\n- name: Check current list of Solr cores.\n  uri:\n    url: http://{{ solr_connect_host }}:{{ solr_port }}/solr/admin/cores\n    return_content: yes\n  register: solr_cores_current\n\n- name: Ensure Solr conf directories exist.\n  file:\n    path: \"{{ solr_home }}/data/{{ item }}/conf\"\n    state: directory\n    owner: \"{{ solr_user }}\"\n    group: \"{{ solr_user }}\"\n    recurse: yes\n  when: \"item not in solr_cores_current.content\"\n  with_items: \"{{ solr_cores }}\"\n\n- name: Ensure core configuration directories exist.\n  shell: \"cp -r {{ solr_install_path }}/example/files/conf/ {{ solr_home }}/data/{{ item }}/\"\n  when: \"item not in solr_cores_current.content\"\n  with_items: \"{{ solr_cores }}\"\n  become: yes\n  become_user: \"{{ solr_user }}\"\n\n- name: Create configured cores.\n  shell: \"{{ solr_install_path }}/bin/solr create -c {{ item }}\"\n  when: \"item not in solr_cores_current.content\"\n  with_items: \"{{ solr_cores }}\"\n  become: yes\n  become_user: \"{{ solr_user }}\"\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "cd386bba40eea09d15637010bf7326ac3561ac0e", "filename": "roles/ansible/tower/manage-inventories/tests/inventory/group_vars/tower.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\ntower_admin_password: \"admin01\"\n\nansible_tower_inventories:\n- name: \"Inventory1\"\n  description: \"My Hosts\"\n  organization: \"Default\"\n  variables: \"---\"\n  hosts:\n  - name: \"localhost\"\n    description: \"\"\n    variables: \"---\\\\nansible_connection: local\"\n  groups:\n  - name: \"seed_hosts\"\n    hosts:\n    - name: \"localhost\"\n"}, {"commit_sha": "2a05a5032ce341d6a1d918453164c59ea2922f58", "sha": "6c893dfc94637973ef5ca363d35ec0d1b4441a47", "filename": "roles/provision_vm/tasks/main.yml", "repository": "CSCfi/fgci-ansible", "decoded_content": "---\n- name: copy over kickstart file\n  template: src=\"kickstart.cfg\" dest=\"{{ kickstart_tempdir }}/{{ inventory_hostname.split('.').0 }}.ks\"\n  sudo: yes\n  delegate_to: \"{{ hyper }}\"\n\n- name: copy over virt-install script\n  template: src=\"virt-install.sh\" dest=\"{{ kickstart_tempdir }}/{{ inventory_hostname.split('.').0 }}-install.sh\"\n  sudo: yes\n  delegate_to: \"{{ hyper }}\"\n\n- name: creates VM disks directory\n  file: path={{ libvirt_pool_path }} state=directory owner=qemu group=qemu mode=0770\n  run_once: true\n  delegate_to: \"{{ hyper }}\"\n\n- name: Check libvirt storage pool\n  command: /usr/bin/virsh pool-info {{ libvirt_pool_name }}\n  register: libvirt_pool_check\n  run_once: true\n  ignore_errors: true\n  delegate_to: \"{{ hyper }}\"\n\n- name: Define libvirt storage pool\n  command: /usr/bin/virsh pool-define-as {{ libvirt_pool_name }} {{ libvirt_pool_type }} --target {{ libvirt_pool_path }}\n  run_once: true\n  when: libvirt_pool_check.rc == 1\n  delegate_to: \"{{ hyper }}\"\n\n- name: Start libvirt storage pool\n  command: /usr/bin/virsh pool-start {{ libvirt_pool_name }}\n  run_once: true\n  delegate_to: \"{{ hyper }}\"\n\n- name: set libvirt storage pool autostart\n  command: /usr/bin/virsh pool-autostart {{ libvirt_pool_name }}\n  run_once: true\n  delegate_to: \"{{ hyper }}\"\n\n- name: run virt-install script\n  command: \"bash {{ kickstart_tempdir }}/{{ inventory_hostname.split('.').0 }}-install.sh\"\n  sudo: yes\n  #environment: env_virt_install\n  environment: { http_proxy: \"\" }\n  args:\n    creates: \"/etc/libvirt/qemu/{{ inventory_hostname.split('.').0 }}.xml\"\n  delegate_to: \"{{ hyper }}\"\n\n- name: wait for VM to become available before continuing\n  wait_for: port=22 host=\"{{ fqdn }}\" timeout=600\n  delegate_to: \"{{ hyper }}\"\n\n- name: set vm to autostart\n  command: /bin/virsh autostart \"{{ inventory_hostname.split('.').0 }}\"\n  delegate_to: \"{{ hyper }}\"\n\n- name: Remove kickstart file\n  file: path=\"{{ kickstart_tempdir }}/{{ inventory_hostname.split('.').0 }}.ks\" state=absent\n  delegate_to: \"{{ hyper }}\"\n\n- name: Remove install script\n  file: path=\"{{ kickstart_tempdir }}/{{ inventory_hostname.split('.').0 }}-install.sh\" state=absent\n  delegate_to: \"{{ hyper }}\"\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "fc89b6a4c12e7d9087afc35da18c0bdb88252470", "filename": "playbooks/roles/bb0-openstack/provisioner-image/Dockerfile", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "#FROM  registry.access.redhat.com/rhel7/rhel\nFROM registry.access.redhat.com/openshift3/jenkins-slave-base-rhel7\nARG RH_ORG_ID\nARG RH_ACTIVATIONKEY\nARG RH_POOL_ID   \n\n\nRUN subscription-manager register --org=$RH_ORG_ID --activationkey=$RH_ACTIVATIONKEY --name=temp-containerbuild-$(date +\"%s\")  && \\\n# ToDo: subscription-manager attach --pool=... FAILED with:\n#       This unit has already had the subscription matching pool ID \"8a85f99c65c8c91b0166c4c531662125\" attached.\n    subscription-manager attach --pool=$RH_POOL_ID ;\\\n    subscription-manager repos --disable=* && \\\n    subscription-manager repos --enable=rhel-7-server-rpms \\\n        --enable=rhel-7-server-extras-rpms \\\n        --enable=rhel-7-server-ose-3.11-rpms \\\n        --enable=rhel-7-server-ansible-2.6-rpms \\\n        --enable=rhel-7-server-openstack-14-rpms \\\n#        --enable=rhel-7-server-openstack-14-devtools-rpms \\\n    && \\\n    yum install -y  openshift-ansible python2-openstacksdk.noarch \\\n                    python2-shade.noarch python2-openstackclient.noarch \\\n                    telnet && \\\n    subscription-manager unregister\n\n    # yum install -y ansible \\\n    #                openssh-clients.x86_64 \\\n    #                python2-openstacksdk.noarch \\ \n    #                python2-shade.noarch \\\n    #                python2-openstackclient.noarch \\\n    #                telnet\n    #                # Important for os_loadbalancer\n    #                python2-urllib3.noarch  python2-chardet.noarch\n#RUN subscription-manager unregister\n\n\n# Tunnel: ssh -o \"DynamicForward 127.0.0.1:65432\" -i /work/q-root-id_rsa q.bohne.io -fN\n# export ALL_PROXY=socks5h://127.0.0.1:65432\n# ENV ALL_PROXY=socks5h://127.0.0.1:65432\n"}, {"commit_sha": "86724cf84fd0fc05d82f8d3dd677b4674cba1338", "sha": "d81f61303e8261800493632a8cec60038c82012c", "filename": "tasks/configure-Debian.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n\nhttpd_package_name: \"apache2\"\nhttpd_config_dir: \"/etc/{{ httpd_package_name }}/sites-enabled\"\ncertificate_file_dest: \"/etc/ssl/certs\"\ncertificate_key_dest: \"/etc/ssl/private\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "b80ad05cc21d8a9c9093c94c1c8e04d389fff553", "filename": "playbooks/osp/manage-user-network.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# See the roles README for detailed info on inventory requirements.\n# https://github.com/redhat-cop/infra-ansible/blob/master/roles/osp/admin-network/README.md\n\n- hosts: osp-provisioner\n  roles:\n  - osp/admin-network\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "7bf2853697f0dc9b549aa05e0c072f6535b4e56e", "filename": "playbooks/roles/check_disks/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- shell: |\n    lsblk -r | grep -c disk\n  register: number_of_disks\n- name: check number of disks in nodes\n  fail:\n    msg: All nodes and masters need 2+ disks\n  when: \"number_of_disks.stdout|int < 2 and inventory_hostname in groups['nodes']\"\n- name: check number of disks in OCS nodes\n  fail:\n    msg: All nodes running OCS need 3+ disks\n  when: \"number_of_disks.stdout|int < 3 and inventory_hostname in groups['glusterfs']\"\n"}, {"commit_sha": "96adc61e360141bb718b75d48c387b3680a8471b", "sha": "61ac429e562756dadd4e3e8ca5abac923e87a024", "filename": "meta/main.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "galaxy_info:\n  author: Bjorn Oscarsson\n  description: \"Installs and configures Docker Community Edition (CE)\"\n  min_ansible_version: 2.4\n  license: MIT\n  platforms:\n  - name: Fedora\n    versions:\n      - 24\n      - 25\n      - 26\n\n  - name: EL\n    versions:\n      - 7\n\n  - name: Debian\n    versions:\n      - jessie\n      - stretch\n\n  - name: Ubuntu\n    versions:\n      - trusty\n      - xenial\n\n  galaxy_tags:\n    - docker\n    - containers\n    - system\n\ndependencies: []\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "11a4b1d2ae3256cddeba4cffac122a86b7b19e25", "filename": "roles/kiwix/templates/iiab-make-kiwix-lib", "repository": "iiab/iiab", "decoded_content": "#!/bin/sh\n\n{{ systemctl_program }} stop kiwix-serve\n/usr/bin/iiab-make-kiwix-lib.py\n/usr/bin/iiab-make-apache-config.py\n{{ systemctl_program }} start kiwix-serve\n\nexit 0\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "171ac89f4ba988dbc91893f9091d13354171af38", "filename": "archive/roles/cicd/tasks/main.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n\n- name: Register Attached Block Storage\n  stat:\n    path: \"{{ cicd_storage_disk_volume }}\"\n  register: block_device\n  \n- name: Validate Block Device\n  fail: msg=\"Attached device at {{ cicd_storage_disk_volume }} is not present\"\n  failed_when: block_device.stat.exists == false\n  \n- name: Creates Temporary Directory\n  file:\n    path: \"{{cicd_temp_dir}}\"\n    state: directory\n  \n- include: prerequisites.yml\n\n- include: java.yml\n\n- include: groovy.yml\n\n- include: maven.yml\n\n- include: nexus.yml\n\n- include: httpd.yml\n\n- include: docker.yml\n\n- include: jenkins.yml"}, {"commit_sha": "7c574f3b148b4df43177a5c0fc398ce4bea6ae3e", "sha": "db45c3c6db880f4ff5a0bc243160b9c1f71cbf24", "filename": "tasks/homebrew_build_depends.yml", "repository": "zzet/ansible-rbenv-role", "decoded_content": "---\n- homebrew: name={{ item }} state=present\n  with_items:\n    - openssl\n    - libyaml\n\n# required for building Ruby <= 1.9.3-p0\n- homebrew_tap: tap=homebrew/dupes state=present\n  when: rbenv.ruby_version <= '1.9.3-p0'\n\n- homebrew: name=apple-gcc42 state=present\n  when: rbenv.ruby_version <= '1.9.3-p0'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "83f4c4a4d9820b52cfdbb32dec1bc9ac055857d1", "filename": "roles/dns/manage-dns-zones-route53/tasks/loop-records.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Loop through zone records\n  include_tasks: empty-zone.yml\n  with_subelements:\n    - \"{{ r53_zone.ResourceRecordSets }}\"\n    - ResourceRecords\n  loop_control:\n    loop_var: r53_record\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "00f972a0a7fe08a3b24f6275f321b7322e31a51f", "filename": "tasks/setup-repository-RedHat.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Include tasks from setup of repositories for CentOS\n  include_tasks: setup-repository-CentOS.yml\n\n# disable rt-beta so we don't get a 403 error retrieving repomd.xml\n- name: Check if rhel-7-server-rt-beta-rpms Repository is enabled (RedHat)\n  become: true\n  shell: \"subscription-manager repos --list-enabled | grep rhel-7-server-rt-beta-rpms\"\n  register: cmd_rhel_rt_beta_repo_enabled\n  changed_when: false\n  failed_when: cmd_rhel_rt_beta_repo_enabled.rc not in [ 0, 1 ]\n  tags:\n    - skip_ansible_lint\n\n- name: Disable rhel-7-server-rt-beta-rpms Repository (RedHat)\n  become: true\n  shell: \"subscription-manager repos --disable=rhel-7-server-rt-beta-rpms\"\n  when: cmd_rhel_rt_beta_repo_enabled.rc == 0\n  tags:\n    - skip_ansible_lint\n\n# container-selinux package wants this\n- name: Check if rhel-7-server-extras-rpms Repository is enabled (RedHat)\n  become: true\n  shell: \"subscription-manager repos --list-enabled | grep rhel-7-server-extras-rpms\"\n  register: cmd_rhel_extras_repo_enabled\n  when: _docker_os_dist == \"RedHat\"\n  changed_when: false\n  failed_when: cmd_rhel_extras_repo_enabled.rc not in [ 0, 1 ]\n  tags:\n    - skip_ansible_lint\n\n- name: Enable rhel-7-server-extras-rpms Repository (RedHat)\n  become: true\n  shell: \"subscription-manager repos --enable=rhel-7-server-extras-rpms\"\n  when: cmd_rhel_extras_repo_enabled.rc == 1\n  tags:\n    - skip_ansible_lint"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "5a4222f444ad43da513079ee72cff57f3c996e69", "filename": "roles/dns/manage-dns-zones-bind/handlers/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: restart named\n  service:\n    name: named\n    state: restarted\n\n- name: reload named\n  service:\n    name: named\n    state: reloaded\n\n- name: cleanup temp\n  file:\n    path: \"{{ dns_zone_temp_config_dir }}\"\n    state: absent\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "59e5957c78f0f2fd0647da8d9aad7ef2bdfb511a", "filename": "tasks/Linux/install/Debian.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Install java packages\n  apt:\n    deb: '{{ java_artifact | default(omit) }}'\n    name: '{{ (jdk_package if transport == \"repositories\") | default(omit) }}'\n    state: present\n    update_cache: true\n    cache_valid_time: 3600\n  register: package_install\n  until: package_install is succeeded\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "23c611dc445117dd65496eaa1ce8d40216ab08c8", "filename": "tasks/create_repo_npm_group_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_npm_group\n    args: \"{{ _nexus_repos_npm_defaults|combine(item) }}\"\n"}, {"commit_sha": "f958689395b3fc98cacf0c605ed7b8b4b19718da", "sha": "6e88deca9c8b784af377d164e211c09dce64c786", "filename": "tasks/deploy_netbox.yml", "repository": "lae/ansible-role-netbox", "decoded_content": "---\n- name: Create NetBox application directories\n  file:\n    path: \"{{ item }}\"\n    state: directory\n  with_items:\n    - \"{{ netbox_releases_path }}\"\n    - \"{{ netbox_shared_path }}\"\n\n- include: \"install_via_{{ 'git' if netbox_git else 'stable' }}.yml\"\n\n- include: generate_secret_key.yml\n  when:\n    - netbox_config.SECRET_KEY is not defined\n\n- name: Create NetBox virtualenv and install needed Python dependencies\n  pip:\n    requirements: \"{{ netbox_current_path }}/requirements.txt\"\n    virtualenv: \"{{ netbox_virtualenv_path }}\"\n    virtualenv_python: \"{{ netbox_python3_binary if (netbox_python == 3) else netbox_python2_binary }}\"\n\n- name: Generate NetBox configuration file\n  template:\n    src: templates/configuration.py.j2\n    dest: \"{{ netbox_shared_path }}/configuration.py\"\n    mode: 0640\n  notify:\n    - reload netbox.service\n\n- block:\n  - name: Install django-auth-ldap if LDAP is enabled\n    pip:\n      name: django-auth-ldap\n      virtualenv: \"{{ netbox_virtualenv_path }}\"\n\n  - name: Generate LDAP configuration for NetBox if enabled\n    template:\n      src: \"{{ netbox_ldap_config_template }}\"\n      dest: \"{{ netbox_shared_path }}/ldap_config.py\"\n      mode: 0640\n    notify:\n      - reload netbox.service\n  when:\n    - netbox_ldap_enabled\n\n- name: Symlink NetBox configuration file into the active NetBox release\n  file:\n    src: \"{{ netbox_shared_path }}/configuration.py\"\n    dest: \"{{ netbox_config_path }}/configuration.py\"\n    state: link\n\n- name: Symlink/Remove NetBox LDAP configuration file into/from the active NetBox release\n  file:\n    src: \"{{ netbox_shared_path }}/ldap_config.py\"\n    dest: \"{{ netbox_config_path }}/ldap_config.py\"\n    state: \"{{ 'link' if netbox_ldap_enabled else 'absent' }}\"\n  notify:\n    - reload netbox.service\n\n- name: Run database migrations for NetBox\n  django_manage:\n    command: migrate\n    app_path: \"{{ netbox_current_path }}/netbox\"\n    virtualenv: \"{{ netbox_virtualenv_path }}\"\n\n- name: Create a super user for NetBox\n  shell: \"printf '{{ netbox_superuser_script }}' | {{ netbox_virtualenv_path }}/bin/python {{ netbox_current_path }}/netbox/manage.py shell\"\n  register: __netbox_superuser_result\n  changed_when: \"'changed' in __netbox_superuser_result.stdout\"\n  when:\n    - not netbox_ldap_enabled\n\n- name: Generate static assets for NetBox\n  django_manage:\n    command: collectstatic\n    app_path: \"{{ netbox_current_path }}/netbox\"\n    virtualenv: \"{{ netbox_virtualenv_path }}\"\n\n- name: Populate NetBox with initial data\n  django_manage:\n    command: loaddata\n    fixtures: initial_data\n    app_path: \"{{ netbox_current_path }}/netbox\"\n    virtualenv: \"{{ netbox_virtualenv_path }}\"\n  when:\n    - netbox_load_initial_data\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "860e8ad8e798a58b2152bc0e12ab53680353bc74", "filename": "roles/config-satellite/tests/group_vars/satellite_servers.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# NOTE: Make sure a valid 'manifest.zip' file exists in the `files` directory before running this test\nmanifest_file_path: \"{{ inventory_dir }}/files/manifest.zip\"\n\nsatellite_organization: \"Example Org\"\nsatellite_location: \"example\"\nsatellite_username: \"admin\"\nsatellite_password: \"admin01\"\n\nsatellite_repositories:\n- product: \"Red Hat Enterprise Linux Server\"\n  name: \"Red Hat Enterprise Linux 7 Server (RPMs)\"\n  release_version:\n  - \"7.3\"\n  - \"7Server\"\n  base_arch: \"x86_64\"\n- product: \"Red Hat Enterprise Linux Server\"\n  name: \"Red Hat Enterprise Linux 7 Server - Extras (RPMs)\"\n  release_version: []\n  base_arch: \"x86_64\"\n\nsatellite_sync_plan: \"example-plan\"\n\n\n# NOTE: Make sure to update the 'Your name  here' below with a matching \n#       name for your subscription - i.e.: something that will match a \"grep\" \nsatellite_activation_keys:\n  rhel-7-example\n    subscription: \"Your name here\"\n\n"}, {"commit_sha": "9662c15ce2e4260fac5cc2bfdf5aaaaf0a2191dd", "sha": "5fb2fb9ee3c5b833a047058872cb18c0d5cd7472", "filename": "tasks/section_01_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 1.1.1 Install Updates, Patches and Additional Security Software (NotScored)\n    apt: update_cache=yes\n    tags:\n      - section1\n      - section1.1\n      - section1.1.1\n\n  - name: 1.1.2 Install Updates, Patches and Additional Security Software (NotScored)\n    apt: upgrade=yes\n    when: travis_env == False\n    tags:\n      - section1\n      - section1.1\n      - section1.1.2\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "19f7f7a873b3e65eb005f7da5a469ace8702fabc", "filename": "roles/nextcloud/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "nextcloud_install: True\nnextcloud_enabled: False\n\nnextcloud_url: /nextcloud\nnextcloud_prefix: /opt\nnextcloud_data_dir: /library/nextcloud/data\nnextcloud_dl_url: https://download.nextcloud.com/server/releases/\nnextcloud_src_file: latest-12.tar.bz2\n\n# we install on mysql with these setting or those from default_vars, etc.\nnextcloud_dbname: nextcloud\nnextcloud_dbhost: localhost\nnextcloud_dbuser: nextcloud\nnextcloud_dbpassword: nextcloudmysql\nnextcloud_user: nextcloud\nnextcloud_user_password: nextcloudmysql\n\nnextcloud_admin_user: 'Admin'\nnextcloud_admin_password: 'changeme'\n\nnextcloud_required_ip: 10.0.0.0/8 192.168.0.0/16\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "69905c3fc965d16b07e4dad379fc98b02fa64ae8", "filename": "roles/rachel/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "rachel_url: /rachel\nrachel_content_path: /library/rachel/www\nrachel_mysqldb_path: /library/rachel/bin/database/mysql-5.6.20/data/sphider_plus/\n\n# These two must be in sync, second saves parsing\nrachel_src_url: http://rachelfriends.org/downloads/public_ftp/rachelusb_32EN/rachelusb_32EN_3.1.5.zip\nrachel_version: rachelusb_32EN_3.1.5\n\nrachel_install: False\nrachel_enabled: False\nrachel_content_found: False\n"}, {"commit_sha": "9662c15ce2e4260fac5cc2bfdf5aaaaf0a2191dd", "sha": "8aa41302ca674ac79a3655e6e1a4c1a0a6acbda7", "filename": "tasks/section_07_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 7.1.1 Disable IP Forwarding (Scored)\n    sysctl: >\n      name=net.ipv4.ip_forward\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.1\n\n  - name: 7.1.2.1 Disable Send Packet Redirects (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.2\n      - section7.1.2.1\n\n  - name: 7.1.2.2 Disable Send Packet Redirects (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.2\n      - section7.1.2.2\n\n  - name: 7.2.1 Modify Network Parameters (Host and Router)\n    sysctl: >\n      name=net.ipv4.conf.all.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.1\n\n  - name: 7.2.2 Modify Network Parameters (Host and Router)\n    sysctl: >\n      name=net.ipv4.conf.default.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.2\n\n  - name: 7.2.1.1 Disable Source Routed Packet Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.accept_source_route\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.1\n      - section7.2.1.1\n\n  - name: 7.2.1.2 Disable Source Routed Packet Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.accept_source_route\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.1\n      - section7.2.1.2\n\n  - name: 7.2.2.1 Disable ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.2\n      - section7.2.2.1\n\n  - name: 7.2.2.2 Disable ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.2\n      - section7.2.2.2\n\n  - name: 7.2.3.1 Disable Secure ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.secure_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.3\n      - section7.2.3.1\n\n  - name: 7.2.3.2 Disable Secure ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.secure_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.3\n      - section7.2.3.2\n\n  - name: 7.2.4.1 Log Suspicious Packets (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.log_martians\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.4\n      - section7.2.4.1\n\n  - name: 7.2.4.2 Log Suspicious Packets (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.log_martians\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.4\n      - section7.2.4.2\n\n  - name: 7.2.5 Enable Ignore Broadcast Requests (Scored)\n    sysctl: >\n      name=net.ipv4.icmp_echo_ignore_broadcasts\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.5\n\n  - name: 7.2.6 Enable Bad Error Message Protection (Scored)\n    sysctl: >\n      name=net.ipv4.icmp_ignore_bogus_error_responses\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.6\n\n  - name: 7.2.7.1 Enable RFC-recommended Source Route Validation (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.rp_filter\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.7\n      - section7.2.7.1\n\n  - name: 7.2.7.2 Enable RFC-recommended Source Route Validation (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.rp_filter\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.7\n      - section7.2.7.2\n\n  - name: 7.2.8 Enable TCP SYN Cookies (Scored)\n    sysctl: >\n      name=net.ipv4.tcp_syncookies\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.8\n\n  - name: 7.3 Configure IPv6\n    sysctl: >\n      name=net.ipv4.tcp_syncookies\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n\n  - name: 7.3.1.1 Disable IPv6 Router Advertisements (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.all.accept_ra\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.1\n      - section7.3.1.1\n\n  - name: 7.3.1.2 Disable IPv6 Router Advertisements (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.default.accept_ra\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.1\n      - section7.3.1.2\n\n  - name: 7.3.2.1 Disable IPv6 Redirect Acceptance (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.all.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.2\n      - section7.3.2.1\n\n  - name: 7.3.2.2 Disable IPv6 Redirect Acceptance (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.default.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.2\n      - section7.3.2.2\n\n  - name: 7.3.3 Disable IPv6 (Not Scored)\n    sysctl: >\n      name={{ item }}\n      value=1\n      state=present\n    with_items:\n      - net.ipv6.conf.all.disable_ipv6\n      - net.ipv6.conf.default.disable_ipv6\n      - net.ipv6.conf.lo.disable_ipv6\n    when: travis_env == False\n    tags:\n      - section7\n      - section7.3\n      - section7.3.3\n\n  - name: 7.4.1 Install TCP Wrappers (Scored)\n    apt: name=tcpd state=present\n    tags:\n      - section7\n      - section7.4\n      - section7.4.1\n\n  - name: 7.4.2 Create /etc/hosts.allow (Not Scored)\n    debug: msg=\"*** Verify /etc/hosts.allow ***\"\n    tags:\n      - section7\n      - section7.4\n      - section7.4.2\n\n  - name: 7.4.3 Verify Permissions on /etc/hosts.allow (Scored)\n    file: >\n        path=/etc/hosts.allow\n        owner=root\n        group=root\n        mode=0644\n    tags:\n      - section7\n      - section7.4\n      - section7.4.3\n\n  - name: 7.4.4 Create /etc/hosts.deny (Not Scored)\n    debug: msg='*** Verify /etc/hosts.deny ***'\n    tags:\n      - section7\n      - section7.4\n      - section7.4.4\n\n  - name: 7.4.5 Verify Permissions on /etc/hosts.deny (Scored)\n    file: >\n        path=/etc/hosts.deny\n        owner=root\n        group=root\n        mode=0644\n    tags:\n      - section7\n      - section7.4\n      - section7.4.5\n\n  - name: Check the presence of the file \"cis.conf\" under modprobe.d\n    stat: >\n        path=/etc/modprobe.d/CIS.conf\n    register: cis_conf_file\n    tags:\n      - section7\n      - section7.5\n\n  - name: Create the file \"cis.conf\" under modprobe.d if doesn't exist\n    file: >\n        dest=/etc/modprobe.d/CIS.conf state=touch\n    when: not cis_conf_file.stat.exists\n    tags:\n      - section7\n      - section7.5\n\n  - name: 7.5.1-4 Disable DCCP, SCTP, RDS, TIPC (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install {{ item }} /bin/true'\n        state=present\n    with_items:\n        - dccp\n        - sctp\n        - rds\n        - tipc\n    tags:\n      - section7\n      - section7.5\n      - section7.5.1\n      - section7.5.2\n      - section7.5.3\n      - section7.5.4\n\n  - name: 7.6 Deactivate Wireless Interfaces (Not Scored)\n    shell: 'lspci -k | grep -i wifi'\n    changed_when: False\n    register: lspci_wifi\n    failed_when: lspci_wifi.rc == 0\n    tags:\n      - section7\n      - section7.6\n\n  - name: 7.7 Ensure Firewall is active (install) (Scored)\n    apt: >\n        name=ufw\n        state=present\n    when: activate_ufw\n    tags:\n      - section7\n      - section7.7\n\n  - name: 7.7 Ensure Firewall is active (Scored)\n    service: >\n        name=ufw\n        state=started\n    when: activate_ufw\n    tags:\n      - section7\n      - section7.7\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "8b2f6721b3113b665688926630d91da3d0f20e8e", "filename": "tasks/Win32NT/fetch/fetch_checksum.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: 'Download artifact from {{ artifact_url }}'\n  win_get_url:\n    url: '{{ artifact_url }}'\n    dest: '{{ java_download_path }}\\{{ artifact_basename }}'\n    force: true\n\n- name: 'Get {{ checksum_alg }} checksum of file'\n  win_stat:\n    path: '{{ java_download_path }}\\{{ artifact_basename }}'\n    get_checksum: true\n    checksum_algorithm: '{{ checksum_alg }}'\n  register: artifact\n"}, {"commit_sha": "836dc4dd0dacc490044a14c0e39469d162b9449b", "sha": "75c853a947d4b8e60a7775ad45da40ea0bcd3250", "filename": "tasks/section4.yml", "repository": "florianutz/Ubuntu1604-CIS", "decoded_content": "---\n- name: \"NOTSCORED | 4.1.1.1 | PATCH | Ensure audit log storage size is configured\"\n  lineinfile:\n      dest: /etc/audit/auditd.conf\n      regexp: \"^max_log_file( |=)\"\n      line: \"max_log_file = 10\"\n      state: present\n  when:\n      - ubuntu1604cis_rule_4_1_1_1\n  notify:\n      - restart auditd\n  tags:\n      - level2\n      - notscored\n      - patch\n      - auditd\n      - rule_4.1.1.1\n\n- name: \"SCORED | 4.1.1.2 | PATCH | Ensure system is disabled when audit logs are full\"\n  lineinfile:\n      dest: /etc/audit/auditd.conf\n      regexp: \"^admin_space_left_action\"\n      line: \"admin_space_left_action = {{ ubuntu1604cis_auditd['admin_space_left_action'] }}\"\n      state: present\n  when:\n      - ubuntu1604cis_rule_4_1_1_2\n  notify:\n      - restart auditd\n  tags:\n      - level2\n      - scored\n      - patch\n      - auditd\n      - rule_4.1.1.2\n\n- name: \"SCORED | 4.1.1.2 | PATCH | Ensure email on non-admin audit space alert\"\n  lineinfile:\n      dest: /etc/audit/auditd.conf\n      regexp: \"^space_left_action\"\n      line: \"space_left_action = email\"\n      state: present\n  when:\n      - ubuntu1604cis_rule_4_1_1_2\n  notify:\n      - restart auditd\n  tags:\n      - level2\n      - scored\n      - patch\n      - auditd\n      - rule_4.1.1.2\n\n- name: \"SCORED | 4.1.1.3 | PATCH | Ensure audit logs are not automatically deleted\"\n  lineinfile:\n      dest: /etc/audit/auditd.conf\n      regexp: \"^max_log_file_action\"\n      line: \"max_log_file_action = {{ ubuntu1604cis_auditd['max_log_file_action'] }}\"\n      state: present\n  when:\n      - ubuntu1604cis_rule_4_1_1_3\n  notify:\n      - restart auditd\n  tags:\n      - level2\n      - scored\n      - patch\n      - auditd\n      - rule_4.1.1.3\n\n- name: \"SCORED | 4.1.2 | PATCH | Ensure auditd service is enabled\"\n  service:\n      name: auditd\n      state: started\n      enabled: true\n  when:\n      - ubuntu1604cis_skip_for_travis == false\n      - ubuntu1604cis_rule_4_1_2\n  tags:\n      - level2\n      - scored\n      - patch\n      - auditd\n      - rule_4.1.2\n\n- name: \"SCORED | 4.1.3 | PATCH | Ensure auditing for processes that start prior to auditd is enabled\"\n  replace:\n      dest: /etc/default/grub\n      regexp: '(^GRUB_CMDLINE_LINUX\\s*\\=\\s*)(?:\")(.+)(?<!audit=1)(?:\")'\n      replace: '\\1\"\\2 audit=1\"'\n      follow: true\n  ignore_errors: true\n  notify:\n      - generate new grub config\n  when:\n      - ubuntu1604cis_rule_4_1_3\n  tags:\n      - level2\n      - scored\n      - patch\n      - auditd\n      - rule_4.1.3\n\n- name: \"SCORED | 4.1.4 | PATCH | Ensure events that modify date and time information are collected\"\n  template:\n      src: audit/ubuntu1604cis_rule_4_1_4.rules.j2\n      dest: /etc/audit/rules.d/ubuntu1604cis_rule_4_1_4.rules\n      owner: root\n      group: root\n      mode: 0600\n  when:\n      - ubuntu1604cis_rule_4_1_4\n  notify:\n      - load audit rules\n      - restart auditd\n  tags:\n      - level2\n      - scored\n      - patch\n      - auditd\n      - rule_4.1.4\n\n- name: \"SCORED | 4.1.5 | PATCH | Ensure events that modify user/group information are collected\"\n  template:\n      src: audit/ubuntu1604cis_rule_4_1_5.rules.j2\n      dest: /etc/audit/rules.d/ubuntu1604cis_rule_4_1_5.rules\n      owner: root\n      group: root\n      mode: 0600\n  when:\n      - ubuntu1604cis_rule_4_1_5\n  notify:\n      - load audit rules\n      - restart auditd\n  tags:\n      - level2\n      - scored\n      - patch\n      - auditd\n      - rule_4.1.5\n\n- name: \"SCORED | 4.1.6 | PATCH | Ensure events that modify the system's network environment are collected\"\n  template:\n      src: audit/ubuntu1604cis_rule_4_1_6.rules.j2\n      dest: /etc/audit/rules.d/ubuntu1604cis_rule_4_1_6.rules\n      owner: root\n      group: root\n      mode: 0600\n  when:\n      - ubuntu1604cis_rule_4_1_6\n  notify:\n      - load audit rules\n      - restart auditd\n  tags:\n      - level2\n      - scored\n      - patch\n      - auditd\n      - rule_4.1.6\n\n- name: \"SCORED | 4.1.7 | PATCH | Ensure events that modify the system's Mandatory Access Controls are collected\"\n  template:\n      src: audit/ubuntu1604cis_rule_4_1_7.rules.j2\n      dest: /etc/audit/rules.d/ubuntu1604cis_rule_4_1_7.rules\n      owner: root\n      group: root\n      mode: 0600\n  when:\n      - ubuntu1604cis_rule_4_1_7\n  notify:\n      - load audit rules\n      - restart auditd\n  tags:\n      - level2\n      - scored\n      - patch\n      - auditd\n      - rule_4.1.7\n\n- name: \"SCORED | 4.1.8 | PATCH | Ensure login and logout events are collected\"\n  template:\n      src: audit/ubuntu1604cis_rule_4_1_8.rules.j2\n      dest: /etc/audit/rules.d/ubuntu1604cis_rule_4_1_8.rules\n      owner: root\n      group: root\n      mode: 0600\n  when:\n      - ubuntu1604cis_rule_4_1_8\n  notify:\n      - load audit rules\n      - restart auditd\n  tags:\n      - level2\n      - scored\n      - patch\n      - auditd\n      - rule_4.1.8\n\n- name: \"SCORED | 4.1.9 | PATCH | Ensure session initiation information is collected\"\n  template:\n      src: audit/ubuntu1604cis_rule_4_1_9.rules.j2\n      dest: /etc/audit/rules.d/ubuntu1604cis_rule_4_1_9.rules\n      owner: root\n      group: root\n      mode: 0600\n  when:\n      - ubuntu1604cis_rule_4_1_9\n  notify:\n      - load audit rules\n      - restart auditd\n  tags:\n      - level2\n      - scored\n      - patch\n      - auditd\n      - rule_4.1.9\n\n- name: \"SCORED | 4.1.10 | PATCH | Ensure discretionary access control permission modification events are collected\"\n  template:\n      src: audit/ubuntu1604cis_rule_4_1_10.rules.j2\n      dest: /etc/audit/rules.d/ubuntu1604cis_rule_4_1_10.rules\n      owner: root\n      group: root\n      mode: 0600\n  when:\n      - ubuntu1604cis_rule_4_1_10\n  notify:\n      - load audit rules\n      - restart auditd\n  tags:\n      - level2\n      - scored\n      - patch\n      - auditd\n      - rule_4.1.10\n\n- name: \"SCORED | 4.1.11 | PATCH | Ensure unsuccessful unauthorized file access attempts are collected\"\n  template:\n      src: audit/ubuntu1604cis_rule_4_1_11.rules.j2\n      dest: /etc/audit/rules.d/ubuntu1604cis_rule_4_1_11.rules\n      owner: root\n      group: root\n      mode: 0600\n  when:\n      - ubuntu1604cis_rule_4_1_11\n  notify:\n      - load audit rules\n      - restart auditd\n  tags:\n      - level2\n      - scored\n      - patch\n      - auditd\n      - rule_4.1.11\n\n- name: \"SCORED | 4.1.12 | PATCH | Ensure use of privileged commands is collected\"\n  block:\n\n      - name: \"SCORED | 4.1.12 | PATCH | Get list of setuid/setguid binaries\"\n        shell: for i in  $(df | grep '^/dev' | awk '{ print $NF }'); do find $i -xdev -type f -perm -4000 -o -type f -perm -2000 2>/dev/null; done\n        register: priv_procs\n        changed_when: false\n        check_mode: false\n\n      - name: \"SCORED | 4.1.12 | PATCH | Ensure use of privileged commands is collected\"\n        template:\n            src: audit/ubuntu1604cis_rule_4_1_12.rules.j2\n            dest: /etc/audit/rules.d/ubuntu1604cis_rule_4_1_12.rules\n            owner: root\n            group: root\n            mode: 0600\n        notify:\n            - load audit rules\n            - restart auditd\n  when:\n      - ubuntu1604cis_rule_4_1_12\n  tags:\n      - level2\n      - scored\n      - patch\n      - auditd\n      - rule_4.1.12\n\n- name: \"SCORED | 4.1.13 | PATCH | Ensure successful file system mounts are collected\"\n  template:\n      src: audit/ubuntu1604cis_rule_4_1_13.rules.j2\n      dest: /etc/audit/rules.d/ubuntu1604cis_rule_4_1_13.rules\n      owner: root\n      group: root\n      mode: 0600\n  when:\n      - ubuntu1604cis_rule_4_1_13\n  notify:\n      - load audit rules\n      - restart auditd\n  tags:\n      - level2\n      - scored\n      - patch\n      - auditd\n      - rule_4.1.13\n\n- name: \"SCORED | 4.1.14 | PATCH | Ensure file deletion events by users are collected\"\n  template:\n      src: audit/ubuntu1604cis_rule_4_1_14.rules.j2\n      dest: /etc/audit/rules.d/ubuntu1604cis_rule_4_1_14.rules\n      owner: root\n      group: root\n      mode: 0600\n  when:\n      - ubuntu1604cis_rule_4_1_14\n  notify:\n      - load audit rules\n      - restart auditd\n  tags:\n      - level2\n      - scored\n      - patch\n      - auditd\n      - rule_4.1.14\n\n- name: \"SCORED | 4.1.15 | PATCH | Ensure changes to system administration scope (sudoers) is collected\"\n  template:\n      src: audit/ubuntu1604cis_rule_4_1_15.rules.j2\n      dest: /etc/audit/rules.d/ubuntu1604cis_rule_4_1_15.rules\n      owner: root\n      group: root\n      mode: 0600\n  when:\n      - ubuntu1604cis_rule_4_1_15\n  notify:\n      - load audit rules\n      - restart auditd\n  tags:\n      - level2\n      - scored\n      - patch\n      - auditd\n      - rule_4.1.15\n\n- name: \"SCORED | 4.1.16 | PATCH | Ensure system administrator actions (sudolog) are collected\"\n  template:\n      src: audit/ubuntu1604cis_rule_4_1_16.rules.j2\n      dest: /etc/audit/rules.d/ubuntu1604cis_rule_4_1_16.rules\n      owner: root\n      group: root\n      mode: 0600\n  when:\n      - ubuntu1604cis_rule_4_1_16\n  notify:\n      - load audit rules\n      - restart auditd\n  tags:\n      - level2\n      - scored\n      - patch\n      - auditd\n      - rule_4.1.16\n\n- name: \"SCORED | 4.1.17 | PATCH | Ensure kernel module loading and unloading is collected\"\n  template:\n      src: audit/ubuntu1604cis_rule_4_1_17.rules.j2\n      dest: /etc/audit/rules.d/ubuntu1604cis_rule_4_1_17.rules\n      owner: root\n      group: root\n      mode: 0600\n  when:\n      - ubuntu1604cis_rule_4_1_17\n  notify:\n      - load audit rules\n      - restart auditd\n  tags:\n      - level2\n      - scored\n      - patch\n      - auditd\n      - rule_4.1.17\n      - notimplemented\n\n- name: \"SCORED | 4.1.18 | PATCH | Ensure the audit configuration is immutable\"\n  template:\n      src: audit/ubuntu1604cis_rule_4_1_18.rules.j2\n      dest: /etc/audit/rules.d/ubuntu1604cis_rule_4_1_18.rules\n      owner: root\n      group: root\n      mode: 0600\n  when:\n      - ubuntu1604cis_rule_4_1_18\n  notify:\n      - load audit rules\n      - restart auditd\n  tags:\n      - level2\n      - scored\n      - patch\n      - auditd\n      - rule_4.1.18\n\n- name: \"SCORED | 4.2.3 | PATCH | Ensure rsyslog or syslog-ng is installed\"\n  apt:\n      name: \"{{ ubuntu1604cis_syslog }}\"\n      state: present\n      install_recommends: false\n  when:\n      - ubuntu1604cis_rule_4_2_3\n  tags:\n      - level1\n      - scored\n      - patch\n      - syslog\n      - rule_4.2.3\n\n- name: \"SCORED | 4.2.1.1 | PATCH | Ensure rsyslog Service is enabled\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_4_2_1_1\n  tags:\n      - level1\n      - scored\n      - patch\n      - syslog\n      - rule_4.2.1.1\n      - notimplemented\n\n- name: \"NOTSCORED | 4.2.1.2 | PATCH | Ensure logging is configured\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_4_2_1_2\n  tags:\n      - level1\n      - notscored\n      - patch\n      - syslog\n      - rule_4.2.1.2\n      - notimplemented\n\n- name: \"SCORED | 4.2.1.3 | PATCH | Ensure rsyslog default file permissions configured\"\n  lineinfile:\n      dest: /etc/rsyslog.conf\n      regexp: '^\\$FileCreateMode'\n      line: '$FileCreateMode 0640'\n  when:\n      - ubuntu1604cis_rule_4_2_1_3\n  tags:\n      - level1\n      - scored\n      - patch\n      - syslog\n      - rule_4.2.1.3\n\n- name: \"SCORED | 4.2.1.4 | PATCH | Ensure rsyslog is configured to send logs to a remote log host\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_4_2_1_4\n  tags:\n      - level1\n      - scored\n      - patch\n      - syslog\n      - rule_4.2.1.4\n      - notimplemented\n\n- name: \"NOTSCORED | 4.2.1.5 | PATCH | Ensure remote rsyslog messages are only accepted on designated log hosts.\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_4_2_1_5\n  tags:\n      - level1\n      - notscored\n      - patch\n      - syslog\n      - rule_4.2.1.5\n      - notimplemented\n\n- name: \"NOTSCORED | 4.2.1.5 | PATCH | Ensure remote rsyslog messages are only accepted on designated log hosts.\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_4_2_1_5\n  tags:\n      - level1\n      - notscored\n      - patch\n      - syslog\n      - rule_4.2.1.5\n      - notimplemented\n\n- name: \"SCORED | 4.2.2.1 | PATCH | Ensure syslog-ng service is enabled\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_4_2_2_1\n  tags:\n      - level1\n      - scored\n      - patch\n      - syslog\n      - rule_4.2.2.1\n      - notimplemented\n\n- name: \"NOTSCORED | 4.2.2.2 | PATCH | Ensure logging is configured\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_4_2_2_2\n  tags:\n      - level1\n      - notscored\n      - patch\n      - syslog\n      - rule_4.2.2.2\n      - notimplemented\n\n- name: \"SCORED | 4.2.2.3 | PATCH | Ensure syslog-ng default file permissions configured\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_4_2_2_3\n  tags:\n      - level1\n      - scored\n      - patch\n      - syslog\n      - rule_4.2.2.3\n      - notimplemented\n\n- name: \"NOTSCORED | 4.2.2.4 | PATCH | Ensure syslog-ng is configured to send logs to a remote log host\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_4_2_2_4\n  tags:\n      - level1\n      - notscored\n      - patch\n      - syslog\n      - rule_4.2.2.4\n      - notimplemented\n\n- name: \"NOTSCORED | 4.2.2.5 | PATCH | Ensure remote syslog-ng messages are only accepted on designated log hosts\"\n  command: /bin/true\n  changed_when: false\n  when:\n      - ubuntu1604cis_rule_4_2_2_5\n  tags:\n      - level1\n      - notscored\n      - patch\n      - syslog\n      - rule_4.2.2.5\n      - notimplemented\n\n- name: \"SCORED | 4.2.4 | PATCH | Ensure permissions on all logfiles are configured\"\n  command: find /var/log -type f -exec chmod g-wx,o-rwx {} +\n  changed_when: false\n  failed_when: false\n  when:\n      - ubuntu1604cis_rule_4_2_4\n  tags:\n      - level1\n      - scored\n      - patch\n      - syslog\n      - rule_4.2.4\n\n- name: \"NOTSCORED | 4.3 | PATCH | Ensure logrotate is configured\"\n  block:\n      - name: \"NOTSCORED | 4.3 | PATCH | Register logrotate.d files\"\n        find:\n            paths: /etc/logrotate.d/\n        register: log_rotates\n\n      - name: \"NOTSCORED | 4.3 | PATCH | Ensure logrotate.conf exists\"\n        file:\n            path: /etc/logrotate.conf\n            state: touch\n        changed_when: false\n\n      - name: \"NOTSCORED | 4.3 | PATCH | Ensure logrotate is configured\"\n        replace:\n            path: \"{{ item.path }}\"\n            regexp: '^(\\s*)(daily|weekly|monthly|yearly)$'\n            replace: \"\\\\1{{ ubuntu1604cis_logrotate }}\"\n        with_items:\n            - \"{{ log_rotates.files }}\"\n            - { path: \"/etc/logrotate.conf\" }\n  when:\n      - ubuntu1604cis_rule_4_3\n  tags:\n      - level1\n      - notscored\n      - patch\n      - syslog\n      - rule_4.3\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "09a9471be6d5714f28e6f9479ff4439ddd6cb4df", "filename": "roles/ovirt-collect-logs/vars/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\novirt_collect_logs_tmp_dir: \"/var/tmp/ovirt-logs\"\novirt_collect_logs_archive: \"/var/tmp/ovirt-logs.tar.gz\"\novirt_collect_logs_shell_commands:\n  rpm-list: \"rpm -qa | sort -f\"\n  yum-list: \"yum list installed\"\n  services: \"systemctl -t service --failed --no-legend | awk '{print $1}'\n            | xargs -r -n1 journalctl -u\"\n  iptables: \"iptables -L\"\n  lsof: \"lsof -P\"\n  pstree: \"pstree -p\"\n  sysctl: \"sysctl -a\"\n  netstat: \"netstat -lnp\"\n  lsmod: \"lsmod\"\n  lspci: \"lspci\"\n  memory_usage: \"ps -e -orss=,args= | sort  -b -k1,1n | tac\"\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "37010b6622c3e02caa4777bc1ff6a68df0f66dc8", "filename": "playbooks/files/bro-networks.cfg", "repository": "rocknsm/rock", "decoded_content": "#LOCAL NETS\n10.0.0.0/8 \tRFC1918\n172.16.0.0/12\tRFC1918\n192.168.0.0/16\tRFC1918\n\n##########\n## ROCK ##\n##########\n# Add networks for the networks you are monitoring into this file if they're not all RFC1918.\n##########\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "9401499cae440dda7d8a7ebb13da9738ee657755", "filename": "roles/manage-sshd-config/test/playbook.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n\n# Test the role to update the access keys\n- name: \"Update  access\"\n  hosts: all\n  roles:\n    - role: manage-local-user-ssh-authkeys\n    - role: manage-local-user-password\n    - role: manage-sshd-config\n\n# Test the SSH Key access by running a remote command on machine\n#\n\n- name: \"Testing authorized ssh keyfile\" \n  hosts: all\n  tasks:\n  - name: \"Test authorized key for {{ user_name }} on {{ ansible_host }}\"\n    raw: \"ssh -v -i id_rsa_user1 {{ user_name }}@{{ ansible_host }} /bin/true\"\n    delegate_to: localhost\n    register: result\n    become: False\n    changed_when: False\n    failed_when:\n      result.rc != 0\n\n  - name: \"Test password for {{ user_name }} on {{ ansible_host }}\"\n    raw: \"sshpass -p \\\"{{ clear_text_password }}\\\" ssh {{ user_name }}@{{ansible_host }} /bin/true\"\n    delegate_to: localhost\n    become: False\n    register: result\n    changed_when: False\n    failed_when:\n      result.rc != 0\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "4f09d6a87cd575288e77ae40df15982953a11d7d", "filename": "playbooks/validate.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "---\n- name: Validate proxy\n  hosts: all\n  gather_facts: yes\n  tags: proxy\n  vars:\n    proxy_uc_envs:\n    - HTTP_PROXY\n    - HTTPS_PROXY\n    proxy_lc_envs:\n    - http_proxy\n    - https_proxy\n    proxies:\n    - \"{{ proxy_http }}\"\n    - \"{{ proxy_https }}\"\n  vars_files:\n  - \"{{file_env}}\"\n  - \"{{file_secrets}}\"\n  roles:\n  - check_proxy\n\n- name: ensure bastion packages.\n  hosts: bastion\n  tags: packages\n  gather_facts: yes\n  vars_files:\n  - \"{{file_env}}\"\n  roles:\n  - check_packages_bastion\n\n- name: ensure nodes packages.\n  hosts: nodes\n  tags: packages\n  gather_facts: no\n  vars_files:\n  - \"{{file_env}}\"\n  roles:\n  - check_packages_nodes\n\n- name: ensure nodes networking.\n  hosts: all\n  tags: networking\n  gather_facts: no\n  vars_files:\n  - \"{{file_env}}\"\n  roles:\n  - check_networking\n\n\n- name: Validate environment\n  gather_facts: no\n  hosts: all\n  tags: validate\n  vars_files:\n  - \"{{file_env}}\"\n  - \"{{file_secrets}}\"\n  tasks:\n    - import_role:\n        name: check_disks\n    - import_role:\n        name: check_os\n    - import_role:\n        name: check_connectivity\n    - import_role:\n        name: check_sizing\n      when: inventory_hostname in groups['nodes']\n    - import_role:\n        name: check_dns\n    - import_role:\n        name: check_selinux\n    - import_role:\n        name: check_ntp\n      when: ntp_servers is defined\n    - import_role:\n        name: check_storage\n      when: inventory_hostname in groups['nodes']\n    - import_role:\n        name: check_nm\n    - import_role:\n        name: check_glusterfs\n      when: inventory_hostname in groups['glusterfs'] | default([])\n\n\n- name: Initialize firewall check\n  hosts: nodes\n  tags: firewall\n  gather_facts: no\n  vars_files:\n  - \"{{file_env}}\"\n  roles:\n  - check_firewall_initialize\n\n- name: Execute firewall check\n  hosts: localhost\n  tags: firewall\n  gather_facts: yes\n  vars_files:\n  - \"{{file_env}}\"\n  roles:\n  - check_firewall\n\n- name: Validate docker\n  hosts: nodes\n  tags: docker\n  gather_facts: yes\n  vars_files:\n  - \"{{file_env}}\"\n  roles:\n  - check_docker_setup\n  - check_docker_validation\n\n- name: Cleanup validation trash\n  hosts: all\n  tags: cleanup\n  gather_facts: yes\n  vars_files:\n  - \"{{file_env}}\"\n  roles:\n  - check_cleanup\n"}, {"commit_sha": "e91a55152358e890a05cf849abc7d58b8badecc2", "sha": "4ab24535830dfc6dd1b228623b6e88392195c5be", "filename": "tasks/install-git.yml", "repository": "fubarhouse/ansible-role-golang", "decoded_content": "---\n\n- name: \"Go-Lang | Ensure directory is absent\"\n  file:\n    path: \"{{ GOROOT }}\"\n    state: absent\n\n- name: \"Go-Lang | Ensure directory is empty\"\n  file:\n    path: \"{{ GOROOT }}\"\n    state: directory\n    owner: \"{{ fubarhouse_user }}\"\n    mode: 0775\n\n- name: \"Go-Lang | Clone distribution\"\n  git:\n    repo: \"https://github.com/golang/go.git\"\n    dest: \"{{ GOROOT }}\"\n    version: \"{{ go_version_string }}\"\n    clone: yes\n    update: no\n    force: yes\n\n- name: \"Go-Lang | Build from source\"\n  shell: \"cd {{ GOROOT }}/src && ./{{ go_build_script }}\"\n  environment:\n    GOROOT: \"{{ GOROOT }}\"\n    GOPATH: \"{{ GOPATH }}\"\n    GOROOT_BOOTSTRAP: \"{{ GOROOT_BOOTSTRAP }}\"\n"}, {"commit_sha": "7032aee7df1c2c6e96795067285efa3b2a6de32e", "sha": "0b3aa351f1a82ea26b1852a6d65c9ce089ce75bf", "filename": "roles/subscription-manager/tasks/main.yml", "repository": "openshift/openshift-ansible-contrib", "decoded_content": "---\n- name: \"Initialize rhsm_password variable if vars_prompt was used\"\n  set_fact:\n    rhsm_password: \"{{ hostvars.localhost.rhsm_password }}\"\n  when:\n    - rhsm_password is not defined or rhsm_password is none or rhsm_password|trim == ''\n  \n- name: \"Initializing Subscription Manager authentication method\"\n  set_fact:\n    rhsm_authentication: false\n\n# 'rhsm_activationkey' will take precedence even if 'rhsm_username' and 'rhsm_password' are also set\n- name: \"Setting Subscription Manager Activation Key Fact\"\n  set_fact:\n    rhsm_authentication: \"key\"\n  when:\n    - rhsm_activationkey is defined\n    - rhsm_activationkey is not none\n    - rhsm_activationkey|trim != ''\n    - not rhsm_authentication\n\n# If 'rhsm_username' and 'rhsm_password' are set but not 'rhsm_activationkey', set 'rhsm_authentication' to password\n- name: \"Setting Subscription Manager Username and Password Fact\"\n  set_fact:\n    rhsm_authentication: \"password\"\n  when:\n    - rhsm_username is defined\n    - rhsm_username is not none\n    - rhsm_username|trim != ''\n    - rhsm_password is defined\n    - rhsm_password is not none\n    - rhsm_password|trim != ''\n    - not rhsm_authentication\n\n- name: \"Initializing registration status\"\n  set_fact:\n    registered: false\n\n- name: \"Checking subscription status (a failure means it is not registered and will be)\"\n  command: \"/usr/bin/subscription-manager status\"\n  ignore_errors: yes\n  changed_when: no\n  register: check_if_registered\n\n- name: \"Set registration fact if system is already registered\"\n  set_fact:\n    registered: true\n  when: check_if_registered.rc == 0\n\n- name: \"Cleaning any old subscriptions\"\n  command: \"/usr/bin/subscription-manager clean\"\n  when:\n    - not registered\n    - rhsm_authentication is defined\n\n- name: \"Install Satellite certificate\"\n  command: \"rpm -Uvh --force http://{{ rhsm_satellite }}/pub/katello-ca-consumer-latest.noarch.rpm\"\n  when:\n    - not registered\n    - rhsm_satellite is defined\n    - rhsm_satellite is not none\n    - rhsm_satellite|trim != ''\n\n- name: \"Register to Satellite using activation key\"\n  command: \"/usr/bin/subscription-manager register --activationkey={{ rhsm_activationkey }} --org='{{ rhsm_org }}'\"\n  when:\n    - not registered\n    - rhsm_authentication == 'key'\n    - rhsm_satellite is defined\n    - rhsm_satellite is not none\n    - rhsm_satellite|trim != ''\n\n# This can apply to either Hosted or Satellite\n- name: \"Register using username and password\"\n  command: \"/usr/bin/subscription-manager register --username={{ rhsm_username }} --password={{ rhsm_password }}\"\n  no_log: true\n  when:\n    - not registered\n    - rhsm_authentication == \"password\"\n    - rhsm_org is not defined or rhsm_org is none or rhsm_org|trim == ''\n\n# This can apply to either Hosted or Satellite\n- name: \"Register using username, password and organization\"\n  command: \"/usr/bin/subscription-manager register --username={{ rhsm_username }} --password={{ rhsm_password }} --org={{ rhsm_org }}\"\n  no_log: true\n  when:\n    - not registered\n    - rhsm_authentication == \"password\"\n    - rhsm_org is defined\n    - rhsm_org is not none\n    - rhsm_org|trim != ''\n\n- name: \"Auto-attach to Subscription Manager Pool\"\n  command: \"/usr/bin/subscription-manager attach --auto\"\n  when:\n    - not registered\n    - rhsm_pool is undefined or rhsm_pool is none or rhsm_pool|trim == ''\n\n- name: \"Attach to a specific pool\"\n  command: \"/usr/bin/subscription-manager attach --pool={{ rhsm_pool }}\"\n  when:\n    - rhsm_pool is defined\n    - rhsm_pool is not none\n    - rhsm_pool|trim != ''\n    - not registered\n\n- name: \"Disable all repositories\"\n  command: \"/usr/bin/subscription-manager repos --disable=*\"\n  when:\n    - not registered\n    - rhsm_repos is defined\n    - rhsm_repos is not none\n    - rhsm_repos|trim != ''\n\n- name: \"Enable specified repositories\"\n  command: \"/usr/bin/subscription-manager repos --enable={{ item }}\"\n  with_items: rhsm_repos\n  when:\n    - not registered\n    - rhsm_repos is defined\n    - rhsm_repos is not none\n    - rhsm_repos|trim != ''\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "71afd3c8e5785e5928510b635fd30a6970ca4f44", "filename": "roles/config-routes/tests/infrahosts.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Configure routes on the host'\n  hosts: infra_hosts\n  roles:\n  - role: config-routes\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "4c5d3a408407ea7a8c1787c296fb8f6777f7df8e", "filename": "playbooks/manage-users/add-users.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Import user data from {{ csv_doc_file_name }} and create users\"\n  hosts: identity-hosts\n  gather_facts: no\n  roles:\n    - user-management/populate-users\n    - user-management/manage-idm-users\n    - user-management/manage-user-passwd\n\n- name: \"Notify users\"\n  import_playbook: ../notifications/email-notify-users.yml\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "456dbaa2ed3642382adb80bdb1cfc364918ced01", "filename": "roles/wp-cli/defaults/main.yml", "repository": "roots/trellis", "decoded_content": "wp_cli_bin_path: /usr/bin/wp\nwp_cli_phar_url: \"https://github.com/wp-cli/wp-cli/releases/download/v0.23.0/wp-cli-0.23.0.phar\"\nwp_cli_completion_url: \"https://raw.githubusercontent.com/wp-cli/wp-cli/master/utils/wp-completion.bash\"\nwp_cli_completion_path: /etc/bash_completion.d\n"}, {"commit_sha": "045ff4bb9f4720739632aac2951fbf2798a99c8c", "sha": "703b1d0420cb6ee7f00f59b754d6439262470281", "filename": "roles/cloud-ec2/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: Locate official Ubuntu 16.04 AMI for region\n  ec2_ami_find:\n    aws_access_key: \"{{ aws_access_key | default(lookup('env','AWS_ACCESS_KEY_ID'))}}\"\n    aws_secret_key: \"{{ aws_secret_key | default(lookup('env','AWS_SECRET_ACCESS_KEY'))}}\"\n    name: \"ubuntu/images/hvm-ssd/ubuntu-xenial-16.04-amd64-server-*\"\n    owner:  099720109477\n    sort: creationDate\n    sort_order: descending\n    sort_end: 1\n    region: \"{{ region }}\"\n  register: ami_search\n\n- set_fact:\n    ami_image: \"{{ ami_search.results[0].ami_id }}\"\n\n- include: encrypt_image.yml\n  tags: [encrypted]\n\n- name: Add ssh public key\n  ec2_key:\n    aws_access_key: \"{{ aws_access_key | default(lookup('env','AWS_ACCESS_KEY_ID'))}}\"\n    aws_secret_key: \"{{ aws_secret_key | default(lookup('env','AWS_SECRET_ACCESS_KEY'))}}\"\n    name: VPNKEY\n    region: \"{{ region }}\"\n    key_material: \"{{ item }}\"\n  with_file: \"{{ SSH_keys.public }}\"\n  register: keypair\n\n- name: Configure EC2 virtual private clouds\n  ec2_vpc:\n    aws_access_key: \"{{ aws_access_key | default(lookup('env','AWS_ACCESS_KEY_ID'))}}\"\n    aws_secret_key: \"{{ aws_secret_key | default(lookup('env','AWS_SECRET_ACCESS_KEY'))}}\"\n    state: present\n    resource_tags: { \"Environment\":\"Algo\" }\n    region: \"{{ region }}\"\n    cidr_block: \"{{ ec2_vpc_nets.cidr_block }}\"\n    internet_gateway: yes\n    subnets:\n      - cidr: \"{{ ec2_vpc_nets.subnet_cidr }}\"\n        resource_tags: { \"Environment\":\"Algo\" }\n  register: vpc\n\n- name: Set up Public Subnets Route Table\n  ec2_vpc_route_table:\n    aws_access_key: \"{{ aws_access_key | default(lookup('env','AWS_ACCESS_KEY_ID'))}}\"\n    aws_secret_key: \"{{ aws_secret_key | default(lookup('env','AWS_SECRET_ACCESS_KEY'))}}\"\n    vpc_id: \"{{ vpc.vpc_id }}\"\n    region: \"{{ region }}\"\n    state: present\n    tags:\n      Environment: Algo\n    subnets:\n      - \"{{ ec2_vpc_nets.subnet_cidr }}\"\n    routes:\n      - dest: 0.0.0.0/0\n        gateway_id: \"{{ vpc.igw_id }}\"\n  register: public_rt\n\n- name: Configure EC2 security group\n  ec2_group:\n    aws_access_key: \"{{ aws_access_key | default(lookup('env','AWS_ACCESS_KEY_ID'))}}\"\n    aws_secret_key: \"{{ aws_secret_key | default(lookup('env','AWS_SECRET_ACCESS_KEY'))}}\"\n    name: vpn-secgroup\n    description: Security group for VPN servers\n    region: \"{{ region }}\"\n    vpc_id: \"{{ vpc.vpc_id }}\"\n    rules:\n      - proto: udp\n        from_port: 4500\n        to_port: 4500\n        cidr_ip: 0.0.0.0/0\n      - proto: udp\n        from_port: 500\n        to_port: 500\n        cidr_ip: 0.0.0.0/0\n      - proto: tcp\n        from_port: 22\n        to_port: 22\n        cidr_ip: 0.0.0.0/0\n    rules_egress:\n      - proto: all\n        from_port: 0-65535\n        to_port: 0-65535\n        cidr_ip: 0.0.0.0/0\n\n- name: Launch instance\n  ec2:\n    aws_access_key: \"{{ aws_access_key | default(lookup('env','AWS_ACCESS_KEY_ID'))}}\"\n    aws_secret_key: \"{{ aws_secret_key | default(lookup('env','AWS_SECRET_ACCESS_KEY'))}}\"\n    keypair: \"VPNKEY\"\n    vpc_subnet_id: \"{{ vpc.subnets[0].id }}\"\n    group: vpn-secgroup\n    instance_type: t2.micro\n    image: \"{{ ami_image }}\"\n    wait: true\n    region: \"{{ region }}\"\n    instance_tags:\n      name: \"{{ aws_server_name }}\"\n      Environment: Algo\n    exact_count: 1\n    count_tag:\n      name: \"{{ aws_server_name }}\"\n    assign_public_ip: yes\n    instance_initiated_shutdown_behavior: terminate\n  register: ec2\n\n- name: Add new instance to host group\n  add_host:\n    hostname: \"{{ item.public_ip }}\"\n    groupname: vpn-host\n    ansible_ssh_user: ubuntu\n    ansible_python_interpreter: \"/usr/bin/python2.7\"\n    ansible_ssh_private_key_file: \"{{ SSH_keys.private }}\"\n    cloud_provider: ec2\n    ipv6_support: no\n  with_items: \"{{ ec2.tagged_instances }}\"\n\n- set_fact:\n    cloud_instance_ip: \"{{ ec2.tagged_instances[0].public_ip }}\"\n\n- name: Get EC2 instances\n  ec2_remote_facts:\n    aws_access_key: \"{{ aws_access_key | default(lookup('env','AWS_ACCESS_KEY_ID'))}}\"\n    aws_secret_key: \"{{ aws_secret_key | default(lookup('env','AWS_SECRET_ACCESS_KEY'))}}\"\n    region: \"{{ region }}\"\n    filters:\n      instance-state-name: running\n      \"tag:Environment\": Algo\n  register: algo_instances\n\n- name: Ensure the group ec2 exists in the dynamic inventory file\n  lineinfile:\n    state: present\n    dest: configs/inventory.dynamic\n    line: '[ec2]'\n\n- name: Populate the dynamic inventory\n  lineinfile:\n    state: present\n    dest: configs/inventory.dynamic\n    insertafter: '\\[ec2\\]'\n    regexp: \"^{{ item.public_ip_address }}.*\"\n    line: \"{{ item.public_ip_address }}\"\n  with_items:\n    - \"{{ algo_instances.instances }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "2553868fbeea4566ad1d6df14d1e626ecda671bd", "filename": "roles/mongodb/defaults/main.yml", "repository": "iiab/iiab", "decoded_content": "mongodb_install: False\nmongodb_enabled: False\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "8edae182b09ab2e07687db5b7ef6c85d5aba0882", "filename": "roles/config-versionlock/tests/inventory/group_vars/all.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nversionlock_packages:\n  - 'bash-*'\n  - 'NetworkManager-*'\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "1bf210d82f67f5388e9561767955dcacb3024d90", "filename": "roles/osp/admin-project/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Add projects / tenants\"\n  os_project:\n    cloud: \"{{ item.cloud | default(osp_default_cloud) | default(omit) }}\"\n    domain_id: \"{{ item.domain }}\"\n    description: \"{{ item.description | default(omit) }}\"\n    name: \"{{ item.name }}\"\n  with_items:\n  - \"{{ osp_projects | default([]) }}\"\n\n- name: \"Update tenant quotas\"\n  os_quota:\n    cloud: \"{{ item.cloud | default(osp_default_cloud) | default(omit) }}\"\n    name: \"{{ item.name }}\"\n    cores: \"{{ item.quota.vcpus | default(omit) }}\"\n    instances: \"{{ item.quota.instances | default(omit) }}\"\n    volumes: \"{{ item.quota.volumes | default(omit) }}\"\n    gigabytes: \"{{ item.quota.total_vol_size | default(omit) }}\"\n    ram: \"{{ item.quota.ram | default(omit) }}\"\n    security_group: \"{{ item.quota.security_groups | default(omit) }}\"\n    security_group_rule: \"{{ item.quota.security_group_rules | default(omit) }}\"\n    floating_ips: \"{{ item.quota.floating_ips | default(omit) }}\"\n    network: \"{{ item.quota.networks | default(omit) }}\"\n    router: \"{{ item.quota.routers | default(omit) }}\"\n    subnet: \"{{ item.quota.subnets | default(omit) }}\"\n    port: \"{{ item.quota.ports | default(omit) }}\"\n  with_items:\n  - \"{{ osp_projects | default([]) }}\"\n  when:\n  - item.quota is defined\n\n- name: \"Assign roles for users/projects\"\n  include_tasks: \"tenant-roles.yml\"\n  with_items:\n  - \"{{ osp_projects | default([]) }}\"\n  loop_control:\n    loop_var: project\n\n"}, {"commit_sha": "a77a8900bb9032eb97498fbb9149d4504e73b0b5", "sha": "44404e0b368a1ca553a8063c7c8a266d0389e61f", "filename": "handlers/main.yml", "repository": "geerlingguy/ansible-role-solr", "decoded_content": "---\n- name: restart solr\n  service:\n    name: \"{{ solr_service_name }}\"\n    state: restarted\n    sleep: 5\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "591f440b12e7b40a59f3ff92e8eb1e91751160a0", "filename": "roles/config-hostname/tasks/prep.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Install required packages'\n  package:\n    name: '{{ item }}'\n    state: installed\n  with_items:\n  - libselinux-python\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "cc13e2382fe7687d0d0fb45a5ba8bc9d6ed63f2f", "filename": "playbooks/validate_config.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "---\n- name: Collect host information\n  hosts: localhost\n  connection: local\n  gather_facts: no\n  vars_files:\n  - \"{{file_env}}\"\n  vars_prompt:\n  - name: sudo_password\n    prompt: Password for sudo, leave blank if passwordless sudo (will be encypted)\n    private: yes\n  - name: rhn_password\n    prompt: Red Hat account password, leave blank if Satellite is using (will be encrypted)\n    private: yes\n  tasks:\n  - name: Cleanup\n    file:\n      path: \"{{item}}\"\n      state: absent\n    with_items:\n    - \"{{file_ip_data}}\"\n    - \"{{file_inventory}}\"\n    - \"{{file_secrets}}\"\n  - name: Ensure secrets file\n    copy:\n      dest: \"{{file_secrets}}\"\n      content: |\n        sudo_password: \"{{sudo_password}}\"\n        rhn_password: \"{{rhn_password}}\"\n  - name: Verify Masters IP addresses\n    local_action: |\n      shell ping -c 1 {{item}} | grep \"PING\"| sed -e 's/[^a-zA-Z0-9.-]/ /g' | awk '{print $3 \": {{item }}\" }' >> {{file_ip_data}}\n    with_items: \"{{masters}}\"\n  - name: Verify Infranodes IP addresses\n    local_action: |\n      shell ping -c 1 {{item}} | grep \"PING\"| sed -e 's/[^a-zA-Z0-9.-]/ /g' | awk '{print $3 \": {{item }}\" }' >> {{file_ip_data}}\n    with_items: \"{{infranodes | default([])}}\"\n  - name: Verify Nodes IP addresses\n    local_action: |\n      shell ping -c 1 {{item}} | grep \"PING\"| sed -e 's/[^a-zA-Z0-9.-]/ /g' | awk '{print $3 \": {{item }}\" }' >> {{file_ip_data}}\n    with_items: \"{{nodes}}\"\n  - name: Verify CNS IP addresses\n    local_action: |\n      shell ping -c 1 {{item}} | grep \"PING\"| sed -e 's/[^a-zA-Z0-9.-]/ /g' | awk '{print $3 }'\n    with_items: \"{{cns | default([])}}\"\n    register: cns_data\n  - local_action: |\n      shell cat \"{{file_ip_data}}\"\n    register: ip_data\n  - name: Print IP addresses\n    debug:\n      msg: |\n        Manager to find following IP adresses:\n        \"{{ip_data.stdout }}\"\n\n  - name: register cns hosts\n    set_fact:\n      cns_hosts: []\n    when: cns is defined\n\n  - name: register cns ip\n    set_fact:\n      cns_hosts: \"{{cns_hosts}} + ['{{ item.stdout }}']\"\n    with_items: \"{{cns_data.results}}\"\n    when: cns is defined\n\n  - name: debug cns hosts\n    debug: var=cns_hosts\n    when: cns is defined\n\n  - name: Create Inventory file based on dynamic collected information.\n    template:\n      src: \"templates/hosts-v{{'%0.2f'| format(ocp_version|float)}}.j2\"\n      dest: \"{{file_inventory}}\"\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "2c600aa8d651c711e8f9e50a07821bb7fe931b18", "filename": "cookbooks/packagecloud/metadata.json", "repository": "rocknsm/rock", "decoded_content": "{\n  \"name\": \"packagecloud\",\n  \"description\": \"Installs/Configures packagecloud.io repositories.\",\n  \"long_description\": \"Installs/Configures packagecloud.io repositories.\",\n  \"maintainer\": \"Joe Damato\",\n  \"maintainer_email\": \"joe@packagecloud.io\",\n  \"license\": \"Apache 2.0\",\n  \"platforms\": {\n\n  },\n  \"dependencies\": {\n\n  },\n  \"recommendations\": {\n\n  },\n  \"suggestions\": {\n\n  },\n  \"conflicting\": {\n\n  },\n  \"providing\": {\n\n  },\n  \"replacing\": {\n\n  },\n  \"attributes\": {\n\n  },\n  \"groupings\": {\n\n  },\n  \"recipes\": {\n\n  },\n  \"version\": \"0.2.5\",\n  \"source_url\": \"https://github.com/computology/packagecloud-cookbook\",\n  \"issues_url\": \"https://github.com/computology/packagecloud-cookbook/issues\",\n  \"privacy\": false\n}\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "d975d7a7ff5263ddfac64b6a562ffeb80e3575c8", "filename": "roles/mesos/tasks/master.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# Tasks for Master nodes\n\n- name: set mesos-master consul service definition\n  when: mesos_install_mode == \"master\"\n  sudo: yes\n  template:\n    src: mesos-master-consul.j2\n    dest: \"{{ consul_dir }}/mesos-master.json\"\n  notify:\n    - restart consul\n  tags:\n    - mesos-master\n\n- name: create mesos-master work directory\n  when: mesos_install_mode == \"master\"\n  file:\n    path: \"{{ mesos_master_work_dir }}\"\n    state: directory\n    mode: 0755\n  sudo: yes\n  tags:\n    - mesos-master\n\n- name: run mesos-master container\n  when: mesos_install_mode == \"master\"\n  docker:\n    name: mesos-master\n    image: \"{{ mesos_master_image }}\"\n    state: started\n    volumes:\n    - \"{{ mesos_master_work_dir }}:{{ mesos_master_work_dir }}\"\n    ports:\n    - \"{{ mesos_master_port }}:{{ mesos_master_port }}\"\n    net: \"host\"\n    env:\n      MESOS_HOSTNAME: \"{{ mesos_hostname }}\"\n      MESOS_IP: \"{{ mesos_ip }}\"\n      MESOS_CLUSTER: \"{{ mesos_cluster_name }}\"\n      MESOS_ZK: \"zk://{{ zookeeper_peers_nodes }}/mesos\"\n      MESOS_LOG_DIR: \"/var/log/mesos\"\n      MESOS_QUORUM: \"{{ mesos_quorum }}\"\n      MESOS_WORK_DIR: \"{{ mesos_master_work_dir }}\"\n  tags:\n    - mesos-master\n\n- name: upload mesos-master template service\n  when: mesos_install_mode == \"master\"\n  template:\n    src: mesos-master.conf.j2\n    dest: /etc/init/mesos-master.conf\n    mode: 0755\n  sudo: yes\n  tags:\n    - mesos-master\n\n- name: ensure mesos-master is running (and enable it at boot)\n  when: mesos_install_mode == \"master\"\n  sudo: yes\n  service:\n    name: mesos-master\n    state: started\n    enabled: yes\n  tags:\n    - mesos-master\n\n- name: run prometheus mesos master exporter container\n  when: mesos_install_mode == \"master\" and prometheus_enabled|bool\n  docker:\n    name: mesos-exporter\n    image: \"{{ prometheus_mesos_exporter_image }}\"\n    command: \"-exporter.scrape-mode=master -exporter.url=http://{{ mesos_hostname }}:{{ mesos_master_port }}\"\n    state: started\n    restart_policy: always\n    ports:\n    - \"{{ prometheus_mesos_exporter_port }}:{{ prometheus_mesos_exporter_port }}\"\n  environment: proxy_env\n  tags:\n    - prometheus\n    - mesos_master\n\n- name: Set mesos-exporter consul service definition\n  when: mesos_install_mode == \"master\" and prometheus_enabled|bool\n  sudo: yes\n  template:\n    src: mesos-exporter-consul.j2\n    dest: \"{{ consul_dir }}/mesos-exporter.json\"\n  notify:\n    - restart consul\n  tags:\n    - prometheus\n    - mesos_master\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "891545f0fc10aa5c9b72dbc0c40471730a825937", "filename": "roles/manage-confluence-space/tasks/prepare_confluence_source.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Retrieve all contents from source space\n  uri:\n    url: '{{ confluence_source_url }}/wiki/rest/api/space/{{ atlassian.confluence.source.key }}/content?expand=body.storage,space,ancestors&limit=500'\n    method: GET\n    user: '{{ confluence_source_username }}'\n    password: '{{ confluence_source_password }}'\n    force_basic_auth: yes\n    status_code: 200\n    return_content: yes\n  register: contents_json\n\n- name: Get Confluence Homepage ID\n  uri:\n    url: '{{ confluence_source_url}}/wiki/rest/api/space/{{ atlassian.confluence.source.key }}'\n    method: GET\n    user: '{{ confluence_source_username }}'\n    password: '{{ confluence_source_password }}'\n    return_content: yes\n    force_basic_auth: yes\n    status_code: 200\n    body_format: json\n  register: source_space\n\n- name: Set Source Homepage ID\n  set_fact:\n    source_homepage_id: \"{{ source_space.json._expandable.homepage.split('/')|last }}\"\n\n- name: Create a tempfile for Content JSON\n  command: mktemp\n  register: uptemp\n  delegate_to: 127.0.0.1\n\n- name: Write content to file\n  copy:\n    content: \"{{ contents_json.json['page']['results'] }}\"\n    dest: \"{{ uptemp.stdout }}\"\n\n- name: Initialise old to new id mapping\n  set_fact:\n    id_mapping: {}\n\n- name: Sort contents based on its dependencies\n  command: \"./contents_order_parser.py '{{ uptemp.stdout }}'\"\n  args:\n    chdir: \"{{ role_path }}/files\"\n  register: processed_contents\n  delegate_to: 127.0.0.1\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "7417cadc39ba6d8538219c7c1efb0ddb02341075", "filename": "roles/ansible/tower/manage-job-templates/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: tower\n  roles:\n  - role: ansible/tower/manage-job-templates\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "ec920927140a279793f7c6f4911d002f702effcd", "filename": "roles/client/tasks/systems/Fedora.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\n- set_fact:\n    prerequisites:\n      - libselinux-python\n    configs_prefix: /etc/strongswan/\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "ea7a0120d2154219f63054b8d7f92f40877d7a68", "filename": "roles/2-common/templates/ansible.repo", "repository": "iiab/iiab", "decoded_content": "[ansible]\nname=ansible\nfailovermethod=priority\nbaseurl=http://releases.ansible.com/ansible/rpm/release/epel-7-x86_64/\nenabled=0\nmetadata_expire=1d\ngpgcheck=0\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "8bb65a5a9bb832bbc81b50393153479ac3296c8b", "filename": "roles/config-vnc-server/tasks/vnc-server.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Install additional packages for VNC server\"\n  package:\n    name: \"{{ item }}\"\n    state: installed\n  with_items:\n  - tigervnc-server\n  - policycoreutils-python-utils\n  - checkpolicy\n\n- name: \"Ensure .vnc dir exists\"\n  file:\n    path: \"{{ vnc_home_dir }}/{{ main_user }}/.vnc\"\n    state: directory\n    owner: \"{{ main_user }}\"\n\n- name: \"Check to see if a VNC password already exists\"\n  stat:\n    path: \"{{ vnc_home_dir }}/{{ main_user }}/.vnc/passwd\"\n  register: passwd_info\n\n- name: \"Set a vnc password\"\n  shell: \"echo {{ vnc_password | default('vncpasswd01') }} | vncpasswd -f > {{ vnc_home_dir }}/{{ main_user }}/.vnc/passwd\"\n  when: passwd_info.stat.exists == False\n\n- name: \"Ensure correct ownership of the vnc password file\"\n  file:\n    path: \"{{ vnc_home_dir }}/{{ main_user }}/.vnc/passwd\"\n    owner: \"{{ main_user }}\"\n    mode: 0600\n\n- name: \"Add the xstartup (gnome) configuration to the main user\"\n  copy :\n    src: xstartup-gnome\n    dest: \"{{ vnc_home_dir }}/{{ main_user }}/.vnc/xstartup\"\n    force: no\n    owner: \"{{ main_user }}\"\n    mode: 0755\n  when:\n  - gnome_install|default(False)\n\n- name: \"Add the xstartup (XFCE) configuration to the main user\"\n  copy :\n    src: xstartup-xfce\n    dest: \"{{ vnc_home_dir }}/{{ main_user }}/.vnc/xstartup\"\n    force: no\n    owner: \"{{ main_user }}\"\n    mode: 0755\n  when:\n  - xfce_install|default(False)\n\n- name: \"Add the xstartup (LXDE) configuration to the main user\"\n  copy :\n    src: xstartup-lxde\n    dest: \"{{ vnc_home_dir }}/{{ main_user }}/.vnc/xstartup\"\n    force: no\n    owner: \"{{ main_user }}\"\n    mode: 0755\n  when:\n  - lxde_install|default(False)\n\n- name: \"Add the xstartup (MATE) configuration to the main user\"\n  copy :\n    src: xstartup-mate\n    dest: \"{{ vnc_home_dir }}/{{ main_user }}/.vnc/xstartup\"\n    force: no\n    owner: \"{{ main_user }}\"\n    mode: 0755\n  when:\n  - mate_install|default(False)\n\n- name: \"Copy VNC service file into place\"\n  copy:\n    src: /usr/lib/systemd/system/vncserver@.service\n    dest: \"/etc/systemd/system/vncserver-{{ main_user }}@.service\"\n    remote_src: True\n\n- name: \"Ensure the user config is set for the vnc service\"\n  replace:\n    path: \"/etc/systemd/system/vncserver-{{ main_user }}@.service\"\n    regexp: \"{{ item.0 }}\"\n    replace: \"{{ item.1 }}\"\n  with_together:\n  - ['<USER>', '/home/' ]\n  - [ \"{{ main_user }}\", \"{{ vnc_home_dir }}/\" ]\n\n- name: \"Reload systemctl daemon\"\n  command: systemctl daemon-reload\n\n- name: \"Copy SELinux .te file to the host - used to build the module\"\n  copy:\n    src: SELinuxVNC.te\n    dest: /tmp/SELinuxVNC.te\n\n- name: \"Build SELinux module (.mod) to allow VNC\"\n  command: checkmodule -M -m -o SELinuxVNC.mod /tmp/SELinuxVNC.te\n\n- name: \"Build SELinux module (.pp) to allow VNC\"\n  command: semodule_package -m SELinuxVNC.mod -o SELinuxVNC.pp\n\n- name: \"Load SELinux module to allow VNC\"\n  command: semodule -i SELinuxVNC.pp\n\n- name: \"Enable and start VNC server for user\"\n  service:\n    name: \"vncserver-{{ main_user }}@:1\"\n    enabled: yes\n    state: started\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "6b0d15d1abf483cf534d2db5a6f855186c2c1b59", "filename": "roles/7-edu-apps/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Educational Apps and Content Installed\n  command: echo Educational Apps and Content Installed\n\n"}, {"commit_sha": "8c72df4ecfaa4188202ab0872f4500384ffe5233", "sha": "cd442b74442fc956a61fa680f8a78b3ee5cf3307", "filename": "tasks/postinstall.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Reset internal variables for additional packages to be installed\n  set_fact:\n    _docker_additional_packages_os: []\n    _docker_additional_packages_pip: []\n    _docker_python_system: false\n\n- name: Do best effort detection and set fact to indicate system Python environment is used\n  set_fact:\n    _docker_python_system: true\n  when: ansible_python.executable | regex_search('^/bin') or ansible_python.executable | regex_search('^/usr/bin')\n\n- name: Set facts to install Docker SDK for Python\n  set_fact:\n    _docker_additional_packages_pip: \"{{ _docker_additional_packages_pip + docker_predefined_packages_pip[_docker_os_dist]['sdk'] }}\"\n  when:\n    - docker_sdk\n\n- name: Set facts to install Docker Compose\n  set_fact:\n    _docker_additional_packages_pip: \"{{ _docker_additional_packages_pip + docker_predefined_packages_pip[_docker_os_dist]['compose'] }}\"\n  when:\n    - docker_compose\n\n- name: Set facts to install Docker Stack dependencies ('docker_stack')\n  set_fact:\n    _docker_additional_packages_pip: \"{{ _docker_additional_packages_pip + docker_predefined_packages_pip[_docker_os_dist]['stack'] }}\"\n  when:\n    - docker_stack\n\n- name: Set facts with additional package to be installed\n  set_fact:\n    _docker_additional_packages_pip: \"{{ _docker_additional_packages_pip + docker_additional_packages_pip }}\"\n    _docker_additional_packages_os: \"{{ _docker_additional_packages_os + docker_additional_packages_os }}\"\n\n- name: Ensure EPEL release repository is installed\n  become: true\n  package:\n    name: \"epel-release\"\n    state: present\n  when:\n    - _docker_os_dist == \"CentOS\"\n    - _docker_additional_packages_os | length > 0\n\n- name: Install additional packages (OS package manager)\n  become: true\n  package:\n    name: \"{{ item }}\"\n    state: present\n  with_items:\n    - \"{{ _docker_additional_packages_os }}\"\n  when: _docker_additional_packages_os | length > 0\n\n- name: Upgrade PiP\n  become: true\n  pip:\n    name: pip\n    state: forcereinstall\n  when: docker_pip_upgrade\n\n- name: Install additional packages (PiP)\n  become: true\n  pip:\n    name: \"{{ item }}\"\n    state: present\n    extra_args: --user\n  with_items:\n    - \"{{ _docker_additional_packages_pip }}\"\n  when: _docker_additional_packages_pip | length > 0\n  environment:\n    PYTHONWARNINGS: ignore\n\n# Not using github_release:  https://github.com/ansible/ansible/issues/45391\n- name: Get latest release of docker-compose\n  uri:\n    url: https://api.github.com/repos/docker/compose/releases/latest\n    body_format: json\n  register: _github_docker_compose\n  when:\n    - docker_compose_no_pip\n\n# Official installation of docker-compose (Linux): https://docs.docker.com/compose/install/#install-compose\n- name: Install docker-compose (Linux)\n  become: true\n  get_url:\n    url: \"https://github.com/docker/compose/releases/download/{{ _github_docker_compose.json.tag_name }}/docker-compose-{{ ansible_system }}-{{ ansible_architecture }}\"\n    checksum: \"sha256:https://github.com/docker/compose/releases/download/{{ _github_docker_compose.json.tag_name }}/docker-compose-{{ ansible_system }}-{{ ansible_architecture }}.sha256\"\n    dest: /usr/local/bin/docker-compose\n    mode: 0755\n  when:\n    - docker_compose_no_pip\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "c3c699e18aeab4dbe410ea04b77942763397186c", "filename": "roles/dns/manage-dns-zones/tests/inventory/group_vars/all.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "dns_data:\n  views:\n    - name: \"private\"\n      zones:\n        - dns_domain: \"roletest1.com\"\n          state: present\n          route53:\n            aws_access_key: \"{{ aws_access_key }}\"\n            aws_secret_key: \"{{ aws_secret_key }}\"\n            vpc_id: vpc-9dcde6f8\n            vpc_region: eu-west-1\n          entries:\n          - type: A\n            record: server_a\n            value: 192.168.1.1\n            ttl: 400\n            state: present\n          - type: A\n            record: server_b\n            value: 192.168.1.2\n            ttl: 500\n            state: present\n        - dns_domain: \"roletest2.com\"\n          state: present\n          route53:\n            aws_access_key: \"{{ aws_access_key }}\"\n            aws_secret_key: \"{{ aws_secret_key }}\"\n            vpc_id: vpc-9dcde6f8\n            vpc_region: eu-west-1\n          entries:\n          - type: A\n            record: server_a\n            value: 192.168.1.1\n            ttl: 400\n            state: present\n          - type: A\n            record: server_b\n            value: 192.168.1.2\n            ttl: 500\n            state: present\n    - name: \"public\"\n      zones:\n        - dns_domain: \"roletest3.com\"\n          state: absent\n          route53:\n            aws_access_key: \"{{ aws_access_key }}\"\n            aws_secret_key: \"{{ aws_secret_key }}\"\n          entries:\n          - type: A\n            record: server_a\n            value: 192.168.1.1\n            ttl: 400\n            state: present\n          - type: A\n            record: server_b\n            value: 192.168.1.2\n            ttl: 500\n            state: present\n        - dns_domain: \"roletest4.com\"\n          state: absent\n          route53:\n            aws_access_key: \"{{ aws_access_key }}\"\n            aws_secret_key: \"{{ aws_secret_key }}\"\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "15fbbd9da9e9cea2c57816a113efc36414488562", "filename": "roles/cloud-digitalocean/tasks/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: Set the DigitalOcean Access Token fact\n  set_fact:\n    do_token: \"{{ do_access_token | default(lookup('env','DO_API_TOKEN'), true) }}\"\n    public_key: \"{{ lookup('file', '{{ SSH_keys.public }}') }}\"\n\n- block:\n    - name: \"Delete the existing Algo SSH keys\"\n      digital_ocean:\n        state: absent\n        command: ssh\n        api_token: \"{{ do_token }}\"\n        name: \"{{ SSH_keys.comment }}\"\n      register: ssh_keys\n      until: ssh_keys.changed != true\n      retries: 10\n      delay: 1\n\n  rescue:\n    - name: Collect the fail error\n      digital_ocean:\n        state: absent\n        command: ssh\n        api_token: \"{{ do_token }}\"\n        name: \"{{ SSH_keys.comment }}\"\n      register: ssh_keys\n      ignore_errors: yes\n\n    - debug: var=ssh_keys\n\n    - fail:\n        msg: \"Please, ensure that your API token is not read-only.\"\n\n- name: \"Upload the SSH key\"\n  digital_ocean:\n    state: present\n    command: ssh\n    ssh_pub_key: \"{{ public_key }}\"\n    api_token: \"{{ do_token }}\"\n    name: \"{{ SSH_keys.comment }}\"\n  register: do_ssh_key\n\n- name: \"Creating a droplet...\"\n  digital_ocean:\n    state: present\n    command: droplet\n    name: \"{{ do_server_name }}\"\n    region_id: \"{{ do_region }}\"\n    size_id: \"{{ cloud_providers.digitalocean.size }}\"\n    image_id: \"ubuntu-16-04-x64\"\n    ssh_key_ids: \"{{ do_ssh_key.ssh_key.id }}\"\n    unique_name: yes\n    api_token: \"{{ do_token }}\"\n    ipv6: yes\n  register: do\n\n- name: Add the droplet to an inventory group\n  add_host:\n    name: \"{{ do.droplet.ip_address }}\"\n    groups: vpn-host\n    ansible_ssh_user: root\n    ansible_python_interpreter: \"/usr/bin/python2.7\"\n    ansible_ssh_private_key_file: \"{{ SSH_keys.private }}\"\n    do_access_token: \"{{ do_token }}\"\n    do_droplet_id: \"{{ do.droplet.id }}\"\n    cloud_provider: digitalocean\n    ipv6_support: true\n\n- set_fact:\n    cloud_instance_ip: \"{{ do.droplet.ip_address }}\"\n\n- name: Tag the droplet\n  digital_ocean_tag:\n    name: \"Environment:Algo\"\n    resource_id: \"{{ do.droplet.id }}\"\n    api_token: \"{{ do_token }}\"\n    state: present\n\n- name: Get droplets\n  uri:\n    url: \"https://api.digitalocean.com/v2/droplets?tag_name=Environment:Algo\"\n    method: GET\n    status_code: 200\n    headers:\n      Content-Type: \"application/json\"\n      Authorization: \"Bearer {{ do_token }}\"\n  register: do_droplets\n\n- name: Ensure the group digitalocean exists in the dynamic inventory file\n  lineinfile:\n    state: present\n    dest: configs/inventory.dynamic\n    line: '[digitalocean]'\n\n- name: Populate the dynamic inventory\n  lineinfile:\n    state: present\n    dest: configs/inventory.dynamic\n    insertafter: '\\[digitalocean\\]'\n    regexp: \"^{{ item.networks.v4[0].ip_address }}.*\"\n    line: \"{{ item.networks.v4[0].ip_address }}\"\n  with_items:\n    - \"{{ do_droplets.json.droplets }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "60eb032b2661a78c785de4c6976f6bfffc8aeba3", "filename": "roles/owncloud/README.rst", "repository": "iiab/iiab", "decoded_content": "===============\nOwncloud README\n===============\n\nThis role installs Owncloud, a local cloud type server to share files, calendars, and contacts.\n\nConfiguration Parameters\n------------------------\n\nThe following are set as defaults in var/main.yml:\n\n* owncloud_install: True\n* owncloud_enabled: False\n* owncloud_prefix: \"/opt\"\n* owncloud_data_dir: /library/owncloud/data\n* owncloud_src_file: owncloud-7.0.12.tar.bz2\n\n* owncloud_admin_user: 'Admin'\n* owncloud_admin_password: 'changeme'\n\nWe install on mysql with these setting or those from default_vars, etc.\n\n* owncloud_dbname: owncloud\n* owncloud_dbhost: localhost\n* owncloud_dbuser: owncloud\n* owncloud_dbpassword: owncloudmysql\n\nAccess and Installation Wizard\n------------------------------\n\nThe ansible installation performs the Owncloud Wizard.\n\nAfter the ansible installation completes, you can access Owncloud at http://schoolserve/owncloud.\n\nThe default admin user name and password are Admin / changeme.\n\nLogin and change the password.  You can now add users and start sharing content.\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "876b7a6a579d82b6bfdb60ee758874d23a5a4967", "filename": "roles/dns/manage-dns-zones/tasks/route53/empty-zone.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: \"Remove records in Private zone\"\n  route53:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    state: absent\n    zone: \"{{ zone.dns_domain }}\"\n    private_zone: \"true\"\n    vpc_id: \"{{ zone.route53.vpc_id }}\"\n    value: \"{{ r53_record.1.Value }}\"\n    record: \"{{ r53_record.0.Name }}\"\n    ttl: \"{{ r53_record.0.TTL }}\"\n    type: \"{{ r53_record.0.Type }}\"\n  when: (zone.dns_domain + \".\" == r53_zone.item.Name) and\n        (view.name == \"private\") and\n        ((r53_record.0.Name != r53_zone.item.Name) and\n        (r53_record.0.Type != \"SOA\") and\n        (r53_record.0.Type != \"NS\"))\n\n- name: \"Remove records in Public zone\"\n  route53:\n    aws_access_key: \"{{ aws_access_key }}\"\n    aws_secret_key: \"{{ aws_secret_key }}\"\n    state: absent\n    zone: \"{{ zone.dns_domain }}\"\n    record: \"{{ r53_record.0.Name }}\"\n    ttl: \"{{ r53_record.0.TTL }}\"\n    value: \"{{ r53_record.1.Value }}\"\n    type: \"{{ r53_record.0.Type }}\"\n  when: (zone.dns_domain + \".\" == r53_zone.item.Name) and\n        (view.name == \"public\") and\n        ((r53_record.0.Name != r53_zone.item.Name) and\n        (r53_record.0.Type != \"SOA\") and\n        (r53_record.0.Type != \"NS\"))\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "7f2902ea256af5502adc08d5388cc4b345a6d43d", "filename": "roles/letsencrypt/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "- include: setup.yml\n- include: nginx.yml\n- include: certificates.yml\n\n- name: Install cronjob for key generation\n  cron:\n    cron_file: letsencrypt-certificate-renewal\n    name: letsencrypt certificate renewal\n    user: root\n    job: cd {{ acme_tiny_data_directory }} && ./renew-certs.py && service nginx reload\n    day: \"{{ letsencrypt_cronjob_daysofmonth }}\"\n    hour: 4\n    minute: 30\n    state: present\n"}, {"commit_sha": "cf72df3efff6896d33fb9e6ec6a8d50ab39341ce", "sha": "7e4fa19281f21c02e17114b75605e85feacb929d", "filename": "archive/roles/cicd/tasks/httpd.yml", "repository": "redhat-cop/casl-ansible", "decoded_content": "---\n  \n- name: Installing HTTPD\n  yum: \n    name: httpd\n    state: present\n  tags: httpd\n  \n- name: Copy HTTPD Files\n  copy: \n    src: \"{{ item.src }}\"\n    dest: \"{{ item.dest }}\"\n  notify:\n  - restart httpd\n  with_items:\n  - { src: httpd/index.html, dest: /var/www/html/index.html }\n  - { src: httpd/cicd.conf, dest: /etc/httpd/conf.d/cicd.conf }\n  tags: httpd\n  \n- name: Open Firewall for HTTP\n  firewalld: \n    port: 80/tcp\n    zone: public\n    permanent: yes\n    immediate: yes\n    state: enabled\n  tags: httpd\n\n- name: HTTPD SELinux Configurations\n  seboolean: \n    name: httpd_can_network_connect\n    state: yes\n    persistent: yes\n  tags: httpd\n  \n- name: Enable HTTPD Service\n  service: \n    name: httpd\n    enabled: true\n  tags: httpd\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "97e8d9c1b28c4053be5702471365f2862355984b", "filename": "roles/network/templates/named/school.external.zone.db", "repository": "iiab/iiab", "decoded_content": "@ in soa localhost. root 1 3H 15M 1W 1D\n  ns localhost.\n\nschoolserver\tIN\tA\t18.85.46.29\nschool\t\tIN\tCNAME\tschoolserver\nwww\t\tIN\tCNAME\tschoolserver\nntp\t\tIN\tCNAME   schoolserver\ntime\t\tIN\tCNAME\tschoolserver\npresence\tIN\tCNAME\tschoolserver\nxs\t\tIN\tCNAME\tschoolserver\nlibrary\t\tIN\tCNAME\tschoolserver\nconference.schoolserver\tIN\tCNAME\tschoolserver\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "8dd11bd89dadcd410bdaf32dd7ce68405f54cc16", "filename": "roles/scm/add-webhooks-github/tasks/add-webhook.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n# Helper for main.yml\n\n- set_fact:\n    payload:\n      name: \"web\"\n      active: \"{{ is_active }}\"\n      events: \"{{ events }}\"\n      config:\n        url: \"{{ url }}\"\n        content_type: \"json\"\n        insecure_ssl: \"1\"\n\n- uri:\n    url: https://api.github.com/repos/{{ owner }}/{{ repo }}/hooks\n    method: POST\n    headers:\n      Authorization: token {{ api_token }}\n    body_format: json\n    body: \"{{ payload | to_json }}\"\n    status_code: 201, 422\n  register: request_output\n  changed_when: request_output.status == 201\n"}, {"commit_sha": "481f7ad18dc225973e1d676d33e58c49cbbfe986", "sha": "3d0e194e46bc9a8cdf67c5fe65c9a3830c8d7091", "filename": "tasks/multitenancy_migration.yml", "repository": "openwisp/ansible-openwisp2", "decoded_content": "- name: multi-tenancy migration dumpdata\n  shell: \"{{ virtualenv_path }}/bin/python manage.py dumpdata > pre_multitenancy_migration.json\"\n  args:\n    chdir: \"{{ openwisp2_path }}\"\n    creates: \"{{ openwisp2_path }}/pre_multitenancy_migration.json\"\n\n- name: upload multitenancy_prepare_data.py script\n  template:\n    src: ../templates/multitenancy_prepare_data.py\n    dest: \"{{ openwisp2_path }}/multitenancy_prepare_data.py\"\n    mode: 0754\n\n- name: prepare data for multitenancy migration\n  command: \"./multitenancy_prepare_data.py\"\n  args:\n    chdir: \"{{ openwisp2_path }}\"\n    creates: \"{{ openwisp2_path }}/post_multitenancy_migration.json\"\n\n- name: DROP sqlite database\n  when: openwisp2_database.engine == \"django.db.backends.sqlite3\"\n  file:\n    name: \"{{ openwisp2_database.name }}\"\n    state: absent\n\n- name: DROP postgres database\n  when: openwisp2_database.engine in [\"django.db.backends.postgresql\", \"django.contrib.gis.db.backends.postgis\"]\n  become: true\n  become_user: postgres\n  postgresql_db:\n    name: \"{{ openwisp2_database.name }}\"\n    state: absent\n\n- name: CREATE postgres database\n  when: openwisp2_database.engine in [\"django.db.backends.postgresql\", \"django.contrib.gis.db.backends.postgis\"]\n  become: true\n  become_user: postgres\n  postgresql_db:\n    name: \"{{ openwisp2_database.name }}\"\n    state: present\n\n- name: install python-mysqldb in system python packages\n  when: openwisp2_database.engine in [\"django.db.backends.mysql\", \"django.contrib.gis.db.backends.mysql\"]\n  pip:\n    name: MySQL-python\n    state: latest\n\n- name: DROP mysql database\n  when: openwisp2_database.engine in [\"django.db.backends.mysql\", \"django.contrib.gis.db.backends.mysql\"]\n  mysql_db:\n    name: \"{{ openwisp2_database.name }}\"\n    state: absent\n    login_user: \"{{ openwisp2_database.user }}\"\n    login_password: \"{{ openwisp2_database.password }}\"\n    login_host: \"{{ openwisp2_database.host|default('127.0.0.1') }}\"\n    login_port: \"{{ openwisp2_database.port|default('3306') }}\"\n\n- name: CREATE mysql database\n  when: openwisp2_database.engine in [\"django.db.backends.mysql\", \"django.contrib.gis.db.backends.mysql\"]\n  mysql_db:\n    name: \"{{ openwisp2_database.name }}\"\n    state: present\n    login_user: \"{{ openwisp2_database.user }}\"\n    login_password: \"{{ openwisp2_database.password }}\"\n    login_host: \"{{ openwisp2_database.host|default('127.0.0.1') }}\"\n    login_port: \"{{ openwisp2_database.port|default('3306') }}\"\n\n# this task purposely duplicates this operation in order to isolate\n# all the multitenancy-migration operations in this single YAML file\n- name: urls.py\n  notify: reload supervisor\n  template:\n    src: ../templates/openwisp2/urls.py\n    dest: \"{{ openwisp2_path }}/openwisp2/urls.py\"\n    group: www-data\n\n# this task purposely duplicates this operation in order to isolate\n# all the multitenancy-migration operations in this single YAML file\n# set openwisp2_secret_key if not defined explicitly\n- import_tasks: django_secret_key.yml\n  when: openwisp2_secret_key is not defined\n\n# this task purposely duplicates this operation in order to isolate\n# all the multitenancy-migration operations in this single YAML file\n- name: settings.py\n  notify: reload supervisor\n  template:\n    src: ../templates/openwisp2/settings.py\n    dest: \"{{ openwisp2_path }}/openwisp2/settings.py\"\n    group: www-data\n\n# this task purposely duplicates this operation in order to isolate\n# all the multitenancy-migration operations in this single YAML file\n- name: migrate\n  notify: reload supervisor\n  become: yes\n  become_user: www-data\n  django_manage:\n    app_path: \"{{ openwisp2_path }}\"\n    command: migrate\n    virtualenv: \"{{ virtualenv_path }}\"\n\n# this task purposely duplicates this operation in order to isolate\n# all the multitenancy-migration operations in this single YAML file\n- name: set permissions to sqlite db\n  when: openwisp2_database.engine == \"django.db.backends.sqlite3\"\n  file:\n    path: \"{{ openwisp2_database.name }}\"\n    state: file\n    group: www-data\n    mode: 0775\n\n- name: upload multitenancy_prepare_db.py script\n  template:\n    src: ../templates/multitenancy_prepare_db.py\n    dest: \"{{ openwisp2_path }}/multitenancy_prepare_db.py\"\n    mode: 0754\n\n- name: prepare DB for multitenancy migration\n  command: \"{{ virtualenv_path }}/bin/python multitenancy_prepare_db.py\"\n  args:\n    chdir: \"{{ openwisp2_path }}\"\n\n- name: multitenancy migration loaddata\n  become: yes\n  become_user: www-data\n  django_manage:\n    app_path: \"{{ openwisp2_path }}\"\n    command: loaddata\n    fixtures: post_multitenancy_migration.json\n    virtualenv: \"{{ virtualenv_path }}\"\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "9e2b1cff0e54cc4113996e264f6dd48caae845c5", "filename": "roles/dns/manage-dns-zones/tasks/named/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: determine-action.yml\n\n- block:\n    - import_tasks: prereq.yml\n    - import_tasks: process-views.yml\n    - import_tasks: keys.yml\n    - import_tasks: print_keys.yml\n  when:\n    - named_processing|bool == True\n"}, {"commit_sha": "a77a8900bb9032eb97498fbb9149d4504e73b0b5", "sha": "77548dd65a2d20d9c2ed8ffc2611b278a83b21fb", "filename": "meta/main.yml", "repository": "geerlingguy/ansible-role-solr", "decoded_content": "---\ndependencies: []\n\ngalaxy_info:\n  author: geerlingguy\n  description: Apache Solr for Linux.\n  company: \"Midwestern Mac, LLC\"\n  license: \"license (BSD, MIT)\"\n  min_ansible_version: 2.2\n  platforms:\n    - name: EL\n      versions:\n      - 6\n      - 7\n    - name: Debian\n      versions:\n      - all\n    - name: Ubuntu\n      versions:\n      - all\n  galaxy_tags:\n    - development\n"}, {"commit_sha": "e91a55152358e890a05cf849abc7d58b8badecc2", "sha": "f56601b9635fc758de798dcbe30b3114181833a4", "filename": "tasks/go-install.yml", "repository": "fubarhouse/ansible-role-golang", "decoded_content": "---\n\n- name: \"Go-Lang | Clone packages\"\n  git:\n    repo: \"{{ item.repo }}\"\n    dest: \"{{ GOPATH }}/src/{{ item.dest }}\"\n    version: \"{{ item.version }}\"\n    clone: yes\n    update: yes\n    force: yes\n  with_items: \"{{ go_install }}\"\n  changed_when: false\n\n- name: \"Go-Lang | Install packages\"\n  shell: \"{{ GOROOT }}/bin/go install {{ item.dest }}/...\"\n  environment:\n    GOROOT: \"{{ GOROOT }}\"\n    GOPATH: \"{{ GOPATH }}\"\n  with_items: \"{{ go_install }}\"\n  changed_when: false"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "8798d0ec132f8098acc265ee32f3cec9ed78842b", "filename": "playbooks/files/rock_start", "repository": "rocknsm/rock", "decoded_content": "#!/bin/bash\n\nfunction feature_enabled() {\n  if grep -qiE \"^with_$1: (true|yes)\" /etc/rocknsm/config.yml; then\n    grep -qiE \"^enable_$1: (true|yes)\" /etc/rocknsm/config.yml;\n    return $?\n  else\n    return 1\n  fi\n}\n\nif feature_enabled zookeeper; then\n  echo \"Starting Zookeeper...\"\n  systemctl start zookeeper\n  sleep 5\n  systemctl status zookeeper | egrep \"^\\s*Active\"\nfi\n\nif feature_enabled elasticsearch; then\n  echo \"Starting Elasticsearch...\"\n  systemctl start elasticsearch\n  sleep 5\n  systemctl status elasticsearch | egrep \"^\\s*Active\"\nfi\n\nif feature_enabled kafka; then\n  echo \"Starting Kafka...\"\n  systemctl start kafka\n  sleep 5\n  systemctl status kafka | egrep \"^\\s*Active\"\nfi\n\nif feature_enabled logstash; then\n  echo \"Starting Logstash...\"\n  systemctl start logstash\n  sleep 5\n  systemctl status logstash | egrep \"^\\s*Active\"\nfi\n\nif feature_enabled kibana; then\n  echo \"Starting Kibana...\"\n  systemctl start kibana\n  sleep 5\n  systemctl status kibana | egrep \"^\\s*Active\"\nfi\n\nif feature_enabled suricata; then\n  echo \"Starting Suricata...\"\n  systemctl start suricata\n  sleep 5\n  systemctl status suricata | egrep \"^\\s*Active\"\nfi\n\nif feature_enabled snort; then\n  echo \"Starting Snort...\"\n  systemctl start snortd\n  sleep 5\n  systemctl status snortd | egrep \"^\\s*Active\"\nfi\n\nif feature_enabled bro; then\n  echo \"Starting Bro...\"\n  systemctl start broctl\n  sleep 5\n  systemctl status broctl | egrep \"^\\s*Active\"\nfi\n\nif feature_enabled stenographer; then\n  echo \"Starting Stenographer...\"\n  systemctl start stenographer\n  sleep 5\n  for item in $(ls  /etc/stenographer/config* | awk -F. '/\\./ { print $2 }')\n  do\n    systemctl status stenographer@${item} | egrep \"^\\s*Active\" | cat <( echo -n \"   ${item}: \") -\n  done\nfi\n\nif feature_enabled fsf; then\n  echo \"Starting FSF...\"\n  systemctl start fsf\n  sleep 5\n  systemctl status fsf | egrep \"^\\s*Active\"\nfi\n\nexit 0\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "6075ddacb80cef74ca3806932a89802353021455", "filename": "tasks/section_11_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 11.1.1 Set Warning Banner for Standard Login Services (Scored)\n    lineinfile: >\n        dest={{ item }}\n        create=yes\n        line='Authorized uses only. All activity may be monitored and reported.'\n        state=present\n        mode=644\n        owner=root\n        group=root\n    with_items:\n        - /etc/motd\n        - /etc/issue\n        - /etc/issue.net\n    tags:\n      - section11\n      - section11.1\n\n  - name: 11.2.1 Remove OS Information from Login Warning Banners (Scored)\n    shell: egrep '(\\\\v|\\\\r|\\\\m|\\\\s)' {{ item }}\n    register: egrep_os_infos\n    failed_when: egrep_os_infos.rc == 0\n    changed_when: False\n    with_items:\n        - /etc/motd\n        - /etc/issue\n        - /etc/issue.net\n    tags:\n      - section11\n      - section11.2\n\n  - name: 11.3.1 Set Graphical Warning Banner (Not Scored)\n    debug: msg=\"*** Set a banner for the display manager ***\"\n    tags:\n      - section11\n      - section11.3\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "10b65e6b87eadb2c7b0105ca56a6a607c3cd422b", "filename": "roles/mysql/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "    - name: Install MySQL Debian\n      package: name={{ item }}\n               state=present\n      with_items:\n        - mariadb-server\n        - mariadb-client\n        - python-mysqldb\n        - php{{ php_version }}\n        - php{{ php_version }}-mysql\n        - php-pear\n        - php{{ php_version }}-gd\n        - php{{ php_version }}-imap\n        - php{{ php_version }}-ldap\n        - php{{ php_version }}-odbc\n#        - php{{ php_version }}-xml\n        - php{{ php_version }}-xmlrpc\n      when: is_debuntu\n      tags:\n        - download\n\n    - name: php-xml for ubuntu and debian-9\n      package: name=php{{ php_version }}-xml state=present\n      when: is_ubuntu or is_debian_9\n\n    - name: php-xml for  debian-8\n      package: name=php-xml-parser state=present\n      when: is_debian_8\n\n    - name: Install MySQL\n      package: name={{ item }}\n               state=present\n      with_items:\n        - MySQL-python\n        - mysql\n        - php\n        - php-mysql\n        - php-pear\n        - php-gd\n        - php-imap\n        - php-ldap\n        - php-odbc\n        - php-xml\n        - php-xmlrpc\n      when: not is_debuntu\n      tags:\n        - download\n\n    - include: centos.yml\n      when: ansible_distribution == \"CentOS\"\n      tags:\n        - download\n\n    - include: fedora.yml\n      when: ansible_distribution == \"Fedora\"\n      tags:\n        - download\n\n# Name of mysql service varies by OS so softcoded in 1-prep\n    - name: Start the MySQL service\n      service: name={{ mysql_service }}\n               state=started\n\n    - name: Enable the MySQL service\n      service: name={{ mysql_service }}\n               enabled=yes\n      when: mysql_enabled\n\n# 'localhost' needs to be the last item for idempotency, see\n# http://ansible.cc/docs/modules.html#mysql-user\n# unfortunately it still doesn't work\n    - name: update mysql root password for localhost root accounts\n      mysql_user: name=root host={{ item }}  password={{ mysql_root_password }} priv=*.*:ALL,GRANT\n      with_items:\n        - localhost\n      when: mysql_enabled\n\n    - name: copy .my.cnf file with root password credentials\n      template: src=my.cnf.j2 dest=/root/.my.cnf owner=root mode=0600\n      when: mysql_enabled\n\n    - name: update mysql root password for all remaining root accounts\n      mysql_user: name=root host={{ item }}  password={{ mysql_root_password }} priv=*.*:ALL,GRANT\n      with_items:\n#        - \"{{ iiab_hostname }}.{{ iiab_domain }}\"\n        - 127.0.0.1\n        - ::1\n      when: mysql_enabled\n\n    - name: delete anonymous MySQL server user for {{ ansible_hostname }}\n      mysql_user: user=\"\" host=\"{{ ansible_hostname }}\" state=\"absent\"\n      when: mysql_enabled\n\n    - name: delete anonymous MySQL server user for localhost\n      mysql_user: user=\"\" state=\"absent\"\n      when: mysql_enabled\n\n    - name: remove the MySQL test database\n      mysql_db: db=test state=absent\n      when: mysql_enabled\n\n# we had to start mysql in order to configure it, now turn if off if not enabled\n    - name: Provisionally Disable the MySQL service\n      service: name={{ mysql_service }}\n               enabled=no\n               state=stopped\n      when: not mysql_enabled\n\n\n    - name: add mysql to service list\n      ini_file: dest='{{ service_filelist }}'\n                    section=mysql\n                    option='{{ item.option }}'\n                    value='{{ item.value }}'\n      with_items:\n            - option: name\n              value: mysql-database\n            - option: description\n              value: '\"mySQL is a widely used database service on the Internet which runs on many platforms, and is often offered and available at hosting Internet Service Providers\"'\n            - option: enabled\n              value: \"{{ mysql_enabled }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "289cca8d70521e0bae4ac626f32cf0a1e50201f6", "filename": "roles/network/tasks/avahi.yml", "repository": "iiab/iiab", "decoded_content": "- name: Install avahi package\n  package: name={{ item }}\n           state=present\n  with_items:\n   - libnss-mdns\n   - avahi-daemon\n   - avahi-discover\n  when: is_debuntu\n  tags:\n    - download\n\n- name: Install avahi package\n  package: name={{ item }}\n           state=present\n  with_items:\n   - nss-mdns\n   - avahi\n   - avahi-tools\n  when: not is_debuntu\n  tags:\n    - download\n\n- name: Create a user for avahi\n  user: name=avahi\n        createhome=no\n        shell=/bin/false\n  when: is_debuntu\n\n- name: Install avahi announce config files\n  template: src=avahi/schoolserver.service\n            dest=/etc/avahi/services/schoolserver.service\n            owner=avahi\n            group=avahi\n            mode=0640\n  when: 'gui_wan == True'\n\n- name: Find a clean copy of ssh.service\n  shell: \"ls /usr/share/doc/ |grep avahi | head -n1\"\n  register: avahi_ver\n  ignore_errors: True\n  changed_when: false\n\n- name: Grab a clean copy of ssh.service\n  copy: src='/usr/share/doc/{{ avahi_ver.stdout }}/ssh.service'\n        dest='/etc/avahi/services/'\n  when: avahi_ver.stdout != \"\" and not is_debuntu\n\n- name: Grab a clean copy of ssh.service\n  copy: src='/usr/share/doc/avahi-daemon/examples/ssh.service'\n        dest='/etc/avahi/services/'\n  when: is_debuntu\n\n- name: set ssh port for avahi\n  lineinfile: dest=/etc/avahi/services/ssh.service\n              regexp='</port>$'\n              line='    <port>{{ ssh_port }}</port>'\n              state=present\n              backrefs=yes\n\n- name: Enable avahi service\n  service: name=avahi-daemon\n           enabled=yes\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "351f1469f9c6afe44965fd77bec6f6bee6c6d257", "filename": "playbooks/roles/bb0-openstack/defaults/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "---\n# defaults file for provisioning_openstack\n\nheat_template_path: heat/openshift.yaml"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "1fc9a54075ec7e15167076fa6f81817229065fde", "filename": "roles/osp/admin-network/tasks/manage-networks.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Set up network(s)\"\n  os_network:\n    cloud: \"{{ item.cloud | default(osp_default_cloud) | default(omit) }}\"\n    project: \"{{ item.project | default(omit) }}\"\n    state: \"{{ item.state | default(osp_resource_state) | default('present') }}\"\n    name: \"{{ item.name }}\"\n    external: \"{{ item.external | default(False) }}\"\n    provider_network_type: \"{{ item.provider_network_type | default(omit) }}\"\n    provider_physical_network: \"{{ item.provider_physical_network | default(omit) }}\"\n    provider_segmentation_id: \"{{ item.provider_segmentation_id | default(omit) }}\"\n  with_items:\n  - \"{{ osp_networks | default([]) }}\"\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "a957171a0ef9bc40ab1e297f190a96cdcd9ac245", "filename": "roles/mariadb/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: Add MariaDB MySQL apt-key\n  apt_key:\n    url: \"http://keyserver.ubuntu.com/pks/lookup?op=get&fingerprint=on&search={{ mariadb_keyserver_fingerprint }}\"\n    state: present\n\n- name: Add MariaDB MySQL deb and deb-src\n  apt_repository:\n    repo: \"{{ item }}\"\n    state: present\n  with_items:\n    - \"deb http://{{ mariadb_mirror }}/mariadb/repo/{{ mariadb_version }}/ubuntu {{ mariadb_dist | default(ansible_distribution_release) }} main\"\n    - \"deb-src http://{{ mariadb_mirror }}/mariadb/repo/{{ mariadb_version }}/ubuntu {{ mariadb_dist | default(ansible_distribution_release) }} main\"\n\n- name: Install MySQL client\n  apt:\n    name: mariadb-client\n    state: present\n\n- block:\n  - name: Install MariaDB MySQL server\n    apt:\n      name: mariadb-server\n      state: present\n\n  - name: Disable MariaDB binary logging\n    template:\n      src: disable-binary-logging.cnf\n      dest: /etc/mysql/conf.d\n      owner: root\n      group: root\n    when: mariadb_binary_logging_disabled\n\n  - name: Restart MariaDB MySQL Server\n    service:\n      name: mysql\n      state: restarted\n      enabled: true\n\n  - name: Set root user password\n    mysql_user:\n      name: root\n      host: \"{{ item }}\"\n      password: \"{{ mysql_root_password }}\"\n      check_implicit_admin: yes\n      state: present\n    with_items:\n      - \"{{ inventory_hostname }}\"\n      - 127.0.0.1\n      - ::1\n      - localhost\n\n  - name: Copy .my.cnf file with root password credentials.\n    template:\n      src: my.cnf.j2\n      dest: ~/.my.cnf\n      owner: root\n      group: root\n      mode: 0600\n\n  - name: Delete anonymous MySQL server users\n    mysql_user:\n      user: \"\"\n      host: \"{{ item }}\"\n      state: absent\n    with_items:\n      - localhost\n      - \"{{ inventory_hostname }}\"\n      - \"{{ ansible_hostname }}\"\n\n  - name: Remove the test database\n    mysql_db:\n      name: test\n      state: absent\n\n  when: not sites_using_remote_db | count\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "3d4aee18287e3a5028a3842332cc904569e759b7", "filename": "roles/usb-lib/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Add a  content directory for links to be located\n  file: dest={{ doc_root }}/local_content\n        state=directory\n        owner={{ apache_user }}\n        group={{ iiab_admin_user }}\n        mode=0775\n\n- name: Copy mount file to usbmount when enabled\n  template: src=mount.d/70-usb-library\n            dest=/etc/usbmount/mount.d/\n            owner=root\n            group=root\n            mode=0751\n  when: usb_lib_enabled\n\n- name: Copy umount file to usbmount when enabled\n  template: src=umount.d/70-usb-library\n            dest=/etc/usbmount/umount.d\n            owner=root\n            group=root\n            mode=0751\n  when: usb_lib_enabled\n\n- name: Remove mount file to usbmount when not enabled\n  file: path=/etc/usbmount/mount.d/70-usb-library\n        state=absent\n  when: not usb_lib_enabled\n\n- name: Remove umount file to usbmount when not enabled\n  file: path=/etc/usbmount/umount.d/70-usb-library\n        state=absent\n  when: not usb_lib_enabled\n\n- name: Add apache config for content directory\n  template: src=content_dir.conf\n            dest=/etc/{{ apache_config_dir }}\n  when: usb_lib_enabled\n\n- name: create the link to enable for debian\n  file: src=/etc/{{ apache_config_dir }}/content_dir.conf\n        dest=/etc/apache2/sites-enabled/content_dir.conf\n        state=link\n  when: is_debuntu\n\n- name: remove the link that enables in debian\n  file: src=/etc/{{ apache_config_dir }}/content_dir.conf\n        dest=/etc/apache2/sites-enabled/content_dir.conf\n        state=absent\n  when: is_debuntu and not usb_lib_enabled\n\n- name: remove apache config for content directory\n  file: name=/etc/{{ apache_config_dir }}/content_dir.conf\n        state=absent\n  when: not usb_lib_enabled\n\n- name: Add usb-lib to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=usb-lib\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: usb-lib\n    - option: description\n      value: '\"usb-lib automounts a usb drive with and links to library content.\"'\n    - option: enabled\n      value: \"{{ usb_lib_enabled }}\"\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "bde310154e9c91a0db00e88cc42696d5b0ddddc4", "filename": "playbooks/templates/broctl.service.j2", "repository": "rocknsm/rock", "decoded_content": "[Unit]\nDescription=Bro Network Intrusion Detection System (NIDS)\nAfter=network.target\n\n[Service]\nType=forking\nUser={{ bro_user }}\nGroup={{ bro_group }}\nEnvironment=HOME={{ bro_data_dir }}/spool\nExecStart=/opt/bro/bin/broctl deploy\nExecStop=/opt/bro/bin/broctl stop\n\n[Install]\nWantedBy=multi-user.target\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "fb807672204b682c6beed9188d20b6ce48d572fa", "filename": "roles/network/tasks/edit_ifcfg.yml", "repository": "iiab/iiab", "decoded_content": "- name: Turn off isp nameservers\n  lineinfile: state=present\n              backrefs=yes\n              regexp='^PEERDNS'\n              line='PEERDNS=\"no\"'\n              dest={{ has_ifcfg_gw }}\n\n- name: Turn on local nameserver\n  lineinfile: state=present\n              line='DNS1=\"127.0.0.1\"'\n              dest={{ has_ifcfg_gw }}\n\n- name: Remove the UUID\n  lineinfile: state=absent\n              regexp='^UUID'\n              dest={{ has_ifcfg_gw }}\n\n# Leave wifi as is NAME=<AP> needs to match keyring name.\n- name: Fix the NM name\n  lineinfile: state=present\n              backrefs=yes\n              regexp='^NAME'\n              line='NAME=\"iiab-WAN\"'\n              dest={{ has_ifcfg_gw }}\n  when: has_wifi_gw == \"none\"\n\n# testpoint - quoting and present\n# note DEVICE can change what is displayed via \"ip and friends\"\n- name: Fix the DEVICE\n  lineinfile: state=present\n              backrefs=yes\n              regexp='^DEVICE'\n              line='DEVICE=\"{{ iiab_wan_iface }}\"'\n              dest={{ has_ifcfg_gw }}\n  when: iiab_wan_iface != \"none\" and has_wifi_gw == \"none\"\n\n- name: add marker\n  lineinfile: state=present\n              line=\"# Modified by XSCE\"\n              dest={{ has_ifcfg_gw }}\n\n- name: Rename supplied gateway ifcfg file to WAN if present\n  shell: mv \"{{ has_ifcfg_gw }}\" /etc/sysconfig/network-scripts/ifcfg-WAN\n  when: has_wifi_gw == \"none\"\n\n- name: Now setting ifcfg-WAN True after moving file\n  set_fact:\n    has_WAN: True\n  when: has_wifi_gw == \"none\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "85f00aec5c656093ed2af7e6230242e9ee3db0a7", "filename": "roles/config-nagios-target/tasks/firewall.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Check if firewalld is enabled - if so, use it\n  command: systemctl status firewalld\n  register: firewalld_status\n  failed_when: false\n  changed_when: false\n\n- name: Open port in firewalld (if enabled)\n  when: firewalld_status.rc == 0\n  firewalld:\n    port: \"{{firewall_port}}/{{firewall_protocol}}\"\n    permanent: true\n    state: enabled\n  notify:\n  - restart firewalld\n\n- name: Ensure iptables is correctly configured \n  when: firewalld_status.rc != 0\n  lineinfile:\n    insertafter: \"^-A INPUT .* --dport 22 .* ACCEPT\"\n    state: present\n    dest: /etc/sysconfig/iptables\n    regexp: \"^-A INPUT .* --dport {{firewall_port}} .* ACCEPT\"\n    line: \"-A INPUT -p {{firewall_protocol}} -m state --state NEW -m {{firewall_protocol}} --dport {{firewall_port}} -j ACCEPT\"\n  notify:\n  - restart iptables\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "71e32966bd974f4a8632a870e10e27f9f4761676", "filename": "roles/osp/admin-sec-group/test/inventory/group_vars/all.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "--- \n\nosp_security_groups:\n- name: \"ingress-sec-group\"\n  description: \"My ingress Sec Group\"\n  rules:\n  - protocol: tcp\n    port_range_min: 1022\n    port_range_max: 1022\n    direction: ingress\n    remote_ip_prefix: 0.0.0.0/0\n- name: \"egress-sec-group\"\n  description: \"My egress Sec Group\"\n  rules:\n  - protocol: tcp\n    port_range_min: 1122\n    port_range_max: 1122\n    direction: egress\n    remote_ip_prefix: 0.0.0.0/0\n\n"}, {"commit_sha": "96adc61e360141bb718b75d48c387b3680a8471b", "sha": "5046dc11257e6e710565aa2ca3e03ec66865a0f8", "filename": "tasks/distribution-checks.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Fail if unsupported CentOS/RedHat version\n  fail:\n    msg: \"CentOS/RedHat 7 or later is required!\"\n  when: (_docker_os_dist == \"CentOS\" or _docker_os_dist == \"RedHat\") and\n        _docker_os_dist_major_version < '7'\n\n- name: Fail if unsupported Fedora version\n  fail:\n    msg: \"Fedora 24 or later is required!\"\n  when: _docker_os_dist == \"Fedora\" and\n        _docker_os_dist_major_version < '24'\n\n- name: Fail if unsupported Ubuntu version\n  fail:\n    msg: \"Ubuntu 14 or later is required!\"\n  when: _docker_os_dist == \"Ubuntu\" and\n        _docker_os_dist_major_version < '14'\n\n- name: Fail if unsupported Debian version\n  fail:\n    msg: \"Debian 8 (jessie) or later is required!\"\n  when: _docker_os_dist == \"Debian\" and\n        _docker_os_dist_major_version < '8'\n\n- name: Fail if this roles does not support the distribution\n  fail:\n    msg: \"Distribution {{ _docker_os_dist }} is not supported by this role!\"\n  when: _docker_os_dist != \"Fedora\" and\n        _docker_os_dist != \"CentOS\" and\n        _docker_os_dist != \"RedHat\" and\n        _docker_os_dist != \"Ubuntu\" and\n        _docker_os_dist != \"Debian\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "ed97d539c095cf1413af30cc23dea272095b97dd", "filename": "roles/config-nagios-server/tests/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "c191afe775dbd5cb34db58d5524b30b475df17b6", "filename": "roles/config-minishift-remote/tasks/minishift_download.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Download Minishift from official release\n  block:\n    - name: Get latest version of Minishift\n      uri:\n        url: https://api.github.com/repos/minishift/minishift/releases/latest\n        status_code: 200\n        return_content: yes\n        body_format: json\n      register: minishift_version_response\n      delegate_to: localhost\n\n    - name: Set Minishift version\n      set_fact:\n        minishift_version: \"{{ minishift_version_response.json.tag_name }}\"\n      delegate_to: localhost\n\n    - name: Set Minishift Download URL\n      set_fact:\n        minishift_url: \"https://github.com/minishift/minishift/releases/download/{{ minishift_version }}/minishift-{{ minishift_version | regex_replace('v') }}-linux-amd64.tgz\"\n      delegate_to: localhost\n  when: minishift_url is not undefined and minishift_url|trim != ''\n\n- name: Download Minishift\n  get_url:\n    url: \"{{ minishift_url }}\"\n    dest: \"{{ minishift_tmp_dir }}/minishift.tar.gz\"\n  delegate_to: localhost\n\n- name: Extract Minishift\n  become: \"{{ minishift_binary_location_escalation | bool }}\"\n  command: >\n    tar --strip-components=1 -xzf {{ minishift_tmp_dir }}/minishift.tar.gz -C {{ minishift_install_dir }}\n  args:\n    warn: false\n  delegate_to: localhost\n\n- name: Remove Downloaded Minishift\n  file:\n    state: absent\n    path: \"{{ minishift_tmp_dir }}/minishift.tar.gz\"\n  delegate_to: localhost\n\n- name: Set Minishift Executable\n  set_fact:\n    minishift_binary: \"{{ minishift_install_dir }}/minishift\"\n  delegate_to: localhost\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "13953683f8f704f79cfd81a8f377a59f76128396", "filename": "playbooks/provision-satellite-server/generate-lvm-list.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Create a temporary list of device_name => storage_device mapping\"\n  set_fact:\n    tmp_device_mapping: \"{{ tmp_device_mapping | default([]) + [ {'name': item.1.name, 'device': item.1.device } ] }}\"\n  with_subelements:\n  - \"{{ hostvars['localhost'].os_servers.results }}\"\n  - server.volumes\n\n- name: \"Create the list of LVM devices / mounts\"\n  set_fact:\n    tmp_lvm_entries: \"{{ tmp_lvm_entries | default([]) + [ item.0 | combine({'storage_device': item.1.device}) ] }}\"\n  when:\n  - item.0.device_name == item.1.name\n  with_nested:\n  - \"{{ lvm_entries }}\"\n  - \"{{ tmp_device_mapping }}\"\n\n- name: \"Move tmp_lvm_entries back to lvm_entries\"\n  set_fact:\n    lvm_entries: \"{{ tmp_lvm_entries }}\"\n"}, {"commit_sha": "c33f3410e002f9d8506f0725f56b7d7afa1c5f74", "sha": "9e6ddcacab08e32e53229f7860e41f184ad69236", "filename": "handlers/main.yml", "repository": "jloh/nagios-nrpe-server", "decoded_content": "---\n# Restart the Nagios NRPE Server\n# Since RedHat based OS's and Debian based ones call the service\n# different names, we use a variable set in vars/{{ ansible_os_family }}.yml\n\n- name: restart nagios-nrpe-server\n  service: name=\"{{ nagios_nrpe_server_service }}\" state=restarted\n"}, {"commit_sha": "6fada6f2a7515ab18178ae350168c3de147c4dd0", "sha": "5e4a4257d7118ad4ddea41a0227dc9ed646b3a44", "filename": "tasks/users.yml", "repository": "inkatze/wildfly", "decoded_content": "---\n# tasks file for wildfly\n\n# The user will always be overwritten every time a user and password is given.\n- name: Create management user\n  command: >\n    {{ wildfly_dir }}/bin/add-user.sh\n    {{ wildfly_management_user }} {{ wildfly_management_password }}\n  become_user: '{{ wildfly_user }}'\n  when: wildfly_management_user is defined and\n        wildfly_management_password is defined\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "01d2f1c23a0eff14da80c7009903a5d1f62ba319", "filename": "roles/config-lvm/tasks/prep.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Install required packages'\n  package:\n    name: '{{ item }}'\n    state: installed\n  with_items:\n  - lvm2\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "8818ce01993d876a026d94d0c6f10ed183caeac7", "filename": "roles/config-routes/tasks/prereq-Fedora.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Install additional packages needed to process tasks\"\n  package:\n    name: \"{{ item }}\"\n    state: latest\n  with_items:\n  - libselinux-python\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "123c87b4237cfcdb1fd6bf973406994273405da8", "filename": "roles/dnsmasq/tasks/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# tasks file for dnsmasq\n- name: create dnsmasq config directory\n  file:\n    path: \"/etc/dnsmasq.d\"\n    state: directory\n    mode: 0755\n  sudo: yes\n  tags:\n    - dnsmasq\n\n- name: configure consul resolution dnsmasq\n  sudo: yes\n  template:\n    src: 10-consul.j2\n    dest: /etc/dnsmasq.d/10-consul\n    owner: root\n    group: root\n    mode: 0644\n  notify:\n    - restart dnsmasq\n  tags:\n    - dnsmasq\n\n# This should be using -cap-add=NET_ADMIN rather than privileged: true.\n# This will be supported in Ansible 2.0\n- name: run dnsmasq container\n  docker:\n    name: dnsmasq\n    image: \"andyshinn/dnsmasq\"\n    state: started\n    net: \"host\"\n    privileged: true\n    volumes:\n    - \"{{ dnsmasq_config_folder }}/:{{ dnsmasq_config_folder }}/\"\n    ports:\n    - \"53:53/tcp\"\n    - \"53:53/udp\"\n    command: \"-r {{ dnsmasq_resolvconf_file }} --conf-dir={{ dnsmasq_config_folder }}\"\n\n- name: upload dnsmasq template service\n  template:\n    src: dnsmasq.conf.j2\n    dest: /etc/init/dnsmasq.conf\n    mode: 0755\n  sudo: yes\n  tags:\n    - dnsmasq\n\n- name: ensure dnsmasq is running (and enable it at boot)\n  service:\n    name: dnsmasq\n    state: started\n    enabled: yes\n  tags:\n    - dnsmasq\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "a31941bae05205dc3d3f948fe23a3514ba8c7c64", "filename": "roles/proxy/handlers/main.yml", "repository": "trailofbits/algo", "decoded_content": "- name: restart privoxy\n  service: name=privoxy state=restarted\n\n- name: daemon-reload\n  shell: systemctl daemon-reload\n\n- name: restart apparmor\n  service: name=apparmor state=restarted\n\n- name: restart apache2\n  service: name=apache2 state=restarted\n\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "d16a11848fb570f49d34d223b685de56d727fe73", "filename": "roles/dcos_cli/tasks/apps.yml", "repository": "Capgemini/Apollo", "decoded_content": "- include_vars: \"{{ item }}.yml\"\n  with_items:\n    - \"{{ dcos_cli_apps_list }}\"\n\n# Create the JSON files for apps\n- name: create json files for apps\n  when: \"dcos_cli_app_{{ item }}_enabled | bool\"\n  run_once: true\n  template:\n    src: '{{ item }}.json.j2'\n    dest: \"/etc/marathon/{{ item }}.json\"\n    mode: 0755\n  sudo: yes\n  tags:\n    - \"{{ item }}\"\n    - dcos_cli\n  with_items:\n    - \"{{ dcos_cli_apps_list }}\"\n\n- name: add marathon app via dcos-cli\n  when: \"dcos_cli_app_{{ item }}_enabled | bool\"\n  run_once: true\n  docker:\n    name: \"{{ item }}\"\n    image: \"{{ dcos_cli_image }}\"\n    state: started\n    command: \"marathon app add /config/{{ item }}.json\"\n    volumes:\n    - \"/etc/marathon:/config\"\n    env:\n      MESOS_MASTER_URL: \"{{ dcos_cli_mesos_master_url }}\"\n      MARATHON_URL: \"{{ dcos_cli_marathon_url }}\"\n      SOURCES: \"{{ dcos_cli_sources }}\"\n  tags:\n    - \"{{ item }}\"\n    - dcos_cli\n  with_items:\n    - \"{{ dcos_cli_apps_list }}\"\n\n\n- name: remove marathon app via dcos-cli\n  when: \"not dcos_cli_app_{{ item }}_enabled | bool\"\n  run_once: true\n  docker:\n    name: \"{{ item }}\"\n    image: \"{{ dcos_cli_image }}\"\n    state: started\n    command: \"marathon app remove {{ item }}\"\n    env:\n      MESOS_MASTER_URL: \"{{ dcos_cli_mesos_master_url }}\"\n      MARATHON_URL: \"{{ dcos_cli_marathon_url }}\"\n  tags:\n    - \"{{ item }}\"\n    - dcos_cli\n  with_items:\n    - \"{{ dcos_cli_apps_list }}\"\n"}, {"commit_sha": "f9f7be7b0d9c533af2362caa235ef37e3adec09b", "sha": "ef71a470ae1fc9dde29c23d7cc33f57b64f837e5", "filename": "roles/proxy/meta/main.yml", "repository": "trailofbits/algo", "decoded_content": "---\n\ndependencies:\n  - { role: common, tags: common }\n  - { role: vpn,  tags: vpn }\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "6c9787a162ebd802d7272c5a0d1c66f83594ea79", "filename": "roles/config-redis/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nmode: containerized\n\nredis_name: redis\nredis_service: \"{{ redis_name }}.service\"\n\n# Redis\nredis_image: quay.io/quay/redis:latest\nredis_storage_dir: /var/lib/redis\nredis_container_storage_dir: /var/lib/redis\nredis_container_port: 6379\nredis_host_port: 6379\n\n#Systemd\nsystemd_service_dir: /usr/lib/systemd/system\nsystemd_environmentfile_dir: /etc/sysconfig\n\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "c22bd729f53cef2b745fac338fd2cfbdeaf1f454", "filename": "tasks/controller/setup-debian.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: Debian/Ubuntu) Add NGINX Controller Agent Repository\"\n  apt_repository:\n    filename: nginx-controller\n    repo: deb http://packages.nginx.org/controller/{{ ansible_distribution | lower }}/ {{ ansible_distribution_release | lower }} controller\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "4df7f37ff6b557d59d58d802bdc59742415a76ce", "filename": "roles/5-xo-services/meta/main.yml", "repository": "iiab/iiab", "decoded_content": "dependencies:\n   - { role: ejabberd_xs, tags: ['olpc','ejabberd-xs','xo-services'], when: ejabberd_xs_install }\n   - { role: idmgr,  tags: ['olpc','idmgr','xo-services'], when: idmgr_install }\n   - { role: activity-server, tags: ['olpc','activity-server','xo-services'], when: activity_server_install }\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "1de3befbc84290df92290365574eecfee8939b5d", "filename": "roles/dcos_cli/vars/chronos.yml", "repository": "Capgemini/Apollo", "decoded_content": "dcos_cli_framework_chronos_enabled: true\ndcos_cli_framework_chronos_mem: 512\ndcos_cli_framework_chronos_cpus: 0.5\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "d274bcb645c3d6d9859e0b2883aa0437094355e6", "filename": "roles/config-satellite/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: 'Configure Satellite'\n  hosts: satellite_servers\n  roles:\n  - role: config-satellite\n\n"}, {"commit_sha": "d7fbb1f61d1191166152acc249d0e910859619ca", "sha": "ed1532b4ca5a1698ce0e3262b0b0c78711acf156", "filename": "tasks/configure-docker.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Ensure /etc/docker directory exists\n  become: true\n  file:\n    path: /etc/docker\n    state: directory\n    mode: 0755\n\n- name: Configure Docker daemon (file)\n  become: true\n  copy:\n    src: \"{{ docker_daemon_config_file }}\"\n    dest: /etc/docker/daemon.json\n  notify: restart docker\n  when: docker_daemon_config_file is defined\n\n- name: Configure Docker daemon (variables)\n  become: true\n  copy:\n    content: \"{{ docker_daemon_config | to_nice_json }}\"\n    dest: /etc/docker/daemon.json\n  notify: restart docker\n  when: docker_daemon_config_file is not defined and\n        docker_daemon_config is defined\n\n- name: Ensure Docker default user namespace is defined in subuid and subgid\n  become: true\n  lineinfile:\n    path: \"{{ item }}\"\n    regexp: '^dockremap'\n    line: 'dockremap:500000:65536'\n  with_items:\n    - /etc/subuid\n    - /etc/subgid\n  when: (_docker_os_dist == \"CentOS\" or _docker_os_dist == \"RedHat\") and\n        ((docker_daemon_config is defined and\n        docker_daemon_config['userns-remap'] is defined and\n        docker_daemon_config['userns-remap'] == 'default') or\n        docker_bug_usermod|bool == true)\n\n- name: Ensure thin-provisioning-tools is installed when devicemapper is used (Ubuntu)\n  become: true\n  package:\n    name: thin-provisioning-tools\n    state: present\n  when: (_docker_os_dist == \"Ubuntu\" or _docker_os_dist == \"Debian\") and\n        docker_daemon_config['storage-driver'] is defined and\n        docker_daemon_config['storage-driver'] == 'devicemapper'\n\n- name: Enable Docker service\n  become: true\n  service:\n    name: docker\n    enabled: yes\n  notify: restart docker\n  register: docker_service\n\n- name: Trigger start/restart of Docker\n  service:\n    name: docker\n  notify: restart docker\n  changed_when: docker_service.status.SubState != \"running\"\n  when: docker_service.status is defined\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "9767b6ff698614550eeb525ad114e62e1849ecb6", "filename": "roles/activity-server/files/www.0/index.html.ht", "repository": "iiab/iiab", "decoded_content": "<!DOCTYPE html>\n<META http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n<body>\n<h1 id=\"olpc-activity-group-name\">Aktivite ki disponib nan Bwat la</h1>\n<p id=\"olpc-activity-group-desc\">Aktivite sa yo disponib sou sit lek\u00f2l la.</p>\n<div class=\"olpc-activity-info\">\nGen kounye a pa gen okenn aktivite. Antre yon USB ak aktivite sou li ajoute k\u00e8k.\n</div>\n\n</body>\n</html>\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "8466ea772fb927884158891d7be351a8f8f754e6", "filename": "roles/update-host/tasks/reboot-host.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Reboot the host\"\n  shell: sleep 5 && shutdown -r now \"Ansible Reboot of host\"\n  async: 1\n  poll: 0\n  ignore_errors: true\n  when:\n    - host_updated.changed or force_host_reboot\n  become: True\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a7e97f542ba5fb877267225d00bcab9798aa0174", "filename": "roles/osp/admin-user/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Create the User Accounts\"\n  os_user:\n    cloud: \"{{ item.cloud | default(osp_default_cloud) | default(omit) }}\"\n    domain: \"{{ item.domain }}\"\n    password: \"{{ item.password }}\"\n    name: \"{{ item.name }}\"\n  with_items:\n  - \"{{ osp_users | default([]) }}\"\n  \n- name: \"Grant access to accounts\"\n  include_tasks: \"roles.yml\"\n  with_items:\n  - \"{{ osp_users | default([]) }}\"\n  loop_control:\n    loop_var: role\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a32b4b9b82a3f288c6344e032fa59feb74384963", "filename": "roles/osp/admin-project/tasks/tenant-roles.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Assign role for project {{ project.name }}\"\n  shell: >\n    source {{ admin_keystonerc_file }};\n    openstack role add \\\n      --user \"{{ item.0.user }}\" \\\n      --user-domain \"{{ item.0.user_domain | default('') }}\" \\\n      --project \"{{ project.name }}\" \\\n      \"{{ item.1 }}\"\n  with_subelements:\n  - \"{{ project.members }}\"\n  - roles\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a8a921d34423a8ed960ca1b4c04c4e3cef3f7b33", "filename": "roles/dns/manage-dns-zones-bind/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\nnamed_processing: false\n\ndefault_ttl: 300\n\nbind_user: named\nbind_group: named\n\ndefault_recursion: false\ndefault_dnssec_keygen_size: 256\ndefault_dnssec_keygen_algorithm: HMAC-SHA256\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "0323d5634372dafc7b9c7c468c4f2745d06bc651", "filename": "tasks/keys/rpm-key.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: RPM OSs) Set Default RPM NGINX Signing Key\"\n  set_fact:\n    default_keysite: >-\n      {{ (ansible_distribution_major_version|int == 6)\n      | ternary('http://nginx.org/keys/nginx_signing.key', 'https://nginx.org/keys/nginx_signing.key') }}\n\n- name: \"(Install: RPM OSs) Set RPM NGINX Signing Key URL\"\n  set_fact:\n    keysite: \"{{ nginx_signing_key | default(default_keysite) }}\"\n\n- name: \"(Install: RPM OSs) Add RPM NGINX Signing Key\"\n  rpm_key:\n    key: \"{{ keysite }}\"\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "0beb5221b779361b35dbb0925b17fa6876e5ec7c", "filename": "tasks/section_01.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - include: section_01_level1.yml\n    tags:\n      - section01\n      - level1\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "dc9672c67beafbcf8320a842e5b367202fa36718", "filename": "roles/1-prep/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Determine if runansible was run\n  stat: path=/etc/iiab/iiab.env\n  register: NewInstall\n\n- name: Setting first run flag\n  set_fact:\n    first_run: True\n  when: NewInstall.stat.exists is defined and not NewInstall.stat.exists\n\n# we need to inialize the ini file\n- include: iiab_ini.yml\n  when: first_run\n\n- name: Set flag for fedora 18\n  set_fact:\n    is_F18: True\n  when: ansible_distribution_release == \"based on Fedora 18\" or ansible_distribution_version == \"18\"\n\n- name: get the uuidgen program\n  package: name=uuid-runtime\n           state=present\n  when: is_debuntu\n\n- name: Test for UUID file\n  stat: path=/etc/iiab/uuid\n  register: uuid_file\n\n- name: Create folder to hold uuid\n  file: path=/etc/iiab state=directory\n  when: not uuid_file.stat.exists\n\n- name: If no uuid exists, create one\n  shell: uuidgen\n  register: uuid_response\n  when: not uuid_file.stat.exists\n\n- name: Put the uuid in place\n  shell: echo {{ uuid_response.stdout_lines[0] }} > /etc/iiab/uuid\n  when: not uuid_file.stat.exists\n\n- name: get the uuid\n  command: cat /etc/iiab/uuid\n  register: stored_uuid\n\n- name: get the value into a variable\n  set_fact:\n      uuid={{ stored_uuid.stdout_lines[0] }}\n\n# for rpi, without rtc, we need time as soon as possible\n- name: Install chrony package\n  package: name={{ item }}\n           state=present\n  with_items:\n   - chrony\n  tags:\n    - download\n\n#TODO: Use regexp filter instead of hard-code ip\n- name: Update chrony config file\n  template: backup=no\n            dest=/etc/chrony.conf\n            src=chrony.conf.j2\n\n- name: Disable apparmor -- on by default in ubuntu\n  service: name=apparmor enabled=False state=stopped\n  when: first_run and is_ubuntu\n  ignore_errors: true\n\n- name: Disable selinux on next boot\n  selinux: state=disabled\n  register: selinux_disabled\n  when: first_run and not is_debuntu\n\n- name: Disable selinux for this session (if needed)\n  command: setenforce Permissive\n  when: not is_debuntu and selinux_disabled is defined and selinux_disabled.changed\n\n##  DISCOVER PLATFORMS ######\n- name: Discover if this is a rpi -- assume if so it is running raspbian\n  set_fact:\n     rpi_model: \"rpi\"\n     is_rpi: \"True\"\n  when:   ansible_local.local_facts.os == \"raspbian\"\n  ignore_errors: true\n\n- include: prep.yml\n\n- include: computed_vars.yml\n\n- include: detected_network.yml\n  when: not installing\n\n# Put conditional actions for hardware platforms here\n- include: raspberry_pi_2.yml\n  when: first_run and rpi_model != \"none\"\n\n- name: Check if the identifier for intel's NUC6 builtin wifi is present\n  shell: \"lsusb | grep 8087:0a2b | wc |awk '{print $1}'\"\n  register: usb_NUC6\n  ignore_errors: true\n  when: first_run\n\n- name: download the firmware for built in wifi on NUC6\n  get_url: dest=/lib/firmware\n           url={{ iiab_download_url }}/iwlwifi-8000C-13.ucode\n  when: first_run and usb_NUC6.stdout|int > 0\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "f86d55058107079340968c279efe2aed269e71d5", "filename": "roles/config-iscsi-client/tests/host_vars/node-1.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\niscsi_initiatorname: iqn.1994-05.com.example:node-1\n\ndisk_mapping:\n- lun: 0\n  vg: vg0\n  lv: lv0\n  mount_path: /mnt/vg0-lv0\n- lun: 1\n  vg: vg1\n  lv: lv0\n  mount_path: /var/vg1-lv0\n- lun: 2\n  vg: vg2\n"}, {"commit_sha": "abafe1581c6c78d784cf215b214947675d49eff8", "sha": "d84a6eb0d0e2c32b47795dc5926992b615b1c524", "filename": "playbooks/common.yml", "repository": "trailofbits/algo", "decoded_content": "- name: Install prerequisites\n  raw: sudo apt-get update -qq && sudo apt-get install -qq -y python2.7\n\n- name: Configure defaults\n  raw: sudo update-alternatives --install /usr/bin/python python /usr/bin/python2.7 1\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "c907de0762108dc779c7fbf7eca05ef5d95456da", "filename": "tasks/Linux/install/RedHat_adoptopenjdk.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Add repository for AdoptOpenJDK\n  yum_repository:\n    name: AdoptOpenJDK\n    description: AdoptOpenJDK\n    baseurl: http://adoptopenjdk.jfrog.io/adoptopenjdk/rpm/centos/7/x86_64\n    enabled: true\n    gpgcheck: true\n    gpgkey: https://adoptopenjdk.jfrog.io/adoptopenjdk/api/gpg/key/public\n\n- name: Install java packages\n  yum:\n    name: '{{ (transport == \"repositories\") | ternary(jdk_package, java_artifact) }}'\n    state: present\n  register: package_install\n  until: package_install is succeeded\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "796f3e4a714a4d5bef2a8f0b4c262c26d82ca45d", "filename": "playbooks/files/GeoIP.conf", "repository": "rocknsm/rock", "decoded_content": "# If you purchase a subscription to the GeoIP database,\n# then you will obtain a license key which you can\n# use to automatically obtain updates.\n# for more details, please go to\n# http://www.maxmind.com/en/geolocation_landing\n\n# HowTo configure geoipupdate\n# http://www.maxmind.com/en/license_key\n\n# customer find the user_id and license key here:\n# https://www.maxmind.com/en/my_license_key\n#\n# UserId, and available ProductIds\n\n# Enter your license key here\n# customers should insert their license key and user_id\n# free GeoLite users should use 000000000000 as license key\nLicenseKey 000000000000\n\n# Enter your User ID here ( GeoLite only users should use 999999 as user_id )\nUserId 999999\n\n# Enter the Product ID(s) of the database(s) you would like to update\n# By default 106 (MaxMind GeoIP Country) is listed below\nProductIds GeoLite-Legacy-IPv6-City GeoLite-Legacy-IPv6-Country 506 517 533\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "214aa619ba139832e259f7d195d518226f2f049f", "filename": "roles/samba/README.rst", "repository": "iiab/iiab", "decoded_content": "Publicly Available Windows Storage\n==================================\nThe school server will advertise a shared \"public\" folder available to all windows machines.\n\nThe permissions are set as follows:\n- Users may read and write to the \"public\" shared folder.\n- The are forced to store their files as a user who has no ability to log on to the server.\n- The user, with no ability to log on, has a password which is very difficult to guess \"verylong%and$hard^to@guess\"\n"}, {"commit_sha": "bc7af5efcd2c8565acee0dc5948c8b752f6c8990", "sha": "336b70faf9f07c24d4ce03b54b0822786ba0a582", "filename": "tasks/section_06_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n  - name: 6.1 Ensure the X Window system is not installed (Scored)\n    apt: name=xserver-xorg-core* purge=yes state=absent\n    when: remove_xserver == True\n    tags:\n      - section6\n      - section6.1\n\n  - name: 6.2 Ensure Avahi Server is not enabled (check) (Scored)\n    stat: path='/etc/init/avahi-daemon.conf'\n    register: avahi_stat\n    tags:\n      - section6\n      - section6.2\n\n  - name: 6.2 Ensure Avahi Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on (filesystem'\n        state=present\n        regexp='start on \\(filesystem'\n        dest=/etc/init/avahi-daemon.conf\n    when: avahi_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.2\n\n  - name: 6.3 Ensure print server is not enabled (check) (Not Scored)\n    stat: path='/etc/init/cups.conf'\n    register: cups_stat\n    tags:\n      - section6\n      - section6.3\n\n  - name: 6.3 Ensure print server is not enabled (Not Scored)\n    lineinfile: >\n        line='#start on (filesystem'\n        state=present\n        regexp='start on \\(filesystem'\n        dest=/etc/init/cups.conf\n    when: cups_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.3\n\n  - name: 6.4.1 Ensure DHCP Server is not enabled (check) (Scored)\n    stat: path='/etc/init/isc-dhcp-server.conf'\n    register: dhcp_stat\n    tags:\n      - section6\n      - section6.4\n      - section6.4.1\n\n  - name: 6.4.1 Ensure DHCP Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n        dest=/etc/init/isc-dhcp-server.conf\n    when: dhcp_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.4\n      - section6.4.1\n\n  - name: 6.4.2 Ensure DHCP Server is not enabled (check) (Scored)\n    stat: path='/etc/init/isc-dhcp-server6.conf'\n    register: dhcp6_stat\n    tags:\n      - section6\n      - section6.4\n      - section6.4.2\n\n  - name: 6.4.2 Ensure DHCP Server is not enabled (Scored)\n    lineinfile: >\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n        dest=/etc/init/isc-dhcp-server6.conf\n    when: dhcp6_stat.stat.exists == True\n    tags:\n      - section6\n      - section6.4\n      - section6.4.2\n\n  - name: 6.5.1 Configure Network Time Protocol (install) (NTP) (Scored)\n    apt: name=ntp state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.1\n\n  - name: 6.5.2 Configure Network Time Protocol (restrict4) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='restrict -4 default kod nomodify notrap nopeer noquery'\n        regexp='^restrict -4 default'\n        state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.2\n\n  - name: 6.5.3 Configure Network Time Protocol (restrict6) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='restrict -6 default kod nomodify notrap nopeer noquery'\n        regexp='^restrict -6 default'\n        state=present\n    tags:\n      - section6\n      - section6.5\n      - section6.5.3\n\n  - name: 6.5.4 Configure Network Time Protocol (server check) (NTP) (Scored)\n    command: 'grep \"^server\" /etc/ntp.conf'\n    register: ntp_server_rc\n    changed_when: False\n    always_run: True\n    tags:\n      - section6\n      - section6.5\n      - section6.5.4\n\n  - name: 6.5.4 Configure Network Time Protocol (server add) (NTP) (Scored)\n    lineinfile: >\n        dest='/etc/ntp.conf'\n        line='server 0.fr.pool.ntp.org'\n        state=present\n    when: ntp_server_rc.rc == 1\n    tags:\n      - section6\n      - section6.5\n      - section6.5.4\n\n  - name: 6.6 Ensure LDAP is not enabled (Not Scored)\n    apt: name=slapd purge=yes state=absent\n    tags:\n      - section6\n      - section6.6\n\n  - name: 6.7.1 Ensure NFS and RPC are not enabled (stat) (Not Scored)\n    stat: path=/etc/init/rpcbind-boot.conf\n    register: nfs_rpc_rc\n    tags:\n      - section6\n      - section6.7\n      - section6.7.1\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (Not Scored)\n    lineinfile: >\n        dest=/etc/init/rpcbind-boot.conf\n        line='#start on virtual-filesystems and net-device-up IFACE=lo'\n        state=present\n        regexp='start on virtual-filesystems and net'\n    when: nfs_rpc_rc.stat.exists == True\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (check) (Not Scored)\n    command: dpkg -S nfs-kernel-server\n    changed_when: False\n    failed_when: False\n    register: nfs_present\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.7.2 Ensure NFS and RPC are not enabled (rc.d) (Not Scored)\n    service: >\n        name=nfs-kernel-server\n        enabled=no\n    when: nfs_present.rc == 0\n    register: nfs_service_result\n    failed_when: \"nfs_service_result|failed and 'service not found' not in nfs_service_result.msg\"\n    tags:\n      - section6\n      - section6.7\n      - section6.7.2\n\n  - name: 6.8-14 Ensure DNS,FTP,HTTP,IMAP,POP,Samba,Proxy,SNMP Servers are not enabled (Not Scored)\n    service: >\n        name={{ item }}\n        enabled=no\n    with_items:\n      - bind9\n      - vsftpd\n      - apache2\n      - dovecot\n      - smbd\n      - squid3\n      - snmpd\n    failed_when: False\n    tags:\n      - section6\n      - section6.8\n      - section6.9\n      - section6.10\n      - section6.11\n      - section6.12\n      - section6.13\n      - section6.14\n\n  - name: 6.15 Configure Mail Transfer Agent for Local-Only Mode (stat) (Scored)\n    stat: path=/etc/postfix/main.cf\n    register: postfix_main_cf\n    tags:\n      - section6\n      - section6.15\n\n  - name: 6.15 Configure Mail Transfer Agent for Local-Only Mode (Scored)\n    lineinfile: >\n        dest=/etc/postfix/main.cf\n        line='inet_interfaces = localhost'\n        state=present\n    when: postfix_main_cf.stat.exists == True\n    tags:\n      - section6\n      - section6.15\n\n  - name: 6.16 Ensure rsync service is not enabled (stat) (Scored)\n    stat: path=/etc/default/rsync\n    register: default_rsync\n    tags:\n      - section6\n      - section6.16\n\n  - name: 6.16 Ensure rsync service is not enabled (Scored)\n    lineinfile: >\n        dest='/etc/default/rsync'\n        regexp='^RSYNC_ENABLE'\n        line='RSYNC_ENABLE=false'\n    when: default_rsync.stat.exists == True\n    tags:\n      - section6\n      - section6.16\n\n  - name: 6.17 Ensure Biosdevname is not enabled (Scored)\n    apt: name=biosdevname purge=yes state=absent\n    tags:\n      - section6\n      - section6.17\n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "9d082d70baa502a662d980269766143e7b2b73cc", "filename": "tasks/Win32NT/fetch/adoptopenjdk-fallback.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Fetch download page\n  win_uri:\n    url: \"{{ adoptopenjdk_api_page }}\\\n      info/releases/\\\n      openjdk{{ java_major_version }}\\\n      ?openjdk_impl={{ adoptopenjdk_impl }}\\\n      &os=windows&\\\n      arch={{ (java_arch == 'x64') | ternary('x64', 'x32') }}\\\n      &release=latest\\\n      &type={{ java_package }}&heap_size=normal\"\n    return_content: true\n    follow_redirects: all\n  register: download_page\n\n- name: Find release url\n  set_fact:\n    release_url: >-\n      {{ (download_page.content | from_json).binaries | map(attribute='binary_link') | list +\n        (download_page.content | from_json).binaries | map(attribute='checksum_link') | list }}\n\n- name: Exit if AdobtOpenJDK version is not found\n  fail:\n    msg: 'AdoptOpenJDK version {{ java_major_version }} not found'\n  when: release_url[0] is not defined\n\n- name: 'Fetch artifact checksum file {{ release_url[1] }}'\n  win_uri:\n    url: '{{ release_url[1] }}'\n    return_content: true\n  register: artifact_checksum_file\n\n- name: 'Get artifact checksum from file {{ release_url[1] }}'\n  set_fact:\n    artifact_checksum:\n      content: >-\n        {{ artifact_checksum_file['content'] |\n          regex_search('([^\\s]+)')\n        }}\n\n- name: 'Download artifact from {{ release_url[0] }}'\n  win_get_url:\n    url: '{{ release_url[0] }}'\n    dest: '{{ java_download_path }}'\n    force: true\n    checksum: '{{ artifact_checksum.content }}'\n    checksum_algorithm: sha256\n  register: file_downloaded\n  retries: 20\n  delay: 5\n  until: file_downloaded is succeeded\n  when: ansible_version.full is version('2.8.0', '>=')\n\n- name: Old fetch (Ansible < 2.8)\n  include_tasks: fetch_fallback_old.yml\n  when: ansible_version.full is version('2.8.0', '<')\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "a1bad8d0caba92e9669f9e4262b4a045253a1f64", "filename": "roles/dhcp/tasks/dhcp.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: 'Copy the dhcp config file to a temp location for validity checking'\n  copy:\n    src: '{{ dhcp_config_dir.path }}/{{ dhcp_config_temp_file }}'\n    dest: '{{ dhcp_config_temp_loc }}'\n  notify: 'cleanup dhcp tmp file'\n\n- name: ' Check the Validity of dhcp.conf file'\n  command: 'dhcpd -t -cf {{ dhcp_config_temp_loc }}'\n\n- name: 'Copy and activate the dhcp config file'\n  copy:\n    remote_src: true\n    src: '{{ dhcp_config_temp_loc }}'\n    dest: '{{ dhcp_config_dest_file }}'\n  notify: 'reload dhcp'\n\n- name: 'Disable dhcp services'\n  service:\n    name: '{{ item }}'\n    enabled: no\n    state: stopped\n  with_items:\n  - dhcpd\n  when: \n  - dhcp_service_enabled|default(True) == False\n\n- name: 'Enable dhcp services'\n  service:\n    name: '{{ item }}'\n    enabled: yes\n    state: started\n  with_items:\n  - dhcpd\n  when: \n  - dhcp_service_enabled|default(True) \n"}, {"commit_sha": "8b0d4eaa526ee1231a5095a821690258693a628b", "sha": "1fd66adb70cf8bd555eeb9a24017c56ca80d83fa", "filename": "tasks/Win32NT/finalize_paths.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Find java_folder\n  win_find:\n    paths: '{{ java_path }}'\n    recurse: false\n    file_type: directory\n    patterns: '{{ java_folder }}'\n    use_regex: true\n  register: java_dir\n\n- name: Set actual java directory\n  set_fact:\n    java_act_path: \"{{ java_dir.files | map(attribute='path') | list | last }}\"\n\n- name: Set java environment variable\n  win_environment:\n    name: JAVA_HOME\n    state: present\n    value: '{{ java_act_path }}'\n    level: machine\n\n- name: Ensure that 'JAVA_HOME\\bin' present in 'Path' variable\n  win_path:\n    elements: '{{ java_act_path }}\\bin'\n    state: present\n    scope: machine\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "bb1bfe6b28adacba44ff9ebb5a8ee0b124b39824", "filename": "roles/config-quay-enterprise/defaults/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# Base Configurations\nquay_name: quay\nquay_service: \"{{ quay_name }}.service\"\nquay_server_hostname:\nquay_database_type: postgresql\n\n#Systemd\nsystemd_service_dir: /usr/lib/systemd/system\nsystemd_environmentfile_dir: /etc/sysconfig\n\n# Quay\nquay_image: quay.io/coreos/quay:v2.9.2\nquay_config_dir: /var/lib/quay/config\nquay_container_config_dir: /conf/stack\nquay_storage_dir: /var/lib/quay/storage\nquay_container_storage_dir: /datastorage\nquay_storage_selinux_relabel: True\n\n# External Databases\npostgresql_db_uri: \"postgresql://{{ quay_database_username }}:{{ quay_database_password }}@{{ quay_database_host }}:{{ quay_database_port | default('5432') }}/{{ quay_database_name }}\"\nmysql_db_uri: \"mysql+pymysql://{{ quay_database_username }}:{{ quay_database_password }}@{{ quay_database_host }}:{{ quay_database_port | default('3306') }}/{{ quay_database_name }}\"\n\n# Container Credentials\ncontainer_credentials_file: /root/.docker/config.json\ncontainer_credentials_file_content: {}\nquay_registry_server: quay.io\nquay_registry_auth:\nquay_registry_email:\n\n# Port Configurations\nquay_host_http_port: 80\nquay_container_http_port: 80\nquay_host_https_port: 443\nquay_container_https_port: 443\n\n# SSL\nquay_ssl_enable: True\nquay_ssl_key_file: \"\"\nquay_ssl_cert_file: \"\"\nquay_ssl_generate_city: Raleigh\nquay_ssl_generate_state: NC\nquay_ssl_generate_country: US\nquay_ssl_generate_organization: Red Hat\nquay_ssl_generate_organizational_unit: CoP\nquay_ssl_generate_days_validity: 365\nquay_ssl_local_tmp_dir: \"/tmp\"\nquay_ssl_delete_generated_cert: True\n\n# Clair\nquay_clair_enable: False\nquay_clair_endpoint: \"\"\n\n# Builder\nquay_builder_enable: False\n\n# Superuser Configuration\nquay_superuser_username: \"\"\nquay_superuser_password: \"\"\nquay_superuser_email: \"\""}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "281b0de28309330f7149647a6e9993d9275fc2c5", "filename": "playbooks/manage-confluence-space.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Clone confluence space\n  hosts: localhost\n  roles:\n  - manage-confluence-space\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "2c63f89e046da8ccf88d395c252040202f539c30", "filename": "roles/config-hostname/tests/test.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- hosts: my-host\n  roles:\n  - role: config-hostname \n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "004bf470febd0a8affea8318111da01bae058ed2", "filename": "roles/8-mgmt-tools/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Assessment and Monitoring Tools Installed\n  command: echo Assessment and Monitoring Tools Installed\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "7c6994bd753f4f07473c9b9c2c2cacb6c0e0175e", "filename": "roles/config-minishift-remote/tasks/minishift_configure_start.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# Download Binary\n- include_tasks: minishift_download.yml\n  when: download_minishift|bool\n\n- name: Build Minishift Start command\n  set_fact:\n    minishift_start_cmd: \"start --vm-driver generic --remote-ipaddress {{ minishift_host_ip }} --remote-ssh-user={{ ansible_user }} --remote-ssh-key={{ ansible_ssh_private_key_file | default('~/.ssh/id_rsa') | expanduser }} {{ minishift_extra_start_args }}\"\n  delegate_to: localhost\n\n- name: Get Name of Current User\n  set_fact:\n    minishift_local_user: \"{{ lookup('pipe','id -u -n') }}\"\n  delegate_to: localhost\n\n- name: Start Minishift\n  shell: >\n    \"{{ minishift_binary }}\" {{ minishift_start_cmd }}\n  environment:\n    USER: \"{{ minishift_local_user }}\"\n  delegate_to: localhost"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "ffed8ab8db6b09335e308b8d6ff492e3bfde7f07", "filename": "roles/httpd/templates/iiab-http", "repository": "iiab/iiab", "decoded_content": "apache ALL=NOPASSWD: /usr/sbin/iptables-save,/usr/sbin/fdisk,/usr/bin/xs-flashbench,/usr/bin/xs-acpowergaps,/root/xs-apply-changes,/usr/bin/xs-regenerate-activities,/bin/mount,/bin/ls,/bin/df,/bin/cat,/bin/systemctl\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "d675d4d509b880f5150d5ce49a7d1e5ff578d908", "filename": "roles/fail2ban/handlers/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: restart fail2ban\n  service: name=fail2ban state=restarted"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "8fbbb656b25f0884593893c4fabb03d87a21427d", "filename": "roles/network/templates/named/named.root", "repository": "iiab/iiab", "decoded_content": ";       This file holds the information on root name servers needed to\n;       initialize cache of Internet domain name servers\n;       (e.g. reference this file in the \"cache  .  <file>\"\n;       configuration file of BIND domain name servers).\n;\n;       This file is made available by InterNIC \n;       under anonymous FTP as\n;           file                /domain/named.cache\n;           on server           FTP.INTERNIC.NET\n;       -OR-                    RS.INTERNIC.NET\n;\n;       last update:    Jun 8, 2011\n;       related version of root zone:   2011060800\n;\n; formerly NS.INTERNIC.NET\n;\n.                        3600000  IN  NS    A.ROOT-SERVERS.NET.\nA.ROOT-SERVERS.NET.      3600000      A     198.41.0.4\nA.ROOT-SERVERS.NET.      3600000      AAAA  2001:503:BA3E::2:30\n;\n; FORMERLY NS1.ISI.EDU\n;\n.                        3600000      NS    B.ROOT-SERVERS.NET.\nB.ROOT-SERVERS.NET.      3600000      A     192.228.79.201\n;\n; FORMERLY C.PSI.NET\n;\n.                        3600000      NS    C.ROOT-SERVERS.NET.\nC.ROOT-SERVERS.NET.      3600000      A     192.33.4.12\n;\n; FORMERLY TERP.UMD.EDU\n;\n.                        3600000      NS    D.ROOT-SERVERS.NET.\nD.ROOT-SERVERS.NET.      3600000      A     128.8.10.90\nD.ROOT-SERVERS.NET.\t 3600000      AAAA  2001:500:2D::D\n;\n; FORMERLY NS.NASA.GOV\n;\n.                        3600000      NS    E.ROOT-SERVERS.NET.\nE.ROOT-SERVERS.NET.      3600000      A     192.203.230.10\n;\n; FORMERLY NS.ISC.ORG\n;\n.                        3600000      NS    F.ROOT-SERVERS.NET.\nF.ROOT-SERVERS.NET.      3600000      A     192.5.5.241\nF.ROOT-SERVERS.NET.      3600000      AAAA  2001:500:2F::F\n;\n; FORMERLY NS.NIC.DDN.MIL\n;\n.                        3600000      NS    G.ROOT-SERVERS.NET.\nG.ROOT-SERVERS.NET.      3600000      A     192.112.36.4\n;\n; FORMERLY AOS.ARL.ARMY.MIL\n;\n.                        3600000      NS    H.ROOT-SERVERS.NET.\nH.ROOT-SERVERS.NET.      3600000      A     128.63.2.53\nH.ROOT-SERVERS.NET.      3600000      AAAA  2001:500:1::803F:235\n;\n; FORMERLY NIC.NORDU.NET\n;\n.                        3600000      NS    I.ROOT-SERVERS.NET.\nI.ROOT-SERVERS.NET.      3600000      A     192.36.148.17\nI.ROOT-SERVERS.NET.      3600000      AAAA  2001:7FE::53\n;\n; OPERATED BY VERISIGN, INC.\n;\n.                        3600000      NS    J.ROOT-SERVERS.NET.\nJ.ROOT-SERVERS.NET.      3600000      A     192.58.128.30\nJ.ROOT-SERVERS.NET.      3600000      AAAA  2001:503:C27::2:30\n;\n; OPERATED BY RIPE NCC\n;\n.                        3600000      NS    K.ROOT-SERVERS.NET.\nK.ROOT-SERVERS.NET.      3600000      A     193.0.14.129\nK.ROOT-SERVERS.NET.      3600000      AAAA  2001:7FD::1\n;\n; OPERATED BY ICANN\n;\n.                        3600000      NS    L.ROOT-SERVERS.NET.\nL.ROOT-SERVERS.NET.      3600000      A     199.7.83.42\nL.ROOT-SERVERS.NET.      3600000      AAAA  2001:500:3::42\n;\n; OPERATED BY WIDE\n;\n.                        3600000      NS    M.ROOT-SERVERS.NET.\nM.ROOT-SERVERS.NET.      3600000      A     202.12.27.33\nM.ROOT-SERVERS.NET.      3600000      AAAA  2001:DC3::35\n; End of File\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "8b5349594d059fc146cfd48154753b7ebef22d04", "filename": "roles/osp/admin-sec-group/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Manage Security Groups\n  os_security_group:\n    cloud: \"{{ item.cloud | default(osp_default_cloud) | default(omit) }}\"\n    state: \"{{ item.state | default(osp_resource_state) | default('present') }}\"\n    name: \"{{ item.name }}\"\n    description: \"{{ item.description | default(omit) }}\"\n  with_items:\n  - \"{{ osp_security_groups | default([]) }}\"\n  register: security_groups\n\n- name: Create Security Group Rules\n  os_security_group_rule:\n    cloud: \"{{ item.cloud | default(osp_default_cloud) | default(omit) }}\"\n    security_group: \"{{ item.0.item.name }}\"\n    protocol: \"{{ item.1.protocol | default(omit) }}\"\n    port_range_min: \"{{ item.1.port_range_min | default(omit) }}\"\n    port_range_max: \"{{ item.1.port_range_max | default(omit) }}\"\n    direction: \"{{ item.1.direction | default(omit) }}\"\n    remote_ip_prefix: \"{{ item.1.remote_ip_prefix | default(omit) }}\"\n  with_subelements:\n  - \"{{ security_groups.results }}\"\n  - item.rules \n  when: \n  - item.0.invocation.module_args.state == 'present'\n\n"}, {"commit_sha": "57fec6b42f8e451d9354597dd1b1fbc8c833ad0d", "sha": "a43ac7a5878c988d4eb511406bcf03a78778ebcf", "filename": "tasks/setup-repository-CentOS.yml", "repository": "haxorof/ansible-role-docker-ce", "decoded_content": "---\n- name: Ensure packages are installed for repository setup\n  become: true\n  package:\n    name: \"{{ item }}\"\n    state: present\n  with_items:\n    - \"{{ docker_repository_related_packages[_docker_os_dist] }}\"\n  register: _pkg_result\n  until: _pkg_result is succeeded\n  when:\n    - docker_network_access\n    - _docker_os_dist == \"CentOS\" or _docker_os_dist == \"RedHat\"\n\n- name: Determine channels to be enabled and/or disabled\n  set_fact:\n    _docker_disable_channels: \"{{ docker_channels | difference(_docker_merged_channels) }}\"\n    _docker_enable_channels: \"{{ docker_channels | intersect(_docker_merged_channels) }}\"\n  vars:\n    _docker_mandatory_channel: []\n    _docker_merged_channels: \"{{ _docker_mandatory_channel }} + [ '{{ docker_channel }}' ]\"\n\n- name: Add Docker CE repository (Fedora/CentOS/RedHat)\n  become: true\n  get_url:\n    url: \"{{ docker_repository_url[_docker_os_dist] }}\"\n    dest: /etc/yum.repos.d/docker-ce.repo\n    mode: 0644\n  register: _docker_repo\n  until: _docker_repo is succeeded\n  when: \n    - docker_network_access\n    - _docker_os_dist == \"CentOS\" or\n      _docker_os_dist == \"Fedora\" or\n      _docker_os_dist == \"RedHat\"\n\n- name: Disable Docker CE repository channels (Fedora/CentOS/RedHat)\n  become: true\n  shell: \"{{ docker_cmd_enable_disable_edge_repo[_docker_os_dist] }}\"\n  args:\n    warn: false\n  with_items: \"{{ _docker_disable_channels }}\"\n  changed_when: false\n  vars:\n    _item_enabled: false\n  when: _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"Fedora\" or\n        _docker_os_dist == \"RedHat\"\n  tags:\n    - skip_ansible_lint\n\n- name: Enable Docker CE repository channels (Fedora/CentOS/RedHat)\n  become: true\n  shell: \"{{ docker_cmd_enable_disable_edge_repo[_docker_os_dist] }}\"\n  args:\n    warn: false\n  with_items: \"{{ _docker_enable_channels }}\"\n  changed_when: false\n  vars:\n    _item_enabled: true\n  when: _docker_os_dist == \"CentOS\" or\n        _docker_os_dist == \"Fedora\" or\n        _docker_os_dist == \"RedHat\"\n  tags:\n    - skip_ansible_lint"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "1db23cae665400bfc78dabe3d6cae780846873c8", "filename": "roles/network/templates/network/dhcpcd.conf", "repository": "iiab/iiab", "decoded_content": "# A sample configuration for dhcpcd.\n# See dhcpcd.conf(5) for details.\n\n# Allow users of this group to interact with dhcpcd via the control socket.\n#controlgroup wheel\n\n# Inform the DHCP server of our hostname for DDNS.\nhostname\n\n# Use the hardware address of the interface for the Client ID.\nclientid\n# or\n# Use the same DUID + IAID as set in DHCPv6 for DHCPv4 ClientID as per RFC4361.\n# Some non-RFC compliant DHCP servers do not reply with this set.\n# In this case, comment out duid and enable clientid above.\n#duid\n\n# Persist interface configuration when dhcpcd exits.\npersistent\n\n# Rapid commit support.\n# Safe to enable by default because it requires the equivalent option set\n# on the server to actually work.\noption rapid_commit\n\n# A list of options to request from the DHCP server.\noption domain_name_servers, domain_name, domain_search, host_name\noption classless_static_routes\n# Most distributions have NTP support.\noption ntp_servers\n# Respect the network MTU. This is applied to DHCP routes.\noption interface_mtu\n\n# A ServerID is required by RFC2131.\nrequire dhcp_server_identifier\n\n# Generate Stable Private IPv6 Addresses instead of hardware based ones\nslaac private\n\n# don't let dhcpcd mess with IIAB LAN\ndenyinterfaces br0 wlan0\n\n# Example static IP configuration:\n{% if gui_static_wan == true %}\ninterface {{ discovered_wan_iface }}\n# strange that dhcpcd does not have a netmask option -- hardcode it FIXME\nstatic ip_address={{ gui_static_wan_ip }}/24\nstatic routers={{ gui_static_wan_gateway }}\ndomain_name_servers= {{ gui_static_wan_nameserver }}\n{% endif %}\n\n# It is possible to fall back to a static IP if DHCP fails:\n# define static profile\n#profile static_eth0\n#static ip_address=192.168.1.23/24\n#static routers=192.168.1.1\n#static domain_name_servers=192.168.1.1\n\n# fallback to static profile on eth0\n#interface eth0\n#fallback static_eth0\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "4b3d7bf2573e31d667e4061d08dc01dbb9ba8c75", "filename": "roles/user-management/populate-users/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- name: Convert csv to json - set facts\n  delegate_to: localhost\n  set_fact:\n    users: \"{{ lookup('csvtojson', 'file=' + csv_doc_file_name + ' var=users') }}\"\n    user_groups: \"{{ lookup('csvtojson', 'file=' + csv_doc_file_name + ' var=user_groups') }}\"\n\n- name: \"Display imported users values\"\n  debug:\n    var: users\n    verbosity: 2\n  \n- name: \"Display imported user_groups values\"\n  debug:\n    var: user_groups\n    verbosity: 2\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "5ac255c6a3ecbfbc6457c6b0f9629a447ba881d7", "filename": "roles/ansible/tower/manage-job-templates/tasks/set-permissions.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: \"Obtain team id based on the team name\"\n  set_fact:\n    object_id: \"{{ item.id }}\" \n  when:\n  - permissions_object == \"teams\"\n  - item.name|trim == permissions_value.name|trim\n  with_items:\n  - \"{{ existing_teams_output.rest_output }}\"\n    \n- name: \"Obtain user id based on the user name\"\n  set_fact:\n    object_id: \"{{ item.id }}\" \n  when:\n  - permissions_object == \"users\"\n  - item.name|trim == permissions_value.name|trim\n  with_items:\n  - \"{{ existing_users_output.rest_output }}\"\n\n- name: \"Obtain role id based on the job_template name + role name\" \n  set_fact:\n    role_id: \"{{ item.id }}\" \n  when:\n  - item.summary_fields is defined\n  - item.summary_fields.resource_name is defined\n  - item.summary_fields.resource_name|trim == job_template.name|trim\n  - item.name|trim == permissions_value.role|trim\n  with_items:\n  - \"{{ existing_roles_output.rest_output }}\"\n\n- name: \"Set Permission\"\n  uri:\n    url: \"https://localhost/api/v2/{{ permissions_object }}/{{ object_id }}/roles/\"\n    method: POST\n    body: \"{{ { 'id': role_id|int } }}\"\n    body_format: 'json'\n    headers:\n      Content-Type: \"application/json\"\n      Accept: \"application/json\"\n    user: admin\n    password: \"{{ tower_admin_password }}\"\n    validate_certs: no\n    status_code: 200,204\n  when:\n  - object_id is defined\n  - object_id|trim != ''\n  - role_id is defined\n  - role_id|trim != ''\n\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "99515c8ab15674760dbe15dc7a7d2c023bb5adc4", "filename": "roles/ovirt-iso-uploader-conf/tasks/main.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\n- name: Make sure that ovirt-iso-uploader installed\n  yum:\n    name: \"ovirt-iso-uploader\"\n    state: present\n\n- name: Set ovirt-iso-uploader parameters in config file\n  lineinfile:\n    dest: \"{{ ovirt_iso_uploader_conf }}\"\n    line: \"{{ item.key }}={{ item.val }}\"\n    regexp: \"^{{ item.key }} *=.*$\"\n    insertafter: EOF\n  when:\n    item.val != \"\"\n  with_items:\n    - { key: \"user\", val: \"{{ ovirt_iso_uploader_user }}\" }\n    - { key: \"passwd\", val: \"{{ ovirt_iso_uploader_password }}\" }\n    - { key: \"engine\", val: \"{{ ovirt_iso_uploader_engine }}\" }\n    - { key: \"cert-file\", val: \"{{ ovirt_iso_uploader_cert_file }}\" }\n    - { key: \"iso-domain\", val: \"{{ ovirt_iso_uploader_iso_domain }}\" }\n    - { key: \"nfs-server\", val: \"{{ ovirt_iso_uploader_nfs_server }}\" }\n    - { key: \"ssh-user\", val: \"{{ ovirt_iso_uploader_ssh_user }}\" }\n    - { key: \"ssh-port\", val: \"{{ ovirt_iso_uploader_ssh_port }}\" }\n    - { key: \"key-file\", val: \"{{ ovirt_iso_uploader_key_file }}\" }\n"}, {"commit_sha": "406f5e0147bdbca391bee5d397c4f336108486df", "sha": "c379572ba2b94e96b87253a49cb2e4e9538f86d4", "filename": "roles/ovirt-collect-logs/tasks/engine.yml", "repository": "rhevm-qe-automation/ovirt-ansible", "decoded_content": "---\n\n- name: Prepare directory structure\n  file:\n    src: \"{{ item }}\"\n    dest: \"{{ ovirt_collect_logs_tmp_dir }}/{{ item }}\"\n    state: directory\n  with_items:\n    - \"etc\"\n    - \"httpd\"\n\n- name: ovirt-requests-logs files\n  shell: ls /var/log/httpd/ovirt-requests-log*\n  register: ovirt_requests_logs\n  ignore_errors: yes\n\n- name: Link ovirt-engine logs\n  file:\n    src: \"{{ item.src }}\"\n    dest: \"{{ ovirt_collect_logs_tmp_dir }}/{{ item.dest }}\"\n    state: link\n  with_items:\n    -\n      src: \"/var/log/ovirt-engine\"\n      dest: \"ovirt-engine-logs\"\n    -\n      src: \"/var/lib/ovirt-engine\"\n      dest: \"ovirt-engine-data\"\n    -\n      src: \"/etc/ovirt-engine\"\n      dest: \"etc/ovirt-engine\"\n    -\n      src: \"/etc/ovirt-engine-setup.conf.d\"\n      dest: \"etc/ovirt-engine-setup.conf.d\"\n    -\n      src: \"/etc/ovirt-host-deploy.conf.d\"\n      dest: \"etc/ovirt-host-deploy.conf.d\"\n    -\n      src: \"/etc/ovirt-vmconsole\"\n      dest: \"etc/ovirt-vmconsole\"\n  ignore_errors: true\n\n- name: Link ovirt-requests logs\n  file:\n    src: \"{{ item }}\"\n    dest: \"{{ ovirt_collect_logs_tmp_dir }}/httpd/{{ item|replace('/var/log/httpd/', '')}}\"\n    state: link\n  with_items: \"{{ ovirt_requests_logs.stdout_lines }}\"\n  ignore_errors: true\n"}, {"commit_sha": "59e0170313922c2092ea9754f7f89914ac359c4b", "sha": "f694e102136f8aceacb7eb473c392bda2d55f934", "filename": "tasks/plus/setup-suse.yml", "repository": "nginxinc/ansible-role-nginx", "decoded_content": "---\n- name: \"(Install: SUSE) Combine NGINX Plus Certificate and License Keys\"\n  assemble:\n    src: /etc/ssl/nginx\n    dest: /etc/ssl/nginx/nginx-repo-bundle.crt\n\n- name: \"(Install: SUSE) Add NGINX Plus Repository\"\n  zypper_repository:\n    name: nginx-plus\n    repo: \"https://plus-pkgs.nginx.com/sles/{{ ansible_distribution_major_version }}?ssl_clientcert=/etc/ssl/nginx/nginx-repo-bundle.crt&ssl_verify=host\"\n"}, {"commit_sha": "35e3fa9ab5349a9909da5d6f3897d265175c6f97", "sha": "d3ca2f1a4072c1e908bcd1914f28e112002db824", "filename": "roles/serverspec/vars/main.yml", "repository": "Capgemini/Apollo", "decoded_content": "---\n# vars file for serverspec\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "c42d6ef7fdc144ccfb24220a41465b86cca79a5b", "filename": "roles/sugar-stats/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "- name: Install sugar-stats required packages\n  package: name={{ item }}\n           state=present\n  with_items:\n    - sugar-stats-server\n    - active-document\n    - restful-document\n    - python-xappy\n  tags:\n    - download\n\n- name: Create sugar-stats directory tree\n  file: path={{ item }}\n        owner=sugar-stats\n        group=sugar-stats\n        mode=0755\n        state=directory\n  with_items:\n    - /library/sugar-stats/\n    - /library/sugar-stats/rrd\n    - /library/sugar-stats/users\n\n- name: Copy sugar-stats config file\n  template: backup=yes\n            src=sugar-stats.conf.j2\n            dest=/etc/sugar-stats.conf\n            owner=sugar-stats\n            group=sugar-stats\n            mode=0644\n\n- name: Enable sugar-stats service\n  service: name=sugar-stats-server\n           enabled=yes\n  when: sugar_stats_enabled\n\n- name: Disable sugar-stats service\n  service: name=sugar-stats-server\n           enabled=no\n  when: not sugar_stats_enabled\n\n- include: statistics-consolidation.yml\n\n- name: Add sugar-stats to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=sugar_stats\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: sugar_stats\n    - option: description\n      value: '\"Collect Sugar statistics, originally written by Alexy Lim, see: http://wiki.sugarlabs.org/go/Platform_Team/Usage_Statistics\"'\n    - option: installed\n      value: \"{{ sugar_stats_install }}\"\n    - option: enabled\n      value: \"{{ sugar_stats_enabled }}\"\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "681a0302c4989bedbb27c37bd9f0cd1be5ae7736", "filename": "roles/manage-sshd-config/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- import_tasks: 'sshd-update.yml'\n\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "485a8b1db2133863e17e3da00cfaa497d8ffff1b", "filename": "roles/network/tasks/static.yml", "repository": "iiab/iiab", "decoded_content": "# supply an ifcfg if no gateway detected but wan_ip is set\n# set user_wan_iface: <device> and use wan_* for static info\n- name: Supply wan interface file\n  template: src=network/ifcfg-WAN.j2\n            dest=/etc/sysconfig/network-scripts/ifcfg-WAN\n\n- include: NM.yml\n  when: 'ansible_distribution_version <= \"20\" and wan_ip != \"dhcp\"'\n\n- name: Re-read network config files\n  shell: 'nmcli con reload'\n  ignore_errors: yes\n  when: 'ansible_distribution_version >= \"21\" and wan_ip != \"dhcp\"'\n\n- name: use upstream nameserver until named is installed\n  lineinfile: dest=/etc/resolv.conf\n              line='nameserver {{ wan_nameserver }}'\n              create=yes\n              state=present\n"}, {"commit_sha": "1224adf2811c827a09ff0bf133fbb476901a547d", "sha": "e6234dbeed316c321388b1b537c0ea69c0078a46", "filename": "tasks/rpm_prepare.yml", "repository": "nusenu/ansible-relayor", "decoded_content": "---\n\n- name: Ensure EPEL repo is installed (yum)\n  become: yes\n  yum:\n    name: epel-release\n  when: ansible_pkg_mgr == 'yum'\n\n- name: Ensure SELinux dependencies are installed\n  become: yes\n  package:\n    name: libselinux-python,libsemanage-python\n    state: present\n  notify: re-gather facts\n\n# re-gathering facts after installing libselinux-python\n# is a workaround for https://github.com/ansible/ansible-modules-core/issues/2432\n- meta: flush_handlers\n\n- name: Ensure SELinux boolean (tor_can_network_relay) is set appropriately (Fedora)\n  become: yes\n  seboolean:\n    name: tor_can_network_relay\n    state: yes\n    persistent: yes\n  when: ansible_selinux.status == 'enabled'\n\n- name: Ensure systemd drop-in folder is present (RPM)\n  become: yes\n  file:\n    path: /etc/systemd/system/tor@.service.d\n    state: directory\n    owner: root\n    mode: 0755\n\n# this is needed for a small service file modification (allow it to write to /var/lib/tor-instances)\n# without replacing the maintainer's file, for details see\n# http://www.freedesktop.org/software/systemd/man/systemd.unit.html#id-1.11.3\n- name: Ensure service file drop-in is present (RPM)\n  become: yes\n  copy:\n    src: local.conf\n    dest: /etc/systemd/system/tor@.service.d/local.conf\n    owner: root\n    mode: 0644\n  notify: systemctl daemon-reload\n\n- meta: flush_handlers\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "f697c88666ba168de632fa2c03042f6f85fd6fbf", "filename": "roles/scm/github.com/tests/inventory/group_vars/all.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "github_org_name: a-github-org\ngithub_api_username: aGithubUser\ngithub_api_password: !vault |\n      $ANSIBLE_VAULT;1.1;AES256\n      38623834633062333931633933636435376166613935643238306138636136663537383634346263\n      38623834633062333931633933636435376166613935643238306138636136663537383634346263\n      38623834633062333931633933636435376166613935643238306138636136663537383634346263\n      38623834633062333931633933636435376166613935643238306138636136663537383634346263\n      3537\n\nteam:\n  name: The Avengers\n\nrepos:\n- repo_name: test-ci-cd\n  description: This is your first Repo\n  private_repo_bool: false\n  has_issues: true\n  has_projects: false\n  has_wiki: true\n  auto_init: false\n  deploy_key_location: \"{{ lookup('file', './files/test-1.pub') }}\"\n  deploy_key_read_only: yes\n  seed_repo_url: https://github.com/rht-labs/labs-ci-cd.git\n- repo_name: test-app\n  description: This is your first Repo\n  private_repo_bool: false\n  has_issues: true\n  has_projects: false\n  has_wiki: true\n  auto_init: false\n  deploy_key_location: \"{{ lookup('file', './files/test-2.pub') }}\"\n  deploy_key_read_only: yes\n  seed_repo_url: https://github.com/rht-labs/labs-ci-cd.git\n\nusers:\n- '\"aGithubUser\"'\n- '\"aGithubUser2\"'"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "07bc74d4b5a43babb39e0d7a9a3c0373c70fc0e5", "filename": "roles/dns/manage-dns-zones-bind/tasks/determine-action.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Determine if named processing is required\n  set_fact:\n    named_processing: True\n  when:\n    - item.0.named is defined or\n      item.1.named is defined\n  with_subelements:\n    - \"{{ dns_data.views | default({}) }}\"\n    - zones\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "5cbeac07c8d0c3d836b279cd7d354189c8a6def3", "filename": "roles/network/tasks/enable_wan.yml", "repository": "iiab/iiab", "decoded_content": "- name: Turn off ONBOOT for WAN on reboot if disabled\n  lineinfile: state=present\n              backrefs=yes\n              regexp='^ONBOOT'\n              line='ONBOOT=\"no\"'\n              dest=/etc/sysconfig/network-scripts/ifcfg-WAN\n  when: has_WAN and iiab_wan_iface == \"none\"\n\n#testpoint Need to ensure we have only one entry\n- name: Ensure macaddress is correct\n  lineinfile: state=present\n              backrefs=yes\n              regexp='^HWADDR'\n              line='HWADDR=\"{{ hostvars[inventory_hostname]['ansible_' + iiab_wan_iface]['macaddress'] }}\"'\n              dest=/etc/sysconfig/network-scripts/ifcfg-WAN\n  when: has_WAN and iiab_wan_iface != \"none\"\n\n- name: Fix the DEVICE\n  lineinfile: state=present\n              backrefs=yes\n              regexp='^NAME'\n              line='NAME=\"iiab-WAN\"'\n              dest=/etc/sysconfig/network-scripts/ifcfg-WAN\n  when: has_WAN and iiab_wan_iface != \"none\"\n\n- name: Turn on ONBOOT for WAN on reboot if enabled\n  lineinfile: state=present\n              backrefs=yes\n              regexp=\"^ONBOOT\"\n              line=\"ONBOOT=yes\"\n              dest=/etc/sysconfig/network-scripts/ifcfg-WAN\n  when: has_WAN and iiab_wan_iface != \"none\"\n"}, {"commit_sha": "ce0921cf63ee0aec70d171a4ade5e2acb6739c4c", "sha": "99e7b5f656742966d4a682e08d2adf67197d08d0", "filename": "playbooks/roles/check_subscription/tasks/main.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "- name: Register to RHSM\n  redhat_subscription:\n    state: present\n    username: \"{{ rhn_username }}\"\n    password: \"{{ rhn_password }}\"\n    pool_ids: \"{{ subscription_pool_id }}\"\n  register: subscribe\n  when: subscription_pool_id is defined\n- name: Register to Satellite\n  redhat_subscription:\n    state: present\n    activationkey: \"{{ subscription_activationkey }}\"\n    org_id: \"{{ subscription_org_id }}\"\n  register: subscribe_sat\n  when: subscription_org_id is defined and subscription_activationkey is defined and subscription_pool_id is not defined\n- name: Disable all repos\n  shell: |\n    subscription-manager repos --disable='*'\n  when: subscribe.changed or subscribe_sat.changed\n- name: Enable correct repos\n  shell: |\n    subscription-manager repos --enable='{{item}}'\n  with_items:\n  - \"{{repos}}\"\n  when: subscribe.changed or subscribe_sat.changed\n- name: Enable correct repos for\n  shell: |\n    subscription-manager repos --enable='{{item}}'\n  with_items:\n  - \"{{repos}}\"\n  when: (subscribe.changed or subscribe_sat.changed) and item != ''\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "e775e9fc37317ffc6372261f9abd6c803f7fe58c", "filename": "roles/1-prep/tasks/computed_vars.yml", "repository": "iiab/iiab", "decoded_content": "# get local vars from scripts in /etc/ansible/facts.d\n# on first run, this will generate UUID\n\n- name: re-read facts\n  setup: filter=ansible_local\n\n# set top level variables from local facts for convenience\n- set_fact:\n     xo_model: '{{ ansible_local[\"local_facts\"][\"xo_model\"] }}'\n     phplib_dir: '{{ ansible_local[\"local_facts\"][\"phplib_dir\"] }}'\n\n- name: Set exFAT enabled for XOs\n  set_fact:\n     exFAT_enabled: True\n  when: xo_model != \"none\"\n\n- name: add version section\n  ini_file: dest='{{ iiab_config_file }}'\n            section=runtime\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: 'runtime_branch'\n      value: '{{ ansible_local[\"local_facts\"][\"iiab_branch\"] }}'\n    - option: 'runtime_commit'\n      value: '{{ ansible_local[\"local_facts\"][\"iiab_commit\"] }}'\n    - option: 'runtime_date'\n      value: '{{ ansible_date_time[\"iso8601\"] }}'\n    - option: 'runtime_php'\n      value: '{{ phplib_dir }}'\n    - option: 'kernel'\n      value: '{{ ansible_kernel }}'\n    - option: 'memory_mb'\n      value: '{{ ansible_memtotal_mb }}'\n    - option: 'swap_mb'\n      value: '{{ ansible_swaptotal_mb }}'\n    - option: 'product_id'\n      value: '{{ ansible_product_uuid }}'\n\n# Put all computed vars here so derive properly from any prior var file\n- name: If the TZ is not set in env, set it to UTC\n  set_fact: local_tz='UTC'\n  when: local_tz == \"\"\n\n- name: Set port 80 for Admin Console\n  set_fact:\n    gui_port: 80\n  when: not adm_cons_force_ssl\n\n- name: Set port 443 for Admin Console\n  set_fact:\n    gui_port: 443\n  when: adm_cons_force_ssl\n\n- name: Turn on mysql if elgg or rachel enabled\n  set_fact:\n    mysql_install: True\n    mysql_enabled: True\n\n# we decided to enable mysql unconditionally\n#  when: elgg_enabled or rachel_enabled or owncloud_enabled or phpmyadmin_enabled or wordpress_enabled or iiab_menu_install\n\n# Commenting out MongoDB on a trial basis, for a more basic/lightweight Sugarizer, per https://github.com/iiab/iiab/pull/427\n# - name: Turn on mongodb if sugarizer enabled\n#   set_fact:\n#     mongodb_install: True\n#     mongodb_enabled: True\n#   when: sugarizer_enabled\n\n# There might be other db's\n- name: Turn on postgresql if moodle or pathagar enabled\n  set_fact:\n    postgresql_install: True\n    postgresql_enabled: True\n  when: moodle_enabled or pathagar_enabled\n\n- name: Turn on docker if schooltool is to be installed\n  set_fact:\n    docker_install: True\n    docker_enabled: True\n  when: schooltool_enabled or schooltool_install\n\n- name: Set python_path for is_redhat\n  set_fact:\n    python_path: /usr/lib/python2.7/site-packages/\n  when: is_redhat\n\n- name: Set python_path for is_debuntu\n  set_fact:\n    python_path: /usr/local/lib/python2.7/dist-packages/\n  when: is_debuntu\n\n# for various reasons the mysql service can not be enabled on fedora 20,\n# but 'mariadb', which is its real name can\n# on fedora 18 we need to use 'mysqld'\n\n- name: Set mysqld service name to mariadb by default\n  set_fact:\n    mysql_service: mariadb\n\n- name: Set mysqld service name to mysqld for fedora 18\n  set_fact:\n    mysql_service: mysqld\n    no_NM_reload: True\n    is_F18: True\n  when: ansible_distribution_release == \"based on Fedora 18\" or ansible_distribution_version == \"18\"\n\n- name: Set mysql service name to mysql for debian\n  set_fact:\n    mysql_service: mysql\n  when: is_debuntu\n\n# PLATFORM variables\n- name: Fedora 20\n  set_fact:\n    is_F20: True\n  when: ansible_distribution == \"Fedora\" and ansible_distribution_version == \"20\"\n\n- name: Fedora 21\n  set_fact:\n    is_F21: True\n  when: ansible_distribution == \"Fedora\" and ansible_distribution_version == \"21\"\n\n- name: Fedora 22\n  set_fact:\n    is_F22: True\n  when: ansible_distribution == \"Fedora\" and ansible_distribution_version == \"22\"\n\n- name: Fedora 23\n  set_fact:\n    is_F23: True\n  when: ansible_distribution == \"Fedora\" and ansible_distribution_version == \"23\"\n\n- name: Fedora 24\n  set_fact:\n    is_F24: True\n  when: ansible_distribution == \"Fedora\" and ansible_distribution_version == \"24\"\n\n- name: CentOS\n  set_fact:\n    is_CentOS: True\n  when: ansible_distribution == \"CentOS\"\n"}, {"commit_sha": "beb41b82405655aa385bb8297bf49ada1a4eb14c", "sha": "5a439c1c937f40259500858ab2e943f6ad843ee6", "filename": "tasks/Linux/install/Debian.yml", "repository": "lean-delivery/ansible-role-java", "decoded_content": "---\n- name: Add apt-key and repository for AdoptOpenJDK\n  block:\n  - name: Add apt-key for AdoptOpenJDK\n    apt_key:\n      url: https://adoptopenjdk.jfrog.io/adoptopenjdk/api/gpg/key/public\n      state: present\n    register: package_install\n    until: package_install is succeeded\n\n  - name: Add repository for AdoptOpenJDK\n    apt_repository:\n      repo: 'deb https://adoptopenjdk.jfrog.io/adoptopenjdk/deb/ bionic main'\n      filename: adoptopenjdk\n      state: present\n      codename: trusty\n      update_cache: true\n  when:\n    - java_distribution == \"adoptopenjdk\"\n\n- name: Install java packages\n  apt:\n    deb: '{{ java_artifact | default(omit) }}'\n    name: '{{ (jdk_package if transport == \"repositories\") | default(omit) }}'\n    state: present\n    update_cache: true\n    cache_valid_time: 3600\n  register: package_install\n  until: package_install is succeeded\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "9a637ec5c079afbe55b46096e7d31c9ed436c9e5", "filename": "roles/letsencrypt/tasks/nginx.yml", "repository": "roots/trellis", "decoded_content": "- name: Check for existing Nginx conf per site\n  stat:\n    path: \"{{ nginx_path }}/sites-enabled/{{ item.key }}.conf\"\n  register: nginx_confs\n  when: site_uses_letsencrypt\n  with_dict: \"{{ wordpress_sites }}\"\n\n- name: Create Nginx conf for challenges location\n  template:\n    src: acme-challenge-location.conf.j2\n    dest: \"{{ nginx_path }}/acme-challenge-location.conf\"\n  when: sites_need_confs\n\n- name: Create needed Nginx confs for challenges\n  template:\n    src: nginx-challenge-site.conf.j2\n    dest: \"{{ nginx_path }}/sites-available/letsencrypt-{{ item.item.key }}.conf\"\n  when: not item | skipped and not item.stat.exists\n  with_items: \"{{ nginx_confs.results }}\"\n\n- name: Enable Nginx sites\n  file:\n    src: \"{{ nginx_path }}/sites-available/letsencrypt-{{ item.item.key }}.conf\"\n    dest: \"{{ nginx_path }}/sites-enabled/letsencrypt-{{ item.item.key }}.conf\"\n    state: link\n  when: not item | skipped and not item.stat.exists\n  with_items: \"{{ nginx_confs.results }}\"\n\n- include: \"{{ playbook_dir }}/roles/common/tasks/reload_nginx.yml\"\n  when: sites_need_confs\n\n- name: Create test Acme Challenge file\n  shell: touch {{ acme_tiny_challenges_directory }}/ping.txt\n  args:\n    creates: \"{{ acme_tiny_challenges_directory }}/ping.txt\"\n    warn: false\n\n- name: Test Acme Challenges\n  test_challenges:\n    hosts: \"{{ site_hosts }}\"\n  register: letsencrypt_test_challenges\n  ignore_errors: true\n  when: site_uses_letsencrypt\n  with_dict: \"{{ wordpress_sites }}\"\n\n- name: Notify of challenge failures\n  fail:\n    msg: >\n      Could not access the challenge file for the hosts/domains: {{ item.failed_hosts | join(', ') }}.\n      Let's Encrypt requires every domain/host be publicly accessible.\n      Make sure that a valid DNS record exists for {{ item.failed_hosts | join(', ') }} and that they point to this server's IP.\n      If you don't want these domains in your SSL certificate, then remove them from `site_hosts`.\n      See https://roots.io/trellis/docs/ssl for more details.\n  when: not item | skipped and letsencrypt_test_challenges | failed\n  with_items: \"{{ letsencrypt_test_challenges.results }}\"\n"}, {"commit_sha": "84c184cb2178f1787292912c7b402ee9cff8e5b4", "sha": "6be3b71bddeb9f2cc485f2cdcf2d44741a83f53e", "filename": "roles/deploy/hooks/finalize-after.yml", "repository": "roots/trellis", "decoded_content": "---\n- name: WordPress Installed?\n  command: wp core is-installed {{ project.multisite.enabled | default(false) | ternary('--network', '') }}\n  args:\n    chdir: \"{{ deploy_helper.new_release_path }}\"\n  register: wp_installed\n  changed_when: false\n  failed_when: wp_installed.stderr != \"\"\n\n- name: Update WP theme paths\n  command: wp eval 'wp_clean_themes_cache(); switch_theme(get_stylesheet());'\n  args:\n    chdir: \"{{ deploy_helper.new_release_path }}\"\n  when: wp_installed | success\n\n- name: Update WP database\n  command: wp core update-db\n  args:\n    chdir: \"{{ deploy_helper.new_release_path }}\"\n  when: wp_installed | success and not project.multisite.enabled | default(false)\n\n- name: Warn about updating network database.\n  debug:\n    msg: \"Updating the network database could take a long time with a large number of sites.\"\n  when: wp_installed | success and project.multisite.enabled | default(false)\n\n- name: Update WP network database\n  command: wp core update-db --network\n  args:\n    chdir: \"{{ deploy_helper.new_release_path }}\"\n  when: wp_installed | success and project.multisite.enabled | default(false)\n\n- name: Reload php-fpm\n  shell: sudo service php7.0-fpm reload\n  args:\n    chdir: \"{{ deploy_helper.new_release_path }}\"\n    warn: false\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "69a58bd0a65c6991ae2fdad8c9a2d479a6972231", "filename": "roles/ansible/tower/manage-projects/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- block: # when ansible_tower.projects is defined\n\n  - name: \"Set default values\"\n    set_fact:\n      processed_projects: []\n      existing_projects_output: []\n\n  # Utilize the `rest_get` library routine to ensure REST pagination is handled\n  - name: \"Get the existing organizations\"\n    rest_get:\n      host_url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}\"\n      rest_user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      rest_password: \"{{ ansible_tower.admin_password }}\"\n      api_uri: \"/api/v2/organizations/\"\n    register: existing_organizations_output\n\n  # Utilize the `rest_get` library routine to ensure REST pagination is handled\n  - name: \"Get the existing projects\"\n    rest_get:\n      host_url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}\"\n      rest_user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      rest_password: \"{{ ansible_tower.admin_password }}\"\n      api_uri: \"/api/v2/projects/\"\n    register: existing_projects_output\n\n  - name: \"Process the inventory projects\"\n    include_tasks: process-project.yml\n    with_items:\n    - \"{{ ansible_tower.projects }}\"\n    loop_control:\n      loop_var: project\n\n  - name: \"Elminate the projects that should not be present\"\n    uri:\n      url: \"{{ ansible_tower.url | default(default_ansible_tower_url) }}/api/v2/projects/{{ item.id }}/\"\n      user: \"{{ ansible_tower.admin_username | default(default_ansible_tower_admin_username) }}\"\n      password: \"{{ ansible_tower.admin_password }}\"\n      force_basic_auth: yes\n      method: DELETE\n      validate_certs: no\n      status_code: 200,204\n    with_items:\n    - \"{{ existing_projects_output.rest_output | get_remaining_items(processed_projects, 'name', 'name')}}\"\n\n  when:\n  - ansible_tower.projects is defined\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "ca12bce610fe36e7be9a5e9e66da57772ccf0e44", "filename": "roles/config-dns-server/tasks/prereq.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n- name: Ensure required packages are installed\n  package:\n    name: \"{{ item }}\"\n    state: latest\n  with_items:\n  - bind\n  - bind-utils\n  - firewalld\n  - python-firewall\n  - libsemanage-python\n  - python-dns\n\n- name: Enable named\n  service:\n    name: named\n    enabled: yes\n\n- name: Enable firewalld\n  service:\n    name: firewalld\n    enabled: yes\n    state: started\n\n- name: Open Firewall for DNS\n  firewalld: \n    port: \"{{item}}\"\n    permanent: yes\n    state: enabled\n    immediate: yes\n  with_items:\n  - 53/tcp\n  - 53/udp\n\n- name: Configure named\n  copy:\n    src: named.conf\n    dest: /etc/named.conf\n    owner: named\n    group: named\n    mode: 0660\n\n- name: Setup Zone Directory\n  file: \n    dest: /var/named/static \n    state: directory \n    owner: named \n    group: named \n    mode: 0770\n\n- name: Setup key for service named status to communicate with BIND\n  command: \"/sbin/rndc-confgen -a -r /dev/urandom\"\n\n- name: Ensure correct permissions and ownerships on rndc.key file\n  file:\n    path: /etc/rndc.key\n    owner: root\n    group: named\n    mode: 0640\n\n- name: Configure SELinux\n  seboolean:\n    name: named_write_master_zones\n    state: yes\n    persistent: yes\n\n- name: Build list of DNS views/zones\n  set_fact:\n    dns_views: \"{{ dns_views | default([]) + [ item.0.name + '-' + item.1.dns_domain ] }}\"\n  with_subelements:\n  - \"{{ named_config_views }}\"\n  - zone\n\n"}, {"commit_sha": "abc45ed164c9b2ac57eea0edda8515673a9942ea", "sha": "29d5775f8055659548e2d59019ac2f87f98e5065", "filename": "roles/load-balancers/manage-haproxy/tasks/generate-config.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n\n# Use a 'block' to ensure it all runs on 'localhost'\n- block:\n\n  - name: 'Create a temporary HAproxy config file'\n    tempfile:\n      state: file\n      suffix: haproxy\n    register: tempfile\n\n  - name: 'Store away the HAproxy temp config file name'\n    set_fact:\n      haproxy_temp_file: \"{{ tempfile.path }}\"\n\n  - name: 'Use a unique temporary directory to store the config files pre-assemble'\n    command: mktemp -d\n    register: tempdir\n    notify: 'cleanup temp dir'\n\n  - name: 'Store away the temp names'\n    set_fact:\n      haproxy_temp_dir: '{{ tempdir.stdout }}'\n\n  - name: 'Populate the common config portion for HAproxy'\n    template:\n      src: \"{{ lb_common_template | default('lb_common.j2') }}\"\n      dest: '{{ haproxy_temp_dir }}/0001_lb.cfg'\n\n  - name: 'Configure and Populate LB Frontends'\n    template:\n      src: \"{{ lb_frontend_template | default('lb_frontend.j2') }}\"\n      dest: '{{ haproxy_temp_dir }}/0002_lb_{{ fe.lb_name }}_{{ fe.lb_host_vip }}_{{ fe.lb_host_port }}.cfg'\n    loop_control:\n      loop_var: fe\n    loop: \"{{ lb_config.frontends|flatten(levels=1) }}\"\n\n  - name: 'Configure and Populate LB Backends'\n    template:\n      src: \"{{ lb_backend_template | default('lb_backend.j2') }}\"\n      dest: '{{ haproxy_temp_dir }}/0003_lb.cfg'\n\n  - name: 'Populate the stats page config'\n    vars:\n      page_config: \"{{ lb_config.stats_page }}\"\n    template:\n      src: lb_http_stats.j2\n      dest: '{{ haproxy_temp_dir }}/0004_lb.cfg'\n    when:\n    - lb_config.stats_page is defined\n    - lb_config.stats_page.enabled is defined\n    - lb_config.stats_page.enabled\n\n  - name: 'Assemble the final HAproxy config file'\n    assemble:\n      src: '{{ haproxy_temp_dir }}'\n      dest: '{{ haproxy_temp_file }}'\n\n  # Delegate the entire block to \"localhost\"\n  delegate_to: localhost\n  run_once: True\n"}, {"commit_sha": "e14b5a521cae632ac6866ce9200d703b8e700e9d", "sha": "299849f258462262742ce5948df44366bd6c819d", "filename": "tasks/create_repo_bower_proxy_each.yml", "repository": "ansible-ThoTeam/nexus3-oss", "decoded_content": "---\n- include_tasks: call_script.yml\n  vars:\n    script_name: create_repo_bower_proxy\n    args: \"{{ _nexus_repos_bower_defaults|combine(item) }}\"\n"}, {"commit_sha": "d25113e8fab871b2ead95ca976c5a43e4759ea26", "sha": "3d3be5efd2f10981847a53489a3e689db96deddf", "filename": "tasks/auth_initialization.yml", "repository": "UnderGreen/ansible-role-mongodb", "decoded_content": "---\n\n- include: auth_initialization_ald.yml\n  when: ansible_local.mongodb.mongodb.mongodb_login_port is defined\n\n- name: create administrative user siteRootAdmin\n  mongodb_user:\n    database: admin\n    name: \"{{ item.name }}\"\n    password: \"{{ item.password }}\"\n    roles: \"{{ item.roles }}\"\n    login_host: 127.0.0.1\n  with_items:\n    - {\n      name: \"{{ mongodb_root_admin_name }}\",\n      password: \"{{ mongodb_root_admin_password }}\",\n      roles: \"root\"\n      }\n  register: rootadmin_user_result\n  when: ansible_local.mongodb.mongodb.mongodb_login_port is undefined\n\n- name: create administrative user siteUserAdmin\n  mongodb_user:\n    database: admin\n    name: \"{{ item.name }}\"\n    password: \"{{ item.password }}\"\n    roles: \"{{ item.roles }}\"\n    login_host: 127.0.0.1\n  with_items:\n    - {\n      name: \"{{ mongodb_user_admin_name }}\",\n      password: \"{{ mongodb_user_admin_password }}\",\n      roles: \"userAdminAnyDatabase\"\n      }\n  register: useradmin_user_result\n  when: ansible_local.mongodb.mongodb.mongodb_login_port is undefined\n\n- name: create normal users\n  mongodb_user:\n    database: \"{{ item.database }}\"\n    name: \"{{ item.name }}\"\n    password: \"{{ item.password }}\"\n    roles: \"{{ item.roles }}\"\n    replica_set: \"{{ mongodb_conf_replSet }}\"\n    login_host: 127.0.0.1\n    login_user: \"{{ mongodb_user_admin_name }}\"\n    login_password: \"{{ mongodb_user_admin_password }}\"\n  with_items:\n    - \"{{ mongodb_users }}\"\n  when: mongodb_users is defined and ansible_local.mongodb.mongodb.mongodb_login_port is undefined\n\n- name: Create facts.d directory\n  file:\n    state: directory\n    recurse: yes\n    path: /etc/ansible/facts.d\n  when: rootadmin_user_result|changed or useradmin_user_result|changed\n\n- name: Create facts file for mongodb\n  copy:\n    dest: /etc/ansible/facts.d/mongodb.fact\n    content: \"[mongodb]\\nmongodb_login_port={{ mongodb_conf_port }}\\n\"\n  when: rootadmin_user_result|changed or useradmin_user_result|changed\n"}, {"commit_sha": "05d17546dd4b4d1530151795cb0171dbc989945f", "sha": "7a69f0c0cbf15f578cea3c6db7f1e7578d24a101", "filename": "playbooks/templates/easy-rsa-vars.j2", "repository": "rocknsm/rock", "decoded_content": "# easy-rsa parameter settings\n\n# NOTE: If you installed from an RPM,\n# don't edit this file in place in\n# /usr/share/openvpn/easy-rsa --\n# instead, you should copy the whole\n# easy-rsa directory to another location\n# (such as /etc/openvpn) so that your\n# edits will not be wiped out by a future\n# OpenVPN package upgrade.\n\n# This variable should point to\n# the top level of the easy-rsa\n# tree.\nexport EASY_RSA=\"`pwd`\"\n\n#\n# This variable should point to\n# the requested executables\n#\nexport OPENSSL=\"openssl\"\nexport PKCS11TOOL=\"pkcs11-tool\"\nexport GREP=\"grep\"\n\n\n# This variable should point to\n# the openssl.cnf file included\n# with easy-rsa.\nexport KEY_CONFIG=`$EASY_RSA/whichopensslcnf $EASY_RSA`\n\n# Edit this variable to point to\n# your soon-to-be-created key\n# directory.\n#\n# WARNING: clean-all will do\n# a rm -rf on this directory\n# so make sure you define\n# it correctly!\nexport KEY_DIR=\"$EASY_RSA/keys\"\n\n# Issue rm -rf warning\necho NOTE: If you run ./clean-all, I will be doing a rm -rf on $KEY_DIR\n\n# PKCS11 fixes\nexport PKCS11_MODULE_PATH=\"dummy\"\nexport PKCS11_PIN=\"dummy\"\n\n# Increase this to 2048 if you\n# are paranoid.  This will slow\n# down TLS negotiation performance\n# as well as the one-time DH parms\n# generation process.\nexport KEY_SIZE=2048\n\n# In how many days should the root CA key expire?\nexport CA_EXPIRE=3650\n\n# In how many days should certificates expire?\nexport KEY_EXPIRE=3650\n\n# These are the default values for fields\n# which will be placed in the certificate.\n# Don't leave any of these fields blank.\nexport KEY_COUNTRY=\"US\"\nexport KEY_PROVINCE=\"MO\"\nexport KEY_CITY=\"St Louis\"\nexport KEY_ORG=\"RockNSM\"\nexport KEY_EMAIL=\"info@rocknsm.io\"\nexport KEY_OU=\"NSM Ninjas\"\n\n# X509 Subject Field\nexport KEY_NAME=\"EasyRSA\"\n\n# PKCS11 Smart Card\n# export PKCS11_MODULE_PATH=\"/usr/lib/changeme.so\"\n# export PKCS11_PIN=1234\n\n# If you'd like to sign all keys with the same Common Name, uncomment the KEY_CN export below\n# You will also need to make sure your OpenVPN server config has the duplicate-cn option set\n# export KEY_CN=\"CommonName\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "4b6d03cf128cbf73fe808d751f7f483d99871a11", "filename": "roles/kiwix/tasks/kiwix_install.yml", "repository": "iiab/iiab", "decoded_content": "- name: Create various directories for zims\n  file: path={{ item }}\n        owner=root\n        group=root\n        mode=0755\n        state=directory\n  with_items:\n    - \"{{ iiab_zim_path }}\"\n    - \"{{ kiwix_content_path }}\"\n    - \"{{ iiab_zim_path }}/index\"\n\n- name: Check for kiwix-serve binary\n  stat: path={{ iiab_base }}/kiwix/bin/kiwix-serve\n  register: kiwix_bin\n\n- name: Set kiwix first pass\n  set_fact:\n    kiwix_first_pass: True\n  when: kiwix_bin.stat.exists is defined and not kiwix_bin.stat.exists\n\n- name: Copy kiwix library file if needed\n  template: src={{ item }}\n            dest=\"{{ kiwix_library_xml }}\"\n            mode=0644\n            owner=root\n            group=root\n            force=no\n  with_items:\n    - library.xml\n  when: kiwix_first_pass\n\n- name: Copy test.zim file\n  copy: src=test.zim\n        dest={{ kiwix_content_path }}/test.zim\n        mode=0644\n        owner=root\n        group=root\n        force=no\n  when: kiwix_first_pass\n\n# we get a whole web server for intel but only the kiwix execs for arm\n\n- name: Unarchive it to permanent location - not bin_only\n  unarchive: src=\"{{ downloads_dir }}/{{ kiwix_src_file }}\"\n             dest=\"{{ iiab_base }}\"\n             owner=root\n             group=root\n  when: not kiwix_src_bin_only and kiwix_first_pass\n\n- name: Create directory for kiwix bin\n  file: path=\"{{ iiab_base }}/kiwix/bin\"\n        owner=root\n        group=root\n        mode=0755\n        state=directory\n\n- name: enable the mods which permit apache to proxy\n  apache2_module: name={{ item }}\n  with_items:\n    - proxy\n    - proxy_html\n    - proxy_http\n    - rewrite\n  when: is_debuntu\n\n- name: Unarchive it to permanent location - bin only\n  unarchive: src=\"{{ downloads_dir }}/{{ kiwix_src_file }}\"\n             dest=\"{{ iiab_base }}/kiwix/bin\"\n             owner=root\n             group=root\n  when: kiwix_src_bin_only and kiwix_first_pass\n\n# workaround because unarchive does not set ownership properly\n- name: Set kiwix ownership\n  command: \"chown -R root:root {{ iiab_base }}\"\n\n# workaround because kiwix-serve does not stay running\n- name: Make an entry in crontab to restart every hour\n# *  *  *  *  * user-name  command to be executed\n  lineinfile: line=\"15 *  *  *  * root /bin/systemctl restart kiwix-serve.service\"\n              dest=/etc/crontab\n  when: is_debuntu\n\n- name: Make an entry in crontab to restart every hour\n# *  *  *  *  * user-name  command to be executed\n  lineinfile: line=\"15 *  *  *  * root /usr/bin/systemctl restart kiwix-serve.service\"\n              dest=/etc/crontab\n  when: is_redhat\n\n# Create kiwix service\n\n- name: Create kiwix-serve service\n  template: backup=no\n            src={{ item.src }}\n            dest={{ item.dest }}\n            owner=root\n            group=root\n            mode={{ item.mode }}\n  with_items:\n    - { src: 'kiwix-serve.service.j2', dest: '/etc/systemd/system/kiwix-serve.service', mode: '0644'}\n\n#    - { src: 'kiwix-serve-init.j2', dest: '/usr/libexec/kiwix-serve-init', mode: '0755'}\n    - { src: 'iiab-make-kiwix-lib', dest: '/usr/bin/iiab-make-kiwix-lib', mode: '0755'}\n    - { src: 'iiab-make-kiwix-lib.py', dest: '/usr/bin/iiab-make-kiwix-lib.py', mode: '0755'}\n    - { src: 'iiab-make-apache-config.py', dest: '/usr/bin/iiab-make-apache-config.py', mode: '0755'}\n\n\n- name: add kiwix to service list\n  ini_file: dest='{{ service_filelist }}'\n            section=kiwix-serve\n            option='{{ item.option }}'\n            value='{{ item.value }}'\n  with_items:\n    - option: name\n      value: kiwix-serve\n    - option: description\n      value: '\"kiwix-serve is a web server for zim files\"'\n    - option: kiwix_url\n      value: \"{{ kiwix_url }}\"\n    - option: kiwix_path\n      value: \"{{ kiwix_path }}\"\n    - option: kiwix_port\n      value: \"{{ kiwix_port }}\"\n    - option: iiab_zim_path\n      value: \"{{ iiab_zim_path }}\"\n    - option: kiwix_library_xml\n      value: \"{{ kiwix_library_xml }}\"\n    - option: kiwix_content_path\n      value: \"{{ kiwix_content_path }}\"\n    - option: enabled\n      value: \"{{ kiwix_enabled }}\"\n\n- name: Enable kiwix-serve service\n  service: name=kiwix-serve\n           enabled=yes\n           state=restarted\n  when: kiwix_enabled\n\n- name: Disable kiwix-serve service\n  service: name=kiwix-serve\n           enabled=no\n           state=stopped\n  when: not kiwix_enabled\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "63aaefee2cad50f6b736d6886b1d2a263f5517b8", "filename": "roles/phpmyadmin/templates/config.inc.php", "repository": "iiab/iiab", "decoded_content": "<?php\n/*\n * Generated configuration file\n * Generated by: phpMyAdmin 4.2.7.1 setup script\n * Date: Wed, 27 Aug 2014 04:06:59 +0000\n */\n\n/* Servers configuration */\n$i = 0;\n\n/* Server: School Server Mysql Database [1] */\n$i++;\n$cfg['Servers'][$i]['verbose'] = 'School Server Mysql Database';\n$cfg['Servers'][$i]['host'] = 'localhost';\n$cfg['Servers'][$i]['port'] = '';\n$cfg['Servers'][$i]['socket'] = '';\n$cfg['Servers'][$i]['connect_type'] = 'tcp';\n$cfg['Servers'][$i]['auth_type'] = 'cookie';\n$cfg['Servers'][$i]['user'] = 'root';\n$cfg['Servers'][$i]['password'] = '';\n\n/* End of servers configuration */\n\n$cfg['blowfish_secret'] = '53fd593a363ed4.99753154';\n$cfg['DefaultLang'] = 'en';\n$cfg['ServerDefault'] = 1;\n$cfg['UploadDir'] = '';\n$cfg['SaveDir'] = '';\n?>"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "b935bfa0584196fdf47c8b3fbbdbef807afee8fa", "filename": "roles/ferm/README.md", "repository": "roots/trellis", "decoded_content": "## What is ansible-ferm? [![Build Status](https://secure.travis-ci.org/nickjj/ansible-ferm.png)](http://travis-ci.org/nickjj/ansible-ferm)\n\nIt is an [ansible](http://www.ansible.com/home) role to manage iptables using the ever so flexible ferm tool.\n\n### What problem does it solve and why is it useful?\n\nWorking with iptables directly can be really painful and the ufw module is decent for basic needs but sometimes you need a bit more control. I also like the approach of writing templates rather than executing allow/deny commands with ufw. I feel like it sets the tone for a more idempotent setup.\n\n## Role variables\n\nBelow is a list of default values along with a description of what they do.\n\n```\n# Should the firewall be enabled?\nferm_enabled: true\n\n# Should ferm do ip-based tagging/locking when it detects someone is trying to port scan you?\nferm_limit_portscans: false\n\n# The default actions to take for certain policies. You likely want to keep them at the default values.\n# This ensures all ports are blocked until you white list them.\nferm_default_policy_input: DROP\nferm_default_policy_output: ACCEPT\nferm_default_policy_forward: DROP\n\n# The lists to use to provide your own rules. This is explained more below.\nferm_input_list: []\nferm_input_group_list: []\nferm_input_host_list: []\n\n# The amount in seconds to cache apt-update.\napt_cache_valid_time: 86400\n```\n\n### `ferm_input_list` with the `dport_accept` template\n\nThe use case for this would be to white list ports to be opened.\n\n```\nferm_input_list:\n    # Choose the template to use.\n    # REQUIRED: It can be either `dport_accept` or `dport_limit`.\n  - type: \"dport_accept\"\n\n    # Which protocol should be used?\n    # OPTIONAL: Defaults to tcp.\n    protocol: \"tcp\"\n\n    # Which ports should be open?\n    # REQUIRED: It can be the port value or a service in `/etc/services`.\n    dport: [\"http\", \"https\"]\n\n    # Which IP addresses should be white listed?\n    # OPTIONAL: Defaults to an empty list.\n    saddr: []\n\n    # Should all IP addresses be white listed?\n    # OPTIONAL: Defaults to true.\n    accept_any: true\n\n    # Which filename should be written out?\n    # OPTIONAL: Defaults to the first port listed in `dport`.\n\n    # The filename which will get written to `/etc/ferm/filter-input.d/nginx_accept`.\n    filename: \"nginx_accept\"\n\n    # Should this rule be deleted?\n    # OPTIONAL: Defaults to false.\n    delete: false\n```\n\n### `ferm_input_list` with the `dport_limit` template\n\nThe use case for this would be to limit connections on specific ports based on an amount of time. This could be used to harden your security.\n\n```\nferm_input_list:\n    # Choose the template to use.\n    # REQUIRED: It can be either `dport_accept` or `dport_limit`.\n  - type: \"dport_limit\"\n\n    # Which protocol should be used?\n    # OPTIONAL: Defaults to tcp.\n    protocol: \"tcp\"\n\n    # Which ports should be open?\n    # REQUIRED: It can be the port value or a service in `/etc/services`.\n    dport: [\"ssh\"]\n\n    # How many seconds to count in between the hits?\n    # OPTIONAL: Defaults to 300.\n    seconds: \"300\"\n\n    # How many connections should be allowed per the amount of seconds you specified.\n    # OPTIONAL: Defaults to 5.\n    hits: \"5\"\n\n    # Should this rule be disabled?\n    # OPTIONAL: Defaults to false.\n    disabled: false\n```\n\n#### `ferm_input_group_list` / `ferm_input_host_list` with either template\n\nThis would be the same as above except it would be scoped to the groups and hosts list.\n\n## Example app play in your playbook\n\nTo open the http/https ports on your server add the following to the appropriate group or host vars file:\n\n```\nferm_input_group_list:\n  - type: \"dport_accept\"\n    dport: [\"http\", \"https\"]\n    filename: \"nginx_accept\"\n```\n\nI only chose the `nginx_accept` filename because I use nginx. You can name it whatever you want or even remove the filename to have this role automatically generate a filename for you.\n\nThis file will be written to `/etc/ferm/filter-input.d/nginx_accept.conf` and it will contain the rules necessary to open the `http` and `https` ports.\n\n## Attribution\n\nMany thanks to [nickjj](https://github.com/nickjj/) for creating the [original version](https://github.com/nickjj/ansible-ferm/) of this role.\n"}, {"commit_sha": "aec670bf22681f81d100c9dbdc6b502c19dab779", "sha": "255279c1e2ddfcd48016cb6db50ebfb2bb58bc10", "filename": "roles/deploy/tasks/main.yml", "repository": "roots/trellis", "decoded_content": "---\n- include: \"{{ deploy_before | default('../hooks/example.yml') }}\"\n  tags: deploy-before\n- include: initialize.yml\n- include: update.yml\n- include: prepare.yml\n- include: build.yml\n- include: share.yml\n- include: finalize.yml\n- include: \"{{ deploy_after | default('../hooks/example.yml') }}\"\n  tags: deploy-after\n"}, {"commit_sha": "c3b8eb7ce2b79fb375e6c09ded01a4efd3d9fe00", "sha": "bdf1f22cbb4aed61ff052fe3125279420de41907", "filename": "roles/dns/manage-dns-zones/tasks/route53/process-zones.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- include_tasks: process-one-zone.yml\n  with_items:\n    - \"{{ view.zones }}\"\n  loop_control:\n    loop_var: \"zone\"\n"}, {"commit_sha": "f4f0e22738291a56093e4cb61c55706fec3a74d3", "sha": "046c6c2f4dd22606c04da8929dca3983e80fb1a6", "filename": "roles/user-management/manage-atlassian-users/tasks/main.yml", "repository": "redhat-cop/infra-ansible", "decoded_content": "---\n- include_tasks: create_atlassian_groups.yml\n  with_items: \"{{ atlassian_groups }}\"\n  loop_control:\n    loop_var: group\n  when: atlassian_groups|length > 0\n\n- include_tasks: create_atlassian_users.yml\n  with_items: \"{{ atlassian_users }}\"\n  loop_control:\n    loop_var: atlassian_user\n  when: atlassian_users|length > 0\n\n- include_tasks: add_user_to_groups.yml\n  with_items: \"{{ atlassian_users }}\"\n  loop_control:\n    loop_var: atlassian_user\n  when: atlassian_users|length > 0\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "18204cab6c2592bbb353319d5442ba30c52969a5", "filename": "roles/phpmyadmin/tasks/main.yml", "repository": "iiab/iiab", "decoded_content": "    - name: Get the phpmyadmin software\n      get_url: url=\"{{ iiab_download_url }}/{{ phpMyAdmin }}\"  dest=\"{{ downloads_dir }}/phpMyAdmin.zip\"\n      when: internet_available\n\n    - name: Copy it to permanent location /opt\n      unarchive: src={{ downloads_dir }}/phpMyAdmin.zip  dest=/opt/\n\n    - name: Create a symbolic link to the folder of the current version phpmyadmin\n      file: path=/opt/phpmyadmin src=phpMyAdmin-4.2.7.1-all-languages state=link\n\n    - name: Copy the phpmyadmin config file into place\n      template: src=config.inc.php dest=/opt/phpmyadmin/config.inc.php\n\n    - name: Change the owner of the php tree to apache\n      shell: \"chown -R {{ apache_user }} /opt/phpmyadmin\"\n\n    - name: Put the alias into Apache config when enabled\n      template: src=phpmyadmin.j2 dest=/etc/{{ apache_config_dir }}/phpmyadmin.conf\n      when: phpmyadmin_enabled\n\n    - name: Enable phpmyadmin\n      file: path=/etc/apache2/sites-enabled/phpmyadmin.conf\n            src=/etc/apache2/sites-available/phpmyadmin.conf\n            state=link\n      when: phpmyadmin_enabled and is_debuntu\n\n    - name: Remove the alias into Apache config when not enabled\n      file: path=/etc/apache2/sites-enabled/phpmyadmin.conf\n            state=absent\n      when: not phpmyadmin_enabled and is_debuntu\n\n    - name: add phpmyadmin to service list\n      ini_file: dest='{{ service_filelist }}'\n                    section=phpmyadmin\n                    option='{{ item.option }}'\n                    value='\"{{ item.value }}\"'\n      with_items:\n            - option: name\n              value: phpMyAdmin\n            - option: description\n              value: '\"phpMyAdmin is an interface with a mysql database written in php, and available to administer the database engine locally or across the network\"'\n            - option: path\n              value: /opt/phpmyadmin\n            - option: enabled\n              value: \"{{ phpmyadmin_enabled }}\"\n"}, {"commit_sha": "89e3461e17f9af588ad6352304a2305dbd2daefc", "sha": "b600053e52a7d560442da1be9d2822e8a8ecfa64", "filename": "roles/activity-server/files/lang_templates/en/activity", "repository": "iiab/iiab", "decoded_content": "<div class=\"olpc-activity-info\">\n<h2>%(name)s</h2>\n%(description)s\n<ul>\n <li>Identifier: <span class=\"olpc-activity-id\">%(bundle_id)s</span></li>\n <li>Version: <span class=\"olpc-activity-version\">%(activity_version)s</span></li>\n <li>URL: <span class=\"olpc-activity-url\"><a href=\"%(bundle_url)s\">%(bundle_url)s</a></span></li>\n <li style=\"display: %(show_older_versions)s\">Older versions: %(older_versions)s</li>\n</ul>\n</div>\n"}, {"commit_sha": "893a1fff787d5de72ccc2033fc28ef228432b780", "sha": "1af260a2a3247fa0b4dd466f5d48f2c7fad434b3", "filename": "tasks/section_08_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "decoded_content": "---\n\n#  - name: 8.2 Configure rsyslog\n#  The rsyslog software is recommended as a replacement for the default syslogd daemon and\n#  provides improvements over syslogd, such as connection-oriented (i.e. TCP) transmission\n#  of logs, the option to log to database formats, and the encryption of log data en route to a\n#  central logging server.\n#  tags:\n#    - section8\n#    - section8.2\n\n\n  - name: 8.2.1 Install the rsyslog package (Scored)\n    apt: name=rsyslog state=present\n    tags:\n      - section8\n      - section8.2\n      - section8.2.1\n\n  - name: 8.2.2 Ensure the rsyslog Service is activated (Scored)\n    command: grep 'start on filesystem' /etc/rsyslog.conf\n    register: startonfilesystem\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.5.2 Configure rsyslog to Send Logs to a Remote Log Host (start rsyslog) (Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line='start on filesystem'\n       insertafter=EOF\n       state=present\n    when: startonfilesystem.rc == 1\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.3 Configure /etc/rsyslog.conf (Not Scored)\n    lineinfile:\n        dest: /etc/rsyslog.conf\n        line: \"{{ item }}\"\n        insertafter: EOF\n    with_items:\n      - '*.emerg :omusrmsg:*'\n      - 'mail.* -/var/log/mail'\n      - 'mail.info -/var/log/mail.info'\n      - 'mail.warning -/var/log/mail.warn'\n      - 'mail.err /var/log/mail.err'\n      - 'news.crit -/var/log/news/news.crit'\n      - 'news.err -/var/log/news/news.err'\n      - 'news.notice -/var/log/news/news.notice'\n      - '*.=warning;*.=err -/var/log/warn'\n      - '*.crit /var/log/warn'\n      - '*.*;mail.none;news.none -/var/log/messages'\n      - 'local0,local1.* -/var/log/localmessages'\n      - 'local2,local3.* -/var/log/localmessages'\n      - 'local4,local5.* -/var/log/localmessages'\n      - 'local6,local7.* -/var/log/localmessages'\n    changed_when: False\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.3\n\n  - name: 8.2.4.1 Create and Set Permissions on rsyslog Log Files (Scored)\n    shell: awk '{ print $NF }' /etc/rsyslog.d/* /etc/rsyslog.conf | grep /var/log | sed 's/^-//' | sed 's/)$//' \n    register: result\n    changed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.4.2 Create and Set Permissions on rsyslog Log Files (Scored)\n    shell: 'mkdir -p -- \"$(dirname -- {{ item }})\"; touch -- {{ item }}' \n    with_items: result.stdout_lines          \n    changed_when: False\n    register: rsyslog_files_created\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.4.3 Create and Set Permissions on rsyslog Log Files (Scored)\n    file:\n        path: \"{{ item }}\"\n        owner: root \n        group: root \n        mode: \"og-rwx\" \n    when: \"(rsyslog_files_created.results|length > 0) and ('skipped' not in rsyslog_files_created.results[0])\"\n    with_items: result.stdout_lines\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.5.1 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    command: grep \"^*.*[^I][^I]*@\" /etc/rsyslog.conf\n    register: remoteloghost \n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.5.2 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    lineinfile:\n        dest: /etc/rsyslog.conf\n        line: \"*.* @@{{remote_logs_host_address}}\"\n        insertafter: EOF\n        state: present\n    when: set_rsyslog_remote == True and remoteloghost.rc == 1\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.6.1 Accept Remote rsyslog Messages Only on Designated Log Hosts (Not Scored)\n    command: grep '^$ModLoad imtcp' /etc/rsyslog.conf\n    register: moadloadpresent\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.6\n\n  - name: 8.2.6.2 Accept Remote rsyslog Messages Only on Designated Log Hosts (Not Scored)\n    lineinfile:\n        dest: /etc/rsyslog.conf\n        regexp: \"^#({{ item }})\"\n        line: \"{{ item }}\"\n        state: present\n    with_items:\n        - '$ModLoad imtcp'\n        - '$InputTCPServerRun 514'\n    when: set_rsyslog_remote == True and moadloadpresent.rc == 1\n    changed_when: False\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.6\n"}, {"commit_sha": "2f16ef611509cb3ee9885ae4558e98568ff00808", "sha": "70f9ad07b3cecded2eabe649ebcc35424efbb716", "filename": "playbooks/validate_config.yml", "repository": "RedHat-EMEA-SSA-Team/stc", "decoded_content": "---\n- name: Collect host information\n  hosts: localhost\n  connection: local\n  gather_facts: no\n  vars_files:\n  - \"{{file_env}}\"\n  vars_prompt:\n  - name: sudo_password\n    prompt: Password for sudo, leave blank if passwordless sudo (will be encypted)\n    private: yes\n  tasks:\n  - name: Cleanup\n    file:\n      path: \"{{item}}\"\n      state: absent\n    with_items:\n    - \"{{file_ip_data}}\"\n    - \"{{file_inventory}}\"\n    - \"{{file_secrets}}\"\n  - name: Ensure secrets file\n    copy:\n      dest: \"{{file_secrets}}\"\n      content: |\n        sudo_password: \"{{sudo_password}}\"\n  - name: Verify Masters IP addresses\n    local_action: |\n      shell ping -c 1 {{item}} | grep \"PING\"| sed -e 's/[^a-zA-Z0-9.-]/ /g' | awk '{print $3 \": {{item }}\" }' >> {{file_ip_data}}\n    with_items: \"{{masters}}\"\n  - name: Verify Infranodes IP addresses\n    local_action: |\n      shell ping -c 1 {{item}} | grep \"PING\"| sed -e 's/[^a-zA-Z0-9.-]/ /g' | awk '{print $3 \": {{item }}\" }' >> {{file_ip_data}}\n    with_items: \"{{infranodes | default([])}}\"\n  - name: Verify Nodes IP addresses\n    local_action: |\n      shell ping -c 1 {{item}} | grep \"PING\"| sed -e 's/[^a-zA-Z0-9.-]/ /g' | awk '{print $3 \": {{item }}\" }' >> {{file_ip_data}}\n    with_items: \"{{nodes}}\"\n  - name: Verify CNS IP addresses\n    local_action: |\n      shell ping -c 1 {{item}} | grep \"PING\"| sed -e 's/[^a-zA-Z0-9.-]/ /g' | awk '{print $3 }'\n    with_items: \"{{cns | default([])}}\"\n    register: cns_data\n  - local_action: |\n      shell cat \"{{file_ip_data}}\"\n    register: ip_data\n  - name: Print IP addresses\n    debug:\n      msg: |\n        Manager to find following IP adresses:\n        \"{{ip_data.stdout }}\"\n\n  - name: register cns hosts\n    set_fact:\n      cns_hosts: []\n    when: cns is defined\n\n  - name: register cns ip\n    set_fact:\n      cns_hosts: \"{{cns_hosts}} + ['{{ item.stdout }}']\"\n    with_items: \"{{cns_data.results}}\"\n    when: cns is defined\n\n  - name: debug cns hosts\n    debug: var=cns_hosts\n    when: cns is defined\n\n  - name: Create Inventory file based on dynamic collected information.\n    template:\n      src: \"templates/hosts-v{{'%0.2f'| format(ocp_version|float)}}.j2\"\n      dest: \"{{file_inventory}}\"\n"}]