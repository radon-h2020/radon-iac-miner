[{"commit_sha": "4e5f889ccbec1ce7d10466a19c3a2613dc14092b", "sha": "e33490ac4c22dcf6ebfafe8b1482fc51e68bf845", "filename": "tasks/section_08_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "2cfa28fd756194b32e320ab9c0df1e455f27dc38", "decoded_content": "---\n\n#  - name: 8.2 Configure rsyslog\n#  The rsyslog software is recommended as a replacement for the default syslogd daemon and\n#  provides improvements over syslogd, such as connection-oriented (i.e. TCP) transmission\n#  of logs, the option to log to database formats, and the encryption of log data en route to a\n#  central logging server.\n#  tags:\n#    - section8\n#    - section8.2\n\n\n  - name: 8.2.1 Install the rsyslog package (Scored)\n    apt: name=rsyslog state=present\n    tags:\n      - section8\n      - section8.2\n      - section8.2.1\n\n  - name: 8.2.2 Ensure the rsyslog Service is activated (Scored)\n    command: grep 'start on filesystem' /etc/rsyslog.conf\n    register: startonfilesystem\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.5.2 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line='start on filesystem'\n       insertafter=EOF\n       state=present\n    when: startonfilesystem.rc == 1\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.3 Configure /etc/rsyslog.conf (Not Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line=\"{{ item }}\"\n       insertafter=EOF\n    with_items:\n      - '*.emerg :omusrmsg:*'\n      - 'mail.* -/var/log/mail'\n      - 'mail.info -/var/log/mail.info'\n      - 'mail.warning -/var/log/mail.warn'\n      - 'mail.err /var/log/mail.err'\n      - 'news.crit -/var/log/news/news.crit'\n      - 'news.err -/var/log/news/news.err'\n      - 'news.notice -/var/log/news/news.notice'\n      - '*.=warning;*.=err -/var/log/warn'\n      - '*.crit /var/log/warn'\n      - '*.*;mail.none;news.none -/var/log/messages'\n      - 'local0,local1.* -/var/log/localmessages'\n      - 'local2,local3.* -/var/log/localmessages'\n      - 'local4,local5.* -/var/log/localmessages'\n      - 'local6,local7.* -/var/log/localmessages'\n    changed_when: False\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.3\n\n  - name: 8.2.4.1 Create and Set Permissions on rsyslog Log Files (Scored)\n    shell: awk '{ print $NF }' /etc/rsyslog.d/* /etc/rsyslog.conf | grep /var/log | sed 's/^-//' | sed 's/)$//' \n    register: result\n    changed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.4.2 Create and Set Permissions on rsyslog Log Files (Scored)\n    shell: 'mkdir -p -- \"$(dirname -- {{ item }})\"; touch -- {{ item }}' \n    with_items: result.stdout_lines          \n    changed_when: False\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.4.3 Create and Set Permissions on rsyslog Log Files (Scored)\n    file: >\n        path='{{item}}' \n        owner=root \n        group=root \n        mode=\"og-rwx\" \n    with_items: result.stdout_lines\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.5.1 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    command: grep \"^*.*[^I][^I]*@\" /etc/rsyslog.conf\n    register: remoteloghost \n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.5.2 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line=\"*.* @@{{Remote_Logs_Host_Address}}\"\n       insertafter=EOF\n       state=present\n    when: remoteloghost.rc == 1\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.6.1 Accept Remote rsyslog Messages Only on Designated Log Hosts (Not Scored)\n    command: grep '^$ModLoad imtcp' /etc/rsyslog.conf\n    register: moadloadpresent\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.6\n\n  - name: 8.2.6.2 Accept Remote rsyslog Messages Only on Designated Log Hosts (Not Scored)\n    lineinfile: >\n        dest=/etc/rsyslog.conf\n        regexp='^#({{ item }})'\n        line='{{ item }}'\n        state=present\n    with_items:\n        - '$ModLoad imtcp'\n        - '$InputTCPServerRun 514'\n    when: moadloadpresent.rc == 1\n    changed_when: False\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.6\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "72cfdcad0e57931884baedba6e81399dde19d195", "filename": "roles/zookeeper/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n\n# Generate config files in the host\n- name: create zookeeper config directory\n  file:\n    path: \"{{ zookeeper_config_dir }}\"\n    state: directory\n    follow: yes\n    mode: 0755\n  sudo: yes\n  tags:\n    - zookeeper\n\n- name: Create zookeeper config file\n  template:\n    src: zoo.cfg.j2\n    dest: \"{{ zookeeper_config_dir }}/zoo.cfg\"\n  sudo: yes\n  notify:\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: Create zookeeper environments file\n  template:\n    src: environment.j2\n    dest: \"{{ zookeeper_config_dir }}/environment\"\n  sudo: yes\n  notify:\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: Create zookeeper configuration.xsl file\n  template:\n    src: configuration.xsl.j2\n    dest: \"{{ zookeeper_config_dir }}/configuration.xsl\"\n  sudo: yes\n  notify:\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: Create zookeeper myid file\n  copy:\n    content: \"{{ zookeeper_id }}\"\n    dest: \"{{ zookeeper_config_dir }}/myid\"\n    mode: 0644\n  sudo: yes\n  notify:\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: Create zookeeper log4j file\n  template:\n    src: log4j.properties.j2\n    dest: \"{{ zookeeper_config_dir }}/log4j.properties\"\n  sudo: yes\n  notify:\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: Set Zookeeper consul service definition\n  sudo: yes\n  template:\n    src: zookeeper-consul.j2\n    dest: \"{{ consul_dir }}/zookeeper.json\"\n  notify:\n    - restart consul\n  tags:\n    - zookeeper\n\n- name: run zookeeper container\n  docker:\n    name: zookeeper\n    image: \"{{ zookeeper_image }}\"\n    state: started\n    volumes:\n    - \"{{ zookeeper_config_dir }}/:{{ zookeeper_config_dir }}/\"\n    ports:\n    - \"{{ zookeeper_client_port }}:{{ zookeeper_client_port }}\"\n    - \"{{ zookeeper_leader_connect_port }}:{{ zookeeper_leader_connect_port }}\"\n    - \"{{ zookeeper_leader_election_port }}:{{ zookeeper_leader_election_port }}\"\n    net: \"host\"\n    command: /usr/share/zookeeper/bin/zkServer.sh start-foreground\n  tags:\n    - zookeeper\n\n- name: upload zookeeper template service\n  template:\n    src: zookeeper.conf.j2\n    dest: /etc/init/zookeeper.conf\n    mode: 0755\n  sudo: yes\n  tags:\n    - zookeeper\n\n- name: ensure zookeeper is running (and enable it at boot)\n  sudo: yes\n  service:\n    name: zookeeper\n    state: started\n    enabled: yes\n  tags:\n    - zookeeper\n\n"}, {"commit_sha": "903181fe699ba052fc8c94ccf16e531b40064f51", "sha": "c4cf4e89edf6628798fbc9e0e92ea9eb80f07552", "filename": "tasks/section_13_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "2cfa28fd756194b32e320ab9c0df1e455f27dc38", "decoded_content": "---\n\n  - name: 13.1 Ensure Password Fields are Not Empty (Scored)\n    command: awk -F':' '($2 == \"\" ) { print $1 }' /etc/shadow\n    register: awk_empty_shadow\n    changed_when: False\n    failed_when: awk_empty_shadow.stdout != '' and lock_shadow_accounts == 'no'\n    tags:\n      - section13\n      - section13.1\n\n  - name: 13.1 Ensure Password Fields are Not Empty (locking accounts) (Scored)\n    command: passwd -l {{ item }}\n    with_items:\n        awk_empty_shadow.stdout_lines\n    when: lock_shadow_accounts\n    tags:\n      - section13\n      - section13.1\n\n  - name: 13.2 Verify No Legacy \"+\" Entries Exist in /etc/passwd File (Scored)\n    command: grep '^+:' /etc/passwd\n    register: plus_pass\n    failed_when: plus_pass.rc == 0\n    changed_when: plus_pass.rc == 0\n    tags:\n      - section13\n      - section13.2\n\n  - name: 13.3 Verify No Legacy \"+\" Entries Exist in /etc/shadow File (Scored)\n    command: grep '^+:' /etc/shadow\n    register: plus_shadow\n    failed_when: plus_shadow.rc == 0\n    changed_when: plus_shadow.rc == 0\n    tags:\n      - section13\n      - section13.3\n\n  - name: 13.4 Verify No Legacy \"+\" Entries Exist in /etc/group File (Scored)\n    command: grep '^+:' /etc/group\n    register: plus_group\n    failed_when: plus_group.rc == 0\n    changed_when: plus_group.rc == 0\n    tags:\n      - section13\n      - section13.4\n\n  - name: 13.5 Verify No UID 0 Accounts Exist Other Than root (Scored)\n    command: awk -F':' '($3 == 0) { print $1 }' /etc/passwd\n    register: uid_zero_root\n    changed_when: False\n    failed_when: uid_zero_root.stdout != 'root'\n    tags:\n      - section13\n      - section13.5\n\n  - name: 13.6.1 Ensure root PATH Integrity (empty value) (Scored)\n    shell: 'echo $PATH | grep ::'\n    register: path_colon\n    changed_when: False\n    failed_when: path_colon.rc == 0\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.2 Ensure root PATH Integrity (colon end) (Scored)\n    shell: 'echo $PATH | grep :$'\n    register: path_colon_end\n    changed_when: False\n    failed_when: path_colon_end.rc == 0\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.3 Ensure root PATH Integrity (dot in path) (Scored)\n    shell: \"echo $PATH | sed -e 's/::/:/' -e 's/:$//' -e 's/:/\\\\n/g'\"\n    register: dot_in_path\n    changed_when: False\n    failed_when: '\".\" in dot_in_path.stdout_lines'\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.4 Ensure root PATH Integrity (Scored)\n    file: >\n        path={{ item }}\n        state=directory\n        owner=root\n        mode='o-w,g-w'\n    with_items:\n        dot_in_path.stdout_lines\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.7.1 Check Permissions on User Home Directories (gather users) (Scored)\n    shell: /bin/egrep -v '(root|halt|sync|shutdown)' /etc/passwd | /usr/bin/awk -F':' '($7 != \"/usr/sbin/nologin\") { print $6 }'\n    register: home_users\n    changed_when: False\n    failed_when: False\n    tags:\n      - section13\n      - section13.7\n\n  - name: 13.7.2 Check Permissions on User Home Directories (Scored)\n    file: >\n        path={{ item }}\n        mode='g-w,o-rwx'\n        state=directory\n    with_items:\n        home_users.stdout_lines\n    tags:\n      - section13\n      - section13.7\n\n  - name: 13.8.1 Check User Dot File Permissions (gather dotfiles) (Scored)\n    shell: for pth in `/bin/egrep -v '(root|halt|sync|shutdown)' /etc/passwd | /usr/bin/awk -F':' '($7 != \"/usr/sbin/nologin\") { print $6 }'`; do ls -d -A -1 $pth/.* | egrep -v '[..]$'; done\n    changed_when: False\n    failed_when: False\n    always_run: True\n    register: home_dot_files\n    tags:\n      - section13\n      - section13.8\n\n  - name: 13.8.2 Check User Dot File Permissions (Scored)\n    file: >\n        path={{ item }}\n        mode='o-w,g-w'\n    with_items:\n        home_dot_files.stdout_lines\n    tags:\n      - section13\n      - section13.8\n\n  - name: 13.9 Check Permissions on User .netrc Files (Scored)\n    file: >\n        path={{ item }}/.netrc\n        mode='g-rwx,o-rwx'\n        recurse=yes\n        state=directory\n    with_items:\n        home_users.stdout_lines\n    tags:\n      - section13\n      - section13.9\n\n  - name: 13.10 Check for Presence of User .rhosts Files (Scored)\n    file: >\n        state=absent\n        path={{ item }}/.rhosts\n    with_items:\n        home_users.stdout_lines\n    tags:\n      - section13\n      - section13.10\n\n  - name: 13.11 Check Groups in /etc/passwd (preparation) (Scored)\n    command: cut -s -d':' -f4 /etc/passwd\n    register: groups_id_cut\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.11\n\n  - name: 13.11 Check Groups in /etc/passwd (Scored)\n    command: grep -q -P \"^.*?:[^:]*:{{ item }}:\" /etc/group\n    with_items:\n        groups_id_cut.stdout_lines\n    register: groups_present\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.11\n\n  - name: 13.12 Check That Users Are Assigned Valid Home Directories (Scored)\n    stat: path={{ item }}\n    with_items:\n        home_users.stdout_lines\n    register: rstat\n    failed_when: rstat is defined and rstat.stat.isdir == False\n    always_run: True\n    tags:\n      - section13\n      - section13.12\n\n  - name: 13.13 Check User Home Directory Ownership (Scored)\n    debug: msg=\"*** Hardcore ***\"\n    tags:\n      - section13\n      - section13.13\n\n  - name: 13.14 Check for Duplicate UIDs (Scored)\n    shell: cut -f3 -d':' /etc/passwd | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.14\n\n  - name: 13.15 Check for Duplicate GIDs (Scored)\n    shell: cut -f3 -d':' /etc/group | sort | uniq -d\n    register: gids_list\n    failed_when: gids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.15\n\n  - name: 13.16 Check for Duplicate User Names (Scored)\n    shell: cut -f1 -d':' /etc/passwd | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.16\n\n  - name: 13.17 Check for Duplicate Group Names (Scored)\n    shell: cut -f1 -d':' /etc/group | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.17\n\n  - name: 13.18 Check for Presence of User .netrc Files (stat) (Scored)\n    stat: path='{{ item }}/.netrc'\n    with_items: home_users.stdout_lines\n    register: netrc_files\n    tags:\n      - section13\n      - section13.18\n\n  - name: 13.18 Check for Presence of User .netrc Files (Scored)\n    file: >\n        path='{{ item }}'\n        state=absent\n    when: item.stat.exists == True\n    with_items: netrc_files.results\n    tags:\n      - section13\n      - section13.18\n\n  - name: 13.19 Check for Presence of User .forward Files (Scored)\n    file: >\n        path='{{ item }}/.forward'\n        state=absent\n    with_items:\n        home_users.stdout_lines\n    tags:\n      - section13\n      - section13.19\n\n  - name: 13.20.1 Ensure shadow group is empty (Scored)\n    shell: grep '^shadow' /etc/group | cut -f4 -d':'\n    register: shadow_group_empty\n    failed_when: shadow_group_empty.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.1\n\n  - name: 13.20.2 Ensure shadow group is empty (preparation) (Scored)\n    shell: grep '^shadow' /etc/group | cut -f1 -d':'\n    register: shadow_group_id\n    failed_when: False\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.1\n\n  - name: 13.20.2 Ensure shadow group is empty (Scored)\n    shell: awk -F':' '($4 == \"{{ item }}\") { print }' /etc/passwd\n    register: awk_passwd_shadow\n    with_items:\n        shadow_group_id.stdout_lines\n    changed_when: False\n    failed_when: awk_passwd_shadow.stdout != ''\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.2\n"}, {"commit_sha": "9ad67b6ef151d5fbaa05230e6cecb4bed1db7d9d", "sha": "daf972e7ccb53cce9d5c9a92b516f16ba89e2908", "filename": "tasks/section_02_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "2cfa28fd756194b32e320ab9c0df1e455f27dc38", "decoded_content": "---\n\n  - name: 2.1 Create Separate Partition for /tmp (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /tmp\"\n    tags:\n      - section2\n      - section2.1\n\n  - name: 2.2 - 4 Set nodev, nosuid, noexec option for /tmp Partition (Scored)\n    mount: name=\"/tmp\" src=\"/tmp\" state=\"mounted\" opts=\"nodev,nosuid,noexec\" fstype=ext4\n    when: partitioning == True\n    tags:\n      - section2\n      - section2.2\n      - section2.3\n      - section2.4\n\n  - name: 2.5 Create Separate Partition for /var (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var\"\n    tags:\n      - section2\n      - section2.5\n\n  - name: 2.6 Bind Mount the /var/tmp directory to /tmp (Scored)\n    mount: name=\"/var/tmp\" src=\"/tmp\" opts=bind state=mounted fstype=ext4\n    when: partitioning == True\n    tags:\n      - section2\n      - section2.6\n\n  - name: 2.7 Create Separate Partition for /var/log (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var/log\"\n    tags:\n      - section2\n      - section2.7\n\n  - name: 2.8 Create Separate Partition for /var/log/audit (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var/log/audit\"\n    tags:\n      - section2\n      - section2.8\n\n  - name: 2.9 Create Separate Partition for /home (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /home\"\n    tags:\n      - section2\n      - section2.9\n\n  - name: 2.10 Add nodev Option to /home (Scored)\n    mount: name:/home state:mounted opts:remount,nodev\n    when: partitioning == True\n    tags:\n      - section2\n      - section2.10\n\n  - name: 2.11 Add nodev Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nodev option\"\n    tags:\n      - section2\n      - section2.11\n\n  - name: 2.12 Add noexec Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have noexec option\"\n    tags:\n      - section2\n      - section2.12\n\n  - name: 2.13 Add nosuid Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nosuid option\"\n    tags:\n      - section2\n      - section2.13\n\n  - name: 2.14 - 16 Add nodev Option to /run/shm Partition (Scored)\n    mount: name=\"/run/shm\" src=\"/run/shm\" state=\"mounted\" opts=\"nodev,nosuid,noexec\" fstype=\"tmpfs\"\n    tags:\n      - section2\n      - section2.14\n      - section2.15\n      - section2.16\n\n  - name: 2.17.1 Set Sticky Bit on All World-Writable Directories (preparation) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type d -perm -0002 -print 2>/dev/null\n    failed_when: False\n    changed_when: False\n    always_run: True\n    register: sticky_bit_dirs\n    tags:\n      - section2\n      - section2.17\n      - section2.17.1\n\n  - name: 2.17.2 Set Sticky Bit on All World-Writable Directories (Scored)\n    file: path='{{ item }}' mode=\"a+t\"\n    with_items: sticky_bit_dirs.stdout_lines\n    tags:\n      - section2\n      - section2.17\n      - section2.17.2\n\n  - name: 2.25 Disable Automounting (stat) (Scored)\n    stat: >\n        path=/etc/init/autofs.conf\n    register: autofs_file\n    tags:\n      - section2\n      - section2.25\n      \n  - name: 2.25 Disable Automounting (Scored)\n    lineinfile: >\n        dest=/etc/init/autofs.conf\n        line='#start on runlevel [2345]'\n        regexp='start on runlevel'\n        state=present\n    when: autofs_file.stat.exists == True\n    tags:\n      - section2\n      - section2.25\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "8501eeea335293fd898808901a2ae7b4f44b8acc", "filename": "roles/st2/meta/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": null, "release_ends_at": "2d0f3f1cf5d5919432c94bb3659c16b85d1cb1db", "decoded_content": "---\ngalaxy_info:\n  description: Install StackStorm and all its components\n  author: armab\n  company: StackStorm\n  license: Apache\n  min_ansible_version: 1.9\n  platforms:\n    - name: Ubuntu\n      versions:\n        - trusty\n        - precise\n  categories:\n    - system\ndependencies: []\n"}, {"commit_sha": "f565940c5163524c7834123625c804e5f69c2b10", "sha": "8a0044fd85c18c7dc7871e46d9c1c9460b30e6b6", "filename": "tasks/server.yml", "repository": "sensu/sensu-ansible", "release_starts_at": null, "release_ends_at": "9b3cb140022faf899910398013334755c8050175", "decoded_content": "---\n# tasks/server.yml: Deploy Sensu Server/API\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Deploy Sensu server API configuration\n    template:\n      dest: \"{{ sensu_config_path }}/conf.d/api.json\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      src: sensu-api.json.j2\n    notify: restart sensu-api service\n\n  - include: SmartOS/server.yml\n    when: ansible_distribution == \"SmartOS\"\n\n  - name: Ensure Sensu server service is running\n    service: name=sensu-server state=started enabled=yes\n\n  - name: Ensure Sensu API service is running\n    service: name=sensu-api state=started enabled=yes\n"}, {"commit_sha": "ec4de12ae75f7191a5f71aa775e0344679ea1477", "sha": "0fa9d9ae451a7f8eb1c45da80b30164d7a5b3745", "filename": "tasks/auth_initialization_ald.yml", "repository": "UnderGreen/ansible-role-mongodb", "release_starts_at": "", "release_ends_at": "", "release": "42487b9f4681a078ef82c07c3307a51653a19791", "decoded_content": "- name: create administrative user siteRootAdmin port=yes\n  mongodb_user:\n    database: admin\n    name: \"{{ item.name }}\"\n    password: \"{{ item.password }}\"\n    roles: \"{{ item.roles }}\"\n    login_host: 127.0.0.1\n    login_port: \"{{ ansible_local.mongodb.mongodb.mongodb_login_port }}\"\n  with_items:\n    - {\n      name: \"{{ mongodb_root_admin_name }}\",\n      password: \"{{ mongodb_root_admin_password }}\",\n      roles: \"root\"\n      }\n\n- name: create administrative user siteUserAdmin port=yes\n  mongodb_user:\n    database: admin\n    name: \"{{ item.name }}\"\n    password: \"{{ item.password }}\"\n    roles: \"{{ item.roles }}\"\n    login_host: 127.0.0.1\n    login_port: \"{{ ansible_local.mongodb.mongodb.mongodb_login_port }}\"\n  with_items:\n    - {\n      name: \"{{ mongodb_user_admin_name }}\",\n      password: \"{{ mongodb_user_admin_password }}\",\n      roles: \"userAdminAnyDatabase\"\n      }\n\n- name: create normal users\n  mongodb_user:\n    database: \"{{ item.database }}\"\n    name: \"{{ item.name }}\"\n    password: \"{{ item.password }}\"\n    roles: \"{{ item.roles }}\"\n    replica_set: \"{{ mongodb_conf_replSet }}\"\n    login_host: 127.0.0.1\n    login_port: \"{{ ansible_local.mongodb.mongodb.mongodb_login_port }}\"\n    login_user: \"{{ mongodb_user_admin_name }}\"\n    login_password: \"{{ mongodb_user_admin_password }}\"\n  with_items:\n    - \"{{ mongodb_users }}\"\n  when: mongodb_users is defined\n"}, {"commit_sha": "9eb1a8fa8e281ef06687c1851f51fa0beec3e232", "sha": "62d99571dcc016b3d90c13e5814daef649bfbdaa", "filename": "tasks/section_13_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "2cfa28fd756194b32e320ab9c0df1e455f27dc38", "decoded_content": "---\n\n  - name: 13.1 Ensure Password Fields are Not Empty (Scored)\n    command: awk -F':' '($2 == \"\" ) { print $1 }' /etc/shadow\n    register: awk_empty_shadow\n    changed_when: False\n    failed_when: awk_empty_shadow.stdout != '' and not lock_shadow_accounts\n    tags:\n      - section13\n      - section13.1\n\n  - name: 13.1 Ensure Password Fields are Not Empty (locking accounts) (Scored)\n    command: passwd -l '{{ item }}'\n    with_items:\n        awk_empty_shadow.stdout_lines\n    when: lock_shadow_accounts\n    tags:\n      - section13\n      - section13.1\n\n  - name: 13.2 Verify No Legacy \"+\" Entries Exist in /etc/passwd File (Scored)\n    command: grep '^+:' /etc/passwd\n    register: plus_pass\n    failed_when: plus_pass.rc == 0\n    changed_when: plus_pass.rc == 0\n    tags:\n      - section13\n      - section13.2\n\n  - name: 13.3 Verify No Legacy \"+\" Entries Exist in /etc/shadow File (Scored)\n    command: grep '^+:' /etc/shadow\n    register: plus_shadow\n    failed_when: plus_shadow.rc == 0\n    changed_when: plus_shadow.rc == 0\n    tags:\n      - section13\n      - section13.3\n\n  - name: 13.4 Verify No Legacy \"+\" Entries Exist in /etc/group File (Scored)\n    command: grep '^+:' /etc/group\n    register: plus_group\n    failed_when: plus_group.rc == 0\n    changed_when: plus_group.rc == 0\n    tags:\n      - section13\n      - section13.4\n\n  - name: 13.5 Verify No UID 0 Accounts Exist Other Than root (Scored)\n    command: awk -F':' '($3 == 0) { print $1 }' /etc/passwd\n    register: uid_zero_root\n    changed_when: False\n    failed_when: uid_zero_root.stdout != 'root'\n    tags:\n      - section13\n      - section13.5\n\n  - name: 13.6.1 Ensure root PATH Integrity (empty value) (Scored)\n    shell: 'echo $PATH | grep ::'\n    register: path_colon\n    changed_when: False\n    failed_when: path_colon.rc == 0\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.2 Ensure root PATH Integrity (colon end) (Scored)\n    shell: 'echo $PATH | grep :$'\n    register: path_colon_end\n    changed_when: False\n    failed_when: path_colon_end.rc == 0\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.3 Ensure root PATH Integrity (dot in path) (Scored)\n    shell: \"echo $PATH | sed -e 's/::/:/' -e 's/:$//' -e 's/:/\\\\n/g'\"\n    register: dot_in_path\n    changed_when: False\n    failed_when: '\".\" in dot_in_path.stdout_lines'\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.6.4 Ensure root PATH Integrity (Scored)\n    file: >\n        path='{{ item }}'\n        state=directory\n        owner=root\n        mode='o-w,g-w'\n    with_items:\n        dot_in_path.stdout_lines\n    tags:\n      - section13\n      - section13.6\n\n  - name: 13.7.1 Check Permissions on User Home Directories (gather users) (Scored)\n    shell: /bin/egrep -v '(root|halt|sync|shutdown|false)' /etc/passwd | /usr/bin/awk -F':' '($7 != \"/usr/sbin/nologin\") { print $6 }'\n    register: home_users\n    changed_when: False\n    failed_when: False\n    tags:\n      - section13\n      - section13.7\n\n  - name: 13.7.2 Check Permissions on User Home Directories (Scored)\n    file: >\n        path='{{ item }}'\n        mode='g-w,o-rwx'\n        state=directory\n    with_items:\n        home_users.stdout_lines\n    when: modify_user_homes == True\n    tags:\n      - section13\n      - section13.7\n\n  - name: 13.8.1 Check User Dot File Permissions (gather dotfiles) (Scored)\n    shell: for pth in `/bin/egrep -v '(root|halt|sync|shutdown)' /etc/passwd | /usr/bin/awk -F':' '($7 != \"/usr/sbin/nologin\") { print $6 }'`; do ls -d -A -1 $pth/.* | egrep -v '[..]$'; done\n    changed_when: False\n    failed_when: False\n    always_run: True\n    register: home_dot_files\n    tags:\n      - section13\n      - section13.8\n\n  - name: 13.8.2 Check User Dot File Permissions (Scored)\n    file: >\n        path='{{ item }}'\n        mode='o-w,g-w'\n    with_items:\n        home_dot_files.stdout_lines\n    tags:\n      - section13\n      - section13.8\n\n  - name: 13.9 Check Permissions on User .netrc Files (Scored)\n    file: >\n        path='{{ item }}/.netrc'\n        mode='g-rwx,o-rwx'\n        recurse=yes\n        state=directory\n    with_items:\n        home_users.stdout_lines\n    tags:\n      - section13\n      - section13.9\n\n  - name: 13.10 Check for Presence of User .rhosts Files (Scored)\n    file: >\n        state=absent\n        path='{{ item }}/.rhosts'\n    with_items:\n        home_users.stdout_lines\n    tags:\n      - section13\n      - section13.10\n\n  - name: 13.11 Check Groups in /etc/passwd (preparation) (Scored)\n    command: cut -s -d':' -f4 /etc/passwd\n    register: groups_id_cut\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.11\n\n  - name: 13.11 Check Groups in /etc/passwd (Scored)\n    command: grep -q -P \"^.*?:[^:]*:{{ item }}:\" /etc/group\n    with_items:\n        groups_id_cut.stdout_lines\n    register: groups_present\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.11\n\n  - name: 13.12 Check That Users Are Assigned Valid Home Directories (Scored)\n    stat: path='{{ item }}'\n    with_items:\n        home_users.stdout_lines\n    register: rstat\n    failed_when: rstat is defined and rstat.stat.isdir == False\n    always_run: True\n    tags:\n      - section13\n      - section13.12\n\n  - name: 13.13 Check User Home Directory Ownership (Scored)\n    debug: msg=\"*** Hardcore ***\"\n    tags:\n      - section13\n      - section13.13\n\n  - name: 13.14 Check for Duplicate UIDs (Scored)\n    shell: cut -f3 -d':' /etc/passwd | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.14\n\n  - name: 13.15 Check for Duplicate GIDs (Scored)\n    shell: cut -f3 -d':' /etc/group | sort | uniq -d\n    register: gids_list\n    failed_when: gids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.15\n\n  - name: 13.16 Check for Duplicate User Names (Scored)\n    shell: cut -f1 -d':' /etc/passwd | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.16\n\n  - name: 13.17 Check for Duplicate Group Names (Scored)\n    shell: cut -f1 -d':' /etc/group | sort | uniq -d\n    register: uids_list\n    failed_when: uids_list.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.17\n\n  - name: 13.18 Check for Presence of User .netrc Files (stat) (Scored)\n    stat: path='{{ item }}/.netrc'\n    with_items: home_users.stdout_lines\n    register: netrc_files\n    tags:\n      - section13\n      - section13.18\n\n  - name: 13.18 Check for Presence of User .netrc Files (Scored)\n    file: >\n        path='{{ item.stat.path }}'\n        state=absent\n    when: item is defined and item.stat.exists == True\n    with_items: netrc_files.results\n    tags:\n      - section13\n      - section13.18\n\n  - name: 13.19 Check for Presence of User .forward Files (Scored)\n    file: >\n        path='{{ item }}/.forward'\n        state=absent\n    with_items:\n        home_users.stdout_lines\n    tags:\n      - section13\n      - section13.19\n\n  - name: 13.20.1 Ensure shadow group is empty (Scored)\n    shell: grep '^shadow' /etc/group | cut -f4 -d':'\n    register: shadow_group_empty\n    failed_when: shadow_group_empty.stdout != ''\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.1\n\n  - name: 13.20.2 Ensure shadow group is empty (preparation) (Scored)\n    shell: grep '^shadow' /etc/group | cut -f1 -d':'\n    register: shadow_group_id\n    failed_when: False\n    changed_when: False\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.1\n\n  - name: 13.20.2 Ensure shadow group is empty (Scored)\n    shell: awk -F':' '($4 == \"{{ item }}\") { print }' /etc/passwd\n    register: awk_passwd_shadow\n    with_items:\n        shadow_group_id.stdout_lines\n    changed_when: False\n    failed_when: awk_passwd_shadow.stdout != ''\n    always_run: True\n    tags:\n      - section13\n      - section13.20\n      - section13.20.2\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "038c8692755b64fd16a2d364fb4fb5f8e862d164", "filename": "roles/cadvisor/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# defaults file for cadvisor\ncadvisor_enabled: true\ncadvisor_version: 'latest'\ncadvisor_restart_policy: 'always'\ncadvisor_net: 'bridge'\ncadvisor_hostname: \"{{ ansible_ssh_host }}\"\ncadvisor_image: \"google/cadvisor:{{ cadvisor_version }}\"\ncadvisor_consul_dir: /etc/consul.d\ncadvisor_consul_service_id: \"{{ ansible_hostname }}:cadvisor:8080\"\ncadvisor_rebuild_container: false\n"}, {"commit_sha": "1510f92858b85f9f623690db747bdfff9b5b0515", "sha": "6c3ec9401fb3dd241b0e33f526d056f491c33377", "filename": "tasks/configure.yml", "repository": "dev-sec/ansible-mysql-hardening", "release_starts_at": null, "release_ends_at": "98e30c4cab55a2719db71947e68249f80b5c9322", "decoded_content": "---\n\n- name: protect my.cnf\n  file: path='{{mysql_hardening_mysql_conf}}' mode=0600 owner=root group=root\n\n- name: ensure permissions on mysql-datadir are correct\n  file: path='{{mysql_datadir}}' state=directory owner='{{mysql_hardening_user}}' group='{{mysql_hardening_user}}'\n\n- name: check mysql configuration-directory exists and has right permissions\n  file: path='/etc/mysql/conf.d' state=directory owner='{{mysql_hardening_user}}' group='{{mysql_hardening_group}}' mode=0470\n\n- name: check include-dir directive is present in my.cnf\n  lineinfile: dest='{{mysql_hardening_mysql_conf}}' line='!includedir /etc/mysql/conf.d/' insertafter='EOF' state=present backup=yes\n  notify: restart mysql\n\n- name: apply hardening configuration\n  template: src='hardening.cnf.j2' dest='{{mysql_hardening_hardening_conf}}' owner='{{mysql_hardening_user}}' group='{{mysql_hardening_group}}' mode=0460\n  notify: restart mysql\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "180d44bcb090674b7de003f07345bb4201d35416", "filename": "roles/mistral/tasks/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": null, "release_ends_at": "2d0f3f1cf5d5919432c94bb3659c16b85d1cb1db", "decoded_content": "- include: gather_facts.yml\n- include: install_deps.yml\n- include: install_mistral.yml\n- include: install_actions.yml\n- include: config.yml\n- include: sync.yml\n- include: install_client.yml\n"}, {"commit_sha": "e8eb28b4b4b1c4fb2490b8198570166b9ca23ab2", "sha": "6071eee218c6d44d2c7da98892f04a91c9a150f7", "filename": "roles/mistral/tasks/install_deps.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": null, "release_ends_at": "2d0f3f1cf5d5919432c94bb3659c16b85d1cb1db", "decoded_content": "- name: Install dependencies\n  sudo: true\n  apt:\n    name: \"{{ item }}\"\n    update_cache: yes\n  with_items:\n    - git\n    - libssl-dev\n    - libyaml-dev\n    - libffi-dev\n    - libxml2-dev\n    - libxslt1-dev\n    - python-dev\n    - python-pip\n    - libmysqlclient-dev\n\n- name: Install pip virtualenv\n  sudo: true\n  pip:\n    name: virtualenv\n"}, {"commit_sha": "1bb50a6149f6ff7f2e6399411418d088e2c52d01", "sha": "0c355d342c1abbf955ed8b09f41e73fa4e42bb49", "filename": "tasks/section_02_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "2cfa28fd756194b32e320ab9c0df1e455f27dc38", "decoded_content": "---\n\n  - name: 2.1 Create Separate Partition for /tmp (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /tmp\"\n    tags:\n      - section2\n      - section2.1\n\n  - name: 2.2 - 4 Set nodev, nosuid, noexec option for /tmp Partition (Scored)\n    mount: name=\"/tmp\" src=\"/tmp\" state=\"mounted\" opts=\"nodev,nosuid,noexec\" fstype=ext4\n    when: partitioning == True\n    tags:\n      - section2\n      - section2.2\n      - section2.3\n      - section2.4\n\n  - name: 2.5 Create Separate Partition for /var (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var\"\n    tags:\n      - section2\n      - section2.5\n\n  - name: 2.6 Bind Mount the /var/tmp directory to /tmp (Scored)\n    mount: name=\"/var/tmp\" src=\"/tmp\" opts=bind state=mounted fstype=ext4\n    when: partitioning == True\n    tags:\n      - section2\n      - section2.6\n\n  - name: 2.7 Create Separate Partition for /var/log (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var/log\"\n    tags:\n      - section2\n      - section2.7\n\n  - name: 2.8 Create Separate Partition for /var/log/audit (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var/log/audit\"\n    tags:\n      - section2\n      - section2.8\n\n  - name: 2.9 Create Separate Partition for /home (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /home\"\n    tags:\n      - section2\n      - section2.9\n\n  - name: 2.10 Add nodev Option to /home (Scored)\n    mount: name=\"/home\" src=\"/home\" state=mounted opts=remount,nodev fstype=\"ext4\"\n    when: partitioning == True\n    tags:\n      - section2\n      - section2.10\n\n  - name: 2.11 Add nodev Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nodev option\"\n    tags:\n      - section2\n      - section2.11\n\n  - name: 2.12 Add noexec Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have noexec option\"\n    tags:\n      - section2\n      - section2.12\n\n  - name: 2.13 Add nosuid Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nosuid option\"\n    tags:\n      - section2\n      - section2.13\n\n  - name: 2.14 - 16 Add nodev Option to /run/shm Partition (Scored)\n    mount: name=\"/run/shm\" src=\"/run/shm\" state=\"mounted\" opts=\"nodev,nosuid,noexec\" fstype=\"tmpfs\"\n    when: run_shm_read_only == False\n    tags:\n      - section2\n      - section2.14\n      - section2.15\n      - section2.16\n\n  - name: 2.17.1 Set Sticky Bit on All World-Writable Directories (preparation) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type d -perm -0002 -print 2>/dev/null\n    failed_when: False\n    changed_when: False\n    always_run: True\n    register: sticky_bit_dirs\n    tags:\n      - section2\n      - section2.17\n      - section2.17.1\n\n  - name: 2.17.2 Set Sticky Bit on All World-Writable Directories (Scored)\n    file: path='{{ item }}' mode=\"a+t\"\n    with_items: sticky_bit_dirs.stdout_lines\n    tags:\n      - section2\n      - section2.17\n      - section2.17.2\n\n  - name: 2.25 Disable Automounting (stat) (Scored)\n    stat: >\n        path=/etc/init/autofs.conf\n    register: autofs_file\n    tags:\n      - section2\n      - section2.25\n      \n  - name: 2.25 Disable Automounting (Scored)\n    lineinfile: >\n        dest=/etc/init/autofs.conf\n        line='#start on runlevel [2345]'\n        regexp='start on runlevel'\n        state=present\n    when: autofs_file.stat.exists == True\n    tags:\n      - section2\n      - section2.25\n"}, {"commit_sha": "c91b6076e3a957fb0a165131d0ff3b3b208ed419", "sha": "fbb96546071be36bc0ab85da1eaf587ab24f55f0", "filename": "meta/main.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "2cfa28fd756194b32e320ab9c0df1e455f27dc38", "decoded_content": "---\n\nallow_duplicates: no\n\n\ngalaxy_info:\n  author: Aur\u00e9lien Wailly\n  description: Ansible role to meet CIS (Center for Internet Security) requirements on ubuntu\n  license: GPLv2\n  min_ansible_version: 1.6\n  platforms:\n    - name: Ubuntu\n      versions:\n        14.04\n  categories:\n    #- cloud\n    #- cloud:ec2\n    #- cloud:gce\n    #- cloud:rax\n    #- clustering\n    #- database\n    #- database:nosql\n    #- database:sql\n    #- development\n    - monitoring\n    #- networking\n    #- packaging\n    - system\n    #- web\n\n\n\ndependencies: []\n"}, {"commit_sha": "95a0ffb87f5a5ecbf178ee4a5b4f890acaba6cbe", "sha": "15ae2bd7e4e3f8b8028e6b2339f0ba7062a3aaeb", "filename": "tasks/rpm_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "1224adf2811c827a09ff0bf133fbb476901a547d", "decoded_content": "---\n\n- name: Setup RPM specific variables (set_fact)\n  set_fact:\n    tor_user: toranon\n    tor_ConfDir: /etc/tor\n    tor_RunAsDaemon: 0\n  tags:\n   - reconfigure\n   - renewkey\n\n- name: Ensure tor package is installed (dnf)\n  become: yes\n  dnf: name=tor,libselinux-python,libsemanage-python state=present\n  when: ansible_pkg_mgr == 'dnf'\n  notify: re-gather facts\n\n# re-gathering facts after installing libselinux-python on F23\n# is a workaround for https://github.com/ansible/ansible-modules-core/issues/2432\n- meta: flush_handlers\n\n- name: Ensure EPEL repo is installed (yum)\n  become: yes\n  yum: name=epel-release\n  when: ansible_pkg_mgr == 'yum'\n\n- name: Ensure tor package is installed (yum)\n  become: yes\n  yum: name=tor,libsemanage-python state=present\n  when: ansible_pkg_mgr == 'yum'\n\n- name: Ensure SELinux boolean (tor_can_network_relay) is set appropriately (Fedora)\n  become: yes\n  seboolean: name=tor_can_network_relay state=yes persistent=yes\n  when: ansible_selinux.status == 'enabled'\n\n"}, {"commit_sha": "584d564218d6e2e63d3ecca157daf817fe4d533c", "sha": "855667b99059b585b7dccf1f6cb7e71e9890daa2", "filename": "meta/main.yml", "repository": "mikolak-net/ansible-raspi-config", "release_starts_at": null, "release_ends_at": "3d62ad13598da398a7b54cd7b215e6ccaea2cb6a", "decoded_content": "---\ngalaxy_info:\n  author: Miko\u0142aj Koziarkiewicz\n  description: Sets up basic configuration for a headless Raspberry Pi Raspbian server.\n  company: miko\u0142ak\n  license: BSD\n  min_ansible_version: 1.8\n  platforms:\n  - name: Raspbian\n  categories:\n  - development\n  - system\ndependencies:\n  - { role: \"knopki.locale\", version: \"v1.0.3\", locale_all: \"{{raspi_config_locale}}\" }\n  - { role: \"Stouts.timezone\", version: \"2.0.1\", timezone_timezone: \"{{raspi_config_timezone}}\" }\n  - { role: \"Stouts.hostname\", version: \"1.0.3\", hostname_hostname: \"{{raspi_config_hostname}}\" }"}, {"commit_sha": "82993d4cbc4985706cf9b863952976637c72e367", "sha": "4d624c44ee0106f6af3200f782beac175b0c5baa", "filename": "tasks/section_09_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "2cfa28fd756194b32e320ab9c0df1e455f27dc38", "decoded_content": "---\n\n  - name: 9.1.1.1 Check that cron conf file exists (check) (Scored)\n    stat: path=/etc/init/cron.conf\n    register: cron_conf_stat\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.1\n\n  - name: 9.1.1.2 Enable cron Daemon (Scored)\n    service: >\n        name=cron\n        state=started\n        enabled=yes\n    when: not cron_conf_stat.stat.exists\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.2\n\n  - name: 9.1.2 Set User/Group Owner and Permission on /etc/crontab (Scored)\n    file: path='/etc/crontab' owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.2\n\n  - name: 9.1.3 Set User/Group Owner and Permission on /etc/cron.hourly (Scored)\n    file: path=/etc/cron.hourly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.3\n\n  - name: 9.1.4 Set User/Group Owner and Permission on /etc/cron.daily (Scored)\n    file: path=/etc/cron.daily owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.4\n\n  - name: 9.1.5 Set User/Group Owner and Permission on /etc/cron.weekly(Scored)\n    file: path=/etc/cron.weekly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.5\n\n  - name: 9.1.6 Set User/Group Owner and Permission on /etc/cron.monthly(Scored)\n    file: path=/etc/cron.monthly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.6\n\n  - name: 9.1.7 Set User/Group Owner and Permission on /etc/cron.d (Scored)\n    file: path=/etc/cron.d owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.7\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (remove deny) (Scored)\n    file: path={{ item }} state=absent\n    with_items:\n        - /etc/cron.deny\n        - /etc/at.deny\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (stat cron allow) (Scored)\n    stat: path=/etc/cron.allow\n    register: cron_allow_path\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation create cron) (Scored)\n    shell: touch /etc/cron.allow\n    when: cron_allow_path.stat.exists == False\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (create cron allow) (Scored)\n    file: path=/etc/cron.allow owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (stat at allow) (Scored)\n    stat: path=/etc/at.allow\n    register: at_allow_path\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation create at) (Scored)\n    shell: touch /etc/at.allow\n    when: at_allow_path.stat.exists == False\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (create at allow) (Scored)\n    file: path=/etc/at.allow owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.2.1 Set Password Creation Requirement Parameters Using pam_cracklib (install) (Scored)\n    apt: name=libpam-cracklib state=present\n    when: use_pam_cracklib == True\n    tags:\n      - section9\n      - section9.2\n      - section9.2.1\n\n  - name: 9.2.1 Set Password Creation Requirement Parameters Using pam_cracklib (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password'\n        regexp=\"pam_cracklib.so\"\n        line=\"password required pam_cracklib.so retry=3 minlen=14 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1\"\n        state=present\n    when: use_pam_cracklib == True\n    tags:\n      - section9\n      - section9.2\n      - section9.2.1\n\n#Note for section 9.2.2:\n#If a user has been locked out because they have reached the maximum consecutive failure count\n#defined by denied= in the pam_tally2.so module, the user can be unlocked by issuing the command\n#/sbin/pam_tally2 -u username --reset\n#This command sets the failed count to 0, effectively unlocking the user\n  - name: 9.2.2 Set Lockout for Failed Password Attempts (Not Scored)\n    lineinfile: >\n        dest='/etc/pam.d/login'\n        regexp='pam_tally2'\n        line=\"auth required pam_tally2.so onerr=fail audit silent deny=5 unlock_time=900\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.2\n\n  - name: 9.2.3 Limit Password Reuse (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password'\n        regexp='remember=5'\n        line=\"password sufficient pam_unix.so remember=5\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.3\n\n  - name: 9.3 Check if ssh is installed (check) (Not Scored)\n    stat: path='/etc/ssh/sshd_config'\n    register: ssh_config_file\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n\n  - name: 9.3.1 Set SSH Protocol to 2 (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Protocol'\n        state=present\n        line='Protocol 2'\n    when: ssh_config_file.stat.exists == True\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n  - name: 9.3.2 Set LogLevel to INFO (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^LogLevel'\n        state=present\n        line='LogLevel INFO'\n    when: ssh_config_file.stat.exists == True\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.2\n\n  - name: 9.3.3 Set Permissions on /etc/ssh/sshd_config (Scored)\n    file: path='/etc/ssh/sshd_config' owner=root group=root mode=600\n    when: ssh_config_file.stat.exists == True\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.3\n\n#Regroups sections 9.3.4 9.3.7 9.3.8 9.3.9 9.3.10\n  - name: 9.3.{4,7,8,9,10} Disable some SSH options (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^{{ item }}'\n        line='{{ item }} no'\n        state=present\n    with_items:\n      - X11Forwarding\n      - HostbasedAuthentication\n      - PermitRootLogin\n      - PermitEmptyPasswords\n      - PermitUserEnvironment\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.4\n      - section9.3.7\n      - section9.3.8\n      - section9.3.9\n      - section9.3.10\n\n  - name: 9.3.5 Set SSH MaxAuthTries to 4 or Less (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^MaxAuthTries'\n        line='MaxAuthTries 4'\n        state=present\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.5\n\n  - name: 9.3.6 Set SSH IgnoreRhosts to Yes (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^IgnoreRhosts'\n        line='IgnoreRhosts yes'\n        state=present\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.6\n\n  - name: 9.3.11 Use Only Approved Cipher in Counter Mode (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Ciphers'\n        line='Ciphers aes128-ctr,aes192-ctr,aes256-ctr'\n        state=present\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.11\n\n  - name: 9.3.12.1 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveInterval'\n        line='ClientAliveInterval 300'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.1\n\n  - name: 9.3.12.2 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveCountMax'\n        line='ClientAliveCountMax 0'\n        state=present\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.2\n\n  - name: 9.3.13.1 Limit Access via SSH (Scored)\n    shell: grep AllowUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.1\n\n  - name: 9.3.13.2 Limit Access via SSH (Scored)\n    shell: grep AllowGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.2\n\n  - name: 9.3.13.3 Limit Access via SSH (Scored)\n    shell: grep DenyUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.3\n\n  - name: 9.3.13.4 Limit Access via SSH (Scored)\n    shell: grep DenyGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.4\n\n  - name: 9.3.14 Set SSH Banner (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Banner'\n        line='Banner /etc/issue.net'\n        state=present\n    notify: restart ssh\n    tags:\n      - section9\n      - section9.3\n      - section9.3.14\n\n  - name: 9.4 Restrict root Login to System Console (stat securetty) (Not Scored)\n    stat: path=/etc/securetty\n    register: securetty_file\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.4 Restrict root Login to System Console (Not Scored)\n    debug: msg='*** Check /etc/securetty for console allowed for root access ***'\n    when: securetty_file.stat.exists == True\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.5.1 Restrict Access to the su Command (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/su'\n        line='auth            required        pam_wheel.so use_uid'\n        state=present\n    tags:\n      - section9\n      - section9.5\n      - section9.5.1\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "5dfba28358408db871316d05ded3388319b22c2d", "filename": "roles/zookeeper/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# defaults file for zookeeper\nzookeeper_config_dir: \"/etc/zookeeper/conf\"\nzookeeper_image: \"mesosphere/mesos:0.25.0-0.2.70.ubuntu1404\"\nzookeeper_client_port: 2181\nzookeeper_leader_connect_port: 2888\nzookeeper_leader_election_port: 3888\nzookeeper_server_group: zookeeper_servers\nzookeeper_id: \"\n\t{%- if zookeeper_host_list is defined -%}\n\t\t{%- for host in zookeeper_host_list.split() -%}\n\t\t\t{%- if host == ansible_eth0.ipv4.address -%}\n\t        \t{{ loop.index }}\n\t\t\t{%- endif -%}\n\t\t{%- endfor -%}\n\t{%- else -%}\n    \t{%- for host in groups[zookeeper_server_group] -%}\n      \t\t{%- if host == 'default' or host == inventory_hostname or host == ansible_fqdn or host in ansible_all_ipv4_addresses -%}\n        \t\t{{ loop.index }}\n  \t\t\t{%- endif -%}\n    \t{%- endfor -%}\n    {%- endif -%}\n\"\nconsul_dir: /etc/consul.d\n"}, {"commit_sha": "694a4890fcf0daa375d6a173511f6ff7dd0f2335", "sha": "7c24c1737e454eff74d4b604cb1cc552ee207af1", "filename": "tasks/freebsd_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "1224adf2811c827a09ff0bf133fbb476901a547d", "decoded_content": "---\n\n- name: Setup FreeBSD specific variables (set_fact)\n  set_fact:\n    tor_DataDir: /var/db/tor-instances\n    tor_ConfDir: /usr/local/etc/tor/enabled\n  tags:\n   - reconfigure\n   - renewkey\n   - createdir\n\n- name: Ensure Tor is installed (FreeBSD)\n  become: yes\n  pkgng: name=tor state=present\n  tags:\n   - install\n\n- name: Ensure sequential IP IDs are avoided (net.inet.ip.random_id)\n  become: yes\n  sysctl: name=net.inet.ip.random_id value=1 reload=no sysctl_set=yes\n  tags:\n    - freebsdkern\n\n- name: Gather current kern.ipc.somaxconn setting (FreeBSD)\n  shell: \"sysctl kern.ipc.somaxconn|cut -d' '  -f2\"\n  register: currentsomaxconn\n  tags:\n   - freebsdkern\n\n- name: Ensure somaxconn setting is reasonable (FreeBSD)\n  become: yes\n  sysctl: name=kern.ipc.somaxconn value={{ freebsd_somaxconn }} reload=no sysctl_set=yes\n  when: currentsomaxconn.stdout|int < {{ freebsd_somaxconn }}\n  tags:\n   - freebsdkern\n\n- name: Gather current kern.ipc.nmbclusters setting (FreeBSD)\n  shell: \"sysctl kern.ipc.nmbclusters|cut -d' '  -f2\"\n  register: currentnmbc\n  tags:\n   - freebsdkern\n\n- name: Ensure nmbclusters setting is reasonable (FreeBSD)\n  become: yes\n  sysctl: name=kern.ipc.nmbclusters value={{ freebsd_nmbclusters }} reload=no sysctl_set=yes\n  when: currentnmbc.stdout|int < {{ freebsd_nmbclusters }}\n  tags:\n   - freebsdkern\n"}, {"commit_sha": "f5364b57f100ae9fa898af59b7812ec0c447ac42", "sha": "78583afe5f1453e6a8f7401926a0eba5bf729c13", "filename": "tasks/ip-list.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "1224adf2811c827a09ff0bf133fbb476901a547d", "decoded_content": "---\n\n# workaround for this ansible IPv6 filter bug\n# https://github.com/ansible/ansible/issues/14829\n# we simply convert False to empty lists\n- name: workaround for ansible bug 14829 (1/3)\n  set_fact:\n    v6tmp: []\n  when: v6tmp == False\n\n- name: workaround for ansible bug 14829 (2/3)\n  set_fact:\n    tor_v6ips: \"{{ v6tmp[0:ipv4_count|int]|ipv6('address') }}\"\n\n- name: workaround for ansible bug 14829 (3/3)\n  set_fact:\n    tor_v6ips: []\n  when: tor_v6ips == False\n\n- name: setup IP list (1/2)\n  set_fact:\n    ips:\n        ipv4: \"{{ item.0 }}\"\n        ipv6: \"{{ item.1 }}\"\n  with_together:\n        - \"{{ tor_v4ips }}\"\n        - \"{{ tor_v6ips }}\"\n  register: ipsinterm\n\n- name: setup IP list (2/2)\n  set_fact:\n    tor_ips: \"{{ ipsinterm.results | map(attribute='ansible_facts.ips')|list}}\"\n"}, {"commit_sha": "f565940c5163524c7834123625c804e5f69c2b10", "sha": "54210b2f00ac4db12939c1f4e788fcee4e5b025f", "filename": "tasks/client.yml", "repository": "sensu/sensu-ansible", "release_starts_at": null, "release_ends_at": "9b3cb140022faf899910398013334755c8050175", "decoded_content": "---\n# tasks/client.yml: Deploy various client-side configurations for Sensu\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Deploy Sensu client service configuration\n    template:\n      dest: \"{{ sensu_config_path }}/conf.d/client.json\"\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n      src: \"{{ sensu_client_config  }}\"\n    notify: restart sensu-client service\n\n  - include: SmartOS/client.yml\n    when: ansible_distribution == \"SmartOS\"\n\n  - name: Ensure Sensu client service is running\n    service: name=sensu-client state=started enabled=yes\n"}, {"commit_sha": "21712b74b7f5d936e70186bbed6bb37e3a7ad5e6", "sha": "8bffc5ad2003a02b37382c60ad7513793c023526", "filename": "roles/zookeeper/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n\n# Generate config files in the host\n- name: create zookeeper config directory\n  file:\n    path: \"{{ zookeeper_config_dir }}\"\n    state: directory\n    follow: yes\n    mode: 0755\n  sudo: yes\n  tags:\n    - zookeeper\n\n- name: Create zookeeper config file\n  template:\n    src: zoo.cfg.j2\n    dest: \"{{ zookeeper_config_dir }}/zoo.cfg\"\n  sudo: yes\n  notify:\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: Create zookeeper environments file\n  template:\n    src: environment.j2\n    dest: \"{{ zookeeper_config_dir }}/environment\"\n  sudo: yes\n  notify:\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: Create zookeeper configuration.xsl file\n  template:\n    src: configuration.xsl.j2\n    dest: \"{{ zookeeper_config_dir }}/configuration.xsl\"\n  sudo: yes\n  notify:\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: Create zookeeper myid file\n  copy:\n    content: \"{{ zookeeper_id }}\"\n    dest: \"{{ zookeeper_config_dir }}/myid\"\n    mode: 0644\n  sudo: yes\n  notify:\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: Create zookeeper log4j file\n  template:\n    src: log4j.properties.j2\n    dest: \"{{ zookeeper_config_dir }}/log4j.properties\"\n  sudo: yes\n  notify:\n    - restart zookeeper\n  tags:\n    - zookeeper\n\n- name: Set Zookeeper consul service definition\n  sudo: yes\n  template:\n    src: zookeeper-consul.j2\n    dest: \"{{ consul_dir }}/zookeeper.json\"\n  notify:\n    - restart consul\n  tags:\n    - zookeeper\n\n- name: run zookeeper container\n  docker:\n    name: zookeeper\n    image: \"mesosphere/mesos:0.23.0-1.0.ubuntu1404\"\n    state: started\n    volumes:\n    - \"{{ zookeeper_config_dir }}/:{{ zookeeper_config_dir }}/\"\n    ports:\n    - \"{{ zookeeper_client_port }}:{{ zookeeper_client_port }}\"\n    - \"{{ zookeeper_leader_connect_port }}:{{ zookeeper_leader_connect_port }}\"\n    - \"{{ zookeeper_leader_election_port }}:{{ zookeeper_leader_election_port }}\"\n    net: \"host\"\n    command: /usr/share/zookeeper/bin/zkServer.sh start-foreground\n  tags:\n    - zookeeper\n\n- name: upload zookeeper template service\n  template:\n    src: zookeeper.conf.j2\n    dest: /etc/init/zookeeper.conf\n    mode: 0755\n  sudo: yes\n  tags:\n    - zookeeper\n\n- name: ensure zookeeper is running (and enable it at boot)\n  sudo: yes\n  service:\n    name: zookeeper\n    state: started\n    enabled: yes\n  tags:\n    - zookeeper\n\n"}, {"commit_sha": "4e9fdb819a1d7565413b47dca677f7811946668d", "sha": "b0ba2addf7d7a07686c6ffa9965c8294cf04ee2d", "filename": "roles/consul/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": null, "release_ends_at": "dfa8978dc272945b9b4fce761c4bb23af2dd6653", "decoded_content": "---\n# tasks file for consul\n- name: remove consul override\n  command: /bin/rm -f /etc/init/consul.override\n\n- name: configure consul\n  sudo: yes\n  template: src=consul.json.j2 dest=/etc/consul.d/consul.json owner=root group=root mode=0644\n  notify:\n    - Restart consul\n  tags:\n    - consul\n\n- name: configure atlas for consul\n  sudo: yes\n  template: src=atlas.json.j2 dest=/etc/consul.d/atlas.json owner=root group=root mode=0644\n  when: consul_atlas_join\n  notify:\n    - Restart consul\n  tags:\n    - consul\n\n- name: start consul\n  service: name=consul state=started\n\n- name: remove consul-join override\n  command: /bin/rm -f /etc/init/consul-join.override\n  when: consul_join is defined\n\n- name: configure consul-join\n  sudo: yes\n  template: src=consul-join.j2 dest=/etc/service/consul-join owner=root group=root mode=0644\n  notify:\n    - Restart consul\n  when: consul_join is defined\n  tags:\n    - consul\n"}, {"commit_sha": "5eb44163b7f6328c1f30168fa86326458d5dbaff", "sha": "ec32b1eb3c804dcb0176a41a339d8493b59c69cb", "filename": "meta/main.yml", "repository": "ansiblebit/oracle-java", "release_starts_at": null, "release_ends_at": "7e4facb9477ad92d61bc998d4118eba4283b0a3d", "decoded_content": "---\n# file: oracle-java/meta/main.yml\n#\n# meta file\n#\ngalaxy_info:\n  author: Pedro Salgado\n  description: Role to install Oracle Java.\n  company: ansiblebit.org\n  license: BSD\n  min_ansible_version: 1.9.3\n  platforms:\n    - name: CentOS\n      versions:\n        - all\n        - any\n        - 7\n        - 6\n    - name: Debian\n      versions:\n        - jessie\n        - wheezy\n    - name: MacOSX\n      versions:\n        - 10.10.2\n        - 10.10.1\n        - 10.9.5\n        - 10.9.4\n        - 10.9.3\n        - 10.9.2\n        - 10.9.1\n    - name: RedHat\n      versions:\n        - all\n        - any\n        - 7\n        - 6\n    - name: Ubuntu\n      versions:\n        - vivid\n        - trusty\n        - precise\n  categories:\n    - development\n    - system\ndependencies:\n  - role: ansiblebit.launchpad-ppa-webupd8\n    when: (ansible_distribution | lower == 'debian') or (ansible_distribution | lower == 'ubuntu')\n"}, {"commit_sha": "9966c6de1ed4ef5071a9bea83b4bb69a11dd32ba", "sha": "0adfcd9fb43be4df51aa32629d759bea5a62b9cc", "filename": "roles/weave/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# tasks file for weave\n- name: include all interfaces.d\n  sudo: yes\n  lineinfile: \"dest=/etc/network/interfaces state=present line='source /etc/network/interfaces.d/*.cfg'\"\n  notify:\n    - Restart networking\n  tags:\n    - weave\n\n- name: Start up docker\n  service: name=docker state=started\n  tags:\n    - weave\n\n- name: configure weave\n  sudo: yes\n  template: src=interfaces.j2 dest=/etc/network/interfaces.d/weave.cfg owner=root group=root mode=0644\n  tags:\n    - weave\n\n- name: bring up weave bridge\n  shell: ifup weave\n  sudo: yes\n  tags:\n    - weave\n\n- name: configure weave bridge for docker\n  sudo: yes\n  lineinfile: \"dest=/etc/default/docker state=present regexp=^DOCKER_OPTS= line='DOCKER_OPTS=\\\"{{ weave_docker_opts }}\\\"'\"\n  notify:\n    - Restart docker\n    - Weave launch\n  tags:\n    - weave\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "c1e5766953f29fecd2341796ca7a50925bfe6c99", "filename": "roles/st2/tasks/config_auth.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": null, "release_ends_at": "2d0f3f1cf5d5919432c94bb3659c16b85d1cb1db", "decoded_content": "- name: Config proxy auth\n  sudo: true\n  lineinfile:\n    dest: /etc/st2/st2.conf\n    regexp: \"^{{ item.option }}\\\\s*=\"\n    value: \"{{ item.option }} = {{ item.value }}\"\n  with_items:\n    - option: mode\n      value: proxy\n  when: \"st2_auth_username is undefined\"\n  notify:\n    - restart st2\n\n- name: Config stanalone auth\n  sudo: true\n  lineinfile:\n    dest: /etc/st2/st2.conf\n    regexp: \"^{{ item.option }}\\\\s*=\"\n    value: \"{{ item.option }} = {{ item.value }}\"\n  with_items:\n    - option: mode\n      value: standalone\n    - option: backend\n      value: flat_file\n    - option: backend_kwargs\n      value: \"{\\\"file_path\\\": \\\"/etc/st2/htpasswd\\\"}\"\n  when: \"st2_auth_username is defined\"\n  notify:\n    - restart st2\n\n- name: Create htpasswd file\n  sudo: true\n  htpasswd:\n    path: /etc/st2/htpasswd\n    name: \"{{ st2_auth_username }}\"\n    password: \"{{ st2_auth_password }}\"\n  when: \"st2_auth_username is defined\"\n"}, {"commit_sha": "d6b9aef3a890db0fa37a2812da7b3aa1b418c15f", "sha": "e82e1a86a91d2e32ca7b1b0bb8cf9a700b98f21b", "filename": "tasks/section_04_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "2cfa28fd756194b32e320ab9c0df1e455f27dc38", "decoded_content": "---\n\n  - name: Determines if grub is used\n    stat: path=/boot/grub/grub.cfg\n    register: grub_cfg_file\n\n  - name: Determines if extlinux is used\n    stat: path=/extlinux.conf\n    register: extlinux_cfg_file\n\n  - name: 4.5 Activate AppArmor (install) (Scored)\n    apt: >\n        name=apparmor\n        state=present\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (Kernel LSM - grub)\n    lineinfile: >\n        dest='/etc/default/grub'\n        regexp='^GRUB_CMDLINE_LINUX=\"\"'\n        line='GRUB_CMDLINE_LINUX=apparmor=\"1 security=apparmor\"'\n        state=present\n    when: use_apparmor == True and grub_cfg_file.stat.exists\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (Kernel LSM - extlinux)\n    lineinfile: >\n        dest='/extlinux.conf'\n        regexp=\"^append initrd=\"\n        line=\"append initrd={{ ansible_cmdline['initrd'] }} root={{ ansible_cmdline['root'] }} console=tty0 console={{ ansible_cmdline['console'] }} apparmor=1 security=apparmor ro quiet\"\n    when: use_apparmor == True and extlinux_cfg_file.stat.exists\n    tags:\n      - section4\n      - section4.5\n  \n  - name: 4.5 Activate AppArmor (start) (Scored)\n    service: >\n        name=apparmor\n        state=started\n    when: use_apparmor == True\n    register: apparmor_status\n    ignore_errors: True\n    tags:\n      - section4\n      - section4.5\n\n  - name: Determine if Apparmor started without error\n    fail: msg=\"Apparmor can not be started. This is normal behavior if you run the playbook for the first time. Please run it again to proceed with the rest of the playbook.\"\n    when: apparmor_status.state != \"started\"\n\n  - name: 4.5 Activate AppArmor (fix profiles) (Scored)\n    service: >\n        name=rsyslog\n        state=restarted\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (Scored)\n    command: apparmor_status\n    register: aa_status_lines\n    failed_when: '\"0 profiles are loaded\" in aa_status_lines.stdout_lines or \"0 processes are in complain mode.\" not in aa_status_lines.stdout_lines or \"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n        # - '\"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n    changed_when: False\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (enforce install) (Scored)\n    apt: >\n        name=apparmor-utils\n        state=present\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (enforce) (Scored)\n    #shell: 'aa-enforce /etc/apparmor.d/*'\n    shell: for profile in /etc/apparmor.d/*; do aa-enforce $profile; done\n    register: aaenforce_rc\n    failed_when: aaenforce_rc.rc == 1\n    changed_when: False\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n"}, {"commit_sha": "fa66f2d6f5193cce5c2f9086e78f9bff39133e60", "sha": "b94910d066d3d639c7732d139e75d3a013cd06cb", "filename": "tasks/freebsd_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "1224adf2811c827a09ff0bf133fbb476901a547d", "decoded_content": "---\n\n- name: Setup FreeBSD specific variables (set_fact)\n  set_fact:\n    tor_DataDir: /var/db/tor\n    tor_ConfDir: /usr/local/etc/tor/enabled\n  tags:\n   - reconfigure\n   - renewkey\n   - createdir\n\n- name: Ensure Tor is installed (FreeBSD)\n  become: yes\n  pkgng: name=tor state=present\n\n# temporary solution until rc.d supports multiple instances\n- name: Ensure Tor starts at boot (FreeBSD)\n  become: yes\n  lineinfile: dest=/etc/rc.local line=\"/usr/local/bin/tor -f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\" create=yes\n  with_nested:\n   - tor_ips\n   - tor_ports\n\n- name: If LogDir is a file, rename it (FreeBSD)\n  become: yes\n  shell: \"test -f {{ tor_LogDir }} && mv {{ tor_LogDir }} {{ tor_LogDir }}.bk-`date '+%Y-%m-%d_%H%M%S'`\"\n  ignore_errors: yes\n\n- name: Ensure sequential IP IDs are avoided (net.inet.ip.random_id)\n  become: yes\n  sysctl: name=net.inet.ip.random_id value=1 reload=no sysctl_set=yes\n  tags:\n    - freebsdkern\n\n- name: Gather current kern.ipc.somaxconn setting (FreeBSD)\n  shell: \"sysctl kern.ipc.somaxconn|cut -d' '  -f2\"\n  register: currentsomaxconn\n  tags:\n   - freebsdkern\n\n- name: Ensure somaxconn setting is reasonable (FreeBSD)\n  become: yes\n  command: \"sysctl kern.ipc.somaxconn={{ freebsd_somaxconn }}\"\n  when: currentsomaxconn.stdout|int < {{ freebsd_somaxconn }}\n  tags:\n   - freebsdkern\n\n- name: Ensure somaxconn setting in sysctl.conf is reasonable (FreeBSD)\n  become: yes\n  lineinfile: dest=/etc/sysctl.conf regexp=^kern.ipc.somaxconn line=\"kern.ipc.somaxconn={{ freebsd_somaxconn }}\" create=yes\n  when: currentsomaxconn.stdout|int < {{ freebsd_somaxconn }}\n  tags:\n   - freebsdkern\n\n- name: Gather current kern.ipc.nmbclusters setting (FreeBSD)\n  shell: \"sysctl kern.ipc.nmbclusters|cut -d' '  -f2\"\n  register: currentnmbc\n  tags:\n   - freebsdkern\n\n- name: Ensure nmbclusters setting is reasonable (FreeBSD)\n  become: yes\n  command: \"sysctl kern.ipc.nmbclusters={{ freebsd_nmbclusters }}\"\n  when: currentnmbc.stdout|int < {{ freebsd_nmbclusters }}\n  tags:\n   - freebsdkern\n\n- name: Ensure nmbclusters setting in sysctl.conf is reasonable (FreeBSD)\n  become: yes\n  lineinfile: dest=/etc/sysctl.conf regexp=^kern.ipc.nmbclusters line=\"kern.ipc.nmbclusters={{ freebsd_nmbclusters }}\" create=yes\n  when: currentnmbc.stdout|int < {{ freebsd_nmbclusters }}\n  tags:\n   - freebsdkern\n"}, {"commit_sha": "15d2da095f9bd54a50954dee18597710e1951943", "sha": "a0ee4554872ba19f1bae880e66f883591e2c20de", "filename": "tasks/redhat/main.yml", "repository": "ansiblebit/oracle-java", "release_starts_at": null, "release_ends_at": "7e4facb9477ad92d61bc998d4118eba4283b0a3d", "decoded_content": "---\n# file: oracle-java/tasks/redhat/main.yml\n#\n# Task file to install Oracle Java Development Kit in a system with a Redhat based Linux distribution.\n#\n\n- name: download Java RPM\n  get_url:\n    headers='Cookie:gpw_e24=http%3A%2F%2Fwww.oracle.com%2F; oraclelicense=accept-securebackup-cookie'    dest=\"{{ oracle_java_dir_source }}/{{ oracle_java_rpm_filename }}\"\n    url=\"{{ oracle_java_rpm_url }}\"\n    validate_certs=\"{{ oracle_java_rpm_validate_certs }}\"\n  register: oracle_java_task_rpm_download\n  become: yes\n  tags: [ installation ]\n\n- name: install RPM\n  action: \"{{ ansible_pkg_mgr }} name={{ oracle_java_dir_source }}/{{ oracle_java_rpm_filename }} state=present\"\n  when: not oracle_java_task_rpm_download|skipped\n  become: yes\n  tags: [ installation ]\n\n- name: set Java version as default\n  alternatives:\n    name=\"{{ item.exe }}\"\n    link=\"/usr/bin/{{ item.exe }}\"\n    path=\"{{ item.path }}/{{ item.exe }}\"\n  with_items:\n    - { path: \"{{ oracle_java_home }}/jre/bin\", exe: 'java' }\n    - { path: \"{{ oracle_java_home }}/jre/bin\", exe: 'keytool' }\n    - { path: \"{{ oracle_java_home }}/bin\", exe: 'javac' }\n    - { path: \"{{ oracle_java_home }}/bin\", exe: 'javadoc' }\n  become: yes\n  when: (\n          oracle_java_set_as_default and\n          oracle_java_task_rpm_download is defined and\n          oracle_java_task_rpm_download|changed\n        ) or (\n          oracle_java_set_as_default and\n          oracle_java_installed is defined and\n          oracle_java_installed and\n          oracle_java_version_installed is defined and\n          oracle_java_version_installed != oracle_java_version_string)\n  register: oracle_java_task_set_default\n\n- name: in case there were changes, check host environment again\n  include: ../check_environment.yml\n  when: (\n          oracle_java_task_rpm_download is defined and\n          not oracle_java_task_rpm_download|skipped\n        ) or (\n          oracle_java_task_set_default is defined and\n          oracle_java_task_set_default|changed\n        )\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "0d5179e1c4fdda1bd5b8f6ae1cbe069aada0041f", "filename": "roles/rabbitmq/tasks/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": null, "release_ends_at": "2d0f3f1cf5d5919432c94bb3659c16b85d1cb1db", "decoded_content": "- name: Ensure rabbitmq repo\n  sudo: true\n  apt_repository:\n    repo: deb http://www.rabbitmq.com/debian/ testing main\n\n- name: Ensure rabbitmq repo key\n  sudo: true\n  apt_key:\n    url: http://www.rabbitmq.com/rabbitmq-signing-key-public.asc\n\n- name: Install rabbitmq packages\n  sudo: true\n  apt:\n    name: \"{{ item }}\"\n    update_cache: true\n  with_items:\n    - rabbitmq-server\n\n- name: Enable rabbitmq_management plugin\n  sudo: true\n  rabbitmq_plugin:\n    names: rabbitmq_management\n  notify:\n    - restart rabbitmq\n\n- meta: flush_handlers\n\n- name: Install rabbitmqadmin\n  sudo: true\n  get_url:\n    url: http://127.0.0.1:15672/cli/rabbitmqadmin\n    dest: /usr/bin/rabbitmqadmin\n    mode: 0755\n"}, {"commit_sha": "e8eb28b4b4b1c4fb2490b8198570166b9ca23ab2", "sha": "537462cb851c20764b0ed17856421e0c31e4cf25", "filename": "roles/mistral/tasks/config.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": null, "release_ends_at": "2d0f3f1cf5d5919432c94bb3659c16b85d1cb1db", "decoded_content": "- name: Copy Mistral config\n  sudo: true\n  copy:\n    src: mistral.conf\n    dest: /etc/mistral/mistral.conf\n\n- name: Copy Mistral log config\n  sudo: true\n  command: cp /opt/openstack/mistral/etc/wf_trace_logging.conf.sample /etc/mistral/wf_trace_logging.conf creates=/etc/mistral/wf_trace_logging.conf\n\n- name: Change Mistral log path\n  sudo: true\n  lineinfile:\n    dest: /etc/mistral/wf_trace_logging.conf\n    regexp: '^args=\\(\"/var/log/mistral.log'\n    line: 'args=(\"/var/log/mistral/mistral.log\",)'\n\n- name: Change Mistral trace path\n  sudo: true\n  lineinfile:\n    dest: /etc/mistral/wf_trace_logging.conf\n    regexp: '^args=\\(\"/var/log/mistral_wf_trace.log'\n    line: 'args=(\"/var/log/mistral/mistral_wf_trace.log\",)'\n\n- name: Create init config\n  sudo: true\n  template:\n    src: init.j2\n    dest: /etc/init/mistral.conf\n  notify:\n    - restart mistral\n\n- name: Enable the service\n  sudo: true\n  service:\n    name: mysql\n    enabled: yes\n"}, {"commit_sha": "c0a575a4d0d5cd8c461b6388abf28ee3a245fd42", "sha": "63ac61ba0eb1469da4db8bef429232eeab4fef3e", "filename": "tasks/cloudsight_setup.yml", "repository": "threatstack/threatstack-ansible", "release_starts_at": "", "release_ends_at": "", "release": "75580f72159e180dd1e97bbcf5870293a9ee5e36", "decoded_content": "---\n\n# Cloudsight Setup\n- name: Create Threat Stack Config Directory\n  file: path=\"{{ threatstack_config_dir }}\" state=directory owner=root group=root mode=0644 recurse=yes\n\n- name: Create ThreatStack Config File\n  template:\n    src: templates/config.j2\n    dest: \"{{ threatstack_config }}\"\n    owner: root\n    group: root\n    mode: 0644\n\n- name: Cloudsight - setup default\n  command: cloudsight setup --config=\"{{ threatstack_config }}\"\n  register: setup_result\n  failed_when: setup_result.stderr and 'FAILED' in setup_result.stderr\n  args:\n    creates: /opt/threatstack/cloudsight/config/.secret\n\n# Test\n- name: Test cloudsight state\n  service:\n    name: cloudsight\n    enabled: yes\n    state: started\n"}, {"commit_sha": "f565940c5163524c7834123625c804e5f69c2b10", "sha": "08e5b8916317e39131130b8f727a7961e84ae694", "filename": "tasks/main.yml", "repository": "sensu/sensu-ansible", "release_starts_at": null, "release_ends_at": "9b3cb140022faf899910398013334755c8050175", "decoded_content": "---\n# tasks/main.yml: \"Master\" playbook for the cmacrae.sensu role\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - include: \"{{ ansible_distribution }}/main.yml\"\n    tags: setup\n\n  - include: redis.yml\n    tags: redis\n    when: redis_server\n          and sensu_deploy_redis\n\n  - include: ssl.yml\n    tags: ssl\n\n  - include: rabbit.yml\n    tags: rabbitmq\n    when: rabbitmq_server\n          and sensu_deploy_rabbitmq\n\n  - include: common.yml\n    tags: common\n\n  - include: server.yml\n    tags: server\n    when: sensu_master\n\n  - include: dashboard.yml\n    tags: dashboard\n    when: sensu_include_dashboard\n\n  - include: client.yml\n    tags: client\n\n  - include: plugins.yml\n    tags: plugins\n    when: sensu_include_plugins\n"}, {"commit_sha": "addbee435e20e706e7cf5d2f0a3723e17f79b527", "sha": "8aa41302ca674ac79a3655e6e1a4c1a0a6acbda7", "filename": "tasks/section_07_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "2cfa28fd756194b32e320ab9c0df1e455f27dc38", "decoded_content": "---\n\n  - name: 7.1.1 Disable IP Forwarding (Scored)\n    sysctl: >\n      name=net.ipv4.ip_forward\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.1\n\n  - name: 7.1.2.1 Disable Send Packet Redirects (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.2\n      - section7.1.2.1\n\n  - name: 7.1.2.2 Disable Send Packet Redirects (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.1\n      - section7.1.2\n      - section7.1.2.2\n\n  - name: 7.2.1 Modify Network Parameters (Host and Router)\n    sysctl: >\n      name=net.ipv4.conf.all.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.1\n\n  - name: 7.2.2 Modify Network Parameters (Host and Router)\n    sysctl: >\n      name=net.ipv4.conf.default.send_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.2\n\n  - name: 7.2.1.1 Disable Source Routed Packet Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.accept_source_route\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.1\n      - section7.2.1.1\n\n  - name: 7.2.1.2 Disable Source Routed Packet Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.accept_source_route\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.1\n      - section7.2.1.2\n\n  - name: 7.2.2.1 Disable ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.2\n      - section7.2.2.1\n\n  - name: 7.2.2.2 Disable ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.2\n      - section7.2.2.2\n\n  - name: 7.2.3.1 Disable Secure ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.secure_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.3\n      - section7.2.3.1\n\n  - name: 7.2.3.2 Disable Secure ICMP Redirect Acceptance (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.secure_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.3\n      - section7.2.3.2\n\n  - name: 7.2.4.1 Log Suspicious Packets (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.log_martians\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.4\n      - section7.2.4.1\n\n  - name: 7.2.4.2 Log Suspicious Packets (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.log_martians\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.4\n      - section7.2.4.2\n\n  - name: 7.2.5 Enable Ignore Broadcast Requests (Scored)\n    sysctl: >\n      name=net.ipv4.icmp_echo_ignore_broadcasts\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.5\n\n  - name: 7.2.6 Enable Bad Error Message Protection (Scored)\n    sysctl: >\n      name=net.ipv4.icmp_ignore_bogus_error_responses\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.6\n\n  - name: 7.2.7.1 Enable RFC-recommended Source Route Validation (Scored)\n    sysctl: >\n      name=net.ipv4.conf.all.rp_filter\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.7\n      - section7.2.7.1\n\n  - name: 7.2.7.2 Enable RFC-recommended Source Route Validation (Scored)\n    sysctl: >\n      name=net.ipv4.conf.default.rp_filter\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.7\n      - section7.2.7.2\n\n  - name: 7.2.8 Enable TCP SYN Cookies (Scored)\n    sysctl: >\n      name=net.ipv4.tcp_syncookies\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.2\n      - section7.2.8\n\n  - name: 7.3 Configure IPv6\n    sysctl: >\n      name=net.ipv4.tcp_syncookies\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n\n  - name: 7.3.1.1 Disable IPv6 Router Advertisements (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.all.accept_ra\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.1\n      - section7.3.1.1\n\n  - name: 7.3.1.2 Disable IPv6 Router Advertisements (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.default.accept_ra\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.1\n      - section7.3.1.2\n\n  - name: 7.3.2.1 Disable IPv6 Redirect Acceptance (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.all.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.2\n      - section7.3.2.1\n\n  - name: 7.3.2.2 Disable IPv6 Redirect Acceptance (Not Scored)\n    sysctl: >\n      name=net.ipv6.conf.default.accept_redirects\n      value=0\n      state=present\n    tags:\n      - section7\n      - section7.3\n      - section7.3.2\n      - section7.3.2.2\n\n  - name: 7.3.3 Disable IPv6 (Not Scored)\n    sysctl: >\n      name={{ item }}\n      value=1\n      state=present\n    with_items:\n      - net.ipv6.conf.all.disable_ipv6\n      - net.ipv6.conf.default.disable_ipv6\n      - net.ipv6.conf.lo.disable_ipv6\n    when: travis_env == False\n    tags:\n      - section7\n      - section7.3\n      - section7.3.3\n\n  - name: 7.4.1 Install TCP Wrappers (Scored)\n    apt: name=tcpd state=present\n    tags:\n      - section7\n      - section7.4\n      - section7.4.1\n\n  - name: 7.4.2 Create /etc/hosts.allow (Not Scored)\n    debug: msg=\"*** Verify /etc/hosts.allow ***\"\n    tags:\n      - section7\n      - section7.4\n      - section7.4.2\n\n  - name: 7.4.3 Verify Permissions on /etc/hosts.allow (Scored)\n    file: >\n        path=/etc/hosts.allow\n        owner=root\n        group=root\n        mode=0644\n    tags:\n      - section7\n      - section7.4\n      - section7.4.3\n\n  - name: 7.4.4 Create /etc/hosts.deny (Not Scored)\n    debug: msg='*** Verify /etc/hosts.deny ***'\n    tags:\n      - section7\n      - section7.4\n      - section7.4.4\n\n  - name: 7.4.5 Verify Permissions on /etc/hosts.deny (Scored)\n    file: >\n        path=/etc/hosts.deny\n        owner=root\n        group=root\n        mode=0644\n    tags:\n      - section7\n      - section7.4\n      - section7.4.5\n\n  - name: Check the presence of the file \"cis.conf\" under modprobe.d\n    stat: >\n        path=/etc/modprobe.d/CIS.conf\n    register: cis_conf_file\n    tags:\n      - section7\n      - section7.5\n\n  - name: Create the file \"cis.conf\" under modprobe.d if doesn't exist\n    file: >\n        dest=/etc/modprobe.d/CIS.conf state=touch\n    when: not cis_conf_file.stat.exists\n    tags:\n      - section7\n      - section7.5\n\n  - name: 7.5.1-4 Disable DCCP, SCTP, RDS, TIPC (Not Scored)\n    lineinfile: >\n        dest=/etc/modprobe.d/CIS.conf\n        line='install {{ item }} /bin/true'\n        state=present\n    with_items:\n        - dccp\n        - sctp\n        - rds\n        - tipc\n    tags:\n      - section7\n      - section7.5\n      - section7.5.1\n      - section7.5.2\n      - section7.5.3\n      - section7.5.4\n\n  - name: 7.6 Deactivate Wireless Interfaces (Not Scored)\n    shell: 'lspci -k | grep -i wifi'\n    changed_when: False\n    register: lspci_wifi\n    failed_when: lspci_wifi.rc == 0\n    tags:\n      - section7\n      - section7.6\n\n  - name: 7.7 Ensure Firewall is active (install) (Scored)\n    apt: >\n        name=ufw\n        state=present\n    when: activate_ufw\n    tags:\n      - section7\n      - section7.7\n\n  - name: 7.7 Ensure Firewall is active (Scored)\n    service: >\n        name=ufw\n        state=started\n    when: activate_ufw\n    tags:\n      - section7\n      - section7.7\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "88f46b0cf5b92c4d624ba4dc94e10db2a3e0c2a1", "filename": "roles/mongodb/tasks/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": null, "release_ends_at": "2d0f3f1cf5d5919432c94bb3659c16b85d1cb1db", "decoded_content": "- name: Install dependencies\n  sudo: true\n  apt:\n    name: \"{{ item }}\"\n    update_cache: yes\n    state: present\n  with_items:\n    - mongodb\n    - mongodb-server\n"}, {"commit_sha": "dc73f16743fa376672b427980c6ca044dd6fa68a", "sha": "40346e75357413acfbbf0797c8fb7bbd824b466b", "filename": "handlers/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "1224adf2811c827a09ff0bf133fbb476901a547d", "decoded_content": "---\n- name: stop-and-mask default tor instance\n  become: yes\n  shell: systemctl stop tor@default && systemctl mask tor@default\n  when: ansible_pkg_mgr == 'apt'\n\n- name: restart apparmor\n  become: yes\n  service: name=apparmor state=restarted\n\n- name: systemctl daemon-reload\n  become: yes\n  command: systemctl daemon-reload\n\n- name: re-gather facts\n  setup:\n  when: ansible_pkg_mgr == 'dnf'\n\n- name: disable default tor instance FreeBSD\n  become: yes\n  lineinfile:\n    dest: /etc/rc.conf\n    line: \"tor_disable_default_instance=\\\"YES\\\"\"\n    create: yes\n  when: ansible_system == 'FreeBSD'\n\n# TODO: this reloads all instances on a FreeBSD host even if just one torrc changed\n- name: Ensure Tor instances are reloaded if its torrc changed (FreeBSD)\n  become: yes\n  service:\n    name: tor\n    state: reloaded\n  when: ansible_system == 'FreeBSD'\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "d64038473437f1ed08189396ec04e65845069ca7", "filename": "roles/cadvisor/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# defaults file for cadvisor\ncadvisor_enabled: true\ncadvisor_version: 'latest'\ncadvisor_restart_policy: 'always'\ncadvisor_net: 'bridge'\ncadvisor_hostname: \"{{ ansible_ssh_host }}\"\ncadvisor_image: \"google/cadvisor:{{ cadvisor_version }}\"\ncadvisor_consul_dir: /etc/consul.d\ncadvisor_consul_service_id: \"{{ ansible_hostname }}:cadvisor:8080\"\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "7e72feee24b0becb4ee95e7a656cbe1f4983c553", "filename": "roles/zookeeper/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\nconsul_dir: /etc/consul.d\nzookeeper_rebuild_container: false\nzookeeper_config_dir: /etc/zookeeper/conf\nzookeeper_image: \"mesosphere/mesos:0.26.0-0.2.145.ubuntu1404\"\nzookeeper_client_port: 2181\nzookeeper_leader_connect_port: 2888\nzookeeper_leader_election_port: 3888\nzookeeper_server_group: zookeeper_servers\nzookeeper_id: \"\n\t{%- if zookeeper_host_list is defined -%}\n\t\t{%- for host in zookeeper_host_list.split() -%}\n\t\t\t{%- if host == ansible_eth0.ipv4.address -%}\n\t        \t{{ loop.index }}\n\t\t\t{%- endif -%}\n\t\t{%- endfor -%}\n\t{%- else -%}\n    \t{%- for host in groups[zookeeper_server_group] -%}\n      \t\t{%- if host == 'default' or host == inventory_hostname or host == ansible_fqdn or host in ansible_all_ipv4_addresses -%}\n        \t\t{{ loop.index }}\n  \t\t\t{%- endif -%}\n    \t{%- endfor -%}\n    {%- endif -%}\n\"\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "25fc22a196134bf3a60fa48878cd021518e41af5", "filename": "roles/st2/tasks/3.user.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": null, "release_ends_at": "2d0f3f1cf5d5919432c94bb3659c16b85d1cb1db", "decoded_content": "# Create system user, on whose behalf remote/local action runners would work\n# See: http://docs.stackstorm.com/install/config.html#configure-ssh\n---\n- name: user | Create system user\n  sudo: yes\n  user:\n    name: \"{{ st2_system_user }}\"\n    home: \"/home/{{ st2_system_user }}\"\n    generate_ssh_key: yes\n    ssh_key_file: \"{{ st2_ssh_key_file }}\"\n    state: present\n  register: _user\n  tags: [st2, user]\n\n- name: user | Authorize key-based access for system user\n  sudo: yes\n  sudo_user: \"{{ st2_system_user }}\"\n  authorized_key:\n    user: \"{{ st2_system_user }}\"\n    key: \"{{ _user.ssh_public_key }}\"\n    state: present\n  tags: [st2, user]\n\n- name: user | Add system user to sudoers\n  sudo: yes\n  lineinfile:\n    create: yes\n    dest: /etc/sudoers.d/st2\n    mode: 0440\n    regexp: \"^{{ st2_system_user }} ALL=\"\n    line: \"{{ st2_system_user }} ALL=(ALL) NOPASSWD: SETENV: ALL\"\n    state: \"{{ 'present' if st2_system_user_in_sudoers else 'absent' }}\"\n    validate: 'visudo -cf %s'\n  tags: [st2, user]\n"}, {"commit_sha": "1818facd0a58a2b42203a403130b71825b960653", "sha": "9fcc07fae0acf7b39eef728b3f9208f6f113e5d2", "filename": "tasks/section_12_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "2cfa28fd756194b32e320ab9c0df1e455f27dc38", "decoded_content": "---\n\n  - name: 12.1 Verify Permissions on /etc/passwd (Scored)\n    file: path=/etc/passwd mode=0644\n    tags:\n      - section12\n      - section12.1\n\n  - name: 12.2 Verify Permissions on /etc/shadow (Scored)\n    file: path=/etc/shadow mode='o-rwx,g-rw'\n    tags:\n      - section12\n      - section12.2\n\n  - name: 12.3 Verify Permissions on /etc/group (Scored)\n    file: path=/etc/group mode=0644\n    tags:\n      - section12\n      - section12.3\n\n  - name: 12.4 Verify User/Group Ownership on /etc/passwd (Scored)\n    file: path=/etc/passwd owner=root group=root\n    tags:\n      - section12\n      - section12.4\n\n  - name: 12.5 Verify User/Group Ownership on /etc/shadow (Scored)\n    file: path=/etc/shadow owner=root group=shadow\n    tags:\n      - section12\n      - section12.5\n\n  - name: 12.6 Verify User/Group Ownership on /etc/group (Scored)\n    file: path=/etc/group owner=root group=root\n    tags:\n      - section12\n      - section12.6\n\n  - name: 12.7 Find World Writable Files (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -0002 -print\n    changed_when: False\n    failed_when: False\n    register: world_files\n    tags:\n      - section12\n      - section12.7\n\n  - name: 12.7 Find World Writable Files (Not Scored)\n    debug: msg=\"{{ item }}\"\n    with_items:\n        world_files.stdout_lines\n    tags:\n      - section12\n      - section12.7\n\n  - name: 12.8 Find Un-owned Files and Directories (check) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -nogroup -ls\n    changed_when: False\n    failed_when: False\n    register: unowned_files\n    tags:\n      - section12\n      - section12.8\n\n  - name: 12.8 Find Un-owned Files and Directories (Scored)\n    debug: msg=\"{{ item }}\"\n    with_items:\n        unowned_files.stdout_lines\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.9 Find Un-grouped Files and Directories (check) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -nogroup -ls\n    changed_when: False\n    failed_when: False\n    register: ungrouped_files\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.9 Find Un-grouped Files and Directories (Scored)\n    debug: >\n        msg=\"{{ item }}\"\n    with_items:\n        ungrouped_files.stdout_lines\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.10 Find SUID System Executables (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -4000 -print\n    changed_when: False\n    failed_when: False\n    register: suid_files\n    tags:\n      - section12\n      - section12.10\n\n  - name: 12.10 Find SUID System Executables (Not Scored)\n    debug: msg=\"{{ item }}\"\n    with_items:\n        suid_files.stdout_lines\n    tags:\n      - section12\n      - section12.10\n\n  - name: 12.11 Find SGID System Executables (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -2000 -print\n    changed_when: False\n    failed_when: False\n    register: gsuid_files\n    tags:\n      - section12\n      - section12.11\n\n  - name: 12.11 Find SGID System Executables (Not Scored)\n    debug: msg=\"{{ item }}\"\n    with_items:\n        gsuid_files.stdout_lines\n    tags:\n      - section12\n      - section12.10\n"}, {"commit_sha": "9966c6de1ed4ef5071a9bea83b4bb69a11dd32ba", "sha": "ca18a240a92dff966b9605d5c6edefc85a7f5a49", "filename": "roles/zookeeper/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "- name: ensure zookeeper is running (and enable it at boot)\n  service: name=zookeeper state=started enabled=yes\n\n- name: Create zookeeper config file\n  template: src=zoo.cfg.j2 dest=/etc/zookeeper/conf/zoo.cfg\n  sudo: yes\n  notify:\n    - Restart zookeeper\n\n- name: Create zookeeper myid file\n  copy:\n    content: \"{{zookeeper_id}}\"\n    dest: /etc/zookeeper/conf/myid\n    mode: 0644\n  sudo: yes\n  notify:\n    - Restart zookeeper\n\n- name: Set Zookeeper consul service definition\n  sudo: yes\n  template:\n    src: zookeeper-consul.j2\n    dest: \"{{ consul_dir }}/zookeeper.json\"\n  notify:\n    - Restart consul\n"}, {"commit_sha": "23dde94de0a1355bc5a9d83fb2d424f136f05fa2", "sha": "f9d6357bd88da2901cc627814657a8ebd322424e", "filename": "roles/weave/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n- name: download weave\n  become: yes\n  become_user: root\n  get_url:\n    url: \"{{ weave_url }}\"\n    dest: \"{{ weave_bin }}\"\n    mode: 0755\n    validate_certs: no\n    force: true\n  environment: \"{{ proxy_env }}\"\n  tags:\n    - weave\n\n- name: deploy weave service\n  become: yes\n  become_user: root\n  template:\n    src: \"{{ item.src }}\"\n    dest: \"{{ item.dest }}\"\n  with_items:\n    - src: weave.service.j2\n      dest: /etc/systemd/system/weave.service\n    - src: weaveproxy.service.j2\n      dest: /etc/systemd/system/weaveproxy.service\n  notify:\n    - systemd reload\n    - restart weave\n    - restart weaveproxy\n  tags:\n    - weave\n\n- name: ensure weave service is running.\n  become: yes\n  service:\n    name: weave\n    state: started\n    enabled: yes\n  tags:\n    - weave\n\n- name: ensure weaveproxy service is running.\n  become: yes\n  service:\n    name: weaveproxy\n    state: started\n    enabled: yes\n  tags:\n    - weave\n\n- name: wait for weave socket to be ready.\n  wait_for:\n    port: 6783\n    delay: 10\n\n# Flush handlers so we restart the Docker process here with the weave network\n# enabled and containers correctly start in the weave network.\n- meta: flush_handlers\n\n# scope\n- include: scope.yml\n  when: scope_enabled|bool\n"}, {"commit_sha": "8af8d9f258ac145b451e2f0db433e5e9ad335ea2", "sha": "a012a05c604e8630539f75866ccc5027da0594aa", "filename": "tasks/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "1224adf2811c827a09ff0bf133fbb476901a547d", "decoded_content": "---\n\n- name: Check for vulnerable ansible version (CVE-2016-8614, CVE-2016-8628)\n  assert:\n    that:\n      - \"{{ ansible_version.full | version_compare('2.1.3.0', '>=') }}\"\n    msg: \"VULNERABLE ansible version DETECTED, please update to v2.1.3 or newer! Exiting.\"\n  run_once: true\n  delegate_to: 127.0.0.1\n  tags:\n    - always\n\n- name: Check for local requirements\n  shell: tor --version && sha1sum --version && sort --version && uniq --version && wc --version && cut --version\n  run_once: true\n  delegate_to: 127.0.0.1\n  tags:\n    - always\n\n- name: Set OS specific variables\n  include_vars: \"{{ ansible_os_family }}.yml\"\n  tags:\n   - always\n\n- include: ip-list.yml\n  tags:\n    - always\n\n- include: apt_prepare.yml\n  when: ansible_pkg_mgr == 'apt'\n  tags:\n   - debian\n   - install\n\n- include: rpm_prepare.yml\n  when: ansible_os_family == 'RedHat'\n  tags:\n   - centos\n   - fedora\n   - install\n\n- include: openbsd_prepare.yml\n  when: ansible_system == 'OpenBSD'\n  tags:\n   - openbsd\n\n- include: freebsd_prepare.yml\n  when: ansible_system == 'FreeBSD'\n  tags:\n   - freebsd\n\n# we specifically opt for present over latest to improve performance\n- name: Ensure tor is installed\n  become: yes\n  package:\n    name: \"{{ item }}\"\n    state: present\n  with_items: \"{{ tor_packages }}\"\n  # apt starts a tor client instance by default after installing the package\n  # we do not need that\n  notify:\n    - stop-and-mask default tor instance\n    - disable default tor instance FreeBSD\n  tags:\n   - openbsd\n   - freebsd\n   - debian\n   - centos\n   - fedora\n   - install\n\n- meta: flush_handlers\n\n- include: configure.yml\n  tags:\n   - debian\n   - centos\n   - fedora\n   - openbsd\n   - freebsd\n\n- include: linux_service.yml\n  when: ansible_system == 'Linux'\n  tags:\n   - debian\n   - centos\n   - fedora\n\n- include: openbsd_service.yml\n  when: ansible_system == 'OpenBSD'\n  tags:\n   - openbsd\n\n- include: freebsd_service.yml\n  when: ansible_system == 'FreeBSD'\n  tags:\n   - freebsd\n"}, {"commit_sha": "9966c6de1ed4ef5071a9bea83b4bb69a11dd32ba", "sha": "60a381501712819c3af73310067f1743eab23b80", "filename": "roles/haproxy/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# tasks file for haproxy\n- name: assures {{ consul_template_dir }} dirs exists\n  file: path={{ consul_template_dir }}/{{ item.path }} state=directory\n  with_items:\n    - { path: 'config' }\n    - { path: 'templates' }\n\n- name: upload template config files\n  template: src=consul.cfg.j2 dest=\"{{ consul_template_dir }}/config/consul.cfg\" mode=0644\n  sudo: yes\n\n- name: upload static config files\n  copy: src={{ item.src }} dest=\"{{ consul_template_dir }}/{{ item.dst }}\" mode=0644\n  sudo: yes\n  with_items:\n    - { src: haproxy.cfg, dst: 'config/haproxy.cfg' }\n    - { src: haproxy.tmpl, dst: 'templates/haproxy.tmpl' }\n\n- name: run haproxy container\n  docker:\n    name: haproxy\n    image: \"{{ haproxy_image }}\"\n    state: started\n    net: host\n    restart_policy: always\n    ports:\n      - \"80:80\"\n    env:\n      HAPROXY_DOMAIN: \"{{ haproxy_domain }}\"\n      CONSUL_TEMPLATE_VERSION: \"{{ consul_template_version }}\"\n      CONSUL_LOGLEVEL: \"{{ consul_template_loglevel }}\"\n      CONSUL_CONNECT: \"{{ consul_backend }}\"\n      CONSUL_CONFIG: \"/config\"\n      SERVICE_NAME: haproxy\n    volumes:\n    - \"{{ consul_template_dir }}/config:/config\"\n    - \"{{ consul_template_dir }}/templates:/templates\"\n"}, {"commit_sha": "a774d7f239841cdb705317557a11935ca87238ad", "sha": "9e1d764954b1764f0488be762559cced09980e9b", "filename": "tasks/section_08_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "2cfa28fd756194b32e320ab9c0df1e455f27dc38", "decoded_content": "---\n\n  - name: Check if the file auditd.conf exists\n    stat: >\n        path=/etc/audit/auditd.conf\n    register: auditd_file\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n\n  - name: Create the audit directory if it does not exists\n    file: >\n        path=/etc/audit/\n        state=directory\n    when: not auditd_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n\n  - name: 8.1.1-3 Configure Data Retention\n    lineinfile: >\n        dest=/etc/audit/auditd.conf\n        regexp=\"{{ item.rxp }}\"\n        line=\"{{ item.line }}\"\n        state=present\n        create=yes\n    with_items:\n      - { rxp: '^max_log_file ', line: 'max_log_file = {{ Max_Log_File }}' }\n      - { rxp: '^space_left_action', line: 'space_left_action = email' }\n      - { rxp: '^action_mail_acct', line: 'action_mail_acct = root' }\n      - { rxp: '^admin_space_left_action', line: 'admin_space_left_action = halt' }\n      - { rxp: '^max_log_file_action', line: 'max_log_file_action = keep_logs' }\n    notify: restart auditd\n    tags:\n      - section8\n      - section8.1\n      - section8.1.1\n      - section8.1.1.1\n      - section8.1.1.2\n      - section8.1.1.3\n\n  - name: 8.1.2 Install and Enable auditd Service (Scored)\n    apt: name=auditd state=present\n    tags:\n      - section8\n      - section8.1\n      - section8.1.2\n      - section8.1.2\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    stat: path=/etc/default/grub\n    register: grubcfg_file\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    file: >\n        path=/etc/default/grub\n        state=touch\n    when: not grubcfg_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.3 Enable Auditing for Processes That Start Prior to auditd (Scored)\n    lineinfile: >\n        dest=/etc/default/grub\n        line='GRUB_CMDLINE_LINUX=\"audit=1\"'\n    when: not grubcfg_file.stat.exists\n    tags:\n      - section8\n      - section8.1\n      - section8.1.3\n\n  - name: 8.1.4 Record Events That Modify Date and Time Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a always,exit -F arch=b64 -S adjtimex -S settimeofday -k time-change'\n      - '-a always,exit -F arch=b32 -S adjtimex -S settimeofday -S stime -k time-change'\n      - '-a always,exit -F arch=b64 -S clock_settime -k time-change'\n      - '-a always,exit -F arch=b32 -S clock_settime -k time-change'\n      - '-w /etc/localtime -p wa -k time-change'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"64\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.4\n\n  - name: 8.1.4 Record Events That Modify Date and Time Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line={{ item }}\n      state=present\n      create=yes\n    with_items:\n      - '-a always,exit -F arch=b32 -S adjtimex -S settimeofday -S stime -k time-change'\n      - '-a always,exit -F arch=b32 -S clock_settime -k time-change'\n      - '-w /etc/localtime -p wa -k time-change'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"32\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.4\n\n  - name: 8.1.5,7,8,9,15,16,17 Record Events That Modify User/Group Information (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-w /etc/group -p wa -k identity'\n      - '-w /etc/passwd -p wa -k identity'\n      - '-w /etc/gshadow -p wa -k identity'\n      - '-w /etc/shadow -p wa -k identity'\n      - '-w /etc/security/opasswd -p wa -k identity'\n      - '-w /var/log/faillog -p wa -k logins'\n      - '-w /var/log/lastlog -p wa -k logins'\n      - '-w /var/log/tallylog -p wa -k logins'\n      - '-w /var/run/utmp -p wa -k session'\n      - '-w /var/log/wtmp -p wa -k session'\n      - '-w /var/log/btmp -p wa -k session'\n      - '-w /etc/selinux/ -p wa -k MAC-policy'\n      - '-w /etc/sudoers -p wa -k scope'\n      - '-w /var/log/sudo.log -p wa -k actions'\n      - '-w /sbin/insmod -p x -k modules'\n      - '-w /sbin/rmmod -px -k modules'\n      - '-w /sbin/modprobe -p x -k modules'\n    notify: restart auditd\n    tags:\n      - section8\n      - section8.1\n      - section8.1.5\n      - section8.1.7\n      - section8.1.8\n      - section8.1.9\n      - section8.1.15\n      - section8.1.16\n      - section8.1.17\n\n  - name: 8.1.6,10,11,13,14,17 Record Events That Modify the System's Network Environment (64b) (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a exit,always -F arch=b64 -S sethostname -S setdomainname -k system-locale'\n      - '-a exit,always -F arch=b32 -S sethostname -S setdomainname -k system-locale'\n      - '-w /etc/issue -p wa -k system-locale'\n      - '-w /etc/issue.net -p wa -k system-locale'\n      - '-w /etc/hosts -p wa -k system-locale'\n      - '-w /etc/network -p wa -k system-locale'\n      - '-a always,exit -F arch=b64 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b64 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b64 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b64 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b32 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b64 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b32 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b64 -S init_module -S delete_module -k modules'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"64\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.6\n      - section8.1.10\n      - section8.1.11\n      - section8.1.13\n      - section8.1.14\n      - section8.1.17\n\n  - name: 8.1.6,10,11,13,14,17 Record Events That Modify the System's Network Environment (32b) (Scored)\n    lineinfile: >\n      dest=/etc/audit/audit.rules\n      line='{{ item }}'\n      state=present\n      create=yes\n    with_items:\n      - '-a exit,always -F arch=b32 -S sethostname -S setdomainname -k system-locale'\n      - '-w /etc/issue -p wa -k system-locale'\n      - '-w /etc/issue.net -p wa -k system-locale'\n      - '-w /etc/hosts -p wa -k system-locale'\n      - '-w /etc/network -p wa -k system-locale'\n      - '-a always,exit -F arch=b32 -S chmod -S fchmod -S fchmodat -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S chown -S fchown -S fchownat -S lchown -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S setxattr -S lsetxattr -S fsetxattr -S removexattr -S lremovexattr -S fremovexattr -F auid>=500 -F auid!=4294967295 -k perm_mod'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EACCES -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S creat -S open -S openat -S truncate -S ftruncate -F exit=-EPERM -F auid>=500 -F auid!=4294967295 -k access'\n      - '-a always,exit -F arch=b32 -S mount -F auid>=500 -F auid!=4294967295 -k mounts'\n      - '-a always,exit -F arch=b32 -S unlink -S unlinkat -S rename -S renameat -F auid>=500 -F auid!=4294967295 -k delete'\n      - '-a always,exit -F arch=b32 -S init_module -S delete_module -k modules'\n    notify: restart auditd\n    when: ansible_userspace_bits == \"32\"\n    tags:\n      - section8\n      - section8.1\n      - section8.1.6\n      - section8.1.10\n      - section8.1.11\n      - section8.1.13\n      - section8.1.14\n      - section8.1.17\n\n  - name: 8.1.12 Collect Use of Privileged Commands (Scored)\n    shell: find / -xdev \\( -perm -4000 -o -perm -2000 \\) -type f | awk '{print \"-a always,exit -F path=\" $1 \" -F perm=x -F auid>=500 -F auid!=4294967295 -k privileged\" }'\n    register: audit_lines_for_find\n    changed_when: False\n    tags:\n      - section8\n      - section8.1\n      - section8.1.12\n\n  - name: 8.1.12 Collect Use of Privileged Commands (infos) (Scored)\n    debug: msg=\"Add a line in auditd for the privileged program\"\n    with_items: audit_lines_for_find.stdout_lines\n    tags:\n      - section8\n      - section8.1\n      - section8.1.12\n\n\n  - name: 8.1.18 Make the Audit Configuration Immutable (Scored)\n    lineinfile: >\n        dest='/etc/audit/audit.rules'\n        line='-e 2'\n        insertafter=EOF\n        state=present\n        create=yes\n    tags:\n      - section8\n      - section8.1\n      - section8.1.18\n\n  - name: 8.3.1 Install AIDE (Scored)\n    apt: name=aide state=present\n    register: aide_installed\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (init) (Scored)\n    command: aideinit\n    when: aide_installed.changed == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (Scored)\n    stat: path=/var/lib/aide/aide.db.new\n    register: aide_db_path\n    when:\n      - aide_installed.changed == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.1 Install AIDE (copy db) (Scored)\n    command: mv /var/lib/aide/aide.db.new /var/lib/aide/aide.db\n    when:\n      - aide_installed.changed == True\n      - aide_db_path.stat.exists == True\n    tags:\n      - section8\n      - section8.3\n      - section8.3.1\n\n  - name: 8.3.2 Implement Periodic Execution of File Integrity (Scored)\n    cron: name=\"Check files integrity\" minute=\"0\" hour=\"5\" job=\"/usr/sbin/aide --check\"\n    tags:\n      - section8\n      - section8.3\n      - section8.3.2\n"}, {"commit_sha": "dc73f16743fa376672b427980c6ca044dd6fa68a", "sha": "2b4c15fae72a68917e00cd3beabe860375f16abf", "filename": "tasks/linux_service.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "1224adf2811c827a09ff0bf133fbb476901a547d", "decoded_content": "---\n\n# Linux/systemd section (uses service module)\n# ===========================================\n\n- name: Ensure Tor instances are reloaded if its torrc changed (Linux/systemd)\n  become: yes\n  service:\n    name: \"tor@{{ item.item.0.ipv4 }}_{{ item.item.1.orport }}.service\"\n    state: reloaded\n  with_items: \"{{ instances.results }}\"\n  when: item.changed == True\n  tags:\n   - reconfigure\n\n- name: Ensure Tor instances are enabled and started (Linux/systemd)\n  become: yes\n  service:\n    name: \"tor@{{ item.0.ipv4 }}_{{ item.1.orport }}.service\"\n    enabled: yes\n    state: started\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "90403e98f4c7e5141a4ab3b2784ad4f8aff3f368", "filename": "roles/mesos/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# Common\nconsul_dir: /etc/consul.d\nmesos_executor_registration_timeout: 10mins\nmesos_cluster_name: \"Cluster01\"\nmesos_ip: \"{{ ansible_default_ipv4.address }}\"\nmesos_hostname: \"{{ ansible_ssh_host }}\"\nmesos_docker_socket: \"/var/run/weave/weave.sock\"\nmesos_version: \"0.25.0-0.2.70.ubuntu1404\"\n\n# Defaults file for mesos-salve\nmesos_slave_port: 5051\nmesos_containerizers: \"docker,mesos\"\nmesos_resources: \"ports(*):[31000-32000]\"\nmesos_slave_work_dir: \"/tmp/mesos\"\nmesos_slave_image: \"mesosphere/mesos-slave:{{ mesos_version }}\"\n\n# Defaults file for mesos-master\nmesos_zookeeper_group: zookeeper_servers\nmesos_master_port: 5050\nmesos_master_work_dir: \"/var/lib/mesos\"\nmesos_master_image: \"mesosphere/mesos-master:{{ mesos_version }}\"\n\nprometheus_mesos_exporter_image: \"prom/mesos-exporter:latest\"\nprometheus_mesos_exporter_port: 9105\nprometheus_mesos_exporter_consul_service_id: \"{{ ansible_hostname }}:mesos-exporter:{{ prometheus_mesos_exporter_port }}\"\n\n# The Mesos quorum value is based on the number of Mesos Masters. Take the\n# number of masters, divide by 2, and round-up to nearest integer. For example,\n# if there are 1 or 2 masters the quorum count is 1. If there are 3 or 4\n# masters then the quorum count is 2. For 5 or 6 masters it's 3 and so on.\nmesos_quorum: \"\n{% if mesos_master_quorum is defined %}\n{{ mesos_master_quorum }}\n{% else %}\n{{ ( groups.mesos_masters|count / 2) | round(0, 'ceil') | int }}\n{%- endif -%}\n\"\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "0785f82df98b35d30a6dd06e7f9e9942cf3fb42e", "filename": "roles/mistral/meta/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": null, "release_ends_at": "2d0f3f1cf5d5919432c94bb3659c16b85d1cb1db", "decoded_content": "---\ngalaxy_info:\n  description: Install custom OpenStack Mistral, patched by StackStorm\n  author: armab\n  company: StackStorm\n  license: Apache\n  min_ansible_version: 1.9.1\n  platforms:\n    - name: Ubuntu\n      versions:\n        - trusty\n        - precise\n  categories:\n    - system\ndependencies:\n  - role: ANXS.postgresql\n    version: v1.2.1\n    tags: [db, postgresql]\n    sudo: yes\n    postgresql_databases:\n      - name: \"{{ mistral_db }}\"\n    postgresql_users:\n      - name: \"{{ mistral_db_username }}\"\n        pass: \"{{ mistral_db_password }}\"\n        encrypted: yes\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "ccaea962677bdcbe478d994e099ae274f9fca80b", "filename": "roles/st2/tasks/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": null, "release_ends_at": "2d0f3f1cf5d5919432c94bb3659c16b85d1cb1db", "decoded_content": "- include: 1.requirements.yml\n- include: 2.version.yml\n- include: 3.user.yml\n- include: 4.dependencies.yml\n- include: 5.packages.yml\n- include: 6.upstart.yml\n- include: config_auth.yml\n  when: \"'st2auth' in st2_packages\"\n- name: Register content\n  shell: \"python /usr/lib/python2.7/dist-packages/st2common/bin/st2-register-content\n          --config-file /etc/st2/st2.conf --register-all 2>&1\"\n"}, {"commit_sha": "21712b74b7f5d936e70186bbed6bb37e3a7ad5e6", "sha": "da4bbe7a4ab2123e65fe3afe3477deebe13cbed0", "filename": "roles/marathon/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# defaults file for marathon\nmarathon_consul_dir: /etc/consul.d\nmarathon_enabled: true\nmarathon_version: '0.10.1'\nmarathon_restart_policy: 'always'\nmarathon_net: 'host'\nmarathon_hostname: \"{{ ansible_ssh_host }}\"\nmarathon_port: '8080'\nmarathon_container_memory_limit: '512MB'\nmarathon_java_settings: '-Xmx512m -Xms512m -XX:+HeapDumpOnOutOfMemoryError'\nmarathon_artifact_store: 'file:///store'\nmarathon_artifact_store_dir: '/etc/marathon/store'\nmarathon_server_zk_group: marathon_servers\nmarathon_rebuild_container: False\nmarathon_image: \"mesosphere/marathon:v{{ marathon_version }}\"\nmarathon_master_peers: \"zk://{{ zookeeper_peers_nodes }}/mesos\"\nmarathon_zk_peers: \"zk://{{ zookeeper_peers_nodes }}/marathon\"\nmarathon_command: \"--artifact_store {{ marathon_artifact_store }} --hostname {{ marathon_hostname }} --master {{ marathon_master_peers }} --zk {{ marathon_zk_peers }}\"\n"}, {"commit_sha": "6d51642c8f7babe4c8185b60872420333a5d3caa", "sha": "f781a225299e033ae225d179c8dfea2eda33af15", "filename": "tasks/ssl_generate.yml", "repository": "sensu/sensu-ansible", "release_starts_at": null, "release_ends_at": "9b3cb140022faf899910398013334755c8050175", "decoded_content": "---\n# tasks/ssl_generate.yml: Generate SSL data and stash to dynamic\n# data store for deployment to clients\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure Sensu SSL directory exists\n    file:\n      dest: \"{{ sensu_config_path }}/ssl\"\n      state: directory\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n\n  - name: Ensure SSL generation directory exists\n    file:\n      dest: \"{{ sensu_config_path }}/ssl_generation\"\n      state: directory\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n    when: sensu_master\n\n  - block:\n\n    - name: Fetch the ssl_certs tarball from sensuapp.org\n      get_url:\n        url: http://sensuapp.org/docs/{{ sensu_ssl_tool_version }}/files/sensu_ssl_tool.tar\n        dest: \"{{ sensu_config_path }}/ssl_generation/sensu_ssl_tool.tar\"\n\n    - name: Untar the ssl_certs tarball from sensuapp.org\n      unarchive:\n      args:\n        src: \"{{ sensu_config_path }}/ssl_generation/sensu_ssl_tool.tar\"\n        dest: \"{{ sensu_config_path }}/ssl_generation/\"\n        creates: \"{{ sensu_config_path }}/ssl_generation/sensu_ssl_tool\"\n\n    - name: Generate SSL certs\n      command: \"_ {{ sensu_config_path }}/ssl_generation/sensu_ssl_tool/ssl_certs.sh generate\"\n      args:\n        chdir: \"{{ sensu_config_path }}/ssl_generation/sensu_ssl_tool\"\n        creates: \"{{ sensu_config_path }}/ssl_generation/sensu_ssl_tool/server\"\n        executable: \"{{ __bash_path }}\"\n\n    when: sensu_master|bool\n    become: true\n    become_user: \"{{ sensu_user_name }}\"\n\n  - name: Stash the Sensu SSL certs/keys\n    fetch:\n      src: \"{{ sensu_config_path }}/ssl_generation/sensu_ssl_tool/{{ item }}\"\n      dest: \"{{ dynamic_data_store }}\"\n    when: sensu_master\n    with_items:\n      - sensu_ca/cacert.pem\n      - server/cert.pem\n      - server/key.pem\n      - client/cert.pem\n      - client/key.pem\n"}, {"commit_sha": "bf6e08dcb2440421477b6536ff6a8d11adc2be17", "sha": "5f6617e8aa4ba6625c4304b534ca54fce0477f41", "filename": "roles/consul/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# defaults file for consul\nconsul_is_server: no\nconsul_dc: dc1\nconsul_servers_group: consul_servers\nconsul_advertise: \"{{ inventory_hostname }}\"\nconsul_bind_addr: \"{{ ansible_default_ipv4.address }}\"\nconsul_retry_join: \"{% for host in groups[consul_servers_group] %}\\\"{{ hostvars[host].ansible_default_ipv4.address }}\\\"{% if not loop.last %}, {% endif %}{% endfor %}\"\nconsul_bootstrap_expect: \"{{ groups[consul_servers_group] | length }}\"\nconsul_client_addr: \"0.0.0.0\"\nconsul_atlas_join: false\nconsul_node_name: \"{{ ansible_hostname }}\"\n"}, {"commit_sha": "fa66f2d6f5193cce5c2f9086e78f9bff39133e60", "sha": "47d0b3c467647d4a309f7231d0a976906113bee3", "filename": "tasks/configure.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "1224adf2811c827a09ff0bf133fbb476901a547d", "decoded_content": "---\n\n- name: Ensure local key folders exist (LOCAL)\n  file: path={{ offline_masterkey_dir }}/{{ item[0] }}_{{ item.1.orport }}/keys\n    state=directory mode=700\n  delegate_to: 127.0.0.1\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - createdir\n\n- name: Ensure all relay keys exist (LOCAL)\n  local_action: command tor --PublishServerDescriptor 0 --orport 1234 --list-fingerprint --datadirectory \"{{ offline_masterkey_dir }}/{{ item[0] }}_{{ item.1.orport }}\" --Log \"err stdout\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Generate new Ed25519 signing keys\n  local_action: command tor --keygen --SigningKeyLifetime {{ tor_signingkeylifetime_days}}\\ days --datadirectory \"{{ offline_masterkey_dir }}/{{ item[0] }}_{{ item.1.orport }}\" --Log \"err stdout\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - renewkey\n\n- name: Detect duplicate relay keys across relays (LOCAL)\n  shell: sha1sum {{ offline_masterkey_dir }}/*/keys/secret_id_key {{ offline_masterkey_dir }}/*/keys/ed25519_master_id_secret_key|cut -d/ -f1|sort|uniq -d|wc -l\n  delegate_to: 127.0.0.1\n  register: dupcount\n\n- name: Abort on duplicate relay keys\n  fail: msg=\"Duplicate relay key detected! Aborting.\"\n  when: dupcount.stdout != \"0\"\n\n- name: Detect if Ed25519 master keys are on the relay\n  stat: path={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}/keys/ed25519_master_id_secret_key\n  become: yes\n  register: masterkeycheck\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Abort if Ed25519 master keys are on the relay\n  fail: msg=\"\n\n            Ed25519 MASTER KEY detected on the relay - it is NOT supposed to be there! Aborting.\"\n  when: item.stat.exists == True\n  with_items: masterkeycheck.results\n\n- name: Collect fingerprints for MyFamily (LOCAL)\n  shell: cut {{ offline_masterkey_dir }}/*/fingerprint -d\" \" -f2|xargs|sed -e 's/ /,/g'\n  delegate_to: 127.0.0.1\n  register: family\n  tags:\n   - reconfigure\n\n- name: Ensure per-instance tor users exist\n  become: yes\n  user: name=_tor-{{ item[0] }}_{{ item.1.orport }} system=yes shell=/bin/false createhome=no home={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - createdir\n\n- name: Ensure per-instance config folders exist (Debian only)\n  become: yes\n  file: path={{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }} state=directory mode=755\n  with_nested:\n   - tor_ips\n   - tor_ports\n  when: ansible_pkg_mgr == 'apt'\n  tags:\n   - createdir\n\n- name: Ensure DataDir exists\n  become: yes\n  file: path={{ tor_DataDir }}\n    state=directory\n    owner=root\n    mode=0755\n  tags:\n   - createdir\n\n- name: Ensure \"keys\" subfolder exists\n  become: yes\n  file: path={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}/keys\n    state=directory\n    owner=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n    group=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n    mode=0700\n    recurse=yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure RSA key is in place (without overriding existing keys)\n  become: yes\n  copy: src={{ offline_masterkey_dir }}/{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}\n   dest={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}\n   owner=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n   mode=700 force=no\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'secret_id_key' ]\n\n- name: Fetch RSA key for comparision\n  become: yes\n  fetch: src={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}\n    dest={{ offline_masterkey_dir }}/{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}.untrustedremotekey\n    flat=yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'secret_id_key' ]\n\n- name: Compare local vs. remote RSA key (secret_id_key)\n  local_action: shell sha1sum {{ offline_masterkey_dir }}/\"{{ item[0] }}_{{ item.1.orport }}\"/keys/secret_id_key*|cut -d/ -f1|uniq -d|wc -l\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  register: rsakey\n\n- name: Abort if local and remote RSA keys do not match\n  fail: 'msg=\"\n\n\n   Key MISMATCH detected: Remote RSA key does not match local key - manual intervention required.\n\n   We deteted that the remote host uses an RSA key that was not generated by us.\n   We will not override it with our locally generated key.\n\n   If you want to make use of the remote RSA key you have to override the local key manually:\n\n\n   cd ~/.tor/offlinemasterkeys/<IP_port>/keys\n\n   mv secret_id_key.untrustedremotekey secret_id_key\"'\n  when: item.stdout != \"1\"\n  with_items: rsakey.results\n\n# this task is separated from the task named \"Ensure RSA key is in place\" because it is not run with 'force=no'\n- name: Renew Ed25519 signing keys\n  become: yes\n  copy: src={{ offline_masterkey_dir }}/{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}\n   dest={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}\n   owner=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n   mode=700\n   setype=tor_var_lib_t\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'ed25519_master_id_public_key', 'ed25519_signing_cert', 'ed25519_signing_secret_key' ]\n  tags:\n   - renewkey\n\n# This needs to be at the end to fix SELinux contexts recursively\n- name: Ensure per-instance DataDir exists\n  become: yes\n  file: path={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}\n    state=directory\n    owner=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n    group=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n    mode=0700\n    recurse=yes\n    setype=tor_var_lib_t\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - createdir\n\n- name: Ensure Tor config directory exists\n  become: yes\n  file: path={{ tor_ConfDir }}\n    state=directory\n    owner=root\n    group={{ tor_user }}\n    mode=755\n\n- name: Ensure LogDir exists\n  become: yes\n  file: path={{ tor_LogDir }}\n    state=directory\n    owner=root\n    mode=755\n  when: ansible_system != 'Linux'\n\n# we only use distinct logfiles on systems that have no SyslogIdentityTag support yet (all non-Debian plaforms)\n# otherwise we log to syslog with SyslogIdentityTag to avoid the filesystem permissions troubles with logrotate.\n# We aim to log to syslog+SyslogIdentityTag for all platforms eventually.\n# This is a medium-term workaround until all platform get SyslogIdentityTag support\n# without this workaround tor will fail to start after logrotate created new logfiles because\n# logrotate is not not aware that every tor instance runs under a distinct user.\n# This effectively disables logrotate.\n- name: Ensure per-instance LogDir exists\n  become: yes\n  file: path={{ tor_LogDir }}/{{ item[0] }}_{{ item.1.orport }}\n    state=directory\n    owner=_tor-{{ item[0] }}_{{ item.1.orport }}\n    group=_tor-{{ item[0] }}_{{ item.1.orport }}\n    mode=700\n  with_nested:\n   - tor_ips\n   - tor_ports\n  when: ansible_system != 'Linux'\n\n- name: Generating torrc file(s)\n  become: yes\n  template: >\n    src=torrc\n    dest=\"{{ (ansible_pkg_mgr != 'apt')| ternary(tor_ConfDir ~ '/' ~ item[0] ~ '_' ~ item.1.orport ~ '.torrc', tor_ConfDir ~ '/' ~ item[0] ~ '_' ~ item.1.orport ~ '/torrc') }}\"\n    owner=root\n    mode=0644\n    backup=yes\n    validate=\"tor --verify-config -f %s\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n  register: instances\n  tags:\n   - reconfigure\n"}, {"commit_sha": "c7cf019326c96b15ccee3b7bf4e14ff0bb894cf0", "sha": "7713d756b3dc5a7a6f1fb9e778c180f0fdb3fbc0", "filename": "handlers/main.yml", "repository": "willshersystems/ansible-sshd", "release_starts_at": "", "release_ends_at": "", "release": "f68fb55dad755ed4d4296695cd7271c7307e4a56", "decoded_content": "---\n- name: reload_sshd\n  service:\n    name: \"{{ sshd_service }}\"\n    state: reloaded\n  when: sshd_allow_reload == True\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "ae140d18323b3fe634a6438e5d44da538824e5b2", "filename": "roles/cadvisor/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "# tasks for running cadvisor\n- name: run cadvisor container\n  when: cadvisor_enabled\n  docker:\n    name: cadvisor\n    image: \"{{ cadvisor_image }}\"\n    state: started\n    restart_policy: \"{{ cadvisor_restart_policy }}\"\n    net: \"{{ cadvisor_net }}\"\n    hostname: \"{{ cadvisor_hostname }}\"\n    volumes:\n    - \"/var/lib/docker/:/var/lib/docker:ro\"\n    - \"/:/rootfs:ro\"\n    - \"/var/run:/var/run:rw\"\n    - \"/sys:/sys:ro\"\n  tags:\n    - cadvisor\n\n- name: upload cadvisor template service\n  when: cadvisor_enabled\n  template:\n    src: cadvisor.conf.j2\n    dest: /etc/init/cadvisor.conf\n    mode: 0755\n  sudo: yes\n  tags:\n    - cadvisor\n\n# Attach to the running container, or start it if needed\n# and forward all signals so that the process manager can detect\n# when a container stops and correctly restart it.\n- name: ensure cadvisor is running (and enable it at boot)\n  when: cadvisor_enabled\n  sudo: yes\n  service:\n    name: cadvisor\n    state: started\n    enabled: yes\n  tags:\n    - cadvisor\n\n- name: get cadvisor container ip\n  sudo: yes\n  command: >\n    docker inspect -f \\{\\{' '.NetworkSettings.IPAddress' '\\}\\} cadvisor\n  register: cadvisor_container_ip\n  when: cadvisor_enabled\n  tags:\n    - cadvisor\n\n- name: Set cadvisor consul service definition\n  sudo: yes\n  template:\n    src: cadvisor-consul.j2\n    dest: \"{{ cadvisor_consul_dir }}/cadvisor.json\"\n  notify:\n    - restart consul\n  when: cadvisor_enabled\n  tags:\n    - cadvisor\n\n- name: stop cadvisor container\n  when: not cadvisor_enabled\n  sudo: yes\n  service:\n    name: cadvisor\n    state: stopped\n    enabled: yes\n  tags:\n    - cadvisor\n"}, {"commit_sha": "ba9f7d378ad95ef9bb2be6c768dd83e81244b795", "sha": "50f1055eeec963f131685fe2391e8b663082b53e", "filename": "tasks/acl.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": null, "release_ends_at": "6f2fdbaf6a98476a156102c6215391a09c3e6a42", "decoded_content": "---\n# File: acl.yml - ACL tasks for Consul\n\n- block:\n    - name: Read ACL master token from previously boostrapped server\n      command: \"cat {{ consul_config_path }}/config.json\"\n      register: config_read\n      no_log: true\n      run_once: true\n\n    - name: Save acl_master_token from existing configuration\n      set_fact:\n        consul_acl_master_token: \"{{ config_read.stdout | from_json | json_query(query) }}\"\n      vars:\n        query: \"acl.tokens.master\"\n      no_log: true\n\n  when:\n    - bootstrap_state.stat.exists | bool\n    - (consul_acl_master_token is not defined or consul_acl_master_token | length == 0)\n    - consul_node_role == 'server'\n\n- block:\n\n    - name: Generate ACL master token\n      command: \"echo {{ ansible_date_time.iso8601_micro | to_uuid }}\"\n      register: consul_acl_master_token_keygen\n      run_once: true\n\n    - name: Save ACL master token\n      set_fact:\n        consul_acl_master_token: \"{{ consul_acl_master_token_keygen.stdout }}\"\n\n  when:\n    - (consul_acl_master_token is not defined or consul_acl_master_token | length == 0)\n    - not bootstrap_state.stat.exists | bool\n    - consul_node_role == 'server'\n\n- name: Display ACL Master Token\n  debug:\n    msg: \"{{ consul_acl_master_token }}\"\n  run_once: true\n  when:\n    - consul_acl_master_token_display | bool\n    - consul_node_role == 'server'\n\n- block:\n\n    - name: Read ACL replication token from previously boostrapped server\n      shell: >\n        cat {{ consul_config_path }}/config.json |\n        grep \"acl_replication_token\" |\n        sed -E 's/\"acl_replication_token\": \"(.+)\",?/\\1/' |\n        sed 'is/^ *//;s/ *$//'\n      changed_when: false\n      check_mode: false\n      register: consul_acl_replication_token_read\n      run_once: true\n\n    - name: Save acl_replication_token from existing configuration\n      set_fact: consul_acl_replication_token=\"{{ consul_acl_replication_token_read.stdout }}\"\n      ignore_errors: true\n\n  when:\n    - bootstrap_state.stat.exists | bool\n    - (consul_acl_replication_token is not defined or consul_acl_replication_token | length == 0)\n    - consul_node_role == 'server'\n\n- block:\n\n    - name: Generate ACL replication token\n      command: \"echo {{ ansible_date_time.iso8601_micro | to_uuid }}\"\n      register: consul_acl_replication_token_keygen\n      run_once: true\n\n    - name: Save ACL replication token\n      set_fact:\n        consul_acl_replication_token: \"{{ consul_acl_replication_token_keygen.stdout }}\"\n\n  when:\n    - (consul_acl_replication_token is not defined or consul_acl_replication_token | length == 0)\n    - not bootstrap_state.stat.exists | bool\n    - consul_node_role == 'server'\n\n- name: Create ACL policy configuration\n  template:\n    src: configd_50acl_policy.hcl.j2\n    dest: \"{{ consul_configd_path }}/50acl_policy.hcl\"\n    owner: \"{{ consul_user }}\"\n    group: \"{{ consul_group }}\"\n  notify:\n    - restart consul\n  when: consul_acl_policy | bool\n"}, {"commit_sha": "069c7c7848545c132aff3c88fe170cbe30c8abb9", "sha": "e8405f23f63b3dfd46d4792bc039a4b84902fa45", "filename": "roles/mesos/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "# used for leader election amongst masters\n- name: Set ZooKeeper URL\n  template: src=zk.j2 dest=/etc/mesos/zk mode=0644\n  sudo: yes\n\n# Tasks for Master nodes\n- name: Set Mesos Master ip\n  copy:\n    content: \"{{mesos_local_address}}\"\n    dest: /etc/mesos-master/ip\n    mode: 0644\n  sudo: yes\n  when: mesos_install_mode == \"master\"\n\n- name: Set Mesos Master hostname\n  copy:\n    content: \"{{mesos_local_address}}\"\n    dest: /etc/mesos-master/hostname\n    mode: 0644\n  sudo: yes\n  when: mesos_install_mode == \"master\"\n\n  # The Mesos quorum value is based on the number of Mesos Masters. Take the\n  # number of masters, divide by 2, and round-up to nearest integer. For example,\n  # if there are 1 or 2 masters the quorum count is 1. If there are 3 or 4\n  # masters then the quorum count is 2. For 5 or 6 masters it's 3 and so on.\n- name: Set Mesos Master quorum count\n  template: src=quorum.j2 dest=/etc/mesos-master/quorum mode=0644\n  sudo: yes\n  when: mesos_install_mode == \"master\"\n\n- name: remove mesos-master override\n  file: path=/etc/init/mesos-master.override state=absent\n  when: mesos_install_mode == \"master\"\n\n- name: Set Mesos Master Cluster name\n  copy:\n    content: \"{{mesos_cluster_name}}\"\n    dest: /etc/mesos-master/cluster\n    mode: 0644\n  sudo: yes\n  notify:\n    - Start mesos master\n  when: mesos_install_mode == \"master\"\n\n- name: Set Mesos Master consul service definition\n  sudo: yes\n  template:\n    src: mesos-master-consul.j2\n    dest: \"{{ consul_dir }}/mesos-master.json\"\n  notify:\n    - Restart consul\n  when: mesos_install_mode == \"master\"\n\n# Tasks for Slave nodes\n- name: Set Mesos Slave hostname\n  copy:\n    content: \"{{mesos_local_address}}\"\n    dest: /etc/mesos-slave/hostname\n    mode: 0644\n  sudo: yes\n  when: mesos_install_mode == \"slave\"\n\n- name: remove mesos-slave override\n  file: path=/etc/init/mesos-slave.override state=absent\n  when: mesos_install_mode == \"slave\"\n\n- name: set executor registration timeout\n  sudo: yes\n  copy:\n    dest: /etc/mesos-slave/executor_registration_timeout\n    content: \"{{ mesos_executor_registration_timeout }}\"\n  when: mesos_install_mode == \"slave\"\n\n- name: set containerizers\n  sudo: yes\n  copy:\n    dest: /etc/mesos-slave/containerizers\n    content: \"{{ mesos_containerizers }}\"\n  when: mesos_install_mode == \"slave\"\n\n- name: set slave resources\n  sudo: yes\n  copy:\n    dest: /etc/mesos-slave/resources\n    content: \"{{ mesos_resources }}\"\n  when: mesos_install_mode == \"slave\"\n\n- name: Set Mesos Slave ip\n  copy:\n    content: \"{{mesos_local_address}}\"\n    dest: /etc/mesos-slave/ip\n    mode: 0644\n  sudo: yes\n  notify:\n    - Start mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: Create Mesos Slave work area\n  file:\n    dest: \"{{mesos_slave_work_dir}}\"\n    mode: 0755\n    state: directory\n  sudo: yes\n  when: mesos_install_mode == \"slave\"\n\n- name: Set Mesos Slave work area\n  copy:\n    content: \"{{mesos_slave_work_dir}}\"\n    dest: /etc/mesos-slave/work_dir\n    mode: 0644\n  sudo: yes\n  notify:\n    - Start mesos slave\n  when: mesos_install_mode == \"slave\"\n"}, {"commit_sha": "ec4de12ae75f7191a5f71aa775e0344679ea1477", "sha": "3d3be5efd2f10981847a53489a3e689db96deddf", "filename": "tasks/auth_initialization.yml", "repository": "UnderGreen/ansible-role-mongodb", "release_starts_at": "", "release_ends_at": "", "release": "42487b9f4681a078ef82c07c3307a51653a19791", "decoded_content": "---\n\n- include: auth_initialization_ald.yml\n  when: ansible_local.mongodb.mongodb.mongodb_login_port is defined\n\n- name: create administrative user siteRootAdmin\n  mongodb_user:\n    database: admin\n    name: \"{{ item.name }}\"\n    password: \"{{ item.password }}\"\n    roles: \"{{ item.roles }}\"\n    login_host: 127.0.0.1\n  with_items:\n    - {\n      name: \"{{ mongodb_root_admin_name }}\",\n      password: \"{{ mongodb_root_admin_password }}\",\n      roles: \"root\"\n      }\n  register: rootadmin_user_result\n  when: ansible_local.mongodb.mongodb.mongodb_login_port is undefined\n\n- name: create administrative user siteUserAdmin\n  mongodb_user:\n    database: admin\n    name: \"{{ item.name }}\"\n    password: \"{{ item.password }}\"\n    roles: \"{{ item.roles }}\"\n    login_host: 127.0.0.1\n  with_items:\n    - {\n      name: \"{{ mongodb_user_admin_name }}\",\n      password: \"{{ mongodb_user_admin_password }}\",\n      roles: \"userAdminAnyDatabase\"\n      }\n  register: useradmin_user_result\n  when: ansible_local.mongodb.mongodb.mongodb_login_port is undefined\n\n- name: create normal users\n  mongodb_user:\n    database: \"{{ item.database }}\"\n    name: \"{{ item.name }}\"\n    password: \"{{ item.password }}\"\n    roles: \"{{ item.roles }}\"\n    replica_set: \"{{ mongodb_conf_replSet }}\"\n    login_host: 127.0.0.1\n    login_user: \"{{ mongodb_user_admin_name }}\"\n    login_password: \"{{ mongodb_user_admin_password }}\"\n  with_items:\n    - \"{{ mongodb_users }}\"\n  when: mongodb_users is defined and ansible_local.mongodb.mongodb.mongodb_login_port is undefined\n\n- name: Create facts.d directory\n  file:\n    state: directory\n    recurse: yes\n    path: /etc/ansible/facts.d\n  when: rootadmin_user_result|changed or useradmin_user_result|changed\n\n- name: Create facts file for mongodb\n  copy:\n    dest: /etc/ansible/facts.d/mongodb.fact\n    content: \"[mongodb]\\nmongodb_login_port={{ mongodb_conf_port }}\\n\"\n  when: rootadmin_user_result|changed or useradmin_user_result|changed\n"}, {"commit_sha": "72a9fefcabb6edccd82abb23946bd305035db334", "sha": "2ec6f5742c637ee759a368237189fd9c4be0b51a", "filename": "tasks/configure.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "1224adf2811c827a09ff0bf133fbb476901a547d", "decoded_content": "---\n\n- name: Ensure Tor DataDir(s) exist and is owned by tor_user\n  sudo: yes\n  file: path={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}\n    state=directory\n    owner={{ tor_user }}\n    mode=0700\n    recurse=yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - debian\n   - centos\n   - freebsd\n   - openbsd\n   - createdir\n\n- name: Ensure Tor config directory exists and has appropriate permissions\n  sudo: yes\n  file: path={{ tor_ConfDir }}\n    state=directory\n    owner=root\n    group={{ tor_user }}\n    mode=755\n  tags:\n   - debian\n   - centos\n   - freebsd\n   - openbsd\n\n- name: Ensure LogDir exists and has appropriate permissions\n  sudo: yes\n  file: path={{ tor_LogDir }}\n    state=directory\n    owner={{ tor_user }}\n    mode=750\n  tags:\n   - debian\n   - centos\n   - freebsd\n   - openbsd\n\n- name: Ensure PidDir is owned by tor_user\n  sudo: yes\n  file: path={{ tor_PidDir }}\n    state=directory\n    owner={{ tor_user }}\n    group={{ tor_user }}\n    mode=2750\n  tags:\n   - debian\n   - centos\n   - freebsd\n   - openbsd\n\n- name: Generating temporary (without MyFamily) torrc file(s)...\n  sudo: yes\n  template: src=torrc\n    dest=\"{{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc-tmp\"\n    owner=root\n    mode=0644\n  with_nested:\n   - tor_ips\n   - tor_ports\n  tags:\n   - debian\n   - centos\n   - freebsd\n   - openbsd\n\n- name: Collect relay fingerprints (for MyFamily)\n  sudo: yes\n  shell: \"tor --hush -f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc-tmp --list-fingerprint |cut -d' ' -f2-|sed -e 's, ,,g'\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n  register: tor_fingerprints\n  tags:\n   - debian\n   - centos\n   - freebsd\n   - openbsd\n   - configure\n\n- name: Generating final torrc file(s) (with MyFamily)\n  sudo: yes\n  template: >\n    src=torrc\n    dest=\"{{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\"\n    owner=root\n    mode=0644\n    backup=yes\n    validate=\"tor --verify-config -f %s\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n  register: instances\n  tags:\n   - debian\n   - centos\n   - freebsd\n   - openbsd\n   - configure\n\n# Linux/systemd section (uses service module)\n# ===========================================\n \n- name: Ensure Tor instances are reloaded if its torrc changed (Linux/systemd)\n  sudo: yes\n  service: name=tor@{{ item.item[0] }}_{{ item.item.1.orport }}.service state=reloaded\n  with_items: instances.results\n  when: ansible_system == 'Linux' and item.changed == True \n  tags:\n   - debian\n   - centos\n   - configure\n\n- name: Ensure Tor instances are enabled and started (Linux/systemd)\n  sudo: yes\n  service: name=tor@{{ item[0] }}_{{ item.1.orport }}.service enabled=yes state=started\n  with_nested:\n   - tor_ips\n   - tor_ports\n  when: ansible_system == 'Linux'\n  tags:\n   - debian\n   - centos\n\n# OpenBSD section (uses service module)\n# This is basically a copy from the Linux\n# section, but it requires different service\n# names and additional arguments.\n# =====================================\n\n# OpenBSD does not support multi-instance rc.d\n# # so we link as many pseudo rc scripts as we need.\n# # OpenBSD does not like dots in rc filenames so\n# # we replace them with underscores.\n- name: Create links to the service files (OpenBSD)\n  sudo: yes\n  file: src=/etc/rc.d/tor state=link path=/etc/rc.d/tor{{ item[0]| replace('.','_') }}_{{ item.1.orport }}\n  with_nested:\n   - tor_ips\n   - tor_ports\n  when: ansible_system == 'OpenBSD'\n  tags:\n   - openbsd\n\n- name: Ensure Tor instances are reloaded if its torrc changed (OpenBSD)\n  sudo: yes\n  service: name=tor{{ item.item[0]|replace('.','_') }}_{{ item.item.1.orport }} state=reloaded\n  with_items: instances.results\n  when: ansible_system == 'OpenBSD' and item.changed == True\n  tags:\n   - openbsd\n   - configure\n\n- name: Ensure Tor instances are enabled and started (OpenBSD)\n  sudo: yes\n  service: name=tor{{ item[0]|replace('.','_') }}_{{ item.1.orport }}\n   arguments=\"-f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\" enabled=yes state=started\n  with_nested:\n   - tor_ips\n   - tor_ports\n  when: ansible_system == 'OpenBSD'\n  tags:\n   - openbsd\n\n\n# FreeBSD section\n# ================\n\n- name: Ensure Tor instances are reloaded if its torrc changed (FreeBSD)\n  sudo: yes\n  shell: \"kill -HUP `cat {{ tor_PidDir }}/{{ item.item[0] }}_{{ item.item.1.orport }}.pid`\"\n  ignore_errors: yes\n  with_items: instances.results\n  when: item.changed == True and ansible_system == 'FreeBSD'\n  tags:\n   - freebsd\n   - configure\n\n- name: Ensure Tor instances are running (FreeBSD)\n  sudo: yes\n  shell: \"kill -0 `cat {{ tor_PidDir }}/{{ item[0] }}_{{ item.1.orport }}.pid` || tor -f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n  when: ansible_system == 'FreeBSD'\n  tags:\n   - freebsd\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "b701c84e1710ef007fe0e647c10ed75e7c2248ae", "filename": "roles/dnsmasq/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# defaults file for dnsmasq\ndnsmasq_config_folder: \"/etc/dnsmasq.d\"\ndnsmasq_resolvconf_file: \"{{ dnsmasq_config_folder }}/resolv.conf~\"\n"}, {"commit_sha": "df06f3c3304c3f73f740d444222642fbad41bebb", "sha": "876b97fa9619d850fbf8e00d6749163ebe6abd90", "filename": "tasks/dnf_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "1224adf2811c827a09ff0bf133fbb476901a547d", "decoded_content": "---\n\n- name: Add tor rpm key\n  become: yes\n  rpm_key: state=present key=https://deb.torproject.org/torproject.org/rpm/RPM-GPG-KEY-torproject.org.asc\n\n- set_fact: tor_rpm_distribution_os=\"fc\"\n  when: ansible_distribution == 'Fedora'\n\n- name: Ensure dependencies are installed (libselinux-python)\n  become: yes\n  dnf: name=libselinux-python state=present\n\n# the tor_alpha var is taken into account here (template)\n- name: Add torproject.org repository (YUM)\n  become: yes\n  template: src=torproject.yum.repo dest=/etc/yum.repos.d/torproject.repo owner=root group=root\n\n# we specifically opt for present over latest to improve performance\n# \"latest\" is covered by auto updates\n- name: Ensure Tor package is installed (dnf)\n  become: yes\n  dnf: name=tor,libsemanage-python state=present\n\n# we need this for the seboolean ansible module to work\n#- name: Ensure setsebool (SELinux) dependencies are installed (Fedora)\n#  become: yes\n#  dnf: name=libsemanage-python state=present\n#  when: ansible_selinux.status == 'enabled'\n\n- name: Ensure the presence of the multi-instance systemd unit file (Fedora)\n  become: yes\n  copy: src=centos_tor@.service dest=/lib/systemd/system/tor@.service owner=root mode=0644 backup=yes setype=tor_unit_file_t\n  notify: systemctl daemon-reload\n\n- name: Ensure SELinux boolean (tor_can_network_relay) is set appropriately (Fedora)\n  become: yes\n  seboolean: name=tor_can_network_relay state=yes persistent=yes\n#  when: ansible_selinux.status == 'enabled'\n\n- meta: flush_handlers\n"}, {"commit_sha": "b02504a0a0a8b0e4169d0327a865dfe08866e9ec", "sha": "e02fc42e7328a9ad6f9cf39c7b90aa2340fda6f2", "filename": "tasks/ssl.yml", "repository": "sensu/sensu-ansible", "release_starts_at": null, "release_ends_at": "9b3cb140022faf899910398013334755c8050175", "decoded_content": "---\n# tasks/ssl.yml: Deploy the client SSL cert/key to client systems\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure Sensu SSL directory exists\n    file:\n      dest: \"{{ sensu_config_path }}/ssl\"\n      state: directory\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n\n  - include: ssl_generate.yml\n    when: sensu_ssl_gen_certs\n\n  - name: Deploy the Sensu client SSL cert/key\n    copy:\n      src: \"{{ item }}\"\n      owner: \"{{ sensu_user_name }}\"\n      remote_src: \"{{ sensu_ssl_deploy_remote_src }}\"\n      group: \"{{ sensu_group_name }}\"\n      dest: \"{{ sensu_config_path }}/ssl\"\n    with_items:\n      - \"{{ sensu_ssl_client_cert }}\"\n      - \"{{ sensu_ssl_client_key }}\"\n    notify: restart sensu-client service\n"}, {"commit_sha": "e8eb28b4b4b1c4fb2490b8198570166b9ca23ab2", "sha": "2b31859c377a08234d70459330db067279201f60", "filename": "roles/mistral/tasks/install_mistral.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": null, "release_ends_at": "2d0f3f1cf5d5919432c94bb3659c16b85d1cb1db", "decoded_content": "- name: Create directory\n  sudo: true\n  file:\n    path: /opt/openstack\n    state: directory\n\n- name: Clone Mistral repo\n  sudo: true\n  git:\n    repo: https://github.com/StackStorm/mistral.git\n    version: \"{{ mistral_branch }}\"\n    dest: /opt/openstack/mistral\n\n- name: Install requirements\n  sudo: true\n  pip:\n    requirements: /opt/openstack/mistral/requirements.txt\n    virtualenv: /opt/openstack/mistral/.venv\n\n- name: Install additional requirements\n  sudo: true\n  pip:\n    name: mysql-python\n    virtualenv: /opt/openstack/mistral/.venv\n\n- name: Install Mistral\n  sudo: true\n  shell: /opt/openstack/mistral/.venv/bin/python setup.py develop\n  args:\n    chdir: /opt/openstack/mistral\n"}, {"commit_sha": "21712b74b7f5d936e70186bbed6bb37e3a7ad5e6", "sha": "1127f21e32ec037e87bc83a011af97cdc2726721", "filename": "roles/zookeeper/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# defaults file for zookeeper\nzookeeper_config_dir: \"/etc/zookeeper/conf\"\nzookeeper_client_port: 2181\nzookeeper_leader_connect_port: 2888\nzookeeper_leader_election_port: 3888\nzookeeper_server_group: zookeeper_servers\nzookeeper_id: \"\n\t{%- if zookeeper_host_list is defined -%}\n\t\t{%- for host in zookeeper_host_list.split() -%}\n\t\t\t{%- if host == ansible_eth0.ipv4.address -%}\n\t        \t{{ loop.index }}\n\t\t\t{%- endif -%}\n\t\t{%- endfor -%}\n\t{%- else -%}\n    \t{%- for host in groups[zookeeper_server_group] -%}\n      \t\t{%- if host == 'default' or host == inventory_hostname or host == ansible_fqdn or host in ansible_all_ipv4_addresses -%}\n        \t\t{{ loop.index }}\n  \t\t\t{%- endif -%}\n    \t{%- endfor -%}\n    {%- endif -%}\n\"\nconsul_dir: /etc/consul.d\n"}, {"commit_sha": "0f46bc2b1f4dac71c882be0ee48a25332a90ed40", "sha": "11c57be75b7ac1bfcff8177c0cd5c25c4002adc2", "filename": "roles/marathon/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": null, "release_ends_at": "dfa8978dc272945b9b4fce761c4bb23af2dd6653", "decoded_content": "---\n# tasks file for marathon\n- name: remove marathon override\n  command: /bin/rm -f /etc/init/marathon.override\n\n- name: ensure marathon is running (and enable it at boot)\n  service: name=marathon state=started enabled=yes\n\n- name: Set Marathon consul service definition\n  sudo: yes\n  template:\n    src: marathon-consul.j2\n    dest: \"{{ consul_dir }}/marathon.json\"\n  notify:\n    - Restart consul\n"}, {"commit_sha": "a2393d46f0b98700161c4cefd9260d7694bd0bf3", "sha": "3f1e9020aed99a681e97f29edda9cac313d192d5", "filename": "tasks/section_04_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "2cfa28fd756194b32e320ab9c0df1e455f27dc38", "decoded_content": "---\n\n  - name: 4.5 Activate AppArmor (install) (Scored)\n    apt: >\n        name=apparmor\n        state=present\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (start) (Scored)\n    service: >\n        name=apparmor\n        state=started\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (Scored)\n    command: apparmor_status\n    register: aa_status_lines\n    failed_when: '\"0 profiles are loaded\" in aa_status_lines.stdout_lines or \"0 processes are in complain mode.\" not in aa_status_lines.stdout_lines or \"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n        # - '\"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n    changed_when: False\n    when: travis_env == False\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (enforce install) (Scored)\n    apt: >\n        name=apparmor-utils\n        state=present\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (enforce) (Scored)\n    #shell: 'aa-enforce /etc/apparmor.d/*'\n    shell: for profile in /etc/apparmor.d/*; do aa-enforce $profile; done\n    register: aaenforce_rc\n    failed_when: aaenforce_rc.rc == 1\n    changed_when: False\n    tags:\n      - section4\n      - section4.5\n"}, {"commit_sha": "f565940c5163524c7834123625c804e5f69c2b10", "sha": "91930b32f80f9204710b1612edc1520c2c0516a5", "filename": "tasks/ssl.yml", "repository": "sensu/sensu-ansible", "release_starts_at": null, "release_ends_at": "9b3cb140022faf899910398013334755c8050175", "decoded_content": "---\n# tasks/ssl.yml: Deploy the client SSL cert/key to client systems\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure Sensu SSL directory exists\n    file:\n      dest: \"{{ sensu_config_path }}/ssl\"\n      state: directory\n      owner: \"{{ sensu_user_name }}\"\n      group: \"{{ sensu_group_name }}\"\n\n  - include: ssl_generate.yml\n    when: sensu_ssl_gen_certs\n\n  - name: Deploy the Sensu client SSL cert/key\n    copy:\n      src: \"{{ item.src }}\"\n      owner: \"{{ sensu_user_name }}\"\n      remote_src: \"{{ sensu_ssl_deploy_remote_src }}\"\n      group: \"{{ sensu_group_name }}\"\n      dest: \"{{ sensu_config_path }}/ssl/{{ item.dest }}\"\n    with_items:\n      - {src: \"{{ sensu_ssl_client_cert }}\", dest: cert.pem}\n      - {src: \"{{ sensu_ssl_client_key }}\", dest: key.pem}\n    notify: restart sensu-client service\n    when: sensu_ssl_manage_certs\n"}, {"commit_sha": "7a3aa0de9bf76ff1b18e6da304031150e4550142", "sha": "d712bec1ac1e3918d0ae854feaf9f508f8d11bd5", "filename": "tasks/configure.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "1224adf2811c827a09ff0bf133fbb476901a547d", "decoded_content": "---\n\n- name: Ensure Tor DataDir(s) exist and is owned by {{ tor_user }}\n  sudo: yes\n  file: path={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}\n    state=directory\n    owner={{ tor_user }}\n    mode=0700\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure Tor config directory exists and has appropriate permissions\n  sudo: yes\n  file: path={{ tor_ConfDir }}\n    state=directory\n    owner=root\n    group={{ tor_user }}\n    mode=755\n\n# on FreeBSD /var/log/tor is a file, let's rename it\n- name: If {{ tor_LogDir }} is a file, rename it\n  sudo: yes\n  shell: \"test -f {{ tor_LogDir }} && mv {{ tor_LogDir }} {{ tor_LogDir }}.bk-`date '+%Y-%m-%d_%H%M%S'`\"\n  ignore_errors: yes\n\n- name: Ensure Tor log directory exists and has appropriate permissions\n  sudo: yes\n  file: path={{ tor_LogDir }}\n    state=directory\n    owner={{ tor_user }}\n    mode=750\n\n- name: Ensure Tor log file(s) are not world readable\n  sudo: yes\n  file: path=\"{{ tor_LogDir }}/{{ item[0] }}_{{ item.1.orport }}.log\"\n    state=touch\n    owner={{ tor_user }}\n    mode=600\n  with_nested:\n   - tor_ips\n   - tor_ports\n\n- name: Ensure Tor PidDir is owned by tor_user\n  sudo: yes\n  file: path={{ tor_PidDir }}\n    state=directory\n    owner={{ tor_user }}\n    group={{ tor_user }}\n    mode=2750\n\n- name: Generating TEMPORARY (without MyFamily) torrc file(s)...\n  sudo: yes\n  template: src=torrc\n    dest=\"{{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc-tmp\"\n    owner=root\n    mode=0644\n  with_nested:\n   - tor_ips\n   - tor_ports\n\n- name: Generate keys (if not in place yet) and gather relay fingerprints (for MyFamily)\n  sudo: yes\n  shell: \"tor --hush -f {{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc-tmp --list-fingerprint |cut -d' ' -f2-|sed -e 's, ,,g'\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n  register: tor_fingerprints\n\n- name: Remove temporary files\n  sudo: yes\n  file: path=\"{{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }}.torrc-tmp\"\n    state=absent\n  with_nested:\n   - tor_ips\n   - tor_ports\n\n- name: Generating torrc file(s) - this time with MyFamily...\n  sudo: yes\n  template: >\n    src=torrc\n    dest=\"{{ tor_ConfDir }}/tor-{{ item[0] }}_{{ item.1.orport }}.torrc\"\n    owner=root\n    mode=0644\n    backup=yes\n  with_nested:\n   - tor_ips\n   - tor_ports\n  register: instances\n\n# disabled for now\n# bug in --verify-config (trac #15015)\n#\n#- name: Ensure torrc files are sane\n#  shell: \"tor --verify-config -f {{ tor_ConfDir }}/tor-{{ item[0] }}_{{ item.1.orport }}.torrc\"\n#  with_nested:\n#   - tor_ips\n#   - tor_ports\n\n- name: Ensure Tor instances are reloaded if its torrc changed\n  sudo: yes\n  shell: \"kill -HUP `cat {{ tor_PidDir }}/tor-{{ item.item[0] }}_{{ item.item.1.orport }}.pid`\"\n  ignore_errors: yes\n  with_items: instances.results\n  when: item.changed == True\n\n- name: Ensure Tor instances are running\n  sudo: yes\n  shell: \"kill -0 `cat {{ tor_PidDir }}/tor-{{ item[0] }}_{{ item.1.orport }}.pid` || tor -f {{ tor_ConfDir }}/tor-{{ item[0] }}_{{ item.1.orport }}.torrc\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n"}, {"commit_sha": "59bde5ac149cca3058d0b8a8bd4b2d0e21e8c861", "sha": "0c3b34937b2ab2fb66d85d062b5ac1f2b8b8867f", "filename": "tasks/section_04_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "2cfa28fd756194b32e320ab9c0df1e455f27dc38", "decoded_content": "---\n\n  - name: 4.5 Activate AppArmor (install) (Scored)\n    apt: >\n        name=apparmor\n        state=present\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (start) (Scored)\n    service: >\n        name=apparmor\n        state=started\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (Scored)\n    command: apparmor_status\n    register: aa_status_lines\n    failed_when: '\"0 profiles are loaded\" in aa_status_lines.stdout_lines or \"0 processes are in complain mode.\" not in aa_status_lines.stdout_lines or \"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n        # - '\"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n    changed_when: False\n    when: travis_env == False\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (enforce install) (Scored)\n    apt: >\n        name=apparmor-utils\n        state=present\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (enforce) (Scored)\n    shell: 'aa-enforce /etc/apparmor.d/*'\n    register: aaenforce_rc\n    failed_when: aaenforce_rc.rc == 1\n    changed_when: False\n    tags:\n      - section4\n      - section4.5\n"}, {"commit_sha": "21712b74b7f5d936e70186bbed6bb37e3a7ad5e6", "sha": "26cc6303649a692df6e37b3800b226a83b1f4be8", "filename": "roles/mesos/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# Common\nconsul_dir: /etc/consul.d\nmesos_executor_registration_timeout: 10mins\nmesos_cluster_name: \"Cluster01\"\nmesos_ip: \"{{ ansible_default_ipv4.address }}\"\nmesos_hostname: \"{{ ansible_ssh_host }}\"\nmesos_docker_socket: \"/var/run/weave/weave.sock\"\n\n# Defaults file for mesos-salve\nmesos_slave_port: 5051\nmesos_containerizers: \"docker,mesos\"\nmesos_resources: \"ports(*):[31000-32000]\"\nmesos_slave_work_dir: \"/tmp/mesos\"\n\n# Defaults file for mesos-master\nmesos_zookeeper_group: zookeeper_servers\nmesos_master_port: 5050\nmesos_master_work_dir: \"/var/lib/mesos\"\n\n# The Mesos quorum value is based on the number of Mesos Masters. Take the\n# number of masters, divide by 2, and round-up to nearest integer. For example,\n# if there are 1 or 2 masters the quorum count is 1. If there are 3 or 4\n# masters then the quorum count is 2. For 5 or 6 masters it's 3 and so on.\nmesos_quorum: \"\n{% if mesos_master_quorum is defined %}\n{{ mesos_master_quorum }}\n{% else %}\n{{ ( groups.mesos_masters|count / 2) | round(0, 'ceil') | int }}\n{%- endif -%}\n\"\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "c8dce8ad6e5eafde6c0a26f8727e22fa5e467235", "filename": "roles/mesos/tasks/slave.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# Tasks for Slave nodes\n\n- name: create mesos-slave work directory\n  when: mesos_install_mode == \"slave\"\n  file:\n    path: \"{{ mesos_slave_work_dir }}\"\n    state: directory\n    mode: 0755\n  sudo: yes\n  tags:\n    - mesos-slave\n\n- name: run mesos-slave container\n  when: mesos_install_mode == \"slave\"\n  docker:\n    name: mesos-slave\n    image: \"{{ mesos_slave_image }}\"\n    state: started\n    privileged: true\n    volumes:\n    - \"{{ mesos_slave_work_dir }}:{{ mesos_slave_work_dir }}\"\n    - \"/proc:/host/proc:ro\"\n    - \"/cgroup:/cgroup\"\n    - \"/sys:/sys\"\n    - \"/lib/libpthread.so.0:/lib/libpthread.so.0:ro\"\n    - \"/usr/bin/docker:/usr/bin/docker:ro\"\n    - \"/usr/lib/x86_64-linux-gnu/libapparmor.so.1.1.0:/usr/lib/x86_64-linux-gnu/libapparmor.so.1\"\n    - \"{{ mesos_docker_socket }}:/var/run/docker.sock\"\n    ports:\n    - \"{{ mesos_slave_port }}:{{ mesos_slave_port }}\"\n    net: \"host\"\n    env:\n      MESOS_MASTER: \"zk://{{ zookeeper_peers_nodes }}/mesos\"\n      MESOS_EXECUTOR_REGISTRATION_TIMEOUT: \"{{ mesos_executor_registration_timeout }}\"\n      MESOS_CONTAINERIZERS: \"{{ mesos_containerizers }}\"\n      MESOS_RESOURCES: \"{{ mesos_resources }}\"\n      MESOS_IP: \"{{ mesos_ip }}\"\n      MESOS_WORK_DIR: \"{{ mesos_slave_work_dir }}\"\n      MESOS_HOSTNAME: \"{{ mesos_hostname }}\"\n  tags:\n    - mesos-slave\n\n- name: upload mesos-slave template service\n  when: mesos_install_mode == \"slave\"\n  template:\n    src: mesos-slave.conf.j2\n    dest: /etc/init/mesos-slave.conf\n    mode: 0755\n  sudo: yes\n  tags:\n    - mesos-slave\n\n- name: ensure mesos-slave is running (and enable it at boot)\n  when: mesos_install_mode == \"slave\"\n  sudo: yes\n  service:\n    name: mesos-slave\n    state: started\n    enabled: yes\n  tags:\n    - mesos-slave\n\n- name: run prometheus mesos slave exporter container\n  when: mesos_install_mode == \"slave\" and prometheus_enabled|bool\n  docker:\n    name: mesos-exporter\n    image: \"{{ prometheus_mesos_exporter_image }}\"\n    command: \"-exporter.scrape-mode=slave -exporter.url=http://{{ mesos_hostname }}:{{ mesos_slave_port }}\"\n    state: started\n    restart_policy: always\n    ports:\n    - \"{{ prometheus_mesos_exporter_port }}:{{ prometheus_mesos_exporter_port }}\"\n  environment: proxy_env\n  tags:\n    - prometheus\n    - mesos_slave\n\n- name: Set mesos-exporter consul service definition\n  when: mesos_install_mode == \"slave\" and prometheus_enabled|bool\n  sudo: yes\n  template:\n    src: mesos-exporter-consul.j2\n    dest: \"{{ consul_dir }}/mesos-exporter.json\"\n  notify:\n    - restart consul\n  tags:\n    - prometheus\n    - mesos_slave\n"}, {"commit_sha": "1bdaeb4774a30e08afcbeebb59e5cdfa97ba44a1", "sha": "f54137e4352d559d530407a7d4b8636aafa5638d", "filename": "tasks/Ubuntu/main.yml", "repository": "sensu/sensu-ansible", "release_starts_at": null, "release_ends_at": "9b3cb140022faf899910398013334755c8050175", "decoded_content": "---\n# tasks/Ubuntu/main.yml: Ubuntu specific set-up\n# This takes care of base prerequisites for Ubuntu\n\n  - include_vars: \"{{ ansible_distribution }}.yml\"\n\n  - name: Ensure the Sensu APT repo GPG key is present\n    apt_key:\n      url: https://sensu.global.ssl.fastly.net/apt/pubkey.gpg\n      state: present\n\n  - name: Ensure the Sensu Core APT repo is present\n    apt_repository:\n      repo: \"deb     https://sensu.global.ssl.fastly.net/apt {{ ansible_distribution_release }} main\"\n      state: present\n      update_cache: true\n\n  - name: Ensure Sensu is installed\n    apt: name={{ sensu_package }} state={{ sensu_pkg_state }}\n"}, {"commit_sha": "9966c6de1ed4ef5071a9bea83b4bb69a11dd32ba", "sha": "7945bed31d9b9974e01dcbab7a6c7d74750b4382", "filename": "roles/consul/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# tasks file for consul\n- name: remove consul override\n  file:\n    path: /etc/init/consul.override\n    state: absent\n\n- name: configure consul\n  sudo: yes\n  template:\n    src: consul.json.j2\n    dest: /etc/consul.d/consul.json\n    owner: root\n    group: root\n    mode: 0644\n  notify:\n    - Restart consul\n  tags:\n    - consul\n\n- name: configure atlas for consul\n  sudo: yes\n  template:\n    src: atlas.json.j2\n    dest: /etc/consul.d/atlas.json\n    owner: root\n    group: root\n    mode: 0644\n  when: consul_atlas_join\n  notify:\n    - Restart consul\n  tags:\n    - consul\n\n- name: enable consul\n  sudo: yes\n  service:\n    name: consul\n    enabled: yes\n    state: started\n\n# Give some time for leader election to occur\n- name: wait for leader\n  wait_for:\n    host: \"{{ consul_bind_addr }}\"\n    port: 8301\n    delay: 10\n\n- name: remove consul-join override\n  file:\n    path: /etc/init/consul-join.override\n    state: absent\n  when: consul_join is defined\n\n- name: configure consul-join\n  sudo: yes\n  template:\n    src: consul-join.j2\n    dest: /etc/service/consul-join\n    owner: root\n    group: root\n    mode: 0644\n  notify:\n    - Restart consul\n  when: consul_join is defined\n  tags:\n    - consul\n\n# We need to force reload here because sometimes Consul gets in a weird\n# state where it cannot elect a cluster leader. Simply restarting the service\n# seems to allow it to recover automatically.\n- name: force reload consul\n  sudo: yes\n  command: /sbin/restart consul\n\n- name: force wait for leader\n  wait_for:\n    host: \"{{ consul_bind_addr }}\"\n    port: 8301\n    delay: 10\n"}, {"commit_sha": "32211ebd2a9f45112f8dceda80bc95d0db029fb4", "sha": "ed9a68ce7a4b11576d230e2381857e9819d84d24", "filename": "tasks/apt_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "1224adf2811c827a09ff0bf133fbb476901a547d", "decoded_content": "---\n\n- name: Setup Debian specific variables (set_fact)\n  set_fact:\n    tor_user: debian-tor\n    tor_DataDir: /var/lib/tor-instances\n    tor_ConfDir: /etc/tor/instances\n    tor_RunAsDaemon: 0\n  tags:\n   - reconfigure\n   - renewkey\n\n- name: Ensure torproject gpg key is installed (A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89)\n  become: yes\n  apt_key: data=\"{{ lookup('file', 'deb.torproject.org_A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89.pub') }}\"\n    id=A3C4F0F979CAA22CDBA8F512EE8CBC9E886DDD89\n    state=present\n\n- name: Ensure torproject.org repository is present (APT)\n  become: yes\n  apt_repository: repo='deb http://deb.torproject.org/torproject.org {{ tor_distribution_release }} main'\n    state=present \n    update_cache=yes\n\n# we specifically opt for present over latest to improve performance\n# \"latest\" is covered by auto updates\n- name: Ensure Tor is installed (APT)\n  become: yes\n  apt: pkg=\"{{ item }}\" state=present\n  with_items: \n    - deb.torproject.org-keyring\n    - tor\n  # apt starts a tor client instance by default after installing the package\n  # we do not need that\n  notify:\n    - stop-and-mask default tor instance\n\n\n#- name: Ensure AppArmor allows access to necessary files (Ubuntu)\n#  become: yes\n#  lineinfile: dest=/etc/apparmor.d/local/system_tor line={{ item }}\n#  with_items:\n#    - '/etc/tor/enabled/*\\ r,'\n#    - '/{,var/}run/tor/*.pid\\ w,'\n#    - '/var/lib/tor/**\\ w,'\n#  when: ansible_distribution == 'Ubuntu'\n#  notify: restart apparmor\n\n- meta: flush_handlers\n"}, {"commit_sha": "e8eb28b4b4b1c4fb2490b8198570166b9ca23ab2", "sha": "24fa0641827c38f62338fec7c534de18219a2483", "filename": "roles/mistral/tasks/install_actions.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": null, "release_ends_at": "2d0f3f1cf5d5919432c94bb3659c16b85d1cb1db", "decoded_content": "- name: Create actions directory\n  sudo: true\n  file:\n    path: /etc/mistral/actions\n    state: directory\n\n- name: Clone Mistral actions repo\n  sudo: true\n  git:\n    repo: https://github.com/StackStorm/st2mistral.git\n    version: \"{{ mistral_branch }}\"\n    dest: /etc/mistral/actions/st2mistral\n\n- name: Install Mistral actions\n  sudo: true\n  shell: /opt/openstack/mistral/.venv/bin/python setup.py develop\n  args:\n    chdir: /etc/mistral/actions/st2mistral\n"}, {"commit_sha": "fa66f2d6f5193cce5c2f9086e78f9bff39133e60", "sha": "acc3b24db12b6ebe49435770498aa974e089fbd7", "filename": "tasks/openbsd_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "1224adf2811c827a09ff0bf133fbb476901a547d", "decoded_content": "---\n\n- name: Setup OpenBSD specific variables (set_fact)\n  set_fact:\n    tor_DataDir: /var/tor\n    tor_ConfDir: /etc/tor/enabled\n  tags:\n   - reconfigure\n   - renewkey\n   - createdir\n\n- name: Ensure Tor is installed (OpenBSD)\n  become: yes\n  openbsd_pkg: name=tor state=present\n\n- name: Gather current system-wide file descriptor limits (OpenBSD)\n  shell: \"sysctl kern.maxfiles|cut -d= -f2\"\n  register: currentlimits\n\n- name: Ensure system-wide runtime file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  command: \"sysctl kern.maxfiles=20000\"\n  when: currentlimits.stdout|int < 20000\n\n- name: Ensure system-wide persistent file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  lineinfile: dest=/etc/sysctl.conf regexp=^kern.maxfiles line=\"kern.maxfiles=20000\" create=yes\n  when: currentlimits.stdout|int < 20000\n\n# We rise openfiles limits for every tor instance separately.\n# An instance is identified by its rc.d file name.\n- name: Ensure Tor process file descriptor limits are reasonable (OpenBSD)\n  become: yes\n  lineinfile: \"dest=/etc/login.conf line='tor{{ item[0]| replace('.','_') }}_{{ item.1.orport }}::openfiles-max=13500::tc=daemon:'\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n  #TODO\n  #notify: restart tor\n"}, {"commit_sha": "7f02cba4441b5367d6916857c9b41f3abae915db", "sha": "b20efbd690546040b3e22815e99c78e88a9dcb65", "filename": "tasks/ip-list.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "9f2f1160c4dc3fea2f6e81e42ba8a6254ef093db", "decoded_content": "---\n\n- name: Use a single private IPv4 address if we have no public IPv4 address\n  include_vars: private_IPv4_only.yml\n  when: tor_v4ips == []\n\n# workaround for this ansible IPv6 filter bug\n# https://github.com/ansible/ansible/issues/14829\n# we simply convert False to empty lists\n- name: workaround for ansible bug 14829 (1/3)\n  set_fact:\n    tor_available_public_ipv6s: []\n  when: not tor_available_public_ipv6s\n\n- name: workaround for ansible bug 14829 (2/3)\n  set_fact:\n    tor_v6ips: \"{{ tor_available_public_ipv6s[0:tor_ipv4_count|int]|ipv6('address') }}\"\n\n- name: workaround for ansible bug 14829 (3/3)\n  set_fact:\n    tor_v6ips: []\n  when: not tor_v6ips\n\n- name: setup IP list (1/2)\n  set_fact:\n    ips:\n        ipv4: \"{{ item.0 }}\"\n        ipv6: \"{{ item.1 }}\"\n  with_together:\n        - \"{{ tor_v4ips }}\"\n        - \"{{ tor_v6ips }}\"\n  register: tor_ipsinterm\n\n- name: setup IP list (2/2)\n  set_fact:\n    tor_ips: \"{{ tor_ipsinterm.results | map(attribute='ansible_facts.ips')|list}}\"\n"}, {"commit_sha": "af3dfdf7cf37437f5609f1a12e4ac7cbaebd4867", "sha": "e425e4a5c2947bf23ec96f059da9777927f8a6e4", "filename": "roles/weave/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# defaults file for weave\nweave_bridge: \"10.2.0.1/16\"\nweave_server_group: weave_servers\nweave_docker_subnet: \"\n    {%- for host in groups[weave_server_group] -%}\n      {%- if host == 'default' or host == inventory_hostname or host == ansible_fqdn or host in ansible_all_ipv4_addresses -%}\n        10.2.{{ loop.index }}.0/24\n      {%- endif -%}\n    {%- endfor -%}\n\"\nweave_launch_peers: \"\n  {%- set weave_peers = [] -%}\n  {%- for host in groups[weave_server_group] -%}\n    {%- if host != inventory_hostname and host not in weave_peers -%}\n      {% do weave_peers.append(hostvars[host]['ansible_eth0']['ipv4']['address']) %}\n    {%- endif -%}\n  {%- endfor -%}\n  {{ weave_peers|join(' ') }}\n\"\nweave_docker_opts: \"--bridge=weave --fixed-cidr={{ weave_docker_subnet }} --dns 172.17.42.1 --dns 8.8.8.8 --dns-search service.{{ consul_domain }}\"\nweave_scope_url: https://github.com/weaveworks/scope/releases/download/latest_release/scope\nweave_scope_dest: /usr/local/bin/scope\n"}, {"commit_sha": "35ca6852d9333ef6c3ed223239f45b840c487d60", "sha": "4296a6370f2e6cc4f7a22da3eea3b72818e2e5c8", "filename": "roles/mesos/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "# used for leader election amongst masters\n- name: Set ZooKeeper URL\n  template:\n    src: zk.j2\n    dest: /etc/mesos/zk\n    mode: 0644\n  sudo: yes\n\n# Tasks for Master nodes\n- name: remove mesos-master override\n  file:\n    path: /etc/init/mesos-master.override\n    state: absent\n  when: mesos_install_mode == \"master\"\n\n- name: start mesos-master (and enable it at boot)\n  service:\n    name: mesos-master\n    state: started\n    enabled: yes\n  when: mesos_install_mode == \"master\"\n\n- name: Set Mesos Master ip\n  copy:\n    content: \"{{mesos_local_address}}\"\n    dest: /etc/mesos-master/ip\n    mode: 0644\n  sudo: yes\n  notify:\n    - Restart mesos master\n  when: mesos_install_mode == \"master\"\n\n- name: Set Mesos Master hostname\n  copy:\n    content: \"{{mesos_local_address}}\"\n    dest: /etc/mesos-master/hostname\n    mode: 0644\n  sudo: yes\n  notify:\n    - Restart mesos master\n  when: mesos_install_mode == \"master\"\n\n  # The Mesos quorum value is based on the number of Mesos Masters. Take the\n  # number of masters, divide by 2, and round-up to nearest integer. For example,\n  # if there are 1 or 2 masters the quorum count is 1. If there are 3 or 4\n  # masters then the quorum count is 2. For 5 or 6 masters it's 3 and so on.\n- name: Set Mesos Master quorum count\n  template:\n    src: quorum.j2\n    dest: /etc/mesos-master/quorum\n    mode: 0644\n  sudo: yes\n  notify:\n    - Restart mesos master\n  when: mesos_install_mode == \"master\"\n\n- name: Set Mesos Master Cluster name\n  copy:\n    content: \"{{mesos_cluster_name}}\"\n    dest: /etc/mesos-master/cluster\n    mode: 0644\n  sudo: yes\n  notify:\n    - Restart mesos master\n  when: mesos_install_mode == \"master\"\n\n- name: Set Mesos Master consul service definition\n  sudo: yes\n  template:\n    src: mesos-master-consul.j2\n    dest: \"{{ consul_dir }}/mesos-master.json\"\n  notify:\n    - Restart consul\n  when: mesos_install_mode == \"master\"\n\n- name: start mesos-master (and enable it at boot)\n  service:\n    name: mesos-master\n    state: started\n    enabled: yes\n  when: mesos_install_mode == \"master\"\n\n# Tasks for Slave nodes\n- name: remove mesos-slave override\n  file:\n    path: /etc/init/mesos-slave.override\n    state: absent\n  when: mesos_install_mode == \"slave\"\n\n- name: Set Mesos Slave hostname\n  copy:\n    content: \"{{mesos_local_address}}\"\n    dest: /etc/mesos-slave/hostname\n    mode: 0644\n  sudo: yes\n  notify:\n    - Restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: set executor registration timeout\n  sudo: yes\n  copy:\n    dest: /etc/mesos-slave/executor_registration_timeout\n    content: \"{{ mesos_executor_registration_timeout }}\"\n  notify:\n    - Restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: set containerizers\n  sudo: yes\n  copy:\n    dest: /etc/mesos-slave/containerizers\n    content: \"{{ mesos_containerizers }}\"\n  notify:\n    - Restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: set slave resources\n  sudo: yes\n  copy:\n    dest: /etc/mesos-slave/resources\n    content: \"{{ mesos_resources }}\"\n  notify:\n    - Restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: Set Mesos Slave ip\n  copy:\n    content: \"{{mesos_local_address}}\"\n    dest: /etc/mesos-slave/ip\n    mode: 0644\n  sudo: yes\n  notify:\n    - Restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: Create Mesos Slave work area\n  file:\n    dest: \"{{mesos_slave_work_dir}}\"\n    mode: 0755\n    state: directory\n  sudo: yes\n  notify:\n    - Restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: Set Mesos Slave work area\n  copy:\n    content: \"{{mesos_slave_work_dir}}\"\n    dest: /etc/mesos-slave/work_dir\n    mode: 0644\n  sudo: yes\n  notify:\n    - Restart mesos slave\n  when: mesos_install_mode == \"slave\"\n\n- name: start mesos-slave (and enable it at boot)\n  service:\n    name: mesos-slave\n    state: started\n    enabled: yes\n  when: mesos_install_mode == \"slave\"\n\n"}, {"commit_sha": "92d2f38d01d7b33610c667cfdc03e28ab2912edc", "sha": "1606767b2bf30e445da635101cf4eefd229a2ec5", "filename": "tasks/section_10_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "2cfa28fd756194b32e320ab9c0df1e455f27dc38", "decoded_content": "---\n\n  - name: 10.1.1 Set Password Expiration Days (Scored)\n    lineinfile: >\n        dest='/etc/login.defs'\n        line='PASS_MAX_DAYS 90'\n        state=present\n        regexp='^PASS_MAX_DAYS'\n    tags:\n      - section10\n      - section10.1\n      - section10.1.1\n\n  - name: 10.1.2 Set Password Change Minimum Number of Days (Scored)\n    lineinfile: >\n        dest='/etc/login.defs'\n        line='PASS_MIN_DAYS 7'\n        regexp='^PASS_MIN_DAYS'\n    tags:\n      - section10\n      - section10.1\n      - section10.1.2\n\n  - name: 10.1.3 Set Password Expiring Warning Days (Scored)\n    lineinfile: >\n        dest='/etc/login.defs'\n        line='PASS_WARN_AGE'\n        regexp='^PASS_WARN_AGE'\n    tags:\n      - section10\n      - section10.1\n      - section10.1.3\n\n  - name: 10.2 Disable System Accounts (check) (Scored)\n    shell: awk -F':' '($1!=\"root\" && $1!=\"sync\" && $1!=\"shutdown\" &&$1!=\"halt\" && $3<500 && $7!=\"/usr/sbin/nologin\" && $7!=\"/bin/false\") {print $1}' /etc/passwd\n    register: awk_etc_passwd\n    changed_when: False\n    tags:\n      - section10\n      - section10.2\n\n  - name: 10.2 Disable System Accounts (Scored)\n    command: /usr/sbin/usermod -s /usr/sbin/nologin {{ item }}\n    with_items: \"{{awk_etc_passwd.stdout_lines}}\"\n    tags:\n      - section10\n      - section10.2\n\n  - name: 10.3 Set Default Group for root Account (Scored)\n    user: >\n        name=root\n        group=root\n    tags:\n      - section10\n      - section10.3\n\n  - name: 10.4 Set Default umask for Users (Scored)\n    lineinfile: >\n        dest=/etc/login.defs\n        line='UMASK\\t077'\n        regexp='^UMASK'\n        state=present\n    tags:\n      - section10\n      - section10.4\n\n  - name: 10.5 Lock Inactive User Accounts (check) (Scored)\n    command: grep INACTIVE /etc/login.defs\n    changed_when: False\n    failed_when: False\n    always_run: True\n    register: lock_inactive_rc\n    tags:\n      - section10\n      - section10.5\n        \n  - name: 10.5 Lock Inactive User Accounts (Scored)\n    lineinfile: >\n        dest=/etc/login.defs\n        line='INACTIVE=35'\n        state=present\n    when: lock_inactive_rc.rc == 1\n    tags:\n      - section10\n      - section10.5\n\n"}, {"commit_sha": "80530fde7df1a94ad361434e02816b0816a2c47a", "sha": "971492a532c7d4d91d4506614b9ca25efa2534fe", "filename": "roles/mesos/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": null, "release_ends_at": "dfa8978dc272945b9b4fce761c4bb23af2dd6653", "decoded_content": "# used for leader election amongst masters\n- name: Set ZooKeeper URL\n  template: src=zk.j2 dest=/etc/mesos/zk mode=0644\n  sudo: yes\n\n# Tasks for Master nodes\n- name: Set Mesos Master ip\n  copy:\n    content: \"{{mesos_local_address}}\"\n    dest: /etc/mesos-master/ip\n    mode: 0644\n  sudo: yes\n  when: mesos_install_mode == \"master\"\n\n- name: Set Mesos Master hostname\n  copy:\n    content: \"{{mesos_local_address}}\"\n    dest: /etc/mesos-master/hostname\n    mode: 0644\n  sudo: yes\n  when: mesos_install_mode == \"master\"\n\n  # The Mesos quorum value is based on the number of Mesos Masters. Take the\n  # number of masters, divide by 2, and round-up to nearest integer. For example,\n  # if there are 1 or 2 masters the quorum count is 1. If there are 3 or 4\n  # masters then the quorum count is 2. For 5 or 6 masters it's 3 and so on.\n- name: Set Mesos Master quorum count\n  template: src=quorum.j2 dest=/etc/mesos-master/quorum mode=0644\n  sudo: yes\n  when: mesos_install_mode == \"master\"\n\n- name: remove mesos-master override\n  command: /bin/rm -f /etc/init/mesos-master.override\n  when: mesos_install_mode == \"master\"\n\n- name: Set Mesos Master Cluster name\n  copy:\n    content: \"{{mesos_cluster_name}}\"\n    dest: /etc/mesos-master/cluster\n    mode: 0644\n  sudo: yes\n  notify:\n    - Start mesos master\n  when: mesos_install_mode == \"master\"\n\n- name: Set Mesos Master consul service definition\n  sudo: yes\n  template:\n    src: mesos-master-consul.j2\n    dest: \"{{ consul_dir }}/mesos-master.json\"\n  notify:\n    - Restart consul\n  when: mesos_install_mode == \"master\"\n\n# Tasks for Slave nodes\n- name: Set Mesos Slave hostname\n  copy:\n    content: \"{{mesos_local_address}}\"\n    dest: /etc/mesos-slave/hostname\n    mode: 0644\n  sudo: yes\n  when: mesos_install_mode == \"slave\"\n\n- name: remove mesos-slave override\n  command: /bin/rm -f /etc/init/mesos-slave.override\n  when: mesos_install_mode == \"slave\"\n\n- name: Set Mesos Slave ip\n  copy:\n    content: \"{{mesos_local_address}}\"\n    dest: /etc/mesos-slave/ip\n    mode: 0644\n  sudo: yes\n  notify:\n    - Start mesos slave\n  when: mesos_install_mode == \"slave\"\n"}, {"commit_sha": "069c7c7848545c132aff3c88fe170cbe30c8abb9", "sha": "86d5827a87ae81c48a9bb3ebbe11383470e7b1be", "filename": "roles/zookeeper/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "- name: Create zookeeper config file\n  template: src=zoo.cfg.j2 dest=/etc/zookeeper/conf/zoo.cfg\n  sudo: yes\n\n- name: Create zookeeper myid file\n  copy:\n    content: \"{{zookeeper_id}}\"\n    dest: /etc/zookeeper/conf/myid\n    mode: 0644\n  sudo: yes\n  notify:\n    - Start zookeeper\n\n- name: Set Zookeeper consul service definition\n  sudo: yes\n  template:\n    src: zookeeper-consul.j2\n    dest: \"{{ consul_dir }}/zookeeper.json\"\n  notify:\n    - Restart consul\n"}, {"commit_sha": "dc73f16743fa376672b427980c6ca044dd6fa68a", "sha": "75300721236cf3b42a2a360cf44cd30ef79527f8", "filename": "tasks/configure.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "1224adf2811c827a09ff0bf133fbb476901a547d", "decoded_content": "---\n\n- name: Ensure local DataDir folders exist (LOCAL)\n  file:\n    path: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    state: directory\n    mode: 0700\n  delegate_to: 127.0.0.1\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - createdir\n\n- name: Ensure all relay keys exist (LOCAL)\n  local_action: command tor --PublishServerDescriptor 0 --orport auto --list-fingerprint --datadirectory \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}\" --Log \"err stdout\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Generate new Ed25519 signing keys (LOCAL)\n  local_action: command tor --keygen --SigningKeyLifetime {{ tor_signingkeylifetime_days}}\\ days --datadirectory \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}\" --Log \"err stdout\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - renewkey\n\n- name: Detect duplicate relay keys across relays (LOCAL)\n  shell: sha1sum {{ tor_offline_masterkey_dir }}/*/keys/secret_id_key {{ tor_offline_masterkey_dir }}/*/keys/ed25519_master_id_secret_key|cut -d/ -f1|sort|uniq -d|wc -l\n  delegate_to: 127.0.0.1\n  register: dupcount\n\n- name: Abort on duplicate relay keys\n  fail: msg=\"Duplicate relay key detected! Aborting.\"\n  when: dupcount.stdout != \"0\"\n\n- name: Detect if Ed25519 master keys are on the relay\n  stat:\n    path: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/ed25519_master_id_secret_key\"\n  become: yes\n  register: masterkeycheck\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Abort if Ed25519 master keys are on the relay\n  fail: msg=\"\n\n            Ed25519 MASTER KEY detected on the relay - it is NOT supposed to be there! Aborting.\"\n  when: item.stat.exists == True\n  with_items: \"{{ masterkeycheck.results }}\"\n\n- name: Collect fingerprints for MyFamily (LOCAL)\n  shell: cut {{ tor_offline_masterkey_dir }}/*/fingerprint -d\" \" -f2|xargs|sed -e 's/ /,/g'\n  delegate_to: 127.0.0.1\n  register: family\n  tags:\n   - reconfigure\n\n- name: Ensure per-instance tor users exist\n  become: yes\n  user:\n    name: _tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\n    system: yes\n    shell: /bin/false\n    createhome: no\n    home: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure per-instance config folders exist (Debian only)\n  become: yes\n  file:\n    path: \"{{ tor_ConfDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    state: directory\n    mode: 0755\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  when: ansible_pkg_mgr == 'apt'\n\n- name: Ensure DataDir exists\n  become: yes\n  file:\n    path: \"{{ tor_DataDir }}\"\n    state: directory\n    owner: root\n    mode: 0755\n\n- name: Ensure \"keys\" subfolder exists\n  become: yes\n  file:\n    path: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys\"\n    state: directory\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    group: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0700\n    recurse: yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure RSA key is in place (without overriding existing keys)\n  become: yes\n  copy:\n    src: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    dest: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0700\n    force: no\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'secret_id_key' ]\n\n- name: Fetch RSA key for comparision\n  become: yes\n  fetch:\n    src: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    dest: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}.untrustedremotekey\"\n    flat: yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'secret_id_key' ]\n\n- name: Compare local vs. remote RSA key (secret_id_key)\n  local_action: shell sha1sum {{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-\"{{ item.0.ipv4 }}_{{ item.1.orport }}\"/keys/secret_id_key*|cut -d/ -f1|uniq -d|wc -l\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  register: rsakey\n\n- name: Abort if local and remote RSA keys do not match\n  fail: 'msg=\"\n\n\n   Key MISMATCH detected: Remote RSA key does not match local key - manual intervention required.\n\n   We detected that the remote host uses an RSA key that was not generated by us.\n   We will not override it with our locally generated key.\n\n   If you want to make use of the remote RSA key you have to override the local key manually:\n\n\n   cd ~/.tor/offlinemasterkeys/<inventoryname>-<IP_port>/keys\n\n   mv secret_id_key.untrustedremotekey secret_id_key\"'\n  when: item.stdout != \"1\"\n  with_items: \"{{ rsakey.results }}\"\n\n# this task is separated from the task named \"Ensure RSA key is in place\" because it is not run with 'force=no'\n- name: Transmit new Ed25519 signing keys\n  become: yes\n  copy:\n    src: \"{{ tor_offline_masterkey_dir }}/{{ inventory_hostname }}-{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    dest: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}/keys/{{ item[2] }}\"\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0700\n    setype: tor_var_lib_t\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'ed25519_signing_cert', 'ed25519_signing_secret_key' ]\n  tags:\n   - renewkey\n\n# This needs to be at the end to fix SELinux contexts recursively\n- name: Ensure per-instance DataDir have proper permissions\n  become: yes\n  file:\n    path: \"{{ tor_DataDir }}/{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    state: directory\n    owner: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    group: \"_tor-{{ item.0.ipv4 }}_{{ item.1.orport }}\"\n    mode: 0700\n    recurse: yes\n    setype: tor_var_lib_t\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure Tor config directory exists\n  become: yes\n  file:\n    path: \"{{ tor_ConfDir }}\"\n    state: directory\n    owner: root\n    group: \"{{ tor_user }}\"\n    mode: 0755\n\n- name: Ensure tor-exit-notice.html is present (if we are an exit)\n  become: yes\n  template:\n    src: tor-exit-notice.html\n    dest: \"{{ tor_ConfDir }}/tor-exit-notice.html\"\n    mode: 0444\n  when: tor_ExitRelay == True and tor_ExitNoticePage == True\n\n- name: Generating torrc file(s)\n  become: yes\n  template:\n    src: torrc\n    dest: \"{{ (ansible_pkg_mgr != 'apt')| ternary(tor_ConfDir ~ '/' ~ item.0.ipv4 ~ '_' ~ item.1.orport ~ '.torrc', tor_ConfDir ~ '/' ~ item.0.ipv4 ~ '_' ~ item.1.orport ~ '/torrc') }}\"\n    owner: root\n    mode: 0644\n    backup: yes\n    validate: \"tor --verify-config -f %s\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  register: instances\n  notify:\n    - Ensure Tor instances are reloaded if its torrc changed (FreeBSD)\n  tags:\n   - reconfigure\n"}, {"commit_sha": "9966c6de1ed4ef5071a9bea83b4bb69a11dd32ba", "sha": "aa767f768eab515e9cd129d92b39618b1ca2d2d7", "filename": "roles/dnsmasq/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# tasks file for dnsmasq\n- name: remove dnsmasq override\n  file: path=/etc/init/dnsmasq.override state=absent\n\n- name: ensure dnsmasq is running (and enable it at boot)\n  service: name=dnsmasq state=started enabled=yes\n\n- name: configure dnsmasq\n  sudo: yes\n  template: src=10-consul.j2 dest=/etc/dnsmasq.d/10-consul owner=root group=root mode=0644\n  notify:\n    - Restart dnsmasq\n  tags:\n    - dnsmasq\n"}, {"commit_sha": "c64269916ee60a23098a45df4b08f814dc7235d2", "sha": "df9a525d38b48dac0393b2d4b4c9511c07dbd5e5", "filename": "tasks/section_02_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "2cfa28fd756194b32e320ab9c0df1e455f27dc38", "decoded_content": "---\n\n  - name: 2.1 Create Separate Partition for /tmp (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /tmp\"\n    tags:\n      - section2\n      - section2.1\n\n  - name: 2.2 - 4 Set nodev, nosuid, noexec option for /tmp Partition (Scored)\n    mount: name=\"/tmp\" state=\"mounted\" opts=\"nodev,nosuid,noexec\"\n    when: partitioning==\"true\"\n    tags:\n      - section2\n      - section2.2\n      - section2.3\n      - section2.4\n\n  - name: 2.5 Create Separate Partition for /var (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var\"\n    tags:\n      - section2\n      - section2.5\n\n  - name: 2.6 Bind Mount the /var/tmp directory to /tmp (Scored)\n    mount: name=\"/var/tmp\" src=\"/tmp\" opts=bind state=mounted\n    when: partitioning==\"true\"\n    tags:\n      - section2\n      - section2.6\n\n  - name: 2.7 Create Separate Partition for /var/log (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var/log\"\n    tags:\n      - section2\n      - section2.7\n\n  - name: 2.8 Create Separate Partition for /var/log/audit (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /var/log/audit\"\n    tags:\n      - section2\n      - section2.8\n\n  - name: 2.9 Create Separate Partition for /home (Scored)\n    debug: msg=\"/!\\ Ensure there is a separate partition dedicated to /home\"\n    tags:\n      - section2\n      - section2.9\n\n  - name: 2.10 Add nodev Option to /home (Scored)\n    mount: name:/home state:mounted opts:remount,nodev\n    when: partitioning==\"true\"\n    tags:\n      - section2\n      - section2.10\n\n  - name: 2.11 Add nodev Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nodev option\"\n    tags:\n      - section2\n      - section2.11\n\n  - name: 2.12 Add noexec Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have noexec option\"\n    tags:\n      - section2\n      - section2.12\n\n  - name: 2.13 Add nosuid Option to Removable Media Partitions (Not Scored)\n    debug: msg=\"/!\\ Ensure removable partitions have nosuid option\"\n    tags:\n      - section2\n      - section2.13\n\n  - name: 2.14 - 16 Add nodev Option to /run/shm Partition (Scored)\n    mount: name=\"/run/shm\" src=\"/run/shm\" state=\"mounted\" opts=\"remount,nodev,nosuid,noexec\" fstype=\"tmpfs\"\n    tags:\n      - section2\n      - section2.14\n      - section2.15\n      - section2.16\n\n  - name: 2.17.1 Set Sticky Bit on All World-Writable Directories (preparation) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type d -perm -0002 -print 2>/dev/null\n    failed_when: False\n    changed_when: False\n    always_run: True\n    register: sticky_bit_dirs\n    tags:\n      - section2\n      - section2.17\n      - section2.17.1\n\n  - name: 2.17.2 Set Sticky Bit on All World-Writable Directories (Scored)\n    file: path={{ item }} mode=\"a+t\"\n    with_items: sticky_bit_dirs.stdout_lines\n    tags:\n      - section2\n      - section2.17\n      - section2.17.2\n\n  - name: 2.25 Disable Automounting (Scored)\n    lineinfile: >\n        dest=/etc/init/autofs.conf\n        line='start on runlevel [2345]'\n        regexp='^start on runlevel [2345]'\n        state=absent\n    tags:\n      - section2\n      - section2.25\n"}, {"commit_sha": "a58e5e6a7e5184c80cf44ff600e8eea60d32cba5", "sha": "8e16ce027e39e201161453ff854f70e993af358b", "filename": "tasks/section_08_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "2cfa28fd756194b32e320ab9c0df1e455f27dc38", "decoded_content": "---\n\n#  - name: 8.2 Configure rsyslog\n#  The rsyslog software is recommended as a replacement for the default syslogd daemon and\n#  provides improvements over syslogd, such as connection-oriented (i.e. TCP) transmission\n#  of logs, the option to log to database formats, and the encryption of log data en route to a\n#  central logging server.\n#  tags:\n#    - section8\n#    - section8.2\n\n\n  - name: 8.2.1 Install the rsyslog package (Scored)\n    apt: name=rsyslog state=present\n    tags:\n      - section8\n      - section8.2\n      - section8.2.1\n\n  - name: 8.2.2 Ensure the rsyslog Service is activated (Scored)\n    command: grep 'start on filesystem' /etc/rsyslog.conf\n    register: startonfilesystem\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.5.2 Configure rsyslog to Send Logs to a Remote Log Host (start rsyslog) (Scored)\n    lineinfile:\n       dest=/etc/rsyslog.conf\n       line='start on filesystem'\n       insertafter=EOF\n       state=present\n    when: startonfilesystem.rc == 1\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.3 Configure /etc/rsyslog.conf (Not Scored)\n    lineinfile:\n        dest: /etc/rsyslog.conf\n        line: \"{{ item }}\"\n        insertafter: EOF\n    with_items:\n      - '*.emerg :omusrmsg:*'\n      - 'mail.* -/var/log/mail'\n      - 'mail.info -/var/log/mail.info'\n      - 'mail.warning -/var/log/mail.warn'\n      - 'mail.err /var/log/mail.err'\n      - 'news.crit -/var/log/news/news.crit'\n      - 'news.err -/var/log/news/news.err'\n      - 'news.notice -/var/log/news/news.notice'\n      - '*.=warning;*.=err -/var/log/warn'\n      - '*.crit /var/log/warn'\n      - '*.*;mail.none;news.none -/var/log/messages'\n      - 'local0,local1.* -/var/log/localmessages'\n      - 'local2,local3.* -/var/log/localmessages'\n      - 'local4,local5.* -/var/log/localmessages'\n      - 'local6,local7.* -/var/log/localmessages'\n    changed_when: False\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.3\n\n  - name: 8.2.4.1 Create and Set Permissions on rsyslog Log Files (check) (Scored)\n    shell: awk '{ print $NF }' /etc/rsyslog.d/* /etc/rsyslog.conf | grep -oiP \"/var/log/[\\w\\.-]+\"\n    register: result\n    changed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.4.2 Create and Set Permissions on rsyslog Log Files (Scored)\n    shell: 'mkdir -p -- \"$(dirname -- {{ item }})\"; touch -- {{ item }}' \n    with_items: \"{{result.stdout_lines}}\"\n    changed_when: False\n    register: rsyslog_files_created\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.4.3 Create and Set Permissions on rsyslog Log Files (Scored)\n    file:\n        path: \"{{ item }}\"\n        owner: root \n        group: \"{{ rsyslog_log_files_group }}\"\n        mode: \"{{ rsyslog_log_files_permissions }}\"\n    when: \"(rsyslog_files_created.results|length > 0) and ('skipped' not in rsyslog_files_created.results[0])\"\n    with_items: \"{{result.stdout_lines}}\"\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.4\n\n  - name: 8.2.5.1 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    command: grep \"^*.*[^I][^I]*@\" /etc/rsyslog.conf\n    register: remoteloghost \n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.5.2 Configure rsyslog to Send Logs to a Remote Log Host (Scored)\n    lineinfile:\n        dest: /etc/rsyslog.conf\n        line: \"*.* @@{{remote_logs_host_address}}\"\n        insertafter: EOF\n        state: present\n    when: set_rsyslog_remote == True and remoteloghost.rc == 1\n    tags:\n      - section8\n      - section8.2\n      - section8.2.5\n\n  - name: 8.2.6.1 Accept Remote rsyslog Messages Only on Designated Log Hosts (check) (Not Scored)\n    command: grep '^$ModLoad imtcp' /etc/rsyslog.conf\n    register: moadloadpresent\n    changed_when: False\n    failed_when: False\n    always_run: True\n    tags:\n      - section8\n      - section8.2\n      - section8.2.6\n\n  - name: 8.2.6.2 Accept Remote rsyslog Messages Only on Designated Log Hosts (Not Scored)\n    lineinfile:\n        dest: /etc/rsyslog.conf\n        regexp: \"^#({{ item }})\"\n        line: \"{{ item }}\"\n        state: present\n    with_items:\n        - '$ModLoad imtcp'\n        - '$InputTCPServerRun 514'\n    when: set_rsyslog_remote == True and moadloadpresent.rc == 1\n    changed_when: False\n    notify: restart rsyslog\n    tags:\n      - section8\n      - section8.2\n      - section8.2.6\n"}, {"commit_sha": "c7cf019326c96b15ccee3b7bf4e14ff0bb894cf0", "sha": "04fa9e3f93b21f5e2f4ca67b0a4247aa7f62878c", "filename": "tasks/main.yml", "repository": "willshersystems/ansible-sshd", "release_starts_at": "", "release_ends_at": "", "release": "f68fb55dad755ed4d4296695cd7271c7307e4a56", "decoded_content": "---\n- name: Set OS dependent variables\n  include_vars: \"{{ item }}\"\n  with_first_found:\n   - \"{{ ansible_distribution }}_{{ ansible_distribution_major_version }}.yml\"\n   - \"{{ ansible_distribution }}.yml\"\n   - \"{{ ansible_os_family }}_{{ ansible_distribution_major_version }}.yml\"\n   - \"{{ ansible_os_family }}.yml\"\n   - default.yml\n  tags:\n    - sshd\n\n- name: OS is supported\n  assert:\n    that: sshd_os_supported == True\n\n- name: Installed\n  action: >\n    {{ ansible_pkg_mgr }}\n    name=\"{{ item }}\"\n    state=installed\n  with_items: sshd_packages\n  tags:\n    - sshd\n\n- name: Run directory\n  file:\n    path: /var/run/sshd\n    state: directory\n    mode: 0755\n  tags:\n    - sshd\n\n- name: Configuration\n  template:\n    src: sshd_config.j2\n    dest: \"{{ sshd_config_file }}\"\n    owner: \"{{ sshd_config_owner }}\"\n    group: \"{{ sshd_config_group }}\"\n    mode: \"{{ sshd_config_mode }}\"\n    validate: \"{{ sshd_binary }} -t -f %s\"\n  notify: reload_sshd\n  tags:\n    - sshd\n\n- name: Service enabled and running\n  service:\n    name: \"{{ sshd_service }}\"\n    enabled: true\n    state: running\n  when: sshd_manage_service\n  tags:\n    - sshd\n\n- name: Register that this role has run\n  set_fact: sshd_has_run=true\n  when: sshd_has_run is not defined\n"}, {"commit_sha": "4aaf839a9916f65d12b8964b23dbc6848a73ca67", "sha": "d4eb61882837a2db4ab7886a09ecf398c073d573", "filename": "roles/weave/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": null, "release_ends_at": "dfa8978dc272945b9b4fce761c4bb23af2dd6653", "decoded_content": "---\n# handlers file for weave\n- name: Up weave interface\n  shell: ifup weave\n  sudo: yes\n\n- name: Down weave interface\n  shell: ifdown weave\n  sudo: yes\n\n- name: Restart networking\n  service: name=networking state=restarted\n  sudo: yes\n\n- name: Weave launch\n  command: /usr/local/bin/weave launch\n  sudo: yes\n  tags:\n    - weave\n"}, {"commit_sha": "95a0ffb87f5a5ecbf178ee4a5b4f890acaba6cbe", "sha": "5bc3923f0fd6ab8f87b87ea68653c6b489ffaad6", "filename": "tasks/configure.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "1224adf2811c827a09ff0bf133fbb476901a547d", "decoded_content": "---\n\n- name: Ensure local key folders exist (LOCAL)\n  file: path={{ offline_masterkey_dir }}/{{ item[0] }}_{{ item.1.orport }}/keys\n    state=directory mode=700\n  delegate_to: 127.0.0.1\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - createdir\n\n- name: Ensure all relay keys exist (LOCAL)\n  local_action: command tor --PublishServerDescriptor 0 --orport 1234 --list-fingerprint --datadirectory \"{{ offline_masterkey_dir }}/{{ item[0] }}_{{ item.1.orport }}\" --Log \"err stdout\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Generate new Ed25519 signing keys\n  local_action: command tor --keygen --SigningKeyLifetime {{ tor_signingkeylifetime_days}}\\ days --datadirectory \"{{ offline_masterkey_dir }}/{{ item[0] }}_{{ item.1.orport }}\" --Log \"err stdout\"\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - renewkey\n\n- name: Detect duplicate relay keys across relays (LOCAL)\n  shell: sha1sum {{ offline_masterkey_dir }}/*/keys/secret_id_key {{ offline_masterkey_dir }}/*/keys/ed25519_master_id_secret_key|cut -d/ -f1|sort|uniq -d|wc -l\n  delegate_to: 127.0.0.1\n  register: dupcount\n\n- name: Abort on duplicate relay keys\n  fail: msg=\"Duplicate relay key detected! Aborting.\"\n  when: dupcount.stdout != \"0\"\n\n- name: Detect if Ed25519 master keys are on the relay\n  stat: path={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}/keys/ed25519_master_id_secret_key\n  become: yes\n  register: masterkeycheck\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Abort if Ed25519 master keys are on the relay\n  fail: msg=\"\n\n            Ed25519 MASTER KEY detected on the relay - it is NOT supposed to be there! Aborting.\"\n  when: item.stat.exists == True\n  with_items: masterkeycheck.results\n\n- name: Collect fingerprints for MyFamily (LOCAL)\n  shell: cut {{ offline_masterkey_dir }}/*/fingerprint -d\" \" -f2|xargs|sed -e 's/ /,/g'\n  delegate_to: 127.0.0.1\n  register: family\n  tags:\n   - reconfigure\n\n- name: Ensure per-instance tor users exist\n  become: yes\n  user: name=_tor-{{ item[0] }}_{{ item.1.orport }} system=yes shell=/bin/false createhome=no home={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - createdir\n\n- name: Ensure per-instance config folders exist (Debian only)\n  become: yes\n  file: path={{ tor_ConfDir }}/{{ item[0] }}_{{ item.1.orport }} state=directory mode=755\n  with_nested:\n   - tor_ips\n   - tor_ports\n  when: ansible_pkg_mgr == 'apt'\n  tags:\n   - createdir\n\n- name: Ensure DataDir exists\n  become: yes\n  file: path={{ tor_DataDir }}\n    state=directory\n    owner=root\n    mode=0755\n  tags:\n   - createdir\n\n- name: Ensure per-instance DataDir exists\n  become: yes\n  file: path={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}\n    state=directory\n    owner=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n    group=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n    mode=0700\n    recurse=yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  tags:\n   - createdir\n\n- name: Ensure \"keys\" subfolder exists\n  become: yes\n  file: path={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}/keys\n    state=directory\n    owner=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n    group=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n    mode=0700\n    recurse=yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n\n- name: Ensure RSA key is in place (without overriding existing keys)\n  become: yes\n  copy: src={{ offline_masterkey_dir }}/{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}\n   dest={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}\n   owner=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n   mode=700 force=no\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'secret_id_key' ]\n\n- name: Fetch RSA key for comparision\n  become: yes\n  fetch: src={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}\n    dest={{ offline_masterkey_dir }}/{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}.untrustedremotekey\n    flat=yes\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'secret_id_key' ]\n\n- name: Compare local vs. remote RSA key (secret_id_key)\n  local_action: shell sha1sum {{ offline_masterkey_dir }}/\"{{ item[0] }}_{{ item.1.orport }}\"/keys/secret_id_key*|cut -d/ -f1|uniq -d|wc -l\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n  register: rsakey\n\n- name: Abort if local and remote RSA keys do not match\n  fail: 'msg=\"\n\n\n   Key MISMATCH detected: Remote RSA key does not match local key - manual intervention required.\n\n   We deteted that the remote host uses an RSA key that was not generated by us.\n   We will not override it with our locally generated key.\n\n   If you want to make use of the remote RSA key you have to override the local key manually:\n\n\n   cd ~/.tor/offlinemasterkeys/<IP_port>/keys\n\n   mv secret_id_key.untrustedremotekey secret_id_key\"'\n  when: item.stdout != \"1\"\n  with_items: rsakey.results\n\n# this task is separated from the task named \"Ensure RSA key is in place\" because it is not run with 'force=no'\n- name: Renew Ed25519 signing keys\n  become: yes\n  copy: src={{ offline_masterkey_dir }}/{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}\n   dest={{ tor_DataDir }}/{{ item[0] }}_{{ item.1.orport }}/keys/{{ item[2] }}\n   owner=\"_tor-{{ item[0] }}_{{ item.1.orport }}\"\n   mode=700\n  with_nested:\n   - \"{{ tor_ips }}\"\n   - \"{{ tor_ports }}\"\n   - [ 'ed25519_master_id_public_key', 'ed25519_signing_cert', 'ed25519_signing_secret_key' ]\n  tags:\n   - renewkey\n\n- name: Ensure Tor config directory exists\n  become: yes\n  file: path={{ tor_ConfDir }}\n    state=directory\n    owner=root\n    group={{ tor_user }}\n    mode=755\n\n- name: Ensure LogDir exists\n  become: yes\n  file: path={{ tor_LogDir }}\n    state=directory\n    owner=root\n    mode=755\n  when: ansible_pkg_mgr != 'apt'\n\n# we only use distinct logfiles on systems that have no SyslogIdentityTag support yet (all non-Debian plaforms)\n# otherwise we log to syslog with SyslogIdentityTag to avoid the filesystem permissions troubles with logrotate.\n# We aim to log to syslog+SyslogIdentityTag for all platforms eventually.\n# This is a medium-term workaround until all platform get SyslogIdentityTag support\n# without this workaround tor will fail to start after logrotate created new logfiles because\n# logrotate is not not aware that every tor instance runs under a distinct user.\n# This effectively disables logrotate.\n- name: Ensure per-instance LogDir exists\n  become: yes\n  file: path={{ tor_LogDir }}/{{ item[0] }}_{{ item.1.orport }}\n    state=directory\n    owner=_tor-{{ item[0] }}_{{ item.1.orport }}\n    group=_tor-{{ item[0] }}_{{ item.1.orport }}\n    mode=700\n  with_nested:\n   - tor_ips\n   - tor_ports\n  when: ansible_pkg_mgr != 'apt'\n\n- name: Generating torrc file(s)\n  become: yes\n  template: >\n    src=torrc\n    dest=\"{{ (ansible_pkg_mgr != 'apt')| ternary(tor_ConfDir ~ '/' ~ item[0] ~ '_' ~ item.1.orport ~ '.torrc', tor_ConfDir ~ '/' ~ item[0] ~ '_' ~ item.1.orport ~ '/torrc') }}\"\n    owner=root\n    mode=0644\n    backup=yes\n    validate=\"tor --verify-config -f %s\"\n  with_nested:\n   - tor_ips\n   - tor_ports\n  register: instances\n  tags:\n   - reconfigure\n"}, {"commit_sha": "9966c6de1ed4ef5071a9bea83b4bb69a11dd32ba", "sha": "04d791a19d127bd54fe5cf9f0c7d8befb92d0dce", "filename": "roles/marathon/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# tasks file for marathon\n- name: Set Marathon hostname\n  copy:\n    content: \"{{marathon_local_address}}\"\n    dest: /etc/marathon/conf/hostname\n    mode: 0644\n  sudo: yes\n\n- name: remove marathon override\n  file: path=/etc/init/marathon.override state=absent\n\n- name: ensure marathon is running (and enable it at boot)\n  service: name=marathon state=started enabled=yes\n\n- name: Set Marathon consul service definition\n  sudo: yes\n  template:\n    src: marathon-consul.j2\n    dest: \"{{ consul_dir }}/marathon.json\"\n  notify:\n    - Restart consul\n"}, {"commit_sha": "35ca6852d9333ef6c3ed223239f45b840c487d60", "sha": "99310146f6beb941de3a0381a7501b1beef8f1c1", "filename": "roles/mesos/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# handlers file for mesos\n- name: Start mesos master\n  sudo: yes\n  service:\n    name: mesos-master\n    state: started\n\n- name: Start mesos slave\n  sudo: yes\n  service:\n    name: mesos-slave\n    state: started\n\n- name: Restart mesos master\n  sudo: yes\n  service:\n    name: mesos-master\n    state: restarted\n\n- name: Restart mesos slave\n  sudo: yes\n  service:\n    name: mesos-slave\n    state: restarted\n"}, {"commit_sha": "9966c6de1ed4ef5071a9bea83b4bb69a11dd32ba", "sha": "f4f147ba603e923f433db23b81dd874a4284fcf7", "filename": "roles/registrator/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n\n# Install (docker-py) python package as is a docker module dependency.\n- pip: name=docker-py version=1.1.0\n\n# tasks file for docker registrator\n- name: run registrator container\n  docker:\n    name: registrator\n    image: \"{{ registrator_image }}\"\n    state: started\n    restart_policy: always\n    net: host\n    command: \"-internal {{ registrator_uri }}\"\n    hostname: \"{{ hostname }}\"\n    volumes:\n    - \"/var/run/docker.sock:/tmp/docker.sock\"\n"}, {"commit_sha": "4aaf839a9916f65d12b8964b23dbc6848a73ca67", "sha": "857fed300e00aea36715e34aa5c3168299eaef42", "filename": "roles/weave/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": null, "release_ends_at": "dfa8978dc272945b9b4fce761c4bb23af2dd6653", "decoded_content": "---\n# defaults file for weave\nweave_bridge: \"10.2.0.1/16\"\nweave_server_group: weave_servers\nweave_docker_subnet: \"\n    {%- for host in groups[weave_server_group] -%}\n      {%- if host == 'default' or host == inventory_hostname or host == ansible_fqdn or host in ansible_all_ipv4_addresses -%}\n        10.2.{{ loop.index }}.0/24\n      {%- endif -%}\n    {%- endfor -%}\n\"\n"}, {"commit_sha": "cb153a13ab607e1c015fec227d8f74cfbb3d9b8e", "sha": "3310b1d762a9eee9880e4e6b1d4f67899fd7d7bf", "filename": "tasks/main.yml", "repository": "willshersystems/ansible-sshd", "release_starts_at": "", "release_ends_at": "", "release": "f68fb55dad755ed4d4296695cd7271c7307e4a56", "decoded_content": "---\n- name: Set OS dependent variables\n  include_vars: \"{{ item }}\"\n  with_first_found:\n   - \"{{ ansible_distribution }}_{{ ansible_distribution_major_version }}.yml\"\n   - \"{{ ansible_distribution }}.yml\"\n   - \"{{ ansible_os_family }}_{{ ansible_distribution_major_version }}.yml\"\n   - \"{{ ansible_os_family }}.yml\"\n   - default.yml\n  tags:\n    - sshd\n\n- name: OS is supported\n  assert:\n    that: sshd_os_supported == True\n  tags:\n    - sshd\n\n- name: Installed\n  action: >\n    {{ ansible_pkg_mgr }}\n    name=\"{{ item }}\"\n    state=installed\n  with_items: sshd_packages\n  tags:\n    - sshd\n\n- name: Run directory\n  file:\n    path: /var/run/sshd\n    state: directory\n    mode: 0755\n  when: sshd_manage_var_run\n  tags:\n    - sshd\n\n- name: Configuration\n  template:\n    src: sshd_config.j2\n    dest: \"{{ sshd_config_file }}\"\n    owner: \"{{ sshd_config_owner }}\"\n    group: \"{{ sshd_config_group }}\"\n    mode: \"{{ sshd_config_mode }}\"\n    validate: \"{{ sshd_binary }} -t -f %s\"\n  notify: reload_sshd\n  tags:\n    - sshd\n\n- name: Service enabled and running\n  service:\n    name: \"{{ sshd_service }}\"\n    enabled: true\n    state: running\n  when: sshd_manage_service\n  tags:\n    - sshd\n\n- name: Register that this role has run\n  set_fact: sshd_has_run=true\n  when: sshd_has_run is not defined\n  tags:\n    - sshd\n"}, {"commit_sha": "9966c6de1ed4ef5071a9bea83b4bb69a11dd32ba", "sha": "accda5820ce8fe2a9a4cf851c0ad1586b6e40924", "filename": "roles/marathon/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# handlers file for marathon\n# Restart service marathon, in all cases\n- name: Restart marathon\n  service: name=marathon state=restarted\n  sudo: yes\n"}, {"commit_sha": "0f46bc2b1f4dac71c882be0ee48a25332a90ed40", "sha": "b865049f2128ad2482c7571c832fa14bbfe3b42a", "filename": "roles/marathon/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": null, "release_ends_at": "dfa8978dc272945b9b4fce761c4bb23af2dd6653", "decoded_content": "---\n# defaults file for marathon\nmarathon_port: 8080\nconsul_dir: /etc/consul.d\n"}, {"commit_sha": "80530fde7df1a94ad361434e02816b0816a2c47a", "sha": "13d7d6c115a3ea0a61756707c129238ff9028b71", "filename": "roles/mesos/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": null, "release_ends_at": "dfa8978dc272945b9b4fce761c4bb23af2dd6653", "decoded_content": "---\n# defaults file for mesos\nmesos_zk_port: 2181\nmesos_zookeeper_group: zookeeper_servers\nmesos_master_port: 5050\nconsul_dir: /etc/consul.d\nmesos_local_address: \"{{ ansible_default_ipv4.address }}\"\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "adad3ac99b5da81fd4dd787780e84b1e29034cac", "filename": "roles/st2/handlers/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": null, "release_ends_at": "2d0f3f1cf5d5919432c94bb3659c16b85d1cb1db", "decoded_content": "- name: restart st2\n  sudo: true\n  service:\n    name: \"{{ item }}\"\n    state: restarted\n  with_items: st2_services\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "123c87b4237cfcdb1fd6bf973406994273405da8", "filename": "roles/dnsmasq/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# tasks file for dnsmasq\n- name: create dnsmasq config directory\n  file:\n    path: \"/etc/dnsmasq.d\"\n    state: directory\n    mode: 0755\n  sudo: yes\n  tags:\n    - dnsmasq\n\n- name: configure consul resolution dnsmasq\n  sudo: yes\n  template:\n    src: 10-consul.j2\n    dest: /etc/dnsmasq.d/10-consul\n    owner: root\n    group: root\n    mode: 0644\n  notify:\n    - restart dnsmasq\n  tags:\n    - dnsmasq\n\n# This should be using -cap-add=NET_ADMIN rather than privileged: true.\n# This will be supported in Ansible 2.0\n- name: run dnsmasq container\n  docker:\n    name: dnsmasq\n    image: \"andyshinn/dnsmasq\"\n    state: started\n    net: \"host\"\n    privileged: true\n    volumes:\n    - \"{{ dnsmasq_config_folder }}/:{{ dnsmasq_config_folder }}/\"\n    ports:\n    - \"53:53/tcp\"\n    - \"53:53/udp\"\n    command: \"-r {{ dnsmasq_resolvconf_file }} --conf-dir={{ dnsmasq_config_folder }}\"\n\n- name: upload dnsmasq template service\n  template:\n    src: dnsmasq.conf.j2\n    dest: /etc/init/dnsmasq.conf\n    mode: 0755\n  sudo: yes\n  tags:\n    - dnsmasq\n\n- name: ensure dnsmasq is running (and enable it at boot)\n  service:\n    name: dnsmasq\n    state: started\n    enabled: yes\n  tags:\n    - dnsmasq\n"}, {"commit_sha": "e8eb28b4b4b1c4fb2490b8198570166b9ca23ab2", "sha": "abbb248f75b32a702abb96afd89f63e84378a32f", "filename": "roles/mistral/vars/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": null, "release_ends_at": "2d0f3f1cf5d5919432c94bb3659c16b85d1cb1db", "decoded_content": "mistral_branches:\n  - if: 0.0.0\n    then: st2-0.5.1\n  - if: 0.8.0\n    then: st2-0.8\n  - if: 0.8.1\n    then: st2-0.8.1\n  - if: 0.9.0\n    then: st2-0.9.0\n"}, {"commit_sha": "8cf75eb68465f1126872131afd102e05068a9df2", "sha": "00d58864de53f30f28a0d9d6d27b0ebda9d22f2d", "filename": "tasks/yum_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "1224adf2811c827a09ff0bf133fbb476901a547d", "decoded_content": "---\n\n- name: Add tor rpm key\n  sudo: yes\n  rpm_key: state=present key=https://deb.torproject.org/torproject.org/rpm/RPM-GPG-KEY-torproject.org.asc\n\n- set_fact: tor_rpm_distribution_os=\"el\"\n  when: ansible_distribution == 'CentOS' or ansible_distribution == \"Red Hat Enterprise Linux\"\n\n# we do not actually support Fedora\n- set_fact: tor_rpm_distribution_os=\"fc\"\n  when: ansible_distribution == 'Fedora'\n\n# the tor_alpha var is taken into account here (template)\n- name: Add torproject.org repository (YUM)\n  sudo: yes\n  template: src=torproject.yum.repo dest=/etc/yum.repos.d/torproject.repo owner=root group=root\n\n# we specifically opt for present over latest to improve performance\n# \"latest\" is covered by auto updates\n- name: Ensure Tor package is installed (YUM)\n  sudo: yes\n  yum: name=tor state=present\n\n# we need this for the seboolean ansible module to work\n- name: Ensure setsebool (SELinux) dependencies are installed (CentOS)\n  sudo: yes\n  yum: name=libsemanage-python state=present\n\n- name: Ensure the presence of the multi-instance systemd unit file (CentOS)\n  sudo: yes\n  copy: src=centos_tor@.service dest=/lib/systemd/system/tor@.service owner=root mode=0644 backup=yes setype=tor_unit_file_t\n  notify: systemctl daemon-reload\n\n- name: Ensure SELinux boolean (tor_can_network_relay) is set appropriately (CentOS)\n  sudo: yes\n  seboolean: name=tor_can_network_relay state=yes persistent=yes\n\n- meta: flush_handlers\n"}, {"commit_sha": "53f9bc7e6a098557bf13ade27a1ec9206a39708c", "sha": "57a9405d42bca3e4df80a9e1ec970e677e5e3c92", "filename": "tasks/tls.yml", "repository": "brianshumate/ansible-consul", "release_starts_at": null, "release_ends_at": "6f2fdbaf6a98476a156102c6215391a09c3e6a42", "decoded_content": "---\n# File: tls.yml - TLS tasks for Consul\n\n- name: Create SSL directory\n  file:\n    dest: \"{{ consul_tls_dir }}\"\n    state: directory\n    owner: \"{{ consul_user }}\"\n    group: \"{{ consul_group }}\"\n    mode: 0755\n\n- block:\n    - name: Copy CA certificate\n      copy:\n        remote_src: \"{{ consul_tls_files_remote_src }}\"\n        src: \"{{ consul_tls_src_files }}/{{ consul_tls_ca_crt | basename }}\"\n        dest: \"{{ consul_tls_dir }}/{{ consul_tls_ca_crt }}\"\n        owner: \"{{ consul_user }}\"\n        group: \"{{ consul_group }}\"\n        mode: 0644\n\n    - name: Copy server certificate\n      copy:\n        remote_src: \"{{ consul_tls_files_remote_src }}\"\n        src: \"{{ consul_tls_src_files }}/{{ consul_tls_server_crt | basename }}\"\n        dest: \"{{ consul_tls_dir }}/{{ consul_tls_server_crt }}\"\n        owner: \"{{ consul_user }}\"\n        group: \"{{ consul_group }}\"\n        mode: 0644\n\n    - name: Copy server key\n      copy:\n        remote_src: \"{{ consul_tls_files_remote_src }}\"\n        src: \"{{ consul_tls_src_files }}/{{ consul_server_key | basename }}\"\n        dest: \"{{ consul_tls_dir }}/{{ consul_server_key }}\"\n        owner: \"{{ consul_user }}\"\n        group: \"{{ consul_group }}\"\n        mode: 0600\n\n  when: consul_tls_copy_keys | bool\n"}, {"commit_sha": "e90eac100980db35187b1c8829e3284cc5db3e30", "sha": "beb2d572be2a61f189b85ce602515d6c9cca50ec", "filename": "tasks/section_12_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "2cfa28fd756194b32e320ab9c0df1e455f27dc38", "decoded_content": "---\n\n  - name: 12.1 Verify Permissions on /etc/passwd (Scored)\n    file: path=/etc/passwd mode=0644\n    tags:\n      - section12\n      - section12.1\n\n  - name: 12.2 Verify Permissions on /etc/shadow (Scored)\n    file: path=/etc/shadow mode='o-rwx,g-rw'\n    tags:\n      - section12\n      - section12.2\n\n  - name: 12.3 Verify Permissions on /etc/group (Scored)\n    file: path=/etc/group mode=0644\n    tags:\n      - section12\n      - section12.3\n\n  - name: 12.4 Verify User/Group Ownership on /etc/passwd (Scored)\n    file: path=/etc/passwd owner=root group=root\n    tags:\n      - section12\n      - section12.4\n\n  - name: 12.5 Verify User/Group Ownership on /etc/shadow (Scored)\n    file: path=/etc/shadow owner=root group=shadow\n    tags:\n      - section12\n      - section12.5\n\n  - name: 12.6 Verify User/Group Ownership on /etc/group (Scored)\n    file: path=/etc/group owner=root group=root\n    tags:\n      - section12\n      - section12.6\n\n  - name: 12.7 Find World Writable Files (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -0002 -print\n    changed_when: False\n    failed_when: False\n    register: world_files\n    tags:\n      - section12\n      - section12.7\n\n  - name: 12.7 Find World Writable Files (Not Scored)\n    debug: msg='{{ item }}'\n    with_items:\n        world_files.stdout_lines\n    tags:\n      - section12\n      - section12.7\n\n  - name: 12.8 Find Un-owned Files and Directories (check) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -nogroup -ls\n    changed_when: False\n    failed_when: False\n    register: unowned_files\n    tags:\n      - section12\n      - section12.8\n\n  - name: 12.8 Find Un-owned Files and Directories (Scored)\n    debug: msg=\"{{ item }}\"\n    with_items:\n        unowned_files.stdout_lines\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.9 Find Un-grouped Files and Directories (check) (Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -nogroup -ls\n    changed_when: False\n    failed_when: False\n    register: ungrouped_files\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.9 Find Un-grouped Files and Directories (Scored)\n    debug: >\n        msg=\"{{ item }}\"\n    with_items:\n        ungrouped_files.stdout_lines\n    tags:\n      - section12\n      - section12.9\n\n  - name: 12.10 Find SUID System Executables (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -4000 -print\n    changed_when: False\n    failed_when: False\n    register: suid_files\n    tags:\n      - section12\n      - section12.10\n\n  - name: 12.10 Find SUID System Executables (Not Scored)\n    debug: msg='{{ item }}'\n    with_items:\n        suid_files.stdout_lines\n    tags:\n      - section12\n      - section12.10\n\n  - name: 12.11 Find SGID System Executables (check) (Not Scored)\n    shell: df --local -P | awk {'if (NR!=1) print $6'} | xargs -I '{}' find '{}' -xdev -type f -perm -2000 -print\n    changed_when: False\n    failed_when: False\n    register: gsuid_files\n    tags:\n      - section12\n      - section12.11\n\n  - name: 12.11 Find SGID System Executables (Not Scored)\n    debug: msg='{{ item }}'\n    with_items:\n        gsuid_files.stdout_lines\n    tags:\n      - section12\n      - section12.10\n"}, {"commit_sha": "addbee435e20e706e7cf5d2f0a3723e17f79b527", "sha": "b2162b6241d6055e60c3b057bf078cb25b044990", "filename": "tasks/section_04_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "2cfa28fd756194b32e320ab9c0df1e455f27dc38", "decoded_content": "---\n\n  - name: 4.1.1 Restrict Core Dumps (Scored)\n    lineinfile: dest='/etc/security/limits.conf' line=\"* hard core 0\" state=present\n    tags:\n      - section4\n      - section4.1\n      - section4.1.1\n\n  - name: 4.1.2 Restrict Core Dumps (Scored)\n    sysctl: >\n        name=fs.suid_dumpable\n        value=0\n        state=present\n    when: travis_env == False\n    tags:\n      - section4\n      - section4.1\n      - section4.1.2\n\n  - name: 4.1.4 Restrict Core Dumps (stat file) (Scored)\n    stat: path='/etc/init/apport.conf'\n    register: apport_present\n    tags:\n      - section4\n      - section4.1\n      - section4.1.4\n\n  - name: 4.1.5 Restrict Core Dumps (Scored)\n    lineinfile: >\n        dest='/etc/init/apport.conf'\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n    when: apport_present.stat.exists == True\n    tags:\n      - section4\n      - section4.1\n      - section4.1.3\n\n  - name: 4.1.6 Restrict Core Dumps (stat file) (Scored)\n    stat: path='/etc/init/whoopsie.conf'\n    register: whoopsie_present\n    tags:\n      - section4\n      - section4.1\n      - section4.1.4\n\n  - name: 4.1.7 Restrict Core Dumps (Scored)\n    lineinfile: >\n        dest='/etc/init/whoopsie.conf'\n        line='#start on runlevel [2345]'\n        state=present\n        regexp='start on runlevel'\n    when: whoopsie_present.stat.exists == True\n    tags:\n      - section4\n      - section4.1\n      - section4.1.4\n\n  - name: 4.2 Enable XD/NX Support on 32-bit x86 Systems (read dmesg) (Not Scored)\n    shell: 'dmesg | grep NX'\n    register: nx_result\n    failed_when: nx_result.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section4\n      - section4.2\n\n  - name: 4.3 Enable Randomized Virtual Memory Region Placement (Scored)\n    sysctl: >\n       name=kernel.randomize_va_space\n       value=2\n       state=present\n    tags:\n      - section4\n      - section4.3\n\n  - name: 4.4 Disable Prelink (check) (Scored)\n    stat: path=/usr/bin/prelink\n    register: prelink_rc\n    tags:\n      - section4\n      - section4.4\n\n  - name: 4.4 Disable Prelink (restore) (Scored)\n    command: '/usr/bin/prelink -ua'\n    when: prelink_rc.stat.exists == True\n    tags:\n      - section4\n      - section4.4\n\n  - name: 4.4 Disable Prelink (remove) (Scored)\n    apt: purge=yes name='prelink' state=absent\n    when: prelink_rc.stat.exists == True\n    tags:\n      - section4\n      - section4.4\n"}, {"commit_sha": "12d2d30c292e5749809cd7476458762a4de31554", "sha": "fa4a2949bbb6f8e178459fd3057c8baafeee1352", "filename": "tasks/openbsd_install.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "1224adf2811c827a09ff0bf133fbb476901a547d", "decoded_content": "---\n\n- name: Setup OpenBSD specific variables (set_fact)\n  set_fact:\n    tor_DataDir: /var/tor\n    tor_PidDir: /var/tor/pids\n  tags: configure\n\n- name: Gather current tor install state (OpenBSD)\n  command: \"pkg_info -qe tor-*\"\n  ignore_errors: yes\n  register: torpkg\n\n# the following task fails HARD on purpose (if ports are not there)\n# TODO: add an opt-in var that takes care of installing ports\n- name: Install tor from ports (OpenBSD)\n  sudo: yes\n  shell: \"cd /usr/ports/net/tor && make install\"\n  when: torpkg.rc == 1\n\n- name: Gather current system-wide file descriptor limits (OpenBSD)\n  shell: \"sysctl kern.maxfiles|cut -d= -f2\"\n  register: currentlimits\n\n- name: Ensure system-wide runtime file descriptor limits are reasonable (OpenBSD)\n  sudo: yes\n  command: \"sysctl kern.maxfiles=20000\"\n  when: currentlimits.stdout|int < 20000\n\n- name: Ensure system-wide persistent file descriptor limits are reasonable (OpenBSD)\n  sudo: yes\n  lineinfile: dest=/etc/sysctl.conf regexp=^kern.maxfiles line=\"kern.maxfiles=20000\" create=yes\n  when: currentlimits.stdout|int < 20000\n\n- name: Ensure Tor process file descriptor limits are reasonable (OpenBSD)\n  sudo: yes\n  lineinfile: \"dest=/etc/login.conf line='{{ tor_loginclass }}::openfiles-max=13500::tc=daemon:'\"\n  #TODO\n  #notify: restart tor\n\n- name: Ensure 'tor_user' has appropriate login class set (OpenBSD)\n  sudo: yes\n  user: name={{ tor_user }} login_class={{ tor_loginclass }}\n  #TODO \n  #notify: restart tor\n"}, {"commit_sha": "e8eb28b4b4b1c4fb2490b8198570166b9ca23ab2", "sha": "bdf96dfcab10933497d064cc3f7f27db7a06a5cc", "filename": "roles/mistral/tasks/sync.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": null, "release_ends_at": "2d0f3f1cf5d5919432c94bb3659c16b85d1cb1db", "decoded_content": "- name: Sync database\n  shell: /opt/openstack/mistral/.venv/bin/python ./tools/sync_db.py --config-file /etc/mistral/mistral.conf\n  args:\n    chdir: /opt/openstack/mistral\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "584131398c3d537842340162578f7755893516b4", "filename": "roles/marathon/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# defaults file for marathon\nmarathon_consul_dir: /etc/consul.d\nmarathon_enabled: true\nmarathon_version: '0.13.0'\nmarathon_restart_policy: 'always'\nmarathon_net: 'host'\nmarathon_hostname: \"{{ ansible_ssh_host }}\"\nmarathon_port: '8080'\nmarathon_container_memory_limit: '512MB'\nmarathon_java_settings: '-Xmx512m -Xms512m -XX:+HeapDumpOnOutOfMemoryError'\nmarathon_artifact_store: 'file:///store'\nmarathon_artifact_store_dir: '/etc/marathon/store'\nmarathon_server_zk_group: marathon_servers\nmarathon_rebuild_container: False\nmarathon_image: \"mesosphere/marathon:v{{ marathon_version }}\"\nmarathon_master_peers: \"zk://{{ zookeeper_peers_nodes }}/mesos\"\nmarathon_zk_peers: \"zk://{{ zookeeper_peers_nodes }}/marathon\"\nmarathon_command: \"--event_subscriber http_callback --artifact_store {{ marathon_artifact_store }} --hostname {{ marathon_hostname }} --master {{ marathon_master_peers }} --zk {{ marathon_zk_peers }}\"\n"}, {"commit_sha": "addbee435e20e706e7cf5d2f0a3723e17f79b527", "sha": "5fb2fb9ee3c5b833a047058872cb18c0d5cd7472", "filename": "tasks/section_01_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "2cfa28fd756194b32e320ab9c0df1e455f27dc38", "decoded_content": "---\n\n  - name: 1.1.1 Install Updates, Patches and Additional Security Software (NotScored)\n    apt: update_cache=yes\n    tags:\n      - section1\n      - section1.1\n      - section1.1.1\n\n  - name: 1.1.2 Install Updates, Patches and Additional Security Software (NotScored)\n    apt: upgrade=yes\n    when: travis_env == False\n    tags:\n      - section1\n      - section1.1\n      - section1.1.2\n"}, {"commit_sha": "21712b74b7f5d936e70186bbed6bb37e3a7ad5e6", "sha": "6bbfd2ffb3fd54c06c2cc363711f1f3eccbf8f2a", "filename": "roles/mesos/tasks/master.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# Tasks for Master nodes\n\n- name: set mesos-master consul service definition\n  when: mesos_install_mode == \"master\"\n  sudo: yes\n  template:\n    src: mesos-master-consul.j2\n    dest: \"{{ consul_dir }}/mesos-master.json\"\n  notify:\n    - restart consul\n  tags:\n    - mesos-master\n\n- name: create mesos-master work directory\n  when: mesos_install_mode == \"master\"\n  file:\n    path: \"{{ mesos_master_work_dir }}\"\n    state: directory\n    mode: 0755\n  sudo: yes\n  tags:\n    - mesos-master\n\n- name: run mesos-master container\n  when: mesos_install_mode == \"master\"\n  docker:\n    name: mesos-master\n    image: \"mesosphere/mesos-master:0.23.0-1.0.ubuntu1404\"\n    state: started\n    volumes:\n    - \"{{ mesos_master_work_dir }}:{{ mesos_master_work_dir }}\"\n    ports:\n    - \"{{ mesos_master_port }}:{{ mesos_master_port }}\"\n    net: \"host\"\n    env:\n      MESOS_HOSTNAME: \"{{ mesos_hostname }}\"\n      MESOS_IP: \"{{ mesos_ip }}\"\n      MESOS_CLUSTER: \"{{ mesos_cluster_name }}\"\n      MESOS_ZK: \"zk://{{ zookeeper_peers_nodes }}/mesos\"\n      MESOS_LOG_DIR: \"/var/log/mesos\"\n      MESOS_QUORUM: \"{{ mesos_quorum }}\"\n      MESOS_WORK_DIR: \"{{ mesos_master_work_dir }}\"\n  tags:\n    - mesos-master\n\n- name: upload mesos-master template service\n  when: mesos_install_mode == \"master\"\n  template:\n    src: mesos-master.conf.j2\n    dest: /etc/init/mesos-master.conf\n    mode: 0755\n  sudo: yes\n  tags:\n    - mesos-master\n\n- name: ensure mesos-master is running (and enable it at boot)\n  when: mesos_install_mode == \"master\"\n  sudo: yes\n  service:\n    name: mesos-master\n    state: started\n    enabled: yes\n  tags:\n    - mesos-master\n"}, {"commit_sha": "cb054bd0ed781881ab5d259917184c0ff4b006a7", "sha": "ebfaba97a66a1f57ed0f5c100b52ea4c0287d1a3", "filename": "tasks/section_09_level1.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "2cfa28fd756194b32e320ab9c0df1e455f27dc38", "decoded_content": "---\n\n  - name: 9.1.1.1 Check that cron conf file exists (check) (Scored)\n    stat: path=/etc/init/cron.conf\n    register: cron_conf_stat\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.1\n\n  - name: 9.1.1.2 Enable cron Daemon (Scored)\n    lineinfile: >\n        dest='/etc/init/cron.conf'\n        line='start on runlevel [2345]'\n        state=present\n    when: not cron_conf_stat.stat.exists\n    tags:\n      - section9\n      - section9.1\n      - section9.1.1\n      - section9.1.1.2\n\n  - name: 9.1.2 Set User/Group Owner and Permission on /etc/crontab (Scored)\n    file: path='/etc/crontab' owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.2\n\n  - name: 9.1.3 Set User/Group Owner and Permission on /etc/cron.hourly (Scored)\n    file: path=/etc/cron.hourly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.3\n\n  - name: 9.1.4 Set User/Group Owner and Permission on /etc/cron.daily (Scored)\n    file: path=/etc/cron.daily owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.4\n\n  - name: 9.1.5 Set User/Group Owner and Permission on /etc/cron.weekly(Scored)\n    file: path=/etc/cron.weekly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.5\n\n  - name: 9.1.6 Set User/Group Owner and Permission on /etc/cron.monthly(Scored)\n    file: path=/etc/cron.monthly owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.6\n\n  - name: 9.1.7 Set User/Group Owner and Permission on /etc/cron.d (Scored)\n    file: path=/etc/cron.d owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.7\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (Scored)\n    file: path={{ item }} state=absent\n    with_items:\n        - /etc/cron.deny\n        - /etc/at.deny\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n  \n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    stat: path=/etc/cron.allow\n    register: cron_allow_path\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    shell: touch /etc/cron.allow\n    when: cron_allow_path.stat.exists == False\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (Scored)\n    file: path=/etc/cron.allow owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    stat: path=/etc/at.allow\n    register: at_allow_path\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (preparation) (Scored)\n    shell: touch /etc/at.allow\n    when: at_allow_path.stat.exists == False\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n\n  - name: 9.1.8 Restrict at/cron to Authorized Users (Scored)\n    file: path=/etc/at.allow owner=root group=root mode=\"og-rwx\"\n    tags:\n      - section9\n      - section9.1\n      - section9.1.8\n \n  - name: 9.2.1 Set Password Creation Requirement Parameters Using pam_cracklib (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password'\n        regexp=\"pam_cracklib.so\"\n        line=\"password required pam_cracklib.so retry=3 minlen=14 dcredit=-1 ucredit=-1 ocredit=-1 lcredit=-1\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.1\n\n#Note for section 9.2.2:\n#If a user has been locked out because they have reached the maximum consecutive failure count \n#defined by denied= in the pam_tally2.so module, the user can be unlocked by issuing the command\n#/sbin/pam_tally2 -u username --reset\n#This command sets the failed count to 0, effectively unlocking the user\n  - name: 9.2.2 Set Lockout for Failed Password Attempts (Not Scored)\n    lineinfile: >\n        dest='/etc/pam.d/login' \n        regexp='pam_tally2'\n        line=\"auth required pam_tally2.so onerr=fail audit silent deny=5 unlock_time=900\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.2\n\n  - name: 9.2.3 Limit Password Reuse (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/common-password' \n        regexp='remember=5'\n        line=\"password sufficient pam_unix.so remember=5\"\n        state=present\n    tags:\n      - section9\n      - section9.2\n      - section9.2.3\n\n  - name: 9.3 Check if ssh is installed (check)\n    stat: path='/etc/ssh/sshd_config'\n    register: ssh_config_file\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n\n  - name: 9.3.1 Set SSH Protocol to 2 (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config' \n        regexp='^Protocol'\n        state=present\n        line='Protocol 2'\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.1\n\n  - name: 9.3.2 Set LogLevel to INFO (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config' \n        regexp='^LogLevel'\n        state=present\n        line='LogLevel INFO'\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.2\n\n  - name: 9.3.3 Set Permissions on /etc/ssh/sshd_config (Scored)\n    file: path='/etc/ssh/sshd_config' owner=root group=root mode=600\n    when: ssh_config_file.stat.exists == True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.3\n\n#Regroups sections 9.3.4 9.3.7 9.3.8 9.3.9 9.3.10\n  - name: 9.3.{4,7,8,9,10} Disable some SSH options (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^{{ item }}'\n        line='{{ item }} no'\n        state=present\n    with_items: \n      - X11Forwarding\n      - HostbasedAuthentication\n      - PermitRootLogin\n      - PermitEmptyPasswords\n      - PermitUserEnvironment\n    tags:\n      - section9\n      - section9.3\n      - section9.3.4\n      - section9.3.7\n      - section9.3.8\n      - section9.3.9\n      - section9.3.10\n\n  - name: 9.3.5 Set SSH MaxAuthTries to 4 or Less (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^MaxAuthTries'\n        line='MaxAuthTries 4'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.5\n\n  - name: 9.3.6 Set SSH IgnoreRhosts to Yes (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^IgnoreRhosts'\n        line='IgnoreRhosts yes'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.6\n\n  - name: 9.3.11 Use Only Approved Cipher in Counter Mode (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Ciphers'\n        line='Ciphers aes128-ctr,aes192-ctr,aes256-ctr'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.11\n\n  - name: 9.3.12.1 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveInterval'\n        line='ClientAliveInterval 300'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.1\n\n  - name: 9.3.12.2 Set Idle Timeout Interval for User Login (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^ClientAliveCountMax'\n        line='ClientAliveCountMax 0'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.12\n      - section9.3.12.2\n\n  - name: 9.3.13.1 Limit Access via SSH (Scored)\n    shell: grep AllowUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.1\n\n  - name: 9.3.13.2 Limit Access via SSH (Scored)\n    shell: grep AllowGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.2\n\n  - name: 9.3.13.3 Limit Access via SSH (Scored)\n    shell: grep DenyUsers /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.3\n\n  - name: 9.3.13.4 Limit Access via SSH (Scored)\n    shell: grep DenyGroups /etc/ssh/sshd_config\n    register: allow_rc\n    failed_when: allow_rc.rc == 1\n    changed_when: False\n    ignore_errors: True\n    tags:\n      - section9\n      - section9.3\n      - section9.3.13\n      - section9.3.13.4\n\n  - name: 9.3.14 Set SSH Banner (Scored)\n    lineinfile: >\n        dest='/etc/ssh/sshd_config'\n        regexp='^Banner'\n        line='Banner /etc/issue.net'\n        state=present\n    tags:\n      - section9\n      - section9.3\n      - section9.3.14\n\n  - name: 9.4 Restrict root Login to System Console (Not Scored)\n    stat: path=/etc/securetty\n    register: securetty_file\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.4 Restrict root Login to System Console (Not Scored)\n    debug: msg='*** Check /etc/securetty for console allowed for root access ***'\n    when: securetty_file.stat.exists == True\n    tags:\n      - section9\n      - section9.4\n\n  - name: 9.5.1 Restrict Access to the su Command (Scored)\n    lineinfile: >\n        dest='/etc/pam.d/su'\n        line='auth            required        pam_wheel.so use_uid'\n        state=present\n    tags:\n      - section9\n      - section9.5\n      - section9.5.1\n"}, {"commit_sha": "069c7c7848545c132aff3c88fe170cbe30c8abb9", "sha": "41f6ad1b37b42bbdae8371cae869308c0cf38c61", "filename": "roles/mesos/handlers/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# handlers file for mesos\n- name: Start mesos master\n  shell: start mesos-master\n  sudo: yes\n\n- name: Start mesos slave\n  shell: start mesos-slave\n  sudo: yes\n"}, {"commit_sha": "e8eb28b4b4b1c4fb2490b8198570166b9ca23ab2", "sha": "71fb340061e49f9c9d68be454cf5e88856f97f8b", "filename": "roles/mistral/defaults/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": null, "release_ends_at": "2d0f3f1cf5d5919432c94bb3659c16b85d1cb1db", "decoded_content": "version: 0.9.0\n"}, {"commit_sha": "067d6cbb20adb31a1e2bd9f689b5b6e259c30288", "sha": "8834dc0e3488de995c43fb4a0cc8ba3d70508d4b", "filename": "tasks/section_04_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "2cfa28fd756194b32e320ab9c0df1e455f27dc38", "decoded_content": "---\n\n  - name: Check if the grub config file exists\n    stat: path=/etc/default/grub\n    register: grub_cfg_file\n\n  - name: Determines if apparmor is set in grub config\n    command: \"grep 'GRUB_CMDLINE_LINUX' /etc/default/grub\"\n    register: grub_apparmor\n    changed_when: False\n    when: grub_cfg_file.stat.exists\n\n  - name: Check if the extlinux config file exists\n    stat: path=/extlinux.conf\n    register: extlinux_cfg_file\n\n  - name: Determines if apparmor is set in extlinux\n    command: \"grep 'apparmor' /extlinux.conf\"\n    register: extlinux_apparmor\n    changed_when: False\n    when: extlinux_cfg_file.stat.exists\n\n  - name: Determines if apparmor is already set in boot config\n    command: \"grep CONFIG_DEFAULT_SECURITY_APPARMOR /boot/config-{{ ansible_kernel }}\"\n    register: boot_apparmor\n    changed_when: False\n\n  - name: 4.5 Activate AppArmor (install) (Scored)\n    apt: >\n        name=apparmor\n        state=present\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (Kernel LSM - grub)\n    lineinfile: >\n        dest='/etc/default/grub'\n        regexp='^GRUB_CMDLINE_LINUX=\"\"'\n        line='GRUB_CMDLINE_LINUX=apparmor=\"1 security=apparmor\"'\n        state=present\n    when: \"(use_apparmor == True) and grub_cfg_file.stat.exists and ('apparmor' not in grub_apparmor['stdout']) and ('not set' in boot_apparmor['stdout'])\"\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (Kernel LSM - extlinux)\n    lineinfile: >\n        dest='/extlinux.conf'\n        regexp=\"^append initrd=\"\n        line=\"append initrd={{ ansible_cmdline['initrd'] }} root={{ ansible_cmdline['root'] }} console=tty0 console={{ ansible_cmdline['console'] }} apparmor=1 security=apparmor ro quiet\"\n    when: \"(use_apparmor == True) and extlinux_cfg_file.stat.exists and ('apparmor' not in extlinux_apparmor['stdout']) and ('not set' in boot_cfg_apparmor['stdout'])\"\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (start) (Scored)\n    service: >\n        name=apparmor\n        state=started\n    when: use_apparmor == True\n    register: apparmor_status\n    ignore_errors: True\n    tags:\n      - section4\n      - section4.5\n\n  - name: Determine if Apparmor started without error\n    fail: msg=\"Apparmor can not be started. This is normal behavior if you run the playbook for the first time.\\nPlease reboot the machine and run it again to proceed with the rest of the playbook.\"\n    when: apparmor_status.failed is defined\n\n  - name: 4.5 Activate AppArmor (fix profiles) (Scored)\n    service: >\n        name=rsyslog\n        state=restarted\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (Scored)\n    command: apparmor_status\n    register: aa_status_lines\n    failed_when: '\"0 profiles are loaded\" in aa_status_lines.stdout_lines or \"0 processes are in complain mode.\" not in aa_status_lines.stdout_lines or \"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n        # - '\"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n    changed_when: False\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (enforce install) (Scored)\n    apt: >\n        name=apparmor-utils\n        state=present\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (enforce) (Scored)\n    #shell: 'aa-enforce /etc/apparmor.d/*'\n    shell: for profile in /etc/apparmor.d/*; do aa-enforce $profile; done\n    register: aaenforce_rc\n    failed_when: aaenforce_rc.rc == 1\n    changed_when: False\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n"}, {"commit_sha": "2a8ca91248bb834daaa8c35f709d6f8158d81a38", "sha": "68010ff13ed86589788e16da1e2769b63107e248", "filename": "tasks/main.yml", "repository": "nusenu/ansible-relayor", "release_starts_at": "", "release_ends_at": "", "release": "1224adf2811c827a09ff0bf133fbb476901a547d", "decoded_content": "---\n\n- name: Check for vulnerable ansible version (CVE-2016-8614, CVE-2016-8628)\n  assert:\n    that:\n      - \"{{ ansible_version.full | version_compare('2.1.3.0', '>=') }}\"\n    msg: \"VULNERABLE ansible version DETECTED, please update to v2.1.3 or newer! Exiting.\"\n  tags:\n    - always\n\n- name: Set OS specific variables\n  include_vars: \"{{ ansible_os_family }}.yml\"\n  tags:\n   - renewkey\n   - reconfigure\n\n- include: ip-list.yml\n  tags:\n    - always\n\n- include: apt_prepare.yml\n  when: ansible_pkg_mgr == 'apt'\n  tags:\n   - debian\n   - install\n\n- include: rpm_prepare.yml\n  when: ansible_os_family == 'RedHat'\n  tags:\n   - centos\n   - fedora\n   - install\n\n- include: openbsd_prepare.yml\n  when: ansible_system == 'OpenBSD'\n  tags:\n   - openbsd\n\n- include: freebsd_prepare.yml\n  when: ansible_system == 'FreeBSD'\n  tags:\n   - freebsd\n\n# we specifically opt for present over latest to improve performance\n- name: Ensure tor is installed\n  become: yes\n  package:\n    name: \"{{ item }}\"\n    state: latest\n  with_items: \"{{ tor_packages }}\"\n  # apt starts a tor client instance by default after installing the package\n  # we do not need that\n  notify:\n    - stop-and-mask default tor instance\n    - disable default tor instance FreeBSD\n  tags:\n   - openbsd\n   - freebsd\n   - debian\n   - centos\n   - fedora\n   - install\n\n- meta: flush_handlers\n\n- include: configure.yml\n  tags:\n   - debian\n   - centos\n   - fedora\n   - openbsd\n   - freebsd\n\n- include: linux_service.yml\n  when: ansible_system == 'Linux'\n  tags:\n   - debian\n   - centos\n   - fedora\n\n- include: openbsd_service.yml\n  when: ansible_system == 'OpenBSD'\n  tags:\n   - openbsd\n\n- include: freebsd_service.yml\n  when: ansible_system == 'FreeBSD'\n  tags:\n   - freebsd\n"}, {"commit_sha": "21712b74b7f5d936e70186bbed6bb37e3a7ad5e6", "sha": "8820314c8b0d5f50b986ad9c83af8bb00ebe3095", "filename": "roles/mesos/tasks/slave.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# Tasks for Slave nodes\n\n- name: create mesos-slave work directory\n  when: mesos_install_mode == \"slave\"\n  file:\n    path: \"{{ mesos_slave_work_dir }}\"\n    state: directory\n    mode: 0755\n  sudo: yes\n  tags:\n    - mesos-slave\n\n- name: run mesos-slave container\n  when: mesos_install_mode == \"slave\"\n  docker:\n    name: mesos-slave\n    image: \"mesosphere/mesos-slave:0.23.0-1.0.ubuntu1404\"\n    state: started\n    privileged: true\n    volumes:\n    - \"{{ mesos_slave_work_dir }}:{{ mesos_slave_work_dir }}\"\n    - \"/proc:/host/proc:ro\"\n    - \"/cgroup:/cgroup\"\n    - \"/sys:/sys\"\n    - \"/lib/libpthread.so.0:/lib/libpthread.so.0:ro\"\n    - \"/usr/bin/docker:/usr/bin/docker:ro\"\n    - \"/usr/lib/x86_64-linux-gnu/libapparmor.so.1.1.0:/usr/lib/x86_64-linux-gnu/libapparmor.so.1\"\n    - \"{{ mesos_docker_socket }}:/var/run/docker.sock\"\n    ports:\n    - \"{{ mesos_slave_port }}:{{ mesos_slave_port }}\"\n    net: \"host\"\n    env:\n      MESOS_MASTER: \"zk://{{ zookeeper_peers_nodes }}/mesos\"\n      MESOS_EXECUTOR_REGISTRATION_TIMEOUT: \"{{ mesos_executor_registration_timeout }}\"\n      MESOS_CONTAINERIZERS: \"{{ mesos_containerizers }}\"\n      MESOS_RESOURCES: \"{{ mesos_resources }}\"\n      MESOS_IP: \"{{ mesos_ip }}\"\n      MESOS_WORK_DIR: \"{{ mesos_slave_work_dir }}\"\n      MESOS_HOSTNAME: \"{{ mesos_hostname }}\"\n  tags:\n    - mesos-slave\n\n- name: upload mesos-slave template service\n  when: mesos_install_mode == \"slave\"\n  template:\n    src: mesos-slave.conf.j2\n    dest: /etc/init/mesos-slave.conf\n    mode: 0755\n  sudo: yes\n  tags:\n    - mesos-slave\n\n- name: ensure mesos-slave is running (and enable it at boot)\n  when: mesos_install_mode == \"slave\"\n  sudo: yes\n  service:\n    name: mesos-slave\n    state: started\n    enabled: yes\n  tags:\n    - mesos-slave\n\n"}, {"commit_sha": "61b008311c40b377e57e166b778232a20224f7c6", "sha": "8947cbb8d9f0fe5a7df4c288a47426966c9f3682", "filename": "tasks/replication_init_auth.yml", "repository": "UnderGreen/ansible-role-mongodb", "release_starts_at": "", "release_ends_at": "", "release": "42487b9f4681a078ef82c07c3307a51653a19791", "decoded_content": "---\n- name: Replication configuration\n  mongodb_replication:\n    login_host: \"{{ mongodb_login_host|default('localhost') }}\"\n    login_port: \"{{ mongodb_conf_port|default(27017) }}\"\n    login_user: \"{{ mongodb_root_admin_name }}\"\n    login_password: \"{{ mongodb_root_admin_password }}\"\n    replica_set: \"{{ mongodb_conf_replSet }}\"\n    host_name: \"{{ item.host_name }}\"\n    host_port: \"{{ item.host_port|default(27017) }}\"\n    host_type: \"{{ item.host_type|default('replica') }}\"\n    hidden: \"{{ item.hidden|default(false) }}\"\n    priority: \"{{ item.priority|default(1.0) }}\"\n  with_items:\n    - \"{{ mongodb_replication_params }}\"\n  register: mongodb_replica_init\n  ignore_errors: true\n\n- include: auth_initialization.yml\n  when: mongodb_replica_init|failed\n\n- name: Replication configuration\n  mongodb_replication:\n    login_host: \"{{ mongodb_login_host|default('localhost') }}\"\n    login_port: \"{{ mongodb_conf_port|default(27017) }}\"\n    login_user: \"{{ mongodb_root_admin_name }}\"\n    login_password: \"{{ mongodb_root_admin_password }}\"\n    replica_set: \"{{ mongodb_conf_replSet }}\"\n    host_name: \"{{ item.host_name }}\"\n    host_port: \"{{ item.host_port|default(27017) }}\"\n    host_type: \"{{ item.host_type|default('replica') }}\"\n    hidden: \"{{ item.hidden|default(false) }}\"\n    priority: \"{{ item.priority|default(1.0) }}\"\n  with_items:\n    - \"{{ mongodb_replication_params }}\"\n  when: mongodb_replica_init|failed\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "d2bdd99a18fe1c4422f90361c1a808dd054c816b", "filename": "roles/st2/defaults/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": null, "release_ends_at": "2d0f3f1cf5d5919432c94bb3659c16b85d1cb1db", "decoded_content": "---\n# Required memory for st2 installation in MB\nst2_required_memory: 2000\n# MongoDB requires at least 3379MB available in /var/lib/mongo/journal\nst2_required_space: 3500\n\n# 'stable', 'unstable' to get latest version or numeric like '0.12.1'\nst2_version: stable\n# 'current' to get latest revision or numberic like '6'\nst2_revision: current\n\nst2_system_user: stanley\nst2_ssh_key_file: /home/{{ st2_system_user }}/.ssh/{{ st2_system_user }}_rsa\n\nst2_packages:\n  - st2common\n  - st2actions\n  - st2api\n  - st2auth\n  - st2client\n  - st2debug\n  - st2reactor\n\n# Number of action runners to register. Defaults to number of vCPUs, but not less than 2\nst2_action_runners: \"{{ [ansible_processor_vcpus, 2] | max }}\"\n\nst2_auth_username: testu\nst2_auth_password: testp\n\n# Set to no if you do not want the st2_system_user to be added in\n# the sudoers file.\nst2_system_user_in_sudoers: yes\n\n"}, {"commit_sha": "f85435227eb23c6e474103286c17d7406baeff47", "sha": "d975d7a7ff5263ddfac64b6a562ffeb80e3575c8", "filename": "roles/mesos/tasks/master.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# Tasks for Master nodes\n\n- name: set mesos-master consul service definition\n  when: mesos_install_mode == \"master\"\n  sudo: yes\n  template:\n    src: mesos-master-consul.j2\n    dest: \"{{ consul_dir }}/mesos-master.json\"\n  notify:\n    - restart consul\n  tags:\n    - mesos-master\n\n- name: create mesos-master work directory\n  when: mesos_install_mode == \"master\"\n  file:\n    path: \"{{ mesos_master_work_dir }}\"\n    state: directory\n    mode: 0755\n  sudo: yes\n  tags:\n    - mesos-master\n\n- name: run mesos-master container\n  when: mesos_install_mode == \"master\"\n  docker:\n    name: mesos-master\n    image: \"{{ mesos_master_image }}\"\n    state: started\n    volumes:\n    - \"{{ mesos_master_work_dir }}:{{ mesos_master_work_dir }}\"\n    ports:\n    - \"{{ mesos_master_port }}:{{ mesos_master_port }}\"\n    net: \"host\"\n    env:\n      MESOS_HOSTNAME: \"{{ mesos_hostname }}\"\n      MESOS_IP: \"{{ mesos_ip }}\"\n      MESOS_CLUSTER: \"{{ mesos_cluster_name }}\"\n      MESOS_ZK: \"zk://{{ zookeeper_peers_nodes }}/mesos\"\n      MESOS_LOG_DIR: \"/var/log/mesos\"\n      MESOS_QUORUM: \"{{ mesos_quorum }}\"\n      MESOS_WORK_DIR: \"{{ mesos_master_work_dir }}\"\n  tags:\n    - mesos-master\n\n- name: upload mesos-master template service\n  when: mesos_install_mode == \"master\"\n  template:\n    src: mesos-master.conf.j2\n    dest: /etc/init/mesos-master.conf\n    mode: 0755\n  sudo: yes\n  tags:\n    - mesos-master\n\n- name: ensure mesos-master is running (and enable it at boot)\n  when: mesos_install_mode == \"master\"\n  sudo: yes\n  service:\n    name: mesos-master\n    state: started\n    enabled: yes\n  tags:\n    - mesos-master\n\n- name: run prometheus mesos master exporter container\n  when: mesos_install_mode == \"master\" and prometheus_enabled|bool\n  docker:\n    name: mesos-exporter\n    image: \"{{ prometheus_mesos_exporter_image }}\"\n    command: \"-exporter.scrape-mode=master -exporter.url=http://{{ mesos_hostname }}:{{ mesos_master_port }}\"\n    state: started\n    restart_policy: always\n    ports:\n    - \"{{ prometheus_mesos_exporter_port }}:{{ prometheus_mesos_exporter_port }}\"\n  environment: proxy_env\n  tags:\n    - prometheus\n    - mesos_master\n\n- name: Set mesos-exporter consul service definition\n  when: mesos_install_mode == \"master\" and prometheus_enabled|bool\n  sudo: yes\n  template:\n    src: mesos-exporter-consul.j2\n    dest: \"{{ consul_dir }}/mesos-exporter.json\"\n  notify:\n    - restart consul\n  tags:\n    - prometheus\n    - mesos_master\n"}, {"commit_sha": "e42f58bc7e876fea3462e363d8ab780889ef000c", "sha": "07c550c5e536e03ac0aac6d0eb2d573f16ad9c72", "filename": "roles/mistral/defaults/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": null, "release_ends_at": "2d0f3f1cf5d5919432c94bb3659c16b85d1cb1db", "decoded_content": "mistral_version: 0.13\nmistral_db_username: mistral\nmistral_db_password: StackStorm\nmistral_db: mistral\n"}, {"commit_sha": "c5ee48e16a5905db37ff878be57f5de16f769368", "sha": "652bdc840882bcd10fa0b521a560196b0e4c1134", "filename": "tasks/main.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "2cfa28fd756194b32e320ab9c0df1e455f27dc38", "decoded_content": "---\n\n  - include: section_01.yml\n    tags: section01\n\n  - include: section_02.yml\n    tags: section02\n\n  - include: section_03.yml\n    tags: section03\n\n  - include: section_04.yml\n    tags: section04\n\n  - include: section_05.yml\n    tags: section05\n\n  - include: section_06.yml\n    tags: section06\n\n  - include: section_07.yml\n    tags: section07\n\n  - include: section_08.yml\n    tags: section08\n\n  - include: section_09.yml\n    tags: section09\n\n  - include: section_10.yml\n    tags: section10\n\n  - include: section_11.yml\n    tags: section11\n\n  - include: section_12.yml\n    tags: section12\n\n  - include: section_13.yml\n    tags: section13\n\n"}, {"commit_sha": "addbee435e20e706e7cf5d2f0a3723e17f79b527", "sha": "414447bee7bd8f011eff223c86cdeddb0d71ae66", "filename": "tasks/section_04_level2.yml", "repository": "awailly/cis-ubuntu-ansible", "release_starts_at": "", "release_ends_at": "", "release": "2cfa28fd756194b32e320ab9c0df1e455f27dc38", "decoded_content": "---\n\n  - name: 4.5 Activate AppArmor (install) (Scored)\n    apt: >\n        name=apparmor\n        state=present\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (start) (Scored)\n    service: >\n        name=apparmor\n        state=started\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n      \n  - name: 4.5 Activate AppArmor (fix profiles) (Scored)\n    service: >\n        name=rsyslog\n        state=restarted\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (Scored)\n    command: apparmor_status\n    register: aa_status_lines\n    failed_when: '\"0 profiles are loaded\" in aa_status_lines.stdout_lines or \"0 processes are in complain mode.\" not in aa_status_lines.stdout_lines or \"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n        # - '\"0 processes are unconfined but have a profile defined.\" not in aa_status_lines.stdout_lines'\n    changed_when: False\n    when: travis_env == False and use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (enforce install) (Scored)\n    apt: >\n        name=apparmor-utils\n        state=present\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n\n  - name: 4.5 Activate AppArmor (enforce) (Scored)\n    #shell: 'aa-enforce /etc/apparmor.d/*'\n    shell: for profile in /etc/apparmor.d/*; do aa-enforce $profile; done\n    register: aaenforce_rc\n    failed_when: aaenforce_rc.rc == 1\n    changed_when: False\n    when: use_apparmor == True\n    tags:\n      - section4\n      - section4.5\n"}, {"commit_sha": "9966c6de1ed4ef5071a9bea83b4bb69a11dd32ba", "sha": "a7a3e42e2e6c2c0a479181620eb333e8009a2d4e", "filename": "roles/docker/tasks/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# tasks file for docker\n- name: remove docker override\n  file: path=/etc/init/docker.override state=absent\n\n- name: ensure docker is running (and enable it at boot)\n  service: name=docker state=started enabled=yes\n"}, {"commit_sha": "3e6af1f0f55cd8f3bfb91cac5560c476d8145a32", "sha": "e55d0c111e3ce50d3ce71adc719c65119a798075", "filename": "roles/mesos/defaults/main.yml", "repository": "Capgemini/Apollo", "release_starts_at": "", "release_ends_at": "", "release": "308889b1c7c114ab9079c9050ee083fffe5508be", "decoded_content": "---\n# Common\nconsul_dir: /etc/consul.d\nmesos_executor_registration_timeout: 10mins\nmesos_cluster_name: \"Cluster01\"\nmesos_ip: \"{{ ansible_default_ipv4.address }}\"\nmesos_hostname: \"{{ ansible_ssh_host }}\"\nmesos_docker_socket: \"/var/run/weave/weave.sock\"\nmesos_version: \"0.26.0-0.2.145.ubuntu1404\"\n\n# Defaults file for mesos-salve\nmesos_slave_port: 5051\nmesos_containerizers: \"docker,mesos\"\nmesos_resources: \"ports(*):[31000-32000]\"\nmesos_slave_work_dir: \"/tmp/mesos\"\nmesos_slave_image: \"mesosphere/mesos-slave:{{ mesos_version }}\"\nmesos_slave_rebuild_container: false\n\n# Defaults file for mesos-master\nmesos_zookeeper_group: zookeeper_servers\nmesos_master_port: 5050\nmesos_master_work_dir: \"/var/lib/mesos\"\nmesos_master_image: \"mesosphere/mesos-master:{{ mesos_version }}\"\nmesos_master_rebuild_container: false\n\nprometheus_mesos_exporter_image: \"prom/mesos-exporter:latest\"\nprometheus_mesos_exporter_port: 9105\nprometheus_mesos_exporter_consul_service_id: \"{{ ansible_hostname }}:mesos-exporter:{{ prometheus_mesos_exporter_port }}\"\n\n# The Mesos quorum value is based on the number of Mesos Masters. Take the\n# number of masters, divide by 2, and round-up to nearest integer. For example,\n# if there are 1 or 2 masters the quorum count is 1. If there are 3 or 4\n# masters then the quorum count is 2. For 5 or 6 masters it's 3 and so on.\nmesos_quorum: \"\n{% if mesos_master_quorum is defined %}\n{{ mesos_master_quorum }}\n{% else %}\n{{ ( groups.mesos_masters|count / 2) | round(0, 'ceil') | int }}\n{%- endif -%}\n\"\n"}, {"commit_sha": "3b115b4dc2162b35c18ab751c8343a95c31caec5", "sha": "de6811b879196d3c36afdbb0aa91ca47532cad5a", "filename": "roles/mongodb/tasks/main.yml", "repository": "StackStorm/ansible-st2", "release_starts_at": null, "release_ends_at": "c9fae17a7c09d2ca31d2d2605ed6da4ac8d37d67", "decoded_content": "- name: Install dependencies\n  sudo: true\n  apt:\n    name: \"{{ item }}\"\n    update_cache: yes\n    state: present\n  with_items:\n    - mongodb-server\n"}]